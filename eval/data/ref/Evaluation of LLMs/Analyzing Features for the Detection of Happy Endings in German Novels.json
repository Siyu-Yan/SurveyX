{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1611.09028",
    "title": "Analyzing Features for the Detection of Happy Endings in German Novels",
    "abstract": "With regard to a computational representation of literary plot, this paper looks at the use of sentiment analysis for happy ending detection in German novels. Its focus lies on the investigation of previously proposed sentiment features in order to gain insight about the relevance of specific features on the one hand and the implications of their performance on the other hand. Therefore, we study various partitionings of novels, considering the highly variable concept of \"ending\". We also show that our approach, even though still rather simple, can potentially lead to substantial findings relevant to literary studies.",
    "bib_name": "jannidis2016analyzingfeaturesdetectionhappy",
    "md_text": "Analyzing Features for the Detection of Happy Endings in German Novels  Fotis Jannidis, Isabella Reger, Albin Zehe, Martin Becker, Lena Hettinger, Andreas Hotho\n# Abstract \nWith regard to a computational representation of literary plot, this paper looks at the use of  sentiment analysis for happy ending detection in German novels. Its focus lies on the  investigation of previously proposed sentiment features in order to gain insight about the  relevance of specific features on the one hand and the implications of their performance on the other hand. Therefore, we study various partitionings of novels, considering the highly  variable concept of \"ending\". We also show that our approach, even though still rather  simple, can potentially lead to substantial findings relevant to literary studies. \n# Introduction \nPlot is fundamental for the structure of literary works. Methods for the computational                           representation of plot or special plot elements would therefore be a great achievement for                            digital literary studies. This paper looks at one such element: happy endings.  We employ sentiment analysis for the detection of happy endings, but focus on a qualitative                              analysis of specific features and their performance in order to gain deeper insight into the                               automatic classification. In addition, we show how the applied method can be used for                           subsequent research questions, yielding interesting results with regard to publishing periods                     of the novels. \n# Related Work\nOne of the first works was on folkloristic tales, done by Mark Finlayson, who created an                                 algorithm capable of detecting events and higher-level abstractions, such as villainy or                         reward (Finlayson 2012). Reiter et al., again on tales, identify events, their participants and                             order and use machine learning methods to find structural similarities across texts (Reiter                           2013, Reiter et al. 2014).   Recently, a significant amount of attention has been paid to sentiment analysis, when                           Matthew Jockers proposed emotional arousal as a new \u201cmethod for detecting plot\u201d (Jockers                          2014). He described his idea to split novels into segments and use those to form plot                                 trajectories (Jockers 2015). Despite general acceptance of the idea to employ sentiment                         analysis, his use of the Fourier Transformation to smooth the resulting plot curves was                             criticized (Swafford 2015, Schmidt 2015).  Among other features, Micha Elsner (Elsner 2015) builds plot representations of romantic                         novels, again by using sentiment trajectories. He also links such trajectories with specific                           characters and looks at character co-occurrences. To evaluate his approach, he                       distinguishes real novels from artificially reordered surrogates with considerable success,                     showing that his methods indeed capture certain aspects of plot structure.  In previous work, we used sentiment features to detect happy endings as a major plot                              element in German novels, reaching an F1-score of 73% (Zehe et al. 2016). \nCorpus and Resources  Our dataset consists of 212 novels in German language mostly from the 19th century . Each                               1 novel has been manually annotated as either having a happy ending (50%) or not (50%).                              The relevant information has been obtained from summaries of the Kindler Literary Lexikon                           Online and Wikipedia. If no summary was available, the corresponding parts of the novel                          2 have been read by the annotators.    Sentiment analysis requires a resource which lists sentiment values that human readers                      typically associate with certain words or phrases in a text. This paper relies on the NRC                                Sentiment Lexicon (Mohammad and Turney 2013), which is available in an automatically                       translated German version . A notable feature of this lexicon is that besides specifying binary                           3 values (0 or 1) for negative and positive connotations (2 features) it also categorizes words                              into 8 basic emotions (anger, fear, disgust, surprise, joy, anticipation, trust and sadness),                          see Table 1 for an example. We add another value (the polarity) by subtracting the negative                                from the positive value (e.g. a word with a positive value of 0 and a negative value of 1 has a                                     polarity value of -1). The polarity serves as an overall sentiment score, which results in 11                                 features.  \n<div style=\"text-align: center;\">Table 1 : Example entries from the NRC Sentiment Lexicon</div>\nTable 1\n: Example entries from the NRC Sentiment Lexicon \nWord/Dimension \nverabscheuen \n(to detest) \nbewundernswert \n(admirable) \nZufall \n(coincidence) \nPositive \n0 \n1 \n0 \nNegative \n1 \n0 \n0 \nPolarity \n-1 \n1 \n0 \nAnger \n1 \n0 \n0 \nAnticipation \n0 \n0 \n0 \nDisgust \n1 \n0 \n0 \nFear \n1 \n0 \n0 \nJoy \n0 \n1 \n0 \nSadness \n0 \n0 \n0 \nSurprise \n0 \n0 \n1 \nTrust \n0 \n1 \n0 \n \nThe goal of this paper is to investigate features that have been used for the detection of                                   happy endings in novels in order to gain insight about the relevance of specific feature sets                                 on the one hand and the implications of their performance on the other hand. To that end,                                   we adopt the features and methods presented in Zehe et al. (2016). The parameters of the                               linear SVM and the partitioning into 75 segments are also adopted from this paper. \n1 Source: https://textgrid.de/digitale-bibliothek  2 www.kll-online.de  3 http://saifmohammad.com/WebPages/NRC-Emotion-Le\nFeatures. Since reliable chapter annotations were not available, each novel has been split                         into 75 equally sized blocks, called \u200bsegments . For each lemmatized word, we look up the 11                               sentiment values (including polarity, see above). Then, for each segment, we calculate the                         respective averages, resulting in 11 scores per segment. We group those 11 scores into one                            feature set. \nQualitative Feature Analysis . As our corpus consists of an equal number of novels with and                               without happy ending, the random baseline as well the majority vote baseline amount to 50%                               classification accuracy.  Since we assumed that the relevant information for identifying happy endings can be found                             at the end of a novel, we first used the sentiment scores of the final segment ( ) as the                               fd,n       only feature set, reaching an F1-score of 67%.   Following the intuition that not only the last segment by itself, but also its relation to the rest                                     of the novel are meaningful for the classification, we introduced the notion of \u200bsections : the                               last segment of a novel constitutes the \u200bfinal section , whereas the remaining segments                           belong to the \u200bmain section . Averages were also calculated for the sections by taking the                               mean of each feature over all segments in the section. To further emphasize the relation                               between these sections, we added the differences between the sentiment scores of the final                             section and the average sentiment scores over all segments in the main section. However,                             this change did not influence the results.  This led us to believe that our notion of an \u201cending\u201d was not accurate enough, as the number                                     of segments for each novel and therefore the boundaries of the final segment have been                               chosen rather arbitrarily. To approach this issue, we varied the partitioning into main and                             final section so that the final section can contain more than just the last segment.  \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6655/665507f3-54b4-433d-ba09-ddd06eb5ccdc.png\" style=\"width: 50%;\"></div>\nFigure 1\u200b: \u200bClassification F1-score for different partitionings into main and final                       section. The dashed line represents a random baseline, the dotted line shows                        where the maximum F1-score is reached. \nFigure 1 shows that classification accuracy improves when at least 75% of the segments are                              in the main section and reaches a peak at about 95% (this means 4 segments in the final                                   section and 71 segments in the main section, for a total of 75 segments). With this                                 partitioning strategy, we improve the F1-score to 68% using only the feature set for the final                                 section ( ) and reach an F1-score of 69% when also including the differences to the  fd, final                             average sentiment scores of the main section ( ). fd, main\u2212final   Since adding the relation between the main section and the final section improved our                             results in the previous setting, we tried to model the development of the sentiments towards                               the end of the novel in a more profound way. For example, a catastrophic event might                               happen shortly before the end of a novel and finally be resolved in a happy ending. To                                 capture this intuition, we introduced one more section, namely the \u200blate-main section, which                           focuses on the segments right \u200bbefore the final section, and used the difference between the                               feature sets for the late-main and the final section as an additional feature set ( ).                            fd, late\u2212final   Using those three feature sets, the classification of happy endings reaches an F1-score of                             70% and increases to 73% when including the feature set for the final segment. \n<div style=\"text-align: center;\">able 2 : Classification F1-score for the different feature sets</div>\nFeatures \nResults \n1) Final segment feature set \n67% \n2) Final segment feature set and difference to main section \n67% \n3) Final section feature set with final section of length 4 \n68% \n4) Feature set 3 and difference to main section \n69% \n5) Feature set 4 and difference between late-main section and final\n \n \n \n \n \n \n \n \n \n \n \nsection \n70% \n6) Feature set 5 and final segment feature set \n73% \n \nTable 2 summarizes these results and shows that the addition of each feature set leads to                              small improvements, amounting up to a F1-score of 73%. While we saw that the                           classification performs best when the final section consists of 4 segments, we also observed                          that quite a few novels could be correctly classified with several different partitionings. On                          the other hand, some novels could not be predicted correctly with any choice of partitioning.                             An example is \u200bTwenty Thousand Leagues Under the Sea by Jules Verne which evidently has a                                happy ending with clearly identifiable boundaries, but an extremely short one, consisting only of                            about 250 words. These observations show that the notion of a novel\u2019s \u201cending\u201d is highly variable                              and can differ considerably from text to text. \nCorrelation with Publication Dates. This raises the question whether we can use the sensitivity of                              our approach to this kind of variability in order to better understand the characteristics of the                                \nnovels in our corpus. As an example, we studied whether different section partitionings are in any                               way correlated with the publication date of a novel. In order to keep the results as interpretable                                as possible, we focused on one single feature set: the sentiment scores of the final section. In a                                  first attempt, we divided our corpus into four subgroups, distinguishing novels published before                         1830 (65 novels), between 1831 and 1848 (31 novels), between 1849 and 1870 (29 novels) and                                 after 1871 (87 novels). This split resulted in similarly sized portions and did not yield a strong                                 bias towards happy/unhappy endings in any period. \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f88b/f88b4001-c5fb-4396-bcac-0a352320b1d7.png\" style=\"width: 50%;\"></div>\nFigure 2\u200b: Classification F1-score for different partitionings into main and final                       section. Each line denotes novels from a different time period. The dashed line                          represents the random baseline for the time period starting from 1871. Random                         baselines for the other periods yield slightly worse results and are omitted. The                           dotted lines show where the maximum F1-score is reached for the respective time                          periods. \nFigure 2 shows that the best classification is again obtained when about 95 - 98% of the                                 segments are in the main section, regardless of the time period. Therefore, the best section split                                point is not correlated with the publication date of a novel. What is striking, however, is the fact                                that the novels published after 1848 yield considerably lower scores than the novels published                             before that year, mostly even below the baseline. This indicates a correlation between                         publication date and automatic classification quality, i.e. novels published before the period of                         Realism are more easily classifiable in terms of having a happy ending than realistic novels. A                               possible explanation is that many novels of that earlier period are more schematically structured   We are aware that the number of novels for each of the time spans is rather small, so that those                                      findings can only be regarded as exploratory insights. Nevertheless, these preliminary results                       show that the automatic detection of happy endings, even with only one rather simple feature set,                               \ncan uncover dependencies to other properties of novels that are highly interesting for literary                             studies. \nConclusion and Future Work  The automatic detection of happy endings as a major plot element of novels is a valuable                             step towards a comprehensive computational representation of literary plot. Our experiments                    show that different features based on sentiment analysis can predict happy endings in                         novels with varying but reasonable quality. Even though our approach is still rather simple,                          we showed that it can potentially lead to substantial insights for literary scholars.  Future work may cover improving our classification by accounting for the high variability of                           endings in novels and may also include further leveraging our approach to study the                           characteristics of different novel collections in-depth. \n  References  Elsner, Micha\u200b (2015): \u201cAbstract Representations of Plot Structure\u201d, in: \u200bLinguistic Issues in  Language Technology  12 (5).    Finlayson, Mark A.\u200b (2012):\u200b Learning Narrative Structure from Annotated Folktales . PhD  thesis, Massachusetts Institute of Technology.    Jockers, Matthew L.\u200b (2014): \u201cA novel method for detecting plot\u201d.  http://www.matthewjockers.net/2014/06/05/a-novel-method-for-detecting-plot/\u200b [Access date 25. August 2016].    Jockers, Matthew L.\u200b (2015): \u201cThe rest of the story\u201d.  http://www.matthewjockers.net/2015/02/25/the-rest-of-the-story/\u200b [Access date 25. August  2016].    Mohammad, Saif / Turney, Peter\u200b (2013): \u201cCrowdsourcing a Word-Emotion Association  Lexicon\u201d, in: \u200bComputational Intelligence  29 (3): 436-465.    Reiter, Nils\u200b (2013): \u200bDiscovering Structural Similarities in Narrative Texts using Event  Alignment Algorithms . PhD thesis, Heidelberg University.    Reiter, Nils / Frank, Anette / Hellwig, Oliver\u200b (2014): \u201cAn NLP-based Cross-Document  Approach to Narrative Structure Discovery\u201d, in: \u200bLiterary and Linguistic Computing  29 (4):  583\u2013605. 10.1093/llc/fqu055.    Schmidt, Benjamin M.\u200b (2015): \u201cCommodius vici of recirculation: the real problem with  Syuzhet\u201d.  http://benschmidt.org/2015/04/03/commodius-vici-of-recirculation-the-real-problem-with-syu het/\u200b [Access date 25. August 2016].    Swafford, Annie\u200b (2015): \u201cProblems with the Syuzhet Package\u201d.  https://annieswafford.wordpress.com/2015/03/02/syuzhet/\u200b [Access date 25. August 2016]. \nReferences  Elsner, Micha\u200b (2015): \u201cAbstract Representations of Plot Structure\u201d, in: \u200bLinguistic Issue Language Technology  12 (5). \n# Jockers, Matthew L.\u200b (2014): \u201cA novel method for detecting plot\u201d.  http://www.matthewjockers.net/2014/06/05/a-novel-method-for-detecting-plot/\u200b [Access date 25. August 2016]. \nZehe, Albin / Becker, Martin / Hettinger, Lena / Hotho, Andreas / Reger, Isabella /  Jannidis, Fotis\u200b (2016): \"Prediction of Happy Endings in German Novels\", in:\u200b Proceedings of  the Workshop on Interactions between Data Mining and Natural Language Processing 2016 . \n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the computational representation of literary plot, specifically focusing on the detection of happy endings in German novels through sentiment analysis. It discusses previous methods and highlights the need for a new approach to enhance understanding in digital literary studies.",
        "problem": {
            "definition": "The problem is to accurately detect happy endings in German novels using sentiment analysis, which involves analyzing the sentiment features of the text.",
            "key obstacle": "The main challenge is the variability in the concept of 'ending', which affects the effectiveness of existing methods for classification."
        },
        "idea": {
            "intuition": "The idea is inspired by the notion that sentiment scores, particularly towards the end of a novel, can provide crucial insights into whether a story concludes happily.",
            "opinion": "The proposed method involves a qualitative analysis of sentiment features to classify happy endings, aiming to refine the automatic classification process.",
            "innovation": "The key innovation is the introduction of a new partitioning strategy for the segments of novels, which allows for a more nuanced understanding of how sentiment evolves towards the end."
        },
        "method": {
            "method name": "Sentiment Analysis for Happy Ending Detection",
            "method abbreviation": "SAHED",
            "method definition": "A method that analyzes sentiment features in segmented novels to classify the presence of happy endings.",
            "method description": "The method involves partitioning novels into segments and analyzing sentiment scores to detect happy endings.",
            "method steps": [
                "Segment the novel into 75 equally sized blocks.",
                "Calculate sentiment scores for each segment using the NRC Sentiment Lexicon.",
                "Analyze the final segment and its relation to previous segments to classify the ending."
            ],
            "principle": "This method is effective because it leverages variations in sentiment scores to capture the emotional trajectory leading to the ending of a novel."
        },
        "experiments": {
            "evaluation setting": "The dataset consists of 212 novels from the 19th century, manually annotated for happy endings, and sentiment scores are derived from the NRC Sentiment Lexicon.",
            "evaluation method": "The performance of the method was assessed using F1-scores based on different feature sets and partitioning strategies for the segments."
        },
        "conclusion": "The experiments indicate that sentiment analysis can predict happy endings in novels with reasonable accuracy, suggesting that further refinement of the method could yield valuable insights for literary studies.",
        "discussion": {
            "advantage": "The approach allows for a computational representation of literary plots, making it easier to analyze large corpora of texts for specific narrative elements.",
            "limitation": "The method is still quite simple and may not account for the complexity and variability of endings in all novels.",
            "future work": "Future research may involve improving classification accuracy by addressing the variability of endings and exploring deeper characteristics of different novel collections."
        },
        "other info": {
            "info1": "The study demonstrates correlations between publication dates and the classification quality of happy endings.",
            "info2": {
                "info2.1": "The approach is exploratory and indicates potential for further research.",
                "info2.2": "The findings suggest that novels published before the period of Realism are more easily classifiable."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "This paper addresses the computational representation of literary plot, specifically focusing on the detection of happy endings in German novels through sentiment analysis."
        },
        {
            "section number": "1.2",
            "key information": "The main challenge is the variability in the concept of 'ending', which affects the effectiveness of existing methods for classification."
        },
        {
            "section number": "2.1",
            "key information": "Define fundamental terms such as sentiment analysis and its application in detecting narrative elements like happy endings."
        },
        {
            "section number": "2.2",
            "key information": "The study demonstrates correlations between publication dates and the classification quality of happy endings."
        },
        {
            "section number": "3.1",
            "key information": "The method involves partitioning novels into segments and analyzing sentiment scores to detect happy endings."
        },
        {
            "section number": "3.2",
            "key information": "The performance of the method was assessed using F1-scores based on different feature sets and partitioning strategies for the segments."
        },
        {
            "section number": "5.4",
            "key information": "Future research may involve improving classification accuracy by addressing the variability of endings and exploring deeper characteristics of different novel collections."
        },
        {
            "section number": "6.1",
            "key information": "The proposed method involves a qualitative analysis of sentiment features to classify happy endings, aiming to refine the automatic classification process."
        },
        {
            "section number": "7",
            "key information": "The experiments indicate that sentiment analysis can predict happy endings in novels with reasonable accuracy, suggesting that further refinement of the method could yield valuable insights for literary studies."
        }
    ],
    "similarity_score": 0.5965040997488742,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-0214_large/papers/Analyzing Features for the Detection of Happy Endings in German Novels.json"
}