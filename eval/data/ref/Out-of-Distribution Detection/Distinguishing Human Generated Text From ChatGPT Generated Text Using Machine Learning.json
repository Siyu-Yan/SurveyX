{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2306.01761",
    "title": "Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning",
    "abstract": "ChatGPT is a conversational artificial intelligence that is a member of the generative pre-trained transformer of the large language model family. This text generative model was fine-tuned by both supervised learning and reinforcement learning so that it can produce text documents that seem to be written by natural intelligence. Although there are numerous advantages of this generative model, it comes with some reasonable concerns as well. This paper presents a machine learning-based solution that can identify the ChatGPT delivered text from the human written text along with the comparative analysis of a total of 11 machine learning and deep learning algorithms in the classification process. We have tested the proposed model on a Kaggle dataset consisting of 10,000 texts out of which 5,204 texts were written by humans and collected from news and social media. On the corpus generated by GPT-3.5, the proposed algorithm presents an accuracy of 77%.",
    "bib_name": "islam2023distinguishinghumangeneratedtext",
    "md_text": "# Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning\nNiful Islam1, Debopom Sutradhar1, Humaira Noor1, Jarin Tasnim Raya2, Monowara Tabassum Maisha2, Dewan Md Farid1 1Department of CSE, United International University (UIU), Bangladesh 2Department of CSE, University of Asia Pacific (UAP), Bangladesh Email : {nislam201057, dsutradhar201046}@bscse.uiu.ac.bd, hnoor222007@mscse.uiu.ac.bd, {20101002, 20101001}@uap-bd.edu, dewanfarid@cse.uiu.ac.bd\nAbstract\u2014ChatGPT is a conversational artificial intelligence that is a member of the generative pre-trained transformer of the large language model family. This text generative model was finetuned by both supervised learning and reinforcement learning so that it can produce text documents that seem to be written by natural intelligence. Although there are numerous advantages of this generative model, it comes with some reasonable concerns as well. This paper presents a machine learning-based solution that can identify the ChatGPT delivered text from the human written text along with the comparative analysis of a total of 11 machine learning and deep learning algorithms in the classification process. We have tested the proposed model on a Kaggle dataset consisting of 10,000 texts out of which 5,204 texts were written by humans and collected from news and social media. On the corpus generated by GPT-3.5, the proposed algorithm presents an accuracy of 77%. Index Terms\u2014ChatCPT, Classification, Generative AI, NLP, Tokenization\n# I. INTRODUCTION\nThe emergence of generative AI models are rapidly changing our way of communication. It is being extensively used in content creation, arts and design, healthcare and many more. Although these models, especially conversational AI models like ChatGPT, have the potential of revolutionizing the society, they also come with some possible dangers. One of the biggest concerns is that, it can produce false news or spread misinformation [1] [2]. Since, the AI-generated texts are almost identical to the human-generated texts, the model can be used to manipulate individuals or organizations in various ways. There are some legal and ethical concerns of using generative AI. Since these models are trained on large datasets, there might remain some bias in a particular sector. For decision making, if an individual employs these models, it may lead to discriminatory attitudes. Furthermore, students may rely too heavily on the AI generated tools, which could damage their critical thinking and communication ability, negatively impacting their academic and professional life [3]. For newly developed problems, it requires new solutions. As these models are trained on old data, asking solutions for advanced challenges might provide misleading solutions [4]. In addition, incorporating conversational AI into the system could result in low user satisfaction. Therefore, it requires a\nsystem for identifying human generated text and AI generated text. Natural Language Processing (NLP) is a rapidly growing field of study that works on understanding human language. NLP gives machines the ability to learn human language by turning it into numerical data [5]. With the increasing number of digital texts, the need of NLP is growing rapidly [6]. In recent years, NlP has provided a large scale analysis and management of text data making sentiment analysis, emotion detection and other complicated tasks possible. Furthermore, with the help of NLP, it is possible to detect mental illness at early stage and provide treatment [7]. Previously the training of NLP models were slow and inefficient [8]. Especially after 2017, the innovation of transformer architecture has revolutionized the NLP field. The transformers made NLP tasks to be carried out sequentially that gave birth to large language models like ChatGPT. This models are so efficient that it can imitate human behaviour which creates some reasonable concerns. Transformers are one of the most powerful tools for natural language processing [9]. It can largely be divided into two parts. The encoder and the decoder. The encoder part takes a text sequence as input and produces a sequence of encoded representation. The difference between other architecture is that the encoded sequence is more context aware. When a series of encoders are stacked togather, it is called a BERT [10]. The decoder part, on the other hand, is able to generate an arbitrary length sequence. Stacking decoder blocks produces an architecture named GPT. ChatGPT is also a transformer based architecture that has been trained on a large set of public data in self-supervised fashion. It has more than a billion parameters making it on of the biggest language model available. It is considered a major breakthrough since it\u2019s release in November, 2022. In this paper, we present a machine learning based approach for detecting ChatGPT generated text and human generated text. The proposed model involves vectoring sentences using TF-IDF vectorizer and then classifying it employing extremely randomized trees classifier. This article also presents a comparative analysis of different machine learning algorithms namely Logistic Regression, Support Vector Machine, Deci-\nsion Tree, K- Nearest Neighbor, Random Forest, AdaBoost, Bagging Classifier and deep learning algorithms named Multilayer Perceptron and Long Short-Term Memory for detecting ChatGPT generated text along with the impact of some data pre-processing techniques in the classification process. To summarize, the article presents the followings: \u2022 A machine learning based model for differentiating ChatGPT generated text from human generated text. \u2022 Comparative analysis of different machine learning and deep learning algorithms in the classification process. The article is organized such that Section II contains the prior works for solving the same problems followed by our proposed method in Section III. Section IV holds the outcomes obtained from the study. The article terminates in Section V.\n# II. RELATED WORK\nTo detect AI generated texts multiple approaches are proposed. Traditionally Sebastian Gehrmann et al. [11] proposed a statistical method to distinguish machine and human generated text. The paper introduces a tool named GLTR. The GLTR tool is a 6-gram character-level statistical language model model, which is trained on a large corpus of text data. The tool uses this model to calculate the probability of each character in the generated text, and then shows any character that has a low probability of occurring in the training corpus. Anton Bakhtin et al. [12] proposed a Energy-based model (EBM) to discriminate machine generated text. EBM is also a statistical model which finds an energy function from given data. The authors used a comparatively larger dataset collected from human to machine conversation. Eric Mitchell et al. [13] proposed a zero shot learning method called DetectGPT. This method detects whether text is machine-written or not by calculating log probabilities computed by the model of interest. On text samples generated by the GPT-2, the research team conducted an study [14]. Atsumu Harada et al. [15] gathered two datasets, one with sentences produced by humans, the other with sentences written by both humans and machines. The cosine similarity between sentence pairs was then calculated as a measure of text consistency. Finally, based on the cosine similarity ratings of the sentences, they classified them as either human-written or human and machine-written using machine learning methods. Sandra Mitrovic et al. [16] proposed a transformer based model to detect chatgpt generated texts. To determine if a text was produced by ChatGPT or a person, the paper\u2019s authors developed a machine learning methodology. The model was trained on a dataset of 10,000 text samples that were classified as either human- or ChatGPT-generated. It is based on a combination of text-based and user-based attributes. Tiziano Fagni et al. [17] proposed a method to detect deepFake tweets. At first tweets were generated by different language models. Then different machine learning methods were used with tf-idf and Bag of Words techniques.Sankar Sadasivan et al. [18] evaluated the effectiveness of several existing approaches for detecting AI-generated text including rule-based methods, statistical methods, and machine learningbased methods.They discover that although these techniques\ncan be effective in identifying some sorts of AI-generated text, they are frequently open to adversarial attempts that trick them into thinking the material is human-generated. A lightweight neural network-based paraphraser was developed and applied it to the AI-generated texts.John Kirchenbauer et al. [19] introduced a watermarking method. This method add a small amount of noise to the weights of the LLM during training.The noise is made with the intention of encoding a distinct watermark signal that can later be decoded by a watermark detector.The GPT-2 and GPT-3 language models are used to demonstrate the utility of their watermarking technology. The watermark can be found even after fine-tuning the LLM on fresh data and that it is resistant to a variety of attacks, including gradient masking and weight perturbations. In a paper Kalpesh Krishna et al. [20] created a substantial amount of AI-generated text samples using a number of cutting-edge language models, such as GPT-3 and T5. The efficiency of several rule-based and machine learning-based text-derived AI detectors is then assessed using the created samples. A retrieval-based defensive method was proposed that depends on determining the text\u2019s original author. The suggested technique operates by maintaining a database of known AI-generated text samples and their associated original sources, and by comparing any new text samples against this database to identify probable sources. The authors demonstrate that the suggested retrieval-based defensive mechanism is successful in identifying material that has been paraphrased by AI, with detection a good accuracy. Souradip Chakraborty et al. [21] proposed multiple possibilities that can detect AI generated texts including some statistical methods and several machine learning algorithms. In most of the papers GPT-2 or previous version of GPT-3 were used. But in our paper we approached with conventional machine learning algorithms but with a dataset that was generated by GPT-3.5 which were more human like.\n# III. METHODOLOGY\nThe aim of this research is to differentiate human text from generative model text using machine learning. In Figure 1, the high level overview of our process is described. The task initiates by data collection. Section III-A holds the detailed process of this stage. In the data preprocessing stage, the dataset was balanced using undersampling technique. Moreover, the class column was converted into numerical values using binary encoding also known as one-hot encoding. Deleting stop words in the pre-processing stage impacted the classification performance negatively since the selection of stop words play a crucial role in differentiating human and AI. Finally, since machines can understand numbers only, the sentences were vectorized using TF-IDF vectorizer. The details of this technique is mentioned in section III-B. The speciality of this vectorizer over other methods is its ability to capture the importance of a word.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ac63/ac63433b-c9fe-4cd1-beae-abfbc585b168.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 1. High level overview of the process</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a03d/a03d9730-f4fd-4f1b-84eb-6482246dfbd1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 2. Extra Tree Classifier</div>\nLater, the data was split into two halfs with a ratio of 80:20 where majority portion was kept for training and the rest for testing. Figure 3 presents the detailed description of the process. Total eleven models were selected for ablation study. Section III-C presents a small description of every algorithms. The final model selected for this task was Extremely Randomized Trees Classifier (ERTC). ERTC is an ensemble algorithm that is based on decision tree. However, instead of selecting the best partition point, it splits the data based on random points. On the training phase, it constructs some number of decision trees based on randomly selected attributes and features [22]. At testing, it takes majority voting for prediction. An illustration of ERTC is shown in Figure\n2. There are several hyper-parametres of this algorithm. In our research, we have found that 50 Decision Tree classifiers without pruning works the best for this problem with splitting criteria as gini.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0e67/0e677dca-c613-4f06-9906-8cce1f3b488e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 3. Detailed overview of the process</div>\nThe dataset consists of 10,000 texts among which 5204 texts are generated from humans and rest of them are from ChatGPT. Figure 4 holds the distribution of the dataset. The initial dataset was constructed by first collecting data from Quora and CNN news using web scrapping. Later they were given to ChatGPT for paraphrasing. However, the initial datset had a 1:8 ratio of human:ChatGPT text. Later, datapreprocessing was applied to make the dataset balanced.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c830/c8309c3f-3731-4065-ad45-b714b410b01e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 4. Dataset distribution</div>\n# B. TF-IDF Vectorizer\nTerm Frequency-Inverse Document Frequency (TF-IDF ) is a popular word vectorization technique. The idea behind\nTF-IDF is to emphasize the important words. The process of calculating TF-IDF has two steps. First step is to calculate the term frequency, that is how often a term (word or group of words) appears in the document. Let term be denoted with t, document with d, the collection of documents (corpus) with D and total number of documents in the corpus with N. Now, the term frequency is calculated by dividing the number of occurrences of a term in the document by the total number of terms. Equation 1 holds the mathematical formula of calculating TF.\n(1)\n\ufffd Inverse Document Frequency, on the other hand, measures how important a term is by calculating the frequency of that term in the corpus. As described in Equation 2, it is calculated by taking the logarithm of the total number of documents in the corpus divided by the number of documents that contain the term.\n(2)\nFinally, the IF-IDF is calculated by multiplying the TF and IDF calculated in the steps above.\n(3)\n# C. Algorithms\nLogistic Regression: Logistic regression is a statistical method which is mainly used for binary classification. It calculates relationship between input data and class variable to make prediction. Support Vector Machines: Support Vector Machine (SVM) is used for both classification and regression. Finding a hyperplane in an N-dimensional space that clearly differentiates the data points is the goal of the SVM. Decision Tree: Decision trees constructs a tree data structure based on information obtained from the data. While inference, it traverses the tree to find the appropriate class. K- Nearest Neighbor: The K-nearest neighbors algorithm (KNN) is based on the theory of proximity. It finds the class label of a given data by calculating the majority of the K nearest instances. Random Forest: Random Forest is a supervised machine learning algorithm which combines some decision trees using the concept of attribute bagging. AdaBoost: AdaBoost algorithm, also known as Adaptive Boosting, is a Boosting method used in machine learning as an ensemble method. It is more useful for noisy data. Bagging Classifier: An ensemble meta-estimator called a bagging classifier fits base classifiers one at a time to random subsets of the original dataset, and it then averages or votes on each classifier\u2019s individual predictions to produce a final prediction. Gradient Boosting: In order to minimize a loss function, the functional gradient algorithm known as Gradient Boosting repeatedly chooses a function that points in the direction\nof a weak hypothesis or a negative gradient. A powerful predicting model is created by the gradient boosting classifier by combining several weak learning models. Multi-layer Perceptron : Artificial neurons are the main concept of Multi-layer Perceptron (MLP). These neurons are a set of interconnected units or nodes that loosely resemble the neurons in a biological brain. Like the synapses in a biological brain, each connection has the ability to send a signal to neighboring neurons. An artificial neuron can signal neurons that are connected to it after processing signals that are sent to it. The output of each neuron is calculated by some non-linear function of the sum of its inputs. Long Short-Term Memory: Long Short-Term Memory(LSTM) is a type of recurrent neural network that can remember information of long sequences. Extremely Randomized Trees : Extremely Randomized Trees, sometimes referred to as Extra Trees, build numerous trees, similar to Random Forest (RF) techniques, over the whole dataset during training. The difference between RF classifier is that RF splits data based on best splitting criteria but Extra Trees classifier splits data randomly.\n# IV. RESULTS\n# A. Experimental Setup\nThe experiment was carried out on a jupyter notebook and the machine was equipped with a CPU of ryzen 5 5600G. The CPU has an integrated Graphics Processing Unit (GPU) for carrying out deep learning tasks. Moreover, the machine also had 16 GB RAMs. Python was used as programming language along with four libraries named Numpy, Pandas, SKlearn and Tensorflow.\n# B. Evaluation Matrices\nEvaluation matrices are used to measure the performance of the model. Different evaluation matrix provides different perspective of the result. In this paper, we have used five matrices namely accuracy, precision, recall,F1 score and Matthews correlation coefficient (MCC). Accuracy calculates the percentage of correctly predicted instances. As shown in Equation 4, it is calculated by the total number of correctly predicted samples divided by the total number of samples.\n(4)\nWhile precision calculates the true positive predictions over all positive predictions, recall measures the true positive predictions out of all actual positive instances. The formula of precision and recall are demonstrated in Equation 5 and Equation 6 respectively.\n(5)\nModel\nAccuracy\nPrecision\nRecall\nF1-Score\nMCC\nLogistic Regression\n0.74\n0.73\n0.73\n0.73\n0.48\nSupport Vector Machines\n0.75\n0.75\n0.71\n0.73\n0.50\nDecision Tree\n0.63\n0.75\n0.79\n0.67\n0.29\nK- Nearest Neighbor\n0.69\n0.67\n0.68\n0.67\n0.37\nRandom Forest\n0.76\n0.73\n0.81\n0.76\n0.53\nAdaBoost\n0.71\n0.68\n0.74\n0.71\n0.43\nBagging Classifier\n0.74\n0.71\n0.75\n0.73\n0.47\nGradient Boosting\n0.71\n0.66\n0.78\n0.72\n0.42\nMulti-layer Perceptron\n0.72\n0.73\n0.72\n0.72\n0.43\nLong Short-Term Memory\n0.73\n0.73\n0.77\n0.75\n0.46\nExtremely Randomized Trees\n0.77\n0.74\n0.78\n0.76\n0.54\nAs shown in Equation 7, F1 score is the mean of precision and recall. This provides a more balanced measurement than precision and recall.\n(7)\nFinally, the Matthews Correlation Coefficient (MCC) is a more stable matrix that takes all four coefficients into account. This matrix is more significant than all other matrices mentioned above [23]. The formula for calculating MCC is mentioned in Equation 8.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6578/65784e81-48ff-46f9-830d-e4b7762b3b7e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 5. Accuracy of different classifiers</div>\n# C. Experimental Results\nWe have tested the performance against nine machine learning classifiers along with an MLP and LSTM model with different hyper-parameters. Table I holds the detailed performance analysis of different models. Figure 5 shows a diagrammatic accuracy comparison of different classifiers.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c062/c062e3a9-a561-4037-85ef-b493027a9cf5.png\" style=\"width: 50%;\"></div>\nForm the results, it is clearly visible that extra tree classifier outperforms all the classifiers with an accuracy of 77%. Moreover, it also has the highest MCC score that is the most informative evaluation matrix compared. The results also demonstrate that some well known classifier such as K-Nearest Neighbor and Decision Tree classifier performs poorly on this dataset. For deep learning based Artificial Neural Network and Long Short-Term Memory, it was trained on 15 epoch. Although it had a high training accuracy, it performed poorly on testing. Some regularization techniques may improve the performance. For further investigation of the result, Figure and 6 presents roc curve. These results show that the model is not biased to a particular class.\n# V. CONCLUSION\nIn this research, we proposed a model that can differentiate between the text generated from human and ChatGPT. Since generating AI has become very advanced, it is difficult to distinguish between human text and machine generated text. However, in this paper, we have presented a machine learning based approach that can effectively identify two types of text. With the continuing research in this area we expect to see\nmore sophisticated models for solving this problem that will ensure transparency and accountability in the day to day life.\n# REFERENCES\n",
    "paper_type": "benchmark",
    "attri": {
        "background": {
            "problem background": "The emergence of generative AI models, particularly conversational AI like ChatGPT, has raised concerns about the potential for misinformation and manipulation due to the indistinguishable nature of AI-generated texts from human-generated texts. This necessitates a benchmark to identify and differentiate between these two types of text, addressing ethical and legal implications.",
            "purpose of benchmark": "The benchmark aims to provide a reliable method for distinguishing between human and AI-generated texts, facilitating the evaluation of various machine learning models in this classification task."
        },
        "problem": {
            "definition": "The benchmark is designed to address the challenge of accurately classifying texts as either human-generated or generated by ChatGPT.",
            "key obstacle": "Existing benchmarks often lack the capacity to effectively differentiate between human and AI-generated texts, leading to potential misclassifications and a lack of trust in automated systems."
        },
        "idea": {
            "intuition": "The development of this benchmark was inspired by the increasing reliance on generative AI and the need for tools to identify AI-generated content amidst rising concerns over misinformation.",
            "opinion": "The authors believe that this benchmark is crucial for enhancing the integrity of communication in various fields by ensuring that AI-generated content can be reliably identified.",
            "innovation": "This benchmark introduces a machine learning-based model that employs a novel approach using TF-IDF vectorization and an Extremely Randomized Trees Classifier, differing from previous methods that may not have utilized such advanced techniques.",
            "benchmark abbreviation": "ChatGPT-Text-Detection"
        },
        "dataset": {
            "source": "The dataset was collected from Quora and CNN news using web scraping, with texts paraphrased by ChatGPT to create a balanced dataset.",
            "desc": "The dataset consists of 10,000 texts, with 5,204 texts written by humans and the remainder generated by ChatGPT, ensuring a balanced representation for classification.",
            "content": "The dataset includes text data that is relevant for training machine learning models to differentiate between human and AI-generated content.",
            "size": "10,000",
            "domain": "Natural Language Processing",
            "task format": "Text Classification"
        },
        "metrics": {
            "metric name": "Accuracy, MCC",
            "aspect": "The metrics measure the classification accuracy and the stability of the model's predictions across different classes.",
            "principle": "The choice of metrics is guided by the need for a comprehensive evaluation of model performance in distinguishing between human and AI-generated texts.",
            "procedure": "Model performance is evaluated using accuracy and Matthews Correlation Coefficient (MCC) calculated from the classification results."
        },
        "experiments": {
            "model": "The benchmark tested various models including Logistic Regression, Support Vector Machine, Decision Tree, K-Nearest Neighbor, Random Forest, AdaBoost, Bagging Classifier, Multi-layer Perceptron, Long Short-Term Memory, and Extremely Randomized Trees Classifier.",
            "procedure": "Models were trained using an 80:20 split of the dataset, with hyperparameters optimized for the Extremely Randomized Trees Classifier, which was selected based on its performance.",
            "result": "The Extremely Randomized Trees Classifier achieved the highest accuracy of 77% and a significant Matthews Correlation Coefficient, indicating its effectiveness in the classification task.",
            "variability": "Variability in results was accounted for through multiple trials and by testing various classifiers to ensure robustness in performance."
        },
        "conclusion": "The proposed model effectively distinguishes between human-generated and ChatGPT-generated texts, highlighting the importance of developing reliable tools to maintain transparency and accountability in communication.",
        "discussion": {
            "advantage": "The benchmark provides a systematic approach for identifying AI-generated content, contributing significantly to the field of NLP and enhancing the ability to combat misinformation.",
            "limitation": "Potential limitations include the reliance on a specific dataset which may not encompass all variations of text generation, possibly affecting generalizability.",
            "future work": "Future research could explore expanding the dataset to include a wider variety of AI-generated texts and further refining the classification algorithms for improved accuracy."
        },
        "other info": {
            "info1": "The research highlights the ethical implications of AI-generated texts.",
            "info2": {
                "info2.1": "The dataset was balanced through undersampling techniques.",
                "info2.2": "The study emphasizes the need for ongoing research in AI text detection."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The emergence of generative AI models, particularly conversational AI like ChatGPT, has raised concerns about the potential for misinformation and manipulation due to the indistinguishable nature of AI-generated texts from human-generated texts."
        },
        {
            "section number": "1.2",
            "key information": "The benchmark aims to provide a reliable method for distinguishing between human and AI-generated texts, facilitating the evaluation of various machine learning models in this classification task."
        },
        {
            "section number": "2.2",
            "key information": "The dataset consists of 10,000 texts, with 5,204 texts written by humans and the remainder generated by ChatGPT, ensuring a balanced representation for classification."
        },
        {
            "section number": "3.4",
            "key information": "This benchmark introduces a machine learning-based model that employs a novel approach using TF-IDF vectorization and an Extremely Randomized Trees Classifier."
        },
        {
            "section number": "4.1",
            "key information": "The benchmark provides a systematic approach for identifying AI-generated content, contributing significantly to the field of NLP and enhancing the ability to combat misinformation."
        },
        {
            "section number": "7.1",
            "key information": "Potential limitations include the reliance on a specific dataset which may not encompass all variations of text generation, possibly affecting generalizability."
        },
        {
            "section number": "8",
            "key information": "The proposed model effectively distinguishes between human-generated and ChatGPT-generated texts, highlighting the importance of developing reliable tools to maintain transparency and accountability in communication."
        }
    ],
    "similarity_score": 0.6654965566925529,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning.json"
}