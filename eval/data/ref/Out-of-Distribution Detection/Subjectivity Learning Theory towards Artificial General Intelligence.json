{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1909.03798",
    "title": "Subjectivity Learning Theory towards Artificial General Intelligence",
    "abstract": "The construction of artificial general intelligence (AGI) was a long-term goal of AI research aiming to deal with the complex data in the real world and make reasonable judgments in various cases like a human. However, the current AI creations, referred to as \u201cNarrow AI\u201d, are limited to a specific problem. The constraints come from two basic assumptions of data, which are independent and identical distributed samples and single-valued mapping between inputs and outputs. We completely break these constraints and develop the subjectivity learning theory for general intelligence. We assign the mathematical meaning for the philosophical concept of subjectivity and build the data representation of general intelligence. Under the subjectivity representation, then the global risk is constructed as the new learning goal. We prove that subjectivity learning holds a lower risk bound than traditional machine learning. Moreover, we propose the principle of empirical global risk minimization (EGRM) as the subjectivity learning process in practice, establish the condition of consistency, and present triple variables for controlling the total risk bound. The subjectivity learning is a novel learning theory for unconstrained real data and provides a path to develop AGI.",
    "bib_name": "su2019subjectivitylearningtheoryartificial",
    "md_text": "# Subjectivity Learning Theory towards Artificial General Intelligence\nXin Su, Shangqi Guo, Feng Chen\n1Department of Automation, Tsinghua University suxin16, gsq15@mails.tsinghua.edu.cn; chenfeng@mail.tsinghua.edu.cn\n# Abstract\nThe construction of artificial general intelligence (AGI) was a long-term goal of AI research aiming to deal with the complex data in the real world and make reasonable judgments in various cases like a human. However, the current AI creations, referred to as \u201cNarrow AI\u201d, are limited to a specific problem. The constraints come from two basic assumptions of data, which are independent and identical distributed samples and single-valued mapping between inputs and outputs. We completely break these constraints and develop the subjectivity learning theory for general intelligence. We assign the mathematical meaning for the philosophical concept of subjectivity and build the data representation of general intelligence. Under the subjectivity representation, then the global risk is constructed as the new learning goal. We prove that subjectivity learning holds a lower risk bound than traditional machine learning. Moreover, we propose the principle of empirical global risk minimization (EGRM) as the subjectivity learning process in practice, establish the condition of consistency, and present triple variables for controlling the total risk bound. The subjectivity learning is a novel learning theory for unconstrained real data and provides a path to develop AGI.\narXiv:1909.03798v2\n# Introduction\nIn the past few decades, artificial intelligence (AI) research has reached or even exceeded human-level performance on many specific problems (Silver et al. 2016; Mnih et al. 2015; He et al. 2015). In the current implementation of AI, the learning relies heavily on datasets, which are built by artificially distinguished and collected data samples of specific domains. The learning machine obtains abilities by minimizing the risk of specific problems, as shown in Figure 1(b). This method of AI introduces a basic data assumption (Vapnik 2003) that data samples are independent and identically distributed (i.i.d). This assumption conforms to the characteristics of datasets and makes AI a solvable problem. However, it also limits the current AI machines to a specific \u201cintelligent\u201d behaviors in a determined environment, which is referred to as \u201cNarrow AI\u201d(Kurzweil 2005). When facing a general learning case, these AI creations still have many problems, such as task specificity, weak generalization, catastrophic forgetting. Some recent works\nPreprint. Under review.\nattempt to solve these problems. For instance, multi-task learning tries to learn multiple data distribution at the same time (Evgeniou and Pontil 2004; Kendall, Gal, and Cipolla 2018); continual learning tries to learn sequential and unstable distributed data (Zenke, Poole, and Ganguli 2017; Aljundi et al. 2019; Farquhar and Gal 2019); transfer learning tries to extend the ability of one data distribution to another related one (Santoro et al. 2016; Ren et al. 2018). Although the above works try to break the limits of i.i.d samples to achieve greater progress, they still cannot deal with the general learning scenario. The essential reason is another basic data assumption in traditional machine learning: The single-valued mapping function of inputs to outputs. The current AI studies are learning the mapping function y = f(x) or F(y|x) from input to output for all data. For the problem of general intelligence, not only the i.i.d assumption but the single-valued mapping assumption in traditional learning theory are all invalid. An input can be given various labels with different recognition methods. Every input-label pair constitutes a true data sample. As shown in Figure 1(a), the same input contains the labels of \u201cApple\u201d, \u201cRed\u201d, \u201cSweet\u201d and even more. It is a common and typical case. Notwithstanding, it shows the mentioned assumptions are not applicable to general learning problems. These data samples do not come from an identical distribution since multiple labels violate the normalization of probability, and we even cannot describe the relationship between inputs and labels by a single-value mapping function because an input corresponds to multiple labels. Directly using traditional machine learning to general learning case results in a label confusion, as shown in Figure 1(c). In summary, these challenges of real data can be attributed to two essential features of artificial general intelligence (AGI): (1) Data Complexity. AGI deals with inconsistent data from uncontrolled disparate tasks and various dynamic environments. (2) Judgment Complexity. AGI involves global judgments over a variety of tasks and problems with different regularities(Adams et al. 2012; Goertzel 2014; Laird and Wray III 2010). To achieve AGI, we must first thoroughly break the traditional data assumptions and then construct a new representation framework for the real data. Therefore, we propose the subjectivity learning theory.\nattempt to solve these problems. For instance, multi-task learning tries to learn multiple data distribution at the same time (Evgeniou and Pontil 2004; Kendall, Gal, and Cipolla 2018); continual learning tries to learn sequential and unstable distributed data (Zenke, Poole, and Ganguli 2017; Aljundi et al. 2019; Farquhar and Gal 2019); transfer learning tries to extend the ability of one data distribution to another related one (Santoro et al. 2016; Ren et al. 2018). Although the above works try to break the limits of i.i.d samples to achieve greater progress, they still cannot deal with the general learning scenario. The essential reason is another basic data assumption in traditional machine learning: The single-valued mapping function of inputs to outputs. The current AI studies are learning the mapping function y = f(x) or F(y|x) from input to output for all data.\nFor the problem of general intelligence, not only the i.i.d assumption but the single-valued mapping assumption in traditional learning theory are all invalid. An input can be given various labels with different recognition methods. Every input-label pair constitutes a true data sample. As shown in Figure 1(a), the same input contains the labels of \u201cApple\u201d, \u201cRed\u201d, \u201cSweet\u201d and even more. It is a common and typical case. Notwithstanding, it shows the mentioned assumptions are not applicable to general learning problems. These data samples do not come from an identical distribution since multiple labels violate the normalization of probability, and we even cannot describe the relationship between inputs and labels by a single-value mapping function because an input corresponds to multiple labels. Directly using traditional machine learning to general learning case results in a label confusion, as shown in Figure 1(c). In summary, these challenges of real data can be attributed to two essential features of artificial general intelligence (AGI): (1) Data Complexity. AGI deals with inconsistent data from uncontrolled disparate tasks and various dynamic environments. (2) Judgment Complexity. AGI involves global judgments over a variety of tasks and problems with different regularities(Adams et al. 2012; Goertzel 2014; Laird and Wray III 2010). To achieve AGI, we must first thoroughly break the traditional data assumptions and then construct a new representation framework for the real data. Therefore, we propose the subjectivity learning theory.\nTo construct the representation of real complex data, we introduce a new learning concept \u2013subjectivity. We notice that human actively classifies related judgments of complex data into a specific category, where the data can be locally represented as a function or distribution. From a philosophical perspective, some ideas, conclusions or judgments considered true only from the perspective of a subject (Allen 2002). We assign the mathematical meaning to the concept of subjectivity, which is an active division and induction of complex data such that inputs hold a consistent judgment under a certain subject. The machine learns to divide the data into multiple subjects and build judgments for every subject. We refer this novel machine learning method to as subjectivity learning, which can model the complex data cases in general intelligence. With the introduction of subjects, the machine of subjectivity learning needs to learn two representations: (1) Which subject each sample should be classified into. (2) How to express the data mapping under a certain subject. The main question of subjectivity learning is how to obtain these two descriptions. To achieve the capabilities of general intelligence, we build a new learning goal \u2013 the global risk. We find that human\u2019s perception of the world is to avoid fatal errors in any situation, rather than just being accurate in a specific task. It means that the general intelligence adopts a risk metric covering all possible scenarios, which is referred to as global risk. In subjectivity learning, this goal is to assess the sum of risks covering all subjects. In this paper, we prove that, for the complex data and the global risk metric, the description in traditional learning theories produces an inevitable error, while the subjectivity learning could mitigate or even eliminate it. Therefore, subjectivity learning is more appropriate for general intelligence, and the global risk can drive the representation of subjectivity learning. In this paper, we propose subjectivity learning theory towards general intelligence. We first describe the framework of subjectivity learning and compare it to traditional learning theory. The principle of empirical global risk minimization is introduced to obtain the practical solution. Then, We further analyze the consistency and the error bound of the learning principle. Our contributions include: (1)In general intelligence understanding, we point out the crucial reasons of \u201cNarrow AI\u201d and violations of data assumptions in traditional learning theory. (2) In theory, we develop subjectivity learning for solving these challenges by introducing the concept of subjectivity. We prove that subjectivity learning can drive a solution with lower risk than traditional machine learning. (3) In mathematical method, we extend the Law of Large Number to the case of two coupled variables and prove the consistency of empirical global risk minimization with the increase of samples when certain conditions are satisfied. We further analyzed the error bound and then present triple variables for controlling the error bound. (4) In philosophy, we attempt to reveal the computational meaning of subjectivity in human intelligence, which explains why the subjectivity is necessary for AI to achieve general intelligence.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b7a9/b7a96cf0-a200-42a0-bf55-768b73c42ac9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">\u2026 \u2026 \u2026 \u2026 (d) Subjectivity Learning for Solving AGI Problem</div>\nFigure 1: The data in AGI problem is complex, while every sample only presents partial information. The traditional machine learning focuses on the datasets of a specific problem which is assigned artificially. When they face the AGI problem, serious errors occur. The subjectivity learning actively divides the complex data into multiple subjects and learns the complete representation for AGI.\n# Related Work\nRecently, some studies try to break down the limits of data assumptions in traditional learning theory to develop AGI. They can be divided into two categories. The first type of works make efforts to solve the non-i.i.d data challenges in one specific problem. (Steinwart and Christmann 2009; Yu 1994) use various stochastic processes to model the complex dataset. (Balcan, Blum, and Vempala 2014) studies classification tasks with unstable distributed data samples in the process of lifelong learning. (Pentina and Lampert 2015) proved that learning tasks with non-i.i.d samples are also beneficial for new tasks. In these works, although the data samples are not i.i.d, the overall data is still assumed to be a certain distribution, and the input-output relation can be represented by a single-valued mapping function. The other category focus on the problem of data with multiple distributions. The representative approach is to build a hierarchical architecture, which consists of a task encoder module and a task decoder module (Garnelo et al. 2018; Sung et al. 2017; Schwarz et al. 2018). The task encoder module explicitly projects the task-specific dataset to a task vector, and the tasks decoder module predicts targets based on both data inputs and task vectors. (He et al. 2019) pays\nattention to the task-agnostic continual learning problem, while they assume the data is piece-wise stationary and recent samples are i.i.d. (Garnelo et al. 2018) addressed learning meta-networks from multiple tasks to perform few-shot learning in supervised learning such as regression, classification and image completion. (Sung et al. 2017) used the hierarchical framework to learn a meta-critic network to perform the few-shot transfer in the domain of reinforcement learning. These efforts attempt to deal with multi-distributed data, while they introduce other artificial assumptions for the raw data. Globally, the single-valued function mapping from the input (data & task) to the output (label) is still preserved. In summary, two basic data assumptions in traditional learning theory are not completely broken in all the existing works. We propose the subjectivity learning theory aiming to deal with the general data without these assumptions.\n# The Framework of Subjectivity Learning\nIn this section, we first explain the problem of general intelligence. Then, we define the framework of subjectivity learning clearly and construct the mathematical form of global risk. We further compare the subjectivity learning to traditional statistical learning, and prove that the global risk minimization in subjectivity learning results in a description with a lower risk.\nWe consider the common learning scenario of general intelligence. The real data contains various complex cases, while every data sample comes from a specific case or specific evaluation criteria. The label in a sample can only reflect a part of the information in a specific task. Unlike the datasets, the sources and tasks of all data are unknown in AGI problem. The system requires learning from various samples and giving a complete and reasonable representation. In the traditional learning theory, the data for a specific problem is collected as a dataset. All samples (input-label pair (x, y)) were assumed to be independent and identical distributed. The machine is looking for a function y = f(x) (or F(y|x)) to express the relation of input x to label y by minimizing the risk functional. Remark the data samples as z = (x, y) \u2208Z and the mapping function between x and y as g((x, y)) = g(z) \u2208G. When a probability distribution function F(z) is defined on Z, the problem of the traditional risk minimization can be expressed as\nwhere L(z, g(z)) is the loss function of sample z. The statistical learning theory ensures that the empirical risk converges to expection with the increase of samples. However, the samples (x, y) in AGI problem are not i.i.d, also the value of mapping y = f(x) (or F(y|x)) changes with various tasks and environments. Human\u2019s general intelligence involves how to adjust the judgment according to different environments. Therefore, the current learning theory is not applicable to general intelligence.\n# Subjectivity Learning\nWe notice that human\u2019s intelligence is based on subjectivity in making specific decisions, and one thing may correspond to different judgments under different subjects. Therefore, we draw on the concept of subjectivity to deal with complex data. In philosophical, that is the collection of the perceptions, experiences, expectations, and beliefs specific to a person. We define the mathematical meaning of subjectivity that Definition 1. The subjectivity is defined as the subjective collection for data samples with unified mapping, distribution, and loss metrics. The core idea of subjectivity learning is learning to subjectively divide complex data samples into various subjects and to represent their various mappings. Although this method can deal with AGI data, it brings a new variable that is the subject attribution of the sample. Specifically, we remark the subject as \u03c4. The data description in subjectivity learning includes two parts: (1) What is the input-label mapping y = f(x, \u03c4) (or F(y|x, \u03c4)) under a specific subject \u03c4? It is similar to the function y = f(x) in the traditional machine learning, but this relation can only be expressed as a function under a single subject. (2) Which subject \u03c4 should the samples (x, y) belong to? It\u2019s a new concept in the subjectivity learning. Mathematically, when we give the subjects attribution for data samples, the data and subjects form a joint distribution F((x, y), \u03c4). Different from the traditional learning problem, this joint distribution is changing in the learning process. Thus, the sample attribution corresponds to the posterior probability for subjects, that is p(\u03c4|(x, y)), which is a function variable to be learned. The current question is what is the goal driving the representation of subjectivity learning.\nWe notice that human\u2019s intelligence is based on subjectivity in making specific decisions, and one thing may correspond to different judgments under different subjects. Therefore, we draw on the concept of subjectivity to deal with complex data. In philosophical, that is the collection of the perceptions, experiences, expectations, and beliefs specific to a person. We define the mathematical meaning of subjectivity that\nDefinition 1. The subjectivity is defined as the subjective collection for data samples with unified mapping, distribution, and loss metrics.\nThe core idea of subjectivity learning is learning to subjectively divide complex data samples into various subjects and to represent their various mappings. Although this method can deal with AGI data, it brings a new variable that is the subject attribution of the sample. Specifically, we remark the subject as \u03c4. The data description in subjectivity learning includes two parts: (1) What is the input-label mapping y = f(x, \u03c4) (or F(y|x, \u03c4)) under a specific subject \u03c4? It is similar to the function y = f(x) in the traditional machine learning, but this relation can only be expressed as a function under a single subject. (2) Which subject \u03c4 should the samples (x, y) belong to? It\u2019s a new concept in the subjectivity learning. Mathematically, when we give the subjects attribution for data samples, the data and subjects form a joint distribution F((x, y), \u03c4). Different from the traditional learning problem, this joint distribution is changing in the learning process. Thus, the sample attribution corresponds to the posterior probability for subjects, that is p(\u03c4|(x, y)), which is a function variable to be learned. The current question is what is the goal driving the representation of subjectivity learning.\n# Global Risk Functional\nThe goal of human\u2019s intelligence is to avoid the fatal error in almost any cases, instead of only focusing on the risk of specific tasks. We also adopt this goal as the evaluation and construct the second core concept, the global risk functional, for subjectivity learning. Since the data samples are divided by different subjects in subjectivity learning, the goal should consider the loss over all subjects. Mathematically, when given the sample z = (x, y), the subject of z is remarked as h(z, \u03c4) = p(\u03c4|z)/p(\u03c4). The input-label relation under a specific subject \u03c4 is defined as g(z, \u03c4) = F(y|x, \u03c4). We define that\n(2)\nwhere L0 is the loss function of sample z under subject \u03c4, F(z) and F(\u03c4) are the distributions of sample z and \u03c4.\nThis global risk is related to the representation of subjectivity learning. For g(z, \u03c4), it is obvious that the risk increases if the output does not match the real label. For the h(z, \u03c4) = p(\u03c4|z)/p(\u03c4), it also causes a serious error if conflict samples in different nature are classified as the same subject. The following sample can clearly illustrate this situation. Let the data (input-label pairs) be (x, y). For traditional statistical learning problem, let the output of the learning machine from input x as f(x). Then the loss function is formed as L(f(x), y), and the risk function should be expressed as\nNote that an sample x may correspond to multiple yj in general case. If we optimize the risk functional\nover all data, the optimal solution is that\nAnd there exist an absolute confusion error in the optimal loss, that is\nIt is the label confusion shown in Figure1(c) of the main context. In the subjectivity learning, the samples are divided into different subjects \u03c4 and measured by global risk Rs(g, h). If the subjects\u2019 division h(z, \u03c4) is unreasonable, such as all samples are still classified into one subject, the above absolute error is reflected in the global risk. On the other hand, when samples are reasonably divided into different subjects, such as no conflict of sample mapping in any subject, the global risk\nlikely converges to zero. It also shows that subjectivity is pretty valuable to general intelligence instead of only human\u2019s prejudice against things. Subjectivity representations and the global risk functional combined role makes the general intelligence a learning problem. Next, we compare the subjectivity learning with traditional machine learning, and prove that subjectivity learning results in a lower global risk.\n# Risk Gap\nHere we compare the global risk minimization of subjectivity learning to traditional learning problem. The following theorem demonstrates that the subjectivity learning results in a lower optimal risk under the equivalent loss measure.\nTheorem 1. Let us consider the problem of machine learning (29) and the problem of subjectivity learning (30). Under the equivalent loss measure L(z, g(z))|\u03c4 = L0(z, \u03c4, g(z)), the inequality\n(3)\ntake place. For the optimal solution g\u2217(z, \u03c4) and h\u2217(z, \u03c4), if there exists samples measured with dF(z, \u03c41), dF(z, \u03c42) > 0 such that g\u2217(z, \u03c41) \u0338= g\u2217(z, \u03c42), there exist an absolute risk gap that\n(4)\n(4)\n\nProof. See the Supplementary Material.\nThe above theorem contains two parts. In the first part (31), we qualitatively state that the global risk functional of subjectivity learning drives a more accurate description. In AGI problem, a sample z almost holds multiple different judgment g(z, \u03c4) with various \u03c4. In the second part (32), we prove that there must be a risk gap greater than 0 between the traditional machine learning and the subjectivity learning. Statistical learning theory ensures that minimum empirical risk approaches the lower bound of the expected risk with the increase of data samples. However, the above risk gap demonstrates that the lower bound of traditional risk functional can never approach the optimal description of AGI. On the other hand, the subjectivity learning with the global risk is able to drive a better description. From a philosophical perspective, this theorem also explains why the human constructs various subjectivity for the real complex data, which is a method of interpreting the world with less risk. After presenting the framework of subjectivity learning, we then illustrate the learning process and its convergence in next section.\n# The Theory of Subjectivity Learning\nAfter giving the representation of subjectivity learning and the form of global risk functional, the current main question is how to find the minimization of the global risk functional. In this section, we introduce the principle of empirical global risk minimization (EGRM), and explain the process of subjectivity learning under this principle. Different from statistical learning theory, the subjectivity learning process involves two types of samples, which are data samples z and subjects samples \u03c4, and the numbers of them are related. The nature of convergence changes with this relationship. Therefore, we generalize the Law of Large Number to the case of coupled variables. Then, we establish the consistency conditions and give the convergence probability of the learning process. We prove that the empirical global risk minimization can tend to the expectation with the increase of data samples and subjects samples.\n# Principle of EGRM\nWe cannot directly minimize the functional (30) since the probability distributions of F(z) in the definition is un-\nknown. Also, we need to consider the newly introduced variable, subject \u03c4. In practical, we first get the data samples z1, ..., zl in various cases. The form of subjects \u03c41, ..., \u03c4m is a set of samples from a prior distribution F(\u03c4), which can be a language, a symbol or something else. Different with data samples, subject samples is artificially introduced and controllable. Before constructing the joint distribution with data samples, the subject sample do not have a specific physical meaning, so it can be sampled from any certain prior distribution. However, the number of subject samples is related to the giving data samples, and it should change as new samples continually arrive. When the data samples and subject samples are determined, we need to select the optimal functions g and h from the sets G and H to minimize the global risk. Therefore, the learning process of subjectivity learning can be summarized as first sampling a set of subjects \u03c41, ..., \u03c4m on the basis of data samples z1, ..., zl, and then selecting the optimal description functions g and h based on these samples to make the global risk functional minimum. This novel principle is called empirical global risk minimization (EGRM). Now we show the specific form in mathematical. For simplicity, we first rewrite the global risk functional. When formulating the minimization of the functional (30), the set of functions g(z, \u03c4) and h(z, \u03c4) will be given in a parametric form that {g(z, \u03c4; \u03b1g)\u03b1g \u2208\u039bg} and {h(z, \u03c4; \u03b1h)\u03b1h \u2208\u039bh}. Here \u03b1g and \u03b1h are parameters from the set \u039bg and \u039bh such that the value \u03b1g = \u03b1\u2217 g defines the specific function g(z, \u03c4; \u03b1\u2217 g) in the set g(z, \u03c4) and similar as \u03b1h. We further merge these two sets of parameters such that \u03b1 = (\u03b1g, \u03b1h) and \u03b1 \u2208\u039b = \u039bg \u00d7 \u039bh. In this notation, the functional (30) can be written as\nwhere\nThe function Q(z, \u03c4, \u03b1), which depends on variables z, \u03c4 and \u03b1, is called basic loss function. Each function Q(z, \u03c4, \u03b1\u2217), \u03b1\u2217\u2208\u039b determines the value of the loss resulting from the data vector z and subject vector \u03c4. Then we introduce the principle of the empirical global risk minimization that Definition 3. (Principle of Empirical Global Risk Minimization, EGRM) On the basis of data samples z1, ..., zl, we select a suitable number of subject samples \u03c41, ..., \u03c4m and minimize the functional\nDefinition 3. (Principle of Empirical Global Risk Minimization, EGRM) On the basis of data samples z1, ..., zl, we select a suitable number of subject samples \u03c41, ..., \u03c4m and minimize the functional\n(7)\nThis functional is defined in an explicit form, and can be minimized. Let the minimum of the global risk functional be attained at Q(z, \u03c4, \u03b10) and let the minimum of the empirical global risk be attained at Q(z, \u03c4, \u03b1l,m). We take the principle of EGRM that is using the function Q(z, \u03c4, \u03b1l,m) as an\napproximation of the function Q(z, \u03c4, \u03b10). The next problem is to establish the conditions under which the function Q(z, \u03c4, \u03b1l,m) is close to the function Q(z, \u03c4, \u03b10). Also, we want to know (1) how to control the number of subject number with data samples; (2) how the speed of Q(z, \u03c4, \u03b1l,m) is close to Q(z, \u03c4, \u03b10) as the data and subjects samples increases. These questions are discussed in the following context.\n# Convergence with Two Coupled Variables\nWe have proposed the empirical global risk to approximate the expectation (5). We need to determine under which conditions such an approximation is valid. In this subsection, we first give the definition of consistency. The consistency in statistical learning theory is based on the Law of Large Number that is the experience converges to expectation as the number of samples increasing. While in the subjectivity learning, besides the data sample, subjects sample are newly introduced. The convergence should consider the increase of these two type of variables and their relationship. Therefore, we generalize the Law of Large Number to the case of two coupled variable and define the consistency for the principle of EGRM. Let us consider a related empirical process. Let the probability distribution function F(\u03c4) and F(z) be defined on the space \u03c4 \u2208Rn\u03c4 and z \u2208Rnz, and let Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b be a set of measurable loss functions. Let \u03c41, ..., \u03c4m, ... and z1, ..., zl, ... be sequences of independent identically distributed vectors of subjects and data. Consider the one-sided empirical process given by the sequence of random values\nwhich R(\u03b1) is the form (5) and Remp is the form (7). In this process, we need to consider the increase of samples number m and l simultaneously, since different number order of two samples changes the characteristics of the process and its convergence. We note it as \u27e8m, l\u27e9, which means the growth of these two variables is based on a certain rule, and \u27e8m, l\u27e9\u2192\u221enotes the variables m, l both tend to infinity under this rule. In the subjectivity learning, this rule can be adjusted with controllable subjects number. The Law of Large Numbers demonstrates that the sequence of means converges to expectation of a random variable (if it exists) as the number of samples increases. As the starting point for consistency theory, we first generalize the Law of Large Number to the case of two couple variables. Now we introduce the theorem: Theorem 2. (Convergence Theorem with two coupled variables.) When the \u03b1\u2217is determined, for the function Q(z, \u03c4, \u03b1\u2217) and any \u03b5 > 0, the following convergence\nTheorem 2. (Convergence Theorem with two coupled variables.) When the \u03b1\u2217is determined, for the function Q(z, \u03c4, \u03b1\u2217) and any \u03b5 > 0, the following convergence\ntake place, where the sample numbers \u27e8m, l\u27e9satisfied the\n(10)\n  The Bz, Az and B\u03c4, A\u03c4 are respectively the bound of functions that Az \u2264Q(z, \u03c4) \u2264Bz and A\u03c4 \u2264Rlo(\u03b1, \u03c4) \u2264B\u03c4.\n\nProof. See the Supplementary Material\nIn the condition of Theorem 8, Rlo(\u03b1, \u03c4) is the local risk that\nIn the condition of Theorem 8, Rlo(\u03b1, \u03c4) is the local risk that\n(11)\nwhich represents the risk integral of all samples z under the specific subject \u03c4. It is only related to the subject variable \u03c4 and parameter \u03b1. The Theorem 8 shows that the sequence of \u03bem,l always converges in probability to zero, if set of functions Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b contains only one element, that is the function Q(z, \u03c4, \u03b1) is determined. The consistency of subjectivity learning should consider the set of functions contains multiple and even infinite elements. Now we give the definition of consistency.\nwhich represents the risk integral of all samples z under the specific subject \u03c4. It is only related to the subject variable \u03c4 and parameter \u03b1. The Theorem 8 shows that the sequence of \u03bem,l always converges in probability to zero, if set of functions Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b contains only one element, that is the function Q(z, \u03c4, \u03b1) is determined. The consistency of subjectivity learning should consider the set of functions contains multiple and even infinite elements. Now we give the definition of consistency. Definition 4. We say that the method of global empirical risk minimization is strictly (non-trivially) consistent the set of function Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b if for any nonempty subset \u039b(c), c \u2208(\u2212\u221e, \u221e) of this set of functions such that\nDefinition 4. We say that the method of global empirical risk minimization is strictly (non-trivially) consistent the set of function Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b if for any nonempty subset \u039b(c), c \u2208(\u2212\u221e, \u221e) of this set of functions such that\n(12)\nthe next convergence is valid:\n(13)\nOur goal is to find the conditions to make consistency (79) exist. In the derivation, we use the convergence conditions of the process (8) to construct the conditions of consistency, that is to describe conditions such that for any \u03b5 > 0, the following relation\n (14)\ntakes place. This formula is referred to one-sided uniform convergence.\n# Conditions of Consistency\nWe first show that one-sided uniform convergence (14) forms not only the sufficient conditions for the consistency of the EGRM, but the necessary conditions as well. We further generalize Theorem 8 to the case of function set Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b and construct the conditions. We formulate the following key theorem of subjectivity learning theory to describe the above conclusions, similar to the equivalent theorem of statistical learning theory.\nTheorem 3. (the Equivalent Theorem) Let there exist the constants a and A such that for all functions in the set Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b and for distribution functions F(t) and F(z), the inequalities\nhold true. Then the following two statements are equivalent: 1. The empirical global risk minimization method is strictly consistent (79) on the set of functions Q(z, \u03c4, \u03b1). 2. The uniform one-sided convergence of the means to their mathematical expectation (14) takes place over the set of functions Q(z, \u03c4, \u03b1).\n# Proof. See the Supplementary Material\n\nThis theorem transforms the problem of consistency to the problem of one-side uniform convergence. Now, we describe the conditions for one-side uniform convergence (14). With the local risk, the following inequality is valid:\n(16)\n(16)\n# Proof. See the Supplementary Material.\nFrom the above theorem, the convergence probability consists of two terms, where the first term is the convergence probability of the subjectivity risk and the second term is the sum of probability of data risk under all subjects. We further use the concept of capacity like statistical learning theory to discuss the conditions of uniform convergence. For the first term, let Rlo(\u03c4, \u03b1), \u03c4 \u2208T, \u03b1 \u2208\u039b be a set of real-valued functions. Let N \u039b,\u03b2\u03c4 \u03c4 (\u03c41, ..., \u03c4m) be the number of different separations of m vectors \u03c41, ..., \u03c4m by a complete set of indicators (detailed in supplementary material). Then we define the annealed entropy of subjectivity risk that Definition 5. (Annealed Entropy of Subjectivity Risk) The quantity\n(17)\nis defined as the annealed entropy of the set indicators of real-valued functions Rlo(\u03c4, \u03b1). Using the error inequality in statistical learning theory(Vapnik 2003), for the bounded real-valued functions\nA\u03c4 \u2264Rlo(\u03c4, \u03b1) \u2264B\u03c4, \u03b1 \u2208\u039b, the following inequality is valid:\n\ufffd (18)\nAlso, we define the annealed entropy of data risk for Q(z, \u03c4, \u03b1), z \u2208Z, \u03b1 \u2208\u039b and consider the second term of (116). Let N \u039b,\u03b2z z (z1, ..., zl) be the number of different separations of l vectors z1, ..., zl by a complete set of indicators (detailed in supplementary material). We define that\n# Definition 6. (Annealed Entropy of Data Risk) The quantity\n(19)\nis defined as the annealed entropy of the set indicators of real-valued functions Q(z, \u03c4, \u03b1) under a specific \u03c4.\n(20)\n(21)\nLet substitute the inequation (125) and (131) into (116), we get: Theorem 5. Let A\u03c4 \u2264Rlo(\u03c4, \u03b1) \u2264B\u03c4, \u03b1 \u2208\u039b and Az \u2264Q(z, \u03c4, \u03b1) \u2264Bz, \u03b1 \u2208\u039b be measurable set of bounded real-valued functions. Let \u02c6H\u039b,\u03b2t \u03c4 (m) and \u02c6H\u039b,\u03b2z z (l) be the annealed entropies of the sets of indicators for them. Then the following inequality is valid:\n(22)\nNote that the samples number satisfied the inequality (53) makes liml,m\u2192\u221eln m/l = 0 must be true. Therefore, from the above theorem, we can establish a set of sufficient conditions for the uniform convergence. Corollary 1. (Sufficient Conditions of Consistency) For the existence of non-trival exponential bounds on uniform\nconvergence, the sufficient conditions is to satisfy all the following three formulas:\n(23)\n(24)\n(25)\n \u2212 It is the sufficient condition for one-side uniform convergence (14), and is also sufficient conditions for the consistency of EGRM. The condition consists of three parts. The equation (133) means that under the specific subject \u03c4, the number of distinguishable events N \u039b,\u03b2z z should increase slowly as the data sample size increases (slower than any exponential function). The equation (134) considers the local risk Rlo(\u03c4, \u03b1) of different subjects. It requires that the number of distinguishable events N \u039b,\u03b2\u03c4 \u03c4 for local risk increases slowly as the subject sample size increases (slower than any exponential function). Besides, the equation (135) constraints the number relation between the subjects and data samples. So far, we have established a sufficient condition for consistency. Next, we analyze the error bound of global risk and discuss how to control the global risk in the case of determined number of data samples.\n# Triple Variables for Global Risk Controlling\nThe Theorem 11 shows the probability of uniform convergence , which is also the probabilistic form on generalization ability. In this subsection, we further analyze the constructive distribution-free bounds on generalization ability, and propose triple variables for controlling the global risk. For analyze the inequality (132), we introduce the concept of the data dimension hz and the subject dimension h\u03c4 for subjectivity learning, which are similar to the VC dimension for statistical learning theory. The data dimension (subject dimension) of a set of indicator functions Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b( or Rlo(\u03c4, \u03b1), \u03b1 \u2208\u039b) is equal to the largest number hz (or h\u03c4) of vectors z1, ..., zl (or \u03c41, ..., \u03c4m) that can be shattered by the complete set of indicators. These two dimensions satify that:\n(26) (27)\n(26)\n(27)\n\ufffd \ufffd We take them into (11) and rewrite it into the form of error bound. We have that Theorem 6. With probability 1 \u2212\u03b7 the risk for the function Q(z, t, \u03b1l,m) which minimizes the empirical glob risk functional satisfies the inequality\n(28)\nAfter getting the bound of generalization error, now we consider how to control the error bound (144) when the size of data samples l is small. In the statistical learning theory, this issue is discussed by structural risk minimization principle and is controlled by VC dimension. In the subjectivity learning, there are three related factors: data dimension hz, subjects number m, and subject dimension hl. When l is determined, we first adjust the data dimension hz and subjects number m to balance the empirical global risk and error of generalization. For EGRM, the smaller number of subjects and small local dimensions could reduce the error of generalization, while they result in a higher empirical global risk. After the subjects number m is determined, the error bound is related to subjectivity dimension h\u03c4. Therefore, for controlling the error bound of subjectivity learning, there are two crucial difference: (1) Besides the design of function complexity hz and h\u03c4, it is necessary to control the number of subject samples m to balance the empirical global risk and generalization error. (2) The subjectivity dimension h\u03c4, reflecting the complexity of subjectivity representation, should change with the number of subject samples. It means that the structure related to subjectivity dimension in the learning machine also need to adjusted dynamically. So far, we have given the complete theory of subjectivity learning.\n# Conclusion\nIn this paper, we point out two basic data assumptions in the current AI and machine learning methods, which are not applicable to the complex data in general intelligence. We thoroughly break these assumptions and develop the theory of subjectivity learning. We make a try to introduce the mathematical meaning to subjectivity, which is the concept of traditional philosophy. The introduction of subjectivity makes it possible to describe complex real data for general intelligence. Our theory proves the feasibility of subjectivity learning framework and raises the guiding idea for AGI algorithm in the future. However, there are still many difficulties in implementation, such as how to design the algorithm structure to express the functions in subjectivity learning and how to optimize them. These questions will be answered in the following works. Beyond theory, we also believe that there exists a physiological explanation for subjectivity learning, and subjectivity learning theory can also model related physiological phenomena in human intelligence. Although we have not yet reached a complete interpretation of general intelligence, the idea of subjectivity learning provides a valuable direction to solve intelligence puzzles.\n# References\n[Adams et al. 2012] Adams, S.; Arel, I.; Bach, J.; Coop, R.; Furlan, R.; Goertzel, B.; Hall, J. S.; Samsonovich, A.; Scheutz, M.; Schlesinger, M.; et al. 2012. Mapping the landscape of human-level artificial general intelligence. AI magazine 33(1):25\u201342. [Aljundi et al. 2019] Aljundi, R.; Lin, M.; Goujaud, B.; and Bengio, Y. 2019. Online continual learning with no task boundaries. arXiv preprint arXiv:1903.08671.\n[Allen 2002] Allen, A. 2002. Power, subjectivity, and agency: Between arendt and foucault. International Journal of Philosophical Studies 10(2):131\u2013149. [Balcan, Blum, and Vempala 2014] Balcan, M. F.; Blum, A.; and Vempala, S. 2014. Efficient representations for life-long learning and autoencoding. Computer Science 191\u2013210. [Evgeniou and Pontil 2004] Evgeniou, T., and Pontil, M. 2004. Regularized multi\u2013task learning. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, 109\u2013117. ACM. [Farquhar and Gal 2019] Farquhar, S., and Gal, Y. 2019. A unifying bayesian view of continual learning. arXiv preprint arXiv:1902.06494. [Garnelo et al. 2018] Garnelo, M.; Rosenbaum, D.; Maddison, C. J.; Ramalho, T.; Saxton, D.; Shanahan, M.; Teh, Y. W.; Rezende, D. J.; and Eslami, S. 2018. Conditional neural processes. arXiv preprint arXiv:1807.01613. [Goertzel 2014] Goertzel, B. 2014. Artificial general intelligence: concept, state of the art, and future prospects. Journal of Artificial General Intelligence 5(1):1\u201348. [He et al. 2015] He, K.; Zhang, X.; Ren, S.; and Sun, J. 2015. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of the IEEE international conference on computer vision, 1026\u2013 1034. [He et al. 2019] He, X.; Sygnowski, J.; Galashov, A.; Rusu, A. A.; Teh, Y. W.; and Pascanu, R. 2019. Task agnostic continual learning via meta learning. arXiv preprint arXiv:1906.05201. [Kendall, Gal, and Cipolla 2018] Kendall, A.; Gal, Y.; and Cipolla, R. 2018. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 7482\u20137491. [Kurzweil 2005] Kurzweil, R. 2005. The singularity is near: When humans transcend biology. Cryonics 85(1):160\u2013160. [Laird and Wray III 2010] Laird, J. E., and Wray III, R. E. 2010. Cognitive architecture requirements for achieving agi. In 3d Conference on Artificial General Intelligence (AGI2010). Atlantis Press. [Mnih et al. 2015] Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Veness, J.; Bellemare, M. G.; Graves, A.; Riedmiller, M.; Fidjeland, A. K.; Ostrovski, G.; et al. 2015. Human-level control through deep reinforcement learning. Nature 518(7540):529. [Pentina and Lampert 2015] Pentina, A., and Lampert, C. H. 2015. Lifelong learning with non-iid tasks. In Advances in Neural Information Processing Systems, 1540\u20131548. [Ren et al. 2018] Ren, M.; Triantafillou, E.; Ravi, S.; Snell, J.; Swersky, K.; Tenenbaum, J. B.; Larochelle, H.; and Zemel, R. S. 2018. Meta-learning for semi-supervised fewshot classification. arXiv preprint arXiv:1803.00676. [Santoro et al. 2016] Santoro, A.; Bartunov, S.; Botvinick, M.; Wierstra, D.; and Lillicrap, T. 2016. One-shot learning with memory-augmented neural networks. arXiv preprint arXiv:1605.06065.\n[Schwarz et al. 2018] Schwarz, J.; Luketina, J.; Czarnecki, W. M.; Grabska-Barwinska, A.; Teh, Y. W.; Pascanu, R.; and Hadsell, R. 2018. Progress & compress: A scalable framework for continual learning. arXiv preprint arXiv:1805.06370. [Silver et al. 2016] Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; Van Den Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.; et al. 2016. Mastering the game of go with deep neural networks and tree search. nature 529(7587):484. [Steinwart and Christmann 2009] Steinwart, I., and Christmann, A. 2009. Fast learning from non-iid observations. In Advances in neural information processing systems, 1768\u2013 1776. [Sung et al. 2017] Sung, F.; Zhang, L.; Xiang, T.; Hospedales, T.; and Yang, Y. 2017. Learning to learn: Meta-critic networks for sample efficient learning. arXiv preprint arXiv:1706.09529. [Vapnik 2003] Vapnik, V. N. 2003. Statistical learning theory. Annals of the Institute of Statistical Mathematics 55(2):371\u2013389. [Yu 1994] Yu, B. 1994. Rates of convergence for empirical processes of stationary mixing sequences. Annals of Probability 22(1):94\u2013116. [Zenke, Poole, and Ganguli 2017] Zenke, F.; Poole, B.; and Ganguli, S. 2017. Continual learning through synaptic intelligence. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, 3987\u20133995. JMLR. org.\n# Supplementary Material\nSupplementary Material\nDue to the limitations of the length of the paper, we put the proof of theorems and some details of discussion in this supplementary Material.\n# Theorem Proof in\nThe Framework of Subjectivity Learning\nIn the Framework of Subjectivity Learning, we consider the general learning scenario and give the form of traditional machine learning and subjectivity learning. The learning system is given a set of input-label pairs (xi, yi). In the statistical learning theory, it was assumed that all samples are independent and identical distributed. It looks for a function y = f(x) (or F(y|x))by minimizing the risk function. We remark samples as z = (x, y) \u2208Z and remark y = f(x) (or F(y|x)) as g((x, y)) = g(z) \u2208G. The traditional risk minimization can be written as\nwhere L(z, g(z)) is the loss function of sample z and function g(z) \u2208G is on the function space Z \u2192R. Note that the sample pairs of real data do not meet the independent and identical distributed. They may come from multiple independent distributions (e.g, the mapping f(xi) = yi,1 and f(xi) = yi,2 are both right with probability 1 but yi,1 \u0338= yi,2). It is obviously wrong to directly estimate one posterior probability p(y|x) since it does not satisfy the normalization condition that \ufffd y p(y|x) \u0338= 1. Even the mapping from x to y can not be expressed as a function. To describe this complex data, we introduce the concept of subjectivity. The data are subjectively divided into multiple subjects \u03c4 and construct a joint distribution F(z, \u03c4). Under a specific subject \u03c4, the input x contains a unique output y and it could be expressed as a function y = f(x, \u03c4) or F(y|x, \u03c4). At the same time, we add a new variable, which is the subject attribution of the sample p(t|z). This framework is named subjectivity learning. The goal of subjectivity learning is to learning the variables g(z, \u03c4) = F(y|x, \u03c4) and h(z, \u03c4) = p(\u03c4|z)/p(\u03c4). As shown in the paper, we construct the global risk functional that:\n(30)\nas the learning goal of subjectivity learning.\n# Proof of Theorem 1\nWe compare the traditional risk of statistical learning problem to the global risk of subjectivity learning. The Theorem 1 demonstrates that the minimization of global risk results in a lower optimal risk under the equivalent loss measure, also there exists a positive risk gap.\nTheorem 7. Let us consider the problem of machine learning (29) and the problem of subjectivity learning (30). Under\nthe equivalent loss measure L(z, g(z))|\u03c4 = L0(z, \u03c4, g(z)), the inequality\nthe equivalent loss measure L(z, g(z))|\u03c4 = L0(z, \u03c4, g(z)), the inequality\n(31)\ntake place.\ntake place. For the optimal solution g\u2217(z, \u03c4) and h\u2217(z, \u03c4), if there exists samples measured with dF(z, \u03c41), dF(z, \u03c42) > 0 such that g\u2217(z, \u03c41) \u0338= g\u2217(z, \u03c42), there exist an absolute risk gap that\n(32)\nProof. The theorem contains two parts. We firstly qualitatively state that the global risk functional drives a lower risk, and then give the proof of the positive risk gap. We consider a set of samples z1, ..., zl, ... are from the distribution F(z). The traditional risk minimization is defined as \ufffd\n(33)\n\ufffd where G1 = Z \u2192R. For comparison to the global risk minimization of subjectivity learning, we first consider a certain data-subjects division \u02c6h(z, \u03c4). We expand the risk function (33) under this joint distribution that:\n\ufffd\ufffd By the condition L(z, g(z))|\u03c4 = L0(z, \u03c4, g(z)) and h(z, \u03c4) = p(\u03c4|z)/p(\u03c4), the above risk minimization can be expressed as\n(34)\n\ufffd\ufffd We then extend the function g1(z) from the space Z \u2192R to the space Z \u00d7 T \u2192R. We construct the function g\u2032 1(z, \u03c4) \u2208 Z \u00d7 T \u2192R such that g\u2032 1(z, \u03c4) = g1(z) holds for all \u03c4, z. Then the traditional risk minimization can be expressed as\n(35)\nwhere G\u2032 1 = {g : g \u2208Z \u00d7 T \u2192R, g(z, \u03c4) = \u00afg(z) for \u2200\u03c4}. On the other hand, the global risk minimization in subjectivity learning is defined as\n(36)\nwhere G2 = {g : g \u2208Z \u00d7 T \u2192R}. When the data-subjects relation is determined by \u02c6h(z, t), the global risk is formed as\nwhere G2 = {g : g \u2208Z \u00d7 T \u2192R}. When the data-subjects relation is determined by \u02c6h(z, t), the global risk is formed as inf  R\u2032 s(g2(z, \u03c4))\n(37)\n(38)\ntake place for any division \u02c6h(z, \u03c4). Also, h(z, \u03c4) is a variable of the global risk functional that\n(39)\nso we get the inequality\n(40)\nThe first part of the theorem has been proved, which qualitatively shows the problem of global risk drives a lower risk bound. Then we consider a more realistic case. Let the optimal solution of global risk functional be g\u2217(z, \u03c4) and h\u2217(z, \u03c4). There should exist samples measured with dF(z, \u03c41), dF(z, \u03c42) > 0 such that\n(41)\n \u0338 which corresponds to the multi-label case of data in general intelligence problem. Generally, the loss function holds L0(z, \u03c4, g1(z, \u03c4)) \u0338= L0(z, \u03c4, g2(z, \u03c4)) when g1(z, \u03c4) \u0338= g2(z, \u03c4). Under the optimal data-subject distribution h\u2217(z, \u03c4), we expand the traditional risk functional by subject \u03c4 that \ufffd\n(\u03c4)\n\ufffd Let the optimal solution of traditional risk functional b g\u2217 1(z). Then we have\n(42)\nOne the other hand, we consider the lower bound of glob risk functional that \ufffd\n(43)\nSince there exist samples z, \u03c41 and z, \u03c42 measured with dF(z, \u03c41), dF(z, \u03c42) > 0 such that\n(44)\nthere must have\nWithout generality, suppose that g\u2217(z, \u03c41) \u0338= g\u2217 1(z). Since the loss function have\n(46)\nwhen g1(z, \u03c4) \u0338= g2(z, \u03c4), we get\n(47)\nAnd, because g\u2217(z, \u03c4) is the optimal description for obtaining the lower bound, the inequality\n(48)\nholds for any z, \u03c4. If the inequality is not satisfied, obviously we can construct a new optimal solution g\u2217\u2217such that g\u2217\u2217(z, \u03c4) = g\u2217 1(z) on the interval where inequality dose not hold and g\u2217\u2217(z, \u03c4) = g\u2217(z, \u03c4) on the other interval. Therefore, we have\n(49)\nfor sample z, \u03c41 with dF(z, \u03c41) > 0. Then the risk gap between lower bound of traditional risk functional and global risk functional satisfies that:\n\nThe theorem is proved.\nFor analysis the consistency of the principle of empirical global risk minimization, we first generalize the Law of Large Number to the case of two coupled number. We use the same notation of the global risk and the empirical risk function in the paper that\n(50)\n(51)\nWe propose the theorem that\nTheorem 8. (Convergency Theorem with two coupled variables.) When the \u03b1\u2217is determined, for the function Q(z, \u03c4, \u03b1\u2217) and any \u03b5 > 0, the following convergence\n(52)\ntake place, where the sample numbers \u27e8m, l\u27e9satisfied the rule:\n(53)\n  The Bz, Az and B\u03c4, A\u03c4 are respectively the bound of functions that Az \u2264Q(z, \u03c4) \u2264Bz and A\u03c4 \u2264Rlo(\u03b1, \u03c4) \u2264B\u03c4. Before the proof, we first introduce two basic inequality of probability. The first one is Lemma 1. The inequality\nThe Bz, Az and B\u03c4, A\u03c4 are respectively the bound of functions that Az \u2264Q(z, \u03c4) \u2264Bz and A\u03c4 \u2264Rlo(\u03b1, \u03c4) \u2264B\u03c4.\n(54)\nProof.\n\nThe second lemma is the generalization of Lemma 1 for multi-variables that\n for\nLemma 2. The inequality\n(55)\nholds true.\nProof. Let us prove it by mathematical induction. For n = 1, the inequality obviously holds true. For n > 1, we assume that the inequality holds true for n \u22121 that\n(56)\nThen we have \ufffd\n\nProof of Theorem 8:. To prove the theorem, we rewrite the equation (52) as that: For any \u03b5 > 0, \u03f5 > 0, we can find a \u03b41 > 0 so that when m\u2217> \u03b41 and l\u2217> \u03b42(m\u2217), the following inequality \ufffd \ufffd\n(57)\n\ufffd take place, where the local risk is defined as\n(58)\n\ufffd Then we consider left side of equation(57) as\n(59)\n(60)\n(61)\n(62)\n(63)\n(64)\n\ufffd \ufffd Note that the inequality (61) and (64) utilize the Lemma 1 and Lemma 2 respectively. From the Law of Large Numbers, we have \ufffd \ufffd\n(65)\nthat is, for any \u03f5 > 0 we can find a \u03b4 such that when l > \u03b4 the inequality\n(66)\n\ufffd \ufffd \ufffd takes place. Therefore, we can find a \u03b41 > 0 so that when m\u2217> \u03b4 we have\n(67)\n\ufffd (68)\nWhen m\u2217is determined, we can find a \u03b42(m\u2217) such that when l\u2217> \u03b42(m\u2217) we have\n(69)\nNow we need to find the form of relation l > \u03b42(m\u2217). From the Hoeffding\u2019s inequality, we give the probability form of (67) and (69) that:\n(70)\nand\n(71)\nSince the m\u2217> \u03b41 makes equation (lemma1proofineq3) be true, we assume that\n(72)\nTo make the inquality (69) take place, we can establish a sufficient condition that:\n(73)\n(74)\n \u2212 With this relation, when m\u2217> \u03b41, the inequalities (67) and (69) all take place. Bringing the inequality (68) and (69) into inequation (64), we have \ufffd \ufffd\n(75)\n\ufffd In summary, we get\n(76)\n\n# Proof of The Equivalent Theorem\nWhen we consider the condition of consistency, we transfer the problem of consistency to the one-sided uniform convergence. The equivalent theorem demonstrates that one-sided uniform convergency\n(77)\nforms not only the sufficient conditions for the consistency of the EGRM, but the necessary conditions as well. The definition of consistency is that :\nDefinition of Consistency We say that the method of global empirical risk minimization is strictly (nontrivially) consistent the set of function Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b if for any nonempty subset \u039b(c), c \u2208(\u2212\u221e, \u221e) of this set of functions such that \ufffd\ufffd\n(78)\nthe next convergence is valid:\n(79)\nTheorem 9. (the Equivalent Theorem) Let there exist the constants a and A such that for all functions in the set Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b and for distribution functions F(t) and F(z), the inequalities\n(80)\n\ufffd\ufffd hold true. Then the following two statements are equivalent: 1. The empirical global risk minimization method is strictly consistent (79) on the set of functions Q(z, \u03c4, \u03b1). 2. The uniform one-sided convergence of the means to their mathematical expectation (77) takes place over the set of functions Q(z, \u03c4, \u03b1). Proof. Let the global empirical risk minimization method be strictly consistent on the set of functions Q(z, \u03c4, \u03b1). According to the definition of strictly consistency, this means that for c such that the set \ufffd\ufffd\nhold true. Then the following two statements are equivalent: 1. The empirical global risk minimization method is strictly consistent (79) on the set of functions Q(z, \u03c4, \u03b1). 2. The uniform one-sided convergence of the means to their mathematical expectation (77) takes place over the set of functions Q(z, \u03c4, \u03b1).\nProof. Let the global empirical risk minimization method be strictly consistent on the set of functions Q(z, \u03c4, \u03b1). According to the definition of strictly consistency, this means that for c such that the set \ufffd\ufffd\n(81)\nis noempty the following convergence in probability is true:\n(82)\nConsider a finite sequence of numbers a1, ..., an such that\n(83)\nWe denote by Gk the event\n(84)\nthat is\n(85)\nBy the consistency of (82), we have\n(86)\nWe denote\nSince n is finite and for any k the equation (82) is true, it follows that\n(88)\nWe denote by A the event\n(89)\nThen we compare the event A and the event G. Suppose that A takes place, then we can find an \u03b1\u2217\u2208\u039b such that\n(90)\nFrom \u03b1\u2217we find k such that \u03b1\u2217\u2208\u039b(ak) and\n(91)\n\ufffd\ufffd For the chosen set \u039b(ak), the inequality\n(92)\nholds true. Therefore for the chosen \u03b1\u2217and the set \u039b(ak), then the following inequalities take place:\n(93) (94) (95) (96)\n(93)\n(94)\n(95)\n(96)\nthat is, the event Gk does occur and, hence, so does G. From above derivation, we have\n(97)\nBy equation(88),\n(98)\nwhich expresses uniform one-sided convergence \ufffd\ufffd\n(99)\n\ufffd \ufffd \ufffd\ufffd So far, the first part of the theorem is proved. Now suppose that uniform one-sided convergence (99) takes place. We need to prove that the strict consistency takes place in this case. It is for any \u03b5 the convergence \ufffd\ufffd\n(100)\n\ufffd \ufffd holds. Let us denote by A the event \ufffd\ufffd\n(101)\n\ufffd \ufffd \ufffd\ufffd Then the event A is the union of two ond-sided event A = A \ufffd A,\n\ufffd \ufffd \ufffd\ufffd Then the event A is the union of two ond-sided events \ufffd\n\ufffd \ufffd \ufffd\ufffd Then the event A is the union of two ond-sided events \ufffd\n(102)\nwhere\n(103)\nand\n(104)\n\ufffd \ufffd Then we bound the probability of the event A\n(105)\nA \u2264AA Suppose that the event A1 occurs. To bound P(A1) we take a function Q(z, \u03c4, \u03b1\u2217) such that \ufffd\ufffd\n< inf \u03b1\u2208\u039b(c) \ufffd\ufffd Q(z, \u03c4, \u03b1) dF(z) dF(\u03c4) + \u03b5 2. (106)\n(106)\n(107)\nholds. The probability of this inequality is therefore not less that the probability of the event A1:\n\ufffd\ufffd \ufffd The probability on the right-hand side tends to zero by the generation of the law of large numbers (Theorem 8), that is\n(109)\nTherefore, we conclude that\n(110)\nOn the other hand, the event A2 occurs, then there is a function Q(z, \u03c4, \u03b1\u2217\u2217), \u03b1\u2217\u2217\u2208\u039b(c) such that\n(111)\n\ufffd\ufffd Therefore, the relation\n(112)\nholds by virtue of (99). Since\n(113)\n(113)\nA \u2264AA from equation (110) and (112) we conclude that\n(114)\n\nThe theorem is proven.\nWith the Equivalent Theorem, we should consider the conditions for uniform convergence (77). We also use the local risk \ufffd\n(115)\n\ufffd for the subject \u03c4. Then, the following inequalities is valid: Theorem 10. For any \u03b5 > 0, the following inequality holds: \ufffd \ufffd\n(116)\nProof.\n\ufffd (117)\n(118)\n(119)\n(120)\n(121)\nre-\nThe convergence probability consists of two terms, where the first term is the convergence probability of the observations risk and the second term is the sum of convergence probability of samples risk under the specific observations. We further use the concept of capacity to discuss the conditions of uniform convergence. Due to space limitations, the representation in the main text is brief, here we present it in detail. Let us consider the first term\n\ufffd (122)\nLet Rlo(\u03c4, \u03b1), \u03c4 \u2208T, \u03b1 \u2208\u039b be a set of real-valued functions. Let N \u039b,\u03b2t t (\u03c41, ..., \u03c4m) be the number of different separations of m vectors \u03c41, ..., \u03c4m by a complete set of indicators:\n\ufffd \ufffd Then we define the annealed entropy of subjectivity risk that Definition 7. (Annealed Entropy of Subjectivity Risk) Let the function\n(123)\nbe measurable with respect to measure on \u03c41, ..., \u03c4m. The quantity\n(124)\nis defined as the annealed entropy of the set indicators \u03b8{Rlo(\u03c4, \u03b1) \u2212\u03b2\u03c4} of real-valued functions Rlo(\u03c4, \u03b1) .\nUsing the error equality in statistical learning theory, for the bounded real-valued functions At \u2264Rlo(t, \u03b1) \u2264 Bt, \u03b1 \u2208\u039b, the following inequality is valid:\n\ufffd \ufffd (125)\nThen we consider the second term\n(126)\n\ufffd Similarly, we define the annealed entropy of data risk. Let Q(z, \u03c4, \u03b1), z \u2208Z, \u03b1 \u2208\u039b be a set of real-valued functions. Let N \u039b,\u03b2z z (z1, ..., zl) be the number of different separations of l vectors z1, ..., zl by a complete set of indicators:\n\ufffd \ufffd The annealed entropy of data risk is defined that Definition 8. Annealed Entropy of Sample Risk Let the function\nDefinition 8. Annealed Entropy of Sample Risk Let the function\n(127)\nbe measurable with respect to measure on z1, ..., zl. The quantity\n(128)\nis defined as the annealed entropy of the set indicators \u03b8{Q(z, \u03c4, \u03b1) \u2212\u03b2z} of real-valued functions Q(z, \u03c4, \u03b1). And we have the inequality that\n(129)\n(130)\n(131)\n\ufffd\ufffd  \u2212 \ufffd \ufffd Let us substitute the inequation (125) and (131) into (116), we get: Theorem 11. Let At \u2264Rlo(t, \u03b1) \u2264Bt, \u03b1 \u2208\u039b and Az \u2264Q(z, t, \u03b1) \u2264Bz, \u03b1 \u2208\u039b be measurable set of bounded real-valued functions. Let \u02c6H\u039b,\u03b2t t (m) and \u02c6H\u039b,\u03b2z z (l)\nbe the annealed entropies of the sets of indicators for them. Then the following inequality is valid: \ufffd \ufffd\n\ufffd (132)\nFrom this theorem, we can directly establish a sufficient condition for the uniform convergence, which is to satisfy three equations:\n(133)\n(134)\n(135)\n(135)\nNote that in the Theorem 8, we have set the number of samples satisfied the inequality (53), which makes the equation (135) always be true. So we replace the equation (135) in the condition with inequality (53). And now we have the sufficient conditions of consistency that Corollary 2. For the existence of nontrival exponential bounds on uniform convergence, the sufficient conditions is to satisfy the following three formulas:\n(136)\n(137)\n(138)\n \u2212 This condition is sufficient for the consistency of EGRM, but is not necessary. More discussion is needed for the necessary conditions, which will be demonstrated in the following paper.\n# Triple Variables for Global Risk Controlling\nTo analyze the error bound (132), we introduce the data dimension hz and subject dimension htau. These two variables is similar to the VC dimension in statistical learning theory. The data dimension hz corresponds to the function Q(z, \u03c4, \u03b1), \u03b1 \u2208\u039b. It is equal to the largest number of vectors z1, ..., zl that can be shattered by the complete set of indicators. Let the growth function of real-valued function Q(z, \u03c4, \u03b1) be\n(139)\nand we have\n(140)\nThe subject dimension corresponds to the function Rlo(\u03c4, \u03b1), \u03b1 \u2208\u039b. It is equal to the largest number of vectors \u03c41, ..., \u03c4m that can be shattered by the complete set of indictors. Let the growth function of the real-valued function Rlo(\u03c4, \u03b1) be\n(141)\nand we have\n(142)\n\ufffd \ufffd Directly take the inequalities (140) and (142) to the equation (132), we get the following probability\n\ufffd \ufffd (143)\nNow we write the above equation. Let the right side of the inequality (143) be \u03b7, that is\n\ufffd\ufffd  \u2212 \ufffd \ufffd Then we get the theorem Theorem 12. With probability 1 \u2212\u03b7 the risk for the function Q(z, t, \u03b1l,m) which minimizes the empirical glob risk functional satisfies the inequality\nTheorem 12. With probability 1 \u2212\u03b7 the risk for the function Q(z, t, \u03b1l,m) which minimizes the empirical glob risk functional satisfies the inequality\n(144)\nThis is the bound of generalization error in the main context.\n",
    "paper_type": "theory",
    "attri": {
        "background": "This paper addresses the limitations of current AI systems, referred to as 'Narrow AI', which are constrained by traditional data assumptions. It emphasizes the importance of developing Artificial General Intelligence (AGI) capable of handling complex real-world data and making reasonable judgments, akin to human intelligence.",
        "problem": {
            "definition": "The core problem is the inadequacy of current AI systems to generalize beyond specific tasks due to two fundamental assumptions: that data samples are independent and identically distributed (i.i.d) and that there is a single-valued mapping from inputs to outputs.",
            "key obstacle": "The main challenge lies in breaking these traditional assumptions to enable AI systems to manage complex, inconsistent data from diverse tasks and environments."
        },
        "idea": {
            "intuition": "The idea is inspired by the human ability to classify and make judgments about complex data based on subjective perspectives.",
            "opinion": "The proposed method, termed subjectivity learning, involves actively categorizing data into various subjects, allowing for multiple mappings of inputs to outputs.",
            "innovation": "The primary innovation is the introduction of subjectivity as a mathematical concept, which allows for a more flexible and accurate representation of complex data compared to traditional machine learning methods."
        },
        "Theory": {
            "perspective": "The theory posits that human intelligence is inherently subjective, and this subjectivity can be mathematically defined to improve AI's understanding of complex data.",
            "opinion": "It assumes that traditional learning theories fail to accommodate the complexities of real-world data and that subjectivity is essential for developing AGI.",
            "proof": "The paper provides a proof that subjectivity learning can achieve a lower risk bound than traditional machine learning approaches, demonstrating its effectiveness for general intelligence."
        },
        "experiments": {
            "evaluation setting": "The experiments involve analyzing datasets that represent complex, real-world scenarios where traditional i.i.d assumptions do not hold.",
            "evaluation method": "The evaluation includes steps for minimizing the empirical global risk functional and assessing the performance of the subjectivity learning framework against traditional methods."
        },
        "conclusion": "The findings conclude that subjectivity learning offers a viable path towards AGI by effectively addressing the limitations of traditional machine learning, enabling better handling of complex data and reducing risk in judgments.",
        "discussion": {
            "advantage": "The main advantage of this paper is its innovative approach to modeling complex data through subjectivity, which allows for improved generalization and flexibility in AI systems.",
            "limitation": "One limitation is the practical implementation challenges of designing algorithms that effectively utilize the subjectivity learning framework.",
            "future work": "Future research can focus on developing specific algorithms that leverage subjectivity learning and exploring its physiological implications in human intelligence."
        },
        "other info": [
            {
                "info1": "The paper introduces the principle of empirical global risk minimization (EGRM) as a practical approach for subjectivity learning.",
                "info2": {
                    "info2.1": "It extends the Law of Large Numbers to accommodate coupled variables in the context of subjectivity learning.",
                    "info2.2": "The paper outlines conditions for consistency in the empirical global risk minimization method."
                }
            }
        ]
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The core problem is the inadequacy of current AI systems to generalize beyond specific tasks due to the assumptions that data samples are independent and identically distributed (i.i.d) and that there is a single-valued mapping from inputs to outputs."
        },
        {
            "section number": "2.1",
            "key information": "The theory posits that human intelligence is inherently subjective, and this subjectivity can be mathematically defined to improve AI's understanding of complex data."
        },
        {
            "section number": "3.5",
            "key information": "The primary innovation is the introduction of subjectivity as a mathematical concept, which allows for a more flexible and accurate representation of complex data compared to traditional machine learning methods."
        },
        {
            "section number": "5.2",
            "key information": "The findings conclude that subjectivity learning offers a viable path towards AGI by effectively addressing the limitations of traditional machine learning, enabling better handling of complex data and reducing risk in judgments."
        },
        {
            "section number": "7.1",
            "key information": "One limitation is the practical implementation challenges of designing algorithms that effectively utilize the subjectivity learning framework."
        }
    ],
    "similarity_score": 0.6265462335033289,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Subjectivity Learning Theory towards Artificial General Intelligence.json"
}