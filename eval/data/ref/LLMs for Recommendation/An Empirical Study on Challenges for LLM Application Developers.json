{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2408.05002",
    "title": "An Empirical Study on Challenges for LLM Application Developers",
    "abstract": "In recent years, large language models (LLMs) have seen rapid advancements, significantly impacting various fields such as computer vision, natural language processing, and software engineering. These LLMs, exemplified by OpenAI's ChatGPT, have revolutionized the way we approach language understanding and generation tasks. However, in contrast to traditional software development practices, LLM development introduces new challenges for AI developers in design, implementation, and deployment. These challenges span different areas (such as prompts, APIs, and plugins), requiring developers to navigate unique methodologies and considerations specific to LLM application development. Despite the profound influence of LLMs, to the best of our knowledge, these challenges have not been thoroughly investigated in previous empirical studies. To fill this gap, we present the first comprehensive study on understanding the challenges faced by LLM developers. Specifically, we crawl and analyze 29,057 relevant questions from a popular OpenAI developer forum. We first examine their popularity and difficulty. After manually analyzing 2,364 sampled questions, we construct a taxonomy of challenges faced by LLM developers. Based on this taxonomy, we summarize a set of findings and actionable implications for LLM-related stakeholders, including developers and providers (especially the OpenAI organization).",
    "bib_name": "chen2024empiricalstudychallengesllm",
    "md_text": "# An Empirical Study on Challenges for LLM Developers\nXIANG CHEN and CHAOYANG GAO, School of Artificial Intelligence and Computer Science, Nantong\nXIANG CHEN and CHAOYANG GAO, School of Artificial Intelligence and Computer Science, Nantong University, China CHUNYANG CHEN, Department of Computer Science, Technical University of Munich, Germany GUANGBEI ZHANG, School of Artificial Intelligence and Computer Science, Nantong University, China YONG LIU, College of Information Science and Technology, Beijing University of Chemical Technology, 2024\nCHUNYANG CHEN, Department of Computer Science, Technical University of Munich, Germany GUANGBEI ZHANG, School of Artificial Intelligence and Computer Science, Nantong University, China YONG LIU, College of Information Science and Technology, Beijing University of Chemical Technology, 2024\nIn recent years, large language models (LLMs) have seen rapid advancements, significantly impacting various fields such as natural language processing, and software engineering. These LLMs, exemplified by OpenAI\u2019s ChatGPT, have revolutionized the way we approach language understanding and generation tasks. However, in contrast to traditional software development practices, LLM development introduces new challenges for AI developers in design, implementation, and deployment. These challenges span different areas (such as prompts, APIs, and plugins), requiring developers to navigate unique methodologies and considerations specific to LLM development. Despite the profound influence of LLMs, to the best of our knowledge, these challenges have not been thoroughly investigated in previous empirical studies. To fill this gap, we present the first comprehensive study on understanding the challenges faced by LLM developers. Specifically, we crawl and analyze 29,057 relevant questions from a popular OpenAI developer forum. We first examine their popularity and difficulty. After manually analyzing 2,364 sampled questions, we construct a taxonomy of challenges faced by LLM developers. Based on this taxonomy, we summarize a set of findings and actionable implications for LLM-related stakeholders, including developers and providers (especially the OpenAI organization). CCS Concepts: \u2022 Software and its engineering \u2192Software creation and management; \u2022 Computing methodologies \u2192Artificial intelligence. Additional Key Words and Phrases: Mining Software Repository, Empirical Study, LLM Developer, Development Challenges, Prompt Engineering ACM Reference Format: Xiang Chen, Chaoyang Gao, Chunyang Chen, Guangbei Zhang, and Yong Liu. 2023. An Empirical Study on Challenges for LLM Developers. ACM Trans. Softw. Eng. Methodol. 1, 1 (August 2023), 29 pages. https: //doi.org/10.1145/nnnnnnn.nnnnnnn\n# 1 INTRODUCTION\nThe emerging large language models (LLMs) are increasingly attracting attention and becoming one of the hot research topics in the field of computer science. Until now, LLMs have demonstrated promising performance in different fields, such as natural language processing and software engi neering [11, 36, 48]. With the rise in popularity of ChatGPT developed by the OpenAI organization\nAuthors\u2019 addresses: Xiang Chen, xchencs@ntu.edu.cn; Chaoyang Gao, gcyol@outlook.com, School of Artificial Intelligenc and Computer Science, Nantong University, Nantong, China; Chunyang Chen, chun-yang.chen@tum.de, Department o Computer Science, Technical University of Munich, Heilbronn, Germany; Guangbei Zhang, guangbei0324@gmail.com School of Artificial Intelligence and Computer Science, Nantong University, Nantong, China; Yong Liu, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China, lyong@mail.buct.edu.cn.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. 1049-331X/2023/8-ART $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\nand the rapid development of related LLM technologies, an increasing number of developers are utilizing these techniques to assist in their development processes. However, during LLM development, developers often encounter various challenges. For example, correctly configuring and invoking LLM\u2019s API can be difficult, including setting parameters, managing rate limits, and handling errors. For those unfamiliar with AI and LLMs, developing plugins and applications can be daunting, involving integration, performance optimization, and ensuring security. Ensuring data privacy and security while handling user data is crucial. Developers must comply with relevant regulations and implement necessary security measures. Compared to traditional software development, LLM developers face the following unique challenges: (1) Automating task processing: LLMs can automatically handle many tasks, such as text generation, image recognition, and speech recognition. In contrast, traditional software engineering often requires manual coding of various algorithms and logic to accomplish these tasks. (2) Dealing with uncertainty: LLMs can produce variable and sometimes unpredictable outputs, unlike traditional software which typically has deterministic outcomes. Developers must account for this uncertainty and implement mechanisms to manage it. (3) Handling large-scale datasets: LLM development often involves working with large-scale datasets to train or fine-tune models. This requires specialized knowledge in data preprocessing, management, and the efficient use of computational resources. (4) Data privacy and security: Using LLMs requires a significant amount of data for training and fine-tuning, raising concerns about the privacy and security of user data. Developers need to design effective methods to ensure data security and privacy. (5) Performance optimization: Optimizing the performance of LLMs, such as output accuracy, differs from optimizing traditional software. (6) Interpreting model outputs: Understanding and interpreting the outputs of LLMs can be complex. Developers need to ensure that the model\u2019s outputs are reliable and contextually appropriate. These challenges require a different set of skills and considerations, highlighting the distinct nature of LLM development compared to traditional software development. However, to the best of our knowledge, these challenges faced by LLM developers have not been thoroughly investigated in previous empirical studies. To fill this gap, we present the first comprehensive study on understanding the challenges for LLM developers. Our empirical study aims to help developers to avoid common pitfalls and improve development efficiency. To this end, we crawl and analyze 29,057 questions from the OpenAI developer forum1. The OpenAI Developer Forum is a collaborative space for LLM developers to seek assistance and share insights on using OpenAI technologies. It supports developers of all skill levels, offering discussions on API integration, plugin development, and best practices. The forum also provides updates on the latest advancements and tools from OpenAI. In our empirical study, we want to answer the following three research questions. RQ1: What is the popularity trend of LLM development among developers? Result. After analyzing posts related to LLM development, we examine the number of new posts and new users added over each period. Our findings indicate that LLM development is attracting increasing attention from developers, particularly with the introduction of OpenAI pivotal products like ChatGPT. This growing trend underscores the rising popularity of LLM technologies, highlighting the timeliness and importance of our empirical study. RQ2: How difficult is LLM development for developers? Result. To illustrate the difficulty level of the challenges faced by LLM developers, we analyze the number of replies to LLM development-related questions. The results show that 54% of these questions have fewer than three replies, suggesting that they are typically challenging to address. This finding prompts us to further investigate the underlying challenges of these development questions.\n1https://community.openai.com\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\nRQ3: What specific challenges for LLM developers? Result. We perform a manual analysis on 2,364 sampled questions and construct a taxonomy of challenges consisting of 27 categories. For example, Prompt Design, Integration with Custom Applications, and Token Limitation. In addition, based on this taxonomy, we summarize findings and actionable implications for LLM stakeholders (such as developers and providers). Though LLM developer challenges are only analyzed by mining the OpenAI developer forum, our study has significant implications beyond the scope of OpenAI\u2019s products. Our study\u2019s findings broadly apply to LLM products developed by other companies (such as Google, Amazon, Microsoft, and Baidu). The commonalities in the challenges developers face (such as API usage, cost management, rate limitations, token limitations, safety, and privacy) are not unique to OpenAI. Still, they are prevalent across the entire LLM ecosystem. Therefore, the insights gained from our research can inform best practices, guide the development of support tools, and improve documentation and community resources for developers working with any LLM-based product. The main contributions of our empirical study can be summarized as follows: \u2022 We conduct the first empirical study to investigate the challenges faced by LLM developers by mining the OpenAI developer forum. \u2022 Our study constructs a taxonomy with detailed findings on these challenges. \u2022 We share our collected posts, analysis scripts, and taxonomy of challenges in a GitHub repository for open science2. Paper Organization. The rest of this paper is organized as follows. Section 2 introduces the background of LLM development. Section 3 describes our methods for collecting and analyzing forum posts. Section 4 analyzes the popularity of the forum. Section 5 analyzes the difficulty levels of the posts in the forum. Section 6 details our constructed taxonomy and discusses related findings. Section 7 analyzes potential threats and the solutions to alleviate these threats. Section 8 discusses work related to our study. Section 9 summarizes our empirical study.\n# 2 BACKGROUND\nOpenAI has emerged as a leading organization in artificial intelligence research, offering a range of APIs that enable developers to integrate advanced AI capabilities into their applications. The OpenAI API provides access to various models that can perform a wide array of tasks, from natural language understanding and generation to more complex functions like code completion and image recognition. This section provides an overview of the API usage and the development of plugins within the OpenAI ecosystem. API Service. The API service of the LLM allows developers to leverage the power of stateof-the-art LLM models through a simple interface. Key features of the API include: (1) Ease of integration: Developers can integrate the API into their applications with minimal setup, using familiar HTTP requests. (2) Versatile capabilities: The API supports various tasks including text generation, translation, summarization, and more. (3) Scalability: The API is designed to handle a wide range of requests, from small-scale personal projects to large-scale enterprise applications. The API offers several endpoints corresponding to different models and capabilities. For instance, the davinci model is known for its high performance in generating coherent and contextually relevant text, making it suitable for applications requiring sophisticated language understanding. Plugin Development. Plugins are extensions that enhance the functionality of software applications by embedding AI capabilities directly within them. For example, OpenAI provides robust support for plugin development, allowing developers to create custom plugins that interact with models provided by OpenAI. Key aspects of plugin development include: (1) API integration: Plugins 2https://github.com/judeomg/OADF\n2https://github.com/judeomg/OADF\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\ntypically make use of the OpenAI API to fetch responses from AI models based on user input or other triggers. (2) Custom functionality: Developers can tailor the behavior of plugins to meet specific needs, such as automating customer support responses, generating content, or providing real-time data analysis. (3) Interoperability: OpenAI plugins can be integrated with various platforms and services, enhancing the AI capabilities of a wide range of applications from web and mobile apps to enterprise systems. In November 2023, OpenAI introduced a customized version of ChatGPT called GPTs3 and developed GPT Store4 for sharing developed GPTs. Similar to plugins, GPTs serve personalized user needs. Developers can create different GPTs for specific purposes, which can be shared with others. GPTs offer a new way to create a tailored version of ChatGPT, assisting in daily life and specific tasks. For instance, GPTs can assist in analyzing math problems, learning soccer rules, or even helping in designing icons. Moreover, creating GPTs is a simple process that does not require coding, allowing anyone to easily build their GPTs by engaging in conversation with ChatGPT, providing instructions and additional knowledge, and selecting actions like web searching, data analysis, or image creation. While the integration of LLM\u2019s APIs and the development of plugins and GPTs offer significant advantages, they also present several challenges, such as: (1) Cost management: Managing the computational and financial costs associated with training, fine-tuning, and deploying LLM models, which can be significantly higher than those for traditional software systems. (2) Ethical considerations: Ensuring that LLM usage adheres to ethical guidelines, particularly in areas like content generation and decision-making. (3) Output authenticity: Verifying the accuracy and reliability of the output generated by LLMs to ensure that plugins and GPTs meet development goals and user expectations.\n# 3 METHODOLOGY\nTo understand the challenges faced by LLM developers, we collect and analyze relevant question posts from the OpenAI developer forum, which is a forum provided by OpenAI for developers working with their LLM products. We mined this forum by following previous studies [2\u20134, 27, 29, 41, 44]. Fig. 1 provides a methodology overview of our empirical study. Step 1: Crawl relevant data from the forum. To analyze the popularity trends and difficulty levels of the questions, we crawl posts from the OpenAI developer forum. To analyze challenges faced by LLM developers, we resort to categories, which make it easier to find relevant posts and ensure that questions reach the appropriate experts. Our study focuses on four specific categories (i.e., API, Prompting, GPT builders, and ChatGPT) in this forum. Specifically, posts in the \u201cAPI\" category concern questions, feedback, and best practices around building with OpenAI\u2019s product API. posts in the \u201cPrompting\" category learn more about prompting by sharing best practices, and favorite prompts. GPTs are a new way for anyone to create a tailored version of ChatGPT to be more helpful in their daily life, therefore, the \u201cGPT builders\" category is designed for developers who are building GPTs. Finally, the \u201cChatGPT\" concerns questions or discussions about ChatGPT. since posts in the remaining categories (i.e., Community, Announcements, Documentation, and Forum feedback) rarely discuss the challenges faced by LLM developers, we ignore these posts in our empirical study. Specifically, posts in the \u201cAnnouncements\" category typically contain official product updates, those in the \u201cDocumentation\" category offer tutorials and instructional content, posts in the \u201cCommunity\" category involve project and technology sharing, and posts in the \u201cForum feedback\" category focus on improving the developer forum.\n3https://openai.com/index/introducing-gpts 4https://openai.com/index/introducing-the-gpt-store/\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d44e/d44e5f2f-eb57-4376-876b-bd049355ae4b.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 1. Methodology overview of our empirical study.</div>\nFig. 2 shows a screenshot of a post5 from the OpenAI developer forum. Typically, a post consists of several key elements: title, category, tags, question description, and code snippet, with a few posts having accepted answers. These posts also include additional relevant information, such as creation time, last reply time, reply count, view count, and the number of participating users. In this step, we gather the following metadata: the post\u2019s title, creation date, and the number of replies. We also collect user metadata including usernames and registration times. In summary, by June 2024, we had crawled data from 29,057 posts and 722,389 users. Step 2: Determining popularity trend. To analyze the popularity trend of LLM development among developers, we first perform the time series analysis. Specifically, we count the number of new posts and new users over different periods (i.e., every three months) from the forum\u2019s inception in February 2021 until our data collection deadline in June 2024. Detailed result analysis can be found in Section 4. Step 3: Determining difficulty level. In our primary investigation, we find that a small proportion of posts mark one of the replies as \u201cSolution\" (i.e., indicating the acceptance by the questioner). The possible reason is that users in this community do not strictly adhere to this practice, unlike those in Stack Overflow [43]. Therefore, the methodology of determining difficulty levels through the proportion of accepted answers, as employed in prior studies [8, 35, 39], is not applicable in our study. In our study, we mainly assess the difficulty level of questions solely based on the number of replies received. Our study assumes that a lower number of replies indicates a higher level of difficulty in addressing the question. Detailed result analysis can be found in Section 5. Step 4: Constructing the taxonomy of challenges. Due to the high cost of manually analyzing all the crawled posts, we first removed posts that had been deleted by the forum community. From the remaining 29,057 questions, we randomly selected a statistically significant sample. This sample size ensures a 99% confidence level with a \u00b12.5% confidence interval [1]. As a result, 2,364 questions constitute the taxonomy dataset of our study. We construct the taxonomy as follows.\n5https://community.openai.com/t/547685\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b95f/b95f0ae7-09f3-445d-92d3-bd9239ed823f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 2. A question post from the OpenAI developer forum</div>\nFirst, we randomly select 70% of the 2,364 posts to construct the initial taxonomy of challenges by following the previous study [39]. This process involves two annotators working collaboratively. We use the open coding procedure [31] to analyze the sampled posts, summarize the preliminary taxonomy, and construct a multi-level hierarchical taxonomy of challenges faced by OpenAI developers. Each annotator has two years of experience in OpenAI development and three years of experience in developing large language models (LLMs). They carefully read the questions of the sampled posts to understand the specific challenges faced by OpenAI developers and the corresponding replies. The open coding procedure is conducted as follows: the two annotators read all the sampled posts, with each post being read at least twice. During the analysis, they examine all the data contained in each post, including titles, problem descriptions, code snippets, and replies, summarizing the specific challenges discussed. Then they summarize the specific challenges discussed in the posts. Specifically, some posts describe issues encountered during the use of ChatGPT, for example, \u201cCan\u2019t log in to Chat\" 6, which are not closely related to developers. In addition, there are also some questions related to account problems, tips for users, etc. These posts are labeled as \u201cUnrelated\". Since the OpenAI developer forum is a platform for all OpenAI users to communicate, some posts are official announcements, document introductions, project discussions, and project sharing. For example, \u201cI have an idea about creating a mix of emoji\" 7, these posts are temporarily labeled as \u201cUnrelated\". If a post is labeled as \u201cUnrelated\", it means that these\n6https://community.openai.com/t/23899 7https://community.openai.com/t/22180\n6https://community.openai.com/t/23899 7https://community.openai.com/t/22180\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\nposts are not considered when constructing the taxonomy because they are not closely related to OpenAI developers. For the remaining posts, the annotators use simple phrases to summarize the developer\u2019s challenges during the first reading. Specifically, some problem descriptions are about developers consulting on parameter settings when calling OpenAI\u2019s APIs, for example, \u201cGPT-4Vision-Preview fidelity/detail-parameter\" 8, the annotators find that this problem is asked because developers do not know how to set API parameters. Therefore, for these issues, the annotators can temporarily describe them as \u201cAPI Usage Issue, Parameter Setting\". The two annotators continue to process all sampled posts according to this step and construct the taxonomy of challenges faced by OpenAI developers. The grouping process is iterative, with continuous modifications to the taxonomy based on the posts and optimization of the post descriptions to improve taxonomy quality. If a post involves multiple categories, it is assigned to all relevant categories. When the two annotators have different opinions on category determination, a third arbitrator is asked to coordinate conflicts. The third arbitrator has five years of software project development experience and three years of experience in developing large language models. After rigorous processing, all participants reach a consensus, and the challenges of all posts are classified, resulting in a preliminary taxonomy of challenges faced by OpenAI developers. Finally, we refine the taxonomy of challenges and conduct a reliability analysis. Specifically, the two annotators independently label the remaining 30% of the posts based on the generated preliminary taxonomy. They label each post as \u201cUnrelated\" or assign it to the corresponding category. If some posts can not be categorized, they are temporarily labeled as \u201cPending\". We use Cohen\u2019s Kappa (k) [9] to measure the consistency between the two annotators during the independent labeling process. The computed \ud835\udc58value is 0.812, indicating that the two annotators almost completely agree [20]. This demonstrates the reliability of our open coding procedure. In addition, for posts labeled as \u201cPending\", we introduce the third arbitrator who discusses and analyzes the posts with the two annotators to determine which category these posts ultimately belong to. If they can not be categorized into the preliminary taxonomy, new categories are added. In this phase, we incorporate nine additional leaf categories into the preliminary taxonomy framework. Finally, our constructed taxonomy covers all posts related to OpenAI development, and all participants agree on the classification. Detailed result analysis can be found in Section 6.\n# 4 RQ1: POPULARITY TREND ANALYSIS\nFig. 3 illustrates the rising trend in LLM development popularity, as evidenced by the increasing number of posts on the OpenAI forum and the surge in registered users. The figure begins at the forum\u2019s inception, tracking the growth in new posts and users every three months. Given that the user number significantly exceeds the post number, we apply a logarithmic transformation to the actual numbers for a clearer representation of the results. This visualization reveals a significant increase in developer interest in OpenAI since 2021, underscoring the timeliness and urgency of our empirical study on challenges for LLM development. Before November 2022, the growth trend was fairly consistent. However, the introduction of GPT-3.5 and its fine-tuned product, ChatGPT, to the public by OpenAI in late November 2022, marked a substantial shift. The number of posts increased by 292%, and the number of users rose by 1,302% compared to the preceding period. The release of GPT-4 to paying customers in March 2023 further accelerated this trend, with a 323% increase in posts and a 628% increase in users. This strong growth trend has persisted until now.\n8https://community.openai.com/t/477563\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bb7a/bb7ae223-9ec0-41e2-a2c6-cb5e329c3076.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 3. The number of new posts and users every three months since creating the OpenAI developer forum Notice, in \ud835\udc66-axis, we apply a logarithmic transformation to the actual numbers for a clearer representation o</div>\n<div style=\"text-align: center;\">Fig. 3. The number of new posts and users every three months since creating the OpenAI developer  Notice, in \ud835\udc66-axis, we apply a logarithmic transformation to the actual numbers for a clearer representat the results</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a9db/a9db3bfa-3d73-4a64-b98f-3672cd516ca9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">5 RQ2: DIFFICULTY LEVEL ANALYSIS</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0146/01464a5d-06a9-42eb-9472-89d06e8515d1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Number of replies </div>\nFig. 4. The number of posts with different numbers of repli\nCM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\nFig. 4 illustrates the number of posts with different numbers of replies. We further calculate the proportion of posts with different numbers of replies among all posts, and the results show that 54% of questions receive fewer than three replies, while only 10% receive more than ten replies. This suggests that questions related to LLM development are generally challenging to resolve. We summarize potential reasons as follows. First, the new and complex technological domains of LLM require deep expertise and skills from developers. This scarcity of qualified professionals results in limited responses. Second, the rapid evolution of LLM technology often leaves issues unresolved, leading to fewer available answers. Finally, the lack of comprehensive documentation and tailored support resources makes it difficult to address diverse developer needs, prolonging the resolution process for many questions. Finding 2. Problems related to LLM development often face challenges in receiving immediate and sufficient replies. This highlights potential areas for improvement within the community and among LLM providers in offering more effective assistance.\n# 6 RQ3: CHALLENGE TAXONOMY CONSTRUCTION\nFig. 5 illustrates the hierarchical taxonomy of challenges faced by LLM developers. In this figure, the nodes are shaded in descending levels of grey based on their depth in the hierarchy (e.g., leaf nodes are white). Each leaf node represents a specific category, while its parent node is an inner node composed of multiple subcategories. For example, API (B) is an inner category that can be further classified into four leaf categories: Faults in API (B.1), Error Messages in API Calling (B.2), and API Usage (B.3). The proportion of posts for each category is shown in parentheses. In summary, our taxonomy includes six inner categories and 27 leaf categories. Based on this taxonomy, we find that LLM developers encounter a wide variety of problems across different aspects of development, highlighting the diversity of challenges in LLM development. Next, we describe and provide examples for each category and summarize our findings and implications for developers and LLM providers.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5332/53324251-40a6-466b-bb8b-fdedfd3c34d7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">. 5. Our Constructed Challenge Taxonomy for LLM Developers</div>\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n# 6.1 General Questions\nGeneral questions encompass challenges that lack specific implementation details and are often posed by developers seeking foundational knowledge in LLM development. Our findings indicate that 26.3% of the challenges fall into this category. The detailed subcategories are discussed as follows.\nGeneral questions encompass challenges that lack specific implementation details and are often posed by developers seeking foundational knowledge in LLM development. Our findings indicate that 26.3% of the challenges fall into this category. The detailed subcategories are discussed as follows. Integration with Custom Applications (A.1). With the launch of ChatGPT and the availability of LLM\u2019s APIs, more developers are leveraging these GPTs/APIs to build custom applications, such as translation systems and text classification systems. When integrating the API into their applications, developers often face complex and diverse technical questions. For example, developers seek to understand how to integrate custom GPTs with web page interfaces9 or inquire about the feasibility of implementing specific functionalities through API calls, such as considering specialized terminology that varies across different languages10, as shown in Fig. 6. Additionally, some developers raise concerns about the reproducibility of results in commercial text classification systems using GPT-3.5-turbo, especially after model updates11. Our findings indicate that challenges in this subcategory account for a significant 17.0%, highlighting the diverse and complex technical issues developers face when building their custom applications.\n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4ac9/4ac915d6-aad6-4dac-9e49-bc49d8c7c8ed.png\" style=\"width: 50%;\"></div>\nFig. 6. A sample post in the integration with custom application\nConceptional Questions (A.2). This category encompasses questions about basic conce background knowledge of LLM development, such as how to calculate the tokens needed fo question12, whether the GPT-4 API has access to the Internet13, or whether plugins can b\nConceptional Questions (A.2). This category encompasses questions about basic concepts or background knowledge of LLM development, such as how to calculate the tokens needed for each question12, whether the GPT-4 API has access to the Internet13, or whether plugins can be used\n9https://community.openai.com/t/589076 10https://community.openai.com/t/584762 11https://community.openai.com/t/281658 12https://community.openai.com/t/81018 13https://community.openai.com/t/468615\n9https://community.openai.com/t/589076 10https://community.openai.com/t/584762 11https://community.openai.com/t/281658 12https://community.openai.com/t/81018 13https://community.openai.com/t/468615\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\nwith the API14. Additionally, developers inquire about the internal implementation details, such as mechanisms of the content filter15. In our taxonomy, the posts in this subcategory account for 6.4%. Feature Suggestions (A.3). Developers often suggest adding new features related to API operations or express a desire to develop plugins for specific functionalities. For example, developers want to provide a way to view historical usage and spending by individual API key for better cost management of deployed chatbot apps using OpenAI\u2019s GPT turbo API16. Additionally, they recommend adding search and categorization features to the plugin page, which can quickly find the desired plugins17. Challenges related to these suggestions account for 2.9% in our taxonomy. Finding 4. The majority of the total challenges, 26.3%, fall under the category of General Questions. Within this category, the subcategory Integration with Custom Applications represents the largest proportion, accounting for 64.6% of General Questions.\nDiscussion and Implication: General questions often reflect fundamental challenges developers face when working with LLM technologies. These challenges span various aspects (such as application integration, conceptual questions, and feature suggestions). When leveraging APIs provided by OpenAI to build their applications (such as translation systems, text analysis systems, speech recognition systems, and others), developers often encounter complex technical questions. These include API integration methods, performance issues, output reproducibility issues, interpretability of output content, and so on. These challenges highlight the diverse and intricate nature of API integration and the need for clearer guidelines and examples from the LLM providers to assist developers in these areas. As integration with custom applications is a major challenge, The LLM providers could develop dedicated resources and support mechanisms to streamline this process. This may include detailed tutorials and integration best practices. Questions in the subcategory of conceptual questions involve basic concepts and background knowledge necessary for understanding OpenAI\u2019s technologies. Developers often inquire about token calculations, API capabilities and internal mechanisms, model versions, and other related issues. These challenges underscore the need for improved foundational documentation. To mitigate these challenges, improving educational resources will help developers grasp fundamental concepts more effectively, reducing the frequency of basic questions and accelerating their development process. For the last subcategory, developers frequently suggest new features or improvements related to API operations, such as better cost management tools, enhanced plugin and GPTs recommendation features, and support for a wide range of data formats. This subcategory reflects a proactive interest from developers in enhancing OpenAI\u2019s tools. Therefore, the LLM providers (e.g., the OpenAI organization) should establish a structured feedback mechanism to capture and address feature suggestions from developers. This will help prioritize feature development based on actual user needs and enhance overall user satisfaction.\n# 6.2 API\nThis category contains challenges related to the LLM APIs. In our taxonomy, 22.9% of the total challenges fall under this category. The detailed subcategories are discussed as follows. Faults in API (B.1). When calling LLM APIs, developers frequently encounter a variety of issues, such as low-quality generated content, limitations in model comprehension, and text coherence problems. These issues often result in LLM outcomes that do not meet developers\u2019 expectations. The majority of these issues are related to unsatisfactory output, such as the presence of extraneous\n14https://community.openai.com/t/186333 15https://community.openai.com/t/1095 16https://community.openai.com/t/305606 17https://community.openai.com/t/215754\ninformation (like spaces and newlines) in the API\u2019s responses18, as well as phrase repetition in answers19. Beyond these common faults, developers face other types of faults, such as APIs failing to respond due to requests being too frequent20. Additionally, when dealing with specific technical problems, such as converting natural language into SQL queries, they might produce incorrect answers21. These examples illustrate the diverse technical challenges that can arise. This subcategory represents 8.7% of the total challenges.\n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/eab4/eab42df8-b41d-4ec7-8e06-fb7efa5faebe.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 7. A sample post in the error messages in API calling (B.2)</div>\nError Messages in API Calling (B.2). This category primarily includes various error messages that developers encounter when calling LLM APIs. For example, developers might face request errors22 and data value capacity limit errors when calling an API for image editing23. As shown in Fig. 7, developers may also face issues related to the OpenAI server, such as gateway timeout errors24. This subcategory represents 7.5% of the total challenges. API Usage (B.3). Parameter configuration is a principal concern among developers, necessitating the parameter value adjustment to meet specific requirements and generate expected outputs from the API. A significant portion of these problems center on determining the appropriate values for API parameters25 (as shown in Fig. 8) and understanding the internal working and implementation mechanism (such as the response_model parameter26). Additionally, some challenges are closely\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3627/3627f212-f19a-47d7-ab8a-0deee4634b3a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">ACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.</div>\n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/421f/421f5ca7-49c2-4fd1-bfad-1b723d639d22.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 8. A sample post in API usage (B.3)</div>\nassociated with GPT models. For example, setting identical values for the seed parameter does not result in consistent outputs for specific GPT models27. This subcategory represents 6.7% of the tota challenges.\nFinding 5. Challenges related to the API rank second, accounting for 22.9% of the total challenges. Within this category, Faults in API and Error Messages in API Calling represent 38.0% and 32.8% of the challenges, respectively.\nDiscussion and Implication: Our results show that developers frequently encounter various issues when using OpenAI APIs. Some of these problems are related to the specific GPT models being used. For instance, certain APIs only support the gpt-4 turbo model for specific fields like response_format, indicating potential compatibility issues. Therefore, OpenAI should ensure that their documentation clearly outlines the compatibility of different models and fields, and provide detailed examples and best practices for developers to follow. This can help mitigate confusion and reduce the frequency of these issues. Developers also encounter various error messages when calling OpenAI API. To address these issues, OpenAI should consider providing more detailed error messages that help developers understand the cause of the errors and how to fix them. Additionally, offering guidance on common parameter configurations and their implications can be beneficial. For example, addressing phrase repetition issues can be managed by adjusting the frequency_penalty parameter, where setting positive values can penalize new tokens based on their existing frequency in the text so far, thereby decreasing the model\u2019s likelihood of repeating the same line verbatim. Parameter configuration is a principal concern among developers. To help developers, OpenAI should provide comprehensive documentation that includes detailed explanations of parameter values and their effects. Offering sample configurations and use-case scenarios can guide developers in making informed decisions about parameter settings. For example, explaining how different values for the temperature parameter affect the creativity and randomness of the generated content can help developers tailor the API output to their needs. In summary, the LLM providers should ensure that the API documentation is thorough, up-to-date, and includes detailed examples and best practices. Moreover, providing more informative error messages can help developers quickly identify and resolve issues. Finally, they should monitor community forums and address recurring issues by updating the API and documentation accordingly.\n27https://community.openai.com/t/487245\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n# 3 Generation and Understanding\nDue to powerful generation and understanding capabilities, developers can use LLM models to perform a variety of tasks (such as text processing via the LLM model GPT-4o, image processing via the model DALL-E, and audio processing via the model Whisper) or fine-tune the OpenAI models for downstream tasks. the challenges in these tasks often overlap with other challenge categories, so a question (such as parameter setting issues related to image generation28) may be classified into multiple categories. Challenges related to this category account for 19.9% of the total challenges. The detailed subcategories are discussed as follows. Text Processing (C.1). As LLM\u2019s core capability, text generation helps developers to create coherent and semantically sound textual content based on the input text (i.e., the prompt). This feature allows developers to automatically generate various types of text (such as articles, stories, and dialogues). By modifying the input prompts, developers can control the style, content, and length of the generated text to meet diverse application requirements across different scenarios. This category contains challenges associated with text generation, such as encountering errors when using the text generation API29 or getting repeated responses from the model davinci30. Moreover, developers want to provide feedback on the given output to improve the upcoming outputs when using the gpt-3.5-turbo model31. This subcategory constitutes 6.8% of all challenges.\n# \n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c079/c0797582-6cb9-496a-8e59-8e126e0f1d5e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 9. A sample post in fine-tuning GPT models (C.2)</div>\nFig. 9. A sample post in fine-tuning GPT models (C.2)\nFine-tuning GPT Models (C.2). LLM developers can fine-tune the models provided by OpenAI by using the training datasets of the downstream tasks. Due to the widespread use of fine-tuning, developers frequently face questions related to this functionality. For example, they often inquire about how to set the parameter n_epochs32 or request the fine-tuned model to output results in JSON format33. Additionally, as shown in Fig. 9, developers are interested in whether they can train a fine-tuned model in an iterative way34. This subcategory of questions accounts for 6.7% of the total challenges. Image Processing (C.3). Developers can influence image generation by inputting prompts into the model, allowing for the creation of images with customized features and styles. This versatile\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0ef8/0ef8ae2e-2a83-4b4a-bf89-e8c7758e5f01.png\" style=\"width: 50%;\"></div>\n28https://community.openai.com/t/359438 29https://community.openai.com/t/486260 30https://community.openai.com/t/254241 31https://community.openai.com/t/452220 32https://community.openai.com/t/339246 33https://community.openai.com/t/525169 34https://community.openai.com/t/18248\noftw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 20\nfeature is useful across diverse applications, including image editing and artistic creation, offering developers opportunities for creative expression and design. However, developers often encounter challenges such as request errors when seeking image generation solutions35 or perceiving that the quality of the generated images is lower than expected36. Finally, they find that the image quality generated through API calls is inferior to that of the ChatGPT web version using the same prompts37. This subcategory constitutes 2.5% of all challenges. Embedding Generation (C.4). By using the Embedding APIs provided by LLM providers, developers can leverage powerful text representation capabilities to convert text into high-dimensional vector representations. These vectors can capture the semantics and contextual information of the text, which can be used for tasks such as semantic search and text clustering. For example, developers may encounter PermissionError when creating embeddings38. Additionally, they often inquire whether modifying user queries can improve the accuracy of semantic search39 and how to determine the length of embedded content40. Challenges related to this subcategory account for 1.8% of the total challenges.\n# \n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ed8b/ed8b54ae-281f-4f26-afaa-e354230b00a5.png\" style=\"width: 50%;\"></div>\nFig. 10. A sample post in audio processing (C.5).\nAudio Processing (C.5). Processing audio is one of the key functionalities provided by OpenAI. Developers can utilize advanced speech models (such as the LLM model Whisper) to perform transformations, analysis, and generation of audio data, thereby supporting applications such as speech recognition and audio generation. For instance, developers might encounter random text in the output after the API recognizes audio41 or face InvalidRequestError when calling the model\n35https://community.openai.com/t/586006 36https://community.openai.com/t/435187 37https://community.openai.com/t/435187 38https://community.openai.com/t/587579 39https://community.openai.com/t/393047 40https://community.openai.com/t/111471 41https://community.openai.com/t/287544\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\nwhisper API42, as shown in Fig. 10. Additionally, they often ask how to combine audio processing with image processing43. Challenges in this subcategory constitute 1.4% of all challenges. Vision Capability (C.6). The Vision API uses pre-trained vision models to quickly and accurately identify objects, scenes, and features in images, providing developers with powerful image processing capabilities. This functionality is widely applicable in areas such as image recognition, intelligent surveillance, and medical image analysis. However, developers may encounter error messages when using the gpt-4-vision-preview API44 or find that it occasionally misinterprets information in images45. They also ask usage-related questions, such as how to add a parameter to view image resolution46. This subcategory constitutes 0.7% of all challenges. Finding 7. The category of Generation and Understanding, the third-largest category, has 34.2%\nDiscussion and Implication: The analysis of the various subcategories within the \"Generation and Understanding\" category reveals several insights into the challenges developers face and the implications for improving OpenAI\u2019s models and their usage. (1) API usage issues. A significant portion of the challenges are related to the practical use of APIs. Issues such as repeated responses from the Davinci model, errors in embedding API usage, and problems with the Whisper API during audio processing are common. Developers often struggle with these API-related problems, seeking solutions and best practices for effective implementation. Therefore, detailed, updated documentation should be provided, especially for frequently encountered issues. For instance, recommending the use of the latest APIs, such as the Chat Completions API instead of older models like Davinci, can help mitigate repeated response issues. Providing best practices for embedding API usage, such as adding an offset vector to improve accuracy, can enhance developer experience. Similarly, sharing solutions for Whisper API errors, like addressing audio recording and encoding issues, can be beneficial. (2) Conceptual challenges. Developers often face conceptual challenges, particularly with fine-tuning GPT models, parameter settings, iterative training, and output formatting, indicating a need for a deeper understanding of these processes. Therefore, creating comprehensive guides and tutorials on fine-tuning, common parameter settings, and iterative training techniques, can address many of these questions. (3) Application-specific issues. Challenges also arise from specific applications. Taking image processing as an example, developers encounter issues like translating prompts from other languages (such as French) to English, intellectual property concerns with generated images, and improving image recognition accuracy by adjusting contrast or rotation. Therefore, enhancing multilingual support for image processing prompts can help generate the desired images regardless of the input language. Providing clear guidelines on the intellectual property rights of generated images can address developers\u2019 concerns and promote more confident use of the technology. Sharing techniques for improving image recognition accuracy, such as contrast adjustment and rotation correction, can help developers achieve better results in their applications.\n# 6.4 Non-functional Properties\nThe importance of non-functional properties cannot be ignored by OpenAI developers. These properties include aspects such as API call costs, rate limitation, and data security. In our taxonomy, 15.4% of the challenges belong to this category. The detailed subcategories are discussed as follows.\n42https://community.openai.com/t/433315 43https://community.openai.com/t/22912 44https://community.openai.com/t/546593 45https://community.openai.com/t/504043 46https://community.openai.com/t/477563\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\nCost (D.1). Challenges in this category are related to API call costs. In the context of OpenAI development, costs are determined by the number of tokens utilized in each API call, particularly for generated content. Developers express concerns regarding the calculation of token usage and the cost47. They seek strategies to reduce costs by minimizing token consumption48. Responses to these challenges typically involve providing documentation-related information or offering strategies that consider factors such as the chosen model, input content length, and response content length. This category constitutes 3.6% of all challenges.\n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/32e5/32e5c38c-84ea-4f80-8480-c9ac3f7a0f1a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 11. A sample post in rate limitation (D.2).</div>\nRate Limitation (D.2). Rate limitation is typically implemented to safeguard the stability and reliability of OpenAI services, preventing service interruptions or performance degradation due to excessive API usage. Developers need to understand the rate-limiting rules of the API, including the maximum number of calls per second, per minute, or per hour for different versions of the API, and how to manage call frequency in a sensible way to avoid triggering rate limits and causing service interruptions or exceptions. For example, developers encounter RateLimitError when calling gpt3.5-turbo-030149. Additionally, developers inquire whether rate limits are shared among different APIs50. Furthermore, as shown in Fig. 11, developers ask about methods to alleviate or increase the API rate limits51. These types of questions account for 3.2% of the total challenges. Regulation (D.3). When utilizing the LLM APIs, developers should strictly adhere to relevant regulations. For instance, the OpenAI organization provides guidelines for the release of specific models or features and determines which users are granted permission to utilize them52. Developers\n47https://community.openai.com/t/496993 48https://community.openai.com/t/525033 49https://community.openai.com/t/566696 50https://community.openai.com/t/360331 51https://community.openai.com/t/248374 52https://openai.com/policies/usage-policies/\n47https://community.openai.com/t/496993 48https://community.openai.com/t/525033 49https://community.openai.com/t/566696 50https://community.openai.com/t/360331 51https://community.openai.com/t/248374 52https://openai.com/policies/usage-policies/\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n\nshould review and abide by the terms of service and usage policies provided by OpenAI to ensure compliance with commercial and copyright regulations during API calls. For example, developers want to know whether LLM API can be used for commercial purposes53, or whether the images generated by the model DALL-E can be sold54. Additionally, developers encounter issues where prompts violate content policy rules55. This category constitutes 3.0% of all challenges. Promotion (D.4). Developers leverage forums as platforms to promote their developed plugins and GPTs, aiming to gather user feedback and potentially generate revenue. To this end, they offer comprehensive introductions to their creations, innovative functionalities, and usage guidelines. For instance, a developer promotes a plugin named \u201cShellMaster\"56. Additionally, developers complain that the current GPT store lacks discoverability, meaning that many excellent GPTs are likely unknown to most people. They hope to add recommendations for users57. This category represents 2.1% of the challenges.\n# \n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f411/f411c617-78de-48eb-9db8-b17823c04c82.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 12. A sample post in token limitation (D.5)</div>\nToken Limitation (D.5). In addition to rate limiting, OpenAI imposes restrictions on the number of tokens for input and output during API calls to prevent abuse of API resources. Therefore, developers should understand the allocation, usage rules, and limitations of API tokens, as well as how to manage and optimize their usage. Specifically, developers find that the context length of the API is not fully utilized58. Additionally, developers seek methods to address token limitation 59. Furthermore, they inquire about solutions for handling large-scale datasets that exceed the token limitation and ineffective data splitting when using the gpt-4-1106-preview model60, as shown in Fig. 12. This category constitutes 2.0% of the challenges. Security (D.6). Ensuring security and preventing data leakage during API calls are the main concerns for OpenAI developers. They should prioritize protecting the privacy and integrity of data, minimizing the risk of data leaks due to security vulnerabilities or improper configurations. For example, developers express apprehension about potential data security risks when utilizing the API to process their uploaded files61. Additionally, they want to know whether using the API within internal networks can lead to data leakage62. This category constitutes 0.8% of all challenges.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2e43/2e4331a3-4291-4830-bcbd-5ba3160f31ed.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">ACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.</div>\nPrivacy (D.7). Developers are advised to carefully review OpenAI\u2019s privacy policy to gain insights into the data collection and processing practices during API calls and to understand the measures in place to protect users\u2019 personal privacy. Furthermore, since API keys serve as critical qualifications for developer authentication and authorization, it is imperative for developers to prioritize the secure storage and management of these keys to prevent leaks or misuse. For example, developers create a desktop application based on ChatGPT and want to know if each user can use their API key within the program for billing purposes63. Additionally, developers have concerns regarding potential privacy issues associated with GPTs64. This subcategory constitutes 0.7% of all challenges.\nFinding 8. 15.4% of the total challenges are in Non-functional Properties, covering seven subcategories. Cost and Rate Limitation are the top two categories, together accounting for 44.2% of the challenges in Non-functional Properties.\nDiscussion and Implication: Challenges such as API call costs, rate limitation, and token limitation are tightly linked to the development and usage of the LLM\u2019s services. Developers often express concerns about the costs associated with API calls, which are influenced by the choice of model and the number of tokens used in each request. Similarly, rate limitations are put in place to ensure service stability, but developers need to understand these limits and manage their API call frequencies accordingly. Token limitations pose additional challenges, especially when developers need to handle large datasets or require extensive context in their applications. Therefore, the LLM provider should develop and provide tools that help developers accurately calculate and manage their token usage. This includes offering cost optimization strategies tailored to different models and usage scenarios. Moreover, providing detailed guidelines on model selection, including trade-offs between cost and performance, will help developers make informed decisions that align with their budget constraints. General challenges such as safety and privacy are paramount when using AI services. Developers should ensure that their applications adhere to safety standards and protect user privacy. Therefore, OpenAI should continue to promote the use of its free moderation API, which helps reduce the frequency of unsafe content in completions. This tool should be integrated into the development process to automatically flag and filter potentially harmful outputs. Moreover, in high-stakes domains and code generation, it is crucial to have a human review of outputs before they are used in practice. This ensures that any limitations of the system are accounted for, and provides a safety net to verify the correctness and appropriateness of the generated content. Finally, limiting the amount of text a user can input into prompts and restricting the number of output tokens can help mitigate the risks of prompt injection and reduce the chances of misuse. These limitations should be implemented as part of best practices for safe AI deployment.\n# 6.5 GPT Builder\nTo meet specific user needs, the OpenAI organization initially introduced the ChatGPT plugin, allowing developers to design plugins with various functionalities based on user requirements. Recently, OpenAI launched GPTs with similar functionality. However, due to their later release, there are fewer posts related to GPTs. Although OpenAI has deprecated plugins and recommends using GPTs as a replacement for users\u2019 personalized needs, the OpenAI developer forum still lists plugins as an important category and combines plugins and GPTs into a single category. Moreover, plugin development and GPT development share many similarities in terms of development goals,\n63https://community.openai.com/t/161185 64https://community.openai.com/t/496343\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\nechnical foundations, and user usage. Therefore, we refer to the categories on the forum and collectively call both ChatGPT plugins and GPTs \u201cGPT Builders\" and analyze the related challenges.\n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3c71/3c7177d1-ff40-48b2-96a1-949a5c3ec96a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 13. A sample post in development (E.1)</div>\nDevelopment (E.1). In plugin development, developers encounter various challenges, including general and technical problems. Among general problems, developers seek guidance on selecting the most convenient IDE for plugin development65 and whether Markdown code can be integrated into plugin development66. Another category of challenges is related to technical issues. For instance, developers encounter a FatalServerError while developing a plugin67 or face parsing errors when attempting to connect GPTs to a cloud website68, as shown in Fig. 13. Additionally, developers ask how to use multiple GPTs simultaneously to handle the same task69. These challenges account for 11.2% of the total challenges. Testing (E.2). Following the development of plugins or GPTs, developers engage in software testing to ensure the correctness of the functionality implementation. During this process, developers encounter various issues. For instance, the openapi.yaml file might fail initial validation because it makes an HTTPS request instead of HTTP when testing the plugin on a local server70,\n65https://community.openai.com/t/404743 66https://community.openai.com/t/199399 67https://community.openai.com/t/297501 68https://community.openai.com/t/545528 69https://community.openai.com/t/552649 70https://community.openai.com/t/254680\noftw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 20\nor developers encounter errors while testing if the plugin is working correctly71. In addition, some functional errors may be encountered during testing. For example, when developers test a GPT action, they find that after clicking to test, only the name of the GPT is displayed, without any other content output72. These challenges represent 0.9% of the total challenges. Finding 9. GPT Builder accounts for 12.1% of the total challenges. Development dominates this category, accounting for 92.6% of the challenges in GPT Builder. Discussion and Implication: Developers face numerous general challenges when developing plugins and GPTs, particularly in selecting the appropriate development environments and tools. This involves decisions about which Integrated Development Environments (IDEs) to use, which programming languages best suit their project needs, and how to set up their development environments efficiently. Therefore, OpenAI should develop comprehensive guides that cover the entire development lifecycle of plugins and GPTs, including recommendations for IDEs, programming languages, and other essential tools. This will help developers make informed choices that enhance their productivity and the quality of their work. Moreover, providing clear examples and templates can streamline the development process, particularly for those at varying skill levels. These resources can include step-by-step tutorials, sample projects, and best practices for developing and debugging, ensuring that developers have the support they need from project initiation to completion. After the development phase, rigorous testing is crucial to ensure the correct functioning of plugins and GPTs. Therefore, OpenAI should provide comprehensive automated testing tools that allow developers to test their plugins and GPTs efficiently. Automated testing can help identify bugs and issues early in the development cycle, reducing the time spent on manual testing and allowing for more consistent and repeatable tests. Moreover, these tools should support various testing methodologies, including unit tests, integration tests, and acceptance tests. By covering a broad range of scenarios, developers can ensure their applications are robust and reliable.\n# 6.6 Prompt\nPrompts play a pivotal role in LLM interactions, offering developers a mechanism to enhance the quality of the content produced. This category primarily focuses on challenges related to prompts, such as how to design and optimize them. Our findings indicate that 3.4% of the challenges fall into this category. Below, we analyze the specific subcategories it contains. Prompt Design (F.1). Developers often struggle with how to provide specific prompts to achieve the desired results and how to adjust their existing prompts. This includes techniques like targeting specific topics and managing the length of generated content to guide the model more accurately. For example, they seek advice on prompts to regenerate part of the output73(as shown in Fig. 14) and how to adjust prompts to improve the conversational style with the GPT model74. Challenges related to prompt design constitute 2.3% of the total questions. Retrieval Augmented Generation (F.2). Retrieval Augmented Generation (RAG) [21] is a technique that enhances the quality and relevance of generated text by integrating information retrieval with generation processes. This technique combines the strengths of retrieval and generation, enabling the model to better grasp the context and produce text that meets user expectations. Developers encounter issues where RAG fails to improve output quality75 or cause hallucinations\n71https://community.openai.com/t/166239 72https://community.openai.com/t/597697/6 73https://community.openai.com/t/214339 74https://community.openai.com/t/301950 75https://community.openai.com/t/550286\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n\n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8e7d/8e7d62ae-2301-410f-a1f9-e9e6c1131e27.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 14. A sample post in prompt design (F.1)</div>\nafter processing76. Questions also arise about preventing the RAG system from answering unrelated questions77. Challenges related to RAG account for 0.4% of the total challenges. Chain of Thought (F.3). The Chain of Thought (CoT) technique [38] is crucial for maintaining coherence and logical progression during text generation. It requires developers to craft input prompts that encourage the generation of text following a logical and semantic chain of thought. Achieving this involves careful selection of keywords, phrases, and sentence structures to steer the model toward producing coherent and structured text. Developers need a robust understanding of language, logical reasoning, and text generation capabilities, along with the skill to evaluate the model\u2019s behavior and outputs. Ensuring semantic coherence and meeting expectations might prompt questions on effectively utilizing the CoT technique to construct prompts78 and seeking best practices for CoT in specific scenarios79. Challenges associated with this technique account for 0.2% of the total challenges. In-context Learning (F.4). In-context learning (ICL) [10] involves the model\u2019s ability to learn and interpret based on the contextual information supplied within the input prompt. By meticulously designing these prompts, developers can embed specific contextual clues, enabling the model to deduce and produce content reflective of that context. For instance, there may be situations where, despite being provided with examples, the model repetitively generates identical outputs80. Developers seek advice on the recommended approach to provide context to follow-up questions\n76https://community.openai.com/t/408275 77https://community.openai.com/t/434871 78https://community.openai.com/t/128180 79https://community.openai.com/t/17367 80https://community.openai.com/t/17866\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n# \n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e0a4/e0a4c871-27dc-423d-8050-2278550b4a96.png\" style=\"width: 50%;\"></div>\nto retrieve relevant context for completion81, as shown in Fig. 15. Challenges related to in-context learning represent 0.2% of the total challenges. Zero-shot Prompting (F.5). Zero-shot prompting [19] allows developers to leverage the model\u2019s capabilities without needing sample data. Common issues include comparing the efficacy of zeroshot prompting versus fine-tuning for specific tasks82. Recently, some developers observed that zero-shot prompting works as expected on the OpenAI Playground but fails to generate valid responses when called via the Python API83. Challenges related to zero-shot prompting constitute 0.2% of the total questions. Tree of Thoughts (F.6). Tree of Thoughts (ToT) [42] is an advanced structured Chain of Thought (CoT) technique that guides the model toward generating text that is hierarchically organized and logically coherent. By creating detailed input prompts that integrate information from various branches and nodes within the ToT framework, developers enable the model to produce outputs with a clear hierarchy and logical structure. This technique assists the model in adhering to the ToT\u2019s structure, facilitating the creation of more organized and logically structured outputs. Researchers have found that ToT significantly enhances language models\u2019 problem-solving abilities in tasks requiring non-trivial planning or search, such as the Game of 24, creative writing, and mini crosswords84. Challenges related to ToT account for 0.1% of the total challenges.\n81https://community.openai.com/t/280666 82https://community.openai.com/t/289714 83https://community.openai.com/t/216108 84https://community.openai.com/t/226512\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n\n\nFinding 6. 3.4% of the total challenges are related to Prompt. Prompt Design constitutes 67.6% o this category, which is the highest proportion among the six subcategories.\nDiscussion and Implication: LLM developers often encounter challenges when crafting prompts that achieve specific outcomes, manage content length, and maintain a conversational style. Prompt engineering involves feeding the model useful phrases and instructions to elicit helpful responses, which includes clearly stating the desired topic or task, and specifying constraints to guide responses within defined boundaries. Therefore, OpenAI should provide comprehensive educational resources on prompt engineering, including tutorials, webinars, and documentation. These resources should cover the principles of effective prompt design, common pitfalls, and best practices for crafting prompts that yield accurate and useful responses. Moreover, developing interactive tools that allow developers to experiment with and optimize prompts in real time would be highly beneficial. Finally, establishing a community platform where developers can share successful prompts, discuss challenges, and collaborate on solving common issues is crucial. Recent advancements in prompt design (such as In-context Learning, and Chain-of-Thought) offer powerful techniques for enhancing the performance of OpenAI models. These techniques involve using contextual information, reasoning through chains of logic, and augmenting responses with external data to improve the quality and relevance of the output. However, in our analysis, the number of posts discussing these advanced techniques is relatively low, indicating that developers are not paying enough attention to these advanced technologies. Therefore, OpenAI should offer extensive documentation and resources on these advanced techniques. This documentation should include detailed explanations of the underlying principles, common pitfalls, and practical examples to help developers effectively implement these techniques. Providing step-by-step guides and use case scenarios can make these resources more accessible and practical. Moreover, providing interactive tools that allow developers to experiment with and optimize these advanced techniques in real time would be invaluable.\n# 7 THREATS TO VALIDITY\nIn this section, we discuss the threats to the validity of our empirical study, ensuring a comprehensive understanding of potential limitations.\n# 7.1 Internal Validity\nExpertise in constructing the challenge taxonomy: One internal threat is related to the expertise involved in constructing the challenge taxonomy. To mitigate this, individuals involved in the taxonomy construction are required to have relevant experience in LLM development and a foundational understanding of large language models. This ensures that the taxonomy accurately reflects the challenges faced by developers. Determining question difficulty levels: Another internal threat is the method used to determine the difficulty level of questions posed on the OpenAI forum. Our analysis shows that only 7.0% of the sampled posts had one reply marked as a \u201cSolution\", Hence, the difficulty level is primarily determined by the number of replies each question receives rather than relying on accepted answers. Manual labeling of topics: We manually label the topics, which can introduce bias. To minimize this threat, two different authors independently label the topics, and a third author, a domain expert, validates these labels. Any conflicts are resolved through discussions among the authors, thereby reducing labeling bias to an acceptable minimum. Selection of forum posts: Our study selectively focuses on posts within specific categories like API, Prompting, ChatGPT, and GPT builders, excluding others such as Community, Announcements,\nDocumentation, and Forum feedback. This selection is based on the observation that excluded ategories rarely discuss challenges related to LLM development.\n# 7.2 External Validity\nScope of data: An external challenge arises from the temporal limitation of our data, encompassing posts up to June 2024. As the LLM providers continue to develop new applications, new challenges will likely emerge, which are not captured in our current empirical study. Incorrect initial categorization: Some developers may choose the wrong category when posting. For example, the issue is related to API calls, but the developer categorizes it under Prompt. To address this issue, when categorizing posts, we carefully read all the information (including questions and replies) and analyze the correct category to mitigate such errors.\n# 7.3 Construct Validity\nAccuracy of taxonomy categories: There is a risk that the taxonomy categories may not fully capture all relevant challenges faced by OpenAI developers. To address this, we iteratively refine the taxonomy based on feedback and consensus among experienced annotators, ensuring a comprehensive representation of challenges.\n# 8 RELATED WORK 8.1 LLM for Software Engineering\n# 8 RELATED WORK\n# 8.1 LLM for Software Engineering\nLarge Language Models (LLMs) have recently demonstrated significant potential in numerous software engineering (SE) applications and this research domain is called LLM4SE. These LLMs, trained on extensive datasets, excel in comprehending, processing, and generating code in various programming languages, achieving promising results across a wide range of SE tasks. One significant application is in code generation, where LLMs have been used to refine and improve code creation processes, making it easier for developers to produce high-quality code efficiently [22, 23]. For automatic program repair, LLMs have shown promise by automatically identifying and fixing bugs, thereby reducing the time and effort required for manual debugging [17, 40]. For bug report management, LLms have been utilized in the process of handling, categorizing, and reproducing bug reports, which enhances the overall efficiency of software maintenance [18, 45]. For mobile application testing, LLMs aid in automating the testing process, ensuring more comprehensive test coverage and faster identification of issues [24\u201326]. For vulnerability detection, LLMs can help in identifying potential security vulnerabilities in code, contributing to the development of more secure software applications [6, 12, 28]. Finally, for source code summarization, LLMs can be used to generate concise and accurate summaries of source code, aiding developers in understanding and documenting code more effectively [33, 47]. Given the widespread applications of LLMs in SE tasks, analyzing the challenges faced by LLM developers is of significant importance.\n# 8.2 Studies on ML/DL Developers\u2019 Challenge\nIn traditional software development, developers face a broad range of challenges across different application domains such as mobile applications [29], web applications [30], and concurrency programs [2]. These challenges include understanding complex requirements, ensuring code quality and maintainability, handling bugs/security vulnerabilities, and integrating various software components. The rapid development of machine learning (ML) technologies poses new challenges for software developers. Thung et al. [34] analyzed bug severity, bug fixing efforts, and bug impacts in ML systems. Alshangiti et al. [3] demonstrated that questions in the process of ML application development are\nIn traditional software development, developers face a broad range of challenges across different application domains such as mobile applications [29], web applications [30], and concurrency programs [2]. These challenges include understanding complex requirements, ensuring code qual ity and maintainability, handling bugs/security vulnerabilities, and integrating various software components.\nThe rapid development of machine learning (ML) technologies poses new challenges for software developers. Thung et al. [34] analyzed bug severity, bug fixing efforts, and bug impacts in ML systems. Alshangiti et al. [3] demonstrated that questions in the process of ML application development are\nmore difficult to answer than questions in other domains on Stack Overflow. These studies highlight the unique difficulties in developing and maintaining ML systems, such as data quality issues, model training complexities, and integrating ML models with traditional software components. In the realm of deep learning (DL), DL developers face distinct challenges. For example, Zhang et al.[44] found that program crashes, model migration, and implementation questions are the top three most frequently asked questions when developing DL applications. Morovati et al. [? ] investigated the challenges of deep reinforcement learning application development. Other researchers have characterized faults in software that make use of DL frameworks. For example, Zhang et al.[46] categorized the symptoms and root causes of these DL bugs for TensorFlow and proposed strategies to detect and locate them. Then Islam et al.[16] and Humbatova et al.[15] extended the scope to include bugs in programs written based on more popular DL frameworks (such as Caffe, Keras, TensorFlow, Theano, and PyTorch), presenting more comprehensive results. Recently, Shen et al. also analyzed the DL compiler bugs [7, 32]. Empirical studies also highlighted specific issues, such as bugs in model optimization [13], compatibility problems [14, 37], DL deployment challenges [8], and performance-related concerns [5]. Different from previous studies, our work aims to fill the gap in understanding the specific challenges faced by LLM developers. By systematically categorizing and analyzing posts in the OpenAI developer forum, we provide a comprehensive overview of the challenges LLM developers encounter. Our findings offer valuable insights for both developers and LLM providers, guiding future improvements in developer support and tool development. This study not only highlights common challenges but also identifies unique challenges faced by LLM developers, providing a foundation for targeted solutions and enhancements in the LLM development ecosystem.\n# 9 CONCLUSION\nIn this study, we conduct a comprehensive analysis of the challenges faced by LLM developers. By examining relevant posts on the OpenAI developer forum, we observe that LLM-related development is gaining significant traction, with developers encountering numerous challenging issues compared to traditional software development. Our goal is to analyze the underlying challenges reflected in these questions. We investigate the popularity trends on the LLM developer forum and the difficulty levels of the problems raised by developers. Subsequently, we manually inspect 2,364 sampled posts related to LLM development and construct a detailed taxonomy consisting of 6 main categories and 27 subcategories, representing the challenges that LLM developers encounter. Finally, we discuss the implications of our findings for various stakeholders, including LLM developers and LLM providers. For future research, there are several avenues to explore. First, expanding the analysis to include posts from other platforms, such as GitHub and Stack Overflow, can provide a more comprehensive view of the challenges faced by LLM developers. Second, an in-depth study of the solutions proposed in response to the identified challenges can yield valuable insights into effective strategies and best practices. Finally, automating the categorization process using machine learning techniques can improve the efficiency and accuracy of the analysis.\n# ACKNOWLEDGMENTS\nXiang Chen and Chaoyang Gao have contributed equally to this work and they are co-first authors Xiang Chen is the corresponding author. This research was partially supported by the National Natural Science Foundation of China (Grant no. 61202006) and the Postgraduate Research & Practice Innovation Program of Jiangsu Province (Grant no. SJCX24_2022).\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n# REFERENCES\n[1] Emad Aghajani, Csaba Nagy, Olga Lucero Vega-M\u00e1rquez, Mario Linares-V\u00e1squez, Laura Moreno, Gabriele Bavota, and Michele Lanza. 2019. Software documentation issues unveiled. In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, 1199\u20131210. [2] Syed Ahmed and Mehdi Bagherzadeh. 2018. What do concurrency developers ask about? a large-scale study using stack overflow. In Proceedings of the 12th ACM/IEEE international symposium on empirical software engineering and measurement. 1\u201310. [3] Moayad Alshangiti, Hitesh Sapkota, Pradeep K Murukannaiah, Xumin Liu, and Qi Yu. 2019. Why is developing machine learning applications challenging? a study on stack overflow posts. In 2019 acm/ieee international symposium on empirical software engineering and measurement (esem). IEEE, 1\u201311. [4] Mehdi Bagherzadeh and Raffi Khatchadourian. 2019. Going big: a large-scale study on what big data developers ask. In Proceedings of the 2019 27th ACM joint meeting on european software engineering conference and symposium on the foundations of software engineering. 432\u2013442. [5] Junming Cao, Bihuan Chen, Chao Sun, Longjie Hu, Shuaihong Wu, and Xin Peng. 2022. Understanding performance problems in deep learning systems. In Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 357\u2013369. [6] Chong Chen, Jianzhong Su, Jiachi Chen, Yanlin Wang, Tingting Bi, Yanli Wang, Xingwei Lin, Ting Chen, and Zibin Zheng. 2023. When chatgpt meets smart contract vulnerability detection: How far are we? arXiv preprint arXiv:2309.05520 (2023). [7] Junjie Chen, Yihua Liang, Qingchao Shen, Jiajun Jiang, and Shuochuan Li. 2023. Toward understanding deep learning framework bugs. ACM Transactions on Software Engineering and Methodology 32, 6 (2023), 1\u201331. [8] Zhenpeng Chen, Yanbin Cao, Yuanqiang Liu, Haoyu Wang, Tao Xie, and Xuanzhe Liu. 2020. A comprehensive study on challenges in deploying deep learning based software. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 750\u2013762. [9] Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and psychological measurement 20, 1 (1960), 37\u201346. [10] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey on in-context learning. arXiv preprint arXiv:2301.00234 (2022). [11] Angela Fan, Beliz Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, and Jie M Zhang. 2023. Large language models for software engineering: Survey and open problems. arXiv preprint arXiv:2310.03533 (2023). [12] Michael Fu, Chakkrit Tantithamthavorn, Van Nguyen, and Trung Le. 2023. Chatgpt for vulnerability detection, classification, and repair: How far are we? arXiv preprint arXiv:2310.09810 (2023). [13] Hao Guan, Ying Xiao, Jiaying Li, Yepang Liu, and Guangdong Bai. 2023. A comprehensive study of real-world bugs in machine learning model optimization. In 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE). IEEE, 147\u2013158. [14] Qianyu Guo, Sen Chen, Xiaofei Xie, Lei Ma, Qiang Hu, Hongtao Liu, Yang Liu, Jianjun Zhao, and Xiaohong Li. 2019. An empirical study towards characterizing deep learning development and deployment across different frameworks and platforms. In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 810\u2013822. [15] Nargiz Humbatova, Gunel Jahangirova, Gabriele Bavota, Vincenzo Riccio, Andrea Stocco, and Paolo Tonella. 2020. Taxonomy of real faults in deep learning systems. In Proceedings of the ACM/IEEE 42nd international conference on software engineering. 1110\u20131121. [16] Md Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan. 2019. A comprehensive study on deep learning bug characteristics. In Proceedings of the 2019 27th ACM joint meeting on european software engineering conference and symposium on the foundations of software engineering. 510\u2013520. [17] Matthew Jin, Syed Shahriar, Michele Tufano, Xin Shi, Shuai Lu, Neel Sundaresan, and Alexey Svyatkovskiy. 2023. Inferfix: End-to-end program repair with llms. In Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1646\u20131656. [18] Sungmin Kang, Juyeon Yoon, and Shin Yoo. 2023. Large language models are few-shot testers: Exploring llm-based general bug reproduction. In 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE). IEEE, 2312\u20132323. [19] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. Advances in neural information processing systems 35 (2022), 22199\u201322213. [20] J Richard Landis and Gary G Koch. 1977. The measurement of observer agreement for categorical data. biometrics (1977), 159\u2013174. [21] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33 (2020), 9459\u20139474.\n[22] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. 2023. Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. arXiv preprint arXiv:2305.01210 (2023). [23] Yue Liu, Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn, Li Li, Xuan-Bach D Le, and David Lo. 2023. Refining ChatGPT-generated code: Characterizing and mitigating code quality issues. arXiv preprint arXiv:2307.12596 (2023). [24] Zhe Liu, Chunyang Chen, Junjie Wang, Mengzhuo Chen, Boyu Wu, Xing Che, Dandan Wang, and Qing Wang. 2023. Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash Detection with Large Language Model. arXiv preprint arXiv:2310.15657 (2023). [25] Zhe Liu, Chunyang Chen, Junjie Wang, Mengzhuo Chen, Boyu Wu, Xing Che, Dandan Wang, and Qing Wang. 2024. Make llm a testing expert: Bringing human-like interaction to mobile gui testing via functionality-aware decisions. In Proceedings of the IEEE/ACM 46th International Conference on Software Engineering. 1\u201313. [26] Zhe Liu, Chunyang Chen, Junjie Wang, Mengzhuo Chen, Boyu Wu, Yuekai Huang, Jun Hu, and Qing Wang. 2024. Unblind Text Inputs: Predicting Hint-text of Text Input in Mobile Apps via LLM. In Proceedings of the CHI Conference on Human Factors in Computing Systems. 1\u201320. [27] Yiling Lou, Zhenpeng Chen, Yanbin Cao, Dan Hao, and Lu Zhang. 2020. Understanding build issue resolution in practice: symptoms and fix patterns. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 617\u2013628. [28] Guilong Lu, Xiaolin Ju, Xiang Chen, Wenlong Pei, and Zhilong Cai. 2024. GRACE: Empowering LLM-based software vulnerability detection with graph structure and in-context learning. Journal of Systems and Software 212 (2024), 112031. [29] Christoffer Rosen and Emad Shihab. 2016. What are mobile developers asking about? a large scale study using stack overflow. Empirical Software Engineering 21 (2016), 1192\u20131223. [30] Gian Luca Scoccia, Patrizio Migliarini, and Marco Autili. 2021. Challenges in developing desktop web apps: a study of stack overflow and github. In 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR). IEEE, 271\u2013282. [31] Carolyn B. Seaman. 1999. Qualitative methods in empirical studies of software engineering. IEEE Transactions on software engineering 25, 4 (1999), 557\u2013572. [32] Qingchao Shen, Haoyang Ma, Junjie Chen, Yongqiang Tian, Shing-Chi Cheung, and Xiang Chen. 2021. A comprehensive study of deep learning compiler bugs. In Proceedings of the 29th ACM Joint meeting on european software engineering conference and symposium on the foundations of software engineering. 968\u2013980. [33] Weisong Sun, Chunrong Fang, Yudu You, Yun Miao, Yi Liu, Yuekang Li, Gelei Deng, Shenghan Huang, Yuchen Chen, Quanjun Zhang, et al. 2023. Automatic Code Summarization via ChatGPT: How Far Are We? arXiv preprint arXiv:2305.12865 (2023). [34] Ferdian Thung, Shaowei Wang, David Lo, and Lingxiao Jiang. 2012. An empirical study of bugs in machine learning systems. In 2012 IEEE 23rd International Symposium on Software Reliability Engineering. IEEE, 271\u2013280. [35] Chao Wang, Zhenpeng Chen, and Minghui Zhou. 2023. Automl from software engineering perspective: Landscapes and challenges. In 2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR). IEEE, 39\u201351. [36] Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, and Qing Wang. 2024. Software testing with large language models: Survey, landscape, and vision. IEEE Transactions on Software Engineering (2024). [37] Jun Wang, Guanping Xiao, Shuai Zhang, Huashan Lei, Yepang Liu, and Yulei Sui. 2023. Compatibility Issues in Deep Learning Systems: Problems and Opportunities. In Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 476\u2013488. [38] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems 35 (2022), 24824\u201324837. [39] Jinfeng Wen, Zhenpeng Chen, Yi Liu, Yiling Lou, Yun Ma, Gang Huang, Xin Jin, and Xuanzhe Liu. 2021. An empirical study on challenges of application development in serverless computing. In Proceedings of the 29th ACM joint meeting on European software engineering conference and symposium on the foundations of software engineering. 416\u2013428. [40] Chunqiu Steven Xia and Lingming Zhang. 2023. Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT. arXiv preprint arXiv:2304.00385 (2023). [41] Xin-Li Yang, David Lo, Xin Xia, Zhi-Yuan Wan, and Jian-Ling Sun. 2016. What security questions do developers ask? a large-scale study of stack overflow posts. Journal of Computer Science and Technology 31 (2016), 910\u2013924. [42] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. 2024. Tree of thoughts: Deliberate problem solving with large language models. Advances in Neural Information Processing Systems 36 (2024). [43] Mohamad Yazdaninia, David Lo, and Ashkan Sami. 2021. Characterization and prediction of questions without accepted answers on stack overflow. In 2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC). IEEE,\nACM Trans. Softw. Eng. Methodol., Vol. 1, No. 1, Article . Publication date: August 2023.\n59\u201370. [44] Tianyi Zhang, Cuiyun Gao, Lei Ma, Michael Lyu, and Miryung Kim. 2019. An empirical study of common challenges in developing deep learning applications. In 2019 IEEE 30th International Symposium on Software Reliability Engineering (ISSRE). IEEE, 104\u2013115",
    "paper_type": "survey",
    "attri": {
        "background": {
            "purpose": "This survey aims to investigate the challenges faced by developers working with large language models (LLMs), filling a gap in empirical studies on this topic.",
            "scope": "The survey focuses on the challenges encountered during LLM development, including areas such as prompts, APIs, and plugins. It excludes challenges related to traditional software development practices."
        },
        "problem": {
            "definition": "The survey explores the unique challenges that LLM developers face, which differ from those in traditional software development.",
            "key obstacle": "Primary challenges include automating tasks, dealing with uncertainty in outputs, managing large datasets, ensuring data privacy and security, optimizing performance, and interpreting model outputs."
        },
        "architecture": {
            "perspective": "The survey introduces a taxonomy of challenges faced by LLM developers, categorizing existing research into distinct areas.",
            "fields/stages": "The taxonomy includes six main categories and 27 subcategories, covering aspects like API usage, prompt design, and plugin development."
        },
        "conclusion": {
            "comparisions": "The survey compares various challenges faced by LLM developers with those in traditional software development, highlighting the complexity and specificity of LLM-related issues.",
            "results": "The study concludes that LLM development presents unique challenges that require tailored strategies and resources, emphasizing the need for improved documentation and community support."
        },
        "discussion": {
            "advantage": "Current research has achieved a better understanding of LLM development challenges, leading to improved practices and tools for developers.",
            "limitation": "Existing studies often overlook the evolving nature of LLM technologies and the specific needs of developers, leading to gaps in support and resources.",
            "gaps": "Unanswered questions remain regarding the long-term sustainability of LLM development practices and the effectiveness of current support mechanisms.",
            "future work": "Future research should explore emerging trends in LLM development, enhance community resources, and investigate automated solutions for categorizing challenges."
        },
        "other info": {
            "additional_info": {
                "repository": "The authors have made their collected posts, analysis scripts, and taxonomy available in a GitHub repository for open science.",
                "empirical study": "This study is the first comprehensive analysis of challenges faced by LLM developers, providing valuable insights for stakeholders."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.2",
            "key information": "The survey aims to investigate the challenges faced by developers working with large language models (LLMs), filling a gap in empirical studies on this topic."
        },
        {
            "section number": "2.3",
            "key information": "The taxonomy includes six main categories and 27 subcategories, covering aspects like API usage, prompt design, and plugin development."
        },
        {
            "section number": "4.1",
            "key information": "The survey explores unique challenges that LLM developers face, which differ from those in traditional software development."
        },
        {
            "section number": "10.1",
            "key information": "Primary challenges include automating tasks, dealing with uncertainty in outputs, managing large datasets, ensuring data privacy and security, optimizing performance, and interpreting model outputs."
        },
        {
            "section number": "10.2",
            "key information": "Future research should explore emerging trends in LLM development, enhance community resources, and investigate automated solutions for categorizing challenges."
        }
    ],
    "similarity_score": 0.7293603677803381,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/An Empirical Study on Challenges for LLM Application Developers.json"
}