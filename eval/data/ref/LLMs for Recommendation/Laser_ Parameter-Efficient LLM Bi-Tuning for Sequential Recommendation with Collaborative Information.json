{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2409.01605",
    "title": "Laser: Parameter-Efficient LLM Bi-Tuning for Sequential Recommendation with Collaborative Information",
    "abstract": "Sequential recommender systems are essential for discerning user preferences from historical interactions and facilitating targeted recommendations. Recent innovations employing Large Language Models (LLMs) have advanced the field by encoding item semantics, yet they often necessitate substantial parameter tuning and are resource-demanding. Moreover, these works fails to consider the diverse characteristics of different types of users and thus diminishes the recommendation accuracy. In this paper, we propose a parameter-efficient Large Language Model Bi-Tuning framework for sequential recommendation with collaborative information (Laser). Specifically, Bi-Tuning works by inserting trainable virtual tokens at both the prefix and suffix of the input sequence and freezing the LLM parameters, thus optimizing the LLM for the sequential recommendation. In our Laser, the prefix is utilized to incorporate user-item collaborative information and adapt the LLM to the recommendation task, while the suffix converts the output embeddings of the LLM from the language space to the recommendation space for the follow-up item recommendation. Furthermore, to capture the characteristics of different types of users when integrating the collaborative information via the prefix, we introduce M-Former, a lightweight MoE-based querying transformer that uses a set of query experts to integrate diverse user-specific collaborative information encoded by frozen ID-based sequential recommender systems, significantly improving the accuracy of recommendations. Extensive experiments on real-world datasets demonstrate that Laser can parameter-efficiently adapt LLMs to effective recommender systems, significantly outperforming state-of-the-art methods.",
    "bib_name": "zhang2024laserparameterefficientllmbituning",
    "md_text": "# Laser: Parameter-Efficient LLM Bi-Tuning for Sequential Recommendation with Collaborative Information\nXinyu Zhang xyzhang0105@gmail.com Beijing Institute of Technology Beijing, China Linmei Hu hulinmei@bit.edu.cn Beijing Institute of Technology Beijing, China\nLinmei Hu hulinmei@bit.edu.cn Beijing Institute of Technology Beijing, China Luhao Zhang zhangluhao@bit.edu.cn Beijing Institute of Technology Beijing, China\nHeyan Huang hhy63@bit.edu.cn Beijing Institute of Technology Beijing, China Liqiang Nie nieliqiang@gmail.com Harbin Institute of Technology Shenzhen, China\nDandan Song sdd@bit.edu.cn Beijing Institute of Technology Beijing, China\nAbstract Sequential recommender systems are essential for discerning user preferences from historical interactions and facilitating targeted recommendations. Conventional techniques rely solely on item IDs for sequence modeling, overlooking the wealth of semantic data in item descriptions, which can lead to subpar performance. Recent innovations employing Large Language Models (LLMs) have advanced the field by encoding item semantics, yet they often necessitate substantial parameter tuning and are resource-demanding. Moreover, these works typically integrate ID-based collaborative signals into LLMs via a simple unified linear projection, which fails to consider the diverse characteristics of different types of users and thus diminishes the recommendation accuracy. In this paper, we propose a parameter-efficient Large Language Model Bi-Tuning framework for sequential recommendation with collaborative information (Laser). Specifically, Bi-Tuning works by inserting trainable virtual tokens at both the prefix and suffix of the input sequence and freezing the LLM parameters, thus optimizing the LLM for the sequential recommendation. In our Laser, the prefix is utilized to incorporate user-item collaborative information and adapt the LLM to the recommendation task, while the suffix converts the output embeddings of the LLM from the language space to the recommendation space for the follow-up item recommendation. Furthermore, to capture the characteristics of different types of users when integrating the collaborative information via the prefix, we introduce M-Former, a lightweight MoE-based querying transformer that uses a set of query experts to integrate diverse user-specific collaborative information encoded by frozen ID-based sequential recommender systems, significantly improving the accuracy of recommendations.\narXiv:2409.01605v1\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/18/06 https://doi.org/XXXXXXX.XXXXXXX\nExtensive experiments on real-world datasets demonstrate that Laser can parameter-efficiently adapt LLMs to effective recommender systems, significantly outperforming state-of-the-art methods.\n# CCS Concepts \u2022 Information systems \u2192Recommender systems.\nSequential recommendation, large language model, parameter-efficient fine-tuning, MoE, collaborative information\nACM Reference Format: Xinyu Zhang, Linmei Hu, Luhao Zhang, Dandan Song, Heyan Huang, and Liqiang Nie. 2024. Laser: Parameter-Efficient LLM Bi-Tuning for Sequential Recommendation with Collaborative Information. In Proceedings of Make sure to enter the correct conference title from your rights confirmation emai (Conference acronym \u2019XX). ACM, New York, NY, USA, 11 pages. https://doi.org/XXXXXXX.XXXXXXX\n# 1 Introduction\nSequential recommender systems are designed to learn effective representations of users\u2019 interests based on their past interactions and to suggest future items that match users\u2019 needs. Due to their abilities to capture the dynamic nature of user preferences and their effectiveness in enhancing user satisfaction, sequential recommender systems are widely applied in various scenarios such as e-commerce, streaming services, and social media platforms [7, 11, 27, 54]. In traditional sequential recommender systems, items are predominantly represented by unique IDs. To obtain effective ID embeddings based on the user interaction sequence, a variety of methods are employed, including Markov Chains [9, 32], RNN/CNN models [11, 20, 34, 46], and self-attentive models [16, 22, 33]. While ID-based methods are promising in capturing latent associations between users and items, they fail to consider the rich semantic information contained in the textual descriptions of items (e.g., item title), resulting in suboptimal performance. To solve this issue, efforts have been made to encode item semantic information with language models [12, 21]. However, previous works mainly focus on small or medium-sized language models, which exhibit limited performance.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ad4f/ad4f0f3c-56a0-4348-899a-fe5c4dd82e53.png\" style=\"width: 50%;\"></div>\n# Figure 1: Comparison of existing methods and our proposed Laser.\nRecently, Large Language Models (LLMs) have made significant progress in language understanding [15, 30, 35, 44]. It is a promising way to harness the powerful semantic information modeling capabilities of LLMs pre-trained on extensive text corpora to capture the semantic information of items. As shown in Figure 1, existing works integrate LLMs into recommendation tasks in two main paradigms. The first paradigm is to use LLMs to directly recommend in the form of natural language. These works design special prompts [14, 28, 37] or use supervised fine-tuning [1, 2, 51] to get LLMs to answer the given recommendation questions. However, this paradigm can only determine the recommendation for one item at a time and the frequency of LLM utilization increases linearly with the number of candidate items. Thus, these methods tend to be used only in the reranking phase , which contains only dozens of candidate items [13, 51]. The second paradigm is to use LLMs as encoders to provide item/user embeddings for similarity comparison and next item prediction. As shown in Figure 1, given the user interaction history represented in natural language, these works use LLMs to encode each token in the input text and then perform various pooling strategies on the output token embeddings to derive the user embedding [23, 39, 49]. Although these works are promising, they typically necessitate the training of extensive parameters, demanding considerable computational resources. Furthermore, these works struggle to effectively incorporate ID-based collaborative information into LLMs, which affects the effectiveness of recommendations. Although efforts have been made to use simple linear projections to map the collaborative embeddings into the language space of LLMs [45, 53], these methods fail to consider the diverse characteristics of various types of users, potentially resulting in inferior recommendation results. To address the above issues, in this paper, we propose a parameterefficient Large Language Model Bi-Tuning framework for sequential recommendation (Laser), which also effectively integrates collaborative information by capturing the characteristics of different types of users through an MoE-based querying transformer. In particular, to efficiently adapt LLMs to effective sequential recommender systems that can provide high-quality item/user embeddings, we design a parameter-efficient bidirectional LLM fine-tuning method, named Bi-Tuning. In Bi-Tuning, we freeze LLMs\u2019 parameters and tailor them for recommendation tasks by optimizing the trainable virtual tokens added at the prefix and suffix of the input text, which largely reduces the scale of parameters that require training. The\nprefix tokens can be utilized to incorporate collaborative information and are responsible for adapting LLMs to recommendation tasks, while the appended single suffix token aims to convert the output of LLMs from the language space to the recommendation space for following embedding similarity comparison and next item recommendation. In addition, to effectively incorporate the collaborative information via the prefix for accurate recommendation, we present M-Former, a lightweight MoE (Mixture of Experts) based querying transformer that employs a set of trainable query experts to capture the diverse characteristics of user-specific collaborative information encoded by frozen ID-based sequential recommender systems. Experimental results on real-world datasets across different domains show that our method outperforms state-of-the-art baselines. In summary, our main contributions can be summarized as follows: \u2022 We propose a parameter-efficient Large Language Model BiTuning framework for sequential recommendation, named Laser, which can effectively adapt LLMs to sequential recommender systems in a parameter-efficient way. \u2022 In our Laser, to effectively incorporate the collaborative information into LLMs for more accurate recommendation, we design M-Former, a lightweight MoE-based querying transformer that employs a set of query experts to capture the characteristics of user-specific collaborative information encoded by frozen ID-based sequential recommender systems. \u2022 Extensive experiments on real-world datasets demonstrate that our proposed Laser significantly outperforms state-ofthe-art methods.\n# 2 Problem Formulation\nIn the setting of sequential recommendation, we are given a user set U and an item set I. Each user \ud835\udc62\u2208U is associated with a temporally ordered sequence of his/her historical interacted items, denoted as \ud835\udc46\ud835\udc62= {\ud835\udc561,\ud835\udc562, . . . ,\ud835\udc56\ud835\udc41}, where \ud835\udc41is the length of \ud835\udc46\ud835\udc62and \ud835\udc56\u2208I. Based on \ud835\udc46\ud835\udc62, sequential recommender systems are used to predict the next item \ud835\udc56\ud835\udc41+1 that user \ud835\udc62is most likely to interact with. In traditional ID-based sequential recommender systems, each item \ud835\udc56is associated with a unique item ID \ud835\udc56\ud835\udc51\ud835\udc56, and the ID sequence \ud835\udc3c\ud835\udc37\ud835\udc62= {\ud835\udc56\ud835\udc51\ud835\udc561,\ud835\udc56\ud835\udc51\ud835\udc562, . . . ,\ud835\udc56\ud835\udc51\ud835\udc56\ud835\udc41} is used as input of the model to predict the next item ID \ud835\udc56\ud835\udc51\ud835\udc56\ud835\udc41+1. Differently, in this work, in addition to the item id sequence \ud835\udc3c\ud835\udc37\ud835\udc62, we also utilize the semantic information of items, including the attributes such as title, category, and brand. Formally, the attributes of an item \ud835\udc56can be represented as \ud835\udc37\ud835\udc56= {(\ud835\udc581, \ud835\udc631), (\ud835\udc582, \ud835\udc632), . . . , (\ud835\udc58\ud835\udc40, \ud835\udc63\ud835\udc40)}, where \ud835\udc58is the attribute name (e.g., \u201ctitle\u201d, \u201ccategory\u201d, and \u201cbrand\u201d),\ud835\udc63is the corresponding value and \ud835\udc40is the number of attributes. Given the user interaction sequence \ud835\udc46\ud835\udc62= {\ud835\udc561,\ud835\udc562, . . . ,\ud835\udc56\ud835\udc41}, we use a template to organize the corresponding item attribute sequence \ud835\udc37\ud835\udc62= {\ud835\udc37\ud835\udc561, \ud835\udc37\ud835\udc562, ..., \ud835\udc37\ud835\udc56\ud835\udc41} into a complete and coherent text \ud835\udc47\ud835\udc62= {\ud835\udc611,\ud835\udc612, ...,\ud835\udc61\ud835\udc4a} (detailed in Section 3.1.1), where \ud835\udc4ais the text length. Then, \ud835\udc47\ud835\udc62will be taken as the input of LLMs for next item prediction.\n# 3 Methodology\nIn this section, we detail our proposed Large Language Model BiTuning framework for sequential recommendation, Laser. As illustrated in Figure 2, a parameter-efficient LLM Bi-Tuning method is\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/73bd/73bd39ef-b1e2-4ca2-88df-617ab6bb47d5.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: The overview of our proposed Laser.</div>\npresented to adapt LLMs for the sequential recommendation. Moreover, a lightweight MoE-based querying transformer, M-Former, is designed to effectively integrate collaborative information into LLMs while capturing the characteristics of users of different types with the MoE strategy.\n# 3.1 LLM Bi-Tuning for Sequential Recommendation\nIn the following, we first describe how to organize the user interaction history \ud835\udc37\ud835\udc62= {\ud835\udc37\ud835\udc561, \ud835\udc37\ud835\udc562, ..., \ud835\udc37\ud835\udc56\ud835\udc41} into a coherent text \ud835\udc47\ud835\udc62= {\ud835\udc611,\ud835\udc612, ...,\ud835\udc61\ud835\udc4a}, which is taken as the input of LLMs for the sequential recommendation, and then introduce how to adapt LLMs for the recommendation task by the proposed parameter-efficient BiTuning method.\n3.1.1 Input Text Formulation. In this work, we utilize a unified template to organize the user interaction history \ud835\udc37\ud835\udc62into the input text \ud835\udc47\ud835\udc62of LLMs for recommendation. For example, given the user who has browsed \u201cKaytee Aspen Bedding Bag\u201d, \u201cGuitar A-Frame SupportS\u201d, ..., and \u201cKONG Wubba Dog Toy\u201d, we can formulate the corresponding input text \ud835\udc47\ud835\udc62as follows.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/53bd/53bdeb6f-1257-4607-ba55-98cf6a7b280f.png\" style=\"width: 50%;\"></div>\nYou are an intelligent recommendation assistant. Please summarize the user\u2019s characteristics into a single token based on the browsing history. In chronological order, the user has browsed the following items: >> 1. Kaytee Aspen Bedding Bag (brand: Kaytee, category: Kaytee) >> 2. Guitar A-Frame Support (brand: Sageworks, category: Sageworks) ... >> 4. KONG Wubba Dog Toy (brand: KONG, category: KONG)\nWith the designed template, LLMs can follow the instruction in the input text to summarize the user browsing history into a single token (i.e., the suffix appended to the end of the input text), whose\ncorresponding output embedding can be taken as the user embedding h\ud835\udc62for similarity comparison with the item embeddings and the next item recommendation. To obtain the item embeddings, we also use the above same template. Particularly, for a specific item \ud835\udc56, we treat it as a special user interaction history that contains only this one item. Therefore, we use the same template to formulate the input text of the LLM and take the output appended suffix embedding as the item embedding h\ud835\udc56. In this way, we can obtain the embedding of each item \ud835\udc56in the item set I, and the original user-item similarity comparison used for recommendation can be regarded as a special kind of user-user similarity comparison. The advantage of this is that a unified template could minimize the impact of hard templates on the performance of LLMs [18, 29]. Detailed experiments in Section 4.5.2 further prove the validity of our unified template.\ncorresponding output embedding can be taken as the user embedding h\ud835\udc62for similarity comparison with the item embeddings and the next item recommendation. To obtain the item embeddings, we also use the above same template. Particularly, for a specific item \ud835\udc56, we treat it as a special user interaction history that contains only this one item. Therefore, we use the same template to formulate the input text of the LLM and take the output appended suffix embedding as the item embedding h\ud835\udc56. In this way, we can obtain the embedding of each item \ud835\udc56in the item set I, and the original user-item similarity comparison used for recommendation can be regarded as a special kind of user-user similarity comparison. The advantage of this is that a unified template could minimize the impact of hard templates on the performance of LLMs [18, 29]. Detailed experiments in Section 4.5.2 further prove the validity of our unified template. 3.1.2 Parameter-Efficient Bi-Tuning. Existing works have shown the powerful capabilities of LLMs in bolstering the sequential recommendation [1, 2, 51]. However, they still face two main challenges: (1) how to adapt LLMs for recommendation tasks in a parameterefficient way, and (2) how to effectively transform the output of LLMs from the language space to the recommendation space for the following item recommendation. To solve these two challenges, as shown in Figure 2, we propose a parameter-efficient LLM Bi-Tuning method that adapts LLMs through the trainable prefix and suffix. Formally, given the input text \ud835\udc47\ud835\udc62= {\ud835\udc611,\ud835\udc612, ...,\ud835\udc61\ud835\udc4a}, it will be expanded with the trainable prefix and suffix:\n3.1.2 Parameter-Efficient Bi-Tuning. Existing works have shown the powerful capabilities of LLMs in bolstering the sequential recommendation [1, 2, 51]. However, they still face two main challenges: (1) how to adapt LLMs for recommendation tasks in a parameterefficient way, and (2) how to effectively transform the output of LLMs from the language space to the recommendation space for the following item recommendation. To solve these two challenges, as shown in Figure 2, we propose a parameter-efficient LLM Bi-Tuning method that adapts LLMs through the trainable prefix and suffix. Formally, given the input text \ud835\udc47\ud835\udc62= {\ud835\udc611,\ud835\udc612, ...,\ud835\udc61\ud835\udc4a}, it will be expanded with the trainable prefix and suffix:\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd where \ud835\udc43= {\ud835\udc5d1, \ud835\udc5d2, ..., \ud835\udc5d\ud835\udc3f} refers to the prefix that contains \ud835\udc3fprepende virtual tokens, and \ud835\udc60refers to the suffix that consists of one single appended virtual token. During model training, we freeze the parameters of LLMs and tailor them for the recommendation task by optimizing the trainable virtual tokens added at the prefix \ud835\udc43 and suffix \ud835\udc60, which greatly reduces the size of the parameters to be trained.\nSpecifically, the prefix \ud835\udc43containing \ud835\udc3fvirtual tokens is responsible for adapting LLMs to the recommendation task with collaborative information. As proven by previous works [18, 24], these virtual tokens can serve as placeholders that allow LLMs to capture task-specific information during fine-tuning. In addition, we also use the prefix \ud835\udc43to integrate ID-based collaborative information into LLMs via the proposed M-Former (detailed in Section 3.2), which has proven useful for improving the recommendation results [40, 55]. In addition to the prefix \ud835\udc43, we also append a special trainable virtual token \ud835\udc60to the end of the input text \ud835\udc47\ud835\udc62, which is called the suffix. Previous works [23] have tried to perform average pooling on the token embeddings output by LLMs to obtain the user embedding. However, most generative LLMs are based on the masked attention mechanism, dictating that only the last token can observe the entire input. Therefore, these works may introduce noise by performing average pooling on all output embeddings. In this work, we utilize an appended trainable virtual token \ud835\udc60to capture the information of the entire input \u02dc\ud835\udc47\ud835\udc62, whose output embedding h\ud835\udc60can be taken as the user embedding h\ud835\udc62for similarity comparison and next item prediction. Formally, the encoding process of LLMs can be represented as:\n(2)\nwhere e \u2208R\ud835\udc51represents an input token embedding of the input \u02dc\ud835\udc47\ud835\udc62= {\ud835\udc5d1, ...,\ud835\udc611, ...,\ud835\udc60}, h \u2208R\ud835\udc51represents the corresponding output embedding, and \ud835\udc51represents the hidden size of the LLM. Through the trainable suffix \ud835\udc60, we can effectively convert the output embedding of the LLM from the language space to the recommendation space. When taking the user interaction history or the single item as input of the LLM, we can directly take the output suffix embedding h\ud835\udc60as the user embedding h\ud835\udc62or item embedding h\ud835\udc56for further recommendation.\n3.1.3 Item Recommendation. Given the obtained user embedding h\ud835\udc62\u2208R\ud835\udc51and the item embedding h\ud835\udc56\u2208R\ud835\udc51from the LLM, we can compute the similarity between them as follows:\n(3)\nwhere \ud835\udc60(\ud835\udc62,\ud835\udc56) \u2208R indicates the probability that the item \ud835\udc56will become the next item browsed by user \ud835\udc62. To predict the next item, we iterate through each item \ud835\udc56in the item set I, and select the item \u02c6\ud835\udc56with the highest score as the next item:\n\u02c6\ud835\udc56= argmax\ud835\udc56\u2208I (\ud835\udc60(\ud835\udc62,\ud835\udc56)) .\n(4)\n# 3.2 M-Former based Collaborative Information Integration\nIn the proposed LLM Bi-Tuning, we use the trainable prefix \ud835\udc43and suffix \ud835\udc60to adapt the LLM for recommendation. In order to achieve better recommendation results, we incorporate the collaborative information via the prefix \ud835\udc43. Existing works have tried to use unified linear layers to project the collaborative embeddings encoded by ID-based sequential recommender systems into the language space of LLMs [45, 53]. However, this method is too simple to detect the diverse characteristics of different types of users [25, 48]. To deal\nwith this challenge, we introduce M-Former, an MoE-based querying transformer that employs a set of query experts to deal with different types of users and integrates user-specific collaborative information into the prefix \ud835\udc43. In the following, we first describe the MoE strategy, namely how to select the appropriate query expert based on the collaborative characteristics of a specific user from a set of experts. Then we explain how the selected query expert interacts with the collaborative information encoded by frozen ID-based sequential recommender systems in the querying transformer.\n3.2.1 Mixture of Experts. As shown in Figure 2, there are \ud835\udc3equery experts dealing with users of different types, each of which contains \ud835\udc3ftrainable virtual tokens. In order to select the most appropriate expert to deal with user-specific collaborative information, we set up a router to calculate the scores of different experts given the specific user. Formally, given the user interaction history \ud835\udc46\ud835\udc62= {\ud835\udc561,\ud835\udc562, . . . ,\ud835\udc56\ud835\udc41} of user \ud835\udc62, the corresponding item ID sequence \ud835\udc3c\ud835\udc37\ud835\udc62= {\ud835\udc56\ud835\udc51\ud835\udc561,\ud835\udc56\ud835\udc51\ud835\udc562, . . . ,\ud835\udc56\ud835\udc51\ud835\udc56\ud835\udc41} is taken as input of a pre-trained IDbased sequential recommender system (frozen) and encoded as C\ud835\udc62\u2208R\ud835\udc41\u00d7\ud835\udc51\ud835\udc56, where \ud835\udc41represents the length of the interaction history \ud835\udc46\ud835\udc62and \ud835\udc51\ud835\udc56represents the hidden size of the sequential recommender system. Then, C\ud835\udc62is sent into the router, which is implemented with a fully-connected layer in this work. The matching degree of the \ud835\udc3equery experts according to the \ud835\udc41user-interactive items embedded as C\ud835\udc62can be calculated as:\n(5)\nwhere W\ud835\udc5f\u2208R\ud835\udc3e\u00d7\ud835\udc51\ud835\udc56is the router\u2019s linear weight, and\ud835\udc5a(\ud835\udc62) \u2208R\ud835\udc41\u00d7\ud835\udc3e. Then, he \ud835\udc56-th item\u2019s score for the \ud835\udc57-th expert can be calculated as:\n\ufffd and the final score of the \ud835\udc57-th query expert can be obtained by: \ufffd\n(7)\n\ufffd Finally, the query expert with the highest score will be selected to deal with the specific user \ud835\udc62.\n3.2.2 MoE-based Querying Transformer. As described above, we obtain the most appropriate query expert to handle the specific user\u2019s collaborative information C\ud835\udc62. Afterward, as shown in Figure 2, the selected query expert containing \ud835\udc3fvirtual tokens is sequentially fed into\ud835\udc4dtransformer blocks to interact with the collaborative information C\ud835\udc62. In this way, the query expert integrates the collaborative information into its \ud835\udc3ftrainable virtual tokens, which further act as the aforementioned prefix \ud835\udc43= {\ud835\udc5d1, \ud835\udc5d2, ..., \ud835\udc5d\ud835\udc3f} to adapt LLMs for the sequential recommendation. Formally, the query expert can be represented as E \u2208R\ud835\udc3f\u00d7\ud835\udc51\ud835\udc5a, where \ud835\udc51\ud835\udc5ais the hidden size of the M-Former. In the transformer block, E is first encoded by a self-attention layer and then projected to the query matrix Q used in the cross-attention layer to interact with the key/value matrix (K/V) projected from the ID-based collaborative embeddings C\ud835\udc62. In this way, we update the query expert\u2019s embedding E and integrate ID-based collaborative information into it. Then, through a linear projection layer set up on the top of the \ud835\udc4dtransformer blocks, the query expert is projected into the LLM\u2019s\nhidden size \ud835\udc51and acts as the prefix \ud835\udc43= {\ud835\udc5d1, \ud835\udc5d2, ..., \ud835\udc5d\ud835\udc3f} to adapt the LLM for sequential recommendation with the enhancement of collaborative information.\n# 3.3 Model Learning\nIn this work, we employ a multi-task training strategy to train our Laser, which takes into account both the recommendation goal and the load balancing goal of the MoE experts. Furthermore, we perform a two-stage training by first finding the most appropriate parameter weights to obtain high-quality item embeddings used for user-item similarity comparison, and then further training Laser based on these fixed item embeddings to achieve the best recommendation results.\n# 3.3.1 Loss Function. We propose a multi-task training strategy to jointly train the proposed Laser for LLM-based sequential recommendation.\nThe first training task is the item-item contrastive (IIC) task, which is widely employed for next item prediction. Following previous work [21], we use the ground-truth next item as the positive instance and all other items in the item set I as negative instances. Formally, the item-item contrastive loss is calculated as:\n(8)\n\ufffd \u2208I where the calculation of cos(h\ud835\udc62, h\ud835\udc56) is consistent with Equation (3), h+ \ud835\udc56represents the embedding of the ground-trouth next item, and \ud835\udf0f is a temperature hyper-parameter. The second training task is the load balancing task, which is used to encourage a balanced load across different query experts of the M-Former. As proven by previous works [6, 17], this task can force the router to assign users with diverse collaborative characteristics to different query experts, such that each expert can be trained to obtain the best collaborative information integration effectiveness for its group of users. Formally, the load balancing loss is calculated as: \u2211\ufe01\n(9)\n\u2211\ufe01 where \ud835\udc3eis the number of query experts, \ud835\udc53\ud835\udc57represents the fraction of items dispatched to the \ud835\udc57-th expert that can be calculated as:\n(10)\n\u2211\ufe01 where \ud835\udc41is the number of items in the user interaction history, \ud835\udc5d(\ud835\udc62) \u2208R\ud835\udc41\u00d7\ud835\udc3eis the score matrix obtained through Equation (6), which represents the degree of correlation between the \ud835\udc41items and the \ud835\udc3equery experts. The \ud835\udc43\ud835\udc57in Equation (9) represents the fraction of the router probability allocated for the \ud835\udc57-th expert, which can be calculated as: \u2211\ufe01\n\u2211\ufe01 Totally, the loss function we use in this work is:\n(12)\nL L +\u00b7 L where \ud835\udf06is a hyper-parameter that controls the weight of different tasks.\n  where \ud835\udf06is a hyper-parameter that controls the weight of different tasks.\nTable 1: Statistics of the preprocessed datasets. Avg. n denotes the average number of items in the user interaction history.\nDatasets\n#Users #Items #Inters. Avg. n Density\nScientific\n11,041\n5,327\n76,896\n6.96\n1.3e-3\nArts\n56,210\n22,855\n492,492\n8.76\n3.8e-4\nPet\n47,569\n37,970\n420,662\n8.84\n2.3e-4\n3.3.2 Two-Stage Training. In this work, the recommendation is conducted based on the user-item embedding similarity comparison. Since the item embedding is determined by the corresponding trainable suffix, which changes after different training epochs. We employ a two-stage training strategy to first find the most appropriate parameter weights to obtain high-quality item embeddings, and then further train Laser based on these fixed item embeddings to achieve the best recommendation results. Specifically, in the first training stage, at the beginning of each epoch, the item embeddings are updated as I \u2208R|I|\u00d7\ud835\udc51using the current parameter weights \ud835\udc34. Then, Laser is trained on I and validated at the end of the epoch based on the updated parameter weights \ud835\udc34\u2032. At the end of the first training stage, the embeddings \u02c6I and the corresponding parameter weights \u02c6\ud835\udc34\u2032 of the best-performing epoch are selected for the second training stage. In the second training stage, Laser is initialized with \u02c6\ud835\udc34\u2032 and then trained for multiple epochs to further adapt to the fixed embeddings \u02c6I. Finally, the parameter weights \u02c6\ud835\udc34that yield the optimal validation performance are reserved, and the test results performed on \u02c6\ud835\udc34and \u02c6I represent the final performance of Laser.\n# 4 Experiments\nIn this section, we conduct detailed experiments to demonstrate the effectiveness of our proposed Laser.\n# 4.1 Experimental Setup\n4.1.1 Datasets. To evaluate the effectiveness of our Laser, we conduct experiments on three categories of the Amazon review datasets [31], including \u201cIndustrial and Scientific\u201d, \u201cArts, Crafts and Sewing\u201d, and \u201cPet Supplies\u201d. Following previous works [12, 21], we use the five-core datasets provided by the data source and filter out items with missing titles. Then, we collect the interactions for different users and sort the interactive items by timestamp in ascending order. The statistics of the preprocessed datasets are shown in Table 1. As for the item semantic information modeling, we select the item attributes including title, category, and brand.\n4.1.2 Baselines and Implementation Details. We compare our Laser to a number of state-of-the-art baselines, including six traditional methods (SASRec [16], BERT4Rec [33], RecGURU [19], FDSA [52] ZESRec [5], RECFORMER [21]), and three LLM-based methods (LLM4REC [36], ZESRec [5], LlamaRec [47]). We list the details of these baselines in the Appendix A. Besides, in this paper, the frozen ID-based sequential recommender employed in the Laser is a pre-trained BERT4Rec [33], and the utilized frozen LLM is the ChatGLM2-6B [8]. The other trainable modules are all randomly initialized. The settings of each module and other implementation details are shown in Appendix B.\n<div style=\"text-align: center;\">Table 2: Performance comparison of different methods. The best results are in bold and the second best results are underlined. Improv. indicates the improvement between the best and second best results.</div>\nTraditional Methods\nLLM-based Methods\nDataset\nMetric\nSASRec BERT4Rec RecGURU ZESRec RECFORMER FDSA LLM4REC\nKAR\nLlamaRec\nLaser\nImprov.\nScientific\nRecall@10\n0.1305\n0.1061\n0.0781\n0.1260\n0.1114\n0.0967\n0.1257\n0.1265\n0.1275\n0.1396\n6.97%\nNDCG@10\n0.0797\n0.0790\n0.0575\n0.0843\n0.0722\n0.0716\n0.0764\n0.0894\n0.0857\n0.0970\n8.54%\nMRR\n0.0696\n0.0759\n0.0566\n0.0745\n0.0650\n0.0692\n0.0683\n0.0813\n0.0793\n0.0893\n9.81%\nPet\nRecall@10\n0.0881\n0.0765\n0.0415\n0.1018\n0.0905\n0.0949\n0.0918\n0.0942\n0.0961\n0.1134\n11.37%\nNDCG@10\n0.0569\n0.0602\n0.0366\n0.0754\n0.0793\n0.0673\n0.0769\n0.0724\n0.0754\n0.0898\n13.27%\nMRR\n0.0507\n0.0585\n0.0371\n0.0706\n0.0774\n0.0650\n0.0681\n0.0677\n0.0711\n0.0856\n10.63%\nArts\nRecall@10\n0.1342\n0.1236\n0.0742\n0.1349\n0.1298\n0.1209\n0.1266\n0.1357\n0.1368\n0.1489\n8.91%\nNDCG@10\n0.0848\n0.0942\n0.0525\n0.0970\n0.1024\n0.0994\n0.0927\n0.0917\n0.0860\n0.1138\n11.17%\nMRR\n0.0742\n0.0899\n0.0488\n0.0870\n0.0980\n0.0941\n0.0880\n0.0818\n0.0794\n0.1095\n11.80%\nTable 3: Parameter scale comparison of different LLM tuning methods.\nMethod\nBackbone\nTuning\nTrainable\nMethod\nParameters\nLLM4REC\nGPT2-Large\nFull Fine-Tuning\n787.3M\nKAR\nChatGPT\n/\n/\nLlamaRec\nLlama2-7B\nQLoRA\n4.194M\nLaser\nChatGLM2-6B\nBi-Tuning\n0.135M\n4.1.3 Evaluation Settings. Following previous works [21, 36, 47], we employ three popular metrics, including Recall@N, NDCG@N and MRR, where N is set to 10. For data splitting, we adopt the leaveone-out [16] strategy, where the most recent item in the interaction history is used for testing, the second most recent item is used for validation, and the remaining items are used for training. We treat all items in the item set as candidate items and report the average results on the test data.\n# 4.2 Overall Performance\nAs shown in Table 2, we compare our proposed Laser to nine stateof-the-art baselines across three Amazon datasets. From the experimental results, we can obtain following observations. First, compared to the other outstanding sequential recommendation methods, our Laser results in significant improvements on all metrics across all datasets. For example, on the Pet dataset, compared to the second best method, our Laser improves Recall@10, NDCG@10, and MRR by around 11.37%, 13.27%, and 10.63%, respectively. This demonstrates that our proposed framework can successively adapt LLMs to effective sequential recommender systems. We believe that our Laser benefits from the Bi-Tuning method that effectively adapts LLMs for sequential recommendation with collaborative information. In addition, when integrating the collaborative information, the designed M-Former (MoE-based querying transformer) captures the diverse characteristics of different types of users for more accurate recommendation. Second, compared to the traditional methods, the three LLMbased baselines do not always yield better results. A possible reason is that LLMs have not been pre-trained on large amounts of recommendation data, resulting in lacking the task-specific knowledge\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1ef7/1ef75e63-71c0-41b5-8807-c9cffab1ab60.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3: Performance comparison under the zero-shot and low-resource settings on the Scientific dataset.</div>\n[1, 2]. This further illustrates the importance of exploring more appropriate methods to adapt LLMs to recommendation tasks more effectively. In contrast, our Laser significantly outperforms all traditional methods on all metrics across all datasets. For example, on the Scientific dataset, compared to the best traditional method, our Laser improves Recall@10, NDCG@10, and MRR by 6.97%, 15.07%, and 17.65%, respectively, demonstrating the validity of our method and hopefully inspiring future LLM-based recommendation works. Additionally, we compare the parameter scale of different LLM tuning methods in Table 3. We can observe that our proposed BiTuning is more parameter-efficient, which contains only 0.135M trainable parameters. The results indicate that Laser can greatly reduce the scale of trainable parameters and achieve effective LLM adaptation with the proposed Bi-Tuning method, outperforming SOTA baselines. Note that in Table 3 we only list the trainable parameter scales of different LLM tuning methods. The total number of Laser\u2019s trainable parameters is about 183.3M, which is also significantly less than 3% of the parameter number of the LLM backbone, ChatGLM2-6B.\n# 4.3 Zero-Shot and Low-Resource Performance\nTo further demonstrate the effectiveness of our Laser, we perform experiments to examine its performance in the zero-shot and lowresource scenarios. Specifically, we compare Laser (which uses both the item semantic information and the ID-based collaborative information) with two other types of baselines, including BERT4Rec\n<div style=\"text-align: center;\">Table 4: Results of the ablation study. The best results are in bold and the second best results are underlined.</div>\nScientific\nPet\nVariants\nRecall@10 NDCG@10\nMRR\nRecall@10 NDCG@10\nMRR\nLaser\n0.1396\n0.0970\n0.0893\n0.1134\n0.0898\n0.0856\nw/o MoE\n0.1261\n0.0889\n0.0795\n0.1056\n0.0818\n0.0763\nw/o M-Former\n0.1245\n0.0844\n0.0739\n0.1049\n0.0775\n0.0721\nw/o prefix\n0.1128\n0.0705\n0.0619\n0.0878\n0.0695\n0.0607\nw/o training stage 1\n0.0784\n0.0544\n0.0509\n0.0514\n0.0443\n0.0398\nw/o training stage 2\n0.1316\n0.0894\n0.0781\n0.1083\n0.0837\n0.0793\nTable 5: Performance comparison of different item/user embedding generation strategies on the Scientific dataset. The best results are in bold and the second best results are underlined.\nStrategies\nRecall@10 NDCG@10\nMRR\nw/ suffix\n0.1396\n0.0970\n0.0893\nw/ average pooling\n0.0551\n0.0416\n0.0401\nw/ [EOS]\n0.0948\n0.0688\n0.0646\n(which uses only the ID-based collaborative information) and RECFORMER (which uses only the item semantic information). We first pre-train these methods (in addition to the ID-based BERT4Rec) on the Pet dataset, and then test whether they can perform well on another domain with no/limited training data. Figure 3 shows the experimental results on the Scientific dataset. From Figure 3, we can observe that: (1) Laser performs best in the zero-shot scenario. Compared to other baselines, Laser achieves significantly better performance (Recall@10 reaches 0.97, NDCG@10 reaches 0.58), even though it has not seen any items on the Scientific dataset. We attribute this superior performance to the design of our Bi-Tuning framework, which fully leverages the generalization capabilities of LLMs and effectively adapts LLMs for sequential recommendation. (2) Laser only needs to use 5% of the training data to exceed the effect of the other two baselines using 100% of the training data. Compared to the other two baselines, Laser\u2019s performance can quickly rise to a very appreciable level as the ratio of training data increases to 5%. This means that we only need a very small amount of training data and training time to migrate the Laser trained on one domain to another unseen domain, accompanied by better results than other baselines that need far more training data. This demonstrates that our proposed framework can effectively transform LLMs into generalizable sequential recommender systems.\n# 4.4 Ablation Study\nTo demonstrate the effectiveness of each module in our Laser, we conduct ablation studies and provide the results in Table 4. We can observe that: (1) The experimental results on the two datasets remain identical. The removal of any module results in a significant decrease in Laser\u2019s performance. (2) Without MoE, Recall@10, NDCG@10, and MRR respectively decrease on average by 8.28%, 8.63%, and 10.92%, showing that the introduction of MoE can help our framework to deal with the diverse collaborative characteristics\nTable 6: Performance comparison under different hard prompt templates on the Scientific dataset. The best results are in bold and the second best results are underlined.\nTemplates\nRecall@10 NDCG@10\nMRR\noriginal\n0.1396\n0.0970\n0.0893\nw/o specified phrase\n0.1042\n0.0814\n0.0782\nw/o instruction\n0.0985\n0.0747\n0.0652\nw/ two instructions\n0.0972\n0.0635\n0.0567\nof different types of users, which leads to higher-quality recommendation results. Furthermore, without the M-Former, the three metrics decrease on average by 9.15%, 13.35%, and 16.51%, respectively. This demonstrates the importance of using ID-based collaborative information for more accurate recommendations, and that our M-Former can effectively integrate collaborative information into LLMs. (3) Without the prefix, Recall@10, NDCG@10, and MRR decrease significantly on average by 20.89%, 24.97%, and 25.39%, respectively, demonstrating the important role of the prefix in adapting LLMs to the recommendation task. (4) Removing any training stage, the effectiveness of the Laser is reduced. Specifically, without the first training stage, Recall@10, NDCG@10, and MRR respectively decline on average by 49.24%, 47.29%, and 48.28%, demonstrating the need to find appropriate parameter weights to obtain the high-quality item embeddings. Besides, without the second training stage, the metrics also decrease by 9.13%, 7.28%, and 9.96%, respectively. This suggests that after obtaining appropriate item embeddings, it\u2019s also necessary to continue training to make Laser better adapt to the fixed item embeddings and achieve the best recommendation results.\n# 4.5 Further Discussion In this section, we provide further discussion about our proposed Laser.\n4.5 Further Discussion In this section, we provide further discussion about our proposed Laser.\n4.5.1 Suffix. We compare the usage of the suffix to two other strategies for generating user/item embeddings, including performing average pooling on all token embeddings output by LLMs and replacing the trainable virtual suffix with a hard token [EOS] which will not be trained. As shown in table 5, compared to the other two strategies, our designed suffix can effectively improve Recall@10, NDCG@10, and MRR by at least 32.07%, 29.04%, and 27.67%, respectively. This proves that a trainable virtual suffix can more effectively convert the LLM output from the language space to the recommendation space, thus generating higher-quality user/item embeddings.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/28f4/28f4aced-bd99-4a71-9ae0-ed08dd303a16.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Performance comparison with different ID-based sequential recommender systems.</div>\n4.5.2 Input Text Template. In this work, we utilize a unified template to organize both the user interaction history and the single item, which is shown in Section 3.1.1. The template instructs LLMs to summarize the semantic information into the suffix, which is further used for recommendation. To ensure the template\u2019s plausibility, we compared it with three other variants, including: (1) deleting the specified instruction phrase \u201cinto a single token\u201d, (2) deleting the entire instruction \u201cYou are an intelligent ... the user has browsed the following items:\u201d, (3) using a different instruction for item embedding generation, \u201cYou are an intelligent recommendation assistant. Please summarize the item characteristics into a single token:\u201d. As shown in Table 6, compared to the other three variants, our prompt template can significantly improve Recall@10, NDCG@10, and MRR by at least 25.36%, 16.05%, and 12.36%, respectively. This demonstrates the effectiveness of our prompt template in harnessing the powerful capabilities of LLMs with clear, consistent, and appropriate instruction.\n4.5.3 ID-based Sequential Recommender. We perform further experiments to study the effect of the ID-based sequential recommender system on the performance of our Laser. As shown in Figure 4, on all datasets, the performance of Laser increases almost linearly with the performance of the employed ID-based sequential recommender system. For example, on the Pet dataset, Laser based on BERT4Rec outperforms Laser based on SASRec by 17.30%, while BERT4Rec outperforms SASRec by 15.38%. This suggests that our Laser can be further improved by using more powerful ID-based sequential recommender systems.\n4.5.4 Parameter Analysis. Furthermore, we perform a detailed parameter analysis to explore the effect of the query expert number \ud835\udc3e and the expert\u2019s virtual token number \ud835\udc3fon the Laser\u2019s performance. As shown in Table 7, smaller values of \ud835\udc3eand \ud835\udc3fcause the M-Former to be insufficient to effectively handle the diverse characteristics of different types of users, while too large values increase the difficulty of training, thus decreasing the effectiveness of Laser. Finally, we respectively set \ud835\udc3eand \ud835\udc3fto 8 and 32 to get the best results.\n# 5 Related Work\n# 5 Related Work 5.1 Sequential Recommendation\n# 5.1 Sequential Recommendation\nSequential recommendation aims to infer users\u2019 preferences based on their past interactions ordered by timestamps. In traditional sequential recommender systems, items are represented by unique IDs. To effectively capture users\u2019 historical interactions and make recommendations based on these IDs, a variety of methods have\nTable 7: The comparison under different \ud835\udc3eand \ud835\udc3fvalues on the validation set of the Scientific dataset. The best results are in bold and the second best results are underlined.\n<div style=\"text-align: center;\">K L Recall@10 NDCG@10 MRR</div>\nK\nL\nRecall@10 NDCG@10\nMRR\n8\n32\n0.1661\n0.1199\n0.1112\n4\n32\n0.1545\n0.1090\n0.0992\n12 32\n0.1560\n0.1138\n0.1054\n8\n16\n0.1487\n0.1099\n0.1032\n8\n48\n0.0975\n0.0692\n0.0644\nbeen employed, including CNNs, RNNs, and GNNs. For example, Caser [34] views the embedding matrix of previous items as an \"image\" and applies convolutional operations to capture user preferences. GRU4Rec [4] introduces GRU [4] to model user sequential patterns. SRGNN [42], GCE-GNN [38], and SURGE [3] are proposed to capture long-term sequential user preferences through multi-layer message passing. Besides, self-attention-based models have also been widely adopted for sequential recommendation [16, 22, 33]. Although these ID-based methods achieve promising performance, they fail to consider the semantic information of item descriptions, resulting in suboptimal performance. Recently, researchers have attempted to create transferable item representations by encoding item descriptions with language models [12, 21]. However, these works primarily focus on small or medium-sized language models.\n# 5.2 LLMs in Recommender Systems\nLarge Language Models (LLMs) have demonstrated remarkable performance in various domains, prompting researchers to explore their potential in recommendation tasks. Existing works integrate LLMs into recommendations in two main paradigms. The first paradigm is to use LLMs to answer specific recommendation questions by in-context learning [10, 13, 28, 50] or supervised fine-tuning [1, 2, 26, 41, 51], which focuses only on the reranking phase. The second paradigm is to use LLMs as encoders to generate item/user embeddings. For example, Li et al. [23] and Wu et al. [39] attempted to get item/user embeddings by performing pooling on the token embeddings encoded by LLMs. Zhang et al. [49] compressed the textual information into a single special token and learned its embedding using a contrastive learning approach. Although these works show promise, they often require training a large number of parameters to bridge the huge gap between recommendation and language generation tasks, which is resource-demanding. Additionally, these works typically integrate ID-based collaborative signals into LLMs via simple unified linear projections [45, 53], which fails to consider the diverse characteristics of different types of users and thus diminishes recommendation accuracy. In this paper, we propose a parameter-efficient LLM Bi-Tuning framework for sequential recommendation. Besides, to improve the recommendation performance, we introduce a lightweight M-Former to effectively integrate ID-based collaborative information into the LLM.\n# 6 Conclusion\nIn this paper, we propose Laser, a parameter-efficient LLM BiTuning framework for sequential recommendation with collaborative information. Specifically, we present Bi-Tuning, a parameterefficient fine-tuning method that adapts LLMs to sequential recommendation through the trainable prefix and suffix. The prefix adapts LLMs to the recommendation task with collaborative information, while the suffix converts LLM output from the language space to the recommendation space and obtains high-quality user/item embeddings. To effectively integrate ID-based collaborative information for more accurate recommendation, we introduce M-Former, a lightweight MoE-based querying transformer that uses a set of query experts to capture the diverse collaborative characteristics of different types of users. Finally, a multi-task loss function and a two-stage training strategy are employed to train Laser for the sequential recommendation. Extensive experiments on real-world datasets demonstrate that Laser can parameter-efficiently adapt LLMs to effective recommender systems, significantly outperforming state-of-the-art methods.\n# References\n[1] Keqin Bao, Jizhi Zhang, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng Luo, and et al. 2023. A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems. (2023). arXiv:2308.08434 [2] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems. 1007\u20131014. [3] Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, and et al. 2021. Sequential Recommendation with Graph Neural Networks. In SIGIR \u201921: The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 378\u2013387. [4] Junyoung Chung, \u00c7aglar G\u00fcl\u00e7ehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. (2014). arXiv:1412.3555 [5] Hao Ding, Yifei Ma, Anoop Deoras, Yuyang Wang, and Hao Wang. 2021. ZeroShot Recommender Systems. (2021). arXiv:2105.08318 [6] William Fedus, Barret Zoph, and Noam Shazeer. 2022. Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity. J. Mach. Learn. Res. (2022), 120:1\u2013120:39. [7] Ehsan Gholami, Mohammad Motamedi, and Ashwin Aravindakshan. 2022. PARSRec: Explainable Personalized Attention-fused Recurrent Sequential Recommendation Using Session Partial Actions. In KDD \u201922: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 454\u2013464. [8] Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, and et al. 2024. ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools. arXiv:2406.12793 [9] Ruining He and Julian J. McAuley. 2016. Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation. In IEEE 16th International Conference on Data Mining (ICDM) (2016). [10] Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck, Dawen Liang, Yesu Feng, and et al. 2023. Large Language Models as Zero-Shot Conversational Recommenders. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management. 720\u2013730. [11] Bal\u00e1zs Hidasi, Alex, ros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based Recommendations with Recurrent Neural Networks. In 4th International Conference on Learning Representations. [12] Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong Wen. 2022. Towards Universal Sequence Representation Learning for Recommender Systems. In KDD \u201922: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 585\u2013593. [13] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian J. McAuley, and et al. 2024. Large Language Models are Zero-Shot Rankers for Recommender Systems. In Advances in Information Retrieval - 46th European Conference on Information Retrieval. 364\u2013381. [14] Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie. 2023. Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations. (2023). arXiv:2308.16505 [15] Ting Jiang, Shaohan Huang, Zhongzhi Luan, Deqing Wang, and Fuzhen Zhuang. 2023. Scaling Sentence Embeddings with Large Language Models. (2023). arXiv:2307.16645 [16] Wang-Cheng Kang and Julian J. McAuley. 2018. Self-Attentive Sequential Recommendation. In IEEE International Conference on Data Mining. 197\u2013206. [17] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, and et al. 2021. GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding. In 9th International Conference on Learning Representations. [18] Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The Power of Scale for Parameter-Efficient Prompt Tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 3045\u20133059. [19] Chenglin Li, Mingjun Zhao, Huanming Zhang, Chenyun Yu, Lei Cheng, Guoqiang Shu, and et al. 2022. RecGURU: Adversarial Learning of Generalized User Representations for Cross-Domain Recommendation. In WSDM \u201922: The Fifteenth ACM International Conference on Web Search and Data Mining. 571\u2013581. [20] Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural Attentive Session-based Recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. 1419\u20131428. [21] Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and et al. 2023. Text Is All You Need: Learning Language Representations for Sequential Recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 1258\u20131267. [22] Jiacheng Li, Yujie Wang, and Julian J. McAuley. 2020. Time Interval Aware SelfAttention for Sequential Recommendation. In WSDM \u201920: The Thirteenth ACM International Conference on Web Search and Data Mining. 322\u2013330. [23] Ruyu Li, Wenhao Deng, Yu Cheng, Zheng Yuan, Jiaqi Zhang, and Fajie Yuan. 2023. Exploring the Upper Limits of Text-Based Collaborative Filtering Using Large Language Models: Discoveries and Insights. (2023). arXiv:2305.11700\n[24] Xiang Lisa Li and Percy Liang. 2021. Prefix-Tuning: Optimizing Continuous Prompts for Generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. 4582\u20134597. [25] Yunqi Li, Hanxiong Chen, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2021. User-oriented Fairness in Recommendation. In WWW \u201921: The Web Conference 2021. 624\u2013632. [26] Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, and et al. 2024. ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation. In Proceedings of the ACM on Web Conference 2024. 3497\u20133508. [27] Chong Liu, Xiaoyang Liu, Rongqin Zheng, Lixin Zhang, Xiaobo Liang, Juntao Li, and et al. 2023. CT4Rec: Simple yet Effective Consistency Training for Sequential Recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 3901\u20133913. [28] Junling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan Zhang. 2023. Is ChatGPT a Good Recommender? A Preliminary Study. (2023). arXiv:2304.10149 [29] Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Tam, Zhengxiao Du, Zhilin Yang, and et al. 2022. P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 61\u201368. [30] Yuanjie Lyu, Zhiyu Li, Simin Niu, Feiyu Xiong, Bo Tang, Wenjin Wang, and et al. 2024. CRUD-RAG: A Comprehensive Chinese Benchmark for RetrievalAugmented Generation of Large Language Models. (2024). arXiv:2401.17043 [31] Jianmo Ni, Jiacheng Li, and Julian J. McAuley. 2019. Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. 188\u2013197. [32] Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing personalized Markov chains for next-basket recommendation. In Proceedings of the 19th International Conference on World Wide Web. 811\u2013820. [33] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and et al. 2019. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 1441\u20131450. [34] Jiaxi Tang and Ke Wang. 2018. Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 565\u2013573. [35] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, and et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. (2023). arXiv:2307.09288 [36] Xinyuan Wang, Liang Wu, Liangjie Hong, Hao Liu, and Yanjie Fu. 2024. LLMEnhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations. (2024). arXiv:2402.09617 [37] Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, and et al. 2023. RecMind: Large Language Model Powered Agent For Recommendation. (2023). arXiv:2308.14296 [38] Ziyang Wang, Wei Wei, Gao Cong, Xiao-Li Li, Xianling Mao, and Minghui Qiu. 2020. Global Context Enhanced Graph Neural Networks for Session-based Recommendation. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval. 169\u2013178. [39] Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2021. Empowering News Recommendation with Pre-trained Language Models. In SIGIR \u201921: The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 1652\u20131656. [40] Junda Wu, Cheng-Chun Chang, Tong Yu, Zhankui He, Jianing Wang, Yupeng Hou, and et al. 2024. CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation. (2024). arXiv:2403.06447 [41] Likang Wu, Zhaopeng Qiu, Zhi Zheng, Hengshu Zhu, and Enhong Chen. 2024. Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations. In Thirty-Eighth AAAI Conference on Artificial Intelligence. 9178\u20139186. [42] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-Based Recommendation with Graph Neural Networks. In The Thirty-Third AAAI Conference on Artificial Intelligence. 346\u2013353. [43] Yunjia Xi, Weiwen Liu, Jianghao Lin, Jieming Zhu, Bo Chen, Ruiming Tang, and et al. 2023. Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models. (2023). arXiv:2306.10933 [44] Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu, Xiangyu Zhao, and et al. 2023. Large Language Models for Generative Information Extraction: A Survey. (2023). arXiv:2312.17617 [45] Zhengyi Yang, Jiancan Wu, Yanchen Luo, Jizhi Zhang, Yancheng Yuan, An Zhang, and et al. 2023. Large Language Model Can Interpret Latent Space of Sequential Recommender. (2023). arXiv:2310.20487 [46] Fajie Yuan, Alex, ros Karatzoglou, Ioannis Arapakis, Joemon M. Jose, and Xiangnan He. 2019. A Simple Convolutional Generative Network for Next Item Recommendation. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining. 582\u2013590.\n[47] Zhenrui Yue, Sara Rabhi, Gabriel de Souza Pereira Moreira, Dong Wang, and Even Oldridge. 2023. LlamaRec: Two-Stage Recommendation using Large Language Models for Ranking. (2023). arXiv:2311.02089 [48] Shuxun Zan, Yujie Zhang, Xiangwu Meng, Pengtao Lv, and Yulu Du. 2021. UDA: A user-difference attention for group recommendation. Inf. Sci. (2021), 401\u2013417. [49] Chao Zhang, Shiwei Wu, Haoxin Zhang, Tong Xu, Yan Gao, Yao Hu, and et al. 2024. NoteLLM: A Retrievable Large Language Model for Note Recommendation. (2024). arXiv:2403.01744 [50] Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems. 993\u2013999. [51] Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach. (2023). arXiv:2305.07001 [52] Tingting Zhang, Pengpeng Zhao, Yanchi Liu, Victor S. Sheng, Jiajie Xu, Deqing Wang, and et al. 2019. Feature-level Deeper Self-Attention Network for Sequential Recommendation. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence. 4320\u20134326. [53] Yang Zhang, Fuli Feng, Jizhi Zhang, Keqin Bao, Qifan Wang, and Xiangnan He. 2023. CoLLM: Integrating Collaborative Embeddings into Large Language Models for Recommendation. (2023). arXiv:2310.19488 [54] Yipeng Zhang, Xin Wang, Hong Chen, and Wenwu Zhu. 2023. Adaptive Disentangled Transformer for Sequential Recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 3434\u20133445. [55] Yaochen Zhu, Liang Wu, Qi Guo, Liangjie Hong, and Jundong Li. 2024. Collaborative Large Language Model for Recommender Systems. In Proceedings of the ACM on Web Conference 2024. 3162\u20133172.\n# A Baselines\ncomprehensively evaluate the performance of our proposed er, we compare it to state-of-the-art baselines, including six ditional methods and three LLM-based methods. 1) Traditional Baselines: \u2022 SASRec [16] employs a self-attention mechanism to capture the semantic relevance between the user interaction sequence and the candidate items. \u2022 BERT4Rec [33] is a bidirectional self-attentive model, employing the cloze objective to model users\u2019 dynamic preferences from their historical behaviors. \u2022 RecGURU [19] introduces an adversarial learning method to incorporate user information across domains and obtain generalized user representations for sequential recommendation. \u2022 FDSA [52] proposes a feature-level self-attention network that integrates different heterogeneous features of items into feature sequences with different weights through a vanilla attention mechanism. \u2022 ZESRec [5] utilizes a pre-trained language model to convert item descriptions into feature representations. \u2022 RECFORMER [21] formulates items as key-value attribute pairs and utilizes pre-trained language models to encode them for ID-free sequential recommendation. 2) LLM-based Baselines: \u2022 LLM4REC [36] proposes a graph knowledge guided attentive LLM recommendation backbone to inject graph edge information into LLMs. \u2022 KAR [43] proposes a hybrid-expert adapter that condenses LLM-generated world knowledge into augmented vectors to enhance the performance of recommendation models. \u2022 LlamaRec [47] adopts a verbalizer-based approach that transforms LLM output logits into probability distributions over the candidate items.\n# (2) LLM-based Baselines:\n# B Implementation Details\nIn this work, we employ a pre-trained BERT4Rec [33] as the frozen ID-based sequential recommender system to encode the user interaction ID sequences. The hyper-parameter settings keep the same as in the original paper, where the number of transformer blocks, the number of attention heads, and the dimension of each attention head are set to 2, 2, and 32, respectively. The frozen LLM we use is the ChatGLM2-6B [8], an impressive open-source large language model with exceptional language modeling capabilities. This model consists of 28 transformer blocks. The hidden size is set to 4096 and the number of attention heads is set to 32. In the feed-forward networks, the dimension of the intermediate layer is set to 13,696. Besides, the model vocabulary consists of 65,024 unique tokens. As for the M-Former, it contains 12 transformer blocks, with alternate blocks conducting cross-attention between the collaborative embeddings and the virtual query expert tokens. The hidden\nsize and the number of attention heads are set to 768 and 12, respectively. The expert number \ud835\udc3e, query token number \ud835\udc3f, and the hidden size of the virtual tokens are set to 8, 32, and 768, respectively. Besides, the router and the projection layer are all implemented by single fully-connected layers, whose input/output dimensions are set to 64/8 and 768/4096, respectively. During the training process, the BERT4Rec and the ChatGLM2 are frozen. We randomly initialize the other trainable modules and train them for two stages (as described in Section 3.3.2). Specifically, we set the batch size to 4 and the learning rate to 1e-4. The loss weight hyper-parameter \ud835\udf06is set to 0.01, and the loss temperature hyper-parameter \ud835\udf0fis set to 0.05. We use the Adam optimizer and train Laser for 15/5 epochs in the first/second training stage, respectively.\nReceived 20 February 2007; revised 12 March 2009; accepted 5 June 2009\n",
    "paper_type": "method",
    "attri": {
        "background": "Sequential recommender systems are essential for discerning user preferences from historical interactions and facilitating targeted recommendations. Conventional techniques rely solely on item IDs for sequence modeling, overlooking the wealth of semantic data in item descriptions, which can lead to subpar performance. Recent innovations employing Large Language Models (LLMs) have advanced the field by encoding item semantics, yet they often necessitate substantial parameter tuning and are resource-demanding.",
        "problem": {
            "definition": "The problem addressed in this paper is the inefficiency of existing sequential recommendation methods that fail to effectively incorporate both item IDs and the rich semantic information from item descriptions, leading to inadequate recommendation performance.",
            "key obstacle": "The primary challenge is that existing methods often integrate ID-based collaborative signals into LLMs via simple linear projections, which do not account for the diverse characteristics of different types of users, thereby diminishing recommendation accuracy."
        },
        "idea": {
            "intuition": "The idea is inspired by the observation that incorporating semantic information along with collaborative user data can significantly enhance the accuracy of recommendations.",
            "opinion": "The proposed method, Laser, utilizes a parameter-efficient framework that integrates collaborative information through a lightweight querying transformer, enabling LLMs to adapt to sequential recommendation tasks effectively.",
            "innovation": "The key innovation of Laser lies in its Bi-Tuning approach, which allows for parameter-efficient adaptation of LLMs by using trainable virtual tokens at both the prefix and suffix of the input sequence, thus optimizing the LLM for the recommendation task."
        },
        "method": {
            "method name": "Laser",
            "method abbreviation": "Laser",
            "method definition": "Laser is a parameter-efficient Large Language Model Bi-Tuning framework that adapts LLMs for sequential recommendation by integrating collaborative information and transforming LLM outputs into a recommendation space.",
            "method description": "Laser employs a Bi-Tuning approach that utilizes trainable virtual tokens to effectively tailor LLMs for the sequential recommendation task.",
            "method steps": [
                "Organize user interaction history into a coherent text template for input into the LLM.",
                "Insert trainable virtual tokens at the prefix to incorporate collaborative information.",
                "Append a trainable virtual token at the suffix to convert LLM outputs from the language space to the recommendation space.",
                "Utilize the M-Former to capture diverse user-specific collaborative information."
            ],
            "principle": "The effectiveness of Laser in solving the problem stems from its ability to leverage both semantic and collaborative information through a structured Bi-Tuning process, which enhances the LLM's capacity to generate accurate user/item embeddings."
        },
        "experiments": {
            "evaluation setting": "Extensive experiments were conducted on real-world datasets, including 'Industrial and Scientific', 'Arts, Crafts and Sewing', and 'Pet Supplies', comparing Laser against various state-of-the-art methods.",
            "evaluation method": "The performance of Laser was assessed using metrics such as Recall@10, NDCG@10, and MRR, employing a leave-one-out strategy for data splitting."
        },
        "conclusion": "The experimental results demonstrate that Laser can parameter-efficiently adapt LLMs to effective recommender systems, significantly outperforming state-of-the-art methods across multiple datasets.",
        "discussion": {
            "advantage": "Laser's main advantage lies in its parameter efficiency, allowing it to achieve high performance with significantly fewer trainable parameters compared to traditional LLM fine-tuning approaches.",
            "limitation": "A limitation of Laser is that it still relies on the performance of the underlying ID-based sequential recommender system, which could affect its overall effectiveness.",
            "future work": "Future research could focus on enhancing the integration of collaborative signals and exploring more advanced architectures to further improve recommendation accuracy."
        },
        "other info": {
            "dataset": "Real-world datasets from Amazon review categories including 'Industrial and Scientific', 'Arts', and 'Pet Supplies'.",
            "baseline methods": [
                "SASRec",
                "BERT4Rec",
                "RecGURU",
                "FDSA",
                "ZESRec",
                "RECFORMER",
                "LLM4REC",
                "LlamaRec"
            ],
            "parameter efficiency": "Laser contains only 0.135M trainable parameters, significantly less than other LLM tuning methods."
        }
    },
    "mount_outline": [
        {
            "section number": "3.3",
            "key information": "The proposed method, Laser, utilizes a parameter-efficient framework that integrates collaborative information through a lightweight querying transformer, enabling LLMs to adapt to sequential recommendation tasks effectively."
        },
        {
            "section number": "4.2",
            "key information": "Laser is a parameter-efficient Large Language Model Bi-Tuning framework that adapts LLMs for sequential recommendation by integrating collaborative information and transforming LLM outputs into a recommendation space."
        },
        {
            "section number": "5.1",
            "key information": "The idea is inspired by the observation that incorporating semantic information along with collaborative user data can significantly enhance the accuracy of recommendations."
        },
        {
            "section number": "10.1",
            "key information": "The primary challenge is that existing methods often integrate ID-based collaborative signals into LLMs via simple linear projections, which do not account for the diverse characteristics of different types of users, thereby diminishing recommendation accuracy."
        },
        {
            "section number": "10.2",
            "key information": "Future research could focus on enhancing the integration of collaborative signals and exploring more advanced architectures to further improve recommendation accuracy."
        }
    ],
    "similarity_score": 0.7869047227267223,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Laser_ Parameter-Efficient LLM Bi-Tuning for Sequential Recommendation with Collaborative Information.json"
}