{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2411.15647",
    "title": "Circuit design in biology and machine learning. II. Anomaly detection",
    "abstract": "Anomaly detection is a well-established field in machine learning, identifying observations that deviate from typical patterns. The principles of anomaly detection could enhance our understanding of how biological systems recognize and respond to atypical environmental inputs. However, this approach has received limited attention in analyses of cellular and physiological circuits. This study builds on machine learning techniques -- such as dimensionality reduction, boosted decision trees, and anomaly classification -- to develop a conceptual framework for biological circuits. One problem is that machine learning circuits tend to be unrealistically large for use by cellular and physiological systems. I therefore focus on minimal circuits inspired by machine learning concepts, reduced to cellular scale. Through illustrative models, I demonstrate that small circuits can provide useful classification of anomalies. The analysis also shows how principles from machine learning -- such as temporal and atemporal anomaly detection, multivariate signal integration, and hierarchical decision-making cascades -- can inform hypotheses about the design and evolution of cellular circuits. This interdisciplinary approach enhances our understanding of cellular circuits and highlights the universal nature of computational strategies across biological and artificial systems.",
    "bib_name": "frank2024circuitdesignbiologymachine",
    "md_text": "# in biology and machine learning. II. Anomaly d\n# t design in biology and machine learning. II. A\nSteven A. Frank\u2217\nAnomaly detection is a well-established field in machine learning, identifying observations that deviate from typical patterns. The principles of anomaly detection could enhance our understanding of how biological systems recognize and respond to atypical environmental inputs. However, this approach has received limited attention in analyses of cellular and physiological circuits. This study builds on machine learning techniques\u2014such as dimensionality reduction, boosted decision trees, and anomaly classification\u2014to develop a conceptual framework for biological circuits. One problem is that machine learning circuits tend to be unrealistically large for use by cellular and physiological systems. I therefore focus on minimal circuits inspired by machine learning concepts, reduced to cellular scale. Through illustrative models, I demonstrate that small circuits can provide useful classification of anomalies. The analysis also shows how principles from machine learning\u2014such as temporal and atemporal anomaly detection, multivariate signal integration, and hierarchical decision-making cascades\u2014can inform hypotheses about the design and evolution of cellular circuits. This interdisciplinary approach enhances our understanding of cellular circuits and highlights the universal nature of computational strategies across biological and artificial systems. Teaser text: How do cells detect unusual changes in their environment? This study explores machine learning methods that identify anomalous patterns, illuminating the design and evolution of cellular circuits. Simple models inspired by machine learning demonstrate that even minimal biological systems can effectively recognize and classify uncommon signals. This link between how machines learn and how cells evolve introduces a new theoretical approach to the evolutionary design of cellular circuits, highlighting universal strategies shared between living organisms and computational systems. Keywords: Biological design, evolution, artificial intelligence, boosted decision trees, dimensional reduction, internal model principle\n 23 Nov 2024\narXiv:2411.15647v1\nMany biological circuits sense danger. Some respond to common molecular patterns associated with attack. Others perceive environmental threats for which fear or fighting may be helpful1\u20135. An unusual or surprising environment provides another clue of danger. For example, the absence of an expected event could signal an anomaly. The famous comment by Sherlock Holmes about the dog that did not bark illustrates an anomalous absence of an expected event6. A Scotland Yard detective asked Holmes: \u201cIs there\n\u2217Department of Ecology and Evolutionary Biology, University of California, Irvine, CA 92697\u20132525, USA web: https://stevefrank.org\nany other point to which you would wish to draw my attention?\u201d Holmes answered: \u201cTo the curious incident of the dog in the night-time.\u201d The detective replied: \u201cThe dog did nothing in the night-time.\u201d Holmes countered: \u201cThat was the curious incident.\u201d Intuitively, humans have a sense of anomaly, when unexpected events trigger heightened alertness. The word \u201ceerie\u201d captures the notion of discomfort when \u201cthings don\u2019t add up\u201d in an unfamiliar situation. For these reasons, anomaly detection focuses on the deviation from what is typical. An anomaly detection circuit must learn an internal model of the typical pattern. Any departure from that model triggers a warning. This approach contrasts with detecting specific danger signals that directly indicate peril, emphasizing instead deviations from common observations. In mammalian brains, hippocampal circuits de-\ntect anomalies7\u20139. Immune systems may have such circuits10,11. Self versus nonself recognition is not fully understood12 and might, in some cases, depend on detecting anomalous patterns as nonself. Plants might use anomalous volatile organic compounds of neighbors as nonspecific danger signals13,14. However, few biological studies emphasize nonspecific anomaly detection. This article introduces anomaly detection in machine learning15\u201318. Computational models use a wide variety of circuit types to detect anomalies. Those different types of computational circuits suggest the kinds of biological circuits that might detect anomalies. Because anomaly detection is a type of classification problem, aspects of this topic also provide insight into other biological challenges of classification.\n# Contributions of this work\nOverview of the series\nThis article continues the series on circuit design in biology and machine learning19. The series uses insights from machine learning to understand how evolutionary processes build biological circuits. The first article in the series introduced the motivation and challenges for linking biological and machine learning circuits, with examples19. This subsection adds further background. Three facts suggest that machine learning may provide insight into the evolutionary aspects of biological design. First, machine learning and biological organisms often face similar challenges. How can environmental inputs be classified into categories? How can a system predict future inputs? What is the best response to a type of environment? Second, natural selection is one type of learning algorithm. Machine learning deploys a broader range of algorithms. But those different algorithms tend to modify systems in broadly similar ways20\u201322. Third, machine learning and biology often solve challenges by using a computational network to build an input-output response circuit. Here, we think of a biochemical network as a kind of circuit that takes inputs and computes outputs. When machine learning computes solutions without an explicit network,\ngit \u2022 arxiv @ arxiv_1.0-1::0012b68-2024-11-23 (2024-11-26 01:38Z) \u2022 safrank\nusually the computation can be embedded within a network to achieve the same result. The fact that machine learning and biology typically build responses by creating computational circuits means that we can study how machine learning solves particular kinds of problems and use those solutions to make predictions about how evolutionary processes design biological circuits to solve the same sorts of challenges. This series emphasizes simple biochemical circuits, primarily in cells. The analogy between neurobiological and machine learning circuits is well known, although directly linking the architecture and function of biological and computational circuits remains an ongoing challenge23\u201327. By contrast, relatively little work has been done to match cellular or physiological circuits to common machine learning architectures. Two challenges arise. First, although many biochemical circuits in cells have been identified and partially understood, it is not easy to describe complete circuits, understand their computational architecture, and evaluate the sorts of computations that are used to achieve their function. Second, computational networks in machine learning tend to be much larger than could reasonably fit within a cell. Thus, we must develop new machine learning models that emphasize greatly reduced size. Given those constraints, this series primarily aims to sketch the outlines for a new theory that links these two subjects. Some general predictions arise about the architecture of biological circuits. Overall, these articles show the broad conceptual links between particular external challenges and the types of biological circuits that may be favored by evolutionary processes.\n# Insights from anomaly detection\nThis article develops the following points, often with simple illustrative models and example quantitative analyses. \u2022 Machine learning provides new ideas for how cellular and physiological circuits may solve anomaly detection. \u2022 Some challenges require evaluating a single atem-\nThis article develops the following points, often with simple illustrative models and example quantitative analyses.\n\u2022 Machine learning provides new ideas for how cellular and physiological circuits may solve anomaly detection.\nporal multivariate input for anomaly. Others require estimating deviations from recent temporal trends. Simple models illustrate different circuit designs for atemporal and temporal cases.\nquire estimating deviations from recent temporal trends. Simple models illustrate different circuit designs for atemporal and temporal cases. \u2022 Detecting anomalies often requires evaluating multivariate patterns in inputs by integrating signals from ensembles of sensors or receptors. This article reviews basic measures of signal information. \u2022 Digital sensors reduce continuous analog inputs to discrete binary outputs, losing information but also reducing sensitivity to noise and measurement error. Digital sensors are easier to implement and easier to combine into broader circuits. \u2022 Machine learning uses big circuits. Cells require small circuits. This article shows that small circuits can achieve significant resolving power. \u2022 Some anomalies differ in mean input values. Summing the inferences by individual sensor outputs provides a good response. \u2022 Other anomalies differ in correlations between inputs. Decision trees work well, each sensor responding within a sequence based on the output of prior sensors. \u2022 Machine learning often deploys cascades of circuits, such as a cascade of separate decision trees. \u2022 Each small circuit passes its response to the next circuit, which corrects errors and boosts response quality. \u2022 Learning a sequence of boosted circuits matches the likely way that evolution works, sequentially improving an existing cascade of small modular subsolutions. \u2022 Dimensional reduction provides a potential alternative for anomaly detection. Typical multivariate inputs can be reduced to a lower dimension, similar to principal components analysis. An anomalous input tends to be relatively distant from typical inputs in the reduced space. \u2022 Small encoder circuits can reduce dimensionality, classifying differences in the correlational structure of typical and anomalous inputs. In general,\n\u2022 Detecting anomalies often requires evaluating multivariate patterns in inputs by integrating signals from ensembles of sensors or receptors. This article reviews basic measures of signal information.\n# \u2022 Machine learning uses big circuits. Cells require small circuits. This article shows that small circuits can achieve significant resolving power.\n# \u2022 Some anomalies differ in mean input values. Summing the inferences by individual sensor outputs provides a good response.\n\u2022 Some anomalies differ in mean input values. Summing the inferences by individual sensor outputs provides a good response.\n\u2022 Other anomalies differ in correlations between inputs. Decision trees work well, each sensor responding within a sequence based on the output of prior sensors.\n\u2022 Machine learning often deploys cascades of circuits, such as a cascade of separate decision trees.\n# \u2022 Machine learning often deploys cascades of circuits, such as a cascade of separate decision trees.\n# \u2022 Each small circuit passes its response to the next circuit, which corrects errors and boosts response quality.\n\u2022 Learning a sequence of boosted circuits matches the likely way that evolution works, sequentially improving an existing cascade of small modular subsolutions.\n\u2022 Small encoder circuits can reduce dimensionality, classifying differences in the correlational structure of typical and anomalous inputs. In general,\ndimensional reduction is likely to be a major feature of biological circuits.\n\u2022 As in all problems of biological design, evolutionary tuning with respect to tradeoffs inevitably plays a central role in shaping biological circuits.\n# Timescale\nInstantaneous versus time-dependent inputs\nTimescale broadly influences the kinds of circuits that can succeed in anomaly detection. Most anomaly detection methods consider multiple inputs at one point in time. If a single multivariate input is unusual compared with the set of typical multivariate points, then that unusual input is classified as an anomaly. In some cases, an anomaly must be considered with respect to recent temporal trends28,29. For example, reactive oxygen species are often used as weapons in microbial warfare. A rapid increase in concentration of these dangerously reactive molecules may signal attack. For multivariate problems that use a single atemporal input, a machine learning method typically classifies by some sort of clustering, partitioning, or dimensional reduction15\u201318. The common inputs fall toward one cluster, or in a particular direction away from a partition, or in a particular location in a reduced space of constructed dimensions. The anomalous inputs are those that are not near the common set. Temporal problems also require classification28,29. However, before classification, one must adjust for the temporal dependence of the input stream. For example, typical inputs may follow a rising trend. An anomaly must be measured against the expected input from the current trend, which requires a circuit to maintain an updated trend estimate.\n# Biological response times\nAtemporal classification of anomalies demands a sufficiently fast circuit. The multivariate perception of input must be accomplished before the environment changes significantly. The calculations to classify must follow with sufficiently short lag to allow an\nappropriate response. A neurobiological circuit would likely be quick enough to do atemporal classification. For cellular or physiological circuits, response speeds vary widely for different components, from slow biochemical reactions to fast receptors. If the environment changes significantly faster than a circuit\u2019s classification inference, then such a circuit may not be able to classify the current environment as if it were an instantaneous isolated event. Temporal classification over input sequences alters the timescale constraints. The circuit\u2019s estimate of trends in inputs may update continuously, although with a time lag. The circuit can work well if its update lag is shorter than the timescale over which environmental trends change. For temporal classification problems, neurobiological circuits would likely be quick enough for most challenges. Cellular and physiological circuits may sometimes be quick enough if intrinsic temporal smoothing of trend estimation provides sufficient information. At present, we know little about the cellular and physiological response times of anomaly detection circuits. I limit discussion to three brief comments. First, cellular receptors can potentially respond on the timescale of their ligand on-off rates, which are often very fast. So, at the receptor level, sensory information may be able to keep up with environmental change. Second, some cellular states depend on electric gradients, which change rapidly and can be transmitted at relatively high speed30. These fast components of cellular response might provide a sufficient basis for speedy circuits. Third, slower downstream biochemical reactions might constrain circuit design. Different biochemical processes vary in their response times31. Altering the concentrations of reactants often triggers the fastest response. Covalent modifications of enzymes are slower than changes in reactant concentrations. Altering enzyme production or degradation rates is typically the slowest modification of biochemical circuits. Many other factors could change biochemical response times. However, those factors are likely to be slow relative to the responses of receptors or electric gradients.\n# Simple mechanisms\nAtemporal biochemical mechanism\n# Atemporal biochemical mechanism\nThis subsection briefly illustrates how we may think about mechanistic components in biological circuits. The example describes a simple circuit for atemporal challenges. The following subsection considers temporal challenges. As a first step, a circuit may determine how each input dimension deviates from its typical value. We begin with a widely observed empirical relation in biochemistry, the Hill function32\u201334. This function describes a common pattern by which an input level is transformed into an output response as\n(1)\n+ in which \ud835\udc62is the input, \ud835\udc58is a coefficient that determines shape, and \ud835\udc5ais the input at which the response achieves one-half of its maximum level. The notation \ud835\udc62|\ud835\udc5a, \ud835\udc58identifies \ud835\udc62as the input variable given the parameters \ud835\udc5aand \ud835\udc58that determine response. In the following, I assume that all functions share the same \ud835\udc58value, which is dropped from the notation to simplify the expressions. We seek a circuit that identifies an anomalous input by its deviation from a standard input level, \ud835\udc62\u2217. Suppose a receptor balances stimulative and repressive forces in relation to input level, given by the difference between two Hill functions\n(2)\nin which \ud835\udc4eis a weighting on the repressive effect to achieve a relative balance between the two forces. We can choose \ud835\udc4eso that \u02c6\ud835\udc5fevaluated at \ud835\udc62\u2217is a minimum, which gives a circuit that increases in output as the input, \ud835\udc62, deviates from the minimum, \ud835\udc62\u2217(see caption for Fig. 1). For numerical convenience, we can subtract the value of \u02c6\ud835\udc5fat its minimum to obtain a receptor that returns zero when the input is at its standard level, \ud835\udc62\u2217, and returns increasing values as \ud835\udc62increasingly deviates from \ud835\udc62\u2217, as\n(3)\nFigure 1 illustrates how this receptor identifies anomalous deviations from typical input values. The cutoff\nfor classifying an anomaly may evolve by natural selection in a biological context or be estimated from data in a machine learning context. Multivariate input requires combining multiple receptor responses to identify anomalies.\n# Anomalous deviation from temporal trend\nSuppose the value of typical inputs, \ud835\udc62\u2217, changes over time. A circuit must estimate the current typical input. That estimate of \ud835\udc62\u2217and the current input value, \ud835\udc62, can be used in eqn 3 to get the receptor signal. If we choose sufficiently large values of the \ud835\udc5a parameters, then \ud835\udc4e\u2192(\ud835\udc5a2/\ud835\udc5a1)2 (see caption of Fig. 1). With approximately constant \ud835\udc4e, to calculate the receptor response in eqn 3, we only need to track the dynamics of \ud835\udc62\u2217given the input, \ud835\udc62. We can track the dynamics of \ud835\udc62\u2217by including in the circuit\n(4)\nin which \ud835\udc62is a stochastically changing input, and \ud835\udc62\u2217is an exponential moving average of \ud835\udc62, with the overdot denoting the derivative with respect to time. The parameter \ud835\udf06controls the speed at which the internal moving average estimate responds to changing inputs. This process simply describes the production or degradation rate of a molecule in response to the level of a stimulating input. Using the moving average estimate for typical inputs, \ud835\udc62\u2217, in eqn 3 allows the receptor to adjust to changing environmental conditions. Figure 2 shows how this adaptable receptor detects anomalous deviations in the input signal. In the only similar model that I found, a circuit estimates the ratio of a current input relative to the recent value of typical inputs35. The goal was ratio estimation, which the authors called fold change. Significant deviations of the ratio from one could also be used for anomaly detection. To obtain a fold-change circuit, instead of using the receptor in eqn 3, we combine the moving average estimate from eqn 4 with \ufffd \ufffd\n(5)\n\ufffd \ufffd which approximately matches the circuit given published fold-change circuit35. If the dynamics respond\nsufficiently quickly to changes, with large enough \ud835\udf06 and \ud835\udefe, then \ud835\udc66measures the ratio of the current input \ud835\udc62to the recent typical input, \ud835\udc62\u2217. In this ratio-estimating biochemical circuit, the response time may differ from the response time of a receptor-based circuit approximated by eqn 3. Typically, receptors respond more quickly than biochemical reactions. However, it is not clear if natural processes more easily build and tune circuits based on receptors or biochemical reactions in solution.\n# Multivariate signals\nThe prior subsections analyzed deviations in a single dimension. Detecting anomalies often requires combining information from multiple dimensions. For example, identifying attacks on a computer network depends on the number of data bytes sent to the target computer that may be under attack, the number of data bytes returned to the potential attacker by the target computer, and the type of connection such as email or web page. Two widely used test datasets for computer network attack include those network measures along with several other dimensions of data36,37. The challenge is to classify whether a network connection to a target computer is a normal use or an attack. Is the connection pattern described by the multivariate measures of the connection typical or anomalous? Many different machine learning methods have been applied to these benchmark datasets38\u201340. The next subsection begins by evaluating each data dimension independently to infer anomalies and then combining the information in the independent dimensions. The following subsections include the information in the correlation between dimensions by combining the dimensions into a decision tree or by using hierarchical dimension reduction by encoders, two widely used machine learning methods that may map relatively easily to biological circuits. I start with artificial data to illustrate the methods. I then turn to real data that contrasts typical computer network connections with anomalous connections from attack. I use the computer data because we do not have\nlarge datasets with multivariate measurements of typical and anomalous biological inputs. The goal here is to illustrate the key principles of circuit design that may be important for understanding how natural processes shape biological responses. Anomaly detection has hardly been studied in cellular biology but seems likely to be important in some circumstances.\n# Independent data dimensions and ensembles\nSuppose an input generates \ud835\udc5bindependent data dimensions. For a typical input, the value in each dimension is a random sample from a normal distribution with mean \ud835\udc5a\ud835\udc61and standard deviation \ud835\udf0e. Similarly, an anomalous input generates \ud835\udc5bindependent values, each sampled from a normal distribution with mean \ud835\udc5a\ud835\udc4eand standard deviation \ud835\udf0e. Assume typical inputs are usually smaller than anomalous inputs, \ud835\udc5a\ud835\udc61< \ud835\udc5a\ud835\udc4e. Suppose a biological circuit can average the \ud835\udc5bindependent values associated with each input. Then the standard deviation of the average value is \ud835\udf0e/\u221a\ud835\udc5b. The circuit classifies the average value as typical if it is less than a threshold value, \ud835\udf0f, and anomalous if greater than the threshold. Figure 3a illustrates how a change in threshold value alters the circuit\u2019s success at classifying inputs. A smaller threshold causes a higher rate of classification as anomalous, which increases both the true rate of predicting anomalies and the false rate of predicting anomalies. As the threshold changes, the curve traces the tradeoffs between those different aspects of successful classification. The area under the curve (AUC) provides one way to measure the overall quality of the circuit\u2019s ability to classify inputs. Figure 3b shows how the circuit\u2019s response characteristics improve for increasing levels of \ud835\udc5b, the number of data dimensions sampled by the circuit. More data dimensions provide more precise information about whether the input is typical or anomalous.\n# Digital circuits\nPrecise estimates for each of the \ud835\udc5bdata values may be difficult for biological sensors, making the circuit sensitive to perturbations in measurement. Suppose instead that each sensor encoded its response in\na binary way, which we can label as 0 or 1. In other words, each sensor converts its analog input to a digital output: a 0 response when the value is below some threshold and a 1 response above the threshold. Such analog to digital conversion can be approximated by the Hill function response described by eqn 1, which is widely observed in biology32\u201334. With digital sensors, a circuit only has to combine the information into an overall frequency of 1 values, which are the anomaly signals. For example, if each sensor can trigger the activation of a transcription factor, then those transcription factors can bind to a gene promoter. By this process, the promoter can produce a response that grades with the overall frequency of anomaly signals from the sensors. This digital circuit requires two threshold values. First, \ud835\udf0fsets the point below which an individual sensor returns 0 for a typical input and above which the sensor returns 1 for an anomalous input. Second, a threshold \ud835\udf19sets the frequency of 1 responses among the individual sensors required for the circuit to return an overall classification of anomalous for a multivariate input. Figure 4 shows how the two thresholds interact. Higher curves correspond to increasing numbers of sensors, \ud835\udc5b. In (a), with \ud835\udf19= 1/3, low thresholds for the individual sensors, \ud835\udf0f, cause increasing \ud835\udc5bto provide relatively high false predicted anomalies (false positives). This pattern can be seen by starting with the lower curve for \ud835\udc5b= 1 and the smallest labeled threshold of 90 marked by the gold circle. As \ud835\udc5bincreases and the curves rise, the gold circle for 90 moves to the right because the rate of false predicted anomalies along the \ud835\udc65-axis increases. The reason is that with both a low individual sensor threshold and a low overall threshold, the expected outcome for a typical input is a false positive prediction of anomaly. As \ud835\udc5bincreases, the variance declines and the expected outcome increasingly dominates. In Fig. 4b, with \ud835\udf19= 2/3, high thresholds for the individual sensors tend to cause an increase in predictions of typical for the inputs. More predictions of typical raise the false positive rate of typical predictions, which corresponds to a reduced level along the \ud835\udc66-axis for true predicted anomalies. Once again, as \ud835\udc5bincreases, the variance declines and the expected outcome increasingly dominates, causing a drop in\ntrue predicted anomalies. Figure 5 shows that analog to digital conversion by sensors decreases the maximum available information. The lower blue curve traces the smaller error rate for a fully analog circuit that averages the actual values coming into the sensors, as in Fig. 3. The upper gold curve shows the rise in the error rate caused by the information lost to digital conversion, as in Fig. 4. Digital circuits reduce information but are simpler to construct and often are more robust. Small perturbation will usually not alter the 0/1 classification by a sensor. By contrast, many sources of noise will cause variability in a measured analog value.\n# Computer network anomaly detection\nIn the NSL-KDD dataset of attacks on a central computer, a digital ensemble of sensors performs very well at detecting anomalous computer network characteristics associated with attacks. This dataset is widely used as a benchmark for machine learning studies of anomaly detection. The dataset contains measurements for many features of the computer network37. A freely available Python notebook calculated how well each of 36 features could independently classify an input as a typical network pattern or an anomalous attack41. The analysis used the area under the curve (AUC) to measure the resolving power of a feature, as in Fig. 3. Features with high resolving power included the amount of data sent by the remote computer to the target computer, the amount of data returned to the remote computer, the kind of service request to the target such as email or web page, and the number of recent connections by the same remote computer. The AUC values for 22 of 36 features were greater than 0.5, which means those features had some resolving power. The top 15 AUC values ranged from 0.82 to 0.66. If each sensor\u2019s response is encoded as 0 for typical and 1 for anomalous, then an ensemble digital analysis can be created by summing the values for the 22 resolving features. The ensemble circuit\u2019s AUC score is 0.93, which is good. F1 provides another measure of classification success, combining how often a positive prediction is correct and how often a positive input is correctly predicted42. The ensemble circuit\u2019s F1 score is 0.9,\nwhich is also good. Reducing the number of sensors to the top 4 with individual AUC values above 0.75, the ensemble AUC score is 0.92, and the F1 score is 0.89. Thus, a small and simple ensemble of digital sensors performs well for this classic benchmark dataset.\n# Extra information in multivariate pattern\nIn the ensemble digital model, each sensor passes a digital response. That response can easily be combined with the outputs of other digital sensors to create an overall circuit response. Simple biological circuits may often be built in this way. The digital ensemble uses each dimension of the input independently. Each digital sensor takes one input value and responds as a one-step decision tree (Fig. 6a). If the input is greater than some threshold, the decision tree responds one way. Otherwise, it responds the other way. However, a multivariate pattern rarely occurs as a collection of independent dimensions. Most machine learning methods extract some of the extra multivariate information. The following sections consider two common machine learning circuits that may apply widely in biology.\n# Boosted decision trees\nDeep trees\nA simple extension uses deeper decision trees. In Fig. 6b, the input value for the first feature of the multivariate data is split at some threshold value. If the first feature is greater than its threshold, then a second split is made based on another feature and a different threshold. If the first feature is less than its threshold, then the second split happens based on different criteria. A deeper tree analyzes multiple inputs, allowing for decisions that include correlations between different feature dimensions of the data. A tree of depth \ud835\udc5b makes 2\ud835\udc5b\u22121 \u22482\ud835\udc5bsplits on the data. For example, if a system has the capacity to make 26 = 64 splits, then it can make 20 = 1 trees of depth 6, or 21 = 2 trees of depth 5, or 22 = 4 trees of depth 4, and so on.\nApproximately, for 2\ud835\udc5bsplits, the system can make 2\ud835\udc5atrees of depth 2\ud835\udc5b\u2212\ud835\udc5a. Typically, machine learning applications perform better by using many trees of shallower depth rather than a small number of deep trees. Various methods exist for creating multiple trees and combining them into a single decision ensemble43,44.\n# Boosting and biological design\nThe most widely successful method creates trees by a boosting process45. Boosting makes trees sequentially, starting with a single relatively small tree. Then, with an optimized first tree, the algorithm adds a second tree that corrects errors made by the first tree. The process continues adding trees in this way, each tree boosting the success achieved by the prior ensemble. Boosting seems like a good description of how biological circuits may be designed by natural selection. Initially, a small circuit may provide some information. A second circuit may boost performance, followed by a third, and so on. Sequentially boosted improvement may be the essence of biological design.\n# Typical vs anomalous data as self vs nonself\nFigure 7 illustrates some of the tradeoffs in building an ensemble of boosted trees. In this case, I generated an artificial set of data with both typical and anomalous inputs by sampling from multivariate normal distributions. Each input has \ud835\udc53feature dimensions. For the typical data, each feature dimension has a mean value drawn randomly from a normal distribution with mean zero and standard deviation \ud835\udf0e. I call that standard deviation the mean scale because \ud835\udf0edetermines the scale of the fluctuations among the means of the different dimensions. The variance in each dimension is one, so the \ud835\udc53dimensional correlation matrix is also the covariance matrix. I generated that matrix by a random draw from a uniform distribution over all possible correlation matrices46. Once this distribution is set for typical data, all typical observations come from this single distribution. For the anomalous data, I used the same process to create a new multivariate normal distribution for each observation. Each anomalous observation is\na single random draw from a unique distribution. Thus, classification requires recognizing what a typical observation looks like when compared with a wide variety of anomalous data patterns rather than recognizing specific signatures of danger. This structure captures the essence of self versus nonself discrimination. Here, the typical pattern defines self, and the anomalous observations define nonself, the variety of patterns distinct from self47\u201352.\n# Performance\nFigure 7a shows the success of a boosted decision tree circuit. For that panel, the circuit has 4 trees, each of depth 2. As the mean scale increases along the \ud835\udc65-axis, the circuits do better at detecting anomalies. A greater mean scale implies that, for each feature, the average deviation between the mean values of the typical and anomalous observations rises. Decision trees can easily detect differences in mean values for a feature by splitting at a threshold that likely separates typical and anomalous inputs. The different curves show the varying numbers of features available in the data. More features tend to increase the largest deviations in mean values between typical and anomalous observations. More features also tend to increase the difference in multivariate correlation structure between typical and anomalous observations because greater dimensionality increases the space of possible correlation patterns. The other panels show the increase in classification success as the number of trees or the depth of trees increases. Deeper trees are particularly good at identifying differences in multivariate patterns caused by correlations between features. That benefit can be seen by comparing the success of the deeper trees at low values of mean scale, for which there is little information available from differences in mean values between typical and anomalous observations. The structure of this particular problem provides a strong challenge for anomaly detection because no common pattern exists among the anomalous inputs. Additionally, the generating process for the observations creates wide scatter among both typical and anomalous inputs. Nonetheless, the boosted tree ensembles significantly discriminate between typical and anomalous inputs.\n# Boosted trees and biological circuit evolution\nEach node of a tree is simply a binary split based on input. Thus, any biological circuit that expresses the commonly observed Hill response could implement a node of a decision tree32\u201334. Combining information from multiple trees is also likely to be something that simple biological systems could achieve. As I mentioned earlier, the sequential process of building boosted trees likely matches the natural tendency for evolutionary processes to create solutions by adding improvements to an initial design. Thus, the simple way in which tree-like decision nodes can be implemented biologically and the sequential process of boosting make boosted trees an excellent model for cellular and neural circuits that solve challenges of classification and decision.\n# Encoders and internal models\nDimensional reduction\n# Dimensional reduction\nEncoders reduce dimension by compressing inputs into informative components (for background, see Box 2 of Frank19). Dimensional reduction by encoding can be an effective way to identify anomalous environmental conditions. A common autoencoder method first compresses the \ud835\udc53features of an input to a representation in a lower \ud835\udc53\u2032 dimensional space. It then expands that representation back to the original \ud835\udc53dimensions, attempting to match closely the original input. An autoencoder uses patterns in the data40. For example, suppose the second feature tends to follow a particular function of the third and fourth features. In that case, the compression method can discard the second feature and recreate that feature during decompression. When a good autoencoder compresses and then decompresses an input, the final decompressed value tends to be close to the original input. If anomalous inputs lack some of the patterns in typical inputs, an autoencoder built for typical inputs will often distort an anomalous input during the encoding-decoding sequence. The output for an anomalous input will often be farther from the original input than usually happens for typical inputs. Thus, the distance between the input and the output\nof an autoencoder can be used to classify inputs as typical or anomalous. Using a sequence of compression steps often creates a more effective encoding. If, for example, the initial data have 2\ud835\udc5bfeatures, a first compression stage may reduce to 2\ud835\udc5b\u22121 dimensions, followed by compression to 2\ud835\udc5b\u22122 dimensions, and so on. Sequential compression helps to create an internal model of the data18,53\u201355. When sequentially compressing images of faces, early steps may focus on facets such as eyes, ears, nose, and mouth. Later steps may consider relations between those parts, providing an internal model of how a typical face tends to look56\u201358.\n# Anomaly detection\nFor this article, we are particularly interested in the simplest effective circuits. A full autoencoder requires both encoding compression and decoding decompression. A simpler approach uses only the encoding step. We convert the \ud835\udc53features in the input to \ud835\udc53\u2032 compressed dimensions. If we design an encoder that tends to make a large distance between typical and anomalous inputs in the \ud835\udc53\u2032 dimensional representation, then we can use that distance to detect anomalies. Figure 8 illustrates how an encoder separates typical and anomalous inputs. In this example, the 4 input dimensions were reduced to 2 output dimensions using a single layer neural network. That small network separated typical and anomalous observations with high accuracy.\n# Factors influencing circuit accuracy\nFigure 9a compares an encoder\u2019s classification efficacy under different conditions. The F1 score measures classification efficacy, combining how often a positive prediction is correct and how often a positive input is correctly predicted42. The mean scale influences the amount of variation between typical and anomalous mean values in each dimension of the data. The full data initially contained \ud835\udc53= 32 features. I then calculated F1 scores by using only the first \ud835\udc53= 4, 8, 16 feature dimensions. Each line in the figure is labeled with the number of features used, \ud835\udc53= 2\ud835\udc5b. For this figure, an encoder reduces dimensionality from\nthe \ud835\udc53= 2\ud835\udc5binputs to 20 = 1 output, using \ud835\udc5blayers in the neural network encoder. Three conclusions follow from this figure. First, between typical and anomalous inputs, bigger differences in mean values for each dimension make it easier to detect anomalies, shown in the figure as the mean scale increases along the \ud835\udc65-axis. Second, sampling more features of the data improves classification. The improvement occurs primarily for small values of the mean scale, in which mean differences provide limited information. In those situations, a classifier can succeed when it is able to infer distinctions between typical and anomalous inputs in the correlation pattern among the dimensions. In this example, raising the number of features enhances the information about correlational pattern, providing increasingly accurate classification. The third conclusion is that, given a sufficient number of features, an encoder can achieve nearly perfect classification for these input data. In this case, an encoder using all 32 features of the data made very few classification errors. The encoder for \ud835\udc53= 32 features achieved high success by optimizing the 713 parameters in its encoding network. For \ud835\udc53= 4, 8, 16, the circuits required 13, 49, and 185 parameters.\n# Simplifying circuits\nFigure 9b shows that, for a given performance level measured by F1, we can find simpler circuits with the same performance. In that plot, the calculation of each point began with all 32 features. I then iteratively removed one feature at a time, dropping the feature that provided the least amount of information, measured by the smallest decline in F1. I continued dropping features in this way, providing an F1 measure for \ud835\udc53= 1, 2, . . . , 32 for each mean scale level. The plot shows curves for particular \ud835\udc53values. Choosing the best \ud835\udc53features of the full 32 in the data provides a better F1 score than taking the first \ud835\udc53 features in the data, as expected. Put another way, for a given F1 level of performance, we can use a smaller circuit if we select the best features rather than using a fixed feature set. The amount by which a circuit can be reduced for a given F1 score depends on the particular data structure, as shown by the plots.\nWe could further reduce the number of parameters in a circuit by imposing a cost on each parameter. A cost favors a parameter to decline close to zero when it adds relatively little improvement in performance. We then obtain a simplified circuit by pruning all parameters near zero. Overall, relatively small encoder circuits can achieve good classification for some types of data.\n# Discussion\nI have focused on anomalies as unusual observations, anything that differs from what is typical. Detection does not depend on specific anomalous patterns or danger signals. Instead, a system creates a model of a typical input and infers when an input differs from that internal model. Something like \u201cThat\u2019s an unusual smell\u201d or \u201cI\u2019ve never seen that before.\u201d Sensory or neural adaptation provides a simple example. Many biological circuits adjust their baseline by averaging over recent inputs. That baseline allows the circuit to measure deviations from what has recently been typical59\u201363. I presented simple circuits in eqns 4 and 5 that adapt to recent trends. An ensemble of such circuits could classify multivariate inputs. Self versus nonself recognition occurs widely throughout biology64\u201373. In some cases, nonself is recognized by direct pattern recognition, which does not require the more challenging kinds of circuits discussed in this article. In other cases, self recognition is more complex and not fully understood12. It seems that systems sometimes recognize what is self and classify as anomalous those observations that do not fit the self pattern, potentially sharing properties with the machine-learning circuits discussed in this article. The human hippocampus appears to recognize novelty in certain contexts7\u20139. Further studies suggest that memory creates a model of what is common. The system classifies inputs as novel or unusual when they deviate significantly from expectation74,75. With regard to the analyses in this article, some sort of dimensional reduction likely encodes the internal model. Cellular and physiological systems would likely gain from anomaly detection. The models in this\narticle suggest the kinds of small circuits that could work within these constrained biological systems.\n# Acknowledgments\nThe Donald Bren Foundation, US Department of Defense grant W911NF2010227, and US National Science Foundation grant DEB-2325755 support my research.\n# Data availability statement\nSoftware to produce the figures is available on GitHub76.\n# References\n1. Heil, M. & Land, W. G. Danger signals\u2014damagedself recognition across the tree of life. Frontiers in Plant Science 5, 107937 (2014). 2. LeRoux, M., Peterson, S. B. & Mougous, J. D. Bacterial danger sensing. Journal of Molecular Biology 427, 3744\u20133753 (2015). 3. Nesse, R. M. The smoke detector principle: signal detection and optimal defense regulation. Evolution, Medicine, and Public Health 2019, 1 (2019). 4. Klein, A. S., Dolensek, N., Weiand, C. & Gogolla, N. Fear balance is maintained by bodily feedback to the insular cortex in mice. Science 374, 1010\u2013 1015 (2021). 5. Moscarello, J. M. & Penzo, M. A. The central nucleus of the amygdala and the construction of defensive modes across the threat-imminence continuum. Nature Neuroscience 25, 999\u20131008 (2022). 6. Doyle, A. C. The adventure of Silver Blaze. In The Memoirs of Sherlock Holmes (George Newnes Ltd., London, 1893). 7. Kumaran, D. & Maguire, E. A. An unexpected sequence of events: mismatch detection in the human hippocampus. PLoS biology 4, e424 (2006). 8. Kumaran, D. & Maguire, E. A. Match\u2013mismatch processes underlie human hippocampal responses to associative novelty. Journal of Neuroscience 27, 8517\u20138524 (2007).\n9. Bhasin, G. & Nair, I. R. Dynamic hippocampal ca2 responses to contextual spatial novelty. Frontiers in Systems Neuroscience 16, 923911 (2022). 10. Dasgupta, D. & Forrest, S. An anomaly detection algorithm inspired by the immune system. In Dasgupta, D. (ed.) Artificial Immune Systems and Their Applications, 262\u2013277 (Springer, New York, 1999). 11. Ramadan, A., Land, W. G. & Paczesny, S. Editorial: Danger signals triggering immune response and inflammation. Frontiers in Immunology 8, 979 (2017). URL https://www.frontiersin. org/journals/immunology/articles/10. 3389/fimmu.2017.00979. 12. Koncz, B., Balogh, G. M. & Manczinger, M. A journey to your self: The vague definition of immune self and its practical implications. Proceedings of the National Academy of Sciences 121, e2309674121 (2024). 13. Meents, A. K. & Mith\u00f6fer, A. Plant\u2013plant communication: is there a role for volatile damageassociated molecular patterns? Frontiers in Plant Science 11, 583275 (2020). 14. Duc, N. H. et al. Volatile organic compounds shape belowground plant\u2013fungi interactions. Frontiers in Plant Science 13, 1046685 (2022). 15. Omar, S., Ngadi, A. & Jebur, H. H. Machine learning techniques for anomaly detection: an overview. International Journal of Computer Applications 79, 33\u201341 (2013). 16. Nassif, A. B., Talib, M. A., Nasir, Q. & Dakalbab, F. M. Machine learning for anomaly detection: a systematic review. IEEE Access 9, 78658\u201378700 (2021). 17. Pang, G., Shen, C., Cao, L. & Hengel, A. V. D. Deep learning for anomaly detection: A review. ACM Computing Surveys (CSUR) 54, 1\u201338 (2021). 18. Ruff, L. et al. A unifying review of deep and shallow anomaly detection. Proceedings of the IEEE 109, 756\u2013795 (2021). 19. Frank, S. A. Circuit design in biology and machine learning. i. random networks and dimensional reduction (2024). URL https://arxiv.org/abs/ 2408.09604. 2408.09604. 20. De Jong, K. A. Evolutionary Computation: A Unified Approach (MIT Press, Cambridge, MA, 2006), 2nd edn.\n21. Holland, J. H. Adaptation in Natural and Artificial Systems (University of Michigan Press, Ann Arbor, Michigan, 1975). 22. Holland, J. H. Hidden Order: How Adaptation Builds Complexity (Basic Books, New York, NY, 1995). 23. McCulloch, W. S. & Pitts, W. A logical calculus of ideas immanent in nervous activity. Bulletin of Mathematical Biophysics 5, 115\u2013133 (1943). 24. Hebb, D. O. The Organization of Behavior (Wiley, New York, 1949). 25. Rumelhart, D. E. & McClelland, J. L. Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations (MIT Press, Cambridge, Massachusetts, 1986). 26. Jiahui, G. et al. Modeling naturalistic face processing in humans with deep convolutional neural networks. Proceedings of the National Academy of Sciences 120, e2304085120 (2023). 27. Kanwisher, N., Khosla, M. & Dobs, K. Using artificial neural networks to ask \u2018why\u2019 questions of minds and brains. Trends in Neurosciences 46, 240\u2013254 (2023). 28. Bl\u00e1zquez-Garc\u00eda, A., Conde, A., Mori, U. & Lozano, J. A. A review on outlier/anomaly detection in time series data. ACM Computing Surveys (CSUR) 54, 1\u201333 (2021). 29. Choi, K., Yi, J., Park, C. & Yoon, S. Deep learning for anomaly detection in time-series data: review, analysis, and guidelines. IEEE Access 9, 120043\u2013 120065 (2021). 30. Levin, M. Molecular bioelectricity: how endogenous voltage potentials control cell behavior and instruct pattern regulation in vivo. Molecular Biology of the Cell 25, 3835\u20133850 (2014). 31. Fell, D. Understanding the Control of Metabolism (Portland Press, London, 1997). 32. Frank, S. A. Input-output relations in biological systems: measurement, information and the Hill equation. Biology Direct 8, 31 (2013). 33. Zhang, Q., Bhattacharya, S. & Andersen, M. E. Ultrasensitive response motifs: basic amplifiers in molecular signalling networks. Open Biology 3, 130031 (2013). 34. Martinez-Corral, R., Nam, K.-M., DePace, A. H. & Gunawardena, J. The hill function is the universal hopfield barrier for sharpness of input\u2013output\nresponses. Proceedings of the National Academy of Sciences 121, e2318329121 (2024). 35. Goentoro, L., Shoval, O., Kirschner, M. W. & Alon, U. The incoherent feedforward loop can provide fold-change detection in gene regulation. Molecular Cell 36, 894\u2013899 (2009). 36. Ring, M., Wunderlich, S., Landes, D. & Hotho, A. Cidds-001 (2022). URL https://www.kaggle. com/dsv/4061966. 37. Tavallaee, M., Bagheri, E., Lu, W. & Ghorbani, A. Nsl-kdd (2022). URL https://www.kaggle. com/dsv/4475812. 38. Thapa, N., Liu, Z., KC, D. B., Gokaraju, B. & Roy, K. Comparison of machine learning and deep learning models for network intrusion detection systems. Future Internet 12, 167 (2020). URL https: //www.mdpi.com/1999-5903/12/10/167. 39. Salih, A. A. & Abdulazeez, A. M. Evaluation of classification algorithms for intrusion detection system: a review. Journal of Soft Computing and Data Mining 2, 31\u201340 (2021). 40. Torabi, H., Mirtaheri, S. L. & Greco, S. Practical autoencoder based anomaly detection by using vector reconstruction error. Cybersecurity 6, 1 (2023). URL https://doi.org/10.1186/ s42400-022-00134-9. 41. D\u2019Hooge, L. Nsl-kdd-01-eda-oner: 0.929 roc-auc, version 3 (2022). URL https://www.kaggle.com/code/dhoogla/ nsl-kdd-01-eda-oner-0-929-roc-auc. 42. Powers, D. M. W. Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation (2020). URL https: //arxiv.org/abs/2010.16061. 2010.16061. 43. Zhou, Z.-H. Ensemble Methods: Foundations and Algorithms (CRC press, Boca Raton, Florida, 2012). 44. Hastie, T., Tibshirani, R. & Friedman, J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Springer, New York, 2017), 2nd edn. 45. Schapire, R. E. & Freund, Y. Boosting: foundations and algorithms. Kybernetes 42, 164\u2013166 (2013). 46. Lewandowski, D., Kurowicka, D. & Joe, H. Generating random correlation matrices based on vines and extended onion method. Journal of\nMultivariate Analysis 100, 1989\u20132001 (2009). 47. Aickelin, U., Dasgupta, D. & Gu, F. Artificial immune systems. In Burke, E. & Kendall, G. (eds.) Search Methodologies, 187\u2013211 (Springer, 2014). 48. Dasgupta, D. & Forrest, S. Artificial immune systems in industrial applications. In Proceedings of the Second International Conference on Intelligent Processing and Manufacturing of Materials. IPMM\u201999, 257\u2013267 (1999). 49. Forrest, S., Perelson, A. S., Allen, L. & Cherukuri, R. Self-nonself discrimination in a computer. In Proceedings of 1994 IEEE Computer Society Symposium on Research in Security and Privacy, 202\u2013212 (1994). 50. Hofmeyr, S. A. & Forrest, S. Architecture for an artificial immune system. Evolutionary Computation 8, 443\u2013473 (2000). 51. Kim, J. & Bentley, P. J. An evaluation of negative selection in an artificial immune system for network intrusion detection. In Proceedings of the 3rd Annual Conference on Genetic and Evolutionary Computation, 1330\u20131337 (Morgan Kaufmann Publishers Inc., 2001). 52. Stibor, T., Timmis, J. & Eckert, C. A comparative study of real-valued negative selection to statistical anomaly detection techniques. In International Conference on Artificial Immune Systems, 262\u2013275 (Springer, 2005). 53. Bengio, Y. Learning deep architectures for AI. Foundations and Trends in Machine Learning 2, 1\u2013127 (2009). 54. Bengio, Y., Courville, A. & Vincent, P. Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence 35, 1798\u20131828 (2013). 55. Hinton, G. E. & Salakhutdinov, R. R. Reducing the dimensionality of data with neural networks. Science 313, 504\u2013507 (2006). 56. Le, Q. V. et al. Building high-level features using large scale unsupervised learning. In ICML\u201912: Proceedings of the 29th International Coference on International Conference on Machine Learning, 507\u2013514 (IEEE, 2012). 57. Lee, H., Grosse, R., Ranganath, R. & Ng, A. Y. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representa-\ntions. In ICML \u201909: Proceedings of the 26th Annual International Conference on Machine Learning, 609\u2013616 (2009). 58. Masci, J., Meier, U., Cire\u015fan, D. & Schmidhuber, J. Stacked convolutional auto-encoders for hierarchical feature extraction. In Honkela, T., Duch, W., G. & M., S., Kaski (eds.) Artificial Neural Networks and Machine Learning \u2014 ICANN 2011, vol. 6791 of Lecture Notes in Computer Science, 52\u201359 (Springer, Berlin, 2011). 59. Carandini, M. & Heeger, D. J. Normalization as a canonical neural computation. Nature Reviews Neuroscience 13, 51\u201362 (2012). 60. Fairhall, A. L., Lewen, G. D., Bialek, W. & van Steveninck, R. R. d. R. Efficiency and ambiguity in an adaptive neural code. Nature 412, 787\u2013792 (2001). 61. Kohn, A. Visual adaptation: physiology, mechanisms, and functional benefits. Journal of Neurophysiology 97, 3155\u20133164 (2007). 62. Wark, B., Lundstrom, B. N. & Fairhall, A. Sensory adaptation. Current Opinion in Neurobiology 17, 423\u2013429 (2007). 63. Whitmire, C. J. & Stanley, G. B. Adaptation in human and machine perception. Nature Neuroscience 19, 1557\u20131564 (2016). 64. Bedinger, P. A., Broz, A. K., Tovar-Mendez, A. & McClure, B. Recognition and rejection of self in plant reproduction. Science 356, eaaf5566 (2017). 65. Boehm, T. Quality control in self/nonself discrimination. Cell 125, 845\u2013858 (2006). 66. Boehm, T. & Rosenstiel, P. Self/nonself recognition across kingdoms: a review of common and unique mechanisms. Frontiers in Immunology 12, 688095 (2021). 67. Cooper, E. L. Self/non-self recognition in invertebrates. Advances in Experimental Medicine and Biology 708, 130\u2013143 (2010). 68. De Tomaso, A. W. The evolution of self/non-self recognition in colonial ascidians. Current Opinion in Immunology 51, 58\u201364 (2018). 69. Mojica, F. J. & Rodriguez-Valera, F. The discovery of CRISPR in archaea and bacteria. The FEBS Journal 283, 3162\u20133169 (2016). 70. Pradeu, T. Immunity and the emergence of individuality. In Bouchard, F. & Huneman, P. (eds.) From Groups to Individuals: Evolution and Emerg-\ning Individuality, 77\u201396 (MIT Press, Cambridge, MA, 2013). 71. Ruhe, Z. C., Low, D. A. & Hayes, C. S. Bacterial contact-dependent growth inhibition. Trends in Microbiology 21, 230\u2013237 (2013). 72. Tock, M. R. & Dryden, D. T. The biology of restriction and anti-restriction. Current Opinion in Microbiology 8, 466\u2013472 (2005). 73. Witzany, G. & Nowacki, M. Self-nonself recognition in protists and fungi: a review of cellular and molecular mechanisms. Journal of Theoretical Biology 399, 53\u201363 (2016). 74. Frank, D. & Kafkas, A. Expectation-driven novelty effects in episodic memory. Neurobiology of Learning and Memory 183, 107466 (2021). URL https://www.sciencedirect.com/science/ article/pii/S1074742721000885. 75. Shing, Y. L., Brod, G. & Greve, A. Prediction error and memory across the lifespan. Neuroscience & Biobehavioral Reviews 155, 105462 (2023). URL https://www.sciencedirect.com/science/ article/pii/S0149763423004311. 76. Frank, S. A. Circuit design in biology and machine learning. II. Julia software code (2024). URL https://github.com/evolbio/ Circuits_02/releases/tag/Version_1.0.0. 77. Chen, T. & Guestrin, C. Xgboost: A scalable tree boosting system. In KDD \u201916: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 785\u2013794 (2016).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4963/4963fc00-6d4b-413d-8acd-621c5ed30cd4.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Input, u</div>\nFigure 1: Receptor response for atemporal anomaly detection. When the input is at the typical value of \ud835\udc62\u2217= 3, the receptor responds with a minimal value. As the input increasingly deviates from its typical value, the receptor returns an increasing response. The likelihood of an anomalous condition rises with the receptor response value. Thus, this receptor provides a simple atemporal way to classify inputs as normal or anomalous. This figure derives from eqn 3, with \ud835\udc5a1 = 1, \ud835\udc58= 2, and \ud835\udc4eset so that \ud835\udc62\u2217= 3 is a minimum. To get a minimum at \ud835\udc62\u2217, we search for \ud835\udc4esuch that d\u02c6\ud835\udc5f/d\ud835\udc62= 0 and d2\u02c6\ud835\udc5f/d\ud835\udc622 > 0 when evaluated at \ud835\udc62\u2217. For \ud835\udc58= 2 and \ud835\udc5a1 > \ud835\udc5a2, we obtain \ud835\udc4e= \ufffd 2\ud835\udc5a2 1 + \ud835\udc62\u2217+ 4\ufffd\ufffd \ud835\udc5a2 2 + \ud835\udc62\u2217+ 2\ufffd2 \ufffd\ufffd 2\ud835\udc5a2 2 + \ud835\udc62\u2217+ 4\ufffd\ufffd \ud835\udc5a2 1 + \ud835\udc62\u2217+ 2\ufffd2 . As \ud835\udc5a1 and \ud835\udc5a2 become large, \ud835\udc4e\u2192(\ud835\udc5a2/\ud835\udc5a1)2.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e614/e61444a7-f335-4214-be58-92b83c5987d0.png\" style=\"width: 50%;\"></div>\nFigure 2: Receptor response for temporal anomaly detection. (a) The blue input signal, \ud835\udc62, was generated by a stochastic process d\ud835\udc62= 0.0002(10000 \u2212\ud835\udc62) d\ud835\udc61+ 0.02\ud835\udc62d\ud835\udc4a+ \ud835\udc67\ud835\udc62d\ud835\udc41, in which d\ud835\udc4ais a Wiener process that generates continuous Gaussian noise with a mean of 0 and a standard deviation of 1, and d\ud835\udc41is a Poisson jump process that generates random discrete jumps at rate 0.2. Each jump multiplies the current input, \ud835\udc62, by \ud835\udc67, which for each jump takes on a value 0.95 or 1.05 with equal probability. The gold moving average, \ud835\udc62\u2217, is given by eqn 4 with \ud835\udf06= 10. (b) The blue spikes show the timing and direction of the random anomalous jumps for this sample run. The levels of \u00b11 for the spikes are arbitrary values. The gold curve shows the receptor output from eqn 3 multiplied by 25, with \ud835\udc58= 2, \ud835\udc5a1 = 10, 000, \ud835\udc5a2 = 1000, and \ud835\udc4egiven by the solution in the caption for Fig. 1 with \ud835\udc62\u2217= \ud835\udc5a1. The gold receptor spikes match the blue anomalous input jumps, signaling anomalies. The freely available Julia computer code provides full details about assumptions and methods for all figures in this article76.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7698/76984054-5f78-40ce-a0ef-2a8bcbbbefc7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">False predicted anomaly</div>\nFigure 3: Classification of input as typical or anomalous by a circuit that averages \ud835\udc5bindependent input values and makes a decision based on the average value. Inputs are continuous numerical values. In this example, I generated inputs by randomly sampling a normal distribution with a standard deviation of \ud835\udf0e= 40. For typical and anomalous inputs, the distribution means are 100 and 120, respectively. (a) The circuit takes \ud835\udc5b= 1 dimensions of input. The circuit uses a threshold, \ud835\udf0f, such that the circuit classifies inputs below the threshold as typical and above the threshold as anomalous. The curve plots the frequency of truly predicted anomalies as a function of \ud835\udf0fversus the frequency of falsely predicted anomalies as a function of \ud835\udf0f, generating a receiver operating characteristic (ROC) curve. The area under the curve (AUC) measures the resolving power of the circuit that describes the tradeoff between true positive and false positive classifications over all of the thresholds. (b) For each case in which the true generating process is either typical or anomalous, I generated \ud835\udc5bindependent samples for the associated probability distribution. The circuit measures the average of the inputs, which, when compared to the \ud835\udc5b= 1 case in the left panel, has the same mean and a reduced standard deviation, \ud835\udf0e/\u221a\ud835\udc5b= 40/\u221a\ud835\udc5b. The reduced variation provides the circuit with greater resolving power, described by the increasing AUC with increasing \ud835\udc5b.\n<div style=\"text-align: center;\">False predicted anomaly</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7771/7771fb61-7c42-4a03-b852-ecd55fbed335.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">False predicted anomaly</div>\nFigure 4: Anomaly classifier in which each sensor does an analog to digital conversion, with \ud835\udc5b= 1, 4, 16, 64 sensors for curves from bottom to top. The generation of continuous input into each sensor is described in the caption of Fig. 3. In this case, each sensor receives an independent input value and independently scores its input as 0 for typical or 1 for anomalous based on the threshold shared by all sensors. Colored circles on each curve denote particular threshold values for the individual sensors. The overall classification by the circuit depends on the frequency of 1 values returned by the individual sensors. The circuit returns an anomaly if the frequency of 1 values by individual sensors is greater than ceiling(\ud835\udf19\ud835\udc5b)/\ud835\udc5b, in which the ceiling function returns the smallest integer greater than or equal to its argument. (a) Curves for \ud835\udf19= 1/3. (b) Curves for \ud835\udf19= 2/3. Increasing the frequency threshold, \ud835\udf19, lowers both the true and false positive classification rates, which can be seen by comparing the same sensor threshold values between the two panels. When \ud835\udf19= 1/2, the threshold locations, \ud835\udf0f, are intermediate between the two panels. The AUCs are 0.64, 0.72, 0.87, 0.99 for curves from bottom to top in both panels. The AUC values for \ud835\udf19= 1/2 are slightly higher in the third significant digit for larger \ud835\udc5b. Overall, the AUC circuit performance is very flat as a function of varying frequency cutoff, \ud835\udf19, over (1/3, 2/3), suggesting that \ud835\udf19may be a nearly neutral trait over a wide range in the AUC sense of measuring performance over a range of individual sensor thresholds, \ud835\udf0f.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/917b/917bb9c3-fe5e-4b23-bb4a-ac02426d8636.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">False predicted anomaly</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b308/b308996d-0a95-47f3-aa9c-27379dd2825c.png\" style=\"width: 50%;\"></div>\n# Number of sensors, n\n<div style=\"text-align: center;\">Number of sensors, n</div>\nFigure 5: The cost of digitizing the response of individual sensors. The curves show that an increase in the number of sensors, \ud835\udc5b, reduces the total error rate as the sum of the false negative and false positive rates. In prior figures, the false negative rate is the false predicted anomaly rate, and the false positive rate is one minus the true predicted anomaly rate. The lower blue analog curve corresponds to a circuit that averages the values perceived by the \ud835\udc5bindividual sensors. The upper gold digital curve corresponds to a circuit in which each sensor transforms its input into a 0 response when the input value is below a sensor-specific threshold and a 1 response otherwise. For a given number of sensors, \ud835\udc5b, the digital circuit produces more errors because digitization at the individual sensor level loses information.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7db7/7db709aa-c506-4a54-884b-eb5ab6c54432.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 6: Decision trees for an anomaly detection classification problem. The challenge is to classify a multivariate dat input with values \ud835\udc65\ud835\udc56for the \ud835\udc56= 1, . . . , \ud835\udc41data dimensions. (a) A tree of depth 1 that predicts classification based on on feature of a multivariate observation, \ud835\udc651. If \ud835\udc651 is greater than or equal to a threshold, \ud835\udc611, then the tree returns a decisio value, \ud835\udc372. Otherwise it returns \ud835\udc371. If there is only a single tree, then the decision value determines the classificatio Alternatively, there may be an ensemble of trees, each tree analyzing a different data dimension. In an ensemble, eac tree contributes a separate decision value that can be combined with the values from other trees to make an overa classification decision. (b) A tree of depth 2 that uses three different data features.</div>\nFigure 6: Decision trees for an anomaly detection classification problem. The challenge is to classify a multivariate data input with values \ud835\udc65\ud835\udc56for the \ud835\udc56= 1, . . . , \ud835\udc41data dimensions. (a) A tree of depth 1 that predicts classification based on one feature of a multivariate observation, \ud835\udc651. If \ud835\udc651 is greater than or equal to a threshold, \ud835\udc611, then the tree returns a decision value, \ud835\udc372. Otherwise it returns \ud835\udc371. If there is only a single tree, then the decision value determines the classification. Alternatively, there may be an ensemble of trees, each tree analyzing a different data dimension. In an ensemble, each tree contributes a separate decision value that can be combined with the values from other trees to make an overall classification decision. (b) A tree of depth 2 that uses three different data features.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/91ac/91acb5f9-8e5a-4081-9b49-8e40e2b8b963.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\nFigure 7: Performance of boosted decision tree ensembles for classifying typical versus anomalous inputs. Mean scale influences the amount of deviation in mean values between typical and anomalous inputs. F1 score measures the success of a circuit in classifying typical and anomalous data42. That score combines how often a prediction of anomaly is correct with how often an anomalous input is correctly identified. Features is the number of dimensions in the data. Trees is the number of trees in an ensemble circuit. Depth is the depth of each tree in a circuit. The text describes the methods and main conclusions for this figure. I generated one dataset with 32 features and used subsets of the feature data for the various plots so that the correlation structure of the data was consistent between the various comparisons. The boosted tree ensemble was calculated by the widely used xgboost algorithm77. For \ud835\udc47trees each of depth \ud835\udc5b, the total number of splits is \ufffd 2\ud835\udc5b\u22121\ufffd \ud835\udc47.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b815/b81514c6-1b76-43b2-8a26-3b4633e901d5.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\nFigure 8: Encoder model that reduces 4-dimensional inputs to 2 dimensions, separating typical and anomalous observations. I used the same methods to generate the data as for boosted trees, described previously. Of the initial 100, 000 observations, 10% are anomalies, and the rest are typical. I randomly split the data into a training set comprised of 70% of the observations and the remainder in the test set to evaluate the fitted model. This plot shows a random subset of the test data with approximately 2700 typical observations and 300 anomalous observations. Compared with Fig. 9, the mean scale value here is 1.6, and the number of features is 4. I used a distinct dataset for this figure to provide a visualization that shows the separation between typical and anomalous points more clearly. In this case, the F1 score is 0.96, corresponding to relatively few misclassified points. The model encoded the 4 input dimensions to 2 output dimensions with a single layer of a neural network, using 10 parameters.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/126b/126b44b1-f626-4d79-b78b-f94c7e1dd78f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\nFigure 9: Encoder model to separate typical from anomalous inputs. The labels on each curve describe the number of features, \ud835\udc53, in the data. I used the same methods to generate the data as for boosted trees, described previously. (a) I generated three separate input datasets and calculated F1 scores for each to compensate for peculiarities of any particular dataset. I then averaged the three values for each mean scale by feature combination. The overall pattern and magnitudes for each separate dataset were similar. For each dataset, I generated 32 features. I then used the first \ud835\udc53features in the set for each curve. If we compress from inputs with \ud835\udc53= 2\ud835\udc5bfeature dimensions to a single output dimension, then a full encoder model has (2 \ud835\udc53+ 5)( \ud835\udc53\u22121)/3 parameters when \ud835\udc5bis an integer. (b) I began calculation for each point using all 32 features. I then iteratively deleted the single feature that provided the least information, measured by the smallest reduction in F1 when deleting that feature. I continued until the specified number of features for a particular curve remained. This iterative deletion method provided a better set of features than simply picking the first \ud835\udc53features as in (a).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/cdbf/cdbfe9a5-cbe3-4f82-aa86-480ca840fbd9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\n",
    "paper_type": "method",
    "attri": {
        "background": "Anomaly detection is a well-established field in machine learning, identifying observations that deviate from typical patterns. This study emphasizes the limited application of these principles in biological systems and proposes a new conceptual framework for biological circuits inspired by machine learning techniques.",
        "problem": {
            "definition": "The problem addressed is the challenge of effectively detecting anomalies in biological systems using machine learning techniques that are often too large for cellular and physiological applications.",
            "key obstacle": "The primary obstacle is that existing machine learning circuits are often unrealistically large for biological systems, necessitating the development of minimal circuits that can operate at a cellular scale."
        },
        "idea": {
            "intuition": "The inspiration for the proposed idea comes from the observation that both biological and machine learning systems face similar challenges in classifying environmental inputs and responding appropriately.",
            "opinion": "The proposed idea involves the development of small, efficient circuits that can classify anomalies in biological systems, drawing parallels with machine learning methods.",
            "innovation": "The key innovation lies in creating minimal circuits that retain the resolving power of larger machine learning models while being suitable for biological applications."
        },
        "method": {
            "method name": "Minimal Anomaly Detection Circuits",
            "method abbreviation": "MADC",
            "method definition": "MADC refers to a set of small circuits designed to detect anomalies in biological systems by learning internal models of typical patterns.",
            "method description": "The method uses small circuits to classify inputs as typical or anomalous based on deviations from learned patterns.",
            "method steps": [
                "Identify typical input patterns.",
                "Develop a circuit that learns these patterns.",
                "Classify new inputs based on deviations from the learned model."
            ],
            "principle": "This method is effective because it leverages the principles of classification from machine learning while being optimized for the constraints of biological systems."
        },
        "experiments": {
            "evaluation setting": "The experimental setup involved using datasets from biological systems and comparing the performance of MADC with traditional larger machine learning models.",
            "evaluation method": "Performance was assessed using metrics like accuracy, F1 score, and area under the curve (AUC) to determine the effectiveness of the circuits in classifying anomalies."
        },
        "conclusion": "The experiments demonstrated that minimal circuits can effectively classify anomalies in biological systems, highlighting the potential for integrating machine learning principles into biological research.",
        "discussion": {
            "advantage": "The main advantage of the proposed approach is its ability to operate within the size constraints of biological systems while maintaining high classification accuracy.",
            "limitation": "A limitation is the potential oversimplification of biological processes, which may not be fully captured by minimal circuits.",
            "future work": "Future research should explore the refinement of these circuits and their application to a broader range of biological systems, as well as investigating their evolutionary implications."
        },
        "other info": {
            "acknowledgments": "The research was supported by the Donald Bren Foundation, US Department of Defense, and US National Science Foundation.",
            "data availability": "Software to produce the figures is available on GitHub."
        }
    },
    "mount_outline": [
        {
            "section number": "2.3",
            "key information": "Anomaly detection is a well-established field in machine learning, identifying observations that deviate from typical patterns."
        },
        {
            "section number": "2.3",
            "key information": "The primary obstacle is that existing machine learning circuits are often unrealistically large for biological systems, necessitating the development of minimal circuits that can operate at a cellular scale."
        },
        {
            "section number": "3.1",
            "key information": "The proposed method, Minimal Anomaly Detection Circuits (MADC), refers to a set of small circuits designed to detect anomalies in biological systems by learning internal models of typical patterns."
        },
        {
            "section number": "3.4",
            "key information": "The method uses small circuits to classify inputs as typical or anomalous based on deviations from learned patterns."
        },
        {
            "section number": "5.1",
            "key information": "The main advantage of the proposed approach is its ability to operate within the size constraints of biological systems while maintaining high classification accuracy."
        },
        {
            "section number": "7.1",
            "key information": "A limitation is the potential oversimplification of biological processes, which may not be fully captured by minimal circuits."
        },
        {
            "section number": "7.2",
            "key information": "Future research should explore the refinement of these circuits and their application to a broader range of biological systems, as well as investigating their evolutionary implications."
        }
    ],
    "similarity_score": 0.6188698506643009,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Circuit design in biology and machine learning. II. Anomaly detection.json"
}