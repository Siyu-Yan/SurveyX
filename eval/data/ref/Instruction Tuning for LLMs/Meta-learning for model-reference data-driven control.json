{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2308.15458",
    "title": "Meta-learning for model-reference data-driven control",
    "abstract": "One-shot direct model-reference control design techniques, like the Virtual Reference Feedback Tuning (VRFT) approach, offer time-saving solutions for the calibration of fixed-structure controllers for dynamic systems. Nonetheless, such methods are known to be highly sensitive to the quality of the available data, often requiring long and costly experiments to attain acceptable closed-loop performance. These features might prevent the widespread adoption of such techniques, especially in low-data regimes. In this paper, we argue that the inherent similarity of many industrially relevant systems may come at hand, offering additional information from plants that are similar (yet not equal) to the system one aims to control. Assuming that this supplementary information is available, we propose a novel, direct design approach that leverages the data from similar plants, the knowledge of controllers calibrated on them, and the corresponding closed-loop performance to enhance model-reference control design. More specifically, by constructing the new controller as a combination of the available ones, our approach exploits all the available priors following a meta-learning philosophy, while ensuring non-decreasing performance. An extensive numerical analysis supports our claims, highlighting the effectiveness of the proposed method in achieving performance comparable to iterative approaches, while at the same time retaining the efficiency of one-shot direct data-driven methods like VRFT.",
    "bib_name": "busetto2023metalearningmodelreferencedatadrivencontrol",
    "md_text": "# Meta-learning for model-reference data-driven control \nRiccardo Busetto a, Valentina Breschi b, Simone Formentin a\naDipartimento di Elettronica, Bioingegneria e Informazione, Politecnico di Milano, Via Ponzio 34/5, Milano, Italy bDepartment of Electrical Engineering, Eindhoven University of Technology, 5600 MB Eindhoven, The Netherlands\nOne-shot direct model-reference control design techniques, like the Virtual Reference Feedback Tuning (VRFT) approach, offer time-saving solutions for the calibration of fixed-structure controllers for dynamic systems. Nonetheless, such methods are known to be highly sensitive to the quality of the available data, often requiring long and costly experiments to attain acceptable closed-loop performance. These features might prevent the widespread adoption of such techniques, especially in low-data regimes. In this paper, we argue that the inherent similarity of many industrially relevant systems may come at hand, offering additional information from plants that are similar (yet not equal) to the system one aims to control. Assuming that this supplementary information is available, we propose a novel, direct design approach that leverages the data from similar plants, the knowledge of controllers calibrated on them, and the corresponding closed-loop performance to enhance model-reference control design. More specifically, by constructing the new controller as a combination of the available ones, our approach exploits all the available priors following a meta-learning philosophy, while ensuring non-decreasing performance. An extensive numerical analysis supports our claims, highlighting the effectiveness of the proposed method in achieving performance comparable to iterative approaches, while at the same time retaining the efficiency of one-shot direct data-driven methods like VRFT. eess.SY]  29 Au\nKey words: meta-learning, data-driven control, Virtual Reference Feedback Tuning, model-reference control\n# 1 Introduction\nReal-world control applications often require calibrating parametric controllers with the same structure for systems that are similar, yet not identical, in nature and scope. This is the case, e.g., when considering a platoon of mass-produced cars that navigate in diverse environments or a motor undergoing different industrial cycles. In this paper, we will argue that in such contexts the knowledge of the controllers already tuned for some systems within a certain set and the insights into the achievable closed-loop performance might be valuable assets to expedite and enhance the control design process for a new plant belonging to the same family. The enabling technology to attain this goal will be the use of some similarity measures for the considered plants.\n\u22c6This paper is partially supported by the FAIR (Future Artificial Intelligence Research) project, funded by the NextGenerationEU program within the PNRR-PE-AI scheme (M4C2, Investment 1.3, Line on Artificial Intelligence). Email address: riccardo.busetto@polimi.it (Riccardo Busetto).\nRelated literature. A similar argument is at the heart of the so-called meta-learning approaches (see [31,23] and references therein), which rely on a set of meta-data comprising all the knowledge acquired from past experience to enhance the learning of a new model or task, by looking at its similarity with the ones already identified or performed. However, existing meta-learning approaches mainly focus on improving the performance of classification [20,18], model fitting (see e.g., [28]), reinforcement learning algorithms ([10,32,34,16]), or, more recently, on reducing the design effort of global optimization tools [5,8,24].\nIn the systems and control area, strategies exist to exploit similarities for improving model fitting following a federated learning perspective (see e.g., [4,3,9,19] for some examples), whereas only few control design approaches have embraced the meta-learning vision. For instance, the work in [33] deals with the classical problem of identifying a linear model for a linear, time-invariant dynamical system. This work shows that using data collected from a single auxiliary system (similar to the target one) improves the finite sample accuracy of the identified model at the price of introducing a bias dictated by the difference between the auxiliary and the target\nsystems. Shifting from linear to non-linear model fitting, the work in [21] focuses on modeling a set of systems sharing the same (unknown) dynamics while determining their (possibly different) operational contexts. By casting a bilevel optimization problem to learn these unknowns from data coming from multiple systems, the authors show in simulation that the obtained model can be successfully employed within a model predictive (MPC) scheme to control the motion of a planar fully actuated rotorcraft (PFAR), even when its operational context is time-varying. Instead, the Bayesian approach presented in [2] exploits meta-learning principles to enhance the description of modeling errors for a system that has to undertake multiple tasks. In particular, the authors propose to improve the system\u2019s model by exploiting data collected when it performs different assignments, to use such a model in designing model-based controllers, and prove the effectiveness of this choice on both simulated and real hardware robotic applications by coupling their strategy with a learning-based MPC scheme.\nAlthough leveraging the meta-learning rationale, all the existing approaches still focus on learning a model of the system rather than a controller. This transition is performed in [15] and [22]. In particular, the work in [15] focuses on reconstructing a Linear Quadratic Gaussian (LQG) regulator from closed-loop data. By exploiting the separation principle, the authors show how to effectively leverage input/output data sequences gathered by deploying both the target regulator and other LQG controllers designed with different weighting matrices. Nonetheless, their objective is to reconstruct (and thus imitate) an existing controller rather than calibrating one from scratch. Meanwhile, the strategy presented in [22] leverages ensemble models (constructed from different input/output datasets) to retrieve a parametric adaptive controller that effectively copes with unmodelled disturbances. Through simulation examples involving the motion control of planar fully actuated and underactuated quadrotors subject to wind, the authors show the effectiveness of this control-oriented meta-learning rationale and its superiority over a modeloriented one. Nevertheless, this control design approach requires a preliminary identification phase that can be lengthy and expensive, especially if the number of ensemble models is high. Therefore, none of these methods is model-free and tailored to design a controller directly from data.\nContributions. In this work, we target the above research gap by proposing a novel meta-design approach for calibrating fixed-structure controllers directly from data, without requiring any preliminary identification phase. By focusing on controlling a linear time-invariant system with unknown dynamics, the stepping stone of our method is the well-known Virtual Reference Feedback Tuning (VRFT) approach [7,11]. As for this technique, our first contribution (Contribution C1) is thus to carry out a calibration procedure to tightly match the\nbehavior of a user-defined reference model, while at the same time incorporating additional meta-data into the design process, so as to ultimately obtain what we will call the meta-controller.\nMoreover, we will prove (Contribution C3) that the closed-loop matching error attained with the new controller is bounded, and the bound depends on (i) the performance experienced in the meta-dataset and (ii) the similarity of the other plants and the new controlled system. We exploit these theoretical insights to augment the VRFT loss for meta-design with two additional regularization terms (Contribution C4), thus shaping the calibrated convex combination based on data-driven indicators of similarity and measured closed-loop performance.\nNote that our structural choice to consider the convex combination of controllers has never been considered in similar works (see, e.g., [1,17] for approaches exploiting the same structural assumption), as it may lead to stability problems even when all the controllers in the meta-dataset are individually stabilizing the new system. However, by leveraging the seminal work [30], we establish (Contribution C5) theoretical and practical sufficient conditions on the controllers within the metadataset, for their combination to result in a controller that stabilizes the closed loop. We will then translate the above stability constraints into their data-driven counterparts and incorporate them into the direct design procedure.\nAs a final contribution (Contribution C6), we test the proposed approach in the tuning of a PI (Proportional Integral) controller within a field-oriented scheme for brushless DC motors. The natural differences arising between multiple instances of these motors due to the manufacturing process and their operational conditions once deployed, along with the industrial relevance of containing control calibration time for each new motor\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2b97/2b97c3b2-1972-4159-85e5-04f4f8c97d14.png\" style=\"width: 50%;\"></div>\nFig. 1. Scheme of the closed-loop system with the meta\u2013 controller C(\u03b1). The noise-free tracking error is denoted as eo(t) = r(t) \u2212yo(t), while the dependence on the back-shift operator is omitted for the sake of readability. instance, make this example an ideal benchmark to analyze the impact of the meta-learning approach to datadriven design. By using a relatively small dataset gathered from the motor to be controlled, our results show that the proposed meta-design strategy leads to dramatically improved closed-loop performance with respect to those achieved with a controller tuned with the classical VRFT approach. A performance enhancement is experienced with the proposed method even when compared to more robust (and demanding) iterative approaches. The paper is organized as follows. The objectives of the work are introduced in Section 2, along with the first mathematical formulation of the meta-design problem. Its main properties are then discussed in Section 3. Based on these features, we introduce the data-driven counterpart of the considered problem in Section 4. The effectiveness of the proposed direct, meta-design strategy is finally shown in a simulation case study in Section 4. The paper is ended by some concluding remarks.\nNotation. Let N be the set of natural numbers (including zero), R denote the set of real numbers and Rn indicate the set of real column vectors of dimension n. Given a \u2208Rn, we denote its transpose as a\u22a4and k-th component as [a]k, for k = 1, . . . , n. Still considering this vector and an n\u00d7n real matrix A \u2208Rn\u00d7n, we compactly denote the quadratic form a\u22a4Aa as \u2225a\u22252 A. Given a set of matrices {Ak \u2208Rn\u00d7n}N k=1, diag(A1, . . . , AN) \u2208RnN\u00d7Nn is the block-diagonal matrix having them as its diagonal entries. Given a stochastic process v \u2208R, its expected value is E[v] while its variance is denoted as var[v]. The uniform distribution within the interval [a, b] is denoted as U[a,b].\n# 2 Setting and goal\nConsider a plant G within the class of systems described by the following linear, time-invariant input/output relationship: \u2212\n(1)\nwhere u(t) \u2208R is the input at time t \u2208N, yo(t) is the corresponding noiseless output, and G(q\u22121) is an unknown, proper rational function in the back-shift operator 1 q\u22121. Our aim is to design a parametric controller for this system within the class\n(2)\n\ufffd \ufffd\ufffd \ufffd for the closed-loop system to match a desired response yd(t) to a reference r(t) for all t, with \u03b8 \u2208Rn\u03b8 being the set of parameters to be tuned and \u03b2(q\u22121) \u2208Rn\u03b8 being a vector of prefixed, rational basis function in q\u22121. The desired behavior is here dictated by a stable, user-defined reference model M, characterized by the relationship:\n(3)\nwhere M(q\u22121) is a proper, rational function in q\u22121 dif ferent from the unitary gain (i.e., M(q\u22121) \u0338= 1).\nAlthough the true system dynamics is unknown, suppose that we have access to a finite set of input/output data 2 DT = {u(t), y(t)}T t=1 gathered from G, where y(t) is defined as\n(4)\nand v(t) is the realization of a zero-mean noise at time t. In addition, assume that we have information on N \u22651 plants {Gk}N k=1, whose dynamics is also unknown but nonetheless similar to that of G according to the following definition. Definition 1 (\u03b5-similarity) Two systems G1 and G2 within the class G in (1) are said to be \u03b5-similar if the following property holds:\nSpecifically, let us suppose to have access to the following data.\n(1) A set of controllers Ck = C(q\u22121; \u03b8k) \u2282C(\u03b8), k = 1, . . . , N, which stabilize the corresponding plants Gk in closed-loop and have been tuned with any of the existing data-driven, model-reference strategies to match the reference model M in (3). (2) The input/output pairs Dk T = {u(t), yk(t)}T t=1 used for such a tuning procedure, that share the same inputs of DT while featuring outputs corrupted by a zero-mean noise vk(t), namely\n1 q\u2212iu(t) = u(t \u2212i), \u2200i \u2208Z. 2 Data can be collected in open-loop when G is stable, otherwise they can be gathered from closed-loop experiments, provided a stabilizing (even if poorly performing) controller is available.\nThese elements constitute what we indicate as the metadataset:\nD  { D  D } that, together with DT , represent the set of all the information at our disposal to design the controller for G, namely\nD  { D  D } that, together with DT , represent the set of all the information at our disposal to design the controller for G,\n(8)\nInstead of designing the new controller C(\u03b8) for G from DT only, in this work we propose to leverage all the available information in D to design (in a model-reference fashion) the meta-controller C(\u03b1) \u2282C(\u03b8) characterized by:\n(9a)\nLet Jk define the loss associated with the k-th controller Ck \u2208Dmeta N , namely\nwith\n(9c)\nnamely the controller given by the convex combination of those available within the meta-dataset Dmeta N .\nBy referring to the closed-loop in Fig. 1, this meta-design problem can be formalized as:\n(10a)\nwhere\n\ufffd\ufffd\ufffd\ufffd\ufffd 2 (10e)\n\ufffd\ufffd\ufffd and F(q\u22121) is any user-defined weighting filter.\nBefore shifting our attention to the data-driven counterpart of (10), let us shed light on the performance one\nwould attain by solving this ideal meta-control problem and, consequently, introduce some changes in the original formulation to enhance the design process. To this end, we rely on the following approximation [30, Section 2] of the loss in (10):\n(11)\nwhere \u039e(q\u22121) = 1\u2212M(q\u22121). For the sake of simplifying the notation, in the following we do not explicitly show the dependence on the backward-shift operator q\u22121.\n3.1 Non-deteriorating performance\nWhen the unknown system G is not just similar but equal to one of the plants Gk on which Dmeta N is build upon, with k \u2208{1, . . . , N}, solving (10) should either enhance the closed-loop matching performance with respect to the ones attained with Ck \u2208Dmeta N or, in the worst case, retain the ones achieved with it.\n(12)\n(13)\nThen, we can formalize the first property of the metacontroller as follows.\nThen, we can formalize the first property of the metacontroller as follows. Proposition 1 (Non-deteriorating performance) Let us assume that there exists one and only one k \u2208{1, . . . , N} such that the unknown plant G satisfies\n(14)\nand that the controllers corresponding to the other plants are non-canceling, namely\n(15)\nif and only if [\u03b1]i = 0, for all i \u0338= k with i = 1, . . . , N. Then, the optimal tuning \u03b1\u22c6in (13) is such that\n(16)\nProof According to (12), let us rewrite J(\u03b1) in (11) as J(\u03b1)\u2248\u2225[F\u039eM \u2212F\u039e2CkG]+F\u039e2 [Ck\u2212C(\u03b1)] G\u22252.\n(17)\n\ufffd \ufffd\ufffd \ufffd with \u2206Jk(\u03b1) being non-negative by definition. Its minimum value \u2206Jk(\u02dc\u03b1) = 0 is attained when\nJ(\u02dc\u03b1) \u2264Jk + \u2206Jk(\u02dc\u03b1) = Jk.\nSince, by definition J(\u03b1\u22c6) \u2264J(\u00af\u03b1), this ends the proof. \u25a1\n3.2 Performance bounds\nToward establishing if and when the choice of designing C(\u03b1) (meta-learning) instead of C(\u03b8) (standard datadriven design) can be effective, it is fundamental to analyze the relationship between the closed-loop performance attained with the meta-controller and the actual similarity between G and {Gk}N k=1, along with its link to the closed-loop performance achieved by the controllers in the meta-dataset (7).\nWith this in mind, let us introduce\n(18)\n\ufffd\ufffd \ufffd\ufffd indicating the performance attained by deploying the controller Ck in feedback with the system Gk, for k = 1, . . . , N. Moreover, let us express the new plant G as a function of the k-th system within the dataset, i.e.,\n(19a)\nwhere\n(19b)\n\u2225\u2225 \u2264 according to Definition 1 for some (unknown) \u03b5, and \u2206Gk = 0 only when G and Gk are equal, for k = 1, . . . , N.\nWe can now formalize the relationship between J(\u03b1) in (10e) and { \u02dcJk, \u2206Gk}N k=1 as follows.\nProposition 2 (Bound on performance) Let G and {Gk}N k=1 verify (19) for some (unknown) \u03b5. Then, for all \u03b1 satisfying (10c)-(10d) it holds that:\n(20a)\nwith { \u02dcJk}N k=1 defined as in (18) and\n(20b)\nProof Consider the approximation in (11) and replace C(\u03b1) with its definition in (9), namely\n(21)\n\ufffd\ufffd which we can be equivalently recast as\n (22)\n\ufffd\ufffd \ufffd\ufffd based on (19). Thanks to (10d), it further holds that\nwhere the last equality holds thanks to (10c). Then, the bound in (20a) straightforwardly follows from the definitions in (18) and (20b), with the upper-bound on Sk being an immediate consequence of the Cauchy\u2013Schwartz inequality and the bound in (19b). \u25a1\nProposition 2 is a quantitative argument in favor of the (intuitive) fact that \u03b1 \u201cprioritizing\u201d controllers in\n(23)\nfor i, k = 1, . . . , N and i \u0338= k, lead to lower upper bounds on the cost (and potentially lower values of J(\u03b1)).\n3.3 Closed-loop stability\nBy solving (10), we have no guarantees that the metacontroller C(\u03b1) would lead to a stable closed-loop system. Inspired by [30], we now point out the features that the controllers in the meta-dataset should enjoy to guarantee the stability of the meta-closed-loop, ultimately allowing us to integrate a sufficient condition for closedloop stability in the meta-design problem.\nTo this end, let us now introduce the following quantity\n\u2206k = M \u2212CkG\u039e,\n(24)\nthat depends on the k-th controller within the metadataset, the reference model (3) and the unknown plant G, for k = 1, . . . , N. By relying on this definition, consider the following property for a certain controller Ck in Dmeta N . Assumption 1 Ck \u2208Dmeta N is such that:\nA.1 \u2206k in (24) is stable; A.2 \u2203\u03b4k \u2208(0, 1) so that\n(25)\nAccording to [30, Theorem 1], this implies that Ck stabilizes the plant G. We can now formalize the following result. Proposition 3 (Meta-stability condition) The controller C(\u03b1) stabilizes the system G if Assumption 1 is satisfied by all Ck \u2208Dmeta N , with k = 1, . . . , N. Proof Along the line of [30, Theorem 1], C(\u03b1) stabilizes the system G if\nP.1 \u2206(\u03b1) = M \u2212C(\u03b1)G\u039e is stable; P.2 \u2203\u03b4 \u2208(0, 1) such that \u03b4(\u03b1) = \u2225\u2206(\u03b1)\u2225\u221e\u2264\u03b4\nTherefore, we have to show that these sufficient conditions are verified under our assumptions. To this end, let us exploit the definition of the meta-controller (9) to recast \u2206(\u03b1) as:\n(26)\nwhere the last equality follows from (24). Since {\u2206k}N k=1 are stable according to Assumption 1 and computing their convex combination does not change their poles, then \u2206(\u03b1) is also stable, ultimately proving P.1. To show that P.2 holds, let us still rely on the equality in (26). By using the triangle and the Cauchy\u2013Schwartz inequalities, it is straightforward to prove that\nwhere the last equality holds thanks to (10c) and Assumption 1. To complete the proof we have now to show that the upper-bound \u03b4 in (27) lays in the interval (0, 1), which can be easily proven by relying once more on Assumption 1. To this end, let us define:\n(28)\nwith \u00af\u03b4 < 1 and \u03b4 > 0 since \u03b4k \u2208(0, 1) for all k = 1, . . . , N thanks to Assumption 1. Accordingly, the following holds:\n(29b)\n\u25a1\n\ufffd\ufffd\ufffd\ufffd also thanks to (10d), and this concludes the proof. \u25a1 Remark 1 Assumption 1 may sound like a strong requirement as G is unknown. However, when \u03b5 is not too large, e.g., when the systems Gk represent several instances of the same batch production, and Ck are tuned with a suitably stability margin, it is likely that - although the performance may vary for different k\u2019s - the controllers will not destabilize G. Note also that A.1 in Assumption 1 can be satisfied by following the guidelines provided in [30, Section 2] when tuning {Ck}N k=1. Finally, if for any reason we doubt this assumption is not satisfied by one of the controllers in the meta-dataset, the latter can be discarded and C(\u03b1) can be constructed based on a reduced meta-dataset Dmeta N\u22121. This will be shown to be doable in a realistic setting in Remark 4.\nTo guarantee the verification of P.2 (see again the above proof) we can directly enforce this condition as a con-\n(30a)\nwhere \u03b4 \u2208(0, 1) becomes a tunable parameter, whose choice might lead to a (more or less) conservative tuning of C(\u03b1).\n3.4 Enhancing (10) with regularization\nAs highlighted by Proposition 2, the loss J(\u03b1) in (10e) is upper-bounded by the convex combination (through \u03b1) of the losses { \u02dcJk}N k=1 characterizing the matching performance of the controllers within Dmeta N , and the similarity between the new plant G and {Gk}n k=1. Therefore, encouraging the choice of higher coefficients [\u03b1]k, with k \u2208{1, . . . , N}, for those controllers that are characterized by small losses (and, thus, better matching performance), while being designed to control plants that are more similar to G, would eventually result in improved performance of the meta-controller.\nTo steer \u03b1 towards a choice aligned this rationale, we propose to augment the matching cost J(\u03b1) in (30) with two regularization terms, shaping \u03b1 based on experienced performance and plants similarities. Accordingly, the meta-design problem in (30) can be transformed as follows:\nAccordingly, the input generated by the meta-controller has to be equal to that comprised in DT . This allows us to cast the data-driven matching loss as\n(31a)\n(31b) (31c) (31d) (31e)\n(31b)\nwhere uL(t) and eL v (t) are obtained by filtering the input and virtual error with L(q\u22121) defined as\nwhere RJ : RN \u2192R and RS : RN \u2192R are two (possibly different) regularization functions, \u02dcJ = { \u02dcJk}N k=1, \u2206G = {\u2206Gk}N k=1, while \u03bbJ, \u03bbS \u22650 are tunable penalties that modulate the relative importance of the regularization terms with respect to the matching loss.\nThe upgraded final meta-design problem in (31) (with respect to (10), it incorporate a stability constraint and suitable regularization terms) is not yet applicable to a real-world problem. Indeed, it still depends on the input/output relationship of the controlled system G, the ideal performance \u02dcJ of the controllers in the metadataset and the mismatch \u2206G between G and the other plants {Gk}N k=1. All the above details are not known nor directly accessible. Instead, only D in (8) is available to solve the meta-design problem. Hence, in this section, our goal is to translate (31) into its purely direct, datadriven counterpart, thus applicable in a realistic setting.\n# 4.1 A data-driven reformulation of J(\u03b1)\nBefore shifting from the loss J(\u03b1) in (10e) to its databased counterpart, let us initially replace it with its square:\n\ufffd\ufffd \ufffd\ufffd which results in a design problem that is easier to handle numerically. We can now follow the footsteps of the VRFT approach [7] to transition toward the data-driven loss. Hence, we define the virtual reference as the set point that would return the measured outputs if fed to the reference model, namely\nin turn resulting in the virtual tracking error\n(34)\n(35)\n(36)\nwith \u03a6u being the spectral density of the input signal in DT . Remark 2 (On the choice of L(q\u22121)) Since the squared loss in (32) corresponds to the standard objective\n (37)\n\ufffd \ufffd the reasoning carried out in [7, Section 3] for the selection of L(q\u22121) applies to the considered problem. Remark 3 (Retrieving rv(t)) For the virtual reference to be computed, one needs to invert the reference model. However, this inverse is non-causal every time M(q\u22121) is a strictly proper rational function. This issue can be overcome by manipulating the reference model as discussed in [12, Proposition 1 and Section 7], in turn resulting in a reduction of the samples available for design. While allowing us to remove the dependence on the plant model, (35) is not yet designed to counteract the impact that noisy data have on meta-design. Once again, we overcome this issue by echoing the VRFT approach and resorting to an instrumental variable scheme [26]. Specifically, we assume to perform an additional experiment on the plant G by feeding it with the same input sequence {u(t)}T t=1 in DT . This allows us to gather a new set of outputs {yIV (t)}T t=1, corrupted by measurement noise uncorrelated with the one affecting the outputs already available in DT . We can now construct the instrument as\n(38)\nwith \u03b2meta(q\u22121) defined as in (37), and recast the datadriven cost as\n(39)\nTo obtain the data-driven counterpart of the stability constraint in (31e) we rely on the strategy already proposed in [30], which we recall only for the case of stable and minimum-phase G due to its relevance for our numerical example 3 .\nSuppose that the data in DT satisfy the assumptions in [30, Section 4]. In this scenario, let us introduce\n\ufffd (40)\n\ufffd \ufffd\ufffd \ufffd which allows us to link the quantity whose infinity norm we aim at bounding (see (27)) and the available data.\n3 Nonetheless, the extension to unstable and non-minimumphase plants is straightforward following [30] and the approach of this section.\nNote that the last approximation is due to the fact that we are neglecting the impact of measurement noise, which is nonetheless legitimate when the measurement noise and the input sequence in DT are uncorrelated (see [30, A4, Section 4]). By relying on (40), \u03b4(\u03b1) in (30e) can be approximated as\n(41)\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd where \u03c9i = 2\u03c0i/(2\u2113+ 1), for i = 0, 1, . . . , \u2113+ 1, and\nwith j denoting the imaginary unit, and\nbeing the sampled auto-correlation of the input and cross-correlation between the input and es in (40). Note that the approximation in (41) depends on the window length \u2113, which is an additional hyper-parameter of the design problem. The reader is referred to [30] for additional insights on the derivation of this approximation. Remark 4 (Checking Ck \u2208Dmeta N ) Apart from being used to approximate \u03b4(\u03b1) in (31e), the previous strategy can be used to approximate \u2225\u2206k\u2225\u221ein (25), for k = 1, . . . , N. In turn, this allows us to empirically evaluate if the controllers added to the meta-dataset stabilize G, eventually discarding them if they do not satisfy the data-driven stability condition \ufffd \u2225\u2206k\u2225\u221e\u2264\u03b4k.\nLet us then focus on the two regularization terms in (31a). To translate them into their data-driven counterparts, we have to define two data-driven indicators for the experienced performance and the plants\u2019 similarities to replace \u02dcJ and \u2206G, respectively.\nUnder the assumption that the controllers in the metadataset have been deployed and tested in closed-loop, we propose to substitute \u02dcJ with the squared (observed) closed-loop matching error\n(42)\nwhere yd(t) is the desired output for a prefixed reference \u02dcr(t) over T cl time steps, while ycl k (t) is the observed closed-loop output comprised in Dmeta N , for k = 1, . . . , N and t = 1, . . . , T cl. Meanwhile, since we assume that both DT and Dk T comprise the same input sequence, we exploit the squared difference between the measured open-loop outputs as a proxy of \u2206G, i.e.,\nThis choice is in line with our definition of similarity, according to which two plants are similar if the average gain of their difference is limited at all frequencies.\nNote that, both \u02dcJd k in (42) and Sk in (43) are built from noisy data, whose impact on their statistical means is formalized in the following lemmas 4 . Lemma 1 (Mean features of \u02dc Jd k) Given \u02dcJd k in (42), assume that the measurement noise vcl k acting on the k-th closed-loop output ycl k is zero-mean. Then:\n(44)\nwith\n(45)\nProof By the superimposition principle, the error characterizing (42) can be equivalently rewritten as\nSince Ck stabilizes Gk in closed-loop by construction, the auto-regressive process \u02dcvcl k resulting from this decomposition is weak-sense stationary. Therefore, its mean value is constant over time, and it is equal to zero because of our assumption on vcl k . The result in (44) follows straightforwardly by bringing the term dependent on yd(t)\u2212yo,cl k (t) outside the expectation, since it is deterministic. \u25a1 This result allows us to highlight the connection between the selected data-driven performance index and \u02dcJk. In particular, the first term on the right-hand-side of (44) can be equivalently rewritten as\nThis result allows us to highlight the connection between the selected data-driven performance index and \u02dcJk. In particular, the first term on the right-hand-side of (44) can be equivalently rewritten as\n4 With a slight abuse of notation, stochastic processes will be denoted by dropping their dependence on t.\n(46)\n\ufffd\ufffd \ufffd\ufffd where \u02dcr compactly denotes {\u02dcr(t)}T cl t=1, and the first element on the right-hand-side of the inequality corresponds to \u02dcJ2 k for F(q\u22121) = 1. Lemma 2 (Mean features of Sk) Assume that the zero-mean noise sequences acting on the outputs comprised in DT and Dk T are uncorrelated, namely\nwith v and vk introduced in (4) and (6), respectively. Then:\nAccordingly, the normalized expected value of Sk becomes\nwhere the first term is outside the expectation as it is deterministic, while mixed products disappear since v and vk are both assumed to be zero mean. The result in (47) follows by further decomposing the square of the second term on the right-hand-side of the previous equality and by exploiting the lack of correlation between v and vk. \u25a1\nThis lemma allows us to bridge between \u2206Gk and the chosen data-based index. Indeed, the first term in (48) can be rewritten as\n(49)\nthus depending on the similarity between G and Gk (see (19)). At the same time, these results indicate that (as expected) noise impacts on the average values of the proposed (normalized) indexes through its variance. In turn, this might make these indicators poor evaluators of similarities and observed performance when the noise is particularly high. Future work will thus be devoted to refine these indexes toward reducing the influence of noise on the regularization penalties.\nCombining all the previous \u201cingredients\u201d, we can finally write the numerically tractable, data-driven counterpart of the ideal problem in (31) as\n(50a)\n(50c)\n(50e)\nwhere \u02dcJd = { \u02dcJd k}N k=1 and S = {Sk}N k=1.\nIn what follows (including the numerical example), we will consider the following as a reasonable choice of the regularizers:\n(51a)\nwith\n(51b)\nIn other words, we use our insights on similarity to promote shrinkage within \u03b1 in (9) via the 1-norm regularization. This choice is coherent with the idea that controllers designed for systems that are more similar to G are also more likely to be effective on the latter. At the same time, thanks to the performance-oriented Tikhonov regularizer, we steer the elements of \u03b1 towards similar values if they are associated to controllers that have been proven to perform comparably, while shrinking them whenever the experienced performance are poor. We wish to stress that these are only two possible regularization options, which we will compare to other alternatives in future works.\n# 5 Meta-FOC of a brushless DC motor\nWe now assess the impact of the proposed strategy on a problem of practical relevance, namely the calibration of the PI controller within a Field-Oriented Control (FOC) scheme for the regulation of a brushless DC motor, according to the scheme in [6]. The controller in charge of generating the quadrature axis current u(t) [A] belongs to the following family:\n(52)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e3a4/e3a40918-64ee-425c-8931-e630feda5756.png\" style=\"width: 50%;\"></div>\nFig. 2. Average magnitude of the frequency response of the family of DC motors (black line) and interval in which the other possible responses may lay (shaded area).\n<div style=\"text-align: center;\">Fig. 2. Average magnitude of the frequency response of the family of DC motors (black line) and interval in which the other possible responses may lay (shaded area).</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7a48/7a48bf92-5880-4e5f-8cf2-f2d0ca00a5ab.png\" style=\"width: 50%;\"></div>\nFig. 3. Current/speeds pairs collected in open-loop from the N meta-motors. The black line indicates their average output, while the shaded area spotlights the outputs\u2019 possible deviations. where T = 0.02 [s] denotes the sampling time. Our goal\nFig. 3. Current/speeds pairs collected in open-loop from the N meta-motors. The black line indicates their average output, while the shaded area spotlights the outputs\u2019 possible deviations. where Ts = 0.02 [s] denotes the sampling time. Our goal is to calibrate \u03b8 in (52) for the closed-loop, noiseless motor speed yo(t) [rpm] to match the output of the ideal target behavior dictated by\n(53)\nIn our simulations, we generate data assuming the dynamical structure of the motor to be given by\n(54a)\nwith p1 = 0.9975, \u03ba \u2208[1.00, 5.75], and p2 \u2208[0, 0.9]. The resulting family of motors has a frequency response with magnitude reported in Fig. 2, and a level of similarity \u03b5 = 784.55 (see again (5)). Both G, indicated from now on as the new motor, and the N = 10 ones used to construct the meta-dataset (that we will refer to as metamotors) are uniformly sampled at random from this family, i.e., the parameters characterizing their dynamics are extracted based on the following sampling rules:\n(55)\nIn our tests, we always consider 10 different realizations of the new motor, for the outcome of our analysis not to\nbe linked to a specific realization of the system\u2019s parameters. We wish to remark that (54), along with the true parameters characterizing the dynamics of each motor, are assumed to be unknown and, thus, not exploited for design purposes.\nThe data collected from the N = 10 meta-motors are further used to design 10 different controllers with the structure in (52). To this end, here we employ the direct (model-reference) control strategy proposed in [6] 5 . The latter entails a closed-loop calibration experiment, that we have carried out for 3 [s] by considering a step reference with amplitude 1000 [rpm]. Note that, apart from stabilizing the plant each controller has been designed for all these N = 10 data-driven controllers stabilize all the new motors we have extracted and tested. Hence, they are never discarded from the meta-dataset. In learning the meta-controller, we consider a unitary weighting filter F(q\u22121) (see the ideal cost in (10e)), while we use the regularization terms introduced in Section 4.4.\nAll results reported hereafter have been obtained by solving the optimization problem in (50) with the CVX package [13,14] on an Intel(R) Core(TM) i7-10875H CPU @ 2.30GHz processor with 16 GB of RAM running MATLAB R2021b.\n# 5.1 The benefits of meta-design\n5.1 The benefits of meta-design\nWe initially compare the performance attained by deploying the meta-controller calibrated by solving problem (50) (with penalties fixed at \u03bbJ = 30 and \u03bbS = 300) and two others, respectively tuned with the iterative method proposed in [6] and the VRFT approach [7]. In solving (50) and using the approach proposed by [6]\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fe61/fe61c38b-c4a1-4342-a80d-c0b282942fc7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(c) Controller tuned with the c-VRFT approach</div>\nFig. 4. Comparison of data-driven techniques: set point (black line) and desired response (dashed red line) vs mean (colored line) and standard deviation (shaded area) of the closed-loop responses attained with different controllers.\nwe neglect the stability constraint (see (50e) and [30, Section 4], respectively), as both methods always result in stable closed-loops. This is not the case with the VRFT approach that, without the stability constraint, results in unstable closed-loop behaviors in 50% of the tested cases. We have thus decided to consider the VRFT scheme equipped with the stability constraint with \u03b4 = 0.5 for our comparison to be fairer (a.k.a., not biased by the unstable behaviors).\nRemark 5 (Practical choice \u2113) A window of length \u2113= 200 is generally used when computing \u02c6\u03b4(\u03b1), as discussed in Section 4.2. Nonetheless, sometimes this choice leads to a failure of the employed solver [27,29]. In this case, \u2113is decreased to 10 and then successively increased up to the maximum value for which the solver is able to retrieve a solution for (50). Note that this operation increases the computational time needed to design the controller.\nBy looking at the responses reported in Fig. 4, it is clear that the meta-controller and the one tuned with SMGO-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ba9e/ba9e7a13-5cac-434a-b2bb-d8afc7dafb03.png\" style=\"width: 50%;\"></div>\nFig. 5. Comparison of data-driven techniques: mismatching error (left panel) and tuning time (right panel). The time required for calibration includes that to carry out all the needed experiments, which are 2 for both the meta-learning and the VRFT approach with stability constraint (c-VRFT), and equal to the number of iterations for SMGO-\u2206.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fdac/fdacf996-ae35-4546-99c4-6db2a53d7814.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 6. Comparison with the \u201ctrivial\u201d meta-controller: set point (black line) and desired response (dashed red line) vs mean (colored line) and standard deviation (shaded area) of the attained closed-loop outputs.</div>\n\u2206lead to similar closed-loop performance, allowing the closed-loop system to mimic the desired behavior. Even if the second controller enables the closed-loop system to attain an average response that is closer to the desired one, this slight improvement in the average matching comes at the price of a considerable increase in tuning time (see Fig. 5). Instead, the VRFT approach returns controllers that result in considerably poorer performance, both in tracking the desired response and the reference signal, most probably due to the limited dimension of the considered dataset DT . These results clearly show the benefits of the proposed meta-learning rationale, which allows for a trade-off between tuning time/effort and performance.\nAs a final remark for this section, we wish to stress the importance of optimizing the weights of the metacontroller, more than simply using the information coming from the meta-dataset. Let us consider the \u201ctrivial\u201d\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a0cc/a0ccd502-bb7f-4107-9907-c04362569a0d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3c2e/3c2e7657-7033-41fd-9e53-1d8d8c50475f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/688c/688ca820-557e-4667-9bce-d3dff372088f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(c) Elements of \u03b1</div>\nFig. 7. Overview of the meta-dataset and outcomes of meta\u2013 control design over different experiments: darker circles for the similarity indexes and the values of [\u03b1]k indicate the values that occur more frequently.\nmeta-controller as the one with\nThe comparison in Fig. 6 shows that such a controller results in worst matching throughout the transient with respect to the optimized one. This result is somehow expected, since the proposed tuning strategy actually leverages all information available in D (see (8)) to calibrate the controller, including insights on the similarities between plants and the performance experienced with the different controllers. In turn, this leads the optimizer to \u201cprefer\u201d some controllers within the metadataset over others, with the least performing ones that are either never or rarely considered in the construction of the controller for the new motor (see Fig. 7).\nWe now empirically evaluate the capability of C(\u03b1) to result in non-deteriorating performance, to test the robustness of the property in Proposition 1 in a non-idealized\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8168/81689397-289e-4425-b79d-ee5560320294.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) \u03bbS = 300</div>\n<div style=\"text-align: center;\">(b) \u03bbS = 3000</div>\n<div style=\"text-align: center;\">Fig. 8. Non-deteriorating performance with \u03bbJ = 30: 2-norm of the mismatching error in closed-loop.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/caf2/caf24e85-18d5-413f-8652-357db31cb276.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) \u03bbS = 300</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/26db/26dbc6a7-60a1-4246-b66c-5e64406cbd5a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) \u03bbS = 3000</div>\n<div style=\"text-align: center;\">Fig. 9. Non-deteriorating performance with \u03bbJ = 30: 2-norm of the mismatching error in closed-loop for each of the 10 tests picking one of the motors in Dmeta.</div>\nsetting. To this end, we still consider 10 different new motors, that are in turn equal to one of the meta-motors used to construct Dmeta N .\nAs shown in Fig. 8 and Fig. 9, the proposed meta-control rationale generally allows us to attain improved or, at least, similar model-reference matching with respect to the one achieved by using the controllers in the metadataset depending on the chosen trade-off between \u03bbS and \u03bbJ in (50a). Indeed, lower values of \u03bbS tend to enhance the overall performance attained by using the meta-controller with respect to that achieved leveraging the controllers within Dmeta (as also confirmed by the closed-loop responses shown in Fig. 10). This improvement comes at the price of having two instances (namely, G1 and G8) for which the meta-controller results in a slight deterioration of performance. Nonetheless, by increasing \u03bbS to 3000, the performance of the\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d4e8/d4e86781-e502-4085-bd9b-1044f3c0324a.png\" style=\"width: 50%;\"></div>\nFig. 10. Non-deteriorating performance with \u03bbS = 300 and \u03bbJ = 30: and mean (line) and standard deviation (shaded area) of closed-loop responses contained in the meta-dataset [top panel] and attained with the meta-controller [low panel] vs the desired output (dashed red line).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/76eb/76ebc0f9-a6e2-4e5a-ba3b-565c5dffe2ff.png\" style=\"width: 50%;\"></div>\nmeta-controller are indeed non-deteriorating, even if the difference in the closed-loop matching attained with the meta-controller and the ones within Dmeta becomes overall less relevant.\nThese results thus show that the proposed approach can recognize the meta-motor equal to the new one (thus prioritizing the associated controller), while still generally benefiting from performing controllers tailored to metamotors that are also similar to the new one as long as \u03bbS does not excessively dominate over \u03bbJ.\n# 5.3 Sensitivity analysis to the regularization penalties\nGoing back to the scenario where the N = 10 new motors are sampled at random, we now evaluate the sensitivity of the attained closed-loop response to the choice\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3808/3808b469-cc35-4bb4-aa73-3175cbc05e9f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 12. Average 2-norm of the closed-loop mismatching error \u03f5d [rpm] vs dimension of the meta-dataset and number of SMGO-\u2206iterations. Dmeta (70) and Dmeta (140) denote the results obtained by running SMGO-\u2206for 70 and 140 iterations, respectively.</div>\nFig. 12. Average 2-norm of the closed-loop mismatching error \u03f5d [rpm] vs dimension of the meta-dataset and number of SMGO-\u2206iterations. Dmeta (70) and Dmeta (140) denote the results obtained by running SMGO-\u2206for 70 and 140 iterations, respectively.\nof \u03bbS and \u03bbJ in (50), while still neglecting the stability constraint. The results of our analysis are reported in Fig. 11, clearly showing that the meta-control design procedure tends to result in poorer performance when both regularization penalties are low, especially for what concerns \u03bbS. This result is somehow expected since low values of \u03bbS do not leverage insights on the plant similarities. At the same time, also high values of \u03bbS result in a drop in performance. In this case, (50) tends to prioritize controllers based on their similarity only, even when the performance already experienced with them is poor. In turn, this potentially hampers the achievement of the desired closed-loop behavior. Fig. 11 further highlights the importance of retaining lower values of \u03bbJ, due to the fact that higher \u03bbJ would result in prioritizing performance over similarity. This might be undesired, especially when the most performing controllers in Dmeta N are the ones associated with meta-motors that are more different from the new one. Note that even when \u03bbS = \u03bbL = 0 the meta-controller attains an average 2-norm of the matching error in closed-loop of about 244.54 [rpm], which is comparable to the one achieved by designing a brand new PI with the VRFT approach, that is equal to 241.35 [rpm].\n# 5.4 On the impact of the meta-dataset\u2019s features\nWe now focus on how the performance attained with the meta-controller is affected by the size N of the metadataset and the \u201cquality\u201d of the included controllers. To this end, we consider 14 meta-datasets of increasing dimension 6 , and two possible values for the maximum number of iterations of SMGO-\u2206, namely 70 and 140. As expected, Fig. 12 highlights that closed-loop matching generally improves when more iterations of SMGO\u2206are performed, concurrently with a decrease of the av-\n6 The meta-dataset of size N = 10 corresponds to the one used in all other analysis, while Dmeta N\u22121 \u2282Dmeta N .\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2bac/2bac6260-d330-4924-8cd9-16fcae3c39db.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) Matching performance and tuning time</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5293/5293ec8a-481e-4b35-b86f-ff6fcadfa3a6.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) attained closed-loop responses</div>\nFig. 13. Meta-control design with stability guarantees: set point (black line) and desired behavior (red dashed line) vs mean (colored lines) and standard deviation (shaded areas) of the responses obtained with the meta-controllers designed with and without the stability constraint. The former is denoted as c-META. erage value of the index \u02dcJd k 7 . Only the results obtained for N = 2 are not consistent with this trend, because the limited dimension of the meta-dataset hampers the overall closed-loop behavior and, thus, the matching performance. Meanwhile, performance tends to improve up to N = 4, then reaching a plateau (on average). This outcome indicates that, at least for the example at hand, a meta-dataset of dimension N = 4 would be sufficiently informative to design a performing meta-controller.\n# 5.5 The effect of the stability constraint\nWe finally incorporate the stability constraint into the design problem, solving (50) for \u03b4 = 0.5, as employed in c-VRFT. The window length \u2113needed as for Section 4.2 is once again chosen as detailed in Remark 5.\nSince the introduction of the stability constraint has not resulted in changes in performance (but only in an increased design time) with the level of noise considered in the previous analysis, we now increase the standard deviation of the noise corrupting the outputs in DT to 40 [rpm] (SNR = 10.61 [dB]), while keeping the metadataset of size N = 10 unchanged with respect to the\none exploited in the other analysis. The results we obtained are reported in Fig. 13. Clearly, they show that the introduction of the stability constraint in this more challenging setting can be of help in effectively coping with the noise acting on the data. Indeed, we observe a significant reduction in instances where matching performance get further away from the average. This benefit comes at the price of an increased design time (see Fig. 13(a)), whose considerable variance is linked to the procedure exploited to adjust the window length \u2113every time the solver fails.\n# 6 Conclusions\nIn this work, we have employed for the first time a metalearning rationale to enhance both the effectiveness and efficiency of direct, data-driven model reference control design. Like humans gain knowledge from past experiences, we propose to leverage controllers already calibrated for similar systems and data-based insights on their experienced performance and similarities to formulate a novel, meta-design problem. The numerical study carried out to calibrate a PI controller for a brushless DC motor has highlighted the potential of the method to enhance closed-loop performance when a reduced amount of data is collected, while at the same time resulting in a reduced tuning time.\nFuture work will be devoted to setting the ground for a theoretical framework to analyze the informativity of the meta-dataset. This development would be crucial to extend the proposed approach to other (possibly iterative) data-based control techniques, since it would allow one to limit the dimension of the meta-dataset, by incorporating only the most informative incoming data in it.\n# References\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of enhancing model-reference control design through meta-learning, leveraging data from similar plants to improve performance and efficiency in calibration processes.",
        "problem": {
            "definition": "The problem focuses on the calibration of fixed-structure controllers for dynamic systems, which are sensitive to data quality and often require extensive experiments.",
            "key obstacle": "Existing methods necessitate long and costly experiments to achieve acceptable performance, particularly in low-data regimes."
        },
        "idea": {
            "intuition": "The inherent similarity of many industrial systems can provide additional information that can be utilized to enhance control design.",
            "opinion": "The proposed idea is to leverage data from similar plants and previously calibrated controllers to design a new controller that improves performance without extensive data requirements.",
            "innovation": "The key innovation is the introduction of a meta-learning approach that combines existing controllers to create a new controller, ensuring non-decreasing performance."
        },
        "method": {
            "method name": "Meta-learning for model-reference data-driven control",
            "method abbreviation": "Meta-DRC",
            "method definition": "A direct design approach that constructs a new controller as a convex combination of controllers tuned on similar systems, incorporating meta-data for improved performance.",
            "method description": "The method utilizes data-driven insights from similar plants to enhance controller calibration directly from data.",
            "method steps": "1. Gather data from the target plant and similar plants. 2. Construct a meta-dataset of controllers. 3. Formulate the meta-design problem. 4. Optimize the controller parameters based on the meta-dataset.",
            "principle": "The method is effective due to its reliance on data from similar systems, allowing for improved performance and reduced calibration time."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted using a PI controller for a brushless DC motor, comparing performance against traditional methods like VRFT.",
            "evaluation method": "Performance was assessed through closed-loop response matching and tuning time, using a numerical analysis of simulation results."
        },
        "conclusion": "The proposed meta-learning approach significantly improves closed-loop performance and reduces tuning time compared to traditional methods, demonstrating its effectiveness in data-driven control design.",
        "discussion": {
            "advantage": "The primary advantage is the ability to achieve high performance with less data and reduced calibration effort by leveraging similarities among systems.",
            "limitation": "The method may still be sensitive to the quality of the data from similar plants and may not generalize well to dissimilar systems.",
            "future work": "Future research will focus on establishing a theoretical framework to analyze the informativity of the meta-dataset and extend the method to other data-driven control techniques."
        },
        "other info": [
            {
                "Funding": "Partially supported by the FAIR project funded by the NextGenerationEU program."
            },
            {
                "Keywords": [
                    "meta-learning",
                    "data-driven control",
                    "Virtual Reference Feedback Tuning",
                    "model-reference control"
                ]
            }
        ]
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The proposed meta-learning approach significantly improves closed-loop performance and reduces tuning time compared to traditional methods, demonstrating its effectiveness in data-driven control design."
        },
        {
            "section number": "2.4",
            "key information": "The problem focuses on the calibration of fixed-structure controllers for dynamic systems, which are sensitive to data quality and often require extensive experiments."
        },
        {
            "section number": "3.1",
            "key information": "Meta-learning for model-reference data-driven control (Meta-DRC) is a direct design approach that constructs a new controller as a convex combination of controllers tuned on similar systems, incorporating meta-data for improved performance."
        },
        {
            "section number": "3.2",
            "key information": "The primary advantage is the ability to achieve high performance with less data and reduced calibration effort by leveraging similarities among systems."
        },
        {
            "section number": "3.4",
            "key information": "Future research will focus on establishing a theoretical framework to analyze the informativity of the meta-dataset and extend the method to other data-driven control techniques."
        },
        {
            "section number": "5.1",
            "key information": "The method utilizes data-driven insights from similar plants to enhance controller calibration directly from data."
        },
        {
            "section number": "8.4",
            "key information": "The method may still be sensitive to the quality of the data from similar plants and may not generalize well to dissimilar systems."
        }
    ],
    "similarity_score": 0.6004643533203226,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-0858_fine-/papers/Meta-learning for model-reference data-driven control.json"
}