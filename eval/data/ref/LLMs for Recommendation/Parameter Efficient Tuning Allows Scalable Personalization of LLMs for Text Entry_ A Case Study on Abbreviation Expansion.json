{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2312.14327",
    "title": "Parameter Efficient Tuning Allows Scalable Personalization of LLMs for Text Entry: A Case Study on Abbreviation Expansion",
    "abstract": "Abbreviation expansion is a strategy used to speed up communication by limiting the amount of typing and using a language model to suggest expansions. Here we look at personalizing a Large Language Model's (LLM) suggestions based on prior conversations to enhance the relevance of predictions, particularly when the user data is small (~1000 samples). Specifically, we compare fine-tuning, prompt-tuning, and retrieval augmented generation of expanded text suggestions for abbreviated inputs. Our case study with a deployed 8B parameter LLM on a real user living with ALS, and experiments on movie character personalization indicates that (1) customization may be necessary in some scenarios and prompt-tuning generalizes well to those, (2) fine-tuning on in-domain data (with as few as 600 samples) still shows some gains, however (3) retrieval augmented few-shot selection also outperforms fine-tuning. (4) Parameter efficient tuning allows for efficient and scalable personalization. For prompt-tuning, we also find that initializing the learned \"soft-prompts\" to user relevant concept tokens leads to higher accuracy than random initialization.",
    "bib_name": "tomanek2023parameterefficienttuningallows",
    "md_text": "# Parameter Efficient Tuning Allows Scalable Personalization of LLMs for Text Entry: A Case Study on Abbreviation Expansion\n Tomanek, Shanqing Cai, Subhashini Venugopalan Google LLC\nAbstract\nAbbreviation expansion is a strategy used to speed up communication by limiting the amount of typing and using a language model to suggest expansions. Here we look at personalizing a Large Language Model\u2019s (LLM) suggestions based on prior conversations to enhance the relevance of predictions, particularly when the user data is small (\u22481000 samples). Specifically, we compare fine-tuning, prompttuning, and retrieval augmented generation of expanded text suggestions for abbreviated inputs. Our case study with a deployed 8B parameter LLM on a real user living with ALS, and experiments on movie character personalization indicates that (1) customization may be necessary in some scenarios and prompt-tuning generalizes well to those, (2) fine-tuning on in-domain data (with as few as 600 samples) still shows some gains, however (3) retrieval augmented few-shot selection also outperforms fine-tuning. (4) Parameter efficient tuning allows for efficient and scalable personalization. For prompt-tuning, we also find that initializing the learned \u201csoft-prompts\u201d to user relevant concept tokens leads to higher accuracy than random initialization.\narXiv:2312.14327v1\n# 1 Introduction\nLanguage models have long been used to reduce keystrokes and aid text entry in smart keyboards. This work looks at models for such keyboard applications in Augmentative and Alternative Communication (AAC) devices, in particular those for users with severe motor impairments, e.g., people living with amyotrophic lateral sclerosis (ALS) who communicate through eye-gaze typing. Recent advances in the generative capabilities of large language models (LLMs) can help significantly accelerate communication for such users. Prior studies (Adhikary et al., 2021; Cai et al., 2022; Shen et al., 2022) proposed techniques for abbreviation expansion, where a user types short keywords or\nabbreviated phrases consisting of the initial letter of each word and an LLM is used to generate the fully-expanded sentence. Including the conversation context (Wisenburn and Higginbotham, 2008; Gorman et al., 2021) was shown to further improve the accuracy of the predictions. In this work we explore personalization, another dimension that can improve the relevance of the predictions to fit a user\u2019s vocabulary and language style. In many real-world applications personalization plays an important role in enhancing the relevance of the suggested options and the quality of the user experience (Valencia et al., 2023). However, very little data is available to adapt a model to a given user, and larger models increase the risk of overfitting. Additionally, it remains unclear how to scale the approach to multiple users given the high cost of LLM checkpoint storage and serving. With these challenges in mind, our work evaluates three approaches to personalizing LLMs for abbreviation expansion as used by eye-gaze typers. Specifically we consider a pre-trained decoder-only LLM tuned for dialog (Roller et al., 2020; Thoppilan et al., 2022). We further fine-tune the model on the abbreviation expansion task on data derived from dialog datasets. We then compare personalizing this fine-tuned LLM on user-specific data via (1) fine-tuning the entire model, (2) augmenting the LLM\u2019s context by retrieving similar conversations from the user\u2019s history, and (3) parameter efficient prompt-tuning (Lester et al., 2021). Overall, prompt-tuning performed best and retrieval augmented in-context learning (RA-ICL) also outperformed fine-tuning.\n# 2 Related Work\n# 2.1 Language models for text-entry.\nUsing language models to expand abbreviated inputs for text-entry has been well studied and different schemes of abbreviation have been proposed\nsuch as, using just context words (Demasco and McCoy, 1992), discarding vowels (Shieber and Nelken, 2007), and additionally omitting repeated consonants (Willis et al., 2005), flexible letter saving schemes (Adhikary et al., 2021; Gorman et al., 2021), and expanding from a bag of words (Shen et al., 2022). Our study focuses on abbreviation expansion used by eye-gaze typers living with severe motor impairments. Given our goal to significantly reduce the number of keystrokes, we consider a form of word-initial abbreviation similar to Cai et al. (2022) where just the initial characters of the words are typed and an LLM predicts the full sentence. The current study focuses on personalizing such a model to a user, which has been less studied.\n# 2.2 LLM prompt engineering.\nLLMs have shown remarkable capabilities in understanding and performing tasks with fewshot (Brown et al., 2020) examples. However, the tokenization used in LLMs makes our task of generating expansions from single characters somewhat hard for the models. Due to this reason and to enable personalization, we focus on Parameter Efficient Fine-Tuning (PEFT) (Lester et al., 2021), and retrieval augmented generation (RAG) (Mialon et al., 2023). PEFT learns a small set of additional parameters while keeping the weights of the original LLM frozen. Many PEFT methods have been proposed in recent years. In case of adapters (Houlsby et al., 2019) and Low-Rank Optimization (LoRA) (Hu et al., 2021) these parameters are interspersed at different transformer layers of the model. Other methods such as, Prompttuning (Lester et al., 2021), Prefix-tuning (Li and Liang, 2021), and P-tuning (Liu et al., 2021) restrict the parameters to the input prompt tokens. We use prompt-tuning (Lester et al., 2021) which append parameters to the token embeddings. We also compare this to retrieval augmentation for ICL (Rubin et al., 2022) where a dense retriever is used to select relevant data point(s) that are then added as context to a generative answering model. While most RAG studies (Mialon et al., 2023) train the retriever or the generator, we keep both of these pre-trained models frozen. Specifically, we use the retrieved context to create more relevant few-shot examples specific to the input query.\n# 3 Tuning and personalization\nOur broad approach consists of taking a pre-trained LLM, performing supervised fine-tuning for the\nabbreviation expansion task, and then personalizing the model on user data by means of further fine-tuning, prompt-tuning, or retrieval augmented in-context few-shot generation. For the pre-trained model, we start with an 8B parameter decoder-only LLM. This model is pre-trained on the C4 dataset (Raffel et al., 2019) and tuned for dialogs (Roller et al., 2020; Thoppilan et al., 2022). We then fine-tune it further for abbreviation expansion on sentences from conversations and associated word-initial abbreviated text. We follow prior works (Cai et al., 2022) and experiment with different learning rates, and use a constant rate during fine-tuning and select the best based on a validation set. We refer to this as the base-AE model. We explore 3 strategies for personalization.\n# 3.1 Fine-tuning on user data.\nWe follow the same fine-tuning recipe on user data as with the base-AE model. The tuning itself is fast since the amount of user data is small, and we avoided overfitting by monitoring performance on the validation set. We experimented with learning rates 1e-5, 1e-6, and 5e-5 and found 5e-5 to work best (see App. Tab. 6).\n# 3.2 Few-shot and Retrieval Augmented In-Context Learning (RA-ICL)\nAnother way to personalize an LLM is to provide it with few-shot examples to allow for in-context learning (ICL). Performance with ICL can vary significantly with few-shot examples (Zhao et al., 2021). Hence, in addition to typical few-shot examples, we also investigate a retrieval-augmented few-shot setup. This is similar to works that retrieve from databases to augment LLMs (Mialon et al., 2023) but we use existing pre-trained models for retrieving and generating, and keep them frozen. For the retriever, we use a pre-trained 11B Sentence-T5 (Ni et al., 2022) and generate embeddings of the abbreviated inputs from the user conversations. Given a new input, we embed it and use Euclidean distance to retrieve the nearest neighbor queries and the corresponding expansions. We use this retrieved context to create relevant, queryspecific few-shot examples with which we prompt the LLM.\n# 3.3 Prompt-tuning\nWe also investigate prompt-tuning (Lester et al., 2021) for personalization. The basic idea is to extend few-shot prompting and use substantially\nmore in-context examples to learn \u201csoft-prompts\u201d in the input embedding layer specifically suited for the task at hand. We choose the length of the soft prompt and initialize the tokens. For tuning, we correspondingly add new learnable parameters to the model\u2019s embedding matrix that are updated using back propagation, keeping the original LLM weights frozen. The number of learned parameters is a product of the length of the soft-prompt and dimensions of the embedding weights. The learned soft-prompts are saved and passed along with each user query to the LLM during inference. This approach allows a single LLM to be served, and the soft-prompt to be swapped for different users (see Sec. 6). The soft-prompts themselves can be tuned on varying amounts of data, and are effective in low data settings (Lester et al., 2021). We train with a warm-up learning rate schedule with 1000 warm up steps to a peak of 0.1 followed by linear decay. We use small batch sizes of 16 for training and limit training to 20k steps. We experiment with different prompt lengths and initialization strategies, and choose the best checkpoints based on validation set accuracy.\n# 4 Dataset\n# 4 Dataset 4.1 Abbreviation Expansion Base Model\n# 4.1 Abbreviation Expansion Base Model\nTo fine-tune the LLM for the abbreviation expansion task, we need pairs of abbreviated phrases and the full expanded text. We use the data from Cai et al. (2022) where they prepare paired sentences and abbreviated inputs from four dialog datasets: crowd-sourced Turk Dialogues (Vertanen, 2017), DailyDialog (Li et al., 2017), the Cornell Movie Dialogues (Danescu-Niculescu-Mizil and Lee, 2011) from movie scripts, and Turk AAC dataset (Vertanen and Kristensson, 2011) of conversations collected with AAC users in mind. The model finetuning is done with a constant low-learning rate (0.01) using the AdaFactor optimizer (Shazeer and Stern, 2018) on over 237,000 examples derived from the dialog datasets.\n# 4.2 Personalization Dataset\nA model trained on generic dialog datasets may not fit the communication needs of all in terms of preserving their style, and vocabulary including proper nouns. Our work is motivated to increase the autonomy and self-expression of AAC users with motor and speech impairments and deploy our abbreviation expansion model for their daily usage. This is also a case where a generic models\u2019 train-\ning data is also lacking in terms of conversations around caregiving and health. Hence, our personalization dataset was collected from a person living with ALS with informed consent from the user and the conversation partners. They use eye-gaze text entry for everyday communication. They type on a virtual keyboard into the text editor of a text-tospeech (TTS) software and activate the audio to \"speak\" out the contents. Private and sensitive content was redacted prior to obtaining the data for research. The data was partitioned chronologically, and repetition was removed from the validation and test portions resulting in 630 (train), 194 (val.) and 224 (test) samples.\n# 4.3 Movie character personalization\nOutside of the real deployment scenario, we also examined other conversation datasets where personalization can be studied without affecting user privacy. Characters in movies and TV series tend to have certain quirks and personalities and make for a great test bed for evaluating personalization of spoken dialogues. Thus, to evaluate the need for customization and scalability of the approach, we performed additional experiments on conversations from the Cornell Movie Dialogs dataset (DanescuNiculescu-Mizil and Lee, 2011) test set. For our experiments, we selected 10 movies with very high ratings (with atleast 5k votes on ImDb). From each movie, we chose 1 character and all their conversations from the movie for personalization. Each character had over a hundred conversations in the movie (range 104 to 344, with a mean of 198.4 and median of 209 conversations). Similar to our AAC personalization dataset we did a time-based split of the data to get train, val., and test splits.\n# 5 Experiments and Results\nExperimental setup. For all experiments, we sample 128 responses from the model with temperature 1.0, sort based on frequency of predictions and select the top-5. We report results on the average (and \u00b1 std. dev.) of 3 runs unless specified otherwise. The metrics we use are Accuracy to measure exact match of the full sentence expansion, and BLEU score (Papineni et al., 2002) to consider partial credit, both measured on the top-5 predictions (noted as @5).\n# 5.1 Prompt-tuning is best for Personalization\nTable 1 compares the performance of the different personalization approaches on the real user data.\nWe note that the base-AE model achieved a top-5 accuracy of 68.3% on the abbreviation expansion test set, however from Tab. 1 we can see that it only gets an accuracy of 22.5% on the user personalization test set highlighting the difference between the user data distribution and the training distribution, and making a strong case for personalization for AAC users. Fine-tuning on user data helps, and retrieval for ICL does even better, however prompttuning results in the best performance.\nModel\npersonalized\nAccuracy@5\nBLEU@5\nbase-AE\n\u00d7\n22.5\n31.8\nICL\n\u2713\n22.8\n34.9\nFine-tuned\n\u2713\n26.5\n34.3\nRA-ICL\n\u2713\n30.3\n39.1\nPrompt-tuned\n\u2713\n38.8\n47.5\nTable 1: Accuracy (exact-match of full sentence) and BLEU score of top 5 predictions of the different approaches on the personalization test set.\nTable 1: Accuracy (exact-match of full sentence) and BLEU score of top 5 predictions of the different approaches on the personalization test set.\n# 5.2 Soft prompt initialization matters\nWe experimented with different soft-prompt lengths, learning rates, and soft-prompt initialization strategies. We tried soft-prompt lengths of 10, 25, and 100 tokens all initialized randomly. Recall that increasing the prompt lengths increases the number of learned parameters. In our case, we found higher prompt lengths led to more training instabilities. We found a length of 10 to work best. Fixing the prompt length as 10, we experimented with learning rates of 0.1, 0.2, and 0.3 and found 0.1 to work best (in App. Tab. 7).\nSoft-prompt Initialization\nAccuracy@5\nBLEU@5\nRandom\n32.7 \u00b13.2\n43.6 \u00b12.3\nLLM vocab. sampled\n33.9 \u00b10.4\n43.2 \u00b11.8\nUser vocab. sampled\n32.6 \u00b11.6\n41.0 \u00b11.9\nUser relevant concepts\n36.8 \u00b11.9\n45.9 \u00b11.4\nUser concept antonyms\n36.4 \u00b10.3\n46.2 \u00b14.3\n<div style=\"text-align: center;\">Table 2: Initializing soft-prompts with proper nouns and concepts from the user\u2019s data performs best.</div>\nTable 2: Initializing soft-prompts with proper nouns and concepts from the user\u2019s data performs best.\nThe thing that made the biggest difference though was the choice of initialization for the softprompt token embeddings, which can be seen in Table 2. We examined 5 strategies, (1) random initialization, (2) sampling from the top 5k words in the LLM\u2019s vocabulary, (3) sampling from the top 25 most common English words in the user\u2019s vocabulary, (4) hand-selecting proper names and concepts relevant to the user (e.g. ALS) and (5) selecting words that are related but might be considered antonyms of the user concepts (e.g. Parkinsons). We found the initialization that relied on the user concepts to perform significantly better. Analogous\nto what is suggested in Lester et al. (2021), perhaps these tokens are the ones the base model is most uncertain about, and hence boosts their chance of appearing in the predictions when prompt-tuned.\n# 5.3 Fine-tuning hampers generalization\nFig. 1 slices performance of the models based on the length of the sentences. The performance of all models degrade with increasing sentence length. However, the fine-tuned model generalizes poorly compared to the base-AE model in some cases (noticeable at lengths 5 and 6). This also highlights the difficulty with fine-tuning large models on very small datasets.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/96b7/96b7ee43-daf2-4909-9087-add43bc02a1a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: Performance of the different approaches on conversation sentences of different lengths. On longer sentences, the prompt-tuned (green) and base non-personalized model (in blue) can outperform fine-tuning highlighting their capacities to generalize to the long tail of complex sentences.</div>\nICL (4-shot) strategy\nAccuracy@5\nBLEU@5\nRandom 4-shot\n22.0 \u00b10.9\n30.8 \u00b11.4\nHand-crafted 4-shot\n21.9 \u00b10.5\n33.3 \u00b10.7\nRetrieval augmented (RA-ICL)\n30.2 \u00b10.3\n38.5 \u00b10.6\nTable 3: Comparing different few-shot selection strategies. Retrieval augmented ICL works best.\nTable 3: Comparing different few-shot selection strategies. Retrieval augmented ICL works best.\n# 5.4 Retrieval augmented few-shots help\nTable 3 presents results for in-context learning where 4-shot examples are selected using different strategies: (1) random selection from the training set, (2) hand-crafted examples containing proper names of people that the user communicates with, and (3) retrieval-augmented few shots, where 4 nearest neighbor examples (in the embedding space of abbreviations) are selected based on each test query. RA-ICL outperforms other strategies by a large margin.\n# 5.5 Customization is not always necessary\nWe also evaluated the prompt-tuning approach on the movie character personalization dataset and report results in Table 4. We observe that: (1) the base non-personalized model accuracies do seem to\nMovie-id\ncharacter-id\nCharacter-Name\nNon-personalized base-AE\nPersonalized (prompt-tuned)\nPersonalization\nAcc. @5\nBLEU @5\nAcc. @5\nBLEU @5\nrel. benefit (%)\nm106\nu1612\nJACOB\n62.75\n67.03\n56.86\n65.13\n-\nm119\nu1799\nGEORGE\n50.00\n59.18\n56.25\n62.46\n13%\nm126\nu1916\nANDERTON\n44.12\n55.66\n38.24\n55.74\n-\nm140\nu2157\nBABE\n60.00\n69.52\n46.67\n62.93\n-\nm148\nu2299\nNANCY\n41.67\n52.67\n41.67\n51.40\n-\nm203\nu3105\nMICHAEL\n61.90\n59.60\n47.62\n45.32\n-\nm274\nu4099\nABBY\n77.78\n77.78\n77.78\n77.78\n-\nm324\nu4866\nSONNY\n62.86\n71.53\n65.71\n72.97\n5%\nm352\nu5310\nJACK\n50.00\n59.18\n56.25\n62.46\n13%\nm565\nu8329\nJEANNE\n61.54\n70.61\n64.10\n71.24\n4%\nTable 4: Performance comparison between Non-personalized base-AE and Personalized (prompt-tuned) models on movie character personalization. LLMs raise the bar on average performance indicating that customization may not always be necessary on certain conversation categories, though some users benefit from it. This is a contrast to the real AAC deployment scenario.\ntransfer reasonably well indicating that customization may not be necessary for conversation types similar to the training data distribution. (2) 4 of the 10 speakers still benefit from personalization. (3) the proposed prompt-tuning approach offers a way to serve the same end-point, while optionally choosing to personalize results to some users.\n# 5.6 Error Analysis\nIn Table 5 we share some examples of the categories of errors we observe comparing the finetuned and prompt-tuned results. Our analysis of the predictions show that the fine-tuned model tends to overfit to proper nouns in the user\u2019s training data, and often misses generating expansions for some of the characters in the acronym. On sessions where there is not enough user context, it can miss the user\u2019s style (e.g. the word contraction \u201cyall\u201d in row 4 of Table 5 is less common in general text, but could be stylistic of a user).\n# 6 Discussion\n# 6 Discussion 6.1 LLM Blind-spots.\nAbbreviation expansion may seem to be an easy task for current LLMs. However, our work focuses on abbreviations motivated to help users with severe disabilities, and hence pushes the limit of keystroke savings. Wherein, the task depends on recognizing individual characters/alphabets. Interestingly, it falls into what could be a \"blindspot\" for the LLMs because the input tokenization schemes - meant to overcome a discrete vocabulary - may fall short in recognizing individual characters. This is now addressed practically e.g. for generating text in JSON format (Lamini, 2023), using constrained decoding and following Backus-Naur Form (BNF) grammar.\n# 6.2 Data efficiency and scaling.\nAnother point of discussion is how personalization can be performed on a small amount of data. Our experiments show that prompt-tuning leads to higher test accuracy than fine-tuning in limited data settings. Fine-tuning the full LLM for personalization not only generalizes poorly, but is also very expensive in terms of storing the personalized model weights. Prompt-tuning on the other hand only involves storing a very small set of weights (on the order of thousands) which would make it not only possible but also convenient to store these on users\u2019 personal devices. This also makes the approach more scalable since only a single model can be served, while clients can query it using different personalized soft prompts. Further, querying a prompt-tuned model incurs little additional inference latency, as the learned prompts and the user input are provided simultaneously to the model during inference.\n# 7 Conclusion\nOur work presents a case study on personalizing LLMs for the task of abbreviation expansion in the context of aiding eye-gaze typers with severe motor and speech disabilities to communicate faster. We fine-tuned an LLM on generic dialog data for the task and compared approaches to personalization using limited user data. We examined fine-tuning, parameter-efficient prompt-tuning, and retrieval augmented in-context learning, and find prompttuning to be the most elegant method for personalization in terms of its performance as well as its training data efficiency, small storage requirements, and ability to scale. Further, initializing the softprompts with concepts and terms relevant to the user resulted in better prompt-tuned personalized models.\nError Type\nAbbreviation\nGold Expansion\nFine-tuned\nPrompt-tuned\nUnmatched Acronym\ns i l t r\nsweet i love that robin\ni love that robin\nsweet i love that robin\nOverfitting to names\ng q d , r a m\ngreat question dude , robin and mommy\ngreg q day, robin and greg\ngood q doc, robin and mommy\nMisses user style (often\nw a d , o d y\nwhat a dunce , okie dokie yall\nwhat about daddy , okie dokie\nwhat a day , okie dokie\nwhen lacking context)\nwipe and dry , ok thanks\nwe are done , ok day yall\n# Limitations\nThe effectiveness of personalization on real usage is difficult to study, since it deals with private and sensitive content. This difficulty is more pronounced when working with people with disabilities. This limits our work to a case study on real user data for personalization. Identifying interesting techniques to collect realistic personalization datasets, perhaps synthetic, can benefit the community significantly. We also limit the extent of hyperparameter tuning, due to significant computation resource consumption of experiments. Though we are able to take advantage of settings shared in literature and open source code. Also, while our abbreviation expansion study and models are limited to English, it will likely translate well to languages with similar morphology, but that remains to be studied. Our references to related work in this space may be limited and further suggestions are welcome.\n# Ethics and Societal Impact\nTechniques that improve Augmentative and Alternative Communication (AAC) applications can significantly enhance quality of life, increase independence and social participation (Caligari et al., 2013) of people living with communication and motor disabilities. A risk of abbreviation expansion is that, when the expansions are not exactly the ones that the user desires, they may be tempted to choose a near similar prediction leading to conveying content that may be less accurate, misinterpreted, or reflecting biases and stereotypes of the underlying models. While the goal of personalization is to mitigate these, some of the risks still remain. Hence there is still a subtle risk of reducing speaker\u2019s autonomy and authentic self-expression which people e.g. with ALS (Kane et al., 2017) value highly. Another risk is that of frequent incorrect predictions if personalization is poor for some users. This could increase effort required to edit minor errors, and inadvertently increase fatigue.\n# References\nJiban Adhikary, Jamie Berger, and Keith Vertanen. 2021. Accelerating text communication via abbreviated sentence input. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6574\u20136588. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165. Shanqing Cai, Subhashini Venugopalan, Katrin Tomanek, Ajit Narayanan, Meredith R Morris, and Michael P Brenner. 2022. Context-aware abbreviation expansion using large language models. arXiv preprint arXiv:2205.03767. Marco Caligari, Marco Godi, Simone Guglielmetti, Franco Franchignoni, and Antonio Nardone. 2013. Eye tracking communication devices in amyotrophic lateral sclerosis: impact on disability and quality of life. Amyotroph Lateral Scler Frontotemporal Degener, 14(7-8):546\u2013552. Cristian Danescu-Niculescu-Mizil and Lillian Lee. 2011. Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs. arXiv preprint arXiv:1106.3077. Patrick W Demasco and Kathleen F McCoy. 1992. Generating text from compressed input: An intelligent interface for people with severe motor impairments. Communications of the ACM, 35(5):68\u201378. Kyle Gorman, Christo Kirov, Brian Roark, and Richard Sproat. 2021. Structured abbreviation expansion in context. arXiv preprint arXiv:2110.01140. Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pages 2790\u20132799. PMLR.\nShanqing Cai, Subhashini Venugopalan, Katrin Tomanek, Ajit Narayanan, Meredith R Morris, and Michael P Brenner. 2022. Context-aware abbreviation expansion using large language models. arXiv preprint arXiv:2205.03767.\nMarco Caligari, Marco Godi, Simone Guglielmetti, Franco Franchignoni, and Antonio Nardone. 2013. Eye tracking communication devices in amyotrophic lateral sclerosis: impact on disability and quality of life. Amyotroph Lateral Scler Frontotemporal Degener, 14(7-8):546\u2013552.\nCristian Danescu-Niculescu-Mizil and Lillian Lee. 2011. Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs. arXiv preprint arXiv:1106.3077.\nPatrick W Demasco and Kathleen F McCoy. 1992. Generating text from compressed input: An intelligent interface for people with severe motor impairments. Communications of the ACM, 35(5):68\u201378.\nKyle Gorman, Christo Kirov, Brian Roark, and Richard Sproat. 2021. Structured abbreviation expansion in context. arXiv preprint arXiv:2110.01140.\nNeil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pages 2790\u20132799. PMLR.\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685.\nand Jon Campbell. 2017. \"at times avuncular and cantankerous, with the reflexes of a mongoose\": Understanding self-expression through augmentative and alternative communication devices. In Proceedings of CSCW 2017. Lamini. 2023. Guarantee valid json output with lamini. https://www.lamini.ai/blog/ guarantee-valid-json-output-with-lamini. Accessed: 2023-12-21. Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691. Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190. Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. Dailydialog: A manually labelled multi-turn dialogue dataset. arXiv preprint arXiv:1710.03957. Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021. Gpt understands, too. arXiv preprint arXiv:2103.10385. Gr\u00e9goire Mialon, Roberto Dess\u00ec, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozi\u00e8re, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. 2023. Augmented language models: a survey. arXiv preprint arXiv:2302.07842. Jianmo Ni, Gustavo Hern\u00e1ndez \u00c1brego, Noah Constant, Ji Ma, Keith B Hall, Daniel Cer, and Yinfei Yang. 2022. Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models. ACL. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311\u2013318. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2019. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683. Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M Smith, et al. 2020. Recipes for building an open-domain chatbot. arXiv preprint arXiv:2004.13637. Ohad Rubin, Jonathan Herzig, and Jonathan Berant. 2022. Learning to retrieve prompts for in-context learning. NAACL. Noam Shazeer and Mitchell Stern. 2018. Adafactor: Adaptive learning rates with sublinear memory cost. In International Conference on Machine Learning, pages 4596\u20134604. PMLR.\nJunxiao Shen, Boyin Yang, John J Dudley, and Per Ola Kristensson. 2022. Kwickchat: A multi-turn dialogue system for aac using context-aware sentence generation by bag-of-keywords. In 27th International Conference on Intelligent User Interfaces, pages 853\u2013867. Stuart M Shieber and Rani Nelken. 2007. Abbreviated text input using language modeling. Natural Language Engineering, 13(2):165\u2013183. Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239. Stephanie Valencia, Richard Cave, Krystal Kallarackal, Katie Seaver, Michael Terry, and Shaun K Kane. 2023. \u201cthe less i type, the better\u201d: How ai language models can enhance or impede communication for aac users. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pages 1\u201314. Keith Vertanen. 2017. Towards improving predictive aac using crowdsourced dialogues and partner context. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility, pages 347\u2013348. Keith Vertanen and Per Ola Kristensson. 2011. The imagination of crowds: conversational aac language modeling using crowdsourcing and large data sources. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 700\u2013 711. Tim Willis, Helen Pain, and Shari Trewin. 2005. A probabilistic flexible abbreviation expansion system for users with motor disabilities. In Accessible Design in the Digital World Conference 2005, pages 1\u20139. Bruce Wisenburn and D Jeffery Higginbotham. 2008. An aac application using speaking partner speech recognition to automatically produce contextually relevant utterances: Objective results. Augmentative and Alternative Communication, 24(2):100\u2013109. Tony Z Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language models. arXiv preprint arXiv:2102.09690.\n# A Parameter selection\n# A.1 Fine-tuning learning rates\nFine-tuning learning rate\nAccuracy@5\nBLEU@5\n5e-5\n26.8\n34.3\n1e-6\n25.4\n34.7\n1e-5\n23.7\n31.6\nTable 6: Comparing different learning rates for fine-tuning base-AE model on personalization data. (val set).\nTable 6: Comparing different learning rates for fine-tuning base-AE model on personalization data. (val set).\n# A.2 Prompt-tuning learning rates\nPrompt-tuning learning rate\nAccuracy@5\nBLEU@5\n0.1\n35.7\n45.6\n0.2\n31.7\n41.7\n0.3\n30.8\n39.9\nTable 7: Comparing different learning rates for prompt-tuning base-AE model on personalization data. soft prompt length of 10 and random initialization (val set).\nTable 7: Comparing different learning rates for prompt-tuning base-AE model on personalization data. soft prompt length of 10 and random initialization (val set).\n# B Personalization Data\nOur personalization dataset was collected with informed consent from a person living with ALS over a period of five months from late 2021 to early 2022. We refer to the person with ALS as \"the user\". The user used a Tobii (R) eye-tracker and gaze-driven keyboard to enter text for daily communication. The gaze-typed text was output as speech audio through text-to-speech (TTS) software. The user had full control over when to start and stop data collection. Private and sensitive content in the data was redacted by trained human curators prior before we ingested the dataset for research. The relevant data used for this study consists of text transcripts of the user\u2019s TTS output. We split the data into three non-overlapping splits along the time axis in chronological order as train, validation and test, containing 630, 285, and 284 sentences, respectively. We filter the validation and test split to preserve only the sentences with abbreviation length \u226410, leading to 194 and 224 sentences, respectively. No filtering is done on the training split. As a result, the average abbreviation length in the train, validation, and test splits are 6.91 \u00b1 6.25, 4.72\u00b12.39, and 5.05\u00b12.74, respectively (\u00b11SD). The sentences belong to 122, 69, and 72 sessions, respectively, each session being a continuous period of conversation data collection. The percentages of proper nouns among the words were 6.73%, 5.88%, and 8.61% in the three splits, respectively.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the challenge of personalizing Large Language Models (LLMs) for abbreviation expansion to enhance communication for users with severe motor impairments, particularly focusing on eye-gaze typing. Previous methods have struggled with limited user data and the risk of overfitting in larger models, necessitating a new approach to improve relevance and accuracy in suggestions.",
        "problem": {
            "definition": "The problem is the need for effective abbreviation expansion in communication systems for users with severe motor impairments, where personalized suggestions are crucial for enhancing user experience.",
            "key obstacle": "The main challenge is the limited amount of user-specific data available to adapt the model, which increases the risk of overfitting and reduces the model's ability to generalize across different users."
        },
        "idea": {
            "intuition": "The idea is inspired by the observation that personalization can significantly improve the relevance of language model predictions by tailoring them to individual user vocabulary and style.",
            "opinion": "The proposed idea involves exploring three methods: fine-tuning, retrieval augmented generation, and prompt-tuning to personalize LLMs for abbreviation expansion.",
            "innovation": "The key innovation lies in the use of parameter-efficient prompt-tuning, which allows for effective personalization without the need to retrain the entire model, thus addressing data scarcity and storage challenges."
        },
        "method": {
            "method name": "Parameter Efficient Prompt-Tuning",
            "method abbreviation": "PEPT",
            "method definition": "PEPT is a method that appends learnable parameters to the input prompt tokens of an LLM, allowing for personalization while keeping the original model weights frozen.",
            "method description": "The method involves extending few-shot prompting to learn soft-prompts that are specifically tuned for individual users.",
            "method steps": [
                "Start with a pre-trained LLM.",
                "Fine-tune the model on a generic abbreviation expansion task.",
                "Implement prompt-tuning using user-specific data to learn soft-prompts.",
                "Use the learned soft-prompts during inference to enhance predictions."
            ],
            "principle": "This method is effective because it allows the model to adapt to user-specific language and vocabulary without extensive retraining, thus maintaining scalability and efficiency."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted using data from users with ALS and other datasets like the Cornell Movie Dialogues to evaluate the effectiveness of the proposed methods.",
            "evaluation method": "Performance was assessed using accuracy and BLEU score metrics on the top-5 predictions from the model, comparing different personalization approaches."
        },
        "conclusion": "The study concludes that parameter-efficient prompt-tuning outperforms traditional fine-tuning and retrieval augmented methods for personalizing LLMs in abbreviation expansion tasks, demonstrating superior performance in limited data settings.",
        "discussion": {
            "advantage": "The primary advantage of the proposed approach is its ability to personalize LLMs efficiently with minimal data and storage requirements, allowing for scalable deployment across multiple users.",
            "limitation": "A limitation of the method is its reliance on user data, which can be sensitive and challenging to collect, potentially affecting the generalizability of the findings.",
            "future work": "Future research could explore methods for synthesizing user data or enhancing the model's ability to generalize across different user profiles to further improve personalization."
        },
        "other info": {
            "data collection": "Personalization datasets were collected from a user with ALS, ensuring informed consent and privacy protection.",
            "model size": "The LLM used in the study is an 8B parameter decoder-only model.",
            "initialization strategy": "Initializing soft-prompts with user-relevant concepts significantly improved performance compared to random initialization."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "Recommendation algorithms are critical for enhancing user experience, particularly in applications for users with severe motor impairments."
        },
        {
            "section number": "2.1",
            "key information": "The paper defines abbreviation expansion as a crucial aspect of communication systems for users with severe motor impairments."
        },
        {
            "section number": "2.3",
            "key information": "The study discusses the development of parameter-efficient prompt-tuning (PEPT) as an innovative method for personalizing LLMs."
        },
        {
            "section number": "3.2",
            "key information": "The proposed approach explores AI-driven techniques such as fine-tuning, retrieval augmented generation, and prompt-tuning for enhancing personalization."
        },
        {
            "section number": "4.1",
            "key information": "The LLM used in the study is an 8B parameter decoder-only model, showcasing the capabilities of large language models in processing user-specific data."
        },
        {
            "section number": "4.2",
            "key information": "The integration of PEPT allows for personalization of LLMs without retraining the entire model, enhancing user interaction."
        },
        {
            "section number": "10.1",
            "key information": "Challenges include the limited amount of user-specific data available for model adaptation, increasing the risk of overfitting."
        },
        {
            "section number": "10.2",
            "key information": "Future research could explore methods for synthesizing user data to improve the generalizability of personalized models."
        }
    ],
    "similarity_score": 0.7358016410041844,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Parameter Efficient Tuning Allows Scalable Personalization of LLMs for Text Entry_ A Case Study on Abbreviation Expansion.json"
}