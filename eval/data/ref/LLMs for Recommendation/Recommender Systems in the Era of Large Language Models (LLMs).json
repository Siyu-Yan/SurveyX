{
    "from": "google",
    "scholar_id": "dPPgW8dQgPAJ",
    "detail_id": null,
    "title": "Recommender systems in the era of large language models (llms)",
    "abstract": "\nAbstract\u2014With the prosperity of e-commerce and web applications, Recommender Systems (RecSys) have become an indispensable and important component in our daily lives, providing personalized suggestions that cater to user preferences. While Deep Neural Networks (DNNs) have achieved significant advancements in enhancing recommender systems by modeling user-item interactions and incorporating their textual side information, these DNN-based methods still exhibit some limitations, such as difficulties in effectively understanding users\u2019 interests and capturing textual side information, inabilities in generalizing to various seen/unseen recommendation scenarios and reasoning on their predictions, etc. Meanwhile, the development of Large Language Models (LLMs), such as ChatGPT and GPT-4, has revolutionized the fields of Natural Language Processing (NLP) and Artificial Intelligence (AI), due to their remarkable abilities in fundamental responsibilities of language understanding and generation, as well as impressive generalization capabilities and reasoning skills. As a result, recent studies have actively attempted to harness the power of LLMs to enhance recommender systems. Given the rapid evolution of this research direction in recommender systems, there is a pressing need for a systematic overview that summarizes existing LLM-empowered recommender systems, so as to provide researchers and practitioners in relevant fields with an in-depth understanding. Therefore, in this survey, we conduct a comprehensive review of LLM-empowered recommender systems from various aspects including pre-training, fine-tuning, and prompting paradigms. More specifically, we first introduce the representative methods to harness the power of LLMs (as a feature encoder) for learning representations of users and items. Then, we systematically review the emerging advanced techniques of LLMs for enhancing recommender systems from three paradigms, namely pre-training, fine-tuning, and prompting. Fin",
    "bib_name": "zhao2023recommender",
    "md_text": "IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023\n# Recommender Systems in the Era of Large Language Models (LLMs)\nZihuai Zhao, Wenqi Fan, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Zhen Wen, Fei Wang, Xiangyu Zhao, Jiliang Tang, and Qing Li\nAbstract\u2014With the prosperity of e-commerce and web applications, Recommender Systems (RecSys) have become an indispensable and important component in our daily lives, providing personalized suggestions that cater to user preferences. While Deep Neural Networks (DNNs) have achieved significant advancements in enhancing recommender systems by modeling user-item interactions and incorporating their textual side information, these DNN-based methods still exhibit some limitations, such as difficulties in effectively understanding users\u2019 interests and capturing textual side information, inabilities in generalizing to various seen/unseen recommendation scenarios and reasoning on their predictions, etc. Meanwhile, the development of Large Language Models (LLMs), such as ChatGPT and GPT-4, has revolutionized the fields of Natural Language Processing (NLP) and Artificial Intelligence (AI), due to their remarkable abilities in fundamental responsibilities of language understanding and generation, as well as impressive generalization capabilities and reasoning skills. As a result, recent studies have actively attempted to harness the power of LLMs to enhance recommender systems. Given the rapid evolution of this research direction in recommender systems, there is a pressing need for a systematic overview that summarizes existing LLM-empowered recommender systems, so as to provide researchers and practitioners in relevant fields with an in-depth understanding. Therefore, in this survey, we conduct a comprehensive review of LLM-empowered recommender systems from various aspects including pre-training, fine-tuning, and prompting paradigms. More specifically, we first introduce the representative methods to harness the power of LLMs (as a feature encoder) for learning representations of users and items. Then, we systematically review the emerging advanced techniques of LLMs for enhancing recommender systems from three paradigms, namely pre-training, fine-tuning, and prompting. Finally, we comprehensively discuss the promising future directions in this emerging field.\n 29 Apr 2024\n[cs.IR]\narXiv:2307.02046v6\n# 1 INTRODUCTION\nR Ecommender Systems (RecSys) play a vital role in alleviating information overload for enriching users\u2019 online experience (i.e., users need to filter overwhelming information to locate their interested information) [1], [2]. They offer personalized suggestions toward candidate items tailored to meet user preferences in various application domains, such as entertainment [3], e-commerce [4], and job matching [2]. For example, in movie recommendations (e.g., IMDB and Netflix), the latest movies can be recommended to users based on the content of movies and the watch histories of users, which assists users in discovering new movies that accord with their interests. The basic idea of recommender systems is to make use of the interactions between users and items and their associated side information, especially\n\u2022 W. Fan is with the Department of Computing (COMP) and Department of Management and Marketing (MM), The Hong Kong Polytechnic University. E-mail: wenqifan03@gmail.com. \u2022 Z. Zhao, J. Li, Y. Liu, and Q. Li are with the Department of Computing, The Hong Kong Polytechnic University. E-mail: scofield.zzh@gmail.com, {jiatong.li, yunqing617.liu}@connect.polyu.hk, csqli@comp.polyu.edu.hk. \u2022 X. Mei is with the Department of Management and Marketing, The Hong Kong Polytechnic University. E-mail: michael.mei@polyu.edu.hk. \u2022 Y. Wang is with National University of Defense Technology. E-mail: yiq@nudt.edu.cn. This work was done when Yiqi Wang was a PhD student at Michigan State University. \u2022 Z. Wen and F. Wang are with Amazon. E-mail: {zhenwen, feiww}@amazon.com. \u2022 X. Zhao is with City University of Hong Kong. E-mail: xy.zhao@cityu.edu.hk. \u2022 J. Tang is with Michigan State University. E-mail: tangjili@msu.edu. (Corresponding authors: Wenqi Fan and Qing Li.)\ntextual information like item descriptions, user profiles, and user reviews, to predict the matching score between users and items (i.e., the probability that the user would like the item) [5]. More specifically, collaborative behaviors between users and items have been leveraged to design various recommendation models, which can be further used to learn the representations of users and items [6], [7]. In addition, textual side information of users and items contains rich knowledge that can assist in the calculation of the matching scores, which provides valuable insights into understanding user preferences for advancing recommender systems [8]. Due to the remarkable ability of representation learning in various fields, Deep Neural Networks (DNNs) have been widely adopted to advance recommender systems [9], [10]. DNNs demonstrate distinctive abilities in modeling useritem interactions with different architectures. For example, as particularly effective tools for sequential data, Recurrent Neural Networks (RNNs) have been adopted to capture highorder dependencies in user interaction sequences [11], [12]. Considering users\u2019 online behaviors (e.g., chick, purchase, socializing) as graph-structured data, Graph Neural Networks (GNNs) have emerged as advanced representation learning techniques to learn user and item representations [1], [6], [13]. Meanwhile, DNNs have also demonstrated advantages in encoding side information. For instance, a BERT-based method is proposed to extract and utilize textual reviews from users [14]. Despite the aforementioned success, most existing advanced recommender systems still face some intrinsic limitations. First, due to the limitations on model scale and data\n<div style=\"text-align: center;\">IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023</div>\n<div style=\"text-align: center;\">Task-specific Prompts (LLMs Inputs)</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9251/92510d35-309f-4c67-978e-beb8e29b58f2.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Task-specific Recommendations (LLMs Outputs)</div>\nFigure 1: Examples of the application of LLMs for various recommendation tasks in the scenario of movie recommendations. In this workflow, LLMs directly act as recommenders through task-specific prompts, where textual information (or even multimodal data like images) are leveraged for recommendation tasks.\nsize, previous DNN-based models (e.g., CNN and LSTM) and pre-trained language models (e.g., BERT) for recommender systems cannot sufficiently capture textual knowledge about users and items, demonstrating their inferior natural language understanding capability, which leads to suboptimal prediction performance in various recommendation scenarios. Second, most existing RecSys methods have been specifically designed for their own tasks and have inadequate generalization ability to their unseen recommendation tasks. For example, a recommendation algorithm is welltrained on a user-item rating matrix for predicting movies\u2019 rating scores, while it is challenging for this algorithm to perform top-k movie recommendations along with certain explanations. This is due to the fact that the design of these recommendation architectures highly depends on task-specific data and domain knowledge toward specific recommendation scenarios such as top-k recommendations, rating predictions, and explainable recommendations. Third, most existing DNN-based recommendation methods can achieve promising performance on recommendation tasks needing simple decisions (e.g., rating prediction, and topk recommendations). However, they face difficulties in supporting complex and multi-step decisions that involve multiple reasoning steps. For instance, multi-step reasoning is crucial to trip planning recommendations, where RecSys should first consider popular tourist attractions based on the destination, then arrange a suitable itinerary corresponding to the tourist attractions, and finally recommend a journal plan according to specific user preferences (e.g., cost and time for travel).\nRecently, as advanced natural language processing techniques, Large Language Models (LLMs) with billion parameters have generated large impacts on various research fields such as Natural Language Processing (NLP) [15], Computer Vision [16], and Molecule Discovery [17]. Technically, most existing LLMs are transformer-based models pre-trained on a vast amount of textual data from diverse sources, such as articles, books, websites, and other publicly available written materials. As the parameter size of LLMs continues to scale up with a larger training corpus, recent studies indicated that LLMs can lead to the emergence of remarkable capabilities [18], [19]. More specifically, LLMs have demonstrated the unprecedentedly powerful abilities of their fundamental responsibilities in language understanding and generation. These improvements enable LLMs to better comprehend human intentions and generate language responses that are more human-like in nature. Moreover, recent studies indicated that LLMs exhibit impressive generalization and reasoning capabilities, making LLMs better generalize to a variety of unseen tasks and domains. To be specific, instead of requiring extensive fine-tuning on each specific task, LLMs can apply their learned knowledge and reasoning skills to fit new tasks simply by providing appropriate instructions or a few task demonstrations. Advanced techniques such as in-context learning can further enhance such generalization performance of LLMs without being fine-tuned on specific downstream tasks [19]. In addition, empowered by prompting strategies such as chainof-thought, LLMs can generate the outputs with step-bystep reasoning in complicated decision-making processes.\nHence, given their powerful abilities, LLMs demonstrate great potential to revolutionize recommender systems. Very recently, initial efforts have been made to explore the potential of LLMs as a promising technique for the nextgeneration RecSys. For example, Chat-Rec [3] is proposed to enhance the recommendation accuracy and explainability by leveraging ChatGPT to interact with users through conversations and then refine the candidate sets generated by traditional RecSys for movie recommendations. Zhang et al. [20] employ T5 as LLM-based RecSys, which enables users to deliver their explicit preferences and intents in natural language as RecSys inputs, demonstrating better recommendation performance than merely based on useritem interactions. Figure 1 demonstrates some examples of applying LLMs for various movie recommendation tasks, including top-K recommendation, rating prediction, conversational recommendation, and explanation generation. Due to their rapid evolution, it is imperative to comprehensively review recent advances and challenges of LLMs-empowered recommender systems. Therefore, in this survey, we provide a systematic overview of LLM-empowered recommender systems in terms of pre-training, fine-tuning, and prompting paradigms, which serve as three representative approaches to harness the power of LLMs [19], [21]. In particular, our survey is organized as follows. First, we review the milestones in the field of RecSys and LLMs, respectively, and their combinations in Section 2. Then, two basic types of recommender systems that take advantage of LLMs to learn the representation of users and items are illustrated in Section 3, namely the ID-based RecSys and the textual side information-enhanced RecSys. Subsequently, we comprehensively summarize the advanced techniques for adapting LLMs to recommender systems in terms of pre-training & fine-tuning and prompting paradigms in Section 4 and Section 5, respectively. Finally, the emerging challenges posed by adapting LLMs to recommendations and some potential future directions are discussed in Section 6. Recapping existing surveys in the domain of recommender systems, diverse focuses have been reviewed to facilitate the performance of RecSys from the perspective of deep learning techniques [9], [22]\u2013[24], evaluation methodology [25], [26], trustworthiness [27]\u2013[29] and other aspects. In the era of LLMs, the integration of LLMs into recommender systems has drawn increasing attention from recent studies, which highlights the significance and necessity of systematically reviewing the emerging trends and advanced techniques in this interdisciplinary field of LLM-empowered recommender systems. Before or concurrent to our survey, Liu et al. [30] review the training strategies and learning objectives of the language modeling paradigm adaptations for recommender systems. However, this work majorly examines early-stage language models for RecSys, such as BERT and GPT-2. Following the release of more advanced LLMs like ChatGPT and LLaMA, remarkable evolution has been brought to the adaption of LLMs in RecSys, which urges a more up-to-date review. More recently, Wu et al. [31] summarize LLMs for recommender systems from discriminative and generative perspectives, which compares the two styles of LLMs tailored to their distinct abilities in recommendations. Meanwhile, Lin et\nal. [32] introduce two orthogonal perspectives: where and how to adapt LLMs in recommender systems. In particular, this survey presents a pipeline of RecSys, reviewing the various functionalities of LLMs through the procedure of recommendations. Despite the aforementioned progress, existing surveys mainly emphasize the application aspects of LLMs in addressing their distinctive capabilities in RecSys, where the corresponding techniques proposed in the domain of LLMs are not systematically reviewed. Therefore, our survey comprehensively reviews such domain-specific techniques for adapting LLMs to recommendations, which contributes to an in-depth understanding of developing LLM-based methods tailored to RecSys for future research.\n# 2 RELATED WORK\nIn this section, we briefly review some related works on recommender systems, LLMs, and their combinations. As illustrated in Figure 2, a timeline of milestones in the domains of recommender systems and language models is provided, reviewing the development of the interdisciplinary field of LLM-empowered recommender systems.\n# 2.1 Recommender Systems (RecSys)\nTo address the information overload problem, recommender systems have emerged as a crucial tool in various online applications by providing personalized content and services to individual users [33], [34]. Typically, most existing recommendation approaches can fall into two main categories: Collaborative Filtering (CF) and Contentbased recommendation. As the most common technique, CF-based recommendation methods aim to find similar behavior patterns of users to predict the likelihood of future interactions [12], which can be achieved by utilizing the historical interaction behaviors between users and items, such as purchase history or rating data. For example, as one of the most popular CF methods, Matrix Factorization (MF) is introduced to learn representations of users and items by using pure user-item interactions [7], [35]. In other words, unique identities of users and items (i.e., discrete IDs) are encoded to continue embedding vectors so that the matching score can be calculated easily for recommendations [36], [37]. Content-based recommendation methods generally take advantage of additional knowledge about users or items, such as user demographics or item descriptions, to enhance user and item representations for improving recommendation performance [38]. Note that as textual information is one of the most available contents for users and items, we mainly focus on text as content in this survey. Due to the remarkable representation learning capabilities, deep learning techniques have been effectively applied to develop recommender systems [5], [34]. For instance, NeuMF is proposed to model non-linear interactions between users and items by replacing the general inner product with DNNs [39]. Considering that data in RecSys can be naturally represented as graph-structured data, GNN techniques are treated as the main deep learning approaches for learning meaningful representations of nodes (i.e., users and items) via message propagation strategies for recommender systems [1],\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/abdd/abddb41d-3bdb-48c6-843b-40ebf5d750a3.png\" style=\"width: 50%;\"></div>\nFigure 2: A timeline of milestones in the domains of recommender systems (RecSys) and language models (LMs). In order t align RecSys and LMs domains, the timeline is organized regardless of the exact time period but according to three stage traditional models, pre-trained language models/deep learning-based models, and the era of LLMs as highlighted in colors.\n[40]\u2013[42]. In order to integrate textual knowledge about users and items, DeepCoNN is developed to use CNNs to encode users\u2019 reviews written for items with two parallel neural networks so as to contribute to rating predictions in recommender systems [8]. Meanwhile, a neural attention framework NARRE is introduced to simultaneously predict users\u2019 ratings towards items and generate review-level explanations for the predictions [43]. Recently, language models have been increasingly utilized in recommender systems due to their capacity to comprehend and produce human natural language. These models are designed to comprehend the semantics and syntax of human natural language, thereby enabling RecSys to provide more personalized recommendations, such as news recommendations [44], [45], and drug recommendations [46]. Specifically, a sequential recommendation method called BERT4Rec is proposed to adopt Bidirectional Encoder Representations from Transformers (i.e., BERT) to model the sequential nature of user behaviors [47]. Furthermore, to take advantage of Transformer\u2019s capability for language generation, Li et al. [48] design a transformer-based framework to simultaneously make item recommendations and generate explanations in recommender systems.\n# 2.2 From Pre-trained Language Models (PLMs) to Large Language Models (LLMs)\nAs a type of advanced Artificial Intelligence (AI) techniques, LLMs are trained on a large amount of textural data with billions of parameters to understand the patterns and structures of natural language. There are several classical types of pre-trained language models (PLMs) available, such as BERT (Bidirectional Encoder Representations from Transformers) [49], GPT (Generative Pre-trained Transformer) [50], and T5 (Text-To-Text Transfer Transformer) [51]. Typically, these language models fall into three main categories: encoder-only models, decoder-only models, and encoderdecoder models. BERT, GPT, and T5 are distinct models based on the Transformer architecture [52]. More specifically, BERT, an encoder-only model, uses bi-directional attention to process token sequences, considering both the left and right context of each token. It is pre-trained based on massive amounts of text data using tasks like masked language modeling and\nT5, GPT-3, ChatGPT, Vicuna, LLaMA, GPT-4, LLaMA2, etc.\nLLM-based RecSys POD, RecMind, RecAgent, etc. P5, PALR, Chat-Rec, TALLRec, (see Table 1/2/3 for more)\nnext-sentence prediction, thereby capturing the nuances of language and meaning in context. This process translates text into a vector space, facilitating nuanced and context-aware analyses. On the other hand, GPT, based on the transformer decoder architecture, uses a self-attention mechanism for onedirectional word sequence processing from left to right. GPT is mainly adopted in language generation tasks, mapping embedding vectors back to text space, and generating contextually relevant responses. At last, T5, an encoderdecoder model, could handle any text-to-text task by converting every natural language processing problem into a text generation problem. For instance, it can re-frame a sentiment analysis task into a text sequence, like \u2019sentiment: I love this movie.\u2019, which adds \u2019sentiment:\u2019 before \u2019I love this movie.\u2019. Then it will get the answer \u2019positive\u2019. By doing so, T5 uses the same model, objective, and training procedure for all tasks, making it a versatile tool for various NLP tasks. Due to the increasing scale of models, LLMs have revolutionized the field of NLP by demonstrating unprecedented capabilities in understanding and generating human-like textual knowledge [18], [53]. These models (e.g., GPT-3 [15], LaMDA [54], PaLM [55], and Vicuna [56]) often based on transformer architectures, undergo training on extensive volumes of text data. This process enables them to capture complex patterns and nuances in human language. Recently, LLMs have demonstrated remarkable capabilities of ICL, a concept that is central to their design and functionality. ICL refers to the model\u2019s capacity to comprehend and provide answers based on the input context as opposed to merely relying on inside knowledge obtained through pre-training. Several works have explored the utilization of ICL in various tasks, such as SG-ICL [57] and EPR [58]. These works show that ICL allows LLMs to adapt their responses based on input context instead of generating generic responses. Another technique that can enhance the reasoning abilities of LLMs is chain-of-thought (CoT). This method involves supplying multiple demonstrations to describe the chain of thought as examples within the prompt, guiding the model\u2019s reasoning process [59]. An extension of the CoT is the concept of selfconsistency, which operates by implementing a majority voting mechanism on answers [60]. Current researches continue to delve into the application of CoT in LLMs, such as STaR [61], THOR [62], and Tab-CoT [63]. By offering a\nset of prompts to direct the model\u2019s thought process, CoT enables the model to reason more effectively and deliver more accurate responses. With the powerful abilities mentioned above, LLMs have shown remarkable potential in various fields, such as chemistry [17], education [64], and finance [65]. These models, such as ChatGPT, have also been instrumental in enhancing the functionality and user experience of RecSys. One of the key applications of LLMs in RecSys is the prediction of user ratings for items. This is achieved by analyzing historical user interactions and preferences, which in turn enhances the accuracy of the recommendations [66], [67]. LLMs have also been employed in sequential recommendations, which analyze the sequence of user interactions to predict their next preference, such as TALLRec [68], M6-Rec [69], PALR [70], and P5 [71]. Moreover, LLMs, particularly ChatGPT, have been utilized to generate explainable recommendations. One such example is Chat-Rec [3], which leverages ChatGPT to provide clear and comprehensible reasoning behind its suggestions, thereby fostering trust and user engagement. Furthermore, the interactive and conversational capabilities of LLMs have been harnessed to create a more dynamic recommendation experience. For instance, UniCRS [72] develops a knowledge-enhanced prompt learning framework to fulfill both conversation and recommendation subtasks based on a pre-trained language model. UniMIND [73] proposes a unified multi-task learning framework by using promptbased learning strategies in conversational recommender systems. Furthermore, it is worth noting that to investigate the potential of LLMs in learning on graphs, Chen et al. [18] introduce two possible pipelines: LLMs-as-Enhancers (e.g., LLMs enhance the textual information of node attributes) and LLMs-as-Predictors (e.g., LLMs serve as independent predictor in graph learning like link prediction problems), which provide guidance on the design of LLMs for graphbased recommendations.\n# 3 DEEP REPRESENTATION LEARNING FOR LLMBASED RECOMMENDER SYSTEMS\nUsers and items are atomic units of recommender systems. To denote items and users in recommender systems, the straightforward method assigns each item or user a unique index (i.e., discrete IDs). To capture users\u2019 preferences towards items, ID-based recommender systems are proposed to learn representations of users and items from user-item interactions. In addition, since textual side information about users and items provides rich knowledge to understand users\u2019 interests, textual side information-enhanced recommendation methods are developed to enhance user and item representation learning in an end-to-end training manner for recommender systems. In this section, we will introduce these two categories that take advantage of language models in recommender systems. These two kinds of recommender systems are illustrated in Figure 3.\n# 3.1 ID-based Recommender Systems\nRecommender systems are commonly used to affect users\u2019 behaviors for making decisions from a range of candidate items. These user behaviors (e.g., click, like, and subscription)\nare generally represented as user-item interactions, where users and items are denoted as discrete IDs. Modern recommendation approaches are proposed to model these behaviors by learning embedding vectors of each ID representation. Generally, in LLM-based recommendation systems, an item or a user can be represented by a short phrase in the format of \u201c[prefix] [ID]\u201d, where the prefix denotes its type (i.e., item or user) and the ID number helps identify its uniqueness. As the early exploration of LLM-based methods, a unified paradigm called P5 is proposed to facilitate the transfer of various recommendation data formats [71], such as useritem interactions, user profiles, item descriptions, and user reviews, into natural language sequences by mapping users and items into indexes. Note that the pre-trained T5 backbone is used to train the P5 with personalized prompts. Meanwhile, P5 incorporates the normal index phrase with a pair of angle brackets to treat these indexes as special tokens in the vocabulary of LLMs (e.g., < item 6637 >), avoiding tokenizing the phrases into separate tokens. Based on P5, Hua et al. put forward four straightforward but effective indexing solutions [74]: sequential indexing, collaborative indexing, semantic (content-based) indexing, and hybrid indexing, underscoring the significance of indexing methods. Different from P5\u2019s randomly assigning numerical IDs to each user or item, Semantic IDs, a tuple of codewords with semantic meanings for each user or item, is proposed to serve as unique identifiers, each carrying semantic meaning for a particular user or item [75]. Meanwhile, to generate these codewords, a hierarchical method called RQ-VAE is also proposed [75] to leverage Semantic IDs, where recommendation data formats can be effectively transformed into natural language sequences for transformer-based models.\n# 3.2 Textual Side Information-enhanced Recommender Systems\nDespite the aforementioned success, ID-based methods suffer from intrinsic limitations. That is due to the fact that pure ID indexing of users and items is naturally discrete, which cannot provide sufficient semantic information to capture representations of users and items for recommendations. As a result, it is very challenging to perform relevance calculations based on index representations among users and items, especially when user-item interactions are severely sparse. Meanwhile, ID indexing usually requires modifying the vocabularies and altering the parameters of LLMs, which brings additional computation costs. To address these limitations, a promising alternative solution is to leverage textual side information of users and items, which includes user profiles, user reviews for items, and item titles or descriptions. Specifically, given the textual side information of an item or a user, language models like BERT can serve as the text encoder to map the item or user into the semantic space, where we can group similar items or users and figure out their differences in a more finegrained granularity. For instance, Li et al. have investigated the performance comparison between ID and modality-based recommender systems, showing that ID-based recommender systems might be challenged by recommender systems\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8d78/8d783bb7-f86e-4ac8-b010-22f2faaa5d0a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3: An illustration of two methods for representing users and items in LLM-based recommender systems: ID based Representation which denotes user-item interactions with discrete identities, and Textual Side Information-enhance Representation which leverages textual side information of users and items, such as user reviews of items.</div>\nthat can better utilize side information [76]. Meanwhile, Unisec [77] is one such approach that takes advantage of item descriptions to learn transferable representations from various recommendation scenarios. More specifically, Unisec also introduces a lightweight item encoder to encode universal item representations by using parametric whitening and a mixture-of-experts (MoE) enhanced adaptor. Besides, text-based collaborative filtering (TCF) is also explored by prompting LLMs like GPT-3 [78]. Compared to the previous ID-based collaborative filtering, TCF methods demonstrate positive performance, proving the potential of textual side information-enhanced recommender systems. However, solely relying on language models to encode item descriptions might excessively emphasize text features. To mitigate this issue, VQ-Rec [79] proposes to learn vector-quantized item representations, which can map item text into a vector of discrete indices (i.e., item codes) and use them to retrieve item representations from a code embedding table in recommendations. Beyond text features, Fan et al. [80] propose a novel method for the Zero-Shot Item-based Recommendation (ZSIR), focusing on introducing a Product Knowledge Graph (PKG) to LLMs to refine item features. More specifically, user and item embeddings are learned via multiple pre-training tasks upon the PKG. Moreover, ShopperBERT [81] investigates modeling user behaviors to denote user representations in e-commerce recommender systems, which pre-trains user embedding through several pre-training tasks based on user purchase history. Furthermore, IDA-SR [81], an ID-Agnostic User Behavior Pre-training framework for Sequential Recommendation, directly retains representations from text information using pre-trained language models like BERT. Specifically, given an item i and its description with m tokens Di = {t1, t2, ..., tm}, an extra start-ofsequence token [CLS] is added to the description Di = {[CLS], t1, t2, ..., tm}. Then, the description is fed as the input to LLMs. Finally, the embedding of the token [CLS] could be used as the ID-agnostic item representation.\n# 4 PRE-TRAINING & FINE-TUNING LLMS FOR RECOMMENDER SYSTEMS\nIn general, there are three key manners in developing and deploying LLMs in recommendation tasks, namely, pre-training, fine-tuning, and prompting. In this section, we first introduce the pre-training and fine-tuning paradigms, which are shown in Figure 4 and Figure 5, respectively.\nMore specifically, we will focus on the specific pre-training tasks applied in LLMs for recommender systems and finetuning strategies for better performance in downstream recommendation tasks. Note that the works mentioned below are summarized in Table 1 and Table 2.\n# 4.1 Pre-training Paradigm for Recommender Systems\nPre-training is an important step in developing LLMs, which inherits the idea of transfer learning. It involves training LLMs on a vast amount of corpus consisting of diverse and unlabeled text data. This strategy enables LLMs to acquire a broad understanding of various linguistic aspects, including grammar, syntax, semantics, and even common sense reasoning. Through pre-training, LLMs can learn to recognize and generate coherent and contextually appropriate responses. In general, there are two mainstream paradigms to pre-train LLMs from the view of Natural Language Processing, while the selection of the pre-training strategy depends on the specific model structure. For encoder-only or encoder-decoder Transformer structures, Masked Language Modeling (MLM) is widely adopted, which randomly masks tokens or spans in the sequence and requires LLMs to generate the masked tokens or spans based on the remaining context [91]. At the same time, Next Token Prediction (NTP) is deployed for pre-training decoder-only Transformer structures, which requires prediction for the next token based on the given context [50]. Both the two pre-training tasks involve completing conditional sentences, but there are differences in their approaches. The Masked Language Model (MLM) task predicts masked tokens in a bidirectional context, while the Next Sentence Prediction (NTP) task only considers the previous context. As a result, MLM could assist LLMs in better understanding the meanings of tokens, while NTP is more natural for language generation tasks. In recommender systems, most of the existing works follow the two classical pre-training paradigms. Next, we will introduce several representative methods. PTUM [82] proposes two similar pre-training tasks, Masked Behavior Prediction (MBP) and Next K behavior Prediction (NBP), to model user behaviors in recommender systems. Unlike language tokens, user behaviors are more diverse and thus more difficult to predict. In this case, instead of masking a span of tokens, PTUM only masks a single user behavior with the goal of predicting the masked behavior based on the other behaviors in the interaction sequence of the target user.\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023\n<div style=\"text-align: center;\">IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0bd4/0bd46c87-0cdb-41e4-8a5b-1870189f129d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">.g., [CLS] Please recommend ...... [MASK] to [SEP] <user_id></div>\nFigure 4: A workflow of pre-training LLMs for recommender systems in terms of two representative methods: Masked Language Modeling which randomly masks tokens or spans in the sequence and requires LLMs to generate the masked tokens or spans based on the remaining context, and Next Token Prediction which requires prediction for the next token based on the given context.\n<div style=\"text-align: center;\">Table 1: Pre-training methods for LLM-empowered RecSys.</div>\nParadigms\nMethods\nPre-training Tasks\nCode Availability\nPre-training\nPTUM [82]\nMasked Behavior Prediction\nhttps://github.com/wuch15/PTUM\nNext K Behavior Prediction\nM6 [69]\nAuto-regressive Generation\nNot available\nP5 [71]\nMulti-task Modeling\nhttps://github.com/jeykigung/P5\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2257/22578b82-3040-4612-b155-26ad48d4c150.png\" style=\"width: 50%;\"></div>\nFigure 5: A workflow of fine-tuning LLMs for recommender systems in terms of two representative methods: Full-model Fine-tuning which involves changing the entire model weights, and Parameter-efficient Fine-tuning which involves fine-tuning a small proportion of model weights or a few extra trainable weights while fixing most of the parameters in LLMs.\nOn the other side, NBP models the relevance between past and future behaviors, which is crucial for user modeling. The goal of NBP is to predict the next k behaviors based on the user-item interaction history. Considering the time sequence of user behaviors, NBP could naturally simulate the users and thus demonstrate better performance. M6 [69] also adopts two pre-training objectives motivated by the two classical pre-training tasks, namely a textinfilling objective and an auto-regressive language generation objective, corresponding to the above two pre-training tasks, respectively. To be more specific, the text-infilling objective exhibits the pre-training task of BART [92], which randomly masks a span with several tokens in the text sequence and predicts these masked spans as the pre-training target, providing the capability to assess the plausibility of a text or an event in the recommendation scoring tasks. Meanwhile,\nthe auto-regressive language generation objective follows the Next Token Prediction task in natural language pre-training, but it is slightly different as it predicts the unmasked sentence based on the masked sequence. Additionally, P5 adopts multi-mask modeling and mixes datasets of various recommendation tasks for pre-training. In this case, it can be generalized to various recommendation tasks and even unseen tasks with zero-shot generation ability [71]. Across different recommendation tasks, P5 applies a unified indexing method for representing users and items in language sequence as stated in Section 3 so that the Masked Language Modelling task could be employed.\n# 4.2 Fine-tuning Paradigm for Recommender Systems\nFine-tuning is a crucial step in deploying pre-trained LLMs for specific downstream tasks. Especially for recommen-\n<div style=\"text-align: center;\">IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 Table 2: Fine-tuning methods for LLM-empowered RecSys.</div>\nParadigms\nMethods\nReferences\nFine-tuning\nFull-model Fine-tuning\n[83], [84], [85], [86], [87], [88], and [89]1\nParameter-efficient Fine-tuning\n[68]2, [90], and [69]\nCode Availability: 1https://github.com/veason-silverbullet/unitrec, 2https://github.com/sai990323/tallrec\ndation tasks, LLMs require fine-tuning to grasp more domain knowledge. Particularly, the fine-tuning paradigm involves training the pre-trained model based on task-specific recommendation datasets that include user-item interaction behaviors (e.g., purchase, click, ratings) and side knowledge about users and items (e.g., users\u2019 social relations and items\u2019 descriptions). This process allows the model to specialize its knowledge and parameters to improve performance in the recommendation domain. In general, fine-tuning strategies can be divided into two categories according to the proportion of model weights changed to fit the given task. One is full-model fine-tuning, which changes the entire model weights in the fine-tuning process. By considering the computation cost, the other is parameter-efficient fine-tuning, which aims to change only a small part of weights or develop trainable adapters to fit specific tasks.\n# 4.2.1 Full-model Fine-tuning\nAs a straightforward strategy in deploying pre-trained LLMs to fit specific downstream recommendation tasks, full-model fine-tuning involves changing the entire model weights. For example, RecLLM [83] is proposed to fine-tune LaMDA as a Conversational Recommender System (CRS) for YouTube video recommendation. Meanwhile, GIRL [87] leverages a supervised fine-tuning strategy for instructing LLMs in job recommendation. However, directly fine-tuning LLMs might bring unintended bias into recommender systems, producing serious harm toward specific groups or individuals based on sensitive attributes such as gender, race, and occupation. To mitigate such harmful effects, a simple LLMs-driven recommendation (LMRec) [84] is developed to alleviate the observed biases through train-side masking and test-side neutralization of non-preferential entities, which achieves satisfying results without significant performance drops. TransRec [85] studies pre-trained recommender systems in an end-to-end manner, by directly learning from the raw features of the mixture-of-modality items (i.e., texts and images). In this case, without relying on overlapped users or items, TransRec can be effectively transferred to different scenarios. Additionally, Carranza et al. [86] propose privacypreserving large-scale recommender systems by applying differentially private (DP) LLMs, which relieves certain challenges and limitations in DP training. Contrastive learning has also emerged as a popular approach for fine-tuning LLMs in recommender systems. Several methods have been proposed in this direction. SBERT [88] introduces a triple loss function, where an intent sentence is paired with an anchor, and corresponding products are used as positive and negative examples in the e-commerce domain. Additionally, UniTRec [89] proposes a unified framework that combines discriminative matching\nscores and candidate text perplexity as contrastive objectives to improve text-based recommendations.\n# 4.2.2 Parameter-efficient Fine-tuning\nFull-model fine-tuning requires large computational resources as the size of LLMs scales up. Currently, it is infeasible for a single consumption-level GPU to fine-tune the most advanced LLMs, which usually have more than 10 billion parameters. In this case, Parameter-efficient Finetuning (PEFT) targets fine-tuning LLMs efficiently with lower requirements for computational resources. PEFT involves fine-tuning a small proportion of model weights or a few extra trainable weights while fixing most of the parameters in LLMs to achieve comparable performance with full-model fine-tuning. Currently, the most popular PEFT methods lie in introducing extra trainable weights as adapters. The adapter structure is designed for embedding into the transformer structure of LLMs [93]. For each Transformer layer, the adapter module is added twice: the first module is added after the projection following the multi-head attention, and the other is added after the two feed-forward layers. During fine-tuning, the original weights of pre-trained LLMs are fixed, while the adapters and layer normalization layers are fine-tuned to fit downstream tasks. Thus, adapters contribute to the expansion and generalization of LLMs, relieving the problem of full-model fine-tuning and catastrophic forgetting. Inspired by the idea of adapters and low intrinsic ranks of weight matrices in LLMs, Low-Rank Adaptation of LLMs (LoRA) [94] introduces low-rank decomposition to simulate the change of parameters. Basically, LoRA adds a new pathway to specific modules handling matrix multiplication in the original structure of the LLMs. In the pathway, two serial matrices first reduce the dimension to a predefined dimension of the middle layer and then increase the dimension back. In this case, the dimension of the middle layer could simulate the intrinsic rank. In recommender systems, PEFT can greatly reduce the computational cost of fine-tuning LLMs for recommendation tasks, which requires less update and maintains most of the model capabilities. TallRec [68] introduces an efficient and effective tuning framework on the LLaMA-7B model and LoRA for aligning LLMs with recommendation tasks, which can be executed on a single RTX 3090. GLRec [90] takes advantage of LoRA for fine-tuning and adapting LLMs as job recommenders. LLaRA [95] also utilizes LoRA for fine-tuning LLMs, enabling LLMs to fit different tasks. Moreover, M6 [69] applies LoRA fine-tuning, making it feasible to deploy LLMs in phone devices.\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8939/8939e2e1-df5d-40d5-b679-94bd14d562dc.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 6: A workflow of prompting LLMs for recommender systems in terms of three representative methods: In-context Learning (top) which requires no parameter update of LLMs, Prompt Tuning (middle) which adds new prompt tokens to LLMs and optimizes the prompt along with minimal parameter updates at the input layer of LLMs, and Instruction Tuning (bottom) which fine-tunes LLMs over multiple tasks-specific prompts, also known as instructions.</div>\n# 5 PROMPTING LLMS FOR RECOMMENDER SYSTEMS\nApart from pre-training and fine-tuning paradigms, prompting serves as the latest paradigm for adapting LLMs to specific downstream tasks with the help of task-specific prompts. A prompt refers to a text template that can be applied to the input of LLMs. For example, a prompt \u201cThe relation between and is .\u201d can be designed to deploy LLMs for relation extraction tasks. Prompting enables LLMs to unify different downstream tasks into language generation tasks, which are aligned to their objectives during pretraining [122]. Compared to pre-training and fine-tuning LLMs that require large task-specific datasets and costly parameter updates, prompting makes it possible to adapt LLMs to recommendation tasks in more lightweight manners, such as providing appropriate task instructions in natural language. For instance, the popular ChatGPT retrieval plugin1 serves as an API schema of prompting, which retrieves customized documents as prompts to the input of ChatGPT. As highlighted in Table 3, we categorize the insights of prompting LLMs for recommendations into three representative approaches, namely LLMs act as recommender, Bridge LLMs and RecSys, and LLM-based autonomous agent, along with each subclass of prompting methods. Recent research has actively explored prompting to facilitate the performance of LLMs for recommendations, advanced techniques like In-context Learning (ICL) and Chain-of-thought (CoT) are increasingly investigated to manually design prompts for various recommendation tasks. In addition, prompt tuning serves as an additive\n1. https://github.com/openai/chatgpt-retrieval-plugin\ntechnique of prompting, by adding prompt tokens to LLMs and then updating them based on task-specific recommendation datasets. More recently, instruction tuning that combines the pre-training & fine-tuning paradigm with prompting [123] is explored to fine-tune LLMs over multiple recommendation tasks with instruction-based prompts, which enhances the zero-shot performance of LLMs on unseen recommendation tasks. Figure 6 compares the representative methods corresponding to each of the aforementioned three prompting techniques of LLMs, in terms of the workflow of LLMs in recommender systems, input formation, and parameter update of LLMs (i.e., either tunable or frozen). In this section, we will discuss the prompting, prompt tuning, and instruction tuning techniques in detail, for improving the performance of LLMs on recommendation tasks. In summary, Table 3 categorizes the existing works according to the aforementioned three techniques, including the specific recommendation tasks and the LLM backbones considered in these works.\n# 5.1 Prompting\nThe key idea of prompting is to keep LLMs frozen (i.e., no parameters updates), and adapt LLMs to downstream tasks via task-specific prompts. To recap the development of prompting strategies for adapting LLMs to downstream tasks, early-stage conventional prompting methods mainly target unifying downstream tasks to language generation manners, such as text summarization, relation extraction, and sentiment analysis. Later on, ICL [15] emerges as a powerful prompting strategy that allows LLMs to learn new tasks (i.e., tasks with knowledge demanding objectives) based on contextual information. In addition, another up-\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 10 Table 3: Prompting, prompt tuning, and instruction tuning methods for LLM-empowered RecSys. In particular, we categorize the integration of LLMs and RecSys into three representative approaches: \u27e8LLMs act as recommender \u27e9(e.g., LLMs directly perform recommendation tasks, such as Tok-K recommendation and explanation generation), \u27e8Bridge LLMs and RecSys \u27e9 (e.g., LLMs provide data augmentation for training recommendation models), and \u27e8LLM-based autonomous agent \u27e9(e.g., LLMs simulate human-level user behaviors in RecSys & Manage complex recommendations into sub-tasks).\nParadigms\nMethods\nLLM Tasks\nLLM Backbones\nReferences\nPrompting\nConventional Prompting\nText Summarization\nChatGPT\n[48]\nRelationship Extraction\nChatGPT\n[4]\nGPT-4\n[96]1\nIn-context Learning (ICL)\nChatGPT\n[48], [67], [96]1, [97]2, [98]3, [99]4\nT5\n[100], [101]5\nRecommendation Tasks\n(e.g., rating prediction, top-K recommendation,\nconversational recommendation, explanation generation, etc.)\nPaLM\n[102], [103]\nGPT-4\n[104]\nChatGPT\n[104], [105]6, [106]7\nData Augmentation of RecSys\nGPT-3\n[107]\nChatGPT\n[3], [108]\nGPT-3\n[109]\nGPT-2\n[110]\nData Refinement of RecSys\nChatGLM\n[111]8\nAPI Call of RecSys & Tools\nChatGPT\n[112], [113]9\nGPT-4\n[114]\nUser Behavior Simulation\nChatGPT\n[115]10, [116]11\nTask Planning\nLLaMA\n[117]\nChain-of-thought (CoT)\nRecommendation Tasks\nT5\n[20]\nGPT-4\n[114]\nTask Planning\nChatGPT\n[112]\nPrompt Tuning\nHard Prompt Tuning\nRecommendation Tasks\nGPT-2\n[118]\nICL can be regarded as a subclass of prompt tuning, namely hard prompt tuning (see Section 5.2.1 for explanations)\nSoft Prompt Tuning\nT5\n[119], [120]\nGPT-2\n[118]\nPaLM\n[102]\nRecommendation Tasks\nM6\n[69]\nInstruction Tuning\nFull-model Tuning\nwith Prompt\nT5\n[20], [66]\nRecommendation Tasks\nLLaMA\n[70], [87]\nParameter-efficient Model\nTuning with Prompt\nRecommendation Tasks\nLLaMA\n[68]12, [90], [121]13\nCode Availability: 1https://github.com/AaronHeee/LLMs-as-Zero-Shot-Conversational-RecSys, 2https://github.com/rainym00d/LLM4RS, 3https://github.com/RUCAIBox/LLMRank, 4https://github.com/RUCAIBox/iEvaLM-CRS, 5https://github.com/JacksonWuxs/PromptRec, 6https://github.com/Jyonn/GENRE-requests, 7https://github.com/HKUDS/LLMRec, 8https://github.com/YunjiaXi/Open-WorldKnowledge-Augmented-Recommendation, 9https://github.com/jwzhanggy/Graph Toolformer, 10https://github.com/RUC-GSAI/YuLan-Rec, 11https://github.com/LehengTHU/Agent4Rec, 12https://anonymous.4open.science/r/LLM4Rec-Recsys, 13https://github.com/rutgerswiselab/GenRec.\nto-date prompting strategy named CoT [59] serves as a particularly effective method for prompting LLMs to address downstream tasks with complex reasoning.\n# 5.1.1 Conventional Prompting\nThere are two major approaches for prompting pre-trained language models to improve the performance on specific downstream tasks. One approach is prompt engineering, which generates prompt by emulating text that language models encountered during pre-training (e.g., text in NLP tasks). This allows pre-trained language models to unify downstream tasks with unseen objectives into language generation tasks with known objectives. For instance, Liu et al. [48] consider prompting ChatGPT to format the review summary task in recommendations into generic language generation task of text summarization, using a prompt \u201cWrite a short sentence to summarize\u201d. Another approach is few-shot prompting, where a few input-output examples (i.e., shots) are provided to prompt and guide pre-trained language\nmodels to generate desired output for specific downstream tasks. Due to the huge gap between language generation tasks (i.e., the pre-training objectives of LLMs) and downstream recommendation tasks, most conventional prompting methods have only shown limited applications in specific recommendation tasks that have similar nature to language generation tasks, such as the review summary of users [48] and the relation labeling between items [4].\nAlongside the introduction of GPT-3 [15], ICL is proposed as an advanced prompting strategy, which significantly boosts the performance of LLMs on adapting to many downstream tasks. Gao et al. [122] attribute the success of ICL in prompting LLMs for downstream tasks to two designs: prompt and in-context demonstrations. In other words, the key innovation of ICL is to elicit the in-context ability of LLMs for learning (new or unseen) downstream tasks from context during the inference stage. In particular, two settings\nproposed in ICL are prevalently leveraged for prompting LLMs for RecSys. One is the few-shot setting, in which a few demonstrations with contexts and desired completions of the specific downstream tasks are provided along with prompts. The other is the zero-shot setting, where no demonstrations will be given to LLMs but only natural language descriptions of the specific downstream tasks are appended to the prompt. As shown in Figure 7, a brief template of zero-shot ICL and few-shot ICL for recommendation tasks is provided. Many existing works consider both few-shot ICL and zero-shot ICL settings at the same time to compare their performance under the same recommendation tasks. Typically, few-shot ICL can outperform zero-shot ICL since additional in-context demonstrations are provided to LLMs. Despite the reduction in performance, zero-shot ICL entirely relieves the requirement of task-specific recommendation datasets to form in-context demonstrations and can be suitable for certain tasks like conversational recommendations, where users are not likely to provide any demonstration to LLMs. For example, Wang et al. [99] prompt ChatGPT for conversational recommendations with a zero-shot ICL template containing two parts: a text description of conversational recommendation tasks (e.g., \u201cRecommend items based on user queries in the dialogue.\u201d), and a format guideline in natural languages, such as \u201cThe output format should be \u27e8no.\u27e9\u27e8item title\u27e9.\u201d, making the recommendation results easier to parse. To adapt LLMs to recommendation tasks via ICL, a straightforward approach is to teach LLMs to act as recommenders. For instance, Liu et al. [48] employ ChatGPT and propose separate task descriptions tailored to different recommendation tasks, including top-K recommendation, rating prediction, and explanation generation, to perform ICL based on corresponding input-output examples of each recommendation task. For instance, the user rating history is given as an example for rating prediction tasks. Similarly, other existing works propose their distinct insights into designing the in-context demonstrations for better recommendation performance. For example, a text description of role injection, such as \u201cYou are a book rating expert.\u201d, is proposed in [67] to augment the in-context demonstrations, which prevents LLMs from refusing to complete the recommendation tasks (e.g., LLMs sometimes respond with \u201cAs a language model, I don\u2019t have the ability to recommend ...\u201d for recommendation tasks). Apart from teaching LLMs to directly act as RecSys, ICL is also leveraged to bridge LLMs and conventional recommendation models. For example, a framework named Chat-Rec [3] is proposed to bridge ChatGPT and traditional RecSys via ICL, where ChatGPT learns to receive candidate items from traditional RecSys and then refines the final recommendation results. What\u2019s more, Zhang [113] designs a textual API call template for external graph reasoning tools and successfully teaches ChatGPT to use those templates through ICL to access the graph-based recommendation results generated by the external tools. More recently, LLMbased autonomous agents have been explored to simulate user behaviors in RecSys, such as InteRecAgent [114], RecAgent [115], and Agent4Rec [116], by equipping LLMs with memory and action modules. In particular, few-show ICL methods are designed to connect LLMs with these external modules, enabling LLMs to interact with RecSys\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/cbca/cbca32bb-a577-48d1-9ef4-94216c9030f5.png\" style=\"width: 50%;\"></div>\nFigure 7: A brief template of zero-shot ICL and few-shot ICL for recommendation tasks.\n# and simulate user behaviors like chatting and posting.\n# 5.1.3 Chain-of-thought (CoT) Prompting\n5.1.3 Chain-of-thought (CoT) Prompting Although ICL has shown great effectiveness in prompting LLMs for downstream tasks with in-context demonstrations, recent studies indicate that LLMs still have limited performance in reasoning-heavy tasks [59]. More specifically, by prompting LLMs with in-context examples of input-output pairs, the answers directly generated by LLMs often suffer from missing one or a few intermediate reasoning steps in multi-step problems like mathematical equations, leading to a broken reasoning logic that causes errors in the subsequent reasoning steps (i.e., \u201cone-step missing errors\u201d [59]). Similar multi-step problems also exist in RecSys, such as the multistep reasoning of user preferences based on the multi-turn dialogues in conversational recommendations. To address such limitations, CoT offers a special prompting strategy to enhance the reasoning ability of LLMs, by annotating intermediate reasoning steps to prompt. This enables LLMs to break down complicated decision-making processes and generate the final output with step-by-step reasoning. Considering the suitable prompting strategies for adapting LLMs to various downstream tasks with complex reasoning, Zhao et al. [19] discuss the combination of ICL and CoT prompting under two major settings: zero-shot CoT and few-shot CoT. By inserting tricky texts such as \u201cLet\u2019s think step by step\u201d and \u201cTherefore, the answer is\u201d to prompt, zero-shot CoT leads LLMs to generate task-specific reasoning steps independently, without providing any taskrelevant instruction or grounding example. As for few-shot CoT, task-specific reasoning steps are manually designed for each demonstration in ICL, where the original input-output examples are augmented to input-CoT-output manners. Besides, CoT can also augment the task descriptions in ICL demonstrations, by adding interpretable descriptions of reasoning steps based on task-specific knowledge. In practice, the design of appropriate CoT reasoning steps highly depends on the contexts and objectives of the specific recommendation tasks. For example, a simple CoT template \u201cPlease infer the preference of the user and recommend suitable items.\u201d is proposed to guide LLMs to first infer the user\u2019s explicit preference and then generate\nfinal recommendations [20]. Below, we present a preliminary idea of CoT prompting, through an example in the context of e-commerce recommendations. [CoT Prompting] Based on the user purchase history, let\u2019s think step-by-step. First, please infer the user\u2019s high-level shopping intent. Second, what items are usually bought together with the purchased items? Finally, please select the most relevant items based on the shopping intent and recommend them to the user.\nMore recently, studies like InteRecAgent [114] and RecMind [112] have employed CoT prompting, enabling LLMs to act as agents and manage complex recommendations into sub-tasks by generating plans for utilizing external tools. Beyond the RecSys field, a recent research [124] has revealed the great effectiveness of adopting CoT prompting to facilitate the graph reasoning ability of LLMs (T5 particularly) by modeling the reasoning steps as nodes and connecting the reasoning paths as edges instead of a sequential chain. We believe that similar ideas can be potentially transferred and contribute to the CoT prompting for RecSys, based on the fact that recommendation tasks can be considered as a special case of link prediction problems in graph learning.\n# 5.2 Prompt Tuning\nIn contrast to manually prompting LLMs for downstream tasks (e.g., manually generate task-specific prompt in natural language), prompt tuning serves as an additive technique of prompting, which adds new prompt tokens to LLMs and optimizes the prompt based on the task-specific dataset. Generally, prompt tuning requires less task-specific knowledge and human effort than manually designing prompts for specific tasks and only involves minimal parameter updates of the tunable prompt and the input layer of LLMs. For example, AutoPrompt [125] takes the step of decomposing prompt into a set of vocabulary tokens, and finding the suitable tokens to language models via gradient-based search with respect to the performance on specific tasks. According to the definition, prompts can be either discrete (i.e., hard) or continuous (i.e., soft) that guide LLMs to generate the expected output [126]. Thus, we categorize prompt tuning strategies for prompting LLMs for RecSys into hard prompt tuning and soft prompt tuning, as illustrated below.\n# 5.2.1 Hard Prompt Tuning\nHard prompt tuning is to generate and update discrete text templates of prompt (e.g., in natural language), for prompting LLMs to specific downstream tasks. Dong et al. [126] argue that ICL can be considered as a subclass of hard prompt tuning and regard the in-context demonstrations in ICL as a part of the prompt. From this perspective, ICL performs hard prompt tuning for prompting LLMs to downstream recommendation tasks by refining prompts in natural language based on task-specific recommendation datasets. Despite the effectiveness and convenience of generating or refining natural language prompts for downstream recommendation tasks, hard prompt tuning inevitably faces the challenge of discrete optimization, which requires laborious trial and error to discover the vast vocabulary space\nin order to find suitable prompts for specific recommendation tasks.\n# 5.2.2 Soft Prompt Tuning\nIn contrast to discrete prompt, soft prompt tuning employs continuous vectors as prompt (e.g., text embeddings), and optimizes the prompt based on task-specific datasets, such as using gradient methods to update the prompt with respect to a recommendation loss. In LLMs, soft prompt tokens are often concatenated to the original input tokens at the input layer (e.g., tokenizer). During soft prompt tuning, only the soft prompt and minimal parameters at the input layer of LLMs will be updated. To improve the recommendation performance of LLMs, some existing works combine advanced feature extraction and representation learning methods to better capture and embed task-specific information in RecSys into soft prompts. For instance, Wu et al. [127] apply contrastive learning to capture user representations and encode them into prompt tokens, and Wang et al. [72] and Guo et al. [128] share the similar idea of encoding mutual information in cross-domain recommendations into soft prompt. In addition to directly embedding task-specific information into soft prompts, soft prompts can also be learned based on task-specific datasets. For example, randomly initialized soft prompts are adopted to guide T5 to generate desired recommendation results [119], where the soft prompt is optimized in an end-to-end manner with respect to a recommendation loss based on the T5 output. Compared to the hard prompt, the soft prompt is more feasible for tuning on continuous space but at a cost of explainability [119]. In other words, compared to taskspecific hard prompt in a natural language like \u201cYour task is to recommend ...\u201d, the relationships between the specific downstream tasks and the soft prompt written in continuous vectors are not interpretable to humans.\n# 5.3 Instruction Tuning\nAlthough prompting LLMs has demonstrated remarkable few-shot performance on unseen downstream tasks, recent studies demonstrated that prompting strategies have much poorer zero-shot ability [123]. To address the limitations, instruction tuning is proposed to fine-tune LLMs over multiple task-specific prompts. In other words, instruction tuning possesses features of both prompting and pre-training & fine-tuning paradigms. This helps LLMs gain better capabilities of exactly following prompts as instructions for diverse downstream tasks, which hence contributes to the enhanced zero-shot performance of LLMs on unseen tasks by accurately following new task instructions. The key insight of instruction tuning is to train LLMs to follow prompts as task instructions, rather than to solve specific downstream tasks. More specifically, instruction tuning can be divided into two stages: \u201cinstruction\u201d (i.e., prompt) generation and model \u201ctuning\u201d, since the straightforward idea of instruction tuning is the combination of prompting and fine-tuning LLMs. \u2022 Instruction (Prompt) Generation Stage. Formally, instruction tuning introduces a format of instructionbased prompt in natural language, which consists of task-oriented input (i.e., task descriptions based on\ntask-specific dataset) and desired target (i.e., corresponding output based on task-specific dataset) pairs. Considering the instruction tuning of LLMs for downstream recommendation tasks, Zhang et al. [20] propose a recommendation-oriented instruction template, including user preferences, intentions, and task forms, which serves as a common template for generating instructions for various recommendation tasks. More directly, three-part instruction templates in the form of \u201dtask description-input-output\u201d are used in [68], [70] to generate instructions based on task-specific recommendation datasets. \u2022 Model Tuning Stage. The second stage is to fine-tune LLMs over multiple aforementioned instructions for downstream tasks, where we categorize the existing works on RecSys, as shown in Table 3, according to the LLMs fine-tuning manners: full-model tuning and parameter-efficient model tuning (see Section 4.2 for explanations), since basically the same principles of finetuning LLMs are adopted in this stage. For example, Bao et al. [68] utilize LoRA to make the instruction tuning of LLaMA more lightweight for downstream recommendation tasks. In addition to textual data in RecSys, instruction tuning has recently been explored to enhance the graph understanding ability of LLMs for recommendation tasks. In particular, Wu et al. [90] propose an LLM-based prompt constructor to encode the paths of nodes (e.g., candidate items) and edges (e.g., relationships between items) in behavior graphs into natural language descriptions, which is subsequently used for instruction tuning an LLM-based recommender based on task-specific datasets.\n# 6 FUTURE DIRECTIONS\nIn this survey, we have comprehensively reviewed the recent advanced techniques for LLM-enhanced recommender systems. Since the adaption of LLMs to recommender systems is still in an early stage, there are still many challenges, which are also the opportunities. In this section, we discuss some potential future directions in this field.\n# 6.1 Hallucination Mitigation\nAlthough LLMs are used in various fields, a significant challenge is the phenomenon of \u2019hallucination\u2019, where language models generate outputs that are plausible-sounding but factually incorrect or not referable in the input data [129], [130]. For instance, considering a scenario where you are seeking today\u2019s news events, the LLMs erroneously recommend/generate news that, in fact, does not exist. The causes of this problem are manifold such as source-reference divergence existing in the dataset, and training&modeling choices of neural network models [131]. Moreover, the hallucination issue poses severe threats to users and society, especially in high-stakes recommendation scenarios such as medical recommendations or legal advice, where the dissemination of incorrect information can have severe real consequences. To address such issues, employing factual knowledge graphs as supplementary factual knowledge during the training and inference stages of LLMs for RecSys\nis promising to mitigate the hallucination problem. In addition, the model\u2019s output stage can be scrutinized to verify the accuracy and factuality of the produced content.\n# 6.2 Trustworthy Large Language Models for Recom-\n# 6.2 Trustworthy Large Language Models for Recommender Systems\nThe development of LLMs for RecSys has brought significant benefits to humans, including economic value creation, time and effort savings, and social benefits. However, these datadriven LLMs for RecSys might also pose serious threats to users and society [5], [132], [133], due to unreliable decision-making, unequal treatment of various consumers or producers, a lack of transparency and explainability, and privacy issues stemming from the extensive use of personal data for customization, among other concerns. As a result, there is an increasing concern about the issue of trustworthiness in LLMs for RecSys to mitigate the negative impacts and enhance public trust in LLM-based RecSys techniques. Thus, it is desired to achieve trustworthiness in LLMs for RecSys from four of the most crucial dimensions, including Safety&Robustness, Non-discrimination&Fairness, Explainability, and Privacy.\n# 6.2.1 Safety&Robustness\nLLMs have been proven to advance recommender systems in various aspects, but they are also highly vulnerable to adversarial perturbations (i.e., minor changes in the input) that can compromise the safety and robustness of their uses in safety-critical applications [53], [132]. These vulnerabilities towards noisy inputs are frequently carried out with malicious intent, such as to gain unlawful profits and manipulate markets for specific products [134]\u2013[137]. Therefore, it is crucial to ensure that the output of LLMs for recommender systems is stable given small changes in the LLMs\u2019 input. In order to enhance model safety and robustness, GPT-4 integrates safety-related prompts during reinforcement learning from human feedback (RLHF) [138]. However, the RLHF method requires a significant number of experts for manual labeling, which might not be feasible in practice. An alternative solution might involve the automatic pre-processing of prompts designed for recommender tasks before input to LLMs. This could include pre-processing for malicious prompts or standardizing prompts with similar purposes to have the same final input, thus potentially improving safety and robustness. In addition, as one of the representative techniques, adversarial training [139] can be used to improve the robustness of LLM-based recommender systems.\n# 6.2.2 Non-discrimination&Fairness\nLLMs, trained on vast datasets, often inadvertently learn and perpetuate biases and stereotypes in the human data that will later reveal themselves in the recommendation results. This phenomenon can lead to a range of adverse outcomes, from the propagation of stereotypes to the unfair treatment of certain user groups [2], [140], [141]. For instance, in the context of recommender systems, these biases can manifest as discriminatory recommendations, where certain items are unfairly promoted or demoted based on these learned biases. More recently, a few studies such as FaiRLLM [142]\nand UP5 [119] explore the fairness problem in recommender systems brought by LLMs, which only focus on user-side and item generation task. Concurrently, Hou et al. [98] guide LLMs with prompts to formalize the recommendation task as a conditional ranking task to improve item-side fairness. However, studies on non-discrimination and fairness in LLMs for RecSys are at a preliminary stage, further research is still needed.\n# 6.2.3 Explainability\nOwing to privacy and security considerations, certain companies and organizations choose not to open-source their advanced LLMs, such as ChatGPT and GPT-4, indicating that the architectures and parameters of these LLMs for RecSys are not publicly available for the public to understand their complex internal working mechanisms. Consequently, LLMs for RecSys can be treated as the \u2019black box\u2019, complicating the process for users trying to comprehend why a specific output or recommendation was produced. Recently, Bills et al. [143] try to use GPT-4 to generate natural language descriptions to explain the neuronal behavior in the GPT-2 model. While this study is foundational, it also introduces fresh perspectives for comprehending the workings of LLMs. Neurons exhibit intricate behaviors that may not be easily encapsulated through simple natural language. To this end, efforts should be made to understand how LLMs for RecSys function, so as to enhance the explainability of LLM-based recommender systems.\n# 6.2.4 Privacy\nPrivacy is a paramount concern when it comes to LLMs for RecSys. The reasons for this are multifold. On the one hand, the success of LLMs for recommender systems highly depends on large quantities of data that are collected from a variety of sources, such as social media and books. Users\u2019 sensitive information (e.g., email and gender) contained in data is likely to be used to train modern LLMs for enhancing prediction performance and providing personalized experiences, leading to the risk of leaking users\u2019 private information. On the other hand, these systems often handle sensitive user data, including personal preferences, online behaviors, and other identifiable information. If not properly protected, this data could be exploited, leading to breaches of privacy. Therefore, ensuring the privacy and security of this data is crucial. Carlini et al. [144] show that LLMs might reveal some uses\u2019 real identity or private information when generating text. Recently, Li et al. [145] introduce RAPT that allows users to customize LLMs with their private data based on prompt tuning. It provides a direction on how to protect user privacy at LLMs for RecSys. Notably, concurrent to the recent advancement of federated learning [146] for facilitating data privacy in recommender systems [147], [148], LLMs have brought distinctive opportunities to the interplay between data privacy and federated learning [149]. For instance, Zhuang et al. [150] systematically review the remarkable capabilities of LLMs as foundation models for federated learning, where LLMs are leveraged as controllers to seamlessly connect distributed devices. In particular, such scalable frameworks empowered by LLMs support the availability of federated learning on\ndistributed data sources, which guarantees more privacypreserving recommender systems by enabling localized learning and data privacy in a decentralized manner.\n# 6.3 Vertical Domain-Specific LLMs for Recommender Systems\n# 6.3 Vertical Domain-Specific LLMs for Recommender\nGeneral LLMs, such as ChatGPT, whose powerful generation and inference capabilities make them a universal tool in various areas. Vertical domain-specific LLMs are LLMs that have been trained and optimized for a specific domain or industry, such as health [151] and finance [65]. Compared to general LLMs for RecSys, vertical domain-specific LLMempowered RecSys are more focused on the knowledge and skills of a particular domain and have a higher degree of domain expertise and practicality. Instead of sifting through irrelevant information, users can focus on content that is directly aligned with their work or personalized preferences. By providing tailored recommendations, vertical domainspecific LLMs for RecSys can save professionals a significant amount of time. More recently, existing works have presented vertical domain-specific LLMs that cover a wide range of areas, such as medical care [152], [153], law [154], [155], and finance [156]. Due to trained specifically, these vertical domain-specific LLMs can better understand and process domain-specific knowledge, terminology and context. Yet the requirement for vast amounts of domain-specific data to train these models poses significant challenges in data collection and annotation. As such, constructing high-quality domain datasets and using suitable tuning strategies for specific domains are necessary steps in the development of vertical domain-specific LLMs for RecSys. In particular, Jin et al. [157] propose a multilingual dataset named Amazon-M2 as a new setting of session-based recommendations from Amazon (i.e., sessions containing the interacted items of users) and inspire the opportunities to leverage LLMs as RecSys to learn on session graphs with multilingual and textual data, such as item (node) attributes including product titles, prices, and descriptions across session graphs of users from different locales (multilingual).\n# 6.4 Users&Items Indexing\nRecent research suggests that LLMs may not perform well when dealing with long texts in RecSys, as it can be difficult to effectively capture user-item interaction information in long texts [98]. On the other hand, user-item interactions (e.g., click, like, and subscription) with unique identities (i.e., discrete IDs) in recommender systems contain rich collaborative knowledge and make great contributions to understanding and predicting user preferences, encompassing both explicit actions like ratings and reviews, as well as implicit behaviors like browsing history or purchase data. Several studies, including InstructRec [20], PALR [70], GPT4Rec [110] and UP5 [119], have attempted to utilize user-item history interaction information as text prompts inputted into LLMs (e.g., ChatGPT) in order to make recommendations. To address the long text problem, one possible solution is to perform user and item indexing for learning collaborative knowledge by incorporating user-item interactions. Therefore, rather than merely using text formats to represent users and items, advanced methods for indexing\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 users&items are desired to build LLM-based recommender systems. have with\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023 users&items are desired to build LLM-based recommender have\nIEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, SUBMISSION 2023\nusers&items are desired to build LLM-based recommender systems. hav with\nusers&items are desired to build LLM-based recommender systems.\n# 6.5 Fine-tuning Efficiency\nIn the application of LLMs to RecSys, fine-tuning refers to the process of adapting a pre-trained LLM to a specific task or domain, such as recommending movies [70] or books [68]. This process allows the model to leverage the general language understanding capabilities learned during pre-training while specializing its knowledge to the task at hand. However, fine-tuning can be computationally expensive, particularly for very large models and large datasets in recommender systems. Therefore, improving the efficiency of fine-tuning is a key challenge. In this case, Fu et al. [158] use adapter modules, which are small, plug-in neural networks that can be optimized separately from the main model, to achieve parameter-efficient transfer learning. However, the current adapter tuning techniques for RecSys fall slightly behind full-model fine-tuning when it comes to cross-platform image recommendation. The exploration of adapter tuning effects for multi-modal (i.e., both text and image) RecSys is a potential future direction. In addition, given that most typical adapter tuning does not help to speed up the training process in practice, it is important to explore effective optimization techniques to reduce the computational cost and time for RecSys through end-to-end training.\n# 6.6 Data Augmentation\nMost conventional studies in the recommender systems domain rely on real data-driven research, founded on the collection of user behavior data via user interaction in digital platforms or through the recruitment of annotators. Nonetheless, these approaches appear to be resource-intensive and may not be sustainable in the long term. The quality and variety of the input data directly influence the performance and versatility of the models. With the aim to overcome the shortcomings of real datacentric studies, Wang et al. [115] introduce RecAgent, a simulation paradigm for recommender systems based on LLMs, which includes a user module for browsing and communication on the social media, and a recommender module for providing search or recommendation lists. Additionally, LLM-Rec [109] incorporates four prompting strategies to improve personalized content recommendations, which demonstrates through experiments that diverse prompts and input augmentation techniques can enhance recommendation performance. Therefore, rather than solely deploying LLMs as recommender systems, utilizing them for data augmentation to bolster recommendations emerges as a promising strategy in the future.\n# 7 CONCLUSION\nAs one of the most advanced AI techniques, LLMs have achieved great success in various applications, such as molecule discovery and finance, owing to their remarkable abilities in language understanding and generation, powerful generalization and reasoning skills, and prompt adaptation to new tasks and diverse domains. Similarly, increasing efforts\nhave been made to revolutionize recommender systems with LLMs, so as to provide high-quality and personalized suggestion services. Given the rapid evolution of this research topic in recommender systems, there is a pressing need for a systematic overview that comprehensively summarizes the existing LLM-empowered recommender systems. To fill the gap, in this survey, we have provided a comprehensive overview of LLM-empowered RecSys from pre-training&fine-tuning and prompting paradigms, so as to provide researchers and practitioners in relevant fields with an in-depth understanding. Nevertheless, the current research on LLMs for RecSys is still in its early stage which calls for more systematic and comprehensive studies of LLMs in this field. Therefore, we also discussed some potential future directions in this field.\n# ACKNOWLEDGMENTS\nThe research described in this paper has been partly supported by NSFC (project no. 62102335), General Research Funds from the Hong Kong Research Grants Council (Project No.: PolyU 15200021, 15207322, and 15200023), internal research funds from The Hong Kong Polytechnic University (project no. P0036200, P0042693, P0048625, P0048752), Research Collaborative Project No. P0041282, and SHTM Interdisciplinary Large Grant (project no. P0043302). Xiangyu Zhao was supported by APRC-CityU New Research Initiatives (No.9610565, Start-up Grant for New Faculty of City University of Hong Kong), SIRG-CityU Strategic Interdisciplinary Research Grant (No.7020046, No.7020074), HKIDS Early Career Research Grant (No.9360163), and Ant Group (CCF-Ant Research Fund, Ant Group Research Fund).\n[1] W. Fan, Y. Ma, Q. Li, J. Wang, G. Cai, J. Tang, and D. Yin, \u201cA graph neural network framework for social recommendations,\u201d IEEE Transactions on Knowledge and Data Engineering, 2020. [2] X. Chen, W. Fan, J. Chen, H. Liu, Z. Liu, Z. Zhang, and Q. Li, \u201cFairly adaptive negative sampling for recommendations,\u201d in Proceedings of the ACM Web Conference 2023, 2023, pp. 3723\u20133733. [3] Y. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang, \u201cChat-rec: Towards interactive and explainable llms-augmented recommender system,\u201d arXiv preprint arXiv:2303.14524, 2023. [4] J. Chen, L. Ma, X. Li, N. Thakurdesai, J. Xu, J. H. Cho, K. Nag, E. Korpeoglu, S. Kumar, and K. Achan, \u201cKnowledge graph completion models are few-shot learners: An empirical study of relation labeling in e-commerce with llms,\u201d arXiv preprint arXiv:2305.09858, 2023. [5] W. Fan, X. Zhao, X. Chen, J. Su, J. Gao, L. Wang, Q. Liu, Y. Wang, H. Xu, L. Chen et al., \u201cA comprehensive survey on trustworthy recommender systems,\u201d arXiv preprint arXiv:2209.10117, 2022. [6] X. He, K. Deng, X. Wang, Y. Li, Y. Zhang, and M. Wang, \u201cLightgcn: Simplifying and powering graph convolution network for recommendation,\u201d in Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, 2020, pp. 639\u2013648. [7] W. Fan, T. Derr, Y. Ma, J. Wang, J. Tang, and Q. Li, \u201cDeep adversarial social recommendation,\u201d in 28th International Joint Conference on Artificial Intelligence (IJCAI-19). International Joint Conferences on Artificial Intelligence, 2019, pp. 1351\u20131357. [8] L. Zheng, V. Noroozi, and P. S. Yu, \u201cJoint deep modeling of users and items using reviews for recommendation,\u201d in Proceedings of the tenth ACM international conference on web search and data mining, 2017, pp. 425\u2013434. [9] S. Zhang, L. Yao, A. Sun, and Y. Tay, \u201cDeep learning based recommender system: A survey and new perspectives,\u201d ACM computing surveys (CSUR), vol. 52, no. 1, pp. 1\u201338, 2019.\n[10] W. Fan, C. Liu, Y. Liu, J. Li, H. Li, H. Liu, J. Tang, and Q. Li, \u201cGenerative diffusion models on graphs: Methods and applications,\u201d arXiv preprint arXiv:2302.02591, 2023. [11] B. Hidasi, A. Karatzoglou, L. Baltrunas, and D. Tikk, \u201cSessionbased recommendations with recurrent neural networks,\u201d arXiv preprint arXiv:1511.06939, 2015. [12] W. Fan, Y. Ma, D. Yin, J. Wang, J. Tang, and Q. Li, \u201cDeep social collaborative filtering,\u201d in Proceedings of the 13th ACM Conference on Recommender Systems, 2019, pp. 305\u2013313. [13] W. Fan, Y. Ma, Q. Li, Y. He, E. Zhao, J. Tang, and D. Yin, \u201cGraph neural networks for social recommendation,\u201d in The world wide web conference, 2019, pp. 417\u2013426. [14] Z. Qiu, X. Wu, J. Gao, and W. Fan, \u201cU-bert: Pre-training user representations for improved recommendation,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 5, 2021, pp. 4320\u20134327. [15] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., \u201cLanguage models are few-shot learners,\u201d NeurIPS, 2020. [16] L. Zhou, H. Palangi, L. Zhang, H. Hu, J. Corso, and J. Gao, \u201cUnified vision-language pre-training for image captioning and vqa,\u201d in Proceedings of the AAAI conference on artificial intelligence, vol. 34, no. 07, 2020, pp. 13 041\u201313 049. [17] J. Li, Y. Liu, W. Fan, X.-Y. Wei, H. Liu, J. Tang, and Q. Li, \u201cEmpowering molecule discovery for molecule-caption translation with large language models: A chatgpt perspective,\u201d arXiv preprint arXiv:2306.06615, 2023. [18] Z. Chen, H. Mao, H. Li, W. Jin, H. Wen, X. Wei, S. Wang, D. Yin, W. Fan, H. Liu et al., \u201cExploring the potential of large language models (llms) in learning on graphs,\u201d arXiv preprint arXiv:2307.03393, 2023. [19] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong et al., \u201cA survey of large language models,\u201d arXiv preprint arXiv:2303.18223, 2023. [20] J. Zhang, R. Xie, Y. Hou, W. X. Zhao, L. Lin, and J.-R. Wen, \u201cRecommendation as instruction following: A large language model empowered recommendation approach,\u201d arXiv preprint arXiv:2305.07001, 2023. [21] B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz, E. Agirre, I. Heintz, and D. Roth, \u201cRecent advances in natural language processing via large pre-trained language models: A survey,\u201d ACM Computing Surveys, vol. 56, no. 2, pp. 1\u201340, 2023. [22] C. Gao, Y. Zheng, N. Li, Y. Li, Y. Qin, J. Piao, Y. Quan, J. Chang, D. Jin, X. He et al., \u201cA survey of graph neural networks for recommender systems: Challenges, methods, and directions,\u201d ACM Transactions on Recommender Systems, vol. 1, no. 1, pp. 1\u2013 51, 2023. [23] M. M. Afsar, T. Crump, and B. Far, \u201cReinforcement learning based recommender systems: A survey,\u201d ACM Computing Surveys, vol. 55, no. 7, pp. 1\u201338, 2022. [24] S. Wu, F. Sun, W. Zhang, X. Xie, and B. Cui, \u201cGraph neural networks in recommender systems: a survey,\u201d ACM Computing Surveys, 2022. [25] B. Alhijawi, A. Awajan, and S. Fraihat, \u201cSurvey on the objectives of recommender systems: measures, solutions, evaluation methodology, and new perspectives,\u201d ACM Computing Surveys, vol. 55, no. 5, pp. 1\u201338, 2022. [26] E. Zangerle and C. Bauer, \u201cEvaluating recommender systems: survey and framework,\u201d ACM Computing Surveys, vol. 55, no. 8, pp. 1\u201338, 2022. [27] M. Zehlike, K. Yang, and J. Stoyanovich, \u201cFairness in ranking, part ii: Learning-to-rank and recommender systems,\u201d ACM Computing Surveys, vol. 55, no. 6, pp. 1\u201341, 2022. [28] J. Chen, H. Dong, X. Wang, F. Feng, M. Wang, and X. He, \u201cBias and debias in recommender system: A survey and future directions,\u201d ACM Transactions on Information Systems, vol. 41, no. 3, pp. 1\u201339, 2023. [29] Y. Wang, W. Ma, M. Zhang, Y. Liu, and S. Ma, \u201cA survey on the fairness of recommender systems,\u201d ACM Transactions on Information Systems, vol. 41, no. 3, pp. 1\u201343, 2023. [30] P. Liu, L. Zhang, and J. A. Gulla, \u201cPre-train, prompt and recommendation: A comprehensive survey of language modelling paradigm adaptations in recommender systems,\u201d arXiv preprint arXiv:2302.03735, 2023. [31] L. Wu, Z. Zheng, Z. Qiu, H. Wang, H. Gu, T. Shen, C. Qin, C. Zhu, H. Zhu, Q. Liu et al., \u201cA survey on large language models for recommendation,\u201d arXiv preprint arXiv:2305.19860, 2023.\n[32] J. Lin, X. Dai, Y. Xi, W. Liu, B. Chen, X. Li, C. Zhu, H. Guo, Y. Yu, R. Tang et al., \u201cHow can recommender systems benefit from large language models: A survey,\u201d arXiv preprint arXiv:2306.05817, 2023. [33] J. Wu, W. Fan, J. Chen, S. Liu, Q. Li, and K. Tang, \u201cDisentangled contrastive learning for social recommendation,\u201d in Proceedings of the 31st ACM International Conference on Information & Knowledge Management, 2022, pp. 4570\u20134574. [34] W. Fan, X. Liu, W. Jin, X. Zhao, J. Tang, and Q. Li, \u201cGraph trend filtering networks for recommendation,\u201d in Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2022, pp. 112\u2013121. [35] W. Fan, Q. Li, and M. Cheng, \u201cDeep modeling of social relations for recommendation,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 32, no. 1, 2018. [36] X. Zhao, H. Liu, W. Fan, H. Liu, J. Tang, and C. Wang, \u201cAutoloss: Automated loss function search in recommendations,\u201d in Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, 2021, pp. 3959\u20133967. [37] X. Zhao, H. Liu, W. Fan, H. Liu, J. Tang, C. Wang, M. Chen, X. Zheng, X. Liu, and X. Yang, \u201cAutoemb: Automated embedding dimensionality search in streaming recommendations,\u201d in 2021 IEEE International Conference on Data Mining (ICDM). IEEE, 2021, pp. 896\u2013905. [38] F. Vasile, E. Smirnova, and A. Conneau, \u201cMeta-prod2vec: Product embeddings using side-information for recommendation,\u201d in Proceedings of the 10th ACM conference on recommender systems, 2016, pp. 225\u2013232. [39] X. He, L. Liao, H. Zhang, L. Nie, X. Hu, and T.-S. Chua, \u201cNeural collaborative filtering,\u201d in Proceedings of the 26th international conference on world wide web, 2017, pp. 173\u2013182. [40] R. Ying, R. He, K. Chen, P. Eksombatchai, W. L. Hamilton, and J. Leskovec, \u201cGraph convolutional neural networks for web-scale recommender systems,\u201d in Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining, 2018, pp. 974\u2013983. [41] Y. Ma and J. Tang, Deep learning on graphs. Cambridge University Press, 2021. [42] T. Derr, Y. Ma, W. Fan, X. Liu, C. Aggarwal, and J. Tang, \u201cEpidemic graph convolutional network,\u201d in Proceedings of the 13th International Conference on Web Search and Data Mining (WSDM), 2020, pp. 160\u2013168. [43] C. Chen, M. Zhang, Y. Liu, and S. Ma, \u201cNeural attentional rating regression with review-level explanations,\u201d in Proceedings of the 2018 world wide web conference, 2018, pp. 1583\u20131592. [44] F. Wu, Y. Qiao, J.-H. Chen, C. Wu, T. Qi, J. Lian, D. Liu, X. Xie, J. Gao, W. Wu et al., \u201cMind: A large-scale dataset for news recommendation,\u201d in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 3597\u20133606. [45] C. Wu, F. Wu, Y. Huang, and X. Xie, \u201cPersonalized news recommendation: Methods and challenges,\u201d ACM Transactions on Information Systems, vol. 41, no. 1, pp. 1\u201350, 2023. [46] S. Dongre and J. Agrawal, \u201cDeep learning-based drug recommendation and adr detection healthcare model on social media,\u201d IEEE Transactions on Computational Social Systems, 2023. [47",
    "paper_type": "survey",
    "attri": {
        "background": {
            "purpose": "This survey aims to provide a systematic overview of LLM-empowered recommender systems, addressing the rapid evolution of this research direction and summarizing existing methods to enhance recommender systems using Large Language Models (LLMs).",
            "scope": "The survey includes topics such as pre-training, fine-tuning, and prompting paradigms for LLMs in recommender systems. It excludes traditional recommender system methods that do not incorporate LLMs, focusing instead on the integration of LLMs into the recommendation process."
        },
        "problem": {
            "definition": "The survey focuses on the challenges faced by recommender systems in effectively understanding user interests and generalizing across various recommendation scenarios, particularly when leveraging LLMs.",
            "key obstacle": "Key challenges include the limitations of existing DNN-based models in capturing complex user-item interactions and textual side information, as well as their inability to generalize to unseen tasks."
        },
        "architecture": {
            "perspective": "The survey introduces a novel perspective on integrating LLMs into recommender systems, categorizing existing research into three paradigms: pre-training, fine-tuning, and prompting.",
            "fields/stages": "The survey organizes research into stages such as ID-based recommender systems and textual side information-enhanced recommender systems, emphasizing the importance of representation learning."
        },
        "conclusion": {
            "comparisions": "The survey compares various LLM-enhanced recommender systems, highlighting differences in effectiveness and approaches across studies, particularly in terms of user-item representation and recommendation accuracy.",
            "results": "The survey concludes that LLMs can significantly enhance recommender systems by improving generalization and reasoning capabilities, but further research is needed to address existing limitations."
        },
        "discussion": {
            "advantage": "Existing research has successfully demonstrated the potential of LLMs to improve recommendation accuracy and explainability through better understanding of user preferences and interactions.",
            "limitation": "Current studies often face issues such as the hallucination of LLMs, biases in recommendations, and the complexity of implementing LLMs in real-world systems.",
            "gaps": "There are notable gaps in understanding how to effectively mitigate biases and hallucination in LLMs, as well as a lack of comprehensive frameworks for integrating LLMs into existing recommender systems.",
            "future work": "Future research directions include enhancing the robustness and trustworthiness of LLMs, exploring domain-specific adaptations, and improving fine-tuning efficiency for practical applications."
        },
        "other info": {
            "acknowledgments": "The research was supported by various funding sources including NSFC and the Hong Kong Research Grants Council.",
            "key studies": [
                "Chat-Rec: Towards interactive and explainable LLMs-augmented recommender system",
                "RecAgent: A simulation paradigm for recommender systems based on LLMs"
            ]
        }
    },
    "mount_outline": [
        {
            "section number": "1.2",
            "key information": "The survey aims to provide a systematic overview of LLM-empowered recommender systems, addressing the rapid evolution of this research direction."
        },
        {
            "section number": "1.3",
            "key information": "Existing research has successfully demonstrated the potential of LLMs to improve recommendation accuracy and explainability through better understanding of user preferences and interactions."
        },
        {
            "section number": "2.1",
            "key information": "The survey focuses on the challenges faced by recommender systems in effectively understanding user interests and generalizing across various recommendation scenarios, particularly when leveraging LLMs."
        },
        {
            "section number": "2.3",
            "key information": "The survey introduces a novel perspective on integrating LLMs into recommender systems, categorizing existing research into three paradigms: pre-training, fine-tuning, and prompting."
        },
        {
            "section number": "4.1",
            "key information": "The survey includes topics such as pre-training, fine-tuning, and prompting paradigms for LLMs in recommender systems."
        },
        {
            "section number": "4.2",
            "key information": "The survey organizes research into stages such as ID-based recommender systems and textual side information-enhanced recommender systems, emphasizing the importance of representation learning."
        },
        {
            "section number": "10.2",
            "key information": "Future research directions include enhancing the robustness and trustworthiness of LLMs, exploring domain-specific adaptations, and improving fine-tuning efficiency for practical applications."
        }
    ],
    "similarity_score": 0.8319253166722551,
    "image": [
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9251/92510d35-309f-4c67-978e-beb8e29b58f2.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/abdd/abddb41d-3bdb-48c6-843b-40ebf5d750a3.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8d78/8d783bb7-f86e-4ac8-b010-22f2faaa5d0a.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0bd4/0bd46c87-0cdb-41e4-8a5b-1870189f129d.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2257/22578b82-3040-4612-b155-26ad48d4c150.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8939/8939e2e1-df5d-40d5-b679-94bd14d562dc.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/cbca/cbca32bb-a577-48d1-9ef4-94216c9030f5.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/20b0/20b08d94-8e8f-465e-9244-bee804a71244.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d1c0/d1c02369-4b0c-43b6-8785-b778e03919bc.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f18b/f18bec05-31d1-40eb-bb27-c6127e771ae4.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/429e/429ef0da-1a7b-4ccf-965c-47efc40f89cb.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bbe0/bbe03455-f9d1-442b-b584-e74888977bed.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4cda/4cda5c1a-1f78-4a0d-a901-1268c4c1b8e2.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0a39/0a39765f-17dd-4109-8fc3-9605e5ad46e7.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6bb3/6bb321dd-208f-468b-994c-3effa739b761.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ce38/ce383785-80f3-4987-ab46-456b523005dd.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5c1a/5c1ac927-eaa8-4b82-a84b-c1d61bfe8742.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1cb7/1cb7bd94-0759-4d72-b2ce-f37265143ae1.png"
    ],
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Recommender systems in the era of large language models (llms).json"
}