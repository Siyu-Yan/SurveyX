{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2409.18205",
    "title": "Bridging OOD Detection and Generalization: A Graph-Theoretic View",
    "abstract": "In the context of modern machine learning, models deployed in real-world scenarios often encounter diverse data shifts like covariate and semantic shifts, leading to challenges in both out-of-distribution (OOD) generalization and detection. Despite considerable attention to these issues separately, a unified framework for theoretical understanding and practical usage is lacking. To bridge the gap, we introduce a graph-theoretic framework to jointly tackle both OOD generalization and detection problems. By leveraging the graph formulation, data representations are obtained through the factorization of the graph\u2019s adjacency matrix, enabling us to derive provable error quantifying OOD generalization and detection performance. Empirical results showcase competitive performance in comparison to existing methods, thereby validating our theoretical underpinnings. Code is publicly available at https://github.com/deeplearning-wisc/graph-spectral-ood.",
    "bib_name": "wang2024bridgingooddetectiongeneralization",
    "md_text": "# Bridging OOD Detection and Generalization: A Graph-Theoretic View\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6475/64756145-f87d-4570-a6b8-de7d1f7d0bf6.png\" style=\"width: 50%;\"></div>\n# Abstract\nIn the context of modern machine learning, models deployed in real-world scenarios often encounter diverse data shifts like covariate and semantic shifts, leading to challenges in both out-of-distribution (OOD) generalization and detection. Despite considerable attention to these issues separately, a unified framework for theoretical understanding and practical usage is lacking. To bridge the gap, we introduce a graph-theoretic framework to jointly tackle both OOD generalization and detection problems. By leveraging the graph formulation, data representations are obtained through the factorization of the graph\u2019s adjacency matrix, enabling us to derive provable error quantifying OOD generalization and detection performance. Empirical results showcase competitive performance in comparison to existing methods, thereby validating our theoretical underpinnings. Code is publicly available at https://github.com/deeplearning-wisc/graph-spectral-ood.\narXiv:2409.18205v1\n# 1 Introduction\nMachine learning models deployed in real-world applications often confront data that deviates from the training distribution in unforeseen ways. As depicted in Figure 1, a model trained on in-distribution (ID) data (e.g., seabirds) may encounter data exhibiting covariate shifts, such as birds in forest environments. In this scenario, the model must retain its ability to accurately classify these covariate-shifted out-of-distribution (OOD) samples as birds\u2014an essential capability known as OOD generalization [37, 51]. Alternatively, the model may encounter data with novel semantics, like dogs, which it has not seen during training. In this case, the model must recognize these semantic-shifted OOD samples and abstain from making incorrect predictions, underscoring the significance of OOD detection [107, 83]. Thus, for a model to be considered robust and reliable, it must excel in both OOD generalization and detection, tasks that are often addressed separately in current research. Recently, Bai et al. [4] introduced a framework that addresses both OOD generalization and detection simultaneously. The problem setting leverages unlabeled wild data naturally arising in the model\u2019s operational environment, representing it as a composite distribution of ID, covariate-shifted OOD, and semantic-shifted OOD data. While such data is ubiquitously available in many real-world applications, harnessing the power of wild data is challenging due to the heterogeneity of the wild data distribution\u2014the learner lacks clear membership (ID, Covariate-OOD, Semantic-OOD) for samples drawn from the wild data distribution. Despite empirical progress made, a formalized understanding of how wild data impacts OOD generalization and detection is still lacking. In this paper, we formalize a graph-theoretic framework for understanding OOD generalization and detection problems jointly. We begin by formulating a graph, where the vertices are all the data points and edges connect similar data points. These edges are defined based on a combination of supervised\n\u2217Work done while visiting UW-Madison.\n38th Conference on Neural Information Processing Systems (NeurIPS 2024).\n38th Conference on Neural Information Processing Systems (NeurIPS 2024).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7beb/7beba052-c281-4f79-8228-3a4ba56c363e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Graph formulation</div>\n<div style=\"text-align: center;\">Figure 1: Illustration of our graph-theoretic framework for joint out-of-distribution generalization and detection. Left: Graph formulation containing three types of data in the wild: ID (e.g., seabird), covariate OOD (e.g., bird in the forest), and semantic OOD (e.g., dog). Right: Graph factorization for obtaining the closed-form solution of the data representations, which are used to derive OOD generalization and OOD detection errors.</div>\nand self-supervised signals, incorporating both labeled ID data and unlabeled wild data. By modeling the connectivity among data points, we can uncover meaningful sub-structures in the graph (e.g., covariate-shifted OOD data is embedded closely to the ID data, whereas semantic-shifted OOD data is distinguishable from ID data). Importantly, this graph serves as a foundation for understanding the impact of wild unlabeled data on both OOD generalization and detection, enabling a theoretical characterization of performance through graph factorization. Within this framework, we derive a formal linear probing error, quantifying the misclassification rate on covariate-shifted OOD data. Furthermore, our framework yields a closed-form solution that quantifies the distance between ID and semantic OOD data, directly elucidating OOD detection performance (Section 4). Beyond theoretical analysis, our graph-theoretic framework can be used practically. In particular, the spectral decomposition can be equivalently achieved by minimizing a surrogate objective, which can be efficiently optimized end-to-end using modern neural networks. Thus, our approach enjoys theoretical guarantees while being applicable to real-world data. Experimental results demonstrate the effectiveness of our graph-based approach, showcasing substantial improvements in both OOD generalization and detection performance. In comparison to the state-of-the-art method Scone [4], our approach achieves a significant reduction in FPR95 by an average of 8.34% across five semantic-shift OOD datasets (Section 5). We summarize our main contributions below: 1. We introduce a graph-theoretic framework for understanding both OOD generalization and detection, formalizing it by spectral decomposition of the graph containing ID, covariateshift OOD data, and semantic-shift OOD data. 2. We provide theoretical insights by quantifying OOD generalization and detection performance through provable error, based on the closed-form representations derived from the spectral decomposition on the graph. 3. We evaluate our model\u2019s performance through a comprehensive set of experiments, providing empirical evidence of its robustness and its alignment with our theoretical analysis. Our model consistently demonstrates strong OOD generalization and OOD detection capabilities, achieving competitive results when benchmarked against the existing state-of-the-art.\n# 2 Problem Setup\nWe consider the empirical training set Dl \u222aDu as a union of labeled and unlabeled data. The labeled set Dl = {\u00afxi, yi}n i=1, where yi belongs to known class space Yl. Let Pin denote the marginal distribution over input space, which is referred to as the in-distribution (ID). Following Bai et al. [4], the unlabeled set Du = {\u00afxi}m i=1 consists of ID, covariate OOD, and semantic OOD data, where each sample \u00afxi is drawn from a mixture distribution defined below. Definition 2.1. The marginal distribution of the wild data is defined as:\nPwild := (1 \u2212\u03c0c \u2212\u03c0s)Pin + \u03c0cPcovariate out + \u03c0sPsemantic out ,\n  where \u03c0c, \u03c0s, \u03c0c + \u03c0s \u2208[0, 1]. Pin, Pcovariate out , and Psemantic out represent the marginal distributions of ID, covariate-shifted OOD, and semantic-shifted OOD data respectively.\n<div style=\"text-align: center;\">Graph factorization</div>\nLearning goal. We aim to learn jointly an OOD detector g\u03b8 : X \u2192{IN, OUT} and a multi-class classifier f\u03b8, by leveraging labeled ID data Dl and unlabeled wild data Du. Let \u02c6y(f\u03b8(\u00afx)) := argmaxyf (y) \u03b8 (\u00afx), where f (y) \u03b8 (\u00afx) denotes the y-th element of f\u03b8(\u00afx), corresponding to label y. We notate g\u03b8 and f\u03b8 with parameters \u03b8 to indicate that these functions share neural network parameters. In our model evaluation, we are interested in three metrics: Definition 2.2. We define ID generalization accuracy (ID-Acc), OOD generalization accuracy (OOD-Acc), and OOD detection error as follows:\n\u2191ID-Acc(f\u03b8) := E(\u00afx,y)\u223cPin(1{\ufffdy(f\u03b8(\u00afx)) = y}), \u2191OOD-Acc(f\u03b8) := E(\u00afx,y)\u223cPcovariate out (1{\ufffdy(f\u03b8(\u00afx)) = y}), \u2193FPR(g\u03b8) := E\u00afx\u223cPsemantic out (1{g\u03b8(\u00afx) = IN}),\n\ufffd where 1{\u00b7} represents the indicator function, and the arrows indicate the directionality of improve ment (higher/lower is better). For OOD detection, ID samples are considered positive and FPR signifies the false positive rate.\n# 3 Graph-Based Framework for OOD Generalization and Detection\n# 3.1 Graph Formulation\nWe start by formally defining the graph and adjacency matrix. We use \u00afx to denote the set of all natural data (raw inputs without augmentation). Given an \u00afx, we use T (x|\u00afx) to denote the probability of x being augmented from \u00afx, and T (\u00b7|\u00afx) to denote the distribution of its augmentation. For instance, when \u00afx represents an image, T (\u00b7|\u00afx) can be the distribution of common augmentations [18] such as Gaussian blur, color distortion, and random cropping. We define X as a general population space, which contains the set of all augmented data. In our case, X is composed of augmented samples from both labeled ID data Xl and unlabeled wild data Xu, with cardinality |X| = N. We define the graph G(X, w) with vertex set X and edge weights w. Given our data setup, edge weights w can be decomposed into two components: (1) self-supervised connectivity w(u) by treating all points in X as entirely unlabeled, and (2) supervised connectivity w(l) by incorporating labeled information from Xl to the graph. We define the connectivity formally below. Definition 3.1 (Self-supervised connectivity). For any two augmented data x, x\u2032 \u2208X, w(u) xx\u2032 denotes the marginal probability of generating the positive pair [38]:\nwhere x and x\u2032 are augmented from the same image \u00afx \u223cP, and P is the marginal distribution of both labeled and unlabeled data. A larger w(u) xx\u2032 indicates stronger similarity between x and x\u2032.\nwhere x and x\u2032 are augmented from the same image \u00afx \u223cP, and P is the marginal distribution of both labeled and unlabeled data. A larger w(u) xx\u2032 indicates stronger similarity between x and x\u2032. Moreover, when having access to the labeling information for ID data, we can define the edge weight by adding additional supervised connectivity to the graph. We consider (x, x\u2032) a positive pair when x and x\u2032 are augmented from two labeled samples \u00afxl and \u00afx\u2032 l with the same known class i \u2208Yl. The total edge connectivity can be formulated as below: Definition 3.2 (Total edge connectivity). Considering both self-supervised and supervised connectivities, the overall similarity for any pair of data (x, x\u2032) is formulated as:\nMoreover, when having access to the labeling information for ID data, we can define the edge weight by adding additional supervised connectivity to the graph. We consider (x, x\u2032) a positive pair when x and x\u2032 are augmented from two labeled samples \u00afxl and \u00afx\u2032 l with the same known class i \u2208Yl. The total edge connectivity can be formulated as below: Definition 3.2 (Total edge connectivity). Considering both self-supervised and supervised connectivities, the overall similarity for any pair of data (x, x\u2032) is formulated as:\n\ufffd where Pli is the distribution of labeled samples with class label i \u2208Yl, and the coefficients \u03b7u, \u03b7l modulate the relative importance between the two terms. Adjacency matrix. Having established the notion of connectivity, we can define the adjacency matrix A \u2208RN\u00d7N with entries Axx\u2032 = wxx\u2032. The adjacency matrix can be decomposed into the summation of self-supervised adjacency matrix A(u) and supervised adjacency matrix A(l): A = \u03b7uA(u) + \u03b7lA(l). (3)\nere Pli is the distribution of labeled samples with class label i \u2208Yl, and the coefficients \u03b7u, \u03b7l dulate the relative importance between the two terms.\nAdjacency matrix. Having established the notion of connectivity, we can define the adjacency matrix A \u2208RN\u00d7N with entries Axx\u2032 = wxx\u2032. The adjacency matrix can be decomposed into the summation of self-supervised adjacency matrix A(u) and supervised adjacency matrix A(l): A = \u03b7uA(u) + \u03b7lA(l). (3)\n(1)\n(2)\n(3)\n\u02dcA \u225cD\u22121 2 AD\u22121 2 ,\nwhere D \u2208RN\u00d7N is a diagonal matrix with Dxx = wx = \ufffd x\u2032\u2208X wxx\u2032, indicating the total edge weights connected to a vertex x. The normalized adjacency matrix defines the probability of x and x\u2032 being considered as the positive pair. The normalized adjacency matrix allows us to perform spectral decomposition as we show next.\n# 3.2 Learning Representations Based on Graph Spectr\nIn this section, we perform spectral decomposition or spectral clustering [76]\u2014a classical approach to graph partitioning\u2014to the adjacency matrices defined above. This process forms a matrix where the top-k eigenvectors are the columns and each row of the matrix can be viewed as a k-dimensional representation of an example. The resulting feature representations enable us to rigorously analyze the separability of ID data from semantic OOD data in a closed form, as well as the generalizability to covariate-shifted OOD data (more in Section 4).\nTowards this end, we consider the following optimization, which performs low-rank matrix approxi mation on the adjacency matrix:\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd where \u2225\u00b7 \u2225F denotes the matrix Frobenious norm. According to the Eckart\u2013Young\u2013Mirsky theorem [32], the minimizer of this loss function is Fk \u2208RN\u00d7k such that FkF \u22a4 k contains the top-k components of \u02dcA\u2019s eigen decomposition.\nA surrogate objective. In practice, directly solving objective (5) can be computationally expensive for an extremely large matrix. To circumvent this, the feature representations can be equivalently recovered by minimizing the following contrastive learning objective [95], which can be efficiently trained end-to-end using a neural network:\nA surrogate objective. In practice, directly solving objective (5) can be computationally expensive for an extremely large matrix. To circumvent this, the feature representations can be equivalently recovered by minimizing the following contrastive learning objective [95], which can be efficiently trained end-to-end using a neural network: L(f) \u225c\u22122\u03b7uL1(f) \u22122\u03b7lL2(f) + \u03b72 uL3(f) + 2\u03b7u\u03b7lL4(f) + \u03b72 l L5(f), (6)\nL(f) \u225c\u22122\u03b7uL1(f) \u22122\u03b7lL2(f) + \u03b72 uL3(f) + 2\u03b7u\u03b7lL4(f) + \u03b72 l L5(f),\nwhere\nL3(f\nImportantly, this contrastive loss allows drawing a theoretical equivalence between learned representations and the top-k singular vectors of \u02dcA, and facilitates theoretical understanding of the OOD generalization and detection on the data represented by \u02dcA. The equivalence is formalized below. Theorem 3.3 (Theoretical equivalence between two objectives). We define each row f \u22a4 x of F as a scaled version of learned feature embedding f : X \ufffd\u2192Rk, with fx = \u221awxf(x). Then minimizing the loss function Lmf(F, A) in Equation 5 is equivalent to minimizing the surrogate loss in Equation 6. Full proof is in Appendix A.\nInterpretation for OOD generalization and detection. The loss learns feature representation jointly from both labeled ID data and unlabeled wild data, so that meaningful structures emerge for both OOD generalization and detection (e.g., covariate-shifted OOD data is embedded closely to the ID data, whereas semantic-shifted OOD data is distinguishable from ID data). At a high level, the loss components L1 and L2 contribute to pulling the embeddings of positive pairs closer, while L3, L4 and L5 push apart the embeddings of negative pairs. In particular, loss components on the positive pairs can pull together samples sharing the same classes, thereby helping OOD generalization. At\n(5)\n(6)\nthe same time, loss components on the negative pairs can help separate semantic OOD data in the embedding space, thus benefiting OOD detection. Difference from prior works. Spectral contrastive learning has been employed to analyze problems such as self-supervised learning [38], unsupervised domain adaptation [87], novel category discovery [96], open-world semi-supervised learning [95] etc. These works share the underlying loss form by pulling together positive pairs and pushing away negative pairs. Despite the shared loss formulation, our work has fundamentally distinct data setup and learning goals, which focus on the joint OOD generalization and detection problems (cf. Section 2). We are interested in leveraging labeled ID data to classify both unlabeled ID and covariate OOD data correctly into the known categories while rejecting the remainder of unlabeled data from new categories, which was not studied in the prior works. Accordingly, we derive a novel theoretical analysis for our setup and present empirical verification uniquely tailored to our problem focus, which we present next.\nthe same time, loss components on the negative pairs can help separate semantic OOD data in the embedding space, thus benefiting OOD detection.\n# 4 Theoretical Analysis\nIn this section, we present a novel theoretical analysis of how the learned representations via graph spectral can facilitate both OOD generalization and detection.\n# 4.1 Analytic Form of Learned Representations\nTo obtain the representations, one can train the neural network f : X \ufffd\u2192Rk using the spectral loss defined in Equation 6. Minimizing the loss yields representation Z \u2208RN\u00d7k, where each row vector zi = f(xi)\u22a4. According to Theorem 3.3, the closed-form solution for the representations is equivalent to performing spectral decomposition of the adjacency matrix. Thus, we have Fk = \u221a DZ, where FkF \u22a4 k contains the top-k components of \u02dcA\u2019s SVD decomposition and D is the diagonal matrix. We further define the top-k singular vectors of \u02dcA as Vk \u2208RN\u00d7k, so we have Fk = Vk \u221a\u03a3k, where \u03a3k is a diagonal matrix of the top-k singular values of \u02dcA. By equalizing the two forms of Fk, the closed-formed solution of the learned feature space is given by Z = [D]\u22121 2 Vk \u221a\u03a3k.\n# 4.2 Analysis Target\nLinear probing evaluation. We assess OOD generalization performance based on the linear probing error, which is commonly used in self-supervised learning [18]. Specifically, the weight of a linear classifier is denoted as M \u2208Rk\u00d7|Yl|, which is learned with ID data to minimize the error. The class prediction for an input \u00afx is given by h(\u00afx; f, M) = argmaxi\u2208Yl(f(\u00afx)\u22a4M)i. The linear probing error measures the misclassification of linear head on covariate-shifted OOD data:\nE(f) \u225cE\u00afx\u223cPcovariate out 1[y(\u00afx) \u0338= h(\u00afx; f, M)],\nwhere y(\u00afx) indicates the ground-truth class of \u00afx. E(f) = 0 indicates perfect OOD generalization. Separability evaluation. Based on the closed-form embeddings, we can also quantify the distance between the ID and semantic OOD data:\nS(f) \u225cE\u00afxi\u223cPin,\u00afxj\u223cPsemantic out \u2225f(\u00afxi) \u2212f(\u00afxj)\u22252 2.\nThe magnitude of S(f) reflects the extent of separation between ID and semantic OOD data. Larger S(f) suggests better OOD detection capability.\n# 4.3 An Illustrative Example\nSetup. We use an illustrative example to explain our theoretical insights. In Figure 2, the training examples come from 5 types of data: angel in sketch (ID), tiger in sketch (ID), angel in painting (covariate OOD), tiger in painting (covariate OOD), and panda (semantic OOD). The label space Yl consists of two known classes: angel and tiger. Class Panda is considered a novel class. The goal is to classify between images of angels and tigers while rejecting images of pandas.\nSetup. We use an illustrative example to explain our theoretical insights. In Figure 2, the training examples come from 5 types of data: angel in sketch (ID), tiger in sketch (ID), angel in painting (covariate OOD), tiger in painting (covariate OOD), and panda (semantic OOD). The label space Yl consists of two known classes: angel and tiger. Class Panda is considered a novel class. The goal is to classify between images of angels and tigers while rejecting images of pandas. Augmentation transformation probability. Based on the data setup, we formally define the augmentation transformation, which encodes the probability of augmenting an original image \u00afx\n(7)\n(8)\n\uf8f4 \uf8f3 Here d(\u00afx) is the domain of sample \u00afx, and y(\u00afx) is the class label of sample \u00afx. \u03b1 indicates the augmentation probability when two samples share the same label but different domains, and \u03b2 indicates the probability when two samples share different class labels but with the same domain. It is natural to assume the magnitude order that follows \u03c1 \u226bmax(\u03b1, \u03b2) \u2265min(\u03b1, \u03b2) \u226b\u03b3 \u22650. Adjacency matrix. With Eq. 9 and the definition in Section 3.1, we can derive the analytic form of adjacency matrix A.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5d29/5d29bab9-2d06-4721-8b21-c182af405ea5.png\" style=\"width: 50%;\"></div>\nwhere C is the normalization constant to ensure the summation of weights amounts to 1. Each row or column encodes connectivity associated with a specific sample, ordered by: angel sketch, tiger sketch, angel painting, tiger painting, and panda. We refer readers to Appendix D.1 for the detailed derivation. Main analysis. We are primarily interested in analyzing the representation space derived from A. We mainly put analysis on the top-3 eigenvectors \ufffdV \u2208R5\u00d73 and measure both the linear probing error and separability. The full derivation of Theorem 4.1 and Theorem 4.2 can be found in Appendix D.1. Theorem 4.1. Assume \u03b7u = 5, \u03b7l = 1, we have:\nMain analysis. We are primarily interested in analyzing the representation space derived from A. We mainly put analysis on the top-3 eigenvectors \ufffdV \u2208R5\u00d73 and measure both the linear probing error and separability. The full derivation of Theorem 4.1 and Theorem 4.2 can be found in Appendix D.1. Theorem 4.1. Assume \u03b7u = 5, \u03b7l = 1, we have:\n\uf8f4 \uf8f4 \uf8f3 Interpretation. The discussion can be divided into two cases: (1) 9 8\u03b1 > \u03b2. (2) 9 8\u03b1 < \u03b2. In the first case when the connection between the class (multiplied by 9 8) is stronger than the domain, the model could learn a perfect ID classifier based on features in the first two rows in V and effectively generalize to the covariate-shifted domain (the third and fourth row in \ufffdV ), achieving perfect OOD generalization with linear probing error E(f) = 0. In the second case when the connection between the domain is stronger than the connection between the class (scaled by 9 8), the embeddings of covariate-shifted OOD data are identical, resulting in high OOD generalization error.\nS(f) = \ufffd (7 + 12\u03b2\u2032 + 12\u03b1\u2032)( 1\u22122\u03b2\u2032 3 (1 \u2212\u03b2\u2032 \u22123 4 \u03b1\u2032)2 + 1) , if 9 8 \u03b1 > \u03b2; (7 + 12\u03b2\u2032 + 12\u03b1\u2032)( 2\u22123\u03b1\u2032 8 (1 \u2212\u03b2\u2032 \u22123 4 \u03b1\u2032)2 + 1) , if 9 8 \u03b1 < \u03b2.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/30ff/30ff1b20-6bdd-4a93-8d31-4fbc98a8ff26.png\" style=\"width: 50%;\"></div>\n(9)\n<div style=\"text-align: center;\">Figure 2: Illustration of graph and augmentation probability.</div>\n(11)\n(12)\n(13)\nInterpretation. We analyze the function S(f) under different \u03b1\u2032 and \u03b2\u2032 values in Figure 3. Overall the distance between semantic OOD data and ID data displays a large value, which facilitates OOD detection. Note that a clear boundary in Figure 3 indicates 9 8\u03b1 = \u03b2.\nInterpretation. We analyze the function S(f) under different \u03b1\u2032 and \u03b2\u2032 values in Figure 3. Overall the distance between semantic OOD data and ID data displays a large value, which facilitates OOD detection. Note that a clear boundary in Figure 3 indicates 9 8\u03b1 = \u03b2. More analysis. Building upon the understanding of both OOD generalization and detection, we further discuss the influence of different semantic OOD data in Appendix B, and the impact of ID labels in Appendix C.\nMore analysis. Building upon the understanding of both OOD generalization and detection, we further discuss the influence of different semantic OOD data in Appendix B, and the impact of ID labels in Appendix C.\n# 5 Experiments\nBeyond theoretical insights, we show empirically that our approach is competitive. We present t experimental setup in Section 5.1, results in Section 5.2, and further analysis in Section 5.3.\n# 5.1 Experimental Setup\nDatasets and benchmarks. Following the setup of [4], we employ CIFAR-10 [52] as Pin and CIFAR-10-C [41] with Gaussian additive noise as the Pcovariate out . For Psemantic out , we leverage SVHN [75], LSUN [108], Places365 [116], Textures [24]. To simulate the wild distribution Pwild, we adopt the same mixture ratio as in Scone [4], where \u03c0c = 0.5 and \u03c0s = 0.1. Detailed descriptions of the datasets and data mixture can be found in the Appendix E.1. To demonstrate the adaptability and robustness of our proposed method, we extend the framework to more diverse and challenging datasets. Large-scale results on the ImageNet dataset can be found in Appendix E.2. Additional results on the Office-Home [101] can be found in Appendix E.3. More ablation studies can be found in Appendix E.4.\nImplementation details. We adopt Wide ResNet with 40 layers and a widen factor of 2 [109]. We use stochastic gradient descent with Nesterov momentum [30], with weight decay 0.0005 and momentum 0.09. We divide CIFAR-10 training set into 50% labeled as ID and 50% unlabeled. And we mix unlabeled CIFAR-10, CIFAR-10-C, and semantic OOD data to generate the wild dataset. Starting from random initialization, we train the network with the loss function in Eq. 6 for 1000 epochs. The learning rate is 0.03 and the batch size is 512. \u03b7u is selected within {1.00, 2.00} and \u03b7l is within {0.02, 0.10, 0.50, 1.00}. Subsequently, we follow the standard approach [87] and use labeled ID data to fine-tune the model with cross-entropy loss for better generalization ability. We fine-tune for 20 epochs with a learning rate of 0.005 and batch size of 512. The fine-tuned model is used to evaluate the OOD generalization and OOD detection performance. We utilize a distance-based method for OOD detection, which resonates with our theoretical analysis. Specifically, our default approach employs a simple non-parametric KNN distance [94], which does not impose any distributional assumption on the feature space. The threshold is determined based on the clean ID set at 95% percentile. For further implementation details, hyper-parameters, and validation strategy, please see Appendix F.\n# 5.2 Results and Discussion\nCompetitive empirical performance. The main results in Table 1 demonstrate that our method not only enjoys theoretical guarantees but also exhibits competitive empirical performance compared to existing baselines. For a comprehensive evaluation, we consider three groups of methods for OOD generalization and OOD detection. Closest to our setting, we compare with strong baselines trained with wild data, namely OE [43], Energy-regularized learning [67], Woods [50], and Scone [4]. The empirical results provide interesting insights into the performance of various methods for OOD detection and generalization. (1) Methods tailored for OOD detection tend to capture the domainvariant information and struggle with the covariate distribution shift, resulting in suboptimal OOD accuracy. (2) While approaches for OOD generalization demonstrate improved OOD accuracy, they cannot effectively distinguish between ID data and semantic OOD data, leading to poor OOD detection performance. (3) Methods trained with wild data emerge as robust OOD detectors, yet display a notable decline in OOD generalization, highlighting the confusion introduced by covariate\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1ebe/1ebe01bd-f31f-43b7-b7f0-22035365bec2.png\" style=\"width: 50%;\"></div>\nMethod\nSVHN Psemantic\nout\n, CIFAR-10-C Pcovariate\nout\nLSUN-C Psemantic\nout\n, CIFAR-10-C Pcovariate\nout\nTextures Psemantic\nout\n, CIFAR-10-C Pcovariate\nout\nOOD Acc.\u2191\nID Acc.\u2191\nFPR\u2193\nAUROC\u2191\nOOD Acc.\u2191\nID Acc.\u2191\nFPR\u2193\nAUROC\u2191\nOOD Acc.\u2191\nID Acc.\u2191\nFPR\u2193\nAUROC\u2191\nOOD detection\nMSP [42]\n75.05\n94.84\n48.49\n91.89\n75.05\n94.84\n30.80\n95.65\n75.05\n94.84\n59.28\n88.50\nODIN [64]\n75.05\n94.84\n33.35\n91.96\n75.05\n94.84\n15.52\n97.04\n75.05\n94.84\n49.12\n84.97\nEnergy [67]\n75.05\n94.84\n35.59\n90.96\n75.05\n94.84\n8.26\n98.35\n75.05\n94.84\n52.79\n85.22\nMahalanobis [57]\n75.05\n94.84\n12.89\n97.62\n75.05\n94.84\n39.22\n94.15\n75.05\n94.84\n15.00\n97.33\nViM [102]\n75.05\n94.84\n21.95\n95.48\n75.05\n94.84\n5.90\n98.82\n75.05\n94.84\n29.35\n93.70\nKNN [94]\n75.05\n94.84\n28.92\n95.71\n75.05\n94.84\n28.08\n95.33\n75.05\n94.84\n39.50\n92.73\nASH [27]\n75.05\n94.84\n40.76\n90.16\n75.05\n94.84\n2.39\n99.35\n75.05\n94.84\n53.37\n85.63\nOOD generalization\nERM [100]\n75.05\n94.84\n35.59\n90.96\n75.05\n94.84\n8.26\n98.35\n75.05\n94.84\n52.79\n85.22\nIRM [3]\n77.92\n90.85\n63.65\n90.70\n77.92\n90.85\n36.67\n94.22\n77.92\n90.85\n59.42\n87.81\nMixup [112]\n79.17\n93.30\n97.33\n18.78\n79.17\n93.30\n52.10\n76.66\n79.17\n93.30\n58.24\n75.70\nVREx [53]\n76.90\n91.35\n55.92\n91.22\n76.90\n91.35\n51.50\n91.56\n76.90\n91.35\n65.45\n85.46\nEQRM [31]\n75.71\n92.93\n51.86\n90.92\n75.71\n92.93\n21.53\n96.49\n75.71\n92.93\n57.18\n89.11\nSharpDRO [48]\n79.03\n94.91\n21.24\n96.14\n79.03\n94.91\n5.67\n98.71\n79.03\n94.91\n42.94\n89.99\nLearning w. Pwild\nOE [43]\n37.61\n94.68\n0.84\n99.80\n41.37\n93.99\n3.07\n99.26\n44.71\n92.84\n29.36\n93.93\nEnergy (w. outlier) [67]\n20.74\n90.22\n0.86\n99.81\n32.55\n92.97\n2.33\n99.93\n49.34\n94.68\n16.42\n96.46\nWoods [50]\n52.76\n94.86\n2.11\n99.52\n76.90\n95.02\n1.80\n99.56\n83.14\n94.49\n39.10\n90.45\nScone [4]\n84.69\n94.65\n10.86\n97.84\n84.58\n93.73\n10.23\n98.02\n85.56\n93.97\n37.15\n90.91\nOurs\n86.62\u00b10.3\n93.10\u00b10.1\n0.13\u00b10.0\n99.98\u00b10.0\n85.88\u00b10.2\n92.61\u00b10.1\n1.76\u00b10.8\n99.75\u00b10.1\n81.40\u00b10.7\n92.50\u00b10.1\n12.05\u00b10.8\n98.25\u00b10.2\nTable 1: Main results: comparison with competitive OOD generalization and OOD detection methods on CIFAR-10. Additional results for the Places365 and LSUN-R datasets can be found in Table 3. Bold=best. (*Since all the OOD detection methods use the same model trained with the CE loss on Pin, they display the same ID and OOD accuracy on CIFAR-10-C.)\nOOD data. In contrast, our method excels in both OOD detection and generalization performance. Our method even surpasses the latest method Scone by 25.10% in terms of FPR95 on the Textures dataset. Methodologically, Scone uses constrained optimization whereas our method brings a novel graph-theoretic perspective. More results can be found in the Appendix E.\nBetter adaptation to the heterogeneous distribution. We conduct a comparative analysis of our methods against other state-of-the-art spectral learning approaches within their respective domains. Specifically, Haochen et al. [38] investigate unsupervised learning, Shen et al. [87] delve into unsupervised domain adaptation, and Sun et al. [96] explores novel class discovery. The baseline methods all assume unlabeled data exhibits a homogeneous distribution, ei-\nPsemantic\nout\nMethod\nOOD Acc.\u2191\nID Acc.\u2191\nFPR\u2193\nAUROC\u2191\nSVHN\nSCL [38, 87]\n75.96\n87.58\n21.53\n96.56\nNSCL [96]\n85.49\n92.42\n0.15\n99.97\nOurs\n86.62\n93.10\n0.13\n99.98\nLSUN-C\nSCL [38, 87]\n65.48\n85.14\n81.30\n83.34\nNSCL [96]\n77.64\n90.61\n18.43\n97.84\nOurs\n85.88\n92.61\n1.76\n99.75\nTEXTURES\nSCL [38, 87]\n63.05\n83.07\n66.86\n87.59\nNSCL [96]\n62.86\n86.56\n39.04\n92.59\nOurs\n81.40\n92.50\n12.05\n98.25\nTable 2: Comparison with spectral learning methods.\nther entirely from Pcovariate out in the case of unsupervised domain adaptation or entirely from Psemantic out in the case of novel class discovery. As depicted in Table 2, our results reveal a significant improvement over competing baselines on both OOD generalization and detection. We attribute this empirical success to our better adaptation to the heterogeneous mixture of wild distributions. Additional results can be found in Table 6. More ablation studies can be found in Appendix E.4.\n# 5.3 Further Analysis\nVisualization of OOD detection score distributions. In Figure 4 (a), we visualize the distribution of KNN distances. The KNN scores are computed based on samples from the test set after contrastive training and fine-tuning stages. There are two salient observations: First, our learning framework effectively pushes the semantic OOD data to be apart from the ID data in the embedding space, which benefits OOD detection. Moreover, as evidenced by the small KNN distance, covariate-shifted OOD data is embedded closely to the ID data, which aligns with our expectations.\nVisualization of embeddings. Figure 4 (b) displays the t-SNE [99] visualization of the normalized penultimate-layer embeddings. Samples are from the test set of ID, covariate OOD, and semantic OOD data, respectively. The visualization demonstrates the alignment of ID and covariate OOD data in the embedding space, which allows the classifier learned on the ID data to extrapolate to the covariate OOD data thereby benefiting OOD generalization.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/877d/877d3d8b-0412-4dcb-a48d-66732dfc3560.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: (a) Distribution of KNN distance. (b) t-SNE visualization of learned embeddings. We employ CIFAR-10 as Pin, CIFAR-10-C as Pcovariate out , and SVHN as Psemantic out .</div>\n# 6 Related Works\nOut-of-distribution detection. OOD detection has gained soaring research attention in recent years. The current research track can be divided into post hoc and regularization-based methods. Post hoc methods derive OOD scores at test-time based on a pre-trained model, which can be categorized as confidence-based methods [9, 42, 65], energy-based methods [67, 103, 91, 92, 73, 27], distancebased methods [58, 119, 85, 94, 29, 69, 71], and gradient-based method [46]. On the other hand, regularization-based methods aim to train the OOD detector by training-time regularization. Most approaches require auxiliary OOD data [10, 35, 72, 43, 70, 106, 28]. However, a limitation of existing methods is the reliance on clean semantic OOD datasets for training. To address this challenge, WOODS [50] first explored the use of wild data, which includes unlabeled ID and semantic OOD data. Building upon this idea, SCONE [4] extended the characterization of wild data to encompass ID, covariate OOD, and semantic OOD data, providing a more generalized data mixture in practice. In our paper, we provide a novel graph-theoretic approach for understanding both OOD generalization and detection based on the setup proposed by Scone [4]. Out-of-distribution generalization. OOD generalization aims to learn domain-invariant representations that can effectively generalize to unseen domains, which is more challenging than classic domain adaptation problem [34, 22, 114, 25], where the model has access to unlabeled data from the target domain. OOD generalization and domain generalization [104] focus on capturing semantic features that remain consistent across diverse domains, which can be categorized as reducing feature discrepancies across the source domains [61, 63, 3, 115, 1, 5], ensemble and meta learning [6, 59, 60, 113, 13], robust optimization [16, 54, 81, 89, 80], augmentation [117, 74, 78, 118], and disentanglement [111]. Distinct from prior literature about generalization, Scone [4] introduces a framework that leverages the wild data ubiquitous in the real world, aiming to build a robust classifier and a reliable OOD detector simultaneously. Following the same problem setting in [4], we contribute novel theoretical insights into the understanding of both OOD generalization and detection. Spectral graph theory. Spectral graph theory is a classical research field [23, 68, 49, 55, 17], concerning the study of graph partitioning through analyzing the eigenspace of the adjacency matrix. The spectral graph theory is also widely applied in machine learning [88, 11, 77, 120, 2, 86]. Recently, Haochen et al. [38] presented unsupervised spectral contrastive loss derived from the factorization of the graph\u2019s adjacency matrix. Shen et al. [87] provided a graph-theoretic analysis for unsupervised domain adaptation based on the assumption of unlabeled data entirely from Pcovariate out . Sun et al. [96] first introduced the label information and explored novel category discovery, considering unlabeled data covers Psemantic out . All of the previous literature assumed unlabeled data has a homogeneous distribution. In contrast, our work focuses on the joint problem of OOD generalization and detection, tackling the challenge of unlabeled data characterized by a heterogeneous mixture distribution, which is a more general and complex scenario than previous works. Contrastive learning. Recent works on contrastive learning advance the development of deep neural networks with a huge empirical success [18\u201320, 36, 45, 15, 21, 8, 110, 93]. Simultaneously, many\nContrastive learning. Recent works on contrastive learning advance the development of deep neural networks with a huge empirical success [18\u201320, 36, 45, 15, 21, 8, 110, 93]. Simultaneously, many theoretical works establish the foundation for understanding representations learned by contrastive learning through linear probing evaluation [84, 56, 97, 98, 7, 90]. Haochen et al. [38, 39], Sun et\nal. [96] extended the understanding and providing error analyses for different downstream tasks. Orthogonal to prior works, we provide a graph-theoretic framework tailored for the wild environment to understand both OOD generalization and detection.\n# 7 Conclusion\nIn this paper, we present a graph-theoretic framework to jointly tackle both OOD generalization and detection problems. Based on the graph formulation, the data representations can be derived by factorizing the graph\u2019s adjacency matrix, allowing us to draw theoretical insight into both OOD generalization and detection performance. In particular, we analyze the closed-form solutions of linear probing error for OOD generalization, as well as separability quantifying OOD detection capability via the distance between the ID and semantic OOD data. Empirically, our framework demonstrates competitive performance against existing baselines, closely aligning with our theoretical insights. We anticipate that our theoretical framework and findings will inspire further research in unifying and understanding both OOD generalization and detection.\n# 8 Broader Impact\nIn the rapidly evolving landscape of machine learning, addressing the dual challenges of OOD generalization and detection has become paramount for deploying robust and reliable models in real-world scenarios. Our work provides a novel spectral learning solution, which not only improves model performance but also ensures its reliability and safety in diverse, dynamic environments. The implications of our research extend beyond theoretical advancements, with potential applications in healthcare, autonomous systems, and finance. The ability to deploy models with superior OOD generalization and detection capabilities addresses a critical bottleneck in the adoption of machine learning technologies, fostering trust among end-users and stakeholders.\n# 9 Limitations\nIn our experimental setup, we focus on covariate shift as the primary form of shift in the out-ofdistribution (OOD) generalization problem, a topic extensively explored in the literature. However, it\u2019s important to acknowledge the existence of other types of distributional shifts (e.g., concept shift), which we defer for future investigation.\n# Acknowledgement\nWe thank Yiyou Sun for the valuable discussion and input during the project. Li gratefully acknowledges the funding support by the AFOSR Young Investigator Program under award number FA9550-23-1-0184, National Science Foundation (NSF) Award No. IIS-2237037 & IIS-2331669, Office of Naval Research under grant number N00014-23-1-2643, Philanthropic Fund from SFF, and faculty research awards/gifts from Google and Meta.\n# References\n[1] Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio, Ioannis Mitliagkas, and Irina Rish. Invariance principle meets information bottleneck for out-of-distribution generalization. In NeurIPS, pages 3438\u20133450, 2021. [2] Andreas Argyriou, Mark Herbster, and Massimiliano Pontil. Combining graph laplacians for semi-supervised learning. In NIPS, pages 67\u201374, 2005. [3] Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019. [4] Haoyue Bai, Gregory Canal, Xuefeng Du, Jeongyeol Kwon, Robert D. Nowak, and Yixuan Li. Feed two birds with one scone: Exploiting wild data for both out-of-distribution generalization and detection. In ICML, volume 202 of Proceedings of Machine Learning Research, pages 1454\u20131471. PMLR, 2023.\n[5] Haoyue Bai, Yifei Ming, Julian Katz-Samuels, and Yixuan Li. Hypo: Hyperspherical out-ofdistribution generalization. In ICLR, 2024. [6] Yogesh Balaji, Swami Sankaranarayanan, and Rama Chellappa. Metareg: Towards domain generalization using meta-regularization. In NeurIPS, pages 1006\u20131016, 2018. [7] Randall Balestriero and Yann LeCun. Contrastive and non-contrastive self-supervised learning recover global and local spectral embedding methods. In NeurIPS, 2022. [8] Adrien Bardes, Jean Ponce, and Yann LeCun. Vicreg: Variance-invariance-covariance regularization for self-supervised learning. In ICLR, 2022. [9] Abhijit Bendale and Terrance E. Boult. Towards open set deep networks. In CVPR, pages 1563\u20131572. IEEE Computer Society, 2016. [10] Petra Bevandic, Ivan Kreso, Marin Orsic, and Sinisa Segvic. Discriminative out-of-distribution detection for semantic segmentation. CoRR, abs/1808.07703, 2018. [11] Avrim Blum. Learning form labeled and unlabeled data using graph mincuts. In Proc. 18th International Conference on Machine Learning, 2001, 2001. [12] Silvia Bucci, Mohammad Reza Loghmani, and Tatiana Tommasi. On the effectiveness of image rotation for open set domain adaptation. In ECCV (16), volume 12361 of Lecture Notes in Computer Science, pages 422\u2013438. Springer, 2020. [13] Manh-Ha Bui, Toan Tran, Anh Tran, and Dinh Q. Phung. Exploiting domain-specific features to enhance domain generalization. In NeurIPS, pages 21189\u201321201, 2021. [14] Kaidi Cao, Maria Brbic, and Jure Leskovec. Open-world semi-supervised learning. In ICLR. OpenReview.net, 2022. [15] Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and Armand Joulin. Unsupervised learning of visual features by contrasting cluster assignments. In NeurIPS, 2020. [16] Junbum Cha, Sanghyuk Chun, Kyungjae Lee, Han-Cheol Cho, Seunghyun Park, Yunsung Lee, and Sungrae Park. SWAD: domain generalization by seeking flat minima. In NeurIPS, pages 22405\u201322418, 2021. [17] Jeff Cheeger. A lower bound for the smallest eigenvalue of the laplacian. In Problems in analysis, pages 195\u2013200. Princeton University Press, 2015. [18] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. A simple framework for contrastive learning of visual representations. In ICML, volume 119 of Proceedings of Machine Learning Research, pages 1597\u20131607. PMLR, 2020. [19] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E. Hinton. Big self-supervised models are strong semi-supervised learners. In NeurIPS, 2020. [20] Xinlei Chen, Haoqi Fan, Ross B. Girshick, and Kaiming He. Improved baselines with momentum contrastive learning. CoRR, abs/2003.04297, 2020. [21] Xinlei Chen and Kaiming He. Exploring simple siamese representation learning. In CVPR, 2021. [22] Yuhua Chen, Wen Li, Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Domain adaptive faster R-CNN for object detection in the wild. In CVPR, pages 3339\u20133348. Computer Vision Foundation / IEEE Computer Society, 2018. [23] Fan RK Chung. Spectral graph theory, volume 92. American Mathematical Soc., 1997. [24] Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi. Describing textures in the wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3606\u20133613, 2014.\n[25] Shuhao Cui, Shuhui Wang, Junbao Zhuo, Chi Su, Qingming Huang, and Qi Tian. Gradually vanishing bridge for adversarial domain adaptation. In CVPR, pages 12452\u201312461. Computer Vision Foundation / IEEE, 2020. [26] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, pages 248\u2013255. IEEE Computer Society, 2009. [27] Andrija Djurisic, Nebojsa Bozanic, Arjun Ashok, and Rosanne Liu. Extremely simple activation shaping for out-of-distribution detection. In ICLR. OpenReview.net, 2023. [28] Xuefeng Du, Zhen Fang, Ilias Diakonikolas, and Yixuan Li. How does unlabeled data provably help out-of-distribution detection? In ICLR, 2024. [29] Xuefeng Du, Gabriel Gozum, Yifei Ming, and Yixuan Li. SIREN: shaping representations for detecting out-of-distribution objects. In NeurIPS, 2022. [30] John C. Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. J. Mach. Learn. Res., 12:2121\u20132159, 2011. [31] Cian Eastwood, Alexander Robey, Shashank Singh, Julius von K\u00fcgelgen, Hamed Hassani, George J. Pappas, and Bernhard Sch\u00f6lkopf. Probable domain generalization via quantile risk minimization. In NeurIPS, 2022. [32] Carl Eckart and Gale Young. The approximation of one matrix by another of lower rank. Psychometrika, 1(3):211\u2013218, 1936. [33] Zhen Fang, Jie Lu, Feng Liu, Junyu Xuan, and Guangquan Zhang. Open set domain adaptation: Theoretical bound and algorithm. IEEE Trans. Neural Networks Learn. Syst., 32(10):4309\u2013 4322, 2021. [34] Yaroslav Ganin and Victor S. Lempitsky. Unsupervised domain adaptation by backpropagation. In ICML, volume 37 of JMLR Workshop and Conference Proceedings, pages 1180\u20131189. JMLR.org, 2015. [35] Yonatan Geifman and Ran El-Yaniv. Selectivenet: A deep neural network with an integrated reject option. In ICML, volume 97 of Proceedings of Machine Learning Research, pages 2151\u20132159. PMLR, 2019. [36] Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo \u00c1vila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, R\u00e9mi Munos, and Michal Valko. Bootstrap your own latent - A new approach to self-supervised learning. In NeurIPS, 2020. [37] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. In ICLR. OpenReview.net, 2021. [38] Jeff Z. HaoChen, Colin Wei, Adrien Gaidon, and Tengyu Ma. Provable guarantees for self-supervised deep learning with spectral contrastive loss. In NeurIPS, pages 5000\u20135011, 2021. [39] Jeff Z HaoChen, Colin Wei, Ananya Kumar, and Tengyu Ma. Beyond separability: Analyzing the linear transferability of contrastive representations to related subpopulations. Advances in Neural Information Processing Systems, 2022. [40] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, pages 770\u2013778. IEEE Computer Society, 2016. [41] Dan Hendrycks and Thomas G Dietterich. Benchmarking neural network robustness to common corruptions and surface variations. arXiv preprint arXiv:1807.01697, 2018. [42] Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-ofdistribution examples in neural networks. In ICLR (Poster). OpenReview.net, 2017. [43] Dan Hendrycks, Mantas Mazeika, and Thomas Dietterich. Deep anomaly detection with outlier exposure. In International Conference on Learning Representations, 2018.\n[44] Grant Van Horn, Oisin Mac Aodha, Yang Song, Yin Cui, Chen Sun, Alexander Shepard, Hartwig Adam, Pietro Perona, and Serge J. Belongie. The inaturalist species classification and detection dataset. In CVPR, pages 8769\u20138778. Computer Vision Foundation / IEEE Computer Society, 2018. [45] Qianjiang Hu, Xiao Wang, Wei Hu, and Guo-Jun Qi. Adco: Adversarial contrast for efficient learning of unsupervised representations from self-trained negative adversaries. In CVPR, pages 1074\u20131083. Computer Vision Foundation / IEEE, 2021. [46] Rui Huang, Andrew Geng, and Yixuan Li. On the importance of gradients for detecting distributional shifts in the wild. In NeurIPS, pages 677\u2013689, 2021. [47] Rui Huang and Yixuan Li. Mos: Towards scaling out-of-distribution detection for large semantic space. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8710\u20138719, 2021. [48] Zhuo Huang, Miaoxi Zhu, Xiaobo Xia, Li Shen, Jun Yu, Chen Gong, Bo Han, Bo Du, and Tongliang Liu. Robust generalization against photon-limited corruptions via worst-case sharpness minimization. In CVPR, pages 16175\u201316185. IEEE, 2023. [49] Ravi Kannan, Santosh Vempala, and Adrian Vetta. On clusterings: Good, bad and spectral. Journal of the ACM (JACM), 51(3):497\u2013515, 2004. [50] Julian Katz-Samuels, Julia B Nakhleh, Robert Nowak, and Yixuan Li. Training ood detectors in their natural habitats. In International Conference on Machine Learning. PMLR, 2022. [51] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton Earnshaw, Imran S. Haque, Sara M. Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, and Percy Liang. WILDS: A benchmark of in-the-wild distribution shifts. In ICML, volume 139 of Proceedings of Machine Learning Research, pages 5637\u20135664. PMLR, 2021. [52] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009. [53] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In International Conference on Machine Learning, pages 5815\u2013 5826. PMLR, 2021. [54] David Krueger, Ethan Caballero, J\u00f6rn-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, R\u00e9mi Le Priol, and Aaron C. Courville. Out-of-distribution generalization via risk extrapolation (rex). In ICML, volume 139 of Proceedings of Machine Learning Research, pages 5815\u20135826. PMLR, 2021. [55] James R Lee, Shayan Oveis Gharan, and Luca Trevisan. Multiway spectral partitioning and higher-order cheeger inequalities. Journal of the ACM (JACM), 61(6):1\u201330, 2014. [56] Jason D. Lee, Qi Lei, Nikunj Saunshi, and Jiacheng Zhuo. Predicting what you already know helps: Provable self-supervised learning. In NeurIPS, pages 309\u2013323, 2021. [57] Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. Advances in neural information processing systems, 31, 2018. [58] Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. In NeurIPS, pages 7167\u20137177, 2018. [59] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M. Hospedales. Learning to generalize: Meta-learning for domain generalization. In AAAI, pages 3490\u20133497. AAAI Press, 2018.\n[60] Da Li, Jianshu Zhang, Yongxin Yang, Cong Liu, Yi-Zhe Song, and Timothy M. Hospedales. Episodic training for domain generalization. In ICCV, pages 1446\u20131455. IEEE, 2019. [61] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C. Kot. Domain generalization with adversarial feature learning. In CVPR, pages 5400\u20135409. Computer Vision Foundation / IEEE Computer Society, 2018. [62] Wuyang Li, Jie Liu, Bo Han, and Yixuan Yuan. Adjustment and alignment for unbiased open set domain adaptation. In CVPR, pages 24110\u201324119. IEEE, 2023. [63] Ya Li, Mingming Gong, Xinmei Tian, Tongliang Liu, and Dacheng Tao. Domain generalization via conditional invariant representations. In AAAI, pages 3579\u20133587. AAAI Press, 2018. [64] Shiyu Liang, Yixuan Li, and R Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. In International Conference on Learning Representations, 2018. [65] Shiyu Liang, Yixuan Li, and R. Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. In ICLR (Poster). OpenReview.net, 2018. [66] Hong Liu, Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Qiang Yang. Separate to adapt: Open set domain adaptation via progressive separation. In CVPR, pages 2927\u20132936. Computer Vision Foundation / IEEE, 2019. [67] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection. Advances in Neural Information Processing Systems, 2020. [68] Frank McSherry. Spectral partitioning of random graphs. In Proceedings 42nd IEEE Symposium on Foundations of Computer Science, pages 529\u2013537. IEEE, 2001. [69] Yifei Ming, Ziyang Cai, Jiuxiang Gu, Yiyou Sun, Wei Li, and Yixuan Li. Delving into out-of-distribution detection with vision-language representations. In NeurIPS, 2022. [70] Yifei Ming, Ying Fan, and Yixuan Li. POEM: out-of-distribution detection with posterior sampling. In ICML, volume 162 of Proceedings of Machine Learning Research, pages 15650\u201315665. PMLR, 2022. [71] Yifei Ming, Yiyou Sun, Ousmane Dia, and Yixuan Li. How to exploit hyperspherical embeddings for out-of-distribution detection? In ICLR. OpenReview.net, 2023. [72] Sina Mohseni, Mandar Pitale, J. B. S. Yadawa, and Zhangyang Wang. Self-supervised learning for generalizable out-of-distribution detection. In AAAI, pages 5216\u20135223. AAAI Press, 2020. [73] Peyman Morteza and Yixuan Li. Provable guarantees for understanding out-of-distribution detection. In AAAI, pages 7831\u20137840. AAAI Press, 2022. [74] Hyeonseob Nam, HyunJae Lee, Jongchan Park, Wonjun Yoon, and Donggeun Yoo. Reducing domain gap by reducing style bias. In CVPR, pages 8690\u20138699. Computer Vision Foundation / IEEE, 2021. [75] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. Neural Information Processing Systems Workshops, 2011. [76] Andrew Ng, Michael Jordan, and Yair Weiss. On spectral clustering: Analysis and an algorithm. Advances in neural information processing systems, 14, 2001. [77] Andrew Y. Ng, Michael I. Jordan, and Yair Weiss. On spectral clustering: Analysis and an algorithm. In NIPS, pages 849\u2013856. MIT Press, 2001. [78] Oren Nuriel, Sagie Benaim, and Lior Wolf. Permuted adain: Reducing the bias towards global statistics in image classification. In CVPR, pages 9482\u20139491. Computer Vision Foundation / IEEE, 2021. [79] Pau Panareda Busto and Juergen Gall. Open set domain adaptation. In Proceedings of the IEEE international conference on computer vision, pages 754\u2013763, 2017.\n[80] Alexandre Ram\u00e9, Corentin Dancette, and Matthieu Cord. Fishr: Invariant gradient variances for out-of-distribution generalization. In ICML, volume 162 of Proceedings of Machine Learning Research, pages 18347\u201318377. PMLR, 2022. [81] Shiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, and Percy Liang. Distributionally robust neural networks. In ICLR. OpenReview.net, 2020. [82] Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada. Open set domain adaptation by backpropagation. In ECCV (5), volume 11209 of Lecture Notes in Computer Science, pages 156\u2013171. Springer, 2018. [83] Mohammadreza Salehi, Hossein Mirzaei, Dan Hendrycks, Yixuan Li, Mohammad Hossein Rohban, and Mohammad Sabokrou. A unified survey on anomaly, novelty, open-set, and out of-distribution detection: Solutions and future challenges. Trans. Mach. Learn. Res., 2022, 2022. [84] Nikunj Saunshi, Orestis Plevrakis, Sanjeev Arora, Mikhail Khodak, and Hrishikesh Khandeparkar. A theoretical analysis of contrastive unsupervised representation learning. In ICML, volume 97 of Proceedings of Machine Learning Research, pages 5628\u20135637. PMLR, 2019. [85] Vikash Sehwag, Mung Chiang, and Prateek Mittal. SSD: A unified framework for selfsupervised outlier detection. In ICLR. OpenReview.net, 2021. [86] Uri Shaham, Kelly P. Stanton, Henry Li, Ronen Basri, Boaz Nadler, and Yuval Kluger. Spectralnet: Spectral clustering using deep neural networks. In ICLR (Poster). OpenReview.net, 2018. [87] Kendrick Shen, Robbie M. Jones, Ananya Kumar, Sang Michael Xie, Jeff Z. HaoChen, Tengyu Ma, and Percy Liang. Connect, not collapse: Explaining contrastive learning for unsupervised domain adaptation. In ICML, volume 162 of Proceedings of Machine Learning Research, pages 19847\u201319878. PMLR, 2022. [88] Jianbo Shi and Jitendra Malik. Normalized cuts and image segmentation. IEEE Trans. Pattern Anal. Mach. Intell., 22(8):888\u2013905, 2000. [89] Yuge Shi, Jeffrey Seely, Philip H. S. Torr, Siddharth Narayanaswamy, Awni Y. Hannun, Nicolas Usunier, and Gabriel Synnaeve. Gradient matching for domain generalization. In ICLR. OpenReview.net, 2022. [90] Zhenmei Shi, Jiefeng Chen, Kunyang Li, Jayaram Raghuram, Xi Wu, Yingyu Liang, and Somesh Jha. The trade-off between universality and label efficiency of representations from contrastive learning. In ICLR. OpenReview.net, 2023. [91] Yiyou Sun, Chuan Guo, and Yixuan Li. React: Out-of-distribution detection with rectified activations. In NeurIPS, pages 144\u2013157, 2021. [92] Yiyou Sun and Yixuan Li. DICE: leveraging sparsification for out-of-distribution detection. In ECCV (24), volume 13684 of Lecture Notes in Computer Science, pages 691\u2013708. Springer, 2022. [93] Yiyou Sun and Yixuan Li. Opencon: Open-world contrastive learning. Trans. Mach. Learn. Res., 2023, 2023. [94] Yiyou Sun, Yifei Ming, Xiaojin Zhu, and Yixuan Li. Out-of-distribution detection with deep nearest neighbors. International Conference on Machine Learning, 2022. [95] Yiyou Sun, Zhenmei Shi, and Yixuan Li. A graph-theoretic framework for understanding open-world semi-supervised learning. In NeurIPS, 2023. [96] Yiyou Sun, Zhenmei Shi, Yingyu Liang, and Yixuan Li. When and how does known class help discover unknown ones? provable understanding through spectral analysis. In ICML, volume 202 of Proceedings of Machine Learning Research, pages 33014\u201333043. PMLR, 2023. [97] Christopher Tosh, Akshay Krishnamurthy, and Daniel Hsu. Contrastive estimation reveals topic posterior information to linear models. J. Mach. Learn. Res., 22:281:1\u2013281:31, 2021.\n[98] Christopher Tosh, Akshay Krishnamurthy, and Daniel Hsu. Contrastive learning, multi-view redundancy, and linear models. In ALT, volume 132 of Proceedings of Machine Learning Research, pages 1179\u20131206. PMLR, 2021. [99] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(11), 2008. [100] Vladimir Vapnik. An overview of statistical learning theory. IEEE Trans. Neural Networks, 10(5):988\u2013999, 1999. [101] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In CVPR, pages 5385\u20135394. IEEE Computer Society, 2017. [102] Haoqi Wang, Zhizhong Li, Litong Feng, and Wayne Zhang. Vim: Out-of-distribution with virtual-logit matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4921\u20134930, 2022. [103] Haoran Wang, Weitang Liu, Alex Bocchieri, and Yixuan Li. Can multi-label classification networks know what they don\u2019t know? In NeurIPS, pages 29074\u201329087, 2021. [104] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and Philip S. Yu. Generalizing to unseen domains: A survey on domain generalization. IEEE Trans. Knowl. Data Eng., 35(8):8052\u20138072, 2023. [105] Qian Wang, Fanlin Meng, and Toby P. Breckon. Progressively select and reject pseudo-labelled samples for open-set domain adaptation. CoRR, abs/2110.12635, 2021. [106] Qizhou Wang, Zhen Fang, Yonggang Zhang, Feng Liu, Yixuan Li, and Bo Han. Learning to augment distributions for out-of-distribution detection. In Advances in Neural Information Processing Systems, 2023. [107] Jingkang Yang, Kaiyang Zhou, Yixuan Li, and Ziwei Liu. Generalized out-of-distribution detection: A survey. CoRR, abs/2110.11334, 2021. [108] Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop. arXiv preprint arXiv:1506.03365, 2015. [109] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In BMVC. BMVA Press, 2016. [110] Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, and St\u00e9phane Deny. Barlow twins: Selfsupervised learning via redundancy reduction. In ICML, 2021. [111] Hanlin Zhang, Yi-Fan Zhang, Weiyang Liu, Adrian Weller, Bernhard Sch\u00f6lkopf, and Eric P. Xing. Towards principled disentanglement for domain generalization. In CVPR, pages 8014\u20138024. IEEE, 2022. [112] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. In International Conference on Learning Representations, 2018. [113] Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, and Chelsea Finn. Adaptive risk minimization: Learning to adapt to domain shift. In NeurIPS, pages 23664\u201323678, 2021. [114] Yabin Zhang, Hui Tang, Kui Jia, and Mingkui Tan. Domain-symmetric networks for adversarial domain adaptation. In CVPR, pages 5031\u20135040. Computer Vision Foundation / IEEE, 2019. [115] Shanshan Zhao, Mingming Gong, Tongliang Liu, Huan Fu, and Dacheng Tao. Domain generalization via entropy regularization. In NeurIPS, 2020. [116] Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. Places: A 10 million image database for scene recognition. IEEE transactions on pattern analysis and machine intelligence, 40(6):1452\u20131464, 2017.\n[117] Kaiyang Zhou, Yongxin Yang, Timothy M. Hospedales, and Tao Xiang. Learning to generate novel domains for domain generalization. In ECCV (16), volume 12361 of Lecture Notes in Computer Science, pages 561\u2013578. Springer, 2020. [118] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Domain generalization with mixstyle. In ICLR. OpenReview.net, 2021. [119] Zhi Zhou, Lan-Zhe Guo, Zhanzhan Cheng, Yu-Feng Li, and Shiliang Pu. STEP: out-ofdistribution detection in the presence of limited in-distribution labeled data. In NeurIPS, pages 29168\u201329180, 2021. [120] Xiaojin Zhu, Zoubin Ghahramani, and John D. Lafferty. Semi-supervised learning using gaussian fields and harmonic functions. In ICML, pages 912\u2013919. AAAI Press, 2003.\n# A Technical Details of Spectral Learning\nProof. We can expand Lmf(F, A) and obtain\nwhere fx = \u221awxf(x) is a re-scaled version of f(x). At a high level, we follow the proof in Haochen t al. [38], while the specific form of loss varies with the different definitions of positive/negative pairs. The form of L(f) is derived from plugging wxx\u2032 and wx.\nwhere fx = \u221awxf(x) is a re-scaled version of f(x). At a high level, we follow the proof in Haochen et al. [38], while the specific form of loss varies with the different definitions of positive/negative pairs. The form of L(f) is derived from plugging wxx\u2032 and wx. Recall that wxx\u2032 is defined by\nwxx\u2032 = \u03b7l \ufffd i\u2208Yl E\u00afxl\u223cPli E\u00afx\u2032 l\u223cPli T (x|\u00afxl)T (x\u2032|\u00afx\u2032 l) + \u03b7uE\u00afxu\u223cPT (x|\u00afxu)T (x\u2032|\u00afxu) ,\nwxx\u2032 = \u03b7l \ufffd E\u00afxl\u223cPli E\u00afx\u2032 l\u223cPli T (x|\u00afxl)T (x\u2032|\u00afx\u2032 l) + \u03b7uE\u00afxu\u223cPT (x|\u00afxu)T (x\u2032|\u00afxu) ,\nand wx is given by\n\ufffd = \u03b7l \ufffd i\u2208Yl E\u00afxl\u223cPli E\u00afx\u2032 l\u223cPli T (x|\u00afxl) \ufffd x\u2032 T (x\u2032|\u00afx\u2032 l) + \u03b7uE\u00afxu\u223cPT (x|\u00afxu) \ufffd x\u2032 T (x\u2032|\u00afxu) = \u03b7l \ufffd E\u00afxl\u223cPli T (x|\u00afxl) + \u03b7uE\u00afxu\u223cPT (x|\u00afxu).\nPlugging in wxx\u2032 we have,\nPlugging wx and wx\u2032 we have,\n=\u03b72 l L3(f) + 2\u03b7l\u03b7uL4(f) + \u03b72 uL5(f).\n# B Impact of Semantic OOD Data\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/145c/145c49bc-6b56-41ad-8338-e7bc2a38ee8d.png\" style=\"width: 50%;\"></div>\nIn our main analysis in Section 4, we consider semantic OOD to be from a different domain. Alternatively, instances of semantic OOD data can come from the same domain as covariate OOD data. In this section, we provide a complete picture by contrasting these two cases. Setup. In Figure 5, we illustrate two scenarios where the semantic OOD data has either a different or the same domain label as covariate OOD data. Other setups are the same as Sec. 4.3. Adjacency matrix. The adjacency matrix for scenario (a) has been derived in Eq. 11. For the alternative scenario (b) where semantic OOD shares the same domain as the covariate OOD, we can derive the analytic f\n<div style=\"text-align: center;\">(a) d(panda) \u0338= painting</div>\n \u0338 Figure 5: Illustration of 5 nodes graph and the augmentation probability defined by classes and domains. Figure (a) illustrates the scenario where semantic OOD data has a different domain from covariate OOD. Figure (b) depicts the case where semantic OOD and covariate OOD share the same domain.\nate OOD, we can derive the analytic form of adjacency matrix A1.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bd7b/bd7b793e-2294-4318-b18e-d1ed677b5ab0.png\" style=\"width: 50%;\"></div>\nwhere C1 is the normalization constant to ensure the summation of weights amounts to 1. Each row or column encodes connectivity associated with a specific sample, ordered by: angel sketch, tiger sketch, angel painting, tiger painting, and panda. We refer readers to the Appendix D.2 for the detailed derivation. Main analysis. Following the same assumption in Sec. 4.3, we are primarily interested in analyzing the difference of the representation space derived from A and A1 and put analysis on the top-3 eigenvectors \ufffdV1 \u2208R5\u00d73. Theorem B.1. Denote \u03b1\u2032 = \u03b1 \u03c1 and \u03b2\u2032 = \u03b2 \u03c1 and assume \u03b7u = 5, \u03b7l = 1, we have:\n\ufffd \uf8f0 \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \uf8fb where a(\u03bb) = \u221a 2(1\u22126\u03b2\u2032\u2212\u03bb) 8\u03b2\u2032 , b(\u03bb) = 4\u03b2\u2032\u22121+\u03bb 4\u03b2\u2032 , c(\u03bb) = \u221a 2(1\u22123\u03b1\u2032\u22126\u03b2\u2032\u2212\u03bb) 3\u03b1\u2032 . R is a diagonal matrix that normalizes the eigenvectors to unit norm and \ufffd\u03bb2, \ufffd\u03bb3 are the 2nd and 3rd highest eigenvalues. Interpretation. When semantic OOD shares the same domain as covariate OOD, the OOD generalization error E(f1) can be reduced to 0 as long as \u03b1 and \u03b2 are positive. This generalization ability shows that semantic OOD and covariate OOD sharing the same domain could benefit OOD generalization. We empirically verify our theory in Section E.4. Theorem B.2. Denote \u03b1\u2032 = \u03b1 \u03c1 and \u03b2\u2032 = \u03b2 \u03c1 and assume \u03b7u = 5, \u03b7l = 1, we have: S(f) \u2212S(f1) \ufffd > 0 , if \u03b1\u2032, \u03b2\u2032 \u2208black area in Figure 6 (b); < 0 , if \u03b1\u2032, \u03b2\u2032 \u2208white area in Figure 6 (b). (17)\nS(f) \u2212S(f1) \ufffd > 0 , if \u03b1\u2032, \u03b2\u2032 \u2208black area in Figure 6 (b); < 0 , if \u03b1\u2032, \u03b2\u2032 \u2208white area in Figure 6 (b).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/33f8/33f8bf90-0110-436e-bf76-c7dffd21a801.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) d(panda) = painting</div>\n(15)\n(16)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7c53/7c53e0af-42ed-4a8e-a9d6-c30e31d4d6e6.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5745/57455c4c-8893-4a4a-902b-6e39ea7b2d6a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) Heatmap of S(f) \u2212S(f1)</div>\nFigure 6: Visualization of the separability difference between two cases defined in Figure 5 (a) and Figure 5 (b). Figure 6 (a) utilizes a heatmap to depict the distribution, while Figure 6 (a) uses the indicator function.\nInterpretation. If \u03b1\u2032, \u03b2\u2032 \u2208black area in Figure 6 (b) and semantic OOD comes from a different domain, this would increase the separability between ID and semantic OOD, which benefits OOD detection. If \u03b1\u2032, \u03b2\u2032 \u2208white area in Figure 6 (b) and semantic OOD comes from a different domain, this would impair OOD detection.\n# C Impacts of ID Labels on OOD Generalization and Detection\nCompared to spectral contrastive loss proposed by Haochen et al. [38], we utilize ID labels in the pre-training. In this section, we analyze the impacts of ID labels on the OOD generalization and detection performance. Following the same assumption in Sec. 4.3, we are primarily interested in analyzing the difference of the representation space derived from A and A(u) and put analysis on the top-3 eigenvectors \ufffdV (u) \u2208R5\u00d73. Detailed derivation can be found in the Appendix D.3.\n\ufffd \u2208 Theorem C.1. Assume \u03b7u = 5, \u03b7l = 1, we have:\n\uf8f3 Interpretation. By comparing the eigenvectors \ufffdV in the supervised case (Theorem 4.1) and the eigenvectors \ufffdV (u) in the self-supervised case, we find that adding ID label information transforms the performance condition from \u03b1 = \u03b2 to 9 8\u03b1 = \u03b2. In particular, the discussion can be divided into two cases: (1) \u03b1 > \u03b2. (2) \u03b1 < \u03b2. In the first case when the connection between the class is stronger than the domain, the model could learn a perfect ID classifier based on features in the first two rows in \ufffdV (u) and effectively generalize to the covariate-shifted domain (the third and fourth row in \ufffdV (u)), achieving perfect OOD generalization with E(f (u)) = 0. In the second case when the connection between the domain is stronger than the connection between the class, the embeddings of covariate-shifted OOD data are identical, resulting in high OOD generalization error. Theorem C.2. Assume \u03b7u = 5, \u03b7l = 1, we have:\n# S(f) \u2212S(f (u)) > 0, if \u03b1 > 0, \u03b2 > 0\nInterpretation. After incorporating ID label information, the separability between ID and semantic OOD in the learned embedding space increases as long as \u03b1 and \u03b2 are positive. This suggests that ID label information indeed helps OOD detection. We empirically verify our theory in Section E.4.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/34e0/34e00043-b9e7-4401-80a2-4eb59ad90c4a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) Heatmap of 1(S(f) \u2212S(f1))</div>\n(18)\n(19)\n# D Technical Details of Derivation\n# D.1 Details for Figure 5 (a)\nAugmentation Transformation Probability. Recall the augmentation transformation probab which encodes the probability of augmenting an original image \u00afx to the augmented view x: \uf8f1\n\uf8f0 \uf8fb Each row or column encodes augmentation connectivity associated with a specific sample, ordered by: angel sketch, tiger sketch, angel painting, tiger painting, and panda.  \n\uf8f0 \uf8fb Each row or column encodes augmentation connectivity associated with a specific sample, ordered by: angel sketch, tiger sketch, angel painting, tiger painting, and panda. Details for A(u) and A(l). Recall that the self-supervised connectivity is defined in Eq. 1. Since w have a 5-nodes graph, A(u) would be 1 5T T \u22a4. If we assume \u03b7u = 5, we can derive the closed-form self-supervised adjacency matrix:\netails for A(u) and A(l). Recall that the self-supervised connectivity is defined in Eq. 1. Since we ave a 5-nodes graph, A(u) would be 1 5T T \u22a4. If we assume \u03b7u = 5, we can derive the closed-form elf-supervised adjacency matrix:\nDetails for A(u) and A(l). Recall that the self-supervised connectivity is defined in Eq. 1. Since we have a 5-nodes graph, A(u) would be 1 5T T \u22a4. If we assume \u03b7u = 5, we can derive the closed-form self-supervised adjacency matrix:\n\u03b7uA(u) =\n\uf8ee\n\uf8f0\n\u03c12 + \u03b22 + \u03b12 + 2\u03b32\n2\u03c1\u03b2 + \u03b32 + 2\u03b3\u03b1\n2\u03c1\u03b1 + \u03b32 + 2\u03b3\u03b2\n2\u03b1\u03b2 + \u03b32 + 2\u03b3\u03c1\n\u03b3(\u03b3 + \u03b1 + \u03b2 + 2\u03c1)\n2\u03c1\u03b2 + \u03b32 + 2\u03b3\u03b1\n\u03c12 + \u03b22 + \u03b12 + 2\u03b32\n2\u03b1\u03b2 + \u03b32 + 2\u03b3\u03c1\n2\u03c1\u03b1 + \u03b32 + 2\u03b3\u03b2\n\u03b3(\u03b3 + \u03b1 + \u03b2 + 2\u03c1)\n2\u03c1\u03b1 + \u03b32 + 2\u03b3\u03b2\n2\u03b1\u03b2 + \u03b32 + 2\u03b3\u03c1\n\u03c12 + \u03b22 + \u03b12 + 2\u03b32\n2\u03c1\u03b2 + \u03b32 + 2\u03b3\u03b1\n\u03b3(\u03b3 + \u03b1 + \u03b2 + 2\u03c1)\n2\u03b1\u03b2 + \u03b32 + 2\u03b3\u03c1\n2\u03c1\u03b1 + \u03b32 + 2\u03b3\u03b2\n2\u03c1\u03b2 + \u03b32 + 2\u03b3\u03b1\n\u03c12 + \u03b22 + \u03b12 + 2\u03b32\n\u03b3(\u03b3 + \u03b1 + \u03b2 + 2\u03c1)\n\u03b3(\u03b3 + \u03b1 + \u03b2 + 2\u03c1)\n\u03b3(\u03b3 + \u03b1 + \u03b2 + 2\u03c1)\n\u03b3(\u03b3 + \u03b1 + \u03b2 + 2\u03c1)\n\u03b3(\u03b3 + \u03b1 + \u03b2 + 2\u03c1)\n\u03c12 + 4\u03b32\n<div style=\"text-align: center;\">\uf8f0 Then, according to the supervised connectivity defined in Eq. 2, we only compute ID-labeled data. Since we have two known classes and each class contains one sample, A(l) = T:,1T \u22a4 :,1 + T:,2T \u22a4 :,2. Then if we let \u03b7l = 1, we can have the closed-form supervised adjacency matrix:</div>\n\uf8f0 \uf8fb Then, according to the supervised connectivity defined in Eq. 2, we only compute ID-labeled data. Since we have two known classes and each class contains one sample, A(l) = T:,1T \u22a4 :,1 + T:,2T \u22a4 :,2. Then if we let \u03b7l = 1, we can have the closed-form supervised adjacency matrix:\n\u03b7lA(l) =\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8f0\n\u03c12 + \u03b22\n2\u03c1\u03b2\n\u03c1\u03b1 + \u03b3\u03b2\n\u03b1\u03b2 + \u03b3\u03c1\n\u03b3(\u03c1 + \u03b2)\n2\u03c1\u03b2\n\u03c12 + \u03b22\n\u03b1\u03b2 + \u03b3\u03c1\n\u03c1\u03b1 + \u03b3\u03b2\n\u03b3(\u03c1 + \u03b2)\n\u03c1\u03b1 + \u03b3\u03b2\n\u03b1\u03b2 + \u03b3\u03c1\n\u03b12 + \u03b32\n2\u03b3\u03b1\n\u03b3(\u03b1 + \u03b3)\n\u03b1\u03b2 + \u03b3\u03c1\n\u03c1\u03b1 + \u03b3\u03b2\n2\u03b3\u03b1\n\u03b12 + \u03b32\n\u03b3(\u03b1 + \u03b3)\n\u03b3(\u03c1 + \u03b2)\n\u03b3(\u03c1 + \u03b2)\n\u03b3(\u03b1 + \u03b3)\n\u03b3(\u03b1 + \u03b3)\n2\u03b32\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fb\netails of eigenvectors \ufffdV . We assume \u03c1 \u226bmax(\u03b1, \u03b2) \u2265min(\u03b1, \u03b2) \u226b\u03b3 \u22650, and denote \u2032 = \u03b1 \u03c1 ,",
    "paper_type": "method",
    "attri": {
        "background": "In the context of modern machine learning, models deployed in real-world scenarios often encounter diverse data shifts like covariate and semantic shifts, leading to challenges in both out-of-distribution (OOD) generalization and detection. Despite considerable attention to these issues separately, a unified framework for theoretical understanding and practical usage is lacking.",
        "problem": {
            "definition": "The problem is defined as the challenge of achieving robust OOD generalization and detection in machine learning models when faced with data that deviates from the training distribution in unforeseen ways.",
            "key obstacle": "The main difficulty lies in the heterogeneity of the wild data distribution, where the learner lacks clear membership information for samples drawn from this distribution, complicating the task of distinguishing between in-distribution (ID), covariate-shifted OOD, and semantic-shifted OOD data."
        },
        "idea": {
            "intuition": "The intuition behind the proposed idea stems from the observation that existing methods often treat OOD generalization and detection as separate tasks, neglecting their interrelated nature.",
            "opinion": "The proposed idea is a graph-theoretic framework that jointly addresses both OOD generalization and detection problems by leveraging the relationships among data points represented in a graph.",
            "innovation": "The primary innovation of the proposed method is the formalization of OOD generalization and detection through spectral decomposition of a graph's adjacency matrix, which allows for a theoretical characterization of performance that existing methods do not provide."
        },
        "method": {
            "method name": "Graph-Theoretic Framework for OOD Generalization and Detection",
            "method abbreviation": "GFOOD",
            "method definition": "This method defines a graph where vertices represent data points and edges connect similar data points, allowing for the extraction of meaningful representations that facilitate OOD generalization and detection.",
            "method description": "The core of the method involves constructing a graph from both labeled ID data and unlabeled wild data, followed by spectral decomposition to derive data representations.",
            "method steps": [
                "Construct a graph with vertices representing data points and edges based on similarity.",
                "Utilize both supervised and self-supervised signals to define edge weights.",
                "Perform spectral decomposition on the adjacency matrix to obtain feature representations.",
                "Train a classifier and an OOD detector using these representations."
            ],
            "principle": "The effectiveness of this method is underpinned by the theoretical insights gained from graph spectral analysis, which elucidates how the learned representations can distinguish between ID and OOD data."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted using CIFAR-10 as the in-distribution dataset and CIFAR-10-C with Gaussian noise as the covariate OOD dataset, along with SVHN, LSUN, and Textures as semantic OOD datasets.",
            "evaluation method": "The performance of the method was assessed using metrics such as ID generalization accuracy, OOD generalization accuracy, and OOD detection error, with comparisons made against baseline methods."
        },
        "conclusion": "The proposed graph-theoretic framework successfully addresses the dual challenges of OOD generalization and detection, demonstrating competitive performance in empirical evaluations while aligning with the theoretical insights provided.",
        "discussion": {
            "advantage": "The key advantage of the proposed approach is its ability to simultaneously improve both OOD generalization and detection performance, leveraging the relationships among data points in a unified framework.",
            "limitation": "A limitation of the method is its focus on covariate shift as the primary form of distributional shift, potentially overlooking other types of shifts such as concept shifts.",
            "future work": "Future research could explore the incorporation of additional types of distributional shifts and further refine the graph-theoretic framework to enhance its applicability across diverse scenarios."
        },
        "other info": {
            "code_url": "https://github.com/deeplearning-wisc/graph-spectral-ood",
            "acknowledgements": "The authors acknowledge funding support from various grants, including AFOSR Young Investigator Program and NSF Awards."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The problem is defined as the challenge of achieving robust OOD generalization and detection in machine learning models when faced with data that deviates from the training distribution in unforeseen ways."
        },
        {
            "section number": "1.2",
            "key information": "The intuition behind the proposed idea stems from the observation that existing methods often treat OOD generalization and detection as separate tasks, neglecting their interrelated nature."
        },
        {
            "section number": "2.1",
            "key information": "Despite considerable attention to OOD detection and generalization separately, a unified framework for theoretical understanding and practical usage is lacking."
        },
        {
            "section number": "3.3",
            "key information": "The proposed idea is a graph-theoretic framework that jointly addresses both OOD generalization and detection problems by leveraging the relationships among data points represented in a graph."
        },
        {
            "section number": "3.4",
            "key information": "The core of the method involves constructing a graph from both labeled ID data and unlabeled wild data, followed by spectral decomposition to derive data representations."
        },
        {
            "section number": "5.1",
            "key information": "The key advantage of the proposed approach is its ability to simultaneously improve both OOD generalization and detection performance, leveraging the relationships among data points in a unified framework."
        },
        {
            "section number": "7.1",
            "key information": "A limitation of the method is its focus on covariate shift as the primary form of distributional shift, potentially overlooking other types of shifts such as concept shifts."
        },
        {
            "section number": "7.2",
            "key information": "Future research could explore the incorporation of additional types of distributional shifts and further refine the graph-theoretic framework to enhance its applicability across diverse scenarios."
        }
    ],
    "similarity_score": 0.6614985389843453,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Bridging OOD Detection and Generalization_ A Graph-Theoretic View.json"
}