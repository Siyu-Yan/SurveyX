{
    "from": "google",
    "scholar_id": "ERu9C2dKl2QJ",
    "detail_id": null,
    "title": "Representation learning with large language models for recommendation",
    "abstract": "\n\nABSTRACT\n\n# ABSTRACT\n\nRecommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in textonly reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLMempowered representation learning. It proposes a recommendation paradigm that integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences. RLMRec incorporates auxiliary textual signals, employs LLMs for user/item profiling, and aligns the semantic space of LLMs with collaborative relational signals through cross-view alignment. This work further demonstrates the theoretical foundation of incorporating textual signals through mutual information maximization, which improves the quality of representations. Our evaluation integrates RLMRec with state-of-the-art recommender models, while also analyzing its efficiency and robustness to noise data. Implementation codes are available at https://github.com/HKUDS/RLMRec.\n\n\u2217 Chao Huang is the Corresponding Author.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pr",
    "bib_name": "ren2024representation",
    "md_text": "# Representation Learning with Large Language Models for Recommendation\n\nXubin Ren University of Hong Kong xubinrencs@gmail.com\nWei Wei University of Hong Kong weiweics@connect.hku.hk\n\nKong.com\nWei Wei University of Hong Kong weiweics@connect.hku.hk\n\nWei Wei University of Hong Kong weiweics@connect.hku.hk\n\nXubin Ren University of Hong Kong xubinrencs@gmail.com\n\nLixin Su Baidu Inc. inict@gmail.com\nSuqi Cheng Baidu Inc. chengsuqi@gmail.com\n\nSuqi Cheng Baidu Inc. chengsuqi@gmail.com\n\nLixin Su Baidu Inc. sulixinict@gmail.com\n\nChao Huang \u2217\nDawei Yin Baidu Inc. yindawei@acm.org\nUniversity of Hong Kong chaohuang75@gmail.com\n\nDawei Yin Baidu Inc. ndawei@acm.\n\nDawei Yin Baidu Inc. yindawei@acm.org\n\nBaidu Inc. yindawei@acm.org\n\nABSTRACT\n\n# ABSTRACT\n\nRecommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in textonly reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLMempowered representation learning. It proposes a recommendation paradigm that integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences. RLMRec incorporates auxiliary textual signals, employs LLMs for user/item profiling, and aligns the semantic space of LLMs with collaborative relational signals through cross-view alignment. This work further demonstrates the theoretical foundation of incorporating textual signals through mutual information maximization, which improves the quality of representations. Our evaluation integrates RLMRec with state-of-the-art recommender models, while also analyzing its efficiency and robustness to noise data. Implementation codes are available at https://github.com/HKUDS/RLMRec.\n\n\u2217 Chao Huang is the Corresponding Author.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WWW \u201924, May 13\u201317, 2024, Singapore, Singapore \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0171-9/24/05...$15.00 https://doi.org/10.1145/3589334.3645458\n\nLianghao Xia University of Hong Kong aka_xia@foxmail.com\n\nJunfeng Wang Baidu Inc. wangjunfeng@baidu.com\n\nChao Huang \u2217\nUniversity of Hong Kong chaohuang75@gmail.com\n\n# CCS CONCEPTS\n\n# CCS CONCEPTS\n\u2022 Information systems \u2192 Recommender systems.\n\n# \u2022 Information systems \u2192 Recommender systems.\nKEYWORDS\n\nKEYWORDS\n\nLarge Language Models, Recommendation, Alignment\nACM Reference Format: Xubin Ren, Wei Wei, Lianghao Xia, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2024. Representation Learning with Large Language Models for Recommendation. In Proceedings of the ACM Web Conference 2024 (WWW \u201924), May 13\u201317, 2024, Singapore, Singapore. ACM, Singapore, Singapore, 12 pages. https://doi.org/10.1145/3589334.3645458\n\n# 1 INTRODUCTION\n\nRecommender systems have evolved to provide personalized item recommendations based on user interactions, with deep learning and graph neural networks playing a significant role [4, 39]. Graphbased recommenders like NGCF [35] and LightGCN [11] have demonstrated impressive capabilities in capturing complex useritem relationships, making them state-of-the-art approaches. However, it\u2019s important to note that recent graph-based recommenders heavily rely on ID-corresponding information for learning. The training data in this line only consists of mapped user/item indices, and their interactions are represented in an interaction matrix using binary values (1 for interaction and 0 for no interaction). While this data arrangement has shown effectiveness, one limitation is its primary reliance on ID-based information, potentially overlooking other valuable data such as rich textual information associated with users and items. The absence of this additional information can lead to reduced informativeness in the learned representations. Furthermore, it is worth noting that a substantial portion of the data in these graph-based recommenders consists of implicit feedback [27, 33], which can introduce noise from false negatives or bias (e. g., misclicks [34] or popularity bias [5]). Consequently, the learned representations of these GNN-based models heavily rely on the inherent quality of the data. This heavy reliance on the data quality poses a potential challenge as it can lead to detrimental representations that hinder the effectiveness of recommendation systems, especially when the data contains noise. In recent times, there have been several endeavors to leverage diverse data modalities in order to enhance traditional ID-based\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ebf0/ebf08b12-7a35-4df5-896e-6b11a4004ebb.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: LLM\u2019s performance for recommendation reranking when dealing with different sizes of candidate items.\n</div>\nrecommenders [9, 17, 46]. Particularly interesting is the emergence of large language models (LLMs) like GPT-4 [24] and LLaMA [32], which have demonstrated impressive capabilities in neural language understanding tasks. This development has sparked significant interest among researchers, who are actively exploring how LLMs, with their proficiency in handling textual content, can extend the capabilities of recommendation systems beyond the original data [7, 18, 21]. A primary focus of current research in this field revolves around aligning recommendation approaches with the characteristics of language models through prompt design. Methods like InstructRec [47] structure the recommendation task in an instruction-question-answering format, enabling LLMs to simultaneously address the recommendation objective and respond to intricately designed questions [1, 9]. However, these methods still lag behind existing recommenders in terms of efficiency and precision. This can be attributed to inherent shortcomings associated with this approach, including the following key aspects: i) Scalability issues in practical recommenders. Utilizing large language models (LLMs) in personalized user behavior modeling requires significant computational resources. As the scale of user behavior data grows, so do the computational demands and associated inference time costs. For instance, in TALLRec [1], where recommendations are generated based on an instruction-questionanswering format, the response time for LLaMA2-13B to provide recommendations to individual users is approximately 3.6 seconds, with an input size of around 800 tokens (equivalent to approximately 5 users). However, this poses significant challenges when attempting to scale up the approach for practical recommender systems with a substantial user base and extensive item catalog. ii) Limitations stemming from text-only reliance. LLMs have the potential to generate text answers that may include recommendations for non-existent items due to hallucination issues [20]. This poses a challenge in ensuring the accuracy and reliability of the generated recommendations. Additionally, the limited capacity of prompt inputs, constrained by the maximum number of tokens (e.g., 2048 tokens for LLaMA), hinders the effective modeling of comprehensive collaborative signals with global user dependencies. To validate the aforementioned limitations, we evaluate the effectiveness of directly using LLMs in enhancing the re-ranking task [12, 31] for recommendation on the Amazon dataset. Specifically, we utilize LightGCN [11] as the backbone model, which retrieve a ranking list of 50 candidate items for each user. To further refine the recommendations, we integrate the textual information of each item with our custom prompts (for details, please refer to Appendix A.3). These prompts are then processed by ChatGPT (i. e., gpt-3.5-turbo). The objective of this task is to re-rank the item list for each user and identify the Top-10&20 most relevant items.\n\nIt is evident from the results in Figure 1 that the recommendations refined by the ChatGPT perform worse than the original results provided by LightGCN. This indicates limitations when blindly using LLMs to improve the re-ranking process in recommendation. These limitations can be attributed to three factors: i) The hallucination issue of LLMs, suggesting items not in the candidate set; ii) The lack of a comprehensive global text-based collaborative relationship input due to token limits; iii) Additionally, it is worth noting that the reranking process using LLM takes several hours to complete, which poses a challenge when dealing with large-scale data in real-world recommendation scenarios. Due to page constraints, we provide detailed analysis and examples in the Appendix to demonstrate the phenomenon of hallucination. Contributions. In light of the aforementioned limitations, we aim to leverage the power of LLMs to seamlessly enhance existing recommender systems. To accomplish this, we propose a modelagnostic framework called RLMRec (R epresentation Learning with Large L anguage M odels for Rec ommendation). The core idea of RLMRec is to utilize representation learning as a bridge between ID-based recommenders and LLMs. Our new recommendation paradigm aims to preserve the accuracy and efficiency of existing recommenders while harnessing the powerful text comprehension capabilities of LLMs to understand the intricate semantic aspects of user behaviors and preferences. To begin, we lay the theoretical groundwork by modeling the benefits of incorporating auxiliary textual signals for representation learning. This involves transforming the textual signals into meaningful representations and establishing a theoretical foundation for maximizing mutual information within general recommendation models. Moreover, we develop a user/item profiling paradigm empowered by LLMs, enhancing representation expressiveness by incorporating comprehensive semantic understanding from the global knowledge space of LLMs. Furthermore, we propose to align the semantic space of LLMs and the representation space of collaborative relational signals through a cross-view alignment framework. This alignment is achieved through a cross-view mutual information maximization scheme, which allows us to find a common semantic subspace where the textual and collaborative relational embeddings are well aligned from the contrastive and generative modeling, respectively. In a nutshell, our main contributions can be summarized as follows: \u2022  This work aims to explore the potential of enhancing the recommendation performance of existing recommender systems, by leveraging LLMs and aligning their semantic space with collaborative relation modeling for better representation learning.\n\u2022 We propose a model-agnostic representation learning framework called RLMRec, which is guided by our theoretical findings. This framework leverages contrastive or generative modeling techniques to enhance the quality of learned representations.\n\u2022  We establish a theoretical foundation to demonstrate the effectiveness of incorporating textual signals in enhancing the representation learning. By utilizing mutual information maximization, we show how textual signals can improve the representation quality.\n\u2022 We integrate RLMRec with various state-of-the-art recommender models and validate the effectiveness of our method. Additionally, we analyze the framework\u2019s robustness to noise and incomplete data, showcasing its ability to handle real-world challenges.\n\n# 2 RELATED WORK\n\nGNN-enhanced Collaborative Filtering. Collaborative Filtering (CF), a fundamental technique in recommendation systems, has been extensively studied [16, 30]. An emerging direction is to use historical user-item interactions to create a bipartite graph and employ Graph Neural Networks (GNNs) to capture high-order collaborative relationships. These graph-based methods, such as NGCF [35], GCCF [6], LightGCN [11], have demonstrated stateof-the-art performance, improving recommendation effectiveness. However, the sparsity and noise in implicit feedback data pose challenges to graph-based methods. To address this, researchers have explored the use of self-supervised learning (SSL) techniques as auxiliary learning objectives to enhance robustness in recommendations [43, 45]. Among various SSL techniques, contrastive learning has emerged as a prominent solution in collaborative filtering models. Methods like SGL [37], SimGCL [44], NCL [19], LightGCL [3] leverage contrastive data augmentation to improve recommendation performance. In this work, we take a step further by integrating LLMs with existing CF models to effectively align the knowledge and reasoning abilities of LLMs with the collaborative relation learning for enhancing recommendation performance. Large Language Models for Recommendation. leveraging LLMs for recommendation systems has gained interest [7, 18, 21, 38]. Several studies have leveraged LLMs as inference models by designing prompts that align them with recommendation tasks. For example, P5 [9] converts the user interaction data into textual prompts using item indexes, which are then used for language model training. Chat-REC [8] builds a conversational recommender by transforming user profiles and interactions into prompts for LLMs to generate recommendations. InstructRec [47] and TALLRec [1] employ instructional designs to define recommendation tasks and fine-tune LLMs to align with these instructions for generating recommendations. However, using LLMs directly for recommendation tasks faces challenges like high computational costs and slow inference times. To address this, our approach adopts mutual information maximization to align LLMs knowledge with collaborative relation modeling, enabling scalable and effective recommendations.\n\n# 3 METHODOLOGY\n\n# 3.1 Theoretical Basis of RLMRec\n\nCollaborative Filtering. In our recommendation scenario, we have a set of users U = \ud835\udc62 1, ...,\ud835\udc62 \ud835\udc3c and a set of items V = \ud835\udc63 1, ..., \ud835\udc63 \ud835\udc3d. The observed user-item interactions are represented by X. In learningbased recommenders, each user and item is assigned initial embeddings x \ud835\udc62 and x \ud835\udc63. The goal is to learn user and item representations e \ud835\udc62, e \ud835\udc63 through a recommender model (i. e., e \ud835\udc62, e \ud835\udc63 = R(x \ud835\udc62, x \ud835\udc63)) that maximizes the posterior distribution shown below:\n\n# \ud835\udc5d (e |X) \u221d \ud835\udc5d (X| e) \ud835\udc5d (e).\n\nIn practical recommendation scenarios, the observed user-item interactions X often contain noise, including false positives (e. g., misclicks or interactions influenced by popularity bias) and false negatives (e. g., users do not interact with unseen but interested items). As a result, the learned representation e can also be affected by this noise, which negatively impacts recommendation accuracy. In this work, we introduce a hidden prior belief z that is inherently\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2d89/2d89973f-e284-45e1-9573-5d055c7b68b5.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/986d/986d55fa-f6b6-42f7-b042-67cd0660acfc.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">e CF-side rational representation s \u2013 LLMs-enhanced semantic representation z hidden prior benefit for recommendation\n</div>\n<div style=\"text-align: center;\">Learning Mechanism\n</div>\nFigure 2: The type of directed graph model under consideration. As the alignment between CF-side representation and LLM-enhanced representation, the noisy effects in the learned representations \ud835\udc52 are alleviated in RLMRec.\n\nbeneficial for recommendation. This prior belief helps identify the true positive samples in X. Hence, the generation of representation e involves a combination of the advantageous prior belief z and the unavoidable noise present during the learning process.\n\nText-enhanced User Preference Learning. To mitigate the impact of irrelevant signals on the representation, it is necessary to incorporate auxiliary informative cues. One approach is to introduce textual information, e. g., user and item profiles, which provide insights for user preference learning. These profiles can be encoded using language models to generate representations s \u2208 R \ud835\udc51 \ud835\udc60 that effectively capture the semantic aspects of user preferences. Importantly, both s and e capture shared information that is relevant to the aspects associated with user-item interactions. This shared information is crucial as it indicates the inclusion of beneficial aspects for recommendation, aligning with the prior belief z. With the collaborative-side representation e and textual-side representation s, both of which contain recommendation-beneficial information generated from z, our objective is to learn the optimal value of e denoted as e \u2217, by maximizing the conditional probability:\n\nThe underlying intuition behind maximizing the conditional probability is to ensure that the learnable representation e from recommender models incorporates purer information generated from the prior belief z and the shared information with the semantic representation s. By doing so, the relevance and benefits of the learned representations e for recommendation are enhanced. Theorem 1. Maximizing the posteriori probability E \ud835\udc5d (e, s) [\ud835\udc5d (z, s | e) given the hidden prior belief z, is equivalent to maximizing the mutual information \ud835\udc3c (\ud835\udc52; \ud835\udc60) between the CF-side relational representation e and LLM-side semantic representation s. Proof. It is important to note that since the profiles of users and items are fixed, the probability \ud835\udc5d (s) remains constant during the learning process. Therefore, we can deduce the following:\n\u222b\n\n(5)\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/06c9/06c91f13-e46b-466d-8c5d-fba18bb1f566.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) Contrastive Alignment\n</div>\n<div style=\"text-align: center;\">(a) Profile Generation via Reasoning\n</div>\nLet\u2019s consider e and s as data samples, assuming that we have \ud835\udc41 pairwise corresponding elements of e and s, forming the sets E = {e 1, . . . , e \ud835\udc56, . . . , e \ud835\udc41} and S = {s 1, . . . , s \ud835\udc56, . . . , s \ud835\udc41}, respectively. Based on this, we optimize the mutual information as follows. Theorem 2. By introducing the density ratio to preserve mutal information [23] \ud835\udc53 (s, e) \u221d \ud835\udc5d (s | e)/ \ud835\udc5d (s), the maximization of \ud835\udc3c (e \ud835\udc56; s \ud835\udc56) can be reformulated as maximizing the following lower bound:\n\n(6)\n\n\ufffd \u2208\nProof. Based on the property of mutual information, we have \ud835\udc3c (e \ud835\udc56, s \ud835\udc56) = \ud835\udc3c (s \ud835\udc56, e \ud835\udc56). With this in mind, we make the deductions as:\n\n(7)\n\n(8)\n\n(9)\n\n(10)\n\n(11)\n\n\ufffd \u2208\nHere, S neg represents the negative samples when considering the \ud835\udc56-th sample (i. e., S \ud835\udc5b\ud835\udc52\ud835\udc54 = S \\ \ud835\udc60 \ud835\udc56). Up to this point, we have derived, from a theoretical perspective, how to alleivate noisy effects in representations by introducing external knowledge. However, this approach also presents two challenges: i) Challenge 1: How to obtain effective descriptions of users and items that capture their interaction preferences. ii) Challenge 2: How to involves effectively modeling the density ratio \ud835\udc53 (s, e) to maximize the mutual information between e and s. In the following sections, we discuss potential solutions to address these two challenges.\n\n# 3.2 User/Item Profiling Paradigm\n\nIn our previous derivation, we emphasize the importance of obtaining textual descriptions, referred to as profiles, for users and items. These profiles play a crucial role in mitigating the impact of noise in the learned representations of recommenders and enable a semantic understanding of users\u2019 and items\u2019 interaction preferences. Ideally, user and item profiles should exhibit the following characteristics: \u2022 User profile: should effectively encapsulate the particular types of items that users are inclined to favor, allowing for a comprehensive representation of their personalized tastes and preferences.\n\n<div style=\"text-align: center;\">(c) Generative Alignmen\n</div>\n\u2022 Item profile: It should eloquently articulate the specific types of users that the item is apt to attract, providing a clear representation of the item\u2019s characteristics and qualities that align with the preferences and interests of those users.\n\nIn some cases, the original data may include textual properties related to users and items. For example, in the Yelp dataset, users provide reviews for visited businesses, and businesses have attributes such as location and category. However, such textual data often contains extraneous noise, leading to common predicaments: i) Missing Attributes: Some attributes of certain items or users may be missing; ii) Noisy Textual Data: The text itself may be contaminated with a plethora of noise that is irrelevant to users\u2019 preferences. For instance, in the Steam dataset, user reviews for games may contain numerous special symbols or irrelevant information. These challenges make it difficult to distill useful user and item profiles from text. As a result, prevailing models often convert low-noise attributes into one-hot encodings without effectively leveraging the semantic information present in the textual data. Fortunately, recent advancements in Large Language Models (LLMs) have unleashed their remarkable text processing capabilities, enabling them to address a wide range of NLP tasks, including text denoising and summarization. This pivotal development opens up new possibilities for generating user and item profiles from the noisy textual features inherent in the dataset. Leveraging the tremendous potential of LLMs, we propose a paradigm for profile generation that capitalizes on collaborative information. Considering that datasets often contain a higher proportion of textual descriptions for item attributes compared to user attributes, our approach takes an item-to-user perspective, as outlined below.\n\n# Profile Generation via Reasoning. Recent re\n\n# Profile Generation via Reasonin\n\ndemonstrated the effectiveness of incorporating process reasoning in LLMs to mitigate hallucination and improve the quality of generated outputs. Building upon these findings, we have meticulously designed the system prompt S \ud835\udc62 / \ud835\udc63 as part of the input provided to LLMs. The objective is to clearly define its functionality in generating user profile for user \ud835\udc62 or item profile for item \ud835\udc63 by precisely specifying the input-output content and desired output format. Importantly, we explicitly emphasize the inclusion of reasoning processes as an integral part of the generated output. By combining this system prompt with user/item profile generation prompts Q \ud835\udc62 and Q \ud835\udc63, we can leverage LLMs to generate accurate profiles. The specific process is outlined as follows:\n\nP \ud835\udc62 = \ud835\udc3f\ud835\udc3f\ud835\udc40\ud835\udc60 (S \ud835\udc62, Q \ud835\udc62), P \ud835\udc63 = \ud835\udc3f\ud835\udc3f\ud835\udc40\ud835\udc60 (S \ud835\udc63, Q \ud835\udc63)\n\n3.2.2 Item Prompt Construction.  we categorize the textual information of an item \ud835\udc63 \u2208V into four types: title \ud835\udefc, original description \ud835\udefd, dataset-specific attributes \ud835\udf38 = \ud835\udefe 1, ...,\ud835\udefe | \ud835\udf38 |, and a collection of \ud835\udc5b reviews from users r = \ud835\udc5f 1, ...,\ud835\udc5f \ud835\udc5b. Based on these categories, we can formally outline the arrangement of the input prompt Q \ud835\udc63 for item-profile generation as follows:\n\ufffd\n\n(13)\n\nIn our approach, we use a function \ud835\udc53 \ud835\udc63 (\u00b7) specific to each item, which combines various text features into a single string. If the original description \ud835\udefd is missing, we randomly sample a subset of reviews \u02c6 r and combine them with the attributes for input. By incorporating item descriptions or user reviews, our prompts provide precise information to Large Language Models, ensuring that the generated item profiles accurately reflect appealing characteristics.\n\nIn our approach, we use a function \ud835\udc53 \ud835\udc63 (\u00b7) specific to each item, which combines various text features into a single string. If the original description \ud835\udefd is missing, we randomly sample a subset of reviews \u02c6 r and combine them with the attributes for input. By incorporating item descriptions or user reviews, our prompts provide precise information to Large Language Models, ensuring that the generated item profiles accurately reflect appealing characteristics.\n3.2.3 User Prompt Construction. To generate the profile of user \ud835\udc62, we leverage collaborative information, assuming that we have already generated the item profiles beforehand. Specifically, we consider the items interacted with by user \ud835\udc62 as I \ud835\udc62 and uniformly sample a subset of items \u02c6 I \ud835\udc62 \u2282I \ud835\udc62. For each item \ud835\udc63 in \u02c6 I \ud835\udc62, we concatenate its textual attributes as c \ud835\udc63 = [\ud835\udefc, P \ud835\udc63,\ud835\udc5f \ud835\udc63 \ud835\udc62], where \ud835\udc5f \ud835\udc63 \ud835\udc62 represents the review provided by user \ud835\udc62. The input prompt Q \ud835\udc62 for user-profile generation can be defined as follows:\n\n3.2.3 User Prompt Construction. To generate the profile of user \ud835\udc62, we leverage collaborative information, assuming that we have already generated the item profiles beforehand. Specifically, we consider the items interacted with by user \ud835\udc62 as I \ud835\udc62 and uniformly sample a subset of items \u02c6 I \ud835\udc62 \u2282I \ud835\udc62. For each item \ud835\udc63 in \u02c6 I \ud835\udc62, we concatenate its textual attributes as c \ud835\udc63 = [\ud835\udefc, P \ud835\udc63,\ud835\udc5f \ud835\udc63 \ud835\udc62], where \ud835\udc5f \ud835\udc63 \ud835\udc62 represents the review provided by user \ud835\udc62. The input prompt Q \ud835\udc62 for user-profile generation can be defined as follows:\n\n(14)\n\nThe function \ud835\udc53 \ud835\udc62 (\u00b7) serves a similar purpose to \ud835\udc53 \ud835\udc63 (\u00b7) by organizing the textual content into a coherent string. Each textual attribute c \ud835\udc63 includes user reviews, which authentically reflect their genuine opinions. This construction of the user prompt provides valuable insights into their true preferences. Due to space constraints, we have included the detailed design of the prompt, including S, Q, and \ud835\udc53 \ud835\udc62 / \ud835\udc63 (\u00b7), along with sample examples in Appendix A.2.\n\n# 3.3 Density Ratio Modeling for Mutual Information Maximization\n\nIn this section, we outline the process of modeling the density ratio, denoted as \ud835\udc53 (s \ud835\udc56, e \ud835\udc56), with the objective of maximizing the mutual information \ud835\udc3c (s \ud835\udc56, e \ud835\udc56). First of all, it is important to note that we have previously generated user/item profiles P \ud835\udc62 / \ud835\udc63 that showcase their interaction preferences. As such, it is logical to encode the semantic representation s based on these profiles as follow:\n\n(15)\n\nHere, T (\u00b7) refers to a cutting-edge technology known as a text embedding model [14, 29], which has been shown to effectively transform diverse text inputs into fixed-length vectors that retain their inherent meaning and contextual information. According to [23], the density ratio \ud835\udc53 (s \ud835\udc56, e \ud835\udc56) can be interpreted as a positive real-valued score measurement function that captures the similarity between s \ud835\udc56 and e \ud835\udc56. A more accurate modeling of the density ratio [28] can have a positive impact on the alignment between CF-side rational representations and LLMs-enhanced semantic representations, helping to mitigate the influence of noisy signals in representation learning. In this context, we propose two types of modeling approaches that are well-suited for achieving this\n\nalignment. The first approach is contrastive modeling, which has been extensively validated [15, 37] for effectively aligning different views bidirectionally, such as through pull and push pairs. The second approach is mask-reconstruction generative modeling, which is widely used as a self-supervised mechanism for reconstructing the partially masked input from data itself [10, 13]. By employing CF-side representations to reconstruct the semantic representations, we can effectively align these two forms of information.\n\n# 3.3.1 Contrastive Alignment. As depicted in Fig 3 (b), we denote the specific implementation of \ud835\udc53 (s \ud835\udc56, e \ud835\udc56) as contrastive alignment.\n\n\ud835\udc53 (s \ud835\udc56, e \ud835\udc56) = \ud835\udc52\ud835\udc65\ud835\udc5d (\ud835\udc60\ud835\udc56\ud835\udc5a (\ud835\udf0e \u2193 (s \ud835\udc56), e \ud835\udc56)).\n\nThe function \ud835\udc60\ud835\udc56\ud835\udc5a (\u00b7) represents the cosine similarity, while \ud835\udf0e \u2193 denotes a multi-layer perception that maps the semantic representation s \ud835\udc56 into the feature space of e \ud835\udc56. In our contrastive alignment, we treat e \ud835\udc56 and s \ud835\udc56 as positive sample pairs. During the learning process, these pairs are pulled towards each other to align their representations. In the specific implementation, the objective is to bring positive sample pairs closer within a batch while considering the remaining samples as negatives.\n\n3.3.2 Generative Alignment. Taking inspiration from recent research on the masked autoencoder (MAE), which is considered a paradigm of generative self-supervised learning, we propose an additional modeling approach for the density ratio within the MAE.\n\n\ud835\udc53 (s \ud835\udc56, e \ud835\udc56) = \ud835\udc52\ud835\udc65\ud835\udc5d (\ud835\udc60\ud835\udc56\ud835\udc5a (s \ud835\udc56, \ud835\udf0e \u2191 (\u02c6 e \ud835\udc62))) \ud835\udc64.\ud835\udc5f.\ud835\udc61. \u02c6 e \ud835\udc56 = R({x} \\ x \ud835\udc56). (17)\n\nWe employ \ud835\udf0e \u2191 as a multi-layer perception model to map the representations to the semantic feature space. x \\ x \ud835\udc56 represents the initial embedding of the \ud835\udc56-th sample with masking applied. The generative process follows a single-direction reconstruction approach, focusing on reconstructing the semantic representations exclusively for the masked samples. Specifically, the masking operation involves replacing the initial embedding with a designated mask token (i. e., [\ud835\udc40\ud835\udc34\ud835\udc46\ud835\udc3e]), and a random subset of users/items is masked and subsequently reconstructed. This allows us to explore the reconstruction capabilities within the semantic feature space. With our contrastive and generative alignment method, we effectively align the knowledge of the LLM with the domain of understanding user preferences. This is achieved by combining id-based collaborative relational signals with text-based behavior semantics. We have given the names RLMRec-Con and RLMRec-Gen to our two proposed modeling approaches, respectively. In our experiments conducted on real-world data, we will comprehensively evaluate the performance of these two models across various tasks, each showcasing its unique advantages and disadvantages.\n\n# 3.4 Model-agnostic Learning\n\nUp until this point, our focus has been on optimizing the CF-side relational representation e and LLM-side semantic representation s. Any model that can perform representation learning for users/items can undergo the optimization process described earlier. Hence, our approach is model-agnostic and can seamlessly enhance existing collaborative filtering recommenders. Assuming that the optimization objective of the recommender R is denoted as L R, our overall\n\noptimization function L can be formulated as follows:\n\n(18)\n\n\ufffd\nMinimizing the overall optimization function L corresponds to maximizing the mutual information mentioned earlier.\n\n# 4 EVALUATION\n\nThis section presents the experimental evaluation of our RLMRec on multiple datasets to address the following research questions:\n\u2022 RQ1: Does our proposed RLMRec improve upon existing stateof-the-art recommenders across various experimental settings?\n\u2022 RQ2: Do the LLM-enhanced semantic representations contribute to the recommendation performance improvement?\n\u2022 RQ3: Does our proposed framework effectively tackle the issue of noisy data through cross-view semantic alignment?\n\u2022 RQ4: What is the potential of our model as a pre-training framework for enhancing the performance of recommender systems?\n\u2022 RQ5: How does our RLMRec perform w. r. t training efficiency?\n\n# 4.1 Experimental Settings\n\n4.1.1 Datasets. We conduct evaluations of our RLMRec on three public datasets: Amazon-book: This dataset contains user ratings and corresponding reviews for books sold on Amazon. Yelp: This dataset is a user-business dataset that provides extensive textual category information about various businesses. Steam: This dataset consists of textual feedback given by users for electronic games available on the Steam platform. Following the similar settings in [35, 42, 44] for data preprocessing, we filter out interactions with ratings below 3 for both the Amazon-book and Yelp data. No filtering is applied to the Steam dataset due to the absence of rating scores. We then perform k-core filtering and divided each dataset into training, validation, and testing sets using a 3:1:1 ratio. Please refer to Table 5 in Appendix for a summary of the dataset statistics.\n4.1.2 Evaluation Protocols and Metrics.  To ensure comprehensive evaluation and mitigate bias, we adopt the all-rank protocol [11, 36, 37] across all items to accurately assess our recommendations. We use two widely adopted ranking-based metrics: Recall@N and NDCG@N, which measure the model effectiveness.\n4.1.3 Base Models.  We evaluate the effectiveness of our RLMRec by integrating it with state-of-the-art representation-based recommenders based on SSLRec [25].\n\u2022 GCCF [6]: It simplifies graph-based recommender design by re-evaluating the role of non-linear operations in GNNs.\n\u2022 LightGCN [11]: It creates a lightweight recommender by streamlining redundant neural modules in graph message passing.\n\u2022 SGL [37]: It utilizes node/edge dropout as a data augmentator to generate diverse perspectives for contrastive learning.\n\u2022 SimGCL [44]: It enhances recommendation performance by introducing an augmentation-free view generation technique.\n\u2022 DCCF [26]: It captures intent-wise relationships for recommendation purposes using disentangled contrastive learning.\n\u2022 AutoCF [41]: It is a self-supervised masked autoencoder to automate the process of data augmentation for recommendation.\n\n4.1.1 Datasets. We conduct evaluations of our RLMRec on three public datasets: Amazon-book: This dataset contains user ratings and corresponding reviews for books sold on Amazon. Yelp: This dataset is a user-business dataset that provides extensive textual category information about various businesses. Steam: This dataset consists of textual feedback given by users for electronic games available on the Steam platform. Following the similar settings in [35, 42, 44] for data preprocessing, we filter out interactions with ratings below 3 for both the Amazon-book and Yelp data. No filtering is applied to the Steam dataset due to the absence of rating scores. We then perform k-core filtering and divided each dataset into training, validation, and testing sets using a 3:1:1 ratio. Please refer to Table 5 in Appendix for a summary of the dataset statistics.\n4.1.2 Evaluation Protocols and Metrics.  To ensure comprehensive evaluation and mitigate bias, we adopt the all-rank protocol [11, 36, 37] across all items to accurately assess our recommendations. We use two widely adopted ranking-based metrics: Recall@N and NDCG@N, which measure the model effectiveness.\n4.1.3 Base Models.  We evaluate the effectiveness of our RLMRec by integrating it with state-of-the-art representation-based recommenders based on SSLRec [25].\n\u2022 GCCF [6]: It simplifies graph-based recommender design by re-evaluating the role of non-linear operations in GNNs.\n\u2022 LightGCN [11]: It creates a lightweight recommender by streamlining redundant neural modules in graph message passing.\n\u2022 SGL [37]: It utilizes node/edge dropout as a data augmentator to generate diverse perspectives for contrastive learning.\n\u2022 SimGCL [44]: It enhances recommendation performance by introducing an augmentation-free view generation technique.\n\u2022 DCCF [26]: It captures intent-wise relationships for recommendation purposes using disentangled contrastive learning.\n\u2022 AutoCF [41]: It is a self-supervised masked autoencoder to automate the process of data augmentation for recommendation.\n\n4.1.4 Implementation Details.  The dimension of representations (i.e., x and e) is set to 32 for all base models. We determine the hyperparameters for each model through grid search. To generate user and item profiles, we leverage the ChatGPT model (specifically, gpt-3.5-turbo) provided by OpenAI. We use the text-embedding-ada002 [22] to generate semantic representations s. During training, all methods are trained with a fixed batch size of 4096 and a learning rate of 1e-3 using the Adam optimizer. We adopt the early stop technique based on the model\u2019s performance on the validation set.\n\n# .2 Performance Comparison (RQ1)\n\nModel-agnostic Performance Gain. To demonstrate the effectiveness of RLMRec in improving recommendation performance, we integrate it into six state-of-the-art collaborative filtering models. We conduct experiments using 5 random initializations and report the average results in Table 1. The evaluation results reveal several interesting observations, as outlined below:\n\n\u2022 Overall, we consistently observe that integrating RLMRec with the backbone recommenders leads to improved performance compared to the original versions. This provides compelling evidence for the effectiveness of RLMRec. We attribute these improvements to two key factors: i) RLMRec enables accurate user/item profiling empowered by LLMs, enhancing the representation of rich semantic information from user interaction behaviors. ii) our cross-view mutual information maximization facilitates the cooperative enhancement of CF-side relational embeddings and LLM-side semantic representations, effectively filtering out irrelevant noise in the recommendation features.\n\u2022  It is clear that both contrastive and generative modeling approaches generally improve performance. However, it is important to note that the contrastive approach exhibits superior performance when combined with various backbones like GCCF and SimGCL. Conversely, when applied to AutoCF, which involves masked reconstruction, RLMRec-Gen shows more significant improvements. We speculate that the mask operation functions as a form of regularization, leading to better results when used in conjunction with methods that employ a generative approach.\nSuperiority over LLM-enhanced Approach. In addition, we conduct a comparative evaluation of the effectiveness of RLMRec in comparison to KAR [40], a recent LLM-enhanced user behavior modeling approach. KAR aims to generate textual user/item descriptions to enhance the learning of user preferences for the CTR task. To ensure a fair comparison, we utilized the same semantic representation as in our approach and employed two classic methods (LightGCN and SGL) as the backbone models. This could be attributed to the fact that, while KAR incorporates textual information into the learning of user preferences, it treats the semantic representation as input features for the model. As a result, it may not effectively align the textual knowledge with the user behavior representations and could be more susceptible to irrelevant noise from either user behaviors or the LLM knowledge base.\n\n\u2022 Overall, we consistently observe that integrating RLMRec with the backbone recommenders leads to improved performance compared to the original versions. This provides compelling evidence for the effectiveness of RLMRec. We attribute these improvements to two key factors: i) RLMRec enables accurate user/item profiling empowered by LLMs, enhancing the representation of rich semantic information from user interaction behaviors. ii) our cross-view mutual information maximization facilitates the cooperative enhancement of CF-side relational embeddings and LLM-side semantic representations, effectively filtering out irrelevant noise in the recommendation features.\n\u2022  It is clear that both contrastive and generative modeling approaches generally improve performance. However, it is important to note that the contrastive approach exhibits superior performance when combined with various backbones like GCCF and SimGCL. Conversely, when applied to AutoCF, which involves masked reconstruction, RLMRec-Gen shows more significant improvements. We speculate that the mask operation functions as a form of regularization, leading to better results when used in conjunction with methods that employ a generative approach.\n\n# 4.3 Ablation Study (RQ2)\n\nIn this section, we examine the impact of integrating semantic representations on performance. To do this, we shuffle the acquired\n\n<div style=\"text-align: center;\">rformance Imprvement of all backbone methods on different datasets in terms of Recall and cates the Imprvement is statistically significant where the p-value is less than 0. 05.\n</div>\n<div style=\"text-align: center;\">Table 1: Recommendation performance Imprvement of all backbone methods on different datasets in NDCG. The superscript * indicates the Imprvement is statistically significant where the p-value is less th\n</div>\nData\nAmazon-book\nYelp\nSteam\nBackbone\nVariants\nR@5\nR@10\nR@20\nN@5\nN@10\nN@20\nR@5\nR@10\nR@20\nN@5\nN@10\nN@20\nR@5\nR@10\nR@20\nN@5\nN@10\nN@20\nSemantic Embeddings Only\n0.0081\n0.0125\n0.0199\n0.0072\n0.0088\n0.0112\n0.0013\n0.0022\n0.0047\n0.0014\n0.0018\n0.0026\n0.0033\n0.0062\n0.0120\n0.0031\n0.0043\n0.0064\nGCCF\nBase\n0.0537\n0.0872\n0.1343\n0.0537\n0.0653\n0.0807\n0.0390\n0.0652\n0.1084\n0.0451\n0.0534\n0.0680\n0.0500\n0.0826\n0.1313\n0.0556\n0.0665\n0.0830\nRLMRec-Con\n0.0561*\n0.0899*\n0.1395*\n0.0562*\n0.0679*\n0.0842*\n0.0409*\n0.0685*\n0.1144*\n0.0474*\n0.0562*\n0.0719*\n0.0538*\n0.0883*\n0.1398*\n0.0597*\n0.0713*\n0.0888*\nRLMRec-Gen\n0.0551*\n0.0891*\n0.1372*\n0.0559*\n0.0675*\n0.0832*\n0.0393\n0.0654\n0.1074\n0.0454\n0.0535\n0.0678\n0.0532*\n0.0874*\n0.1385*\n0.0588*\n0.0702*\n0.0875*\nBest Imprv.\n\u21914.28%\n\u21913.10%\n\u21913.87%\n\u21914.66%\n\u21913.98%\n\u21914.34%\n\u21914.87%\n\u21915.06%\n\u21915.54%\n\u21915.10%\n\u21915.24%\n\u21915.74%\n\u21917.60%\n\u21916.90%\n\u21916.47%\n\u21917.37%\n\u21917.22%\n\u21916.99%\nLightGCN\nBase\n0.0570\n0.0915\n0.1411\n0.0574\n0.0694\n0.0856\n0.0421\n0.0706\n0.1157\n0.0491\n0.0580\n0.0733\n0.0518\n0.0852\n0.1348\n0.0575\n0.0687\n0.0855\nRLMRec-Con\n0.0608*\n0.0969*\n0.1483*\n0.0606*\n0.0734*\n0.0903*\n0.0445*\n0.0754*\n0.1230*\n0.0518*\n0.0614*\n0.0776*\n0.0548*\n0.0895*\n0.1421*\n0.0608*\n0.0724*\n0.0902*\nRLMRec-Gen\n0.0596*\n0.0948*\n0.1446*\n0.0605*\n0.0724*\n0.0887*\n0.0435*\n0.0734*\n0.1209*\n0.0505\n0.0600*\n0.0761*\n0.0550*\n0.0907*\n0.1433*\n0.0607*\n0.0729*\n0.0907*\nBest Imprv.\n\u21916.67%\n\u21915.90%\n\u21915.10%\n\u21915.57%\n\u21915.76%\n\u21915.49%\n\u21915.70%\n\u21916.80%\n\u21916.31%\n\u21915.50%\n\u21915.86%\n\u21915.87%\n\u21916.18%\n\u21916.46%\n\u21916.31%\n\u21915.74%\n\u21916.11%\n\u21916.08%\nSGL\nBase\n0.0637\n0.0994\n0.1473\n0.0632\n0.0756\n0.0913\n0.0432\n0.0722\n0.1197\n0.0501\n0.0592\n0.0753\n0.0565\n0.0919\n0.1444\n0.0618\n0.0738\n0.0917\nRLMRec-Con\n0.0655*\n0.1017*\n0.1528*\n0.0652*\n0.0778*\n0.0945*\n0.0452*\n0.0763*\n0.1248*\n0.0530*\n0.0626*\n0.0790*\n0.0589*\n0.0956*\n0.1489*\n0.0645*\n0.0768*\n0.0950*\nRLMRec-Gen\n0.0644\n0.1015\n0.1537*\n0.0648*\n0.0777*\n0.0947*\n0.0467*\n0.0771*\n0.1263*\n0.0537*\n0.0631*\n0.0798*\n0.0574*\n0.0940*\n0.1476*\n0.0629*\n0.0752*\n0.0934*\nBest Imprv.\n\u21912.83%\n\u21912.31%\n\u21914.34%\n\u21913.16%\n\u21912.91%\n\u21913.72%\n\u21918.10%\n\u21916.79%\n\u21915.51%\n\u21917.19%\n\u21916.59%\n\u21915.98%\n\u21915.20%\n\u21914.03%\n\u21913.12%\n\u21914.37%\n\u21914.07%\n\u21913.60%\nSimGCL\nBase\n0.0618\n0.0992\n0.1512\n0.0619\n0.0749\n0.0919\n0.0467\n0.0772\n0.1254\n0.0546\n0.0638\n0.0801\n0.0564\n0.0918\n0.1436\n0.0618\n0.0738\n0.0915\nRLMRec-Con\n0.0633*\n0.1011*\n0.1552*\n0.0633*\n0.0765*\n0.0942*\n0.0470\n0.0784*\n0.1292*\n0.0546\n0.0642\n0.0814*\n0.0582*\n0.0945*\n0.1482*\n0.0638*\n0.0760*\n0.0942*\nRLMRec-Gen\n0.0617\n0.0991\n0.1524*\n0.0622\n0.0752\n0.0925*\n0.0464\n0.0767\n0.1267\n0.0541\n0.0634\n0.0803\n0.0572\n0.0929\n0.1456*\n0.0627*\n0.0747*\n0.0926*\nBest Imprv.\n\u21912.43%\n\u21911.92%\n\u21912.65%\n\u21912.26%\n\u21912.14%\n\u21912.50%\n\u21910.64%\n\u21911.55%\n\u21913.03%\n\u2212\n\u21910.63%\n\u21911.62%\n\u21913.19%\n\u21912.94%\n\u21911.53%\n\u21913.24%\n\u21912.98%\n\u21912.95%\nDCCF\nBase\n0.0662\n0.1019\n0.1517\n0.0658\n0.0780\n0.0943\n0.0468\n0.0778\n0.1249\n0.0543\n0.0640\n0.0800\n0.0561\n0.0915\n0.1437\n0.0618\n0.0736\n0.0914\nRLMRec-Con\n0.0665\n0.1040*\n0.1563*\n0.0668\n0.0798*\n0.0968*\n0.0486*\n0.0813*\n0.1321*\n0.0561*\n0.0663*\n0.0836*\n0.0572*\n0.0929*\n0.1459*\n0.0627*\n0.0747*\n0.0927*\nRLMRec-Gen\n0.0666\n0.1046*\n0.1559*\n0.0670*\n0.0801*\n0.0969*\n0.0475\n0.0785\n0.1281*\n0.0549\n0.0646\n0.0815\n0.0570*\n0.0918\n0.1430\n0.0625\n0.0741\n0.0915\nBest Imprv.\n\u21910.60%\n\u21912.65%\n\u21913.03%\n\u21911.82%\n\u21912.69%\n\u21912.76%\n\u21913.85%\n\u21914.50%\n\u21915.76%\n\u21913.31%\n\u21913.59%\n\u21914.50%\n\u21912.14%\n\u21911.53%\n\u21911.53%\n\u21911.46%\n\u21911.49%\n\u21911.42%\nAutoCF\nBase\n0.0689\n0.1055\n0.1536\n0.0705\n0.0828\n0.0984\n0.0469\n0.0789\n0.1280\n0.0547\n0.0647\n0.0813\n0.0519\n0.0853\n0.1358\n0.0572\n0.0684\n0.0855\nRLMRec-Con\n0.0695\n0.1083*\n0.1586*\n0.0704\n0.0837\n0.1001*\n0.0488*\n0.0814*\n0.1319*\n0.0562*\n0.0663*\n0.0835*\n0.0540*\n0.0876*\n0.1372*\n0.0593*\n0.0704*\n0.0872*\nRLMRec-Gen\n0.0693\n0.1069*\n0.1581*\n0.0701\n0.0830\n0.0996\n0.0493*\n0.0828*\n0.1330*\n0.0572*\n0.0677*\n0.0848*\n0.0539*\n0.0888*\n0.1410*\n0.0593*\n0.0710*\n0.0886*\nBest Imprv.\n\u21910.87%\n\u21912.65%\n\u21913.26%\n\u21930.14%\n\u21911.87%\n\u21911.73%\n\u21915.12%\n\u21914.94%\n\u21913.91%\n\u21914.57%\n\u21914.64%\n\u21914.31%\n\u21914.05%\n\u21914.10%\n\u21913.83%\n\u21913.67%\n\u21913.80%\n\u21913.63%\n<div style=\"text-align: center;\">Table 2: Comparison with LLMs-enhanced Approaches.\n</div>\nData\nAmazon-book\nYelp\nBackb.\nVariants\nR@20\nN@20\nR@20\nN@20\nLight-\nGCN\nBase\n0.1411\n0.0856\n0.1157\n0.0733\nKAR\n0.1416+0.3%\n0.0863+0.8%\n0.1194+3.2%\n0.0756+3.1%\nRLMRec-Con\n0.1483+5.1%\n0.0903+5.5%\n0.1230+6.3%\n0.0776+5.9%\nRLMRec-Gen\n0.1446+2.5%\n0.0887+3.6%\n0.1209+4.5%\n0.0761+3.8%\nSGL\nBase\n0.1473\n0.0913\n0.1197\n0.0753\nKAR\n0.1436\u22122.5%\n0.0875\u22124.2%\n0.1208+0.9%\n0.0761+1.1%\nRLMRec-Con\n0.1528+3.7%\n0.0945+3.5%\n0.1248+4.3%\n0.0790+4.9%\nRLMRec-Gen\n0.1537+4.3%\n0.0947+3.7%\n0.1263+5.5%\n0.0798+6.0%\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6aee/6aee7ebc-4d74-4296-a2d3-d602e491239a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Ablation study on variant text embedding models conducted on the Amazon-book dataset. Shuffling involves reordering user/item embeddings.\n</div>\n# Figure 4: Ablation study on variant text embedding models conducted on the Amazon-book dataset. Shuffling involves reordering user/item embeddings.\n\nsemantic representations, creating a misalignment with collaborative relational representation and LLM\u2019s knowledge. We use the default semantic encoding model, text-embedding-ada-002 [2], and also experiment with advanced models like Contriever [14] and Instructor [29]. We evaluate our approach on four backbone methods (i. e., LightGCN, GCCF, SimGCL, and DCCF). The results are summarized in Figure 4, leading to two key observations. \u2022  After randomly rearranging the semantic representations to disrupt the correlation between collaborative and semantic signals,\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8e7c/8e7cc871-12de-4567-82d2-8129fe761c7e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 5: Comparing performance on different noise ratios in the Amazon-book dataset with LightGCN as the base model.\n</div>\nwe observe a decrease in performance for both RLMRec-Con and RLMRec-Gen on the evaluated backbone models. This indicates that the shuffled representations introduce noise due to the mismatch between semantic and collaborative information. It provides evidence that accurate alignment between the LLM\u2019s semantic knowledge and collaborative relationships among users is crucial for enhancing recommendation performance.\n\u2022 When we utilize variant text embedding models like Contriever and Instructor, our RLMRec still enhances the base performance, similar to the default setting with text-embedding-ada-002. This indicates that our RLMRec can effectively leverage an appropriate text encoder capable of transferring textual semantics into preference representations to improve the performance of the recommender backbone. Moreover, the ability of text embedding models to capture semantic information with higher accuracy can lead to even more significant improvements.\n\n# In-depth Analysis of RLMRec (RQ3 \u2013 RQ5)\n\n4.4.1 Performance w.r.t. Noisy Data (RQ3).  We assess the robustness of RLMRec to data noise by adding non-existent interactions to the original training data. Noise levels range from 5% to 25% relative to the training set size. Using the Amazon dataset, we compare the performance of vanilla LightGCN with LightGCN enhanced by our RLMRec-Con/Gen. Key findings from Fig 5 are:\n\n<div style=\"text-align: center;\">Table 3: Performance comparison with different initialized parameters from various pre-training methods on the Yelp.\n</div>\nMetric\nRecall\nNDCG\nPretrained Params\n@5\n@10\n@20\n@5\n@10\n@20\nNone\n0.0274\n0.0462\n0.0820\n0.0203\n0.0270\n0.0375\nBase\n0.0304\n0.0557\n0.0971\n0.0229\n0.0319\n0.0439\nRLMRec-Con\n0.0359\n0.0613\n0.1034\n0.0261\n0.0352\n0.0475\nRLMRec-Gen\n0.0362\n0.0612\n0.1068\n0.0263\n0.0353\n0.0484\n<div style=\"text-align: center;\">able 4: RLMRec\u2019s efficiency with various recommenders.\n</div>\nTable 4: RLMRec\u2019s efficiency with various recommenders.\nAma-Variants\nGCCF\nLightGCN\nSGL\nSimGCL\nDCCF\nAutoCF\nBase\n0.88s\n1.01s\n2.18s\n2.62s\n2.26s\n2.73s\nRLMRec-Con\n1.95s\n1.94s\n2.58s\n3.02s\n2.49s\n2.96s\nRLMRec-Gen\n1.72s\n1.76s\n2.36s\n2.69s\n2.29s\n2.96s\nYelp-Variants\nGCCF\nLightGCN\nSGL\nSimGCL\nDCCF\nAutoCF\nBase\n1.11s\n1.26s\n2.80s\n3.35s\n3.02s\n3.96s\nRLMRec-Con\n2.39s\n2.57s\n3.27s\n3.95s\n3.42s\n4.41s\nRLMRec-Gen\n2.03s\n2.12s\n3.20s\n3.50s\n3.24s\n4.39s\nSteam-Variants\nGCCF\nLightGCN\nSGL\nSimGCL\nDCCF\nAutoCF\nBase\n2.05s\n2.27s\n5.42s\n6.47s\n9.31s\n8.44s\nRLMRec-Con\n4.32s\n4.67s\n6.77s\n7.88s\n10.18s\n10.06s\nRLMRec-Gen\n3.33s\n3.81s\n6.10s\n6.89s\n9.57s\n9.89s\n\u2022 (i) Both RLMRec-Con and RLMRec-Gen consistently outperform the LightGCN backbone model at all noise levels. This highlights the advantages of incorporating semantic information and leveraging mutual information to filter out irrelevant data, resulting in improved recommendations and robustness over noise.\n\u2022  (ii) RLMRec-Con has shown better resistance to data noise compared to RLMRec-Gen. This is likely due to the inherent noise introduced by the generative method through node masking. In contrast, contrastive methods encounter less noise, leading to superior performance under the same noise ratio.\n\n# Performance in Pre-training Scenarios (RQ4).  We ex\n\n4.4.2 Performance in Pre-training Scenarios (RQ4).  We explore the potential of our semantically involved training mechanism as a pre-training technique for downstream models. Using the Yelp dataset, we utilize data from 2012 to 2017 for pre-training and divide the data from 2018 to 2019 into a training set, a validation set, and a test set (the downstream dataset). Both datasets contain the same users and items. We train vanilla LightGCN and our model on the pre-training dataset. The learned parameters are used to initialize the embeddings for vanilla LightGCN, which is then trained on the downstream dataset. Key findings from Table 3 are: \u2022 Pre-training with parameters yields superior results compared to no pre-training, regardless of whether it was done with the base model or our RLMRec. This suggests that the pre-training dataset contains valuable collaborative information that helps predict user/item preferences and benefits downstream tasks.\n\u2022 Both RLMRec-Con and RLMRec-Gen provide better pre-training benefits compared to pre-training with the base model alone, with RLMRec-Gen achieving the best results. This highlights the advantage of incorporating semantic information and the effectiveness of generative methods in pre-training scenarios, potentially due to the regulatory function of the mask operation, preventing overfitting on the pre-training dataset.\n\n4.4.3 Analysis of Training Efficiency (RQ5). We analyze the time complexity of using RLMRec. The theoretical time complexity\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1909/1909f9f6-3a4c-423a-908e-50a9906836cd.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 6: Case study on capturing global user dependencies.\n</div>\nFigure 6: Case study on capturing global user dependencies.\nof the multi-layer perception (\ud835\udf0e \u2191 and \ud835\udf0e \u2193) for both RLMRec-Con and RLMRec-Gen is O(\ud835\udc41 \u00d7 \ud835\udc51 \ud835\udc60 \u00d7 \ud835\udc51 \ud835\udc52). For RLMRec-Con, the loss computation introduces an additional complexity of \ud835\udc42 (\ud835\udc41 2 \u00d7 \ud835\udc51). For RLMRec-Gen, the time complexity is \ud835\udc42 (\ud835\udc40 \u00d7 \ud835\udc51 + \ud835\udc40 \u00d7 \ud835\udc41 \u00d7 \ud835\udc51), where the masking operation accounts for \ud835\udc40 \u00d7 \ud835\udc51, with \ud835\udc40 representing the number of masked nodes. In Table 4, we present the epoch time of training on a server with an Intel Xeon Silver 4314 CPU and an NVIDIA RTX 3090 GPU. The results show that the time cost of RLMRec-Gen is consistently lower than that of RLMRec-Con. This is primarily because the value of \ud835\udc41 in RLMRec-Con is determined by the batch size, which tends to be larger than the number of masked nodes M in RLMRec-Gen. Additionally, for larger models with improved performance, the additional time complexity is only around 10% to 20% compared to the original time.\n\n# 4.5 Case Study\n\nWe explore the integration of LLM-enhanced semantics to capture global user relationships that are not easily captured through direct message passing. Figure 6 presents a case study where the distance between user \ud835\udc62 1998 and \ud835\udc62 227 exceeds 3 hops. To evaluate the models\u2019 ability to capture their relationship, we examine the similarity of user representations. We compared LightGCN and RLMRec-Con, both using the same backbone. Two metrics were introduced: a relevance score for user \ud835\udc62 1998 and the ranking of its long-distance neighbors (> 3 hops) based on the score. By incorporating semantic information derived from LLMs, such as shared interests between \ud835\udc62 1998 and \ud835\udc62 227 (e. g., friendly service), we observed an increase in both the relevance score and ranking. This suggests that the learned representations from RLMRec capture global collaborative relationships beyond ID-based recommendation techniques.\n\n# 5 CONCLUSION\n\nThis paper presents RLMRec, a model-agnostic framework that leverages Large Language Models (LLMs) to improve the representation performance of recommender systems. We introduce a collaborative profile generation paradigm and a reasoning-driven system prompt, emphasizing the inclusion of reasoning processes in the generated output. RLMRec utilizes contrastive and generative alignment techniques to align CF-side relational embeddings with LLM-side semantic representations, effectively reducing feature noise. The framework combines the strengths of general recommenders and LLMs, supported by robust theoretical guarantees, and is extensively evaluated on real-world datasets. Our future investigations will focus on advancing LLM-based reasoning results in recommender systems by providing more insightful explanations.\n\n# REFERENCES\n\n[1] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Tallrec: An effective and efficient tuning framework to align large language model with recommendation. arXiv preprint arXiv:2305.00447 (2023).\n[2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. In NeurIPS, Vol. 33. 1877\u20131901.\n[3] Xuheng Cai, Chao Huang, Lianghao Xia, and Xubin Ren. 2023. LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation. In ICLR.\n[4] Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng Jin, and Yong Li. 2021. Sequential recommendation with graph neural networks. In SIGIR. 378\u2013387.\n[5] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. 2023. Bias and debias in recommender system: A survey and future directions. ACM Transactions on Information Systems (TOIS) 41, 3 (2023), 1\u201339.\n[6] Lei Chen, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. 2020. Revisiting graph based collaborative filtering: A linear residual graph convolutional network approach. In AAAI, Vol. 34. 27\u201334.\n[7] Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, and Qing Li. 2023. Recommender systems in the era of large language models (llms). arXiv preprint arXiv:2307.02046 (2023).\n[8] Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei Zhang. 2023. Chat-rec: Towards interactive and explainable llms-augmented recommender system. arXiv preprint arXiv:2303.14524 (2023).\n[9] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5). In RecSys. 299\u2013315.\n[10] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. 2022. Masked autoencoders are scalable vision learners. In CVPR. 16000\u201316009.\n[11] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for recommendation. In SIGIR. 639\u2013648.\n[12] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, and Wayne Xin Zhao. 2023. Large language models are zero-shot rankers for recommender systems. arXiv preprint arXiv:2305.08845 (2023).\n[13] Zhenyu Hou, Xiao Liu, Yuxiao Dong, Chunjie Wang, Jie Tang, et al.  2022. Graphmae: Self-supervised masked graph autoencoders. arXiv preprint arXiv:2205.10803 (2022).\n[14]  Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2021. Unsupervised dense information retrieval with contrastive learning. arXiv preprint arXiv:2112.09118 (2021).\n[15] Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, and Dilip Krishnan. 2020. Supervised contrastive learning. NeurIPS (2020).\n[16] Yehuda Koren, Steffen Rendle, and Robert Bell. 2021. Advances in collaborative filtering. Recommender systems handbook (2021), 91\u2013142.\n[17] Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and Julian McAuley. 2023. Text Is All You Need: Learning Language Representations for Sequential Recommendation. arXiv preprint arXiv:2305.13731 (2023).\n[18] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, et al. 2023. How Can Recommender Systems Benefit from Large Language Models: A Survey. arXiv preprint arXiv:2306.05817 (2023).\n[19] Zihan Lin, Changxin Tian, Yupeng Hou, and Wayne Xin Zhao. 2022. Improving graph collaborative filtering with neighborhood-enriched contrastive learning. In WWW. 2320\u20132329.\n[20] Junling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan Zhang. 2023. Is chatgpt a good recommender? a preliminary study. arXiv preprint arXiv:2304.10149 (2023).\n[21] Peng Liu, Lemei Zhang, and Jon Atle Gulla. 2023. Pre-train, prompt and recommendation: A comprehensive survey of language modelling paradigm adaptations in recommender systems. arXiv preprint arXiv:2302.03735 (2023).\n[22] Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas Tezak, Jong Wook Kim, Chris Hallacy, et al. 2022. Text and code embeddings by contrastive pre-training. arXiv preprint arXiv:2201.10005 (2022).\n\n[23] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748 (2018).\n[24] OpenAI. 2023. GPT-4 Technical Report. arXiv preprint arXiv:2303.08774 (2023). [25] Xubin Ren, Lianghao Xia, Yuhao Yang, Wei Wei, Tianle Wang, Xuheng Cai, and Chao Huang. 2023. SSLRec: A Self-Supervised Learning Framework for Recommendation. arXiv preprint arXiv:2308.05697 (2023).\n[26]  Xubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, and Chao Huang. 2023. Disentangled Contrastive Collaborative Filtering. In SIGIR. 1137\u20131146.\n[27] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv preprint arXiv:1205.2618 (2012).\n[28]  Hiroaki Sasaki and Takashi Takenouchi. 2022. Representation learning for maximization of MI, nonlinear ICA and nonlinear subspaces with robust density ratio estimation. JMLR (2022).\n[29] Hongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen-tau Yih, Noah A. Smith, Luke Zettlemoyer, and Tao Yu. 2023. One Embedder, Any Task: Instruction-Finetuned Text Embeddings. In Findings of the ACL. 1102\u2013 1121.\n[30] Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey of collaborative filtering techniques. Advances in artificial intelligence 2009 (2009).\n[31] Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin, and Zhaochun Ren. 2023. Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent. arXiv preprint arXiv:2304.09542 (2023).\n[32] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023).\n[33] Wenjie Wang, Fuli Feng, Xiangnan He, Liqiang Nie, and Tat-Seng Chua. 2021. Denoising implicit feedback for recommendation. In WSDM. 373\u2013381.\n[34] Wenjie Wang, Fuli Feng, Xiangnan He, Xiang Wang, and Tat-Seng Chua. 2021. Deconfounded recommendation for alleviating bias amplification. In KDD. 1717\u2013 1725.\n[35] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. In SIGIR. 165\u2013174.\n[36] Yifan Wang, Suyao Tang, Yuntong Lei, Weiping Song, Sheng Wang, and Ming Zhang. 2020. Disenhan: Disentangled heterogeneous graph attention network for recommendation. In CIKM. 1605\u20131614.\n[37] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and Xing Xie. 2021. Self-supervised graph learning for recommendation. In SIGIR. 726\u2013735.\n[38] Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, et al. 2023. A Survey on Large Language Models for Recommendation. arXiv preprint arXiv:2305.19860 (2023).\n[39] Shiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, and Bin Cui. 2022. Graph neural networks in recommender systems: a survey. ACM Computing Surveys (CSUR) 55, 5 (2022), 1\u201337.\n[40] Yunjia Xi, Weiwen Liu, Jianghao Lin, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Rui Zhang, and Yong Yu. 2023. Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models. arXiv preprint arXiv:2306.10933 (2023).\n[41] Lianghao Xia, Chao Huang, Chunzhen Huang, Kangyi Lin, Tao Yu, and Ben Kao. 2023. Automated Self-Supervised Learning for Recommendation. In WWW.\n[42] Lianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, and Jimmy Huang. 2022. Hypergraph contrastive collaborative filtering. In SIGIR. 70\u201379.\n[43] Yuhao Yang, Chao Huang, Lianghao Xia, Chunzhen Huang, Da Luo, and Kangyi Lin. 2023. Debiased Contrastive Learning for Sequential Recommendation. In WWW. 1063\u20131073.\n[44] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung Nguyen. 2022. Are graph augmentations necessary? simple graph contrastive learning for recommendation. In SIGIR. 1294\u20131303.\n[45] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Jundong Li, and Zi Huang. 2023. Self-supervised learning for recommender systems: A survey. TKDE (2023).\n[46] Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023. Where to go next for recommender systems? id-vs. modality-based recommender models revisited. In SIGIR. 2639\u20132649.\n[47] Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Recommendation as instruction following: A large language model empowered recommendation approach. arXiv preprint arXiv:2305.07001 (2023).\n\n<div style=\"text-align: center;\">Table 5: Statistics of the experimental datasets\n</div>\nTable 5: Statistics of the experimental datasets.\nDataset\n#Users\n#Items\n#Interactions\nDensity\nAmazon-book\n11,000\n9,332\n120,464\n1.2\ud835\udc52\u22123\nYelp\n11,091\n11,010\n166,620\n1.4\ud835\udc52\u22123\nSteam\n23,310\n5,237\n316,190\n2.6\ud835\udc52\u22123\nYelp\n11,091\n11,010\n166,620\n1.4\ud835\udc52\u2212\nSteam\n23,310\n5,237\n316,190\n2.6\ud835\udc52\u22123\nAlgorithm 1: Training Procedure in RLMRec-Con\ninput :Base model R, implicit feedback X, semantic\nrepresentation s for each user & item and learning\nrate \ud835\udf02\nResult: Trained model parameters \u0398\n1 repeat\n2\nuniformly sample batch data B = {(\ud835\udc62, \ud835\udc63\ud835\udc5d\ud835\udc5c\ud835\udc60, \ud835\udc63\ud835\udc5b\ud835\udc52\ud835\udc54)} \u2208X;\n3\ninference collaborative-side representation e\ud835\udc62/\ud835\udc63with R;\n4\ncalculate model optimization objective LR based on B;\n5\ncalculate \ud835\udc3f\ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5cw.r.t. Eq (16 & 18) for all \ud835\udc62/\ud835\udc63in B;\n6\nL = LR + L\ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5c;\n7\n\u0398 \u2190\u0398 \u2212\ud835\udf02\u2207\u0398L;\n8 until convergence;\nAlgorithm 2: Training Procedure in RLMRec-Gen\ninput :Base model R, implicit feedback X, semantic\nrepresentation s for each user & item, learning rate\n\ud835\udf02and masking ratio \ud835\udefc\nResult: Trained model parameters \u0398\n repeat\nAlgorithm 2: Training Procedure in RLMRec-Gen\ninput :Base model R, implicit feedback X, semantic\nrepresentation s for each user & item, learning rate\n\ud835\udf02and masking ratio \ud835\udefc\nResult: Trained model parameters \u0398\n1 repeat\n2\nuniformly sample batch data B = {(\ud835\udc62, \ud835\udc63\ud835\udc5d\ud835\udc5c\ud835\udc60, \ud835\udc63\ud835\udc5b\ud835\udc52\ud835\udc54)} \u2208X;\n3\nrandomly sample a subset of users & items with ratio \ud835\udefc;\n4\nreplace initial embeddings of masked \ud835\udc62/\ud835\udc63with [\ud835\udc40\ud835\udc34\ud835\udc46\ud835\udc3e];\n5\ninference collaborative-side representation e\ud835\udc62/\ud835\udc63with R;\n6\ncalculate model optimization objective LR based on B;\n7\ncalculate \ud835\udc3f\ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5cw.r.t. Eq (17 & 18) for masked \ud835\udc62/\ud835\udc63in B;\n8\nL = LR + L\ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5c;\n9\n\u0398 \u2190\u0398 \u2212\ud835\udf02\u2207\u0398L;\n10 until convergence;\nrepeat\n2 uniformly sample batch data B = {(\ud835\udc62, \ud835\udc63 \ud835\udc5d\ud835\udc5c\ud835\udc60, \ud835\udc63 \ud835\udc5b\ud835\udc52\ud835\udc54)} \u2208X;\n3 randomly sample a subset of users & items with ratio \ud835\udefc;\n4 replace initial embeddings of masked \ud835\udc62 / \ud835\udc63 with [\ud835\udc40\ud835\udc34\ud835\udc46\ud835\udc3e];\n5 inference collaborative-side representation e \ud835\udc62 / \ud835\udc63 with R;\n6 calculate model optimization objective L R based on B;\n7 calculate \ud835\udc3f \ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5c w.r.t. Eq (17 & 18) for masked \ud835\udc62 / \ud835\udc63 in B;\n8 L = L R + L \ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5c;\n9 \u0398 \u2190 \u0398 \u2212 \ud835\udf02 \u2207 \u0398 L;\n10 until convergence;\n\n# A SUPPLEMENTARY MATERIAL\n\nIn the supplementary materials, we provide the training procedure of our proposed framework, RLMRec, through pseudocode. We also offer detailed insights into the design of prompts, accompanied by examples, to visualize the profile generation process within our item-to-user generation paradigm. Finally, we present experiment details for the reranking task mentioned in Section 1, where we analyze specific examples within the task.\n\n# A.1 Pseudocode of RLMRec\n\nThis section introduces the pseudocode for our model-agnostic RLMRec framework implementations, namely RLMRec-Con and RLMRec-Gen. The focus is on the training procedure of these implementations. Prior to training, user and item profiles are preprocessed, and their semantic embeddings s are generated using text models. Algorithm 1 presents the training procedure for RLMRecCon, while Algorithm 2 outlines the process for RLMRec-Gen.\n\nThe difference between RLMRec-Con and RLMRec-Gen is that RLMRec-Gen randomly masks a portion of users/items before the base model encodes the CF-side relational representations. The objective function L \ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5c for mutual information maximization is then computed based on the representations of the masked users and items. In contrast, RLMRec-Con models the density ratio in a contrastive manner and calculates the L \ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5c objective for all users and items in the batch data, including both positives and negatives.\n\n# A.2 Details of Profile Generation\n\nIn this section, we offer a comprehensive explanation of the generation process for both user and item profiles. Real examples from the Amazon-book dataset are used to illustrate this process, as depicted in Figure 7 and Figure 8. We adopt a general interaction paradigm with large language models (LLMs), where the system prompt serves as an instruction to guide the profile generation task. While the Amazon-book dataset is specifically showcased, the overall generation process remains consistent for the Yelp and Steam datasets as well, with minor differences in the instructions provided to represent the data information.\n\ncases an example of item profile generation specifically for the Amazon-book dataset. The instruction prompt provided to the language models for all items remains consistent, directing them to summarize the types of books that would appeal to users, thus offering valuable information for recommendation purposes. The input information consists of the book\u2019s title and original description from the dataset. To maintain consistency and facilitate parsing, we enforce the requirement that the output of the language models adhere to the JSON format. Furthermore, it is essential for the language models to provide their reasoning behind the generated profile, ensuring high-quality summarization while preventing any potential hallucinations. The generated results demonstrate that the language model, in this case ChatGPT, accurately captures from the book description that the book is likely to attract readers interested in mental health and women\u2019s experiences.\n\n# A.2.2 Example of the Generated User Pro\n\n# 2.2 Example of the Generated User Profile. Figure 8 ill\n\ntrates the process of generating user profiles using the Amazonbook dataset as an example. Our approach adopts an item-to-user generation paradigm, which allows us to leverage the previously generated profiles that describe the interaction preferences of items. To accomplish this, our prompt methodology incorporates not only users\u2019 feedback information on items but also the profiles of the items themselves. By utilizing both sources of information comprehensively, large language models are empowered to capture users\u2019 true preferences with enhanced accuracy. In the presented example, leveraging both the book descriptions and users\u2019 review text, the language models distill the user\u2019s preference for young adult fiction that seamlessly combines paranormal or supernatural elements.\n\n# Analysis on the Reranking Task with LLMs\n\nIn this section, we explore real-world scenarios where LLMs are employed for reranking tasks on the Amazon-book dataset, as introduced in Section 1. Firstly, as depicted in Figure 9, we carefully design the instruction and input prompt. We utilize the item ID as\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/73b7/73b738d4-88b5-4305-b85e-056091ef0eaf.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/186a/186a408e-cebd-4871-b68d-71695dca8915.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3e80/3e808efb-b38c-4c01-8bb1-ada4e176b6dc.png\" style=\"width: 50%;\"></div>\nFigure 8: Case study on user profile generation in Amazon-book data.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fc0e/fc0e9f13-f827-4448-a996-82bdec13e1ae.png\" style=\"width: 50%;\"></div>\nYou serve as an assistant that helps me to recommend 20 items (each item is a book) to a specific user from a candidate item set with the size of 40. First, I will provide you with a list of items that he or she has already interacted with. Then, I will provide you with a candidate item set which includes the index and title of each item. Your goal is to create a list of recommended items from the candidate item set for the user, and the more recommended items are in the front of the list Here are the instructions: 1. Each item in the candidate set will be described in JSON format, with the following attributes: {\n\"index\": \"a unique integer to identify the item\",\"title\": \"the title of the item (book)\"\n\n1. When recommending, please explore his/her preferences through the items that the user has interacted with to determine the recommendation list. 2. Recommended items can only be selected from the CANDIDATE ITEMS. 3. Please provide your decision in JSON format, following this structure:\n\n4. Make sure there are 20 recommended items in the list and do not use the title to represent items in the list 5. Do not provided any other text outside the JSON string.\n\n{  \"items\": [585, 597, 330, 1098, 293, 344, 327, 340, 752, 1141, 1071, 1022, 329, 319, 2911, 1057, 1253, 721, 974, 1127],\n\"reasoning\": \"Based on the user's previous interactions, it seems that they enjoy books with dark and intense themes, so I have selected books like 'Raw', 'Captive in the Dark', and 'Seduced in the Dark' that fit this genre. I have also included some books with a similar writing style like 'Thoughtless' and 'Slammed'. Additionally, I have chosen books from popular series such as 'Lux' and 'Divergent', which the user may be interested in based on their previous interactions.\"} Rerank Results\nFigure 9: Case study on LLMs-based reranking. The candidate items are retrieved by LightGCN.\n\na key to index the items, along with their textual information such as the book title. This approach aims to enhance the accuracy of the generated outputs by avoiding direct generation of item titles that may not precisely match the original titles. In the prompt, we include the historical purchased books of the user as a reference, along with a list of 40 candidate items retrieved by LightGCN. The goal is for the LLM to select the top 20 items for recommendation. However, upon examining the output results, it becomes apparent that the language models have recommended some non-existent items (highlighted in green) within the provided list. Despite utilizing item IDs for indexing, this occurrence is common in many reranking examples, and the presence of non-existent items can undoubtedly impact the overall reranking performance. Additionally, the number of correctly recommended items from the language models is lower than the retrieved items (highlighted\n\nInstruction\n\nin red). This discrepancy is primarily attributed to the limited textual information available for the language models to effectively exploit users\u2019 preferences. Moreover, the retrieved item list, learned by the state-of-the-art method LightGCN, benefits from collaborative information beyond just the textual content. This collaborative information contributes to the improved performance of the retrieval process compared to the language models\u2019 recommendations. Incorporating other raw textual information from the datasets to improve performance may have some anticipated limitations: i) The limitation of input token numbers may constrain the size of candidate items, as many raw descriptions can be excessively lengthy. ii) Raw descriptions may be missing or contain substantial noise in certain datasets. The absence of descriptions or the presence of noisy information can hinder the language models\u2019 comprehension of users\u2019 preferences. iii) Including a larger amount of input data, such as additional raw textual information, can increase the computational cost, which impacts the system\u2019s scalability.\n\n",
    "paper_type": "method",
    "attri": {
        "background": "Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems.",
        "problem": {
            "definition": "The paper addresses the limitations of existing recommender systems that rely heavily on ID-based data and ignore rich textual information, leading to less effective user preference learning.",
            "key obstacle": "The main challenge is the reliance on ID-based information, which can overlook valuable textual data and introduce noise from implicit feedback, leading to poor representation quality."
        },
        "idea": {
            "intuition": "The idea is inspired by the potential of large language models to enhance recommendation systems by integrating semantic understanding with traditional collaborative filtering methods.",
            "opinion": "The proposed framework, RLMRec, aims to enhance existing recommenders by integrating representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences.",
            "innovation": "RLMRec differs from existing methods by incorporating auxiliary textual signals and aligning the semantic space of LLMs with collaborative relational signals through cross-view alignment."
        },
        "method": {
            "method name": "Representation Learning with Large Language Models for Recommendation",
            "method abbreviation": "RLMRec",
            "method definition": "RLMRec is a model-agnostic framework that enhances recommender systems by leveraging large language models for improved representation learning.",
            "method description": "The core of RLMRec is to integrate representation learning with LLMs, enhancing the quality of learned representations by incorporating textual signals.",
            "method steps": [
                "Generate user and item profiles using LLMs.",
                "Align the semantic space of LLMs with collaborative relational signals.",
                "Maximize mutual information to improve representation quality."
            ],
            "principle": "The method is effective because it combines the strengths of collaborative filtering with the semantic understanding of LLMs, allowing for better representation of user preferences."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted on three public datasets: Amazon-book, Yelp, and Steam, with various state-of-the-art recommender models as baselines.",
            "evaluation method": "Performance was measured using ranking-based metrics such as Recall@N and NDCG@N across different datasets and models."
        },
        "conclusion": "RLMRec successfully enhances the representation performance of recommender systems by integrating LLMs and aligning their semantic representations with collaborative filtering techniques, demonstrating robustness against noise and improvements in recommendation quality.",
        "discussion": {
            "advantage": "RLMRec improves recommendation performance by leveraging LLMs for semantic understanding, enabling accurate user/item profiling and filtering out irrelevant noise.",
            "limitation": "The method may encounter challenges related to scalability and computational resources, particularly when dealing with large datasets and complex models.",
            "future work": "Future research will focus on advancing LLM-based reasoning capabilities in recommender systems, aiming for more insightful explanations and improved performance."
        },
        "other info": {
            "implementation codes": "Available at https://github.com/HKUDS/RLMRec",
            "datasets": {
                "Amazon-book": {
                    "users": 11000,
                    "items": 9332,
                    "interactions": 120464,
                    "density": "1.2e-3"
                },
                "Yelp": {
                    "users": 11091,
                    "items": 11010,
                    "interactions": 166620,
                    "density": "1.4e-3"
                },
                "Steam": {
                    "users": 23310,
                    "items": 5237,
                    "interactions": 316190,
                    "density": "2.6e-3"
                }
            },
            "key findings": "RLMRec consistently outperformed baseline models across various datasets and showed significant improvements in handling noisy data."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "Recommendation algorithms have advanced significantly with deep learning and graph neural networks, capturing complex user-item relationships."
        },
        {
            "section number": "1.2",
            "key information": "The integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, enhancing recommendation systems."
        },
        {
            "section number": "2.1",
            "key information": "The paper defines the limitations of existing recommender systems that rely heavily on ID-based data and ignore rich textual information."
        },
        {
            "section number": "2.3",
            "key information": "RLMRec is a model-agnostic framework that enhances recommender systems by leveraging large language models for improved representation learning."
        },
        {
            "section number": "3.2",
            "key information": "The proposed framework, RLMRec, integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences."
        },
        {
            "section number": "4.1",
            "key information": "RLMRec combines the strengths of collaborative filtering with the semantic understanding of LLMs, allowing for better representation of user preferences."
        },
        {
            "section number": "6.1",
            "key information": "RLMRec enhances recommendation performance by leveraging LLMs for semantic understanding, enabling accurate user/item profiling."
        },
        {
            "section number": "10.1",
            "key information": "Challenges include the reliance on ID-based information, which can overlook valuable textual data and introduce noise from implicit feedback."
        },
        {
            "section number": "10.2",
            "key information": "Future research will focus on advancing LLM-based reasoning capabilities in recommender systems for more insightful explanations and improved performance."
        }
    ],
    "similarity_score": 0.7791910923358725,
    "image": [
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ebf0/ebf08b12-7a35-4df5-896e-6b11a4004ebb.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2d89/2d89973f-e284-45e1-9573-5d055c7b68b5.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/986d/986d55fa-f6b6-42f7-b042-67cd0660acfc.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/06c9/06c91f13-e46b-466d-8c5d-fba18bb1f566.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6aee/6aee7ebc-4d74-4296-a2d3-d602e491239a.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8e7c/8e7cc871-12de-4567-82d2-8129fe761c7e.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1909/1909f9f6-3a4c-423a-908e-50a9906836cd.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/73b7/73b738d4-88b5-4305-b85e-056091ef0eaf.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/186a/186a408e-cebd-4871-b68d-71695dca8915.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3e80/3e808efb-b38c-4c01-8bb1-ada4e176b6dc.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fc0e/fc0e9f13-f827-4448-a996-82bdec13e1ae.png"
    ],
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Representation learning with large language models for recommendation.json"
}