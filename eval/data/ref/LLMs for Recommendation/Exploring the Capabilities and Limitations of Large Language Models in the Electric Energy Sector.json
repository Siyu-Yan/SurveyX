{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2403.09125",
    "title": "Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector",
    "abstract": "Large Language Models (LLMs) as ChatBots have drawn remarkable attention thanks to their versatile capability in natural language processing as well as in a wide range of tasks. While there has been great enthusiasm towards adopting such foundational model-based artificial intelligence tools in all sectors possible, the capabilities and limitations of such LLMs in improving the operation of the electric energy sector need to be explored, and this article identifies fruitful directions in this regard. Key future research directions include data collection systems for fine-tuning LLMs, embedding power system-specific tools in the LLMs, and retrieval augmented generation (RAG)based knowledge pool to improve the quality of LLM responses and LLMs in safety-critical use cases.",
    "bib_name": "majumder2024exploringcapabilitieslimitationslarge",
    "md_text": "EXPLORING THE CAPABILITIES AND LIMITATIONS OF LARGE LANGUAGE MODELS IN THE ELECTRIC ENERGY SECTOR \u2217\nSubir Majumder\u2020, Lin Dong\u2217, Fatemeh Doudi\u2217, Yuting Cai\u2217,\nChao Tian, Dileep Kalathil\nDepartment of Electrical and Computer Engineering\nTexas A&M University\nCollege Station, Texas, USA\nKevin Ding\nCenterPoint Energy\nHouston, Texas, USA\nAnupam A. Thatte\u2021\nMidcontinent Independent System Operator (MISO)\nCarmel, Indiana, USA\nNa Li\nSchool of Engineering and Applied Sciences\nHarvard University\nCambridge, Massachusetts, USA\n# Subir Majumder\u2020, Lin Dong\u2217, Fatemeh Doudi\u2217, Yuting Cai Chao Tian, Dileep Kalathil\nY]  20 Jun 2024\nAnupam A. Thatte\u2021 Midcontinent Independent System Operator (MISO) Carmel, Indiana, USA\n# Le Xie (Corresponding author) Department of Electrical and Computer Engineering Texas A&M University, and\nLe Xie (Corresponding author) Department of Electrical and Computer Engineering Texas A&M University, and Texas A&M Energy Institute College Station, Texas, USA le.xie@tamu.edu\narXiv:2403.09125v5\n# ABSTRACT\nLarge Language Models (LLMs) as ChatBots have drawn remarkable attention thanks to their versatile capability in natural language processing as well as in a wide range of tasks. While there has been great enthusiasm towards adopting such foundational model-based artificial intelligence tools in all sectors possible, the capabilities and limitations of such LLMs in improving the operation of the electric energy sector need to be explored, and this article identifies fruitful directions in this regard. Key future research directions include data collection systems for fine-tuning LLMs, embedding power system-specific tools in the LLMs, and retrieval augmented generation (RAG)based knowledge pool to improve the quality of LLM responses and LLMs in safety-critical use cases.\narge Language Models \u00b7 Electric Energy Sector \u00b7 Capabilities \u00b7 Limitation\n# 1 Introduction\nThe transformative impact of self-attention and multi-head attention mechanisms, integral components of the transformer architecture1, has reshaped the landscape of AI research. Particularly noteworthy is their role in developing models to comprehend sequential data, notably text. These breakthroughs have been a cornerstone of large language models (LLMs) known for their capability to perform a wide range of tasks without being explicitly programmed for them. This architecture\u2019s scalability and efficiency in capturing long-range dependencies led to the development of Generative Pre-trained Transformer (GPT) models2. Due to their versatility, these LLMs are swiftly finding applications across many sectors, with researchers actively exploring their potential within the electric energy sector. While research has\n\u2217Preprint to the paper accepted by Joule: https://doi.org/10.1016/j.joule.2024.05.009 \u2020Equal contribution as joint first co-authors \u2021The views expressed in this paper are solely those of the author and do not necessarily represent those of MISO\nshowcased their potential in tasks such as generating customized code3, utilizing retrieval augmented generation (RAG) capabilities in answering technical questions3, power network data synthesis4, using deep reinforcement learning for in-context optimal power-flow solution5, concerns regarding data ownership6, privacy7, and safety guarantees8, have also been raised. The electric energy sector is the lifeblood of modern society. Power consumption not only serves as a barometer of societal behavior and prosperity but also underpins economic activities within the industrial and commercial sectors. Driven by the urgent imperative of global climate change and increasing electricity demand, the power industry is encountering an unprecedented volume of sensor integration, growing adoption of variable renewable resources such as solar and wind, and integration of newer technologies like hydrogen, electric vehicles, and large computing loads. Customer expectations regarding the quality and reliability of electricity supply are also evolving. This expansion has led to an exponential increase in the volume of equipment/devices and associated data, posing significant challenges for power system operators and utilities who must manage these complexities without a corresponding increase in the workforce. The rapid accumulation of new knowledge and instantaneous data exceeds the human capacity to process it unaided. These developments are propelling the power system into a phase of transition, necessitating adaptations to accommodate these new technologies and mitigate their associated challenges. In this landscape, LLMs offer promising value to the electric energy sector, thanks to their ability to interpret human prompts and alleviate sensory overload, especially providing near real-time guidance in managing extreme weather events and risks associated with diverse sources of uncertainty. Therefore, it is important to demystify the capabilities and limitations of LLMs in performing realistic power-engineering tasks by themselves or delegate them via add-on capabilities, if needed. In this vein, as shown in Figure 1, through rigorous testing and analysis utilizing a productiongrade LLM, specifically the GPT models, our study embarks on a comprehensive exploration of the capabilities of LLMs to scrutinize their readiness as an interface between human and electric energy systems. Further, we investigate how to better facilitate the integration of LLMs in the new era, considering their potential limitations. Finally, we discuss future research opportunities in the electric energy sector.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f9ed/f9eda2f4-de2a-4052-9469-1afaa2691061.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">apabilities and Limitations of Applying LLMs in the Electric Energy Sec</div>\n# 2 Capabilities of LLMs to Fill in the Gap\nIn this section, we explore the capabilities of LLMs in tackling power engineering challenges as exemplified in Figure 2 based on experiments provided in the Supplemental Information (contain Sections SI.1-8). Our research delves into the accuracy of LLMs in performing various electrical engineering domain-specific tasks, including power flow analysis,\noptimal power flow analysis, forecasting, image and pattern recognition, and answering questions utilizing a custom domain-specific knowledge base, among others. While our focus primarily revolves around the GPT model series, most of our observations are relevant to other mainstream models. In this section, we expand on the four key strengths of LLMs, illustrated in Figure 1, and elaborate on how these four strengths translate into key LLM capabilities for performing power engineering tasks.\n# 2.1 Language Models and In-weight Learning\nA foundational capability of LLMs is to produce semantically meaningful text outputs (responses) from text inputs (prompts). Though it is not clear what the pre-training datasets are, based on our investigation, current language models have the capability to provide schematically logical responses for power engineering domain-specific questions (see Sections SI.5). A major part of this capability may be a natural consequence of the large number of model parameters where certain information has been memorized. Then, the efficient processing in the transformer architecture allows efficient retrievals of such memorized information. This memorization and retrieval capability is sometimes referred to as in-weight learning. Foundational LLM models usually allow users to refine the model on a newer corpus of information through the \u2018fine-tuning\u2019 process9, which we have harnessed for load forecasting tasks as shown in Figure 2(B) (see Section SI.6). This process allows the model parameters within the LLM to be changed. LLMs have profound implications for power systems, where LLMs can improve operational efficiency and support decision-making processes within the power sector by facilitating interaction between power system data, software, tools, and cross-domain datasets. Leveraging their inference capabilities, LLMs can enable real-time diagnostics (Section SI.1), on-demand analysis, and augment traditional control center operations.\n# 2.2 Prompt Engineering and In-context Learning\nThe efficacy of LLMs in generating responses is significantly influenced by the structure and style of queries or prompts10, a practice commonly referred to as prompt engineering. Prompt engineering can help power engineers obtain more meaningful responses on difficult problem-solving tasks, while na\u00efve prompts usually fail to induce desirable responses (Sections SI.2 and SI.4). Some of the most well-known techniques in this direction are chain-of-thoughts prompts and retrieval augmented generations (RAGs). As illustrated in Figure 2(D), LLMs can sift through documents with large amounts of text information, which can be extremely useful in fast-paced work environments such as those in power system operations (Section SI.5.2). One of the most surprising capabilities of LLMs observed in prompt engineering research is the emergent in-context learning capability, based on a few example prompts, as demonstrated in Figure 2(A) (see Section SI.3). More precisely, LLMs appear to derive patterns or learn rules from the prompts without the underlying model going through any additional changes and are then able to apply the learned patterns and rules from the prompts to produce correct responses (also demonstrated in one of the load forecasting examples in Section SI.6). Even if the LLM\u2019s performance may not be the best in class, the ability to learn based on limited data can be extremely useful for power engineers, given that power system datasets are usually protected. LLM-generated responses are typically variable, and one can reduce the variability of LLM-generated responses by harnessing custom domain-specific knowledge as a part of prompt engineering.\nThe efficacy of LLMs in generating responses is significantly influenced by the structure and style of queries or prompts10, a practice commonly referred to as prompt engineering. Prompt engineering can help power engineers obtain more meaningful responses on difficult problem-solving tasks, while na\u00efve prompts usually fail to induce desirable responses (Sections SI.2 and SI.4). Some of the most well-known techniques in this direction are chain-of-thoughts prompts and retrieval augmented generations (RAGs). As illustrated in Figure 2(D), LLMs can sift through documents with large amounts of text information, which can be extremely useful in fast-paced work environments such as those in power system operations (Section SI.5.2).\nOne of the most surprising capabilities of LLMs observed in prompt engineering research is the emergent in-context learning capability, based on a few example prompts, as demonstrated in Figure 2(A) (see Section SI.3). More precisely, LLMs appear to derive patterns or learn rules from the prompts without the underlying model going through any additional changes and are then able to apply the learned patterns and rules from the prompts to produce correct responses (also demonstrated in one of the load forecasting examples in Section SI.6). Even if the LLM\u2019s performance may not be the best in class, the ability to learn based on limited data can be extremely useful for power engineers, given that power system datasets are usually protected. LLM-generated responses are typically variable, and one can reduce the variability of LLM-generated responses by harnessing custom domain-specific knowledge as a part of prompt engineering.\n# 2.3 Enhanced Capability via Tool Embedding\nLLMs, by themselves, are complex language processing units; however, their capability could be enhanced by including further processing units. Tool embedding is one of such enhanced capabilities, where LLMs are trained to delegate some of the tasks. For example, we have noted that GPT-4 prioritizes writing text files, executing codes utilizing the embedded tools, and inferring the generated results (as shown in the examples of Section SI.1, SI.2). As depicted in Figure 2(C), LLMs utilizes its tool embedding capability to extract regions with wildfire and superimpose on top of transmission line infrastructure map to identify the transmission lines at risk (Section SI.2). This tool embedding capability can be extremely powerful for the power system engineers, where many of the applications require solving non-linear non-convex problems. Power system engineers utilize physics-based modeling and simulation tools, such as PSS/E, PSCAD, PowerWorld, and CyME, which could be called upon by LLMs to solve complex problems. This tool embedding capability could be facilitated by API-calling11. Tool embedding also facilitates on-demand remote processing of typical spatiotemporal time series power system data (e.g., SCADA data) (see Section SI.1).\nLLMs, by themselves, are complex language processing units; however, their capability could be enhanced by including further processing units. Tool embedding is one of such enhanced capabilities, where LLMs are trained to delegate some of the tasks. For example, we have noted that GPT-4 prioritizes writing text files, executing codes utilizing the embedded tools, and inferring the generated results (as shown in the examples of Section SI.1, SI.2). As depicted in Figure 2(C), LLMs utilizes its tool embedding capability to extract regions with wildfire and superimpose on top of transmission line infrastructure map to identify the transmission lines at risk (Section SI.2).\nThis tool embedding capability can be extremely powerful for the power system engineers, where many of the applications require solving non-linear non-convex problems. Power system engineers utilize physics-based modeling and simulation tools, such as PSS/E, PSCAD, PowerWorld, and CyME, which could be called upon by LLMs to solve complex problems. This tool embedding capability could be facilitated by API-calling11. Tool embedding also facilitates on-demand remote processing of typical spatiotemporal time series power system data (e.g., SCADA data) (see Section SI.1).\nMany times, power engineers are expected to work with non-text and non-numeric data (see Sections SI.3 and SI.4), such as time-series measurements, images, or videos. Foundational LLMs can be combined with other models to obtain multi-modal processing capabilities, enabling them to contextualize information presented in various non-text formats. Such capabilities are primarily facilitated by semantic embeddings, which are similar to the embeddings commonly used in natural language processing. Consequently, large language models (LLMs) exhibit robust performance for multi-modal data. Notably, state-of-the-art computer science literature are focusing on enhancing the capabilities of LLMs with multi-modal input and output. We anticipate that in the near future, multi-modal capabilities will be a native part of most off-the-shelf LLMs and that the next-generation applications will indeed exploit these capabilities. In our experiments, LLMs demonstrate proficiency in interpreting image data. In this regard, as shown in Figure 2(A), LLMs utilize multi-modal capability in addition to their in-context learning ability to diagnose defects in the insulator images (see Section SI.3).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a457/a4576cf5-b485-4e79-ad4f-928cc94e2288.png\" style=\"width: 50%;\"></div>\nFigure 2: Applications of LLMs in the Electric Energy Sector. This figure illustrates four distinct applications of LLMs in power systems. (A) Highlights the use of LLMs\u2019 multi-modality and appropriate choice of prompts in insulator defect detection from captured images. (B) Illustrates that fine-tuned language models through in-weight learning and further enhanced by prompt engineering techniques can be used for time-series forecasting. (C) Depicts LLMs\u2019 tool-embedding ability alongside prompt engineering can be employed to analyze wildfire patterns for risk assessments. (D) Demonstrates natural language processing strengths of LLMs and the use of RAG to generate precise responses to documents LLMs may not have seen before.\n# imitations of LLMs for Applications in the Electric Energ\n# 3.1 Challenges in Domain-Specific Data Availability and Processing\n1 Challenges in Domain-Specific Data Availability and Processing\nA significant challenge in applying large language models (LLMs) within the power sector is the scarcity of domainspecific data in the pre-training of LLMs. Due to privacy concerns and regulations, pre-training of LLMs can only rely on publicly available and licensed third-party datasets12. Therefore, an open question for the research community is how to construct large power system domain specific training datasets for LLMs overcoming Critical Energy/Electric Infrastructure Information (CEII) per section 215A(d) of the United States Federal Power Act13. Constrained by this reality, smaller curated high-quality (labeled) datasets can be used for fine-tuning; which, for example, can assist the user in performing power flow analysis (Section SI.7), or even to prevent LLMs from generating unsafe responses (Section SI.8). Depending on usage scenarios, these fine-tuning datasets may need to be processed to prevent privacy leakage and converted into a format that is most efficient to fine-tune for downstream tasks. In-context few-shot learning capability of LLMs, including limited high-quality data as part of the prompt can potentially improve the performance, and some researchers are already exploring such possibilities4. Additionally, a significant portion of power system data comes in the form of long-range time series datasets from diverse measuring instruments that may not be in natural language. This may require a customized design of more efficient embedding algorithms. Also, LLMs can only process a limited amount of information during each query, which is also known as context window, and power system signals may exhibit long-range dependence, which may not be captured due to these limitations.\n# 3.2 Lack of Safety Guardrails\nSafety in the power system context includes a broad spectrum, encompassing equipment safety, personnel safety, end-user safety, and safe operation of the electric energy systems. LLMs integrated into the power system must uphold these safety standards. Firstly, the results obtained from LLMs is probabilistic due to the nature of the generative models, and therefore, the correctness of responses may not be fully guaranteed. Secondly, LLMs generally do not provide uncertainty estimates for their outputs. Power system operations must comply with very strict safety performance guidelines, such as voltage magnitude limits. These power system operational requirements do not easily get satisfied by the LLMs. In our experiments, we observed that with subtle changes in prompts, LLMs generated varied responses and codes, which can potentially lead to erroneous results. We also found out that there are different ways LLMs could be tricked into providing responses that are unsafe (see Section SI.8). The lack of customized safety guardrails may also prevent us from performing some of the tasks necessary to do in electric energy systems. For example, during our experiments, we were not able to predict wildfire propagation or conduct auditing based solely on visual inputs. Additionally, since the LLMs are trained based on a large corpus of data, we need to ensure that minority voices are not suppressed14. Domain experts play a major role by providing real-time guidance and flagging problematic content to train LLMs. Therefore, while LLMs could greatly benefit the power industry, they also pose unique risks that are different from traditional software systems. Hence, a governance framework is needed to mitigate their unique risks. As an example, the U.S. National Institute of Standards and Technology\u2019s (NIST) AI Risk Management Framework provides a voluntary guideline built upon the universal principles of responsible AI15. Creating a safe LLM-based system is a crucial area of research, especially in safety-critical infrastructure system such as the power industry.\n# 3.3 Not Adapted to Handle Physical Principles\nEnergy production and consumption is a complex process governed by a set of physical principles such as Maxwell\u2019s equations, machine dynamics as well as human behavior. Modeling human behavior through LLMs, particularly in tasks like price forecasting and demand response policy design, presents formidable challenges, probably because prices are a much more compounded outcome of loads, human decisions, and market rules. Using more data might improve renewable generation prediction, price forecasting (Section SI.6), and understanding of human behavior, which could benefit power grid operation. While efforts have been underway to incorporate multiple specialized attention-seeking transformers16 for decision-making, which could also be utilized for power flow analysis (Section SI.7), the LLMs used in the control process are heavily specialized. Foundational LLMs often lack explainability due to the black-box nature of these models. They can also be problematic in power systems where unexpected conditions can frequently arise. Therefore, LLM explainability will be a crucial component of building systems that are interpretable and transparent17. This also makes us believe that existing physics-driven, complex, specialized tools for power engineers remain indispensable. General purpose LLMs can serve\nFoundational LLMs often lack explainability due to the black-box nature of these models. They can also be problematic in power systems where unexpected conditions can frequently arise. Therefore, LLM explainability will be a crucial component of building systems that are interpretable and transparent17. This also makes us believe that existing physics-driven, complex, specialized tools for power engineers remain indispensable. General purpose LLMs can serve\nas valuable assistants, summarizing and finding implications of decision-making and assisting power engineers through tool embedding without delving into complex processes.\n# 3.4 Potential Exposure to Cybersecurity and Privacy Threats\nWhile integrating large language models (LLMs) into electric energy systems, cybersecurity and privacy emerge as a paramount concern. Even within the local LLM setups, there are potential cyber vulnerabilities. For example, building an LLM using power system-related company-specific data could inadvertently expose organizations to privilege escalation attacks, backdoor exploits, and the extraction of sensitive training data18. Online LLMs used for safety-critical tasks, such as price forecasting (Section SI.6), would be a frequent target of cyber-attacks. Furthermore, specialized prompts could be treated as trade secrets, which malicious actors could expose (Section SI.7). As concerns regarding data privacy loom large, particularly as LLMs become integrated into power systems, establishing a standard protocol becomes imperative to ensure the data is sufficiently anonymized and sanitized to remove personal identification information before utilizing data for training. However, challenges persist in cases where personal or group information is context-dependent7.\n# 4 Future Prospects\nLLMs, such as, GPT models, have shown great promise in interpreting power engineering tasks through natural language-based inputs. Through this study, we tested the capabilities and limitations of LLMs when applied to the electric energy sector. We discussed the effectiveness of LLMs in answering general power system queries, code generation and data analysis. Further, through retrieval augmented generation, LLMs can serve as a documentation knowledge base and help with tasks such as operator training. Finally, the multi-modal capabilities of LLMs can be useful in diagnosing equipment failure and remote monitoring. Effectively, general-purpose LLMs show strong capabilities in detecting the correlation between objects (text, image, data), while they are still lacking in solving problems highly related to physics, which usually involve complex mathematical principles. There are multiple possibilities to expand and enhance the capabilities of LLMs in power system research and applications. The first direction is curated data collection for fine-tuning foundational LLMs. This would require strong power system expertise to recognize the most effective data sources and design collection mechanisms to ensure the availability of high-quality datasets. Uncertainty quantification of the outcome of the LLMs is also an important direction for research in the electric power sector. The second direction is to allow power-system-specific tool embeddings. There are already strong and diverse tools for various power system functionalities, and LLMs can serve as a central point to connect all these tools through high-quality embedding. Na\u00efve embeddings are likely to lose efficiency and may further cause different tools to conflict; therefore, power system expertise may be required to identify the desired behaviors for such tool embedding. A third direction is to build a power system knowledge base for retrieval augmentation. Although there are already generic approaches to generating such knowledge bases, they may not fully take advantage of physical constraints and power system specifics; therefore, this effort may require a deep understanding of power system operation and capabilities. The future of foundational model-based AI tools as a decision support co-pilot in the electric energy sector is bright.\n# 5 Declaration of Interests\nThe authors declare no competing interests.\n# 6 Acknowledgements\nThis work is supported in part by the Texas A&M Engineering Smart Grid Center and Texas A&M Energy Institute\n1. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141. & Polosukhin, I. Attention is all you need Proceedings of the 31st International Conference on Neural Information Processing Systems (Curran Associates Inc., Long Beach, California, USA, 2017), 6000\u20136010. https://dl.acm.org/doi/10. 5555/3295222.3295349. 2. Radford, A., Narasimhan, K., Salimans, T. & Sutskever, I. Improving Language Understanding by Generative Pre-Training OpenAI (2018). https://cdn.openai.com/research-covers/language-unsupervised/ language_understanding_paper.pdf. 3. Huang, C., Li, S., Liu, R., Wang, H. & Chen, Y. Large Foundation Models for Power Systems. arXiv. https: //doi.org/10.48550/arXiv.2312.07044 (2023). 4. Bonadia, R. S., Trindade, F. C. L., Freitas, W. & Venkatesh, B. On the Potential of ChatGPT to Generate Distribution Systems for Load Flow Studies Using OpenDSS. IEEE Trans. Power Syst. 38, 5965\u20135968 (2023). 5. Yan, Z. & Xu, Y. Real-Time Optimal Power Flow With Linguistic Stipulations: Integrating GPT-Agent and Deep Reinforcement Learning. IEEE Trans. Power Syst. 39, 4747\u20134750 (2024). 6. Jernite, Y. et al. Data Governance in the Age of Large-Scale Data-Driven Language Technology. Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (Association for Computing Machinery, Seoul, Republic of Korea, 2022), 2206\u20132222. https://doi.org/10.1145/3531146.3534637. 7. Li, H., Chen, Y., Luo, J., Kang, Y., Zhang, X., Hu, Q., Chan, C. & Song, Y. Privacy in Large Language Models: Attacks, Defenses and Future Directions. arXiv. https://doi.org/10.48550/arXiv.2310.10383 (2023). 8. Huang, X. et al. A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation. arXiv. https://doi.org/10.48550/arXiv.2305.11391 (2023). 9. Ziegler, D. M., Stiennon, N., Wu, J., Brown, T. B., Radford, A., Amodei, D., Christiano, P. & Irving, G. Fine-tuning language models from human preferences. arXiv. https://doi.org/10.48550/arXiv.1909.08593 (2019). 10. Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv. https://doi.org/10. 48550/arXiv.2303.12712 (2023). 11. Song, Y., Xiong, W., Zhu, D., Li, C., Wang, K., Tian, Y. & Li, S. Restgpt: Connecting large language models with real-world applications via restful apis. arXiv. https://doi.org/10.48550/arXiv.2306.06624 (2023). 12. OpenAI. Enterprise Privacy at OpenAI Accessed: 13/03/2024. 2023. https://openai.com/enterpriseprivacy. 13. Department of Energy. Critical Electric Infrastructure Information; New Administrative Procedures https: //www.govinfo.gov/content/pkg/FR-2020-03-16/pdf/2020-04640.pdf. Mar. 2020. 14. Okerlund, J., Klasky, E., Middha, A., Kim, S., Rosenfeld, H., Kleinman, M. & Parthasarathy, S. What\u2019s in the chatterbox? Large language models, why they matter, and what we should do about them. tech. rep. (2022). https://stpp.fordschool.umich.edu/research/research-report/whats-in-the-chatterbox. 15. NIST AI Risk Management Framework https://www.nist.gov/itl/ai-risk-management-framework. 16. Zhang, L., Xiong, Y., Yang, Z., Casas, S., Hu, R. & Urtasun, R. Learning unsupervised world models for autonomous driving via discrete diffusion. arXiv. https://doi.org/10.48550/arXiv.2311.01017 (2023). 17. Luo, H. & Specia, L. From Understanding to Utilization: A Survey on Explainability for Large Language Models. arXiv. https://doi.org/10.48550/arXiv.2401.12874 (2024). 18. Yao, Y., Duan, J., Xu, K., Cai, Y., Sun, Z. & Zhang, Y. A survey on large language model (llm) security and privacy: The good, the bad, and the ugly. High-Confidence Computing, 100211 (2024).\nThis supplemental information contains supporting experimental results to understand the capabilities and limitations of large language models (LLMs) in the electric energy sector. Experiments appear in the same order as they were introduced in Figure 1 of the main article. Detailed discussions on the capabilities and limitations of LLMs in the main article have primarily been drawn from these experimental results. For each experiment, we first briefly introduce the relevant power engineering applications and then elaborate on how we have utilized the LLM to solve the underlying task. For experimentation and analysis, we have explicitly used OpenAI\u2019s GPT series models either through Web Interface (WI) or through Application Programming Interface (API). Unless specifically mentioned, we utilized WI for experimentation. It should be noted that the experiments conducted in this supplemental information are only meant to explore the many capabilities and limitations of LLM in the electric energy sector. Due to the generative nature of the LLMs, each time, the answers may not be consistent. Future research will investigate each of these use cases in much more detail. All the codes, prompts, and specific datasets as a part of this research analysis are available in1. While the detailed step-by-step responses generated by the LLM are not reproduced in their entirety in this document, they can be accessed through our shared Github repository.\n  20 Jun 2024\n\u2022 SI.1: Correlation Analysis for the Power Systems \u2022 SI.1.1: Correlation Analysis with Power Flow Data \u2022 SI.1.2: Correlation Analysis with Demand and Prices Data \u2022 SI.2: Wildfire Risks Recognition on the Power Lines \u2022 SI.3: Equipment Damage Detection in Power Grids \u2022 SI.4: On-site Hazards Recognition \u2022 SI.5: Document analysis for power systems \u2022 SI.5.1: Document Summarizing \u2022 SI.5.2: Knowledge Pool Analysis Through Retrieval-Augmented Generation \u2022 SI.6: Forecasting in Power Systems: Load and Price Forecasts \u2022 SI.7: Power Flow-related Problems \u2022 SI.7.1: Power Flow \u2022 SI.7.2: Optimal Power Flow \u2022 SI.8: Ensuring Safe Power Systems Operation\n[eess.SY]\n# SI.1 Correlation Analysis for the Power Systems\nCorrelation analysis is a valuable tool for identifying the influence of one parameter on another, reducing the necessity for elaborate simulations commonly employed in power systems analysis. Its utility extends to control rooms, where operators can employ it as a preliminary step before in-depth analysis. Here, we emphasize two primary aspects concerning power systems operators: (i) the pivotal role of correlation analysis in augmenting decision-making within control rooms, and (ii) its potential to unveil insights into the dynamics of specific load demands. Our objective is twofold: to assess the efficacy of the foundational GPT model in aiding this endeavor and to explore how incremental prompt engineering can bridge this gap. It should be highlighted that this study is an exploratory analysis and not a comprehensive performance evaluation.\n# SI.1.1 Correlation Analysis with Power Flow Data\nTo be able to perform correlation analysis with power flow data, we have conducted a detailed simulation with an IEEE 24-node RTS, modified by wind generators at nodes 18, 21, and 22 and solar generators at nodes 2 and 3. We utilized PyPower for power flow calculations, with the results serialized into time-series CSV files for correlation analysis. Notably, the code to run PyPower and store the generated data in the CSV file was obtained from the GPT-4 Web Interface (WI). GPT-4 seems well-versed in the PyPower data structure, which would be useful in data analysis. GPT-4 WI also interprets dictionaries in JSON format extremely well. Subsequently, we queried the GPT-4 with the dictionaries and CSV files in the following way. A sample of the network\u2019s architecture in JSON format is also provided below for reference:\nBuses \"1\": {\"type\":2, \"Pd\":83.85, \"Qd\":22.0, \"area\":1, \"Vm\":1.0, \"Va\":0.0, \"zone\":1, \"VA\":\"bus_1_VA\", \"PD\":\"bus_1_PD\"} Generators \"1\": {\"bus\":1,\"Pg\":10.0,\"Qg\":0.0,\"status\":1,\"Pmax\":100.0,\"Pmin\":16.0,\"PG\":\"gen_1_PG\"} Branches \"1\": {\"x\":0.01, rateA\":350.0, \"ratio\":0.0, \"angle\":0.0, \"status\":1, \"from_bus\":1, \"to_bus\":2, \"PF\": \"branch_2_PF\", \"PT\":\"branch_2_PT\"}, The CSV file contains time series power flow data. Can you perform exploratory data analytics for me? The dictionary for interpreting the csv file is also provided. Please load the dictionaries first.\nBuses \"1\": {\"type\":2, \"Pd\":83.85, \"Qd\":22.0, \"area\":1, \"Vm\":1.0, \"Va\":0.0, \"zone\":1, \"VA\":\"bus_1_VA\", \"PD\":\"bus_1_PD\"} Generators \"1\": {\"bus\":1,\"Pg\":10.0,\"Qg\":0.0,\"status\":1,\"Pmax\":100.0,\"Pmin\":16.0,\"PG\":\"gen_1_PG\"} Branches \"1\": {\"x\":0.01, rateA\":350.0, \"ratio\":0.0, \"angle\":0.0, \"status\":1, \"from_bus\":1, \"to_bus\":2, \"PF\": \"branch_2_PF\", \"PT\":\"branch_2_PT\"}, The CSV file contains time series power flow data. Can you perform exploratory data analytics for me? The dictionary for interpreting the csv file is also provided. Please load the dictionaries first.\nBased on our observation, at GPT-4\u2019s current capability, it may not load the dictionary first, which often results in misidentification of the CSV file containing power flow data. The prompt \u201cPlease load the dictionaries first.\u201d seems to alleviate this challenge. While we have indicated that the GPT-4 seems to automatically focus on exploratory data analysis, of which correlation is an integral part, for time series power flow data. If we slightly change our query to \u201cprovide us with insights\u201d, the generated response differs significantly. Comparative visualization of LLMs responses are shown in Figure S1. Figure S1(a) demonstrates how changing loads and generations impact power flow. Figure S1(b) demonstrates comprehensive correlation analysis as provided by GPT-4. Here, red represents a positive correlation, and blue represents a negative correlation. In the next prompt, we ask the GPT-4 about the lines approaching their limits, and from the generated Python code, we observe that it correctly compares the maximum of the absolute value of the branch flows while comparing with flow limits as available in the JSON dictionary:\nmax_flows = data[branch_pf_columns].abs().max().reset_index() max_flows.columns = [\u2018Branch\u2019, \u2018Max Flow\u2019]\nIn the subsequent prompt, we furnish GPT-4 with the specifics regarding the locations of the wind and solar generators mentioned earlier. We then pose the query \u201chow solar and wind generators are contributing to the line congestion\u201d. GPT responds by highlighting some branches that negatively correlate with power generation, this is also evident in Figure S1(b). However, based on our electrical engineering knowledge, we know that line flows are direction-specific, which can also be seen in Figure S1(a). Still, our objective here is to ascertain whether renewable energy sources contribute to line overload. To ensure accurate analysis, we provide additional guidance: \u201cKnowledge: When comparing power generation or load with branch flow, please consider the absolute value.\u201d With this knowledge, GPT-4 can accurately identify the correlation between generator injection and branch flow. Additionally, GPT-4 generates a scatterplot illustrating the impact of solar/wind generation on line flows as shown in Figure S2 . GPT-4 can also estimate overloads for an unknown scenario based on these correlations.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1304/1304b6f7-1491-45ac-81d1-9b0ebb59e8e3.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) LLM asked to provide insights based on power flow data.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/885e/885e623d-e09c-4bff-81e6-7263fd80dc9e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) LLM asked to perform EDA with power flow data. Figure S1: Correlation analysis demonstrating GPT-4 WI\u2019s capability in analyzing power flow data (Figures generated by GPT).</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2061/206198cc-65f2-4857-a40e-fa63bbc820fe.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/01d3/01d347c9-8c1d-4509-b977-1474dd8d14be.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) LLM generated solar vs branch flow correlation</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/55bf/55bf2283-2860-4468-b9a3-5d3be9f32cd7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) LLM generated wind vs branch flow correlation.</div>\n<div style=\"text-align: center;\">Figure S2: Correlation analysis between renewable generation and branch flow (Figures generated by GPT).</div>\n<div style=\"text-align: center;\">.1.2 Correlation Analysis with Demand and Prices Data</div>\n# SI.1.2 Correlation Analysis with Demand and Prices Data\nAnalyzing the correlation between demand and prices is significant for distinguishing load groups contributing to demand response initiatives. Identifying such correlation could be of absolute importance to an operator in managing resources, especially during peak demand days. For such analysis, we compiled a large time-series dataset comprising historical real-time price data, day-ahead price data, total wind generation, total solar generation, aggregated systemwide load demand, and the farm load data, which we tried to model. We provided the following prompt to the GPT-4 with the first two rows of the CSV file provided for reference.\ndemand response initiatives. Identifying such correlation could be of absolute importance to an operator in managin\nresources, especially during peak demand days. For such analysis, we compiled a large time-series dataset comprisin\nhistorical real-time price data, day-ahead price data, total wind generation, total solar generation, aggregated system\nwide load demand, and the farm load data, which we tried to model. We provided the following prompt to the GPT-\nwith the first two rows of the CSV file provided for reference.\ntime\nrtm_lz_south\ndam_lz_south\nwind\nsolar\nercot\nfarm_load\n7/1/2022 0:00\n0.015257266\n0.019299607\n0.668166171\n0\n0.650940015\n0.998710355\n7/1/2022 1:00\n0.010880517\n0.016610027\n0.684359174\n0\n0.615978621\n0.997153536\n...\n...\n...\n...\n...\n...\n...\nI wanted to model the farm load as available in the \u2018.csv\u2019 file. Can you help me with the exploratory data analytics?\ntime\nrtm_lz_south\ndam_lz_south\nwind\nsolar\nercot\nfarm_load\n7/1/2022 0:00\n0.015257266\n0.019299607\n0.668166171\n0\n0.650940015\n0.998710355\n7/1/2022 1:00\n0.010880517\n0.016610027\n0.684359174\n0\n0.615978621\n0.997153536\n...\n...\n...\n...\n...\n...\n...\nI wanted to model the farm load as available in the \u2018.csv\u2019 file. Can you help me with the exploratory data analytics?\ns available in the \u2018.csv\u2019 file. Can you help me with the exploratory data analytics\nGPT-4 demonstrates an ability to discern contextual cues within the dataset, interpreting column headers such as \u2018rtm_lz_south\u2019 and \u2018dam_lz_south\u2019 as indicative of real-time and day-ahead prices, respectively. It contextualizes \u2018wind\u2019 and \u2018solar\u2019 columns further to identify them as corresponding to respective generation availability, while \u2018ercot\u2019 represents an energy-related metric specific to Texas. Notably, the Electric Reliability Council of Texas (ERCOT), the transmission grid operator in Texas, USA, widely utilizes the column header \u2018ercot\u2019 to signify total electricity demand across ERCOT-managed areas. Given the enormous scope of exploratory data analytics, GPT-4 suggests a few possible directions, and upon request for \u201cconsider your best judgment\u201d, it performs time-series visualization, correlation analysis, and distribution analysis, with key insights and visualizations as shown in Figure S3. Based on our observation, in two subsequent interactions, GPT-4 recommends constructing a load forecasting model utilizing LSTM (Long Short-Term Memory), an AI-model typically used for forecasting. However, when generating the answer, we again observe a lack of self-awareness of the GPT-4,\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/67d2/67d2f726-6463-472d-bc47-22611a8dddfd.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) Correlation in the data across multiple columns.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/cb9f/cb9f9ae2-0ccb-4352-99f4-c0df23ded967.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) Data visualizations through histograms.</div>\nFigure S3: LLM demand and prices correlation analysis visualization (Figures generated by GPT).\nwhere it prepares a Python script to train an LSTM model using the TensorFlow/Keras environment, encountering errors likely due to platform limitations\u2014potentially imposed by the OpenAI. It\u2019s worth noting that such constraints may be mitigated when executing the code on local machines, reducing the likelihood of encountering such issues in actual deployment. In the second experiment, we directed GPT-4 to identify why the loads are behaving in a certain way, especially when the loads are below 0.9. GPT responded by conducting regression analysis using random forest. However, recognizing that power systems engineers might be more familiar with regression methods, we adjusted our prompt accordingly. GPT then conducted linear regression without data transformation. When we specifically inquired \u201cabout the accuracy of this model based on the residuals,\u201d GPT identified that the residuals are expected to be normally distributed around zero. Additionally, GPT-4 flagged potential issues such as heteroscedasticity or autocorrelation in the residuals and proposed applying transformations to address them but did not apply them automatically.\n# Key points:\n(i) LLMs require contextual information for time-series data analysis. LLMs lack crucial insights about power systems and, therefore, still require human oversight and guidance for insights. (ii) LLMs exhibit proficiency in conducting exploratory data analysis even without explicit guidance, yielding desired models. However, the model could be erroneous unless the user specifically checks for the model\u2019s accuracy. (iii) LLMs may not inherently address data distribution issues unless specifically prompted. Power systems engineers may not always be able to understand these nuances, and LLMs do not bridge these gaps.\n(i) LLMs require contextual information for time-series data analysis. LLMs lack crucial insights about power systems and, therefore, still require human oversight and guidance for insights. (ii) LLMs exhibit proficiency in conducting exploratory data analysis even without explicit guidance, yielding desired models. However, the model could be erroneous unless the user specifically checks for the model\u2019s accuracy. (iii) LLMs may not inherently address data distribution issues unless specifically prompted. Power systems engineers may not always be able to understand these nuances, and LLMs do not bridge these gaps.\n# SI.2 Wildfire Risks Recognition on the Power Lines\nHistorically, wildfires have caused unprecedented damages in California, USA, causing nearly $20 billion in property damage over the past five years alone. These events pushed PG&E, a major utility company, to bankruptcy. As wildfires progress, power systems operators would receive a meteorological map as part of situational awareness, and the operators could be interested in overlaying the weather map onto the power map to assess the risk of the power lines. We wanted to investigate whether LLM\u2019s multi-modal capabilities could be leveraged to identify the risk of wildfires on power lines. To demonstrate this capability, we utilized data from the August Complex wildfire, California\u2019s largest wildfire in 2020. This wildfire persisted throughout August, September, and October. The wildfire-affected areas (maps are sourced from2) and transmission line maps (sourced from3) are given in Figure S4.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8d87/8d87070b-9613-464f-875f-6d6e465fa815.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) Fire situation in August. (b) Fire situation in September. (c) Fire situation in October. (d) Transmission Line Ma Figure S4: August complex wildfire map and transmission lines.</div>\nWe prompted GPT-4 with the instruction: \u201cI will provide you with a wildfire map of August, September, and October. The area in red implies the wildfire area. A map of transmission lines is provided for the same area. Can you extract the wildfire areas for all three months and plot them in distinguishable colors on top of the transmission line map?\u201d Given that we uploaded multiple files together, the identification of labels is not trivial. We observe from the generated codebases that GPT-4 can browse through metadata (e.g., file name) to correctly label the figures and use them for overlaying. This is demonstrated in Figure S5(b).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a392/a3924b5f-d9bd-4e8c-966b-08b6738cfbc2.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure S5: LLM\u2019s Variational Results: wildfires superimposed on transmission Lines (Figures generated by GPTthrough overlaying by generating suitable codes).</div>\nThe generative nature of the LLMs is visible in Figure S5. Based on our experience, LLMs exclusively utilize tool embedding for image manipulation. Upon close inspection, we observe that the code primarily fails due to mistakes in filter applications. To investigate if prompt engineering can reduce some of the variabilities in code generation, we performed two additional sets of experiments and extracted the Python code generated by the GPT-4 across multiple trial runs. We then utilize the Abstract Syntax Tree (AST) data structure to compare the generated Python codes and generate the similarity score4. For the scenario in Figure S7(A), we provided all three wildfire maps as well as the transmission line map to the GPT, while for the scenarios in Figure S7(B) and (C) we considered only one of the wildfire maps. It can be seen that directness in the prompt can help GPT-4 to understand the problem statement better, and the codes so generated across multiple runs can become nearly identical, leading to a decreasing AST score. In all three scenarios, we conducted these experiments utilizing the map data obtained from Fire Information for Resource Management System of NASA5, as shown in Figure S6.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a7d1/a7d1ce0d-e41a-4eeb-ab3a-4291aee630fc.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/71ce/71ce26d7-662c-49c2-b0a8-b7e2121cf0ec.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">situation in August. (b) Fire situation in September. (c) Fire situation in October. (d) Transmissi Figure S6: Unannotated August complex wildfire map and transmission lines (revised).</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f4aa/f4aac870-4744-47cf-80d9-54b543b3c5f6.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Can you extract all red patches from  this map? Ignore everything in white.  Please make this image transparent.</div>\n<div style=\"text-align: center;\">Can you extract all red patches from  this map? Ignore everything in white.  Please make this image transparent.</div>\n<div style=\"text-align: center;\">Figure S7: Variation in the codebase generated using python tool. Histograms in Figures (A), (B) an using codes considering different prompts.</div>\nFigure S7: Variation in the codebase generated using python tool. Histograms in Figures (A), (B) and (C) are generated using codes considering different prompts.\nWe utilized the best prompt in the previous experiments, namely, \u201cRemove all background and keep only red area for me\" for extracting wildfire-affected regions. While the generated codes are similar, differences exist in the extraction process, as highlighted in Figures S8(b) and S8(c). Nevertheless, once the images with transparent backgrounds are generated, they can be superimposed on top of the transmission line map as shown in S8(d).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/56d1/56d1a579-378c-45bb-a6a4-d422c29cdfa0.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">e map and transmission lines (Figures (b), (c) and (d) are generated throu</div>\nNext, we utilized an iterative approach to generate the wildfire map overlayed on the power line as demonstrated in Figure S9. We systematically extracted wildfire-affected areas and overlayed all the extracted figures atop one another to gain a comprehensive understanding of the wildfire\u2019s impact on power lines. This exercise demonstrates that LLMs could be leveraged to overlay wildfire risk onto the electric energy systems map for visualization and situational awareness.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a82b/a82b1d1b-d9e9-4745-9c57-7b463c538048.png\" style=\"width: 50%;\"></div>\nRemove all background, and keep only red area for me.\n<div style=\"text-align: center;\">(c) Filtered wildfire area with transparent background. (d) Wildfire superimposed on transmission lines.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7f13/7f13c96b-9f6b-42b9-aab4-2ceae4078f36.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure S9: LLM-generated wildfire impact on transmission line identification and visualization (Bottom figure generated by GPT-4 through overlaying).</div>\nWith this capability in mind, we presented GPT-4 with this prompt: \u201cIn the wildfire map, the green patches symbolize vegetation. Can you show the area that can catch fire next month?\u201d However, we encountered a bottleneck with this command, where GPT-4 indicated: \u201cAs an AI, I\u2019m unable to predict future wildfire spread as I do not have real-time data or the ability to run such models.\u201d such limitation appears to be an imposition by OpenAI, which may not be a concern with localized LLMs.\n# Key points:\n(i) The capability of LLMs is continuously improving. However, GPTs are generative models. Based on thei contextualization, the results can vary widely. (ii) Prompt engineering can help in dividing the overall tasks into manageable tasks that GPT can do without erro and would improve their credibility to the power systems engineers.\n# SI.3 Equipment Damage Detection in Power Grids\nWith the growing complexity of power systems infrastructures, manual condition monitoring of equipment becomes practically infeasible. While machine learning can aid engineers6, such a capability would require training with a vast amount of data, which may not always be available. Given the foundational model nature of GPTs and leveraging its multi-modal feature, we wanted to investigate if LLMs can detect faulty equipment. Initially, we explored whether GPT-4 could accurately identify faulty insulators using its inherent knowledge. Encountering limited accuracy, we aimed to overcome this by introducing a richer set of examples of intact and faulty insulators as shown in S10. We tagged every intact insulator as \"Intact.\" Conversely, each faulty insulator was labeled and accompanied by a detailed description of its defects.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7018/7018920d-1fe7-41b8-bd72-59599afe19dc.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure S10: Images of faulty insulators presented to GPT-4 for comprehension/questionnaire.</div>\nWe introduced the figures to the GPT-4 one by one using the following knowledge base as a part of few-shot learning.\nFigure (a): Insulator with breakage on the third layer. Status: Failure.\nFigure (b): Insulator is not damaged. Status: Intact.\nFigure (c): Insulator with breakage on the fifth layer. Status: Failure.\nNow, tell me the status of Figure (d).\nFigure (a): Insulator with breakage on the third layer. Status: Failure.\nFigure (b): Insulator is not damaged. Status: Intact.\nFigure (c): Insulator with breakage on the fifth layer. Status: Failure.\nNow, tell me the status of Figure (d).\nThis strategy was designed to implement the few-shot prompt technique to improve GPT\u2019s ability to distinguish faulty and intact insulators by supplying clear, well-defined examples and criteria. Consequently, GPT-4 demonstrated a marked improvement, successfully recognizing insulator status with greater accuracy. To assess accuracy quantitatively, we used a dataset comprising 40 insulators evenly split between intact and defective conditions. The GPT model tended to mislabel defective insulators when encountering unfamiliar failure conditions. GPT-4 sometimes mistook shadows for actual chips, leading to false classifications. Overall accuracy with this few-shot training method is reported in Table S1. Although the accuracy achieved in this study is lower than the results reported by6, which exceeds 90%, it is important to note that our dataset was significantly smaller than theirs, and we did not use any synthetic images for training.\nThis strategy was designed to implement the few-shot prompt technique to improve GPT\u2019s ability to distinguish faulty and intact insulators by supplying clear, well-defined examples and criteria. Consequently, GPT-4 demonstrated a marked improvement, successfully recognizing insulator status with greater accuracy.\nTo assess accuracy quantitatively, we used a dataset comprising 40 insulators evenly split between intact and defective conditions. The GPT model tended to mislabel defective insulators when encountering unfamiliar failure conditions GPT-4 sometimes mistook shadows for actual chips, leading to false classifications. Overall accuracy with this few-shot training method is reported in Table S1. Although the accuracy achieved in this study is lower than the results reported by6, which exceeds 90%, it is important to note that our dataset was significantly smaller than theirs, and we did not use any synthetic images for training.\n<div style=\"text-align: center;\">Table S1: Insulator Accuracy</div>\nTable S1: Insulator Accuracy\nDataset\nAccuracy(%)\nOverall Accuracy\n80\nOnly Intact Insulator\n85\nOnly Faulty Insulator\n70\nWe continued our evaluation of this experiment by analyzing GPT\u2019s robustness in two additional scenarios: (i) whether the responses were consistent across various prompts and (ii) how the accuracy of the responses was influenced by the quality of the images used. As a part of the first question, we utilized an identical training dataset within a different prompt to analyze the outcomes. Our findings showed that, despite asking questions in various styles while conveying the same information, GPT-4 responses were consistent in this case. As for the second question, we investigated how GPT performs where low-quality images were presented as a part of the question and where the context images were of high quality. These low-quality images were generated in6. We observe that the GPT fails to identify faulty Insulators even with apparent flaws.\nThese assessments suggest that while both prompt engineering and multi-modal LLMs are promising candidates for facilitating fault detection tasks in power grids, further research is required to enhance their performance and robustness. Ultimately, it is important to highlight that although our analysis was exclusively focused on insulators, the methodology we employed can be adapted to include a wider range of power system equipment.\nThese assessments suggest that while both prompt engineering and multi-modal LLMs are promising candidates for facilitating fault detection tasks in power grids, further research is required to enhance their performance and robustness. Ultimately, it is important to highlight that although our analysis was exclusively focused on insulators, the methodology we employed can be adapted to include a wider range of power system equipment. Key points: (i) Due to vast pre-training datasets, LLMs may achieve satisfying performance while requiring less data compared to models developed from scratch. (ii) LLMs may struggle to accurately label insulators if they encounter faults that have not been previously seen.\n(i) Due to vast pre-training datasets, LLMs may achieve satisfying performance while requiring less data compared to models developed from scratch. (ii) LLMs may struggle to accurately label insulators if they encounter faults that have not been previously seen.\n# SI.4 On-site Hazards Recognition\nElectrical work around the power grid infrastructures ranks among the most hazardous professions, necessitating unwavering attention and stringent precautions throughout operations. Supervision and safety checks are indispensable to ensure adherence to these protocols. Remote supervision offers efficiency in ensuring safe operation around power grid infrastructures. To investigate GPT\u2019s proficiency in recognizing risks around the power lines, we posed the question \u201cBetween 0-10 give me a safety score for the given figure\u201d with Figure S11.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7a6f/7a6fa79e-86d2-4c17-9829-fccc0200524a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure S11: Electrical project site. Taken from7.</div>\nOur expectation behind this prompt was to investigate whether an LLM would properly recognize hazards and alert site engineers to take necessary actions. However, we encountered a bottleneck when GPT-4 indicated: \u201cI can\u2019t give a precise numerical safety score,\u201d which is an artificial constraint imposed by OpenAI as we suspected. Nonetheless, GPT-4 demonstrated its ability to identify several critical safety concerns, including \u2018Proximity to power lines\u2019, \u2018Personal protective equipment (PPE)\u2019, \u2018Stability of the crane\u2019, \u2018Fall protection\u2019, \u2018Observing a safe working radius\u2019. To gain insight into GPT\u2019s situational awareness regarding power lines, we prompted it with the question, \u201cWhat factor should I consider for giving score for working around power lines.\u201d we devised the following prompt based on the response from GPT-4 with a range list of factors:\nGive an aggregated safety score for this picture. Instruction: First, allocate a score between 0-10 for each of the following factors. If you are unsure about a particular aspect, give it a score of 5. My aggregated score will be the average of all individual scores. Factors: Distance from Power Lines, Use of Insulating Equipment, Personal Protective Equipment (PPE), Training and Awareness, Lockout/Tagout Procedures, Warning Signs and Barriers, Weather Conditions, Supervision and Safety Protocols, Emergency Plans, Inspection and Maintenance\nWe observed that GPT-4 provided the following individual scores(s) in one of the instances: Distance from Power Lines (Score: 2), Use of Insulating Equipment (Score: 2), Personal Protective Equipment (PPE) (Score: 1), Training and Awareness (Score: 3), Lockout/Tagout Procedures (Score: 2), Warning Signs and Barriers (Score: 1), Weather Conditions (Score: 8), Supervision and Safety Protocols (Score: 3), Emergency Plans (Score: 5, unavailable), Inspection and Maintenance (Score: 5, unavailable). Given the limitations of self-consistency prompting, we observed that GPT-4 employed its embedded Python tool to compute aggregated scores in the backend. To investigate the ability to deploy this method in the real world, we have repeated this experiment 55 times, and the distribution of individual components scores and the aggregated score is given in Figure S12. It can be observed that the aggregated audit score lies between 3 and 4 (out of 10) for \u223c60% of the time, with a peak at 3.5, symbolizing the GPT-4 consistently identifies hazards and poor operating conditions around the electricity infrastructures. To understand what contributes to these variations, we looked into distributions of individual components of the audit score. The prompt specifically states that we should allocate a score of 5 if uncertain, and we observe the associated impact on the decision-making. For the individual metrics, such as Training and Awareness, Lockout/Tagout Procedures, Supervision and Safety Protocols, Emergency Plans, Inspection, and Maintenance, it is hard to determine the presence of these protocols from one picture, so we observe GPT-4 allocating a score of 5 in those cases in several instances. We also observe GPT-4 consistently drawing lower values, for example, in Lockout/Tagout Procedures, Supervision, and Safety Protocols, where GPT-4 seems to be quite certain that these guidelines are not being followed.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fd05/fd056ea1-a5db-48cf-ae3c-42baf3d4ed4f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">A. Score Distribution of Individual  Components of the Metric</div>\nFigure S12: Variations in GPT generated audit scores. (A) (a) Distance from Power Lines, (b) Use of Insulating Equipment, (c) Personal Protective Equipment (PPE), (d) Training and Awareness, (e) Lockout/Tagout Procedures, (f) Warning Signs and Barriers, (g) Weather Conditions, (h) Supervision and Safety Protocols, (i) Emergency Plans, (j) Inspection and Maintenance. (B) Aggregated Audit Score.\nGiven the unsafeness of the operating condition, GPT-4 extrapolates the absence of warning signs and barriers. Finally, while we observe a blue sky from one picture, it is hard to determine the entire weather condition. Therefore, we observe GPT-4 allocating scores ranging from 6 to 9, with scores peaking at 8, symbolizing the GPT-4 is able to capture the uncertainty. These experiments demonstrate the suitability of GPTs in real-world situational surveillance based on constant supply of images and we can extrapolate that videos could also be suitably embedded for this applications. Therefore, this tool can be of immense value to power engineers.\n(i) LLMs have the capability to identify on-site security risks and furnish supervisors with necessary feedback with sufficient prompts. (ii) Including more contexts in the calculation of scores would help in generating consistent safety scores for decision-making.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/be0a/be0a29f0-2048-4358-a6e1-7376b79a9b10.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">B. Distribution of Audit Score</div>\n# SI.5 Document analysis for power systems\nIn power systems management, efficient processing of information is crucial for effective decision-making. This sector relies extensively on diverse documents such as protocols, guidelines, and technical reports, making it crucial to utilize tools that can adeptly manage this information. This section examines two such tools ideally suited for document processing in the power system domain: the GPT-4 Web Interface (WI) and the Retrieval-Augmented Generation (RAG) model. We assess the GPT-4 WI by its performance in document summarization tasks, and evaluate the RAG model through its capability for question answering, which aligns well with its design purpose. It should be highlighted that this study is an exploratory analysis and not a comprehensive performance evaluation.\nSI.5.1 Document Summarizing\n# SI.5.1 Document Summarizing\nIn this context, we referred to the Department of Energy (DoE)\u2019s technical report8 on smart grids and tasked the GPT-4 WI with summarizing the document without providing additional context. GPT-4 excelled in comprehending and discussing all sections of the 170-page report. It summarized smart grids as \u201cmore intelligent, efficient, and resilient infrastructure through the adoption of digital sensing, communication, and control technologies.\u201d However, we sought to explore how GPT-4 would perform with more specific instructions. To this end, we asked it to \u201cinterpret the document from the perspective of a power system technician?\u201d In response, GPT-4 provided a more detailed and technical summary, describing smart grids as \u201ctransition from traditional grid systems to more advanced, digitally enabled grids that integrate renewable energy sources, manage distributed energy resources (DERs), and enhance grid reliability and efficiency through digital communication and control technologies.\u201d These varied responses clearly demonstrate GPT\u2019s ability to tailor its analysis based on the audience or questions posed, which could be instrumental in developing structured summaries.\nThis experiment not only served as a practical demonstration of the GPT-4 WI\u2019s capabilities in document processing but also highlighted the importance of customized prompts in significantly improving the system\u2019s ability to generate specialized content, affirming its potential as a valuable tool in technical fields.\n# .5.2 Knowledge Pool Analysis Through Retrieval-Augmented Gene\nRetrieval-Augmented Generation (RAG) enhances the performance of LLMs by combining their text-generating capabilities with the ability to retrieve relevant information from external databases. This integration significantly improves both the accuracy and contextual relevance of the responses generated by LLMs. Introduced in9, RAG first processes the content of the query. It then uses this processed query to search an external database to find the most relevant text fragments. This search typically employs vector similarity measures, where both the query and the documents are represented as high-dimensional vectors. The goal is to retrieve documents whose vectors closely match the query vector, indicating high relevance to the input query. Given the promising enhancements brought by the RAG system, in this section, we evaluate RAG\u2019s effectiveness in the power sector by assessing its question-answering capabilities across power-specific documents. We integrate Langchain with OpenAI\u2019s API to develop a Retrieval-Augmented Generation (RAG) system, utilizing the GPT-3.5-Turbo model. Following data segmentation, we employ the following techniques for processing:\n\u2022 OpenAIEmbeddings which utilize Byte Pair Encoding (BPE) for tokenization and vectorization. \u2022 Facebook AI Similarity Search is employed for storing vectors, which is crucial for the retrieval capabilitie of our RAG system.\nIn our investigation of RAG\u2019s potential as a knowledge repository, we concentrated on nodal protocols 2 through 9 from ERCOT10. Initially, we appended these documents into a single corpus for analysis and then segmented this corpus to facilitate the knowledge examination. Our evaluation of RAG\u2019s performance was based on two types of questions: (i) those that could be directly answered from the text (e.g., \"What is the Opportunity Outage?\"), and (ii) those that require nuanced reasoning for a response (e.g., \"How do you calculate physical responsive ancillary service capability across ERCOT?\" - the term \u2019Ancillary service\u2019 was included in the question to introduce complexity). Based on our repeated experiments so far, we observed that RAG can provide more accurate and coherent answers\nBased on our repeated experiments so far, we observed that RAG can provide more accurate and coherent answers to direct questions. As shown in S13, when compared with the excerpt from the ERCOT nodal protocol, the RAG\u2019s responses surpassed even those generated by the GPT-4 WI in terms of precision and alignment. However, RAG\u2019s ability got diminished when addressing more complex queries. For example, it either failed to provide an answer or offered responses that are not thorough and vary with each attempt. As demonstrated in S14(a), RAG struggled to pinpoint the correct response according to nodal protocol 6.5.7.5, Even when tested under lower temperatures. In LLMs,\nthe temperature parameter influences the level of creativity or randomness allowed in the model\u2019s responses, with higher temperatures resulting in more creative and varied outputs and lower temperatures producing more predictable text. Furthermore, as highlighted in S14(b), RAG generated a diverse set of responses. While none of the responses highlighted here are incorrect, they often lack comprehensiveness. For instance, the right prompt accurately stated that a qualified scheduling entity (QSE) that meets all the required criteria is eligible to become a must-run alternative (MRA) service provider. Yet, it failed to capture all the detailed nuances. Conversely, the left prompt mentioned various types of MRAs but did not specifically address the QSEs. We further explored these issues by testing the same questions using the GPT-4 WI. After uploading the nodal protocols into the chat and posing the same questions, we observed similar fluctuations in the GPT-4 WI\u2019s responses, especially concerning questions about MRAs. However, in scenarios where RAG was unable to provide an answer, such as the one involving physical responsive ancillary service capabilities, the GPT-4 WI managed to deliver a partially correct answer. These experiments suggest that while the RAG model and the GPT-4 WI demonstrate promising capabilities, their effective implementation in power systems requires additional refinement and adaptation.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/93ce/93ce4ca5-9e24-4aa1-834b-8f91daff3722.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure S13: Quality of response for different models for more direct questions</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4637/4637a82b-945b-4f86-ac70-8124cb80b02d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1a98/1a9866c5-07be-4aae-8350-4a03badb670d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a)</div>\n<div style=\"text-align: center;\">Figure S14: Comparison of RAG\u2019s performance over complex questions: (a) RAG\u2019s inability to find answers for more complex questions. (b) Non-comprehensive answers for nuanced questions</div>\n# Key points:\nKey points:\n(i) RAG-based LLMs demonstrate improved domain-specific answers. (ii) Their performance may surpass that of simply uploading the file to a chatbot (such as GPT-4 WI). (iii) LLMs may fail to generate any response or generate varied responses to questions that require nuanced answers The prompt engineering can be extremely useful to reduce these variabilities.\n<div style=\"text-align: center;\">(b)</div>\n# Forecasting in Power Systems: Load and Price Forecast\nForecasting is a key responsibility for power systems engineers to maintain the balance of demand and supply within the electric grid. For instance, the Electric Reliability Council of Texas (ERCOT), the transmission grid operator in Texas, USA, regularly publishes forecasts of loads, prices, and renewable generation production on its dashboard. The accuracy of these forecasts is paramount to ensuring the grid\u2019s reliability. Price forecasts are important for parties participating in the energy market. In this section, we present a comparative analysis of three distinct techniques facilitated by LLMs for load and day-ahead market clearing price forecasting. To conduct our analysis, we draw upon hourly weather data for Texas, USA, sourced from the National Solar Radiation Database (NSRDB)11, alongside hourly load and electricity price data retrieved from the ERCOT open database12,13. We compiled a time-stamped CSV file encompassing historical weather data, aggregated ERCOT load information, and hourly day-ahead load zone settlement point prices for the \u2018Houston\u2019 load zone of ERCOT.\nHere, person 1 signifies the temperature (in \u25e6F with decimal points removed), person 2 as loads (in GW with\ndecimal points removed), and person 3 as prices in ($/MWh with decimal points removed). When utilizing\nGPT-4 WI for this purpose, we noticed that the responses tended to be quite verbose, often elaborating on\nwhy a particular answer was chosen and providing a likely sequence. However, when employing GPT-3.5\nWI for the same task, we observed swift responses for persons 2 and 3. Subsequently, we need to revert the\ngenerated solution to generate the forecast. Upon inquiring about the methodology, \u201cwhen you generated\nlikely responses for Person 2 and Person 3, did you utilize your pre-trained transformer built within yourself\nfor this activity?\u201d we get the response, \u201cYes, I utilized my pre-trained transformer architecture for generating\nthe likely responses for Person 2 and Person 3.\u201d\n(iii) In the first two examples, we directly interacted with the GPT-4 WI. One can also leverage the API to fine-tune\nGPT-3.5. Unlike method (i), where we utilize LLM-generated code, and method (ii), where we exploit the\npre-trained transformer within the LLM, this method directly allows us to modify the GPT transformer model\nbased on our own dataset14. In this setup, we first fine-tune GPT-3.5 with one-year historical hourly resolution\ndata and query the model to generate forecasts for the next day by following the official guidance15. Below is\na JSON entry representing a typical prompt used for training:\n{\"messages\": {\"role\": \"system\", \"content\": \"You are an electrical engineer who predict electricity price\nbased on provided information\"}, {\"role\": \"user\", \"content\": \"Here is information for previous day:\nLoads: 43719.85, 43321.05... What\u2019s load forecast for today?\"},{\"role\": \"assistant\", \"content\": \"Here is\nthe load forecast for today: 44688.67, 42656.83, 41196.68, 40377.20, 39906.83...\"}\nHere, person 1 signifies the temperature (in \u25e6F with decimal points removed), person 2 as loads (in GW with decimal points removed), and person 3 as prices in ($/MWh with decimal points removed). When utilizing GPT-4 WI for this purpose, we noticed that the responses tended to be quite verbose, often elaborating on why a particular answer was chosen and providing a likely sequence. However, when employing GPT-3.5 WI for the same task, we observed swift responses for persons 2 and 3. Subsequently, we need to revert the generated solution to generate the forecast. Upon inquiring about the methodology, \u201cwhen you generated likely responses for Person 2 and Person 3, did you utilize your pre-trained transformer built within yourself for this activity?\u201d we get the response, \u201cYes, I utilized my pre-trained transformer architecture for generating the likely responses for Person 2 and Person 3.\u201d ) In the first two examples, we directly interacted with the GPT-4 WI. One can also leverage the API to fine-tune GPT-3.5. Unlike method (i), where we utilize LLM-generated code, and method (ii), where we exploit the pre-trained transformer within the LLM, this method directly allows us to modify the GPT transformer model based on our own dataset14. In this setup, we first fine-tune GPT-3.5 with one-year historical hourly resolution data and query the model to generate forecasts for the next day by following the official guidance15. Below is a JSON entry representing a typical prompt used for training: {\"messages\": {\"role\": \"system\", \"content\": \"You are an electrical engineer who predict electricity price based on provided information\"}, {\"role\": \"user\", \"content\": \"Here is information for previous day: Loads: 43719.85, 43321.05... What\u2019s load forecast for today?\"},{\"role\": \"assistant\", \"content\": \"Here is the load forecast for today: 44688.67, 42656.83, 41196.68, 40377.20, 39906.83...\"}\nn the first approach, we employed a simple linear regression model through GPT-4 WI for our task. As reported in16, uring summer times, higher temperatures can correlate to higher load demands, and this relationship gets reversed uring winter times, where lower temperatures can correlate to higher demand. Due to this season-based linear orrelation, linear regression could be useful for load forecasting. However, this method struggles in price forecasting\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8e3d/8e3d7abc-bfed-4902-98cf-26cce70ba272.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure S15: Comparison of LLM-based load and price forecasts considering a typical day.</div>\n<div style=\"text-align: center;\">Figure S15: Comparison of LLM-based load and price forecasts considering a typical day.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ee8f/ee8f55b4-c593-4b5b-ac34-33912844fd1a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(c) Load forecast during summer peaks (with confidence interval)</div>\n<div style=\"text-align: center;\">Figure S16: Comparison of LLM-based load forecasts considering multiple days.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/28da/28dab6de-0726-4368-9d27-023b83f8d7ae.png\" style=\"width: 50%;\"></div>\ndue to the inherent complexity of the patterns within the price information. As for the second approach, the transformer architecture demonstrates an enhanced capability to discern intricate patterns. However, for this method, we need to convert the data back into numeric format. The fine-tuned GPT does not suffer from related challenges with significant improvement in forecasting accuracy. Comparative assessments of load forecasting for 06/06/2022 and day-ahead market price forecasts for 01/02/2022 of ERCOT system-wide data, as determined by these three methods, are given in Figure S15. We repeated the experiments 20 times for each method for the same day to obtain the mean and confidence interval to show the robustness of the result, both of which are plotted in the figure. We have compared the mean value of the GPT-generated results with the true measurements to assess the accuracy of the models. We have considered mean absolute percentage error (MAPE) to compare the accuracy. The results reveal that for short-term load forecasting on the selected day, the fine-tuned model achieves commendable accuracy. Model (ii) that incorporates text embedding also achieves reasonable accuracy. However, in the case of price forecasts, the proposed methods performed notably worse than the load forecast scenario. This underscores the complexity of price information, which entails intricate interdependencies with other variables that are not accounted for in this exercise. It underscores the necessity for further research and refinement in this area. Given the accuracy of our models on the short-term load forecasts, we further compared GPT\u2019s performance in longer-term forecasting, and the results are demonstrated in Figure S16. According to the results, we further show that our method has competitive performance in the weekly scenario. It also shows the forecast errors are only 2% to 4% MAPE compared to the actual load for the summer peak. However, winter peak forecasting is very challenging. This is because, as discussed before, the correlation between temperature and electrical load reverses during the winter seasons. Given that the majority of the time, temperature and ERCOT system load demands show positive correlations, forecasting results obtained utilizing each of the three methodologies perform poorly. Furthermore, the results obtained through the text embedding method worsened during the winter peaks. This is possible because embedding a negative sign is difficult for GPT due to limited data within the context window. To examine the generalization capacity of the GPT model for load forecasting tasks, we performed fine-tuning methodology utilizing the GEF14 dataset from Global Energy Forecasting Competition 201417. The results are benchmarked against the deep learning models evaluated in18. For evaluation consistency, the GPT model was finetuned using data from 2012 and subsequently used to perform day-ahead forecasting for 2013 and 2014. The forecasting accuracy was quantified in average pinball loss calculated19 across time. Results, as detailed in Table S2, indicate that the fine-tuned GPT model exhibits competitive performance relative to traditional deep learning models.\n\u2217indicates the state-of-art calculated in\nDataset\nFFNN\nLSTM\nCNN\nTransformer\nLSTNet\nN-BEATS\nWaveNet\nFine-tuned GPT\nGEF14\n92.99*\n131.05*\n86.51*\n137.47*\n421.25*\n156.07*\n132.32*\n132.84\nKey points:\n(i) The pre-trained transformer of LLMs can be directly used for load and price forecasting. Fine-tuned model demonstrates notably promising capabilities with load forecasting. (ii) The intricate nature of price data requires continued exploration and refinement to achieve accurate predictions\n# SI.7 Power Flow-related Problems\nWorking with power-flow equations is an indispensable part of power systems engineering. If LLMs are to be used for solving power-flow-related tasks, they must recognize the correct models and apply them correctly. Here, we will investigate GPT\u2019s capability to utilize DC power flow and DC optimal power flow. In this regard, we first queried GPT-4 to provide us with the codes for performing DC power flow and DC optimal power flow. The Diversity of GPT-generated codes across multiple prompts can be seen in Figure S17(a-c), where we see that during three instances, GPT-4 wrote codes while calling three different solvers. We utilized the Abstract Syntax Tree (AST) data structure to compare the generated Python codes and generate the similarity score4 for both DC power flow and DC optimal power flow. In addition to variation in the codebase for solving DC power flow, there are variations in solving optimization problems as a part of optimal power flow problem, which increases the similarity score significantly. As demonstrated in Figure S17(f), the generated text produced erroneous text, but, apparently, its impact did not translate into generated code. This raises a fundamental question about the utility of LLMs in performing power engineering tasks.\nWrite me a python code for DC optimal  power flow.\nWrite me a python code for DC optimal  power flow.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bf19/bf19a651-f57b-4230-9301-7dff8c8310e2.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ba36/ba369b27-a9fb-44fe-bc52-c41f42a65c3c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/45e9/45e950fc-6120-4624-bacd-be030bc89512.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ef70/ef70fc3e-0dcf-4434-941b-e4d4d10844e8.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a526/a5265890-d942-4b71-9bea-6000944304f8.png\" style=\"width: 50%;\"></div>\nFigure S17: GPT-generated responses when prompted to generate code for DC Power Flow and DC Optimal Powe Flow. Figures (a)-(c) shows three different generated codes with the same prompt. Figures (d) and (e) are histogram showing diversity of the generated codes. Figure (f) shows while the generated text with LLMs can be erroneous, it di not translate to generated code.\nWrite me a python code for DC optimal  power flow.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0291/0291199d-56cf-4b2b-bec0-d9a83d696f04.png\" style=\"width: 50%;\"></div>\nIn this avenue, first, we provided GPT-3.5 and 4.0 with a set of simultaneous equations to investigate its computational capability. We observed that both GPT-3.5 and 4 can generate Python code for solving the set of linear equations, and GPT 4 can utilize embedded tools to generate the solution. GPT-3.5 utilizes self-consistency20 in generating responses, which sometimes leads to erroneous responses. Secondly, we tasked GPT-4 to provide me a step-by-step procedure for solving power flow using DC power flow methods. While it adeptly recognized key components such as voltage magnitudes at all buses at 1 pu, the need for specifying one bus as the slack or reference bus, fixing its phase angle (often to zero), the line resistances are negligible, and voltage phase angle differences are small, we identified some discrepancies in the GPT-generated responses, some of which are identified in Figure S18(b-d). Furthermore, despite specifically asking to provide us with the procedure, it generated a wide variety of texts, as depicted in the COMET score21 generated in Figure S18(a). In this regard, we first obtained GPT-generated texts by invoking the same prompt multiple times. Then, we utilized the COMET score to generate semantic similarity among all possible combinations of two generated responses. The figure shows the histogram of these scores, identifying similarities among the generated responses.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1760/1760aab8-c7d1-4797-bc95-37fa2ef56f3a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6bfc/6bfcb489-4499-4894-ae5b-2a6deaaeed14.png\" style=\"width: 50%;\"></div>\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ca42/ca429519-5d27-41e4-b58f-5d284f812f38.png\" style=\"width: 50%;\"></div>\n\n\n<div style=\"text-align: center;\">Figure S18: GPT-response when tasked with step-by-step procedure for solving power flow using DC power flow. Figure (a) shows the histogram depicting diversity of powerflow methodologies generated with the LLM. Figures (b)-(d) shows mistakes in GPT-generated results for solving power flow equations considering DC power flow.</div>\nAs it can be seen in Figure S19, GPT does not translate the matrix very well. In this regard, we have tested with multiple different Y-bus matrix as shown in this figure. We observe that GPT tends to replicate the Y-bus matrix taken from the lecture note22. The lecture note is publicly available, and GPT-4 might have seen/trained with this dataset, and automatic correction could be attributed to the memory leakage issue discussed in23. Secondly, while this example is a straightforward problem that satisfies all the assumptions of DC power flow, we observe that GPT utilizes a variety of methods, Gauss-Siedel and Newton-Raphson, to solve this problem. We also observe that GPT\u2019s response seems to be a lot verbose. In the next experiment, we modified the last sentence of the prompt as: \u201c\u00b7 \u00b7 \u00b7 can you provide me the bus voltage magnitude and bus angles using DC-power flow equations?\u201d Here, we observe multiple methodological issues in solving DC power flow problem, e.g., in one of the cases, GPT does not reduce the Y-bus matrix before inverting it, as demonstrated below:\n# Extracting the reactance matrix X X_bus = -1 / np.imag(Y_bus)\n# (b)\n(c)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2f25/2f25cb9e-a6e7-419f-a6d2-24eb7a23e6d3.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure S19: GPT\u2019s limited ability to parse the metrices.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0577/0577a7dc-29e2-4009-b406-8d6df0be57d1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f150/f15048d9-fbea-4746-ad17-9f1e33296779.png\" style=\"width: 50%;\"></div>\nThe y-bus system matrix of a power system is given by: Y = [ -30j, 10j, 10j, 10j; 10j, -20j, 10j, 0; 10j, 10j, -30j",
    "paper_type": "survey",
    "attri": {
        "background": {
            "purpose": "This survey aims to explore the capabilities and limitations of Large Language Models (LLMs) in the electric energy sector, addressing the knowledge gaps regarding their applicability in power engineering tasks.",
            "scope": "The survey focuses on the integration of LLMs in various domains within the electric energy sector, including data collection, operational efficiency, and decision-making processes. It excludes areas where LLMs may not provide significant advantages or where traditional methods are more effective."
        },
        "problem": {
            "definition": "The core issue explored is the readiness and effectiveness of LLMs in performing realistic power-engineering tasks and their integration into existing systems.",
            "key obstacle": "Primary challenges include the scarcity of domain-specific data, safety concerns related to LLM outputs, and the inability of LLMs to handle physical principles inherent in power systems."
        },
        "architecture": {
            "perspective": "The survey introduces a framework categorizing LLM capabilities based on their performance in power engineering tasks, emphasizing the importance of prompt engineering and tool embedding.",
            "fields/stages": "The survey organizes current research into fields such as language model capabilities, prompt engineering, tool embedding, and multi-modal processing."
        },
        "conclusion": {
            "comparisons": "The comparative analysis indicates that while LLMs show potential in generating responses and performing analyses, their effectiveness varies significantly across tasks, particularly in complex scenarios.",
            "results": "Key takeaways include the recognition of LLMs' strengths in data processing and diagnostics, alongside their limitations in safety-critical applications and physical modeling."
        },
        "discussion": {
            "advantage": "Existing research highlights the strengths of LLMs in improving operational efficiency, facilitating real-time diagnostics, and enhancing decision-making processes.",
            "limitation": "Current studies fall short in addressing the need for domain-specific training data, safety guarantees, and the ability to model physical principles accurately.",
            "gaps": "Unanswered questions include the development of robust safety protocols for LLM integration and the creation of comprehensive datasets for fine-tuning.",
            "future work": "Future research should focus on curated data collection, enhanced tool embeddings for power-system-specific applications, and the development of knowledge bases tailored to the electric energy sector."
        },
        "other info": {
            "additional_info": {
                "authors": [
                    "Subir Majumder",
                    "Lin Dong",
                    "Fatemeh Doudi",
                    "Yuting Cai",
                    "Chao Tian",
                    "Dileep Kalathil",
                    "Kevin Ding",
                    "Anupam A. Thatte",
                    "Na Li"
                ],
                "affiliations": [
                    "Texas A&M University",
                    "CenterPoint Energy",
                    "Midcontinent Independent System Operator (MISO)",
                    "Harvard University"
                ],
                "publication": "Accepted by Joule"
            }
        }
    },
    "mount_outline": [
        {
            "section number": "2.1",
            "key information": "The survey defines key concepts related to the integration of Large Language Models (LLMs) in the electric energy sector, focusing on their applicability in power engineering tasks."
        },
        {
            "section number": "2.2",
            "key information": "The survey discusses the historical development and evolution of recommendation systems in the context of LLMs, emphasizing their integration into various domains."
        },
        {
            "section number": "4.1",
            "key information": "The survey introduces a framework categorizing LLM capabilities based on their performance in power engineering tasks, emphasizing the importance of prompt engineering and tool embedding."
        },
        {
            "section number": "4.2",
            "key information": "The survey analyzes how LLMs can enhance operational efficiency and decision-making processes in the electric energy sector."
        },
        {
            "section number": "10.1",
            "key information": "The survey identifies challenges faced by LLMs in power engineering, including the scarcity of domain-specific data and safety concerns related to LLM outputs."
        },
        {
            "section number": "10.2",
            "key information": "Future research directions include the development of robust safety protocols and comprehensive datasets for fine-tuning LLMs in the electric energy sector."
        }
    ],
    "similarity_score": 0.740494803211026,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector.json"
}