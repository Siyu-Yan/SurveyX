{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2306.08511",
    "title": "Measuring and Controlling Divisiveness in Rank Aggregation",
    "abstract": "In rank aggregation, members of a population rank issues to decide which are collectively preferred. We focus instead on identifying divisive issues that express disagreements among the preferences of individuals. We analyse the properties of our divisiveness measures and their relation to existing notions of polarisation. We also study their robustness under incomplete preferences and algorithms for control and manipulation of divisiveness. Our results advance our understanding of how to quantify disagreements in collective decision-making.",
    "bib_name": "colley2023measuringcontrollingdivisivenessrank",
    "md_text": "# Measuring and Controlling Divisiveness in Rank Aggregation\nRachael Colley1 Umberto Grandi1 C\u00b4esar Hidalgo2,3,4 Mariana Macedo2 Carlos Navarrete2\n{rachael.colley,umberto.grandi}@irit.fr, {cesar.hidalgo, mariana.macedo, carlos.navarrete}@univ-toulouse.fr 1IRIT, Universit\u00b4e Toulouse Capitole, France 2Center for Collective Learning, ANITI, TSE, IAST, IRIT, Universit\u00b4e de Toulouse, France 3Alliance Manchester Business School, University of Manchester UK 4Center for Collective Learning, CIAS, Corvinus University, Hungary\n# Abstract\nIn rank aggregation, members of a population rank issues to decide which are collectively preferred. We focus instead on identifying divisive issues that express disagreements among the preferences of individuals. We analyse the properties of our divisiveness measures and their relation to existing notions of polarisation. We also study their robustness under incomplete preferences and algorithms for control and manipulation of divisiveness. Our results advance our understanding of how to quantify disagreements in collective decision-making.\n# 1 Introduction\nRank aggregation is the problem of ordering a set of issues according to a set of individual rankings given as input. This problem has been studied extensively in computational social choice (see, e.g., Brandt et al. 2016) when the rankings are assumed to represent human preferences over, for example, candidates in a political election, projects to be funded, or more generally alternative proposals. The most common approach in this literature is to find normative desiderata for the aggregation process, including computational requirements such as the existence of tractable algorithms for its calculation and characterisations of the aggregators that satisfy them. Rank aggregation also has a wide spectrum of applications from metasearch engines [Dwork et al., 2001] to bioinformatics\n[Korba et al., 2017]. Previous work on rank aggregation has focused on how to best elicit which issues are the most agreed upon, without identifying the issues that divide them. Instead, a wide literature in economics and the social sciences has developed measures of social, economic, and political polarisation. Classical work analysed polarisation in the distribution of wealth, goods, and opinions [Esteban and Ray, 1994; Duclos et al., 2004], showing that well-studied notions of inequality are unfit to measure polarisation as they do not consider the weight of subpopulations. Another common approach in social science uses the variance of distributions to measure polarisation (see, e.g., Musco et al.; Gaitonde et al. 2018; 2020). In this paper, we put forward a family of functions that starting from a collection of individual rankings are able to order issues based on their divisiveness. We compute an issue\u2019s divisiveness by aggregating the disagreement among all possible sub-populations defined by the relative preference among the other issues. Our proposal relates to the literature on three important aspects. First, a parameter in our definition allows us to move from an adaptation of the classical measure of polarisation from Esteban and Ray 1994 at one end of the spectrum to the detection of disagreements from minorities at the other end. Second, our measures are parameterised by the rank aggregation function that is used to compute the most agreed-upon issues. In this way, we can align our notions of divisiveness with the functions chosen to measure the agreement of the population.1 Third, while existing work focused on comparing different sets of rankings based on polarisation [Can et al., 2015], diversity [Hashemi and Endriss, 2014], or cohesiveness [Alcantud et al., 2015], here, we aim at identifying the most divisive issues within a complete profile of rankings. In doing so, we do not need to assume that issues are independent, as common in the social choice literature. Our work can further guide how to query a population towards being more inclusive and unified, e.g., through deliberative instances. This can include measures that go towards decreasing divisiveness, such as recent work suggesting the construction of recommender systems to depolarise a population [Stray, 2022], or simply take advantage of this information when steering the public debate (recent work from Ash et al. [2017] suggests that politicians spend more time on divisive topics than on neutral ones). Our work also contributes to social choice theory, where related notions of preference diversity have shown to have effects on the probability of paradoxes [Gehrlein and Lepelley, 2010], the competitiveness in matching markets [Ha\ufffdlaburda, 2010], or the computational complexity of manipulating an election [Wu et al., 2022]. Moreover, our work can be useful in refining the preference analysis of applications, such as online forums or surveys, that query a population on their opinions and return aggregated information about the group as a whole.\nContribution and Paper Structure. We extend the notion of divisiveness, introduced by Navarrete et al. 2022, to a family of measures which take into account the size of a sub-population and use the well-studied scoring functions. These extensions allow us to connect divisiveness to measures of polarisation. We give a theoretical and experimental analysis of our divisiveness measures by relating them to other notions and giving bounds on their limit cases (Section 3). Importantly, we show that our measures can distinguish between key profiles which other measures cannot. We then inspect two aspects of control, first, by studying the effect of removing pairwise comparisons from the agent\u2019s rankings (Section 4.2 ) and second, by adding additional controlled agents (Section 4.2). All our code is available at https://github.com/ CenterForCollectiveLearning/divisiveness-theoretical-IJCAI2023. Related Work. The notion of divisiveness studied in this paper builds on the work of Navarrete et al. 2022, who identify the most divisive issues from proposed government programs from crowdsourced political preferences. Many papers start from a profile of rankings and compare them based on how consensual (equivalently, cohesive) they are [Bosch, 2005; Garc\u00b4\u0131a-Lapresta and P\u00b4erezRom\u00b4an, 2010; Alcalde-Unzu and Vorsatz, 2008, 2013], or in the opposite direction, i.e., how diverse is the set of preferences [Hashemi and Endriss, 2014; Karpov, 2017]. In particular, Alcantud et al. 2015 measures the cohesiveness of a group by aggregating the dissimilarity of their orderings (similarly to Can et al. 2015 who however focus on polarisation). Most of these settings are based on pairwise comparisons, except for Alcalde-Unzu and Vorsatz 2016 and Xue et al. 2020, who look at patterns of varying sizes in the rank profile. One of the methods proposed by Hashemi and Endriss 2014 to measure preference diversity is to average the distance between the individual rankings and the aggregated one. This is in line with our approach, but it only provides a measure to compare different populations of rankings without going to the level of single issues. We note that also an influential theory of diversity not based on preferences but on (binary) features of not necessarily independent alternatives has been proposed by Nehring and Puppe 2002.\n# 2 Basic Definitions\nThis section introduces the basics of rank aggregation and scoring rules. We put forward our definition of divisiveness, then we compare it with existing notions of polarisation.\n# 2.1 Preliminaries\nRankings. Let I = {a, b . . . } be a finite non-empty set of m issues. A strict ranking (aka. linear order) on I is an asymmetric, transitive, and complete binary relation on I. We let a \u227bb denote the fact that a is strictly preferred to b in the ranking \u227b. In what follows, we will write \u227b= acdb for \u227b= a \u227bc \u227bd \u227bb,\nreading preferences from left to right. The set of all strict rankings over I will be denoted by L(I). We denote with rank(a, \u227b) the rank of a in \u227bwith the first position being 1 and the last being m. Individual Rankings. Let a finite non-empty set of N = {1, . . . , n} agents express a strict rankings over I (sometimes referred to as preferences). We let P = (\u227b1, . . . , \u227bn) denote the resulting profile of rankings, where \u227bi is agent\u2019s i ranking over I. We let Na\u227bb = {i \u2208N | a \u227bi b} be the set of voters in N who prefer a to b. The restriction of profile P to the agents in X is denoted by PX = \u27e8\u227bi| i \u2208X\u27e9. When X = Na\u227bb we simply write Pa\u227bb. We call P a consensual profile if for all i, j \u2208N we have that \u227bi=\u227bj. Every preference profile P can be represented as a weighted (anonymous) profile, i.e., as a set of pairs (wj, \u227bj) indicating that wj \u2208N agents have preference \u227bj. Collective Scoring of Issues. Rank aggregation functions define a collective ranking of issues based on the agreements among the individual rankings in a profile. A large number of rules have been proposed and analysed in the literature on (computational) social choice and artificial intelligence. We focus on rank aggregators defined by a scoring function, where the collective ranking over issues is obtained via a function s : I \u00d7 L(I) \u2192[0, 1] that assigns a score to each issue in a given profile. Notable examples are the (normalised) Borda score, which counts the number of issues strictly preferred to a given issue, Borda(a, P) = \ufffd b\u2208I\\{a} #(Na>b) n\u00b7(m\u22121) , where #(X) is the cardinality of a set X. Or the normalised Copeland score, which counts the number of majority contests won by an issue, Cop(a, P) = #{b\u2208I\\{a} | #(Na>b)>#(Nb>a)} m\u22121 .\nreading preferences from left to right. The set of all strict rankings over I will be denoted by L(I). We denote with rank(a, \u227b) the rank of a in \u227bwith the first position being 1 and the last being m.\nCollective Scoring of Issues. Rank aggregation functions define a collective ranking of issues based on the agreements among the individual rankings in a profile. A large number of rules have been proposed and analysed in the literature on (computational) social choice and artificial intelligence. We focus on rank aggregators defined by a scoring function, where the collective ranking over issues is obtained via a function s : I \u00d7 L(I) \u2192[0, 1] that assigns a score to each issue in a given profile. Notable examples are the (normalised) Borda score, which counts the number of issues strictly preferred to a given issue, Borda(a, P) = \ufffd b\u2208I\\{a} #(Na>b) n\u00b7(m\u22121) , where #(X) is the cardinality of a set X. Or the normalised Copeland score, which counts the number of majority contests won by an issue, Cop(a, P) = #{b\u2208I\\{a} | #(Na>b)>#(Nb>a)} m\u22121 .\n# 2.2 Divisiveness\nFor a given sub-population X \u2286N and issue a \u2208I, we measure the divisiveness of a for X as the difference between the collective scoring of a in sub-population X and in its complement sub-population N\\X.\n# Definition 1. [Navarrete et al., 2022] The divisiveness of an issue a \u2208I with respect to a sub-population X \u2286N in profile P is defined as:\nDefinition 1. [Navarrete et al., 2022] The divisiveness of an issue a \u2208I with respect to a sub-population X \u2286N in profile P is defined as:\nIf X = \u2205or X = N, we set DivF(a, X, P) = 0.\nExamples of a sub-population X can be descriptive, such as agents living in cities (thus N\\X are agents living in rural areas) or agents with a given political orientation (thus, N\\X would be those who do not ascribe to this orientation). We can now give a definition of divisiveness for issue a that is independent of a given sub-population by averaging over all sub-populations Na\u227bb for all other issues b. We include an additional parameter \u03b1 that allows us to take into consideration the size of a sub-population allowing for a weighted average version of an issue\u2019s divisiveness.\nDefinition 2. The \u03b1-divisiveness Divs \u03b1(a, P) of an issue a\u2208I in profile P, with \u03b1 \u2208[0, 1] and \u2113\u2208R+, is defined as:\nWhen \u03b1 = 0 and s = Borda, our definition is a reformulation of the divisiveness measure from Navarrete et al. 2022. When \u03b1 = 1, Definition 2 can be interpreted as one of the polarisation measures of Duclos et al. 2004 and Esteban and Ray 1994, calculated on the distribution of ranks that issue a received from individuals. We refer to the multiplicative factor of the measure defined in Definition 2 in each summand as the \u03b1-factor. The \u03b1-factor is maximal when #(Na\u227bb) = #(Nb\u227ba) = n/2, and we will often set \u2113= 4 so that the \u03b1-factor is at most 1. \u2113is a normalising factor left open in line with Esteban and Ray 1994. Intuitively, as \u03b1 increases in Definition 2, the relevance of the size of the disagreeing sub-population increases. The following example presents the limit case of \u03b1 = 0 where the size of disagreeing sub-populations is ignored, resulting in a different divisiveness ranking than \u03b1 = 1.\nExample 1. Consider 2k agents giving their preferences in profile P over issues I = {a, b, c, d, e, f} as such:\nAssume now that k = 5 and \u2113= 4 (the normalising factor). Table 1 presents, for issue a, the table of disagreements (in terms of Borda score difference) between the 5 possible sub-populations defined by the pairwise comparisons of a with the remaining issues.\n<div style=\"text-align: center;\">Issue x s(Pa\u227bx) s(Px\u227ba) disagreement \u03b1-factor</div>\nP\u227b\nP\u227b\nb\n0.8\n0.46\n0.3\n0.36\nc\n0.46\n0.8\n0.3\n0.36\nd\n0.8\n0.2\n0.6\n1\ne\n0.8\n0.2\n0.6\n1\nf\n0.8\n0.2\n0.6\n1\nTable 1: Details of the calculations for divisiveness for issue a, setting \u2113= 4 and k = 5 and with s = Borda.\nFrom Table 1, we can compute DivBorda 0 (a, P) by averaging the disagreements and weighting by the \u03b1-factors to obtain DivBorda 1 (a, P). Repeating this process for every issue gives us the values of divisiveness in Table 2. The most divisive issue for DivBorda 0 is b and c, who are at the opposite extreme of the ordering for the first agent with respect to the rest of the population, while the most divisive for DivBorda 1 are a and e, who are second or\n<div style=\"text-align: center;\">x Borda(x, P) DivBorda 0 (x, P) DivBorda 1 (x, P)</div>\n P\n P\n P\na\n0.5\n0.493\n0.408\nb\n0.9\n1\n0.36\nc\n0.1\n1\n0.36\nd\n0.6\n0\n0\ne\n0.5\n0.493\n0.408\nf\n0.4\n0\n0\nTable 2: Normalised Borda score and divisiveness for \u03b1 = 0, 1 of issues in th profile of Example 1 with k = 5 and \u2113= 4.\n<div style=\"text-align: center;\">Table 2: Normalised Borda score and divisiveness for \u03b1 = 0, 1 of issues in the profile of Example 1 with k = 5 and \u2113= 4.</div>\nsecond-to-last for all agents, yet this divides the population into two. Observe that this holds for any k \u22655, showing a class of examples where the ranking of \u03b1-divisiveness differs significantly depending on if \u03b1 = 0 or \u03b1 = 1.\n# 2.3 Rank-variance\nRelated literature in the social sciences often measures polarisation using notions of variance, which we now adapt to rankings. Let \u00b5P(a) = 1 n \ufffd i\u2208N rank(a, \u227bi) be the average rank of an issue a \u2208I in a profile of rankings P. The rankvariance of issue a is defined as follows:\n\ufffd The following example shows a profile in which the ranking of issues by variance differs from divisiveness (assuming \u03b1 = 0 and s = Borda).\n\ufffd The following example shows a profile in which the ranking of issues variance differs from divisiveness (assuming \u03b1 = 0 and s = Borda). Example 2. Consider the following preference profile:\nExample 2. Consider the following preference profile:\nThe rank-variance and the divisiveness using Borda and \u03b1 = 0 for each issue is the following:\nThe rank-variance and the divisiveness using Borda and \u03b1 = 0 for each issue\nThis shows that issue c has higher variance than issues b and d but lower divisiveness (Kendall\u2019s tau correlation between the two rankings is \u03c4 \u22480.5).\nThis shows that issue c has higher variance than issues b and d but lower divisiveness (Kendall\u2019s tau correlation between the two rankings is \u03c4 \u22480.5). Unlike other notions of polarisation, we focus on the comparisons between our divisiveness measures and rank-variance as they both return information about a single issue rather than about the population as a whole.\n \u2248 Unlike other notions of polarisation, we focus on the comparisons between our divisiveness measures and rank-variance as they both return information about a single issue rather than about the population as a whole.\n# 3 Measuring Divisiveness and Polarisation\nIn this section, we present some basic properties of our definition of divisiveness, showing in particular that with \u03b1 = 0 it does not coincide nor is correlated with standard notions of polarisation. We also show how our definitions can be used to identify the sub-population that is most divided on an issue.\n# 3.1 Divisiveness Bounds\nWe first observe that if s is a polynomially computable function, then so is Divs \u03b1 for any \u03b1. Moreover, if s is anonymous and neutral (as in the classical social choice terminology2) so is Divs \u03b1 for any \u03b1. A direct consequence of our definitions is that 0 \u2264Divs \u03b1(a, P) \u22641, for any \u03b1. We now characterise the extremes of the spectrum. First we give the sufficient conditions for minimal divisiveness with the Borda and Copeland scorings. Let a profile P be rank-unanimous on a if for all i, j \u2208N we have that rank(a, \u227bi)=rank(a, \u227bj). Profile P is unanimous if \u227bi=\u227bj for all i, j \u2208N. The next result shows that divisiveness is minimal when consensus is maximal, following this, we will discuss the converse of this statement in a few different ways.\nProposition 1. If profile P is rank-unanimous on a then DivBorda \u03b1 (a, P) = 0, while not necessarily true for DivCop \u03b1 . If P is unanimous, then DivCop \u03b1 (a, P) = 0 for all a \u2208I.\nProposition 2. If P is fully polarised and n is even, then DivBorda \u03b1 (a, P) = 1 when \u2113= 4, where a is the top-ranked issue in one of the two sub-populations. If P is fully polarised and n is odd, then DivCop \u03b1 (a, P) equals the \u03b1-factor.\nProof. If P is fully polarised and n is even, then each summand of DivBorda \u03b1 (a, P) is 1, as all agents in Na\u227bb rank a first, all in Nb\u227ba rank a last, and #(Na\u227bb)=#(Nb\u227ba). Thus, DivBorda \u03b1 (a, P)=1. If P is fully polarised and n is odd, then a is a Condorcet winner in the larger sub-population and a Condorcet loser in the other. Thus, Divs(a, Na>b, P)=1 for each b \u2208I\\{a}. As sub-populations differ by 1, DivCop \u03b1 (a, P) = \ufffd n2\u22121 n2 \ufffd\u03b1 when \u2113= 4.\n\ufffd \ufffd In fully polarised profiles, two issues have maximal divisiveness: the topranked issues in \u227b1 and \u227b2. Moreover, in any profile, at most two issues can have maximal divisiveness. Finally, uniform profiles contain each of the m! possible rankings over the m issues, and each ranking is equally represented in the profile (note that n is even). They represent a fully noisy population of preferences. While the measure of polarisation proposed by Can et al. 2015 cannot distinguish between uniform and fully polarised profiles, we show that the ranking of divisiveness is strict in the former while in the latter all issues have the same divisiveness. The following proposition is straightforward due to the symmetry of uniform profiles:\n# Proposition 3. If P is a uniform profile, then Divs \u03b1(a, P) = Divs \u03b1(a, P) for all a, b \u2208I.\nFor a uniform profile P, DivBorda \u03b1 (a, P) = 1 m\u22121 when \u2113= 4, as the average Borda score between two sub-populations Na\u227bb and Nb\u227ba differs by 1/m\u22121. Whereas DivCop \u03b1 (a, P) = 1 when \u2113= 4, as the divide of the two sub-populations always ensures that a always wins every majority contest in Na\u227bb and always loses in Nb\u227ba.\n# 3.2 Divisiveness and Rank Variance\nWe conducted experiments on synthetic preference profiles to test whether divisiveness with \u03b1 = 0 correlates with the rank-variance defined in Section 2.3. We computed Kendall\u2019s tau correlation (KT) of DivBorda 0 and DivCop 0 with the rank variance (cf. Section 2.3). We tested 100 profiles of rankings generated via the impartial culture (IC) and the Urn model with a correlation of 10% and 50% (named UM10 and UM50, respectively). Rankings were generated using the PrefLib library [Mattei and Walsh, 2017, 2013]. Using the Urn model with 10% correlation as an example, we plot in Figure 1 the average Kendall\u2019s tau correlation. We observe that the three measures are correlated when profiles are on a few issues but that the values of correlation decrease significantly as we increase the number of issues, and therefore increase the possible rankings for the measures to return. The correlation between the rank variance and the divisiveness computed using Borda is higher than using Copeland. The correlation between divisiveness using Borda and divisiveness using Copeland shows a similar decreasing trend. Similar results are captured for the impartial culture scenario, but the correlation decreases even more for\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/159a/159a543e-e0f0-430c-ae3a-23aa32ed2649.png\" style=\"width: 50%;\"></div>\nFigure 1: The average Kendall\u2019s tau correlation between each pair of divisiveness rankings using Borda and Copeland with \u03b1 = 0, and the rank variance, varying the number of issues. The average is taken from 100 profiles with 100 agents generated by UM10.\nthe case of KT(DivBorda 0 , DivCop 0 ) and KT(DivCop 0 , Variance). A possible explanation of this decreasing correlation is that rank-variance only considers an issue\u2019s position in each individual ranking discarding which the rankings\u2019 structures (which are ranked above or below the issue in question). Additional details and figures can be found in the Appendix.\n# 3.3 Maximally Divided Sub-Populations\nIn addition to providing a ranking of issues based on their divisiveness, Definition 2 can also be used to identify the partition that maximally divides the population for an issue. This is a seemingly hard computational problem, as there is an exponential number of sub-populations to consider, but we show that it can be solved efficiently for the Borda score.\nProposition 4. For any profile P and issue a \u2208I, finding the sub-population X \u2286N that maximises DivBorda 0 (a, X, P) can be done in polynomial time.\nProof. Consider an arbitrary preference profile P. For an arbitrary issue a \u2208I, we will use the following algorithm to find the sub-population X such that DivBorda 0 (a, X, P) is maximal. We first order the agents with respect to their ranking of issue a. Thus, without loss of generality, we can assume that for each i \u2208[1, n \u22121] we have that rank(a, \u227bi) \u2265rank(a, \u227bi+1). Note that if two agents rank a at the same level, their ordering is irrelevant. We will now prove\nthat any sub-population X that gives the maximum value of DivBorda(a, X, P) will partition N such that for some k \u2208[1, n \u22121] we have that X = {1, \u00b7 \u00b7 \u00b7 k} and thus N\\X = {k + 1, \u00b7 \u00b7 \u00b7 , n}. Our polynomial algorithm then tests each of the n \u22121 partitions defined by Xk = {1, \u00b7 \u00b7 \u00b7 , k} and returns the one that maximises DivBorda 0 (a, Xk, P). Clearly, in each of these partitions Xk, calculating DivBorda 0 (a, Xk, P) can be done in polynomial time. We now prove that any X that maximises DivBorda 0 (a, X, P) is of the form Xk = {1, \u00b7 \u00b7 \u00b7 , k} for some k. To do so, we consider some X such that there exists some i \u2208X yet i \u2212z /\u2208X, for z \u2208[1, i \u22121]. We need to show that the set X \u2032 = (X\\{i}) \u222a{i \u2212z} is more divisive than X, thus DivBorda 0 (a, X \u2032, P) \u2265 DivBorda 0 (a, X, P). It is clear that Borda(a, PX ) \u2264Borda(a, PX \u2032) due to our assumption on the ordering of the agents in P in decreasing order of rank of a. For similar reasons, we have that Borda(a, PN \\X ) \u2265Borda(a, PN \\X \u2032). Therefore, it must be the case that DivBorda 0 (a, X \u2032, P) \u2265DivBorda 0 (a, X, P). Thus, we can transform any X that maximises divisiveness into a sub-population of the form Xk by performing a finite number of swaps, as described above. Determining the complexity of finding maximally divided sub-populations under DivCop 0 does not seem trivial, and we leave it as an open problem.\n# 4 Divisiveness Control\nManipulation and control have been widely studied for rank aggregation procedures. Manipulation is when an individual misrepresents their reported ranking to improve the score of their favourite candidate. A classical result showed that manipulation can be performed in polynomial time for the Borda score [Bartholdi et al., 1989]. Instead, control is when an external agent aims at altering the score of a designated candidate by performing actions such as removing agents or candidates from the profile of ranking. To give an example, preventing a candidate from being the Copeland winner by adding new rankings was shown to be a computationally hard problem. For an introduction to the computational complexity of these problems, we refer to the survey from Faliszewski and Rothe 2016. In this section, we focus on two approaches to control the measure of divisiveness: (i) by removing pairwise comparisons from the agents\u2019 rankings and (ii) by adding new agents (which could, e.g., be performed by bots on any platform that crowdsources individual preferences). This section focuses on the less studied divisiveness measure with \u03b1=0 and hence we omit \u03b1 from Divs \u03b1.\n# 4.1 Removing Pairwise Comparisons\nThis section studies the disruption of the divisiveness measure by the deletion of pairwise comparisons from the rankings. This can be thought of as sabotage, as the control actions here do not have a clear goal, e.g., making a single issue the most divisive one. Instead, the aim of this control problem is to disrupt the\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7964/79647e43-faef-40b8-86e9-0d8040f9a56c.png\" style=\"width: 50%;\"></div>\nFigure 2: The average Kendall\u2019s tau correlation between the divisiveness ranking under DivBorda 0 computed on the full ranking with respect to incomplete rankings. The horizontal axis shows the percentage of pairwise comparisons of the incomplete profile with respect to the complete one. The experiment is run on 100 preference profiles drawn from UM10. The different markers on the lines represent different numbers of issues in {4, 6, 8, 10, 14, 18}\ndivisiveness ranking such that it no longer resembles the ranking under complete preferences. To do so, we evaluate through simulations what percentage of pairwise comparisons of the agents\u2019 full rankings are required to be able to compute the divisiveness measure accurately. As we are removing parts of the rankings given by the agents, we need to compute divisiveness on incomplete rankings as in the original definition by Navarrete et al. 2022. When s = Cop, we see that the definition of divisiveness is well-defined on incomplete rankings. However, on incomplete rankings, we use the win rate instead of Borda when calculating the divisiveness, noting that they are equivalent on complete rankings. We define the win rate of an issue a to be \ufffd b\u2208I\\{a} #(Na>b) #(Na\u227bb\u222aNb\u227ba)\u00b7(m\u22121). We generated 100 profiles for each of the three preference generation methods IC, UM10, and UM50, varying the number of issues m \u2208[3, 18]. We compared the average Kendall\u2019s tau correlation between the divisiveness ranking computed on the full rankings and the adapted measure of divisiveness computed on subprofiles containing X% of the pairwise comparisons of the complete one (X \u2208 [10, 100] increasing by increments of 10). Here, pairwise comparisons are deleted from the profile at random. We highlight a single figure from these simulations to illustrate and leave the remainder of the figures in the Appendix. The main message of this simulation is that disrupting divisiveness by delet-\ning pairwise comparisons is easy. Figure 2 focuses on the case when the average KT is taken over 100 profiles with 100 agents created via the UM10 method. It shows that if there are sufficiently many issues (say more than 10), then deleting between 10 and 20% of the pairwise comparisons in the profile is sufficient to significantly decrease the accuracy of divisiveness (the correlation between complete and incomplete divisiveness is below 0.5). We also observe an inversion of the curves when the number of issues exceeds 6, tending towards an exponential shape. Our findings imply that with a large number of issues and under the assumption of moderately correlated preferences, the almost-totality of the pairwise comparisons needs to be elicited from agents to obtain an accurate measure of divisiveness.\n# 4.2 Control by Adding Rankings\nThe next form of control we study is the addition of fake rankings by an external agent. Modelling this type of control is particularly realistic when the divisiveness measures are used in online forums, where attacks by bots are commonplace (such as in the experimental setting of Navarrete et al. 2022). Similar problems were previously studied in the literature, such as Sybil attacks in online elections [Meir et al., 2022]. We start by presenting an example in which a single agent is able to alter the divisiveness ranking.\nExample 3. Consider four agents and four issues I = {a, b, c, d}. Consider that three agents have submitted their preferences, one agent with \u227b1, and two with \u227b2. The fourth agent has the truthful preference of \u227b3:\nExample 3 shows that one agent can manipulate the divisiveness measure. We now show that the problem of control by adding rankings can be solved easily by showing a simple heuristic, which we call Injects. Injects takes as input a profile P and an issue a which it aims to make the most divisive by adding new agents to the profile. It first computes the ranking over issues defined by s(x, P), which we denote by \u227bs. This is used\nto create the two rankings which will be added to the profile to increase the divisiveness of a, namely \u227bodd and \u227beven. The former modifies \u227bs by putting issue a first and leaving the rest of the ranking unchanged. The latter modifies \u227bs symmetrically by putting a in the last position and leaving the remaining part of the order unchanged. In this way, \u227bodd and \u227beven resemble the ranking of agreements computed using s, with the only difference being the position of a that alternates between first and last. Injects then alternates between adding \u227bodd and \u227beven to profile P until the issue a is the most divisive. We show that Injects always terminates and succeeds in making the target issue the most divisive.\nProposition 5. InjectBorda always terminates for \u03b1 = 0.\nProof. Let a be the target issue. If a is already the most divisive issue in P then InjectBorda terminates immediately. Else, we first prove that DivBorda(a, P\u2032) > DivBorda(a, P) for any profile P\u2032 obtained by using InjectBorda on a profile P. Take an arbitrary profile P, issue a \u2208I, and k such that P\u2032 = (P, (k, \u227bodd), (k, \u227beven)), where N \u2032 are the agents in P\u2032. Take an arbitrary b \u2208I\\{a}, we have that DivBorda(a, N \u2032 a\u227bb, P\u2032) > DivBorda(a, Na\u227bb, P) as Borda(a, P\u2032 a\u227bb) \u2265Borda(a, Pa\u227bb) and Borda(a, Pb\u227ba) \u2265Borda(a, P\u2032 b\u227ba), with at least one of the two inequalities being strict. To see this, observe that all injected agents rank a the highest in P\u2032 a\u227bb and the lowest in P\u2032 b\u227ba (and a is not the most divisive issue). Thus, we proved that DivBorda(a, P\u2032) tends to 1 as k increases. To conclude, note that the rank of any issue b \u2208I\\{a} in the injected sub-profile ((k, \u227beven),(k, \u227bodd)) varies only by one position. Thus, with k large enough the divisiveness of any issue b \u0338= a cannot tend to 1.\nProof. Let k = 2n + 2 and a be the target issue, where n is the number of voters in P. By definition, DivCop 0 (a, P\u2032) = 1/m\u22121 \ufffd b\u2208I\\{a} |Cop(a, P\u2032 a\u227bb) \u2212 Cop(a, P\u2032 a\u227bb)|. As k is sufficiently large, for all b \u2208I\\{a} we have that a is a Condorcet winner in P\u2032 a\u227bb, since n + 1 copies of \u227bodd were added with a as the top issue. Symmetrically, a is a Condorcet loser in P\u2032 b\u227ba. Thus, we have that Cop(a, PNa\u227bb) = 1 and Cop(a, PNb\u227ba) = 0, which in turn implies that DivCop 0 (a, P\u2032) = 1. By the uniqueness of a Condorcet winner, we have that no other issue b \u0338= a can have DivCop 0 (b, P\u2032) = 1, concluding the proof.\nThe previous results shows that Injects can manipulate the divisiveness ranking. However, it does not provide a bound on how many agents InjectBorda are required and only provides a large bound for InjectCop, namely k = 2n+2. To complement this, we conducted simulations to estimate how many new agents Injects needs to alter the divisiveness ranking. For each m \u2208[2, 11] and each of three profile generation methods (IC, UM10, UM50), we considered 100 profiles to test how many new agents Injects required to make the target issue the most divisive. Figure 3 focuses on IC profiles with 8 issues. It shows the divisiveness rankings of the 8 issues in the initial profile (at 0%) and their evolution when\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2ef6/2ef611a7-7bd2-40d8-b5bb-e7033e4c1e20.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">0% 20% 40% 60% 80% New agents (%)</div>\n<div style=\"text-align: center;\">Figure 3: Percentage of new agents added by InjectBorda to make the least divisive issue the most divisive. The average divisiveness of the other issues is also plotted in grey. Averages are computed over 100 IC profiles of 100 agents and 8 issues.</div>\nInjectBorda inserts additional rankings to make the least divisive issue the most divisive (the highlighted line at the 8th position). In particular, by adding around 35% new agents we can make the least divisive issue the most via our simple algorithm. In crowdsourcing applications with wide participation this percentage implies that too many additional agents might need to be injected without being noticed. Yet, we recall that Injects is a simple heuristic, and this percentage could be lower with a more efficient procedure. Furthermore, we see that the average divisiveness ranking of the other issues converges to the middle of the ranking. We obtained similar results by varying the number of issues and the profile generation methods (we give more details in the Appendix). We also tested how many additional agents InjectBorda required to reach easier targets, such as making either the second most divisive issue or an issue in the middle of the divisiveness ranking the most divisive issue. Figure 4 presents our findings for s = Borda and m = 8, computed on 100 profiles generated using either IC or UM50. Clearly, if the task of control is harder, InjectBorda needs additional agents to meet its target. More importantly, if we compare the performance of InjectBorda on different preference generation methods, we see that more correlated profiles (using UM50 in our case) are harder to control no matter the target issue. Given the results, we see that Injects can be an effective way of manipulating, but it simulates a static scenario. We also note that this way of manipulat-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6266/6266f9d2-9336-4b04-b531-e5c3dc51743a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">0% 25% 50% 75% New agents (%)</div>\ning requires very little information about the original profile, i.e., the controlling agent just need to know the current ranking of agreement given by the scoring s. Furthermore, our results show that Injects can be used just to increase an issue\u2019s rank in the divisiveness ranking, rather than insisting that it becomes the most divisive. Additional details can be found in the Appendix.\n# 5 Conclusions and Future Work\nThis paper extends the notion of divisiveness given by Navarrete et al. [2022] to a family of measures and applies them to complete rankings over issues. We ground these measures by highlighting their behaviour at limit cases and comparing them to other notions of disagreement and polarisation. We also point out how we can find a sub-population for which an issue is most divisive in polynomial time when considering the Borda score, yet, no such algorithm was found for the Copeland score. The main contribution of this paper is the study of the robustness of the divisiveness measures to external control. We showed via simulations that by randomly removing pairwise comparisons from the rankings, the correlation between the divisiveness ranking of the full vs partial rankings can drop significantly, especially when there are many issues. Furthermore, we show that a simple algorithm can affect the divisiveness ranking\nby inserting (a possibly large number of) controlled fake rankings. This paper opens many directions for future work. First, how can our divisiveness measures be modified to be more robust to external control. Second, our divisiveness measures can be used to compare how divisive or polarised is a given population (instead of focusing on comparisons of single issues). Finally, following in the social choice theory tradition, we will explore axiomatic characterisations of divisiveness.\n# References\nIn all of our experiments, we built profiles of 100 agents, giving a ranking of the issues, the number of which varied from 3 to 18. The profiles were created using three different methods, namely impartial culture (IC) and the urn culture with 10% and 50% correlation (UM10 and UM50) using the tools provided by PrefLib Mattei and Walsh [2013, 2017]; Mattei [2022]. IC means that when there are m issues, each of the possible m! rankings are chosen uniformly. The IC method implies that there is not much correlation between the agents; thus, we look at a profile creation method which makes agents more likely to be similar to one another, namely the urn model. We look at the urn model with two values of the similarity parameter, namely being either 10% or 50% correlated. For the urn model, we start with the m! possible rankings an agent could have over the issues. The similarity between agents is determined by this parameter which says how many of these given profiles are returned to the urn. Thus to be 50% correlated means that m! of this profile will be returned to the urn, meaning that this ranking will be chosen half of the time when selecting the following ranking. Similarly, to be 10% correlated, the model returns m!/9 copies of the ranking. Hence, UM50 provides more correlated profiles, and IC gives us random profiles. Note that when m > 18, the time to create the profiles via the urn model is difficult due to space and time constraints as 19! \u22481017. To avoid outliers, we take 100 profiles in our simulations and will average the result for this desired parameter.\n# A.1 Additional details of experiments in Section\nIn this section we give more details of the simulations conducted for Section 3.2. These simulations aim to show if there is any correlation between divisiveness (with \u03b1 = 0) with either s = Borda or s = Cop and the rank-variance (defined in Section 2.3). The purpose of this is to test if (i) the choice of scoring function impacts the divisiveness ranking and (ii) if our metrics are, in fact, the rankvariance (a known notion from the social sciences). In the main paper show that the Kendall\u2019s tau (KT) correlation between pairs of the three metrics mentioned are positive, yet around a 0.5 correlation. They differ when the 100 profiles over 100 agents are built using the UM10 method. We give more details about the other methods in Figure 5. From left to right, we inspect the KT correlation between the ranking of the issues when using the divisiveness issue with either scoring, between divisiveness with the Borda scoring and the rank-variance, and between divisiveness with the Copeland scoring and the rank-variance. In each image, we inspect the effect on the value of the KT correlation when changing the number of issues. Furthermore, we vary the number of agents in the profile with n \u2208{100, 200, 300, 400, 500}. However, this seems to have little effect on the KT score. The general trend is that the correlation decreases slightly as the number of issues increases. This is to be expected, as when there are more issues, it becomes much harder to have the same ranking as more possible combinations.\nOne interesting takeaway from these figures is that the order of the lines of which profile creation method at the two measures more correlated changes depending on the variance. We see that KT(DivBorda 0 , DivCop 0 ) and KT(DivCop 0 , V ar) have that they are more correlated when using UM10 and UM50 to create the profiles and less correlated using IC. KT(DivBorda 0 , V ar) is more correlated with IC than UM10 and UM50. In particular, we see that the correlation KT(DivBorda 0 , V ar) is generally higher than the others. This could be to do with the similar nature of the measures, in that both use the position in the agents\u2019 rankings. In contrast, the correlation between either of the other two and Copeland is lower as it looks at which issues are being beaten. Furthermore, we conjecture that on IC profiles KT(DivBorda 0 , V ar) is highly correlated as the size of the subgroups in divisiveness are generally equal, and thus, the impact of not using the group sizes is not coming into play.\n# A.2 Additional details of the experiments in Section 4.1\nThe robustness of rank aggregators has been widely studied, either in terms of communication complexity, i.e., bounding how much information needs to be elicited to compute the full ranking Conitzer and Sandholm [2005], or, more recently, by assessing the effect of perturbations of the input Kahng et al. [2019]. In this section we evaluate, via simulations, how many queries on pairwise comparisons are needed from voters to compute a robust notion of divisiveness (assuming \u03b1 = 0, for s = Borda and s = Cop). The pairwise comparisons from the agents\u2019 full rankings are removed at random. Here, we focus on n = 100 and 100 profiles of each type and take the average over each of the correlations. As we are removing parts of the rankings given by the agents, we need to compute divisiveness on incomplete rankings as in the original definition by Navarrete et al. 2022. When s = Cop, we see that the definition of divisiveness is well-defined on incomplete rankings. However, on incomplete rankings we use the win rate when calculating the divisiveness instead of Borda, noting that they are equivalent on complete rankings. We define the win rate of an issue a to be \ufffd b\u2208I\\{a} #(Na>b) #(Na\u227bb\u222aNb\u227ba)\u00b7(m\u22121). In Figure 6, we show the impact of removing pairwise comparisons from the agents\u2019 rankings on how accurate the divisiveness measure is on a partial profile. We focus on m \u2208{4, 10, 18}, shown in the figures from left to right. As a general trend, when there are more issues, we need more information about the full rankings for the divisiveness ranking to be more accurate. For the average KT score to be at least 0.5, we need roughly 20%, 70%, and 90% of the ranking when the numbers of issues are 4, 10, and 18, respectively. Moreover, we see that when the profiles are less correlated, i.e., created with the IC method, more pairwise comparisons are required than the other methods to be as accurate. Lastly, the choice of score does not make much of a difference. One takeaway from these simulations is that for many issues, it is hard to predict the divisiveness ranking under incomplete information accurately. Thus, there can be an element of control, as if the agents are restricted to answering\na subset of pairwise comparisons, then it may be possible to make one issue divisive easily.\n# A.3 Additional details of experiments in Section 4.2\nIn this section we inspect the simulations to complement the results in Section 4.2, where we showed that a simple heuristic (described in Section 4.2) can change the divisiveness ranking such that a target issue becomes the most divisive in the ranking by adding in extra controlled agents, which can be thought of as bots or Sybil agents. These simulations reflect the robustness of the divisiveness measures when used in online contexts where the creation of additional agents is possible. In Figure 7 we show the effect of the heuristic on 100 profiles for each creation method (IC, UM10, and UM50) with 10 issues and 50 agents in the original profile using s = Borda and \u03b1 = 0. The purpose of these images is to show the effect on all of the issues when the target issue originally was the least divisive. For each plot in Figure 7, we see that the divisiveness of the non-target issues slightly tends to the middle rankings but generally remains roughly the same (each of the grey lines). Next, we see that the more correlated the agents are, the longer it takes the final issue in the divisiveness ranking to become the most divisive issue using this heuristic. Thus, the IC profiles have the target issue becoming the most divisive much more quickly than the UM10 profiles, which in turn has the least divisive issue becoming the most, more rapidly than in the UM50 profiles. Note that when computing the same when s = Cop, that the images are very similar. To complement Figure 4 We now inspect the effect of the number of issues on n = 100 and 100 profiles for each m \u2208{4, \u00b7 \u00b7 \u00b7 , 10} and each profile creation method IC, UM10, UM50 (corresponding to the yellow, red, and purple lines, respectively, in the figure). In general, the number of additional agents required is affected much by the number of issues in the profile. An intuitive aspect seen in the figure is that the fewer positions required for InjectCop to move the target issue, the fewer extra agents are needed, i.e., more agents are required to make the least divisive issue the most, rather than the second most divisive issue the most. A significant takeaway from the simulations seen in the figures is that profiles created with the IC method are very easily manipulated by InjectCop, with even 10 issues and the target issue being initially the least divisive issue that only 10% extra agents are required. With more correlated profiles, i.e., made with UM10 and UM50, we see that more agents are required to manipulate the divisiveness ranking. We see that around an additional 50% of the agents are required to make the least divisive issue the most in significantly correlated profiles. Hence, the heuristic is an effective way of manipulating the divisiveness ranking. Furthermore, for more modest aims, such as making the second most divisive issue the most, it seems possible by adding 15% new agents for UM10 and 25% for UM50.\nThe same experiment for s = Borda produces similar figures, yet with slightly more noise.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/cb36/cb369a15-279e-4564-8b86-7f0778bb6d33.png\" style=\"width: 50%;\"></div>\nFigure 5: Kendall\u2019s tau correlation between divisiveness using Borda and divisiveness using Copeland; divisiveness using Borda and rank-variance; divisiveness using Copeland and rank-variance (from top to bottom). We measure the correlation against the number of issues the 100 agents have given a ranking on. The colours represent the methods used to create the rankings, and the style of the lines represents the number of agents n \u2208{100, 200, 300, 400, 500}. 23\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4af5/4af55400-c2e2-4fec-930e-9048e9525e02.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">20 40 60 80 100 % of pairs</div>\nFigure 6: KT correlation between the divisiveness given every agent\u2019s full rankings are known and when only a certain percentage of the full preferences are known computed using both the Borda or Copeland scoring (represented by the solid and dashed line, respectively). The colours represent the methods to create the rankings, IC, UM10, UM50. 24\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/89f9/89f9bf8b-f163-48d7-9e54-b9e3ded8e12a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 7: The effect of the heuristic InjectBorda on 100 profiles built using the method UM10, UM50 and IC, respectively from left to right with 50 agents and 10 issues. The red line highlights the target issue, the last issue in the divisiveness ranking, becoming more divisive via the addition of new agents via InjectBorda.</div>\nFigure 7: The effect of the heuristic InjectBorda on 100 profiles built using the method UM10, UM50 and IC, respectively from left to right with 50 agents and 10 issues. The red line highlights the target issue, the last issue in the divisiveness ranking, becoming more divisive via the addition of new agents via InjectBorda.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e715/e7159a53-e4ad-44f5-ab18-7ee560d32476.png\" style=\"width: 50%;\"></div>\nFigure 8: This figure shows the effect of the number of issues for each of the different profile creation methods on the number of new agents required by InjectCop to make the target issue a the most divisive issue. From left to right, a begins, in the original profile, being the second most divisive issue, middle of the divisiveness ranking, and the least divisive issue.\n<div style=\"text-align: center;\">Figure 8: This figure shows the effect of the number of issues for each of the different profile creation methods on the number of new agents required by InjectCop to make the target issue a the most divisive issue. From left to right, a begins, in the original profile, being the second most divisive issue, middle of the divisiveness ranking, and the least divisive issue.</div>\n",
    "paper_type": "theory",
    "attri": {
        "background": "This paper addresses the issue of rank aggregation, focusing on identifying divisive issues that express disagreements among individual preferences, which has been less explored compared to measuring consensus.",
        "problem": {
            "definition": "The problem is to quantify disagreements in collective decision-making by measuring the divisiveness of issues based on individual rankings.",
            "key obstacle": "The main challenge is the lack of robust measures to identify divisive issues in the presence of incomplete preferences and the manipulation of divisiveness."
        },
        "idea": {
            "intuition": "The idea was inspired by the need to differentiate between consensus and divisiveness in collective decision-making.",
            "opinion": "The authors propose a family of functions to measure divisiveness, which can adapt to different levels of consensus and minority preferences.",
            "innovation": "The primary improvement compared to previous methods is the introduction of parameterized measures of divisiveness that can relate to existing notions of polarization."
        },
        "Theory": {
            "perspective": "The theoretical framework relates divisiveness to established concepts of polarization and disagreement in social choice theory.",
            "opinion": "The authors assume that traditional measures of polarization do not adequately capture the nuances of divisiveness.",
            "proof": "The paper provides theoretical bounds and properties of the proposed divisiveness measures, demonstrating their robustness under various conditions."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted using synthetic preference profiles generated via three methods (IC, UM10, UM50) with varying numbers of issues (3 to 18) and agents (100).",
            "evaluation method": "The evaluation involved computing divisiveness measures and assessing their correlation with rank-variance, as well as simulating scenarios of control through manipulation of rankings."
        },
        "conclusion": "The paper concludes that the proposed divisiveness measures are effective in capturing disagreements within a population and can be manipulated through external control, highlighting the need for robustness in these measures.",
        "discussion": {
            "advantage": "The advantage of this paper is its novel approach to measuring divisiveness, providing a clearer understanding of how preferences can be polarized.",
            "limitation": "A limitation is the potential difficulty in accurately measuring divisiveness with incomplete rankings and the computational complexity involved in some scenarios.",
            "future work": "Future work could focus on enhancing the robustness of divisiveness measures against manipulation and exploring their applications in broader contexts."
        },
        "other info": [
            {
                "info1": "All code related to the experiments is available at https://github.com/CenterForCollectiveLearning/divisiveness-theoretical-IJCAI2023."
            },
            {
                "info2": {
                    "info2.1": "The paper builds on previous work by Navarrete et al. (2022) regarding divisiveness in political preferences.",
                    "info2.2": "The experiments included 100 profiles for each preference generation method to ensure statistical significance."
                }
            }
        ]
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper addresses the issue of rank aggregation, focusing on identifying divisive issues that express disagreements among individual preferences, which is significant in understanding collective decision-making."
        },
        {
            "section number": "2.1",
            "key information": "The problem is defined as quantifying disagreements in collective decision-making by measuring the divisiveness of issues based on individual rankings."
        },
        {
            "section number": "2.3",
            "key information": "The theoretical framework relates divisiveness to established concepts of polarization and disagreement in social choice theory, suggesting that traditional measures of polarization do not adequately capture the nuances of divisiveness."
        },
        {
            "section number": "5.3",
            "key information": "The paper proposes a family of functions to measure divisiveness, which can adapt to different levels of consensus and minority preferences, highlighting its innovative approach to problem-solving."
        },
        {
            "section number": "6.2",
            "key information": "The paper discusses how the proposed divisiveness measures can highlight the polarization of preferences, impacting logical reasoning and decision-making processes."
        },
        {
            "section number": "8",
            "key information": "The paper concludes that the proposed divisiveness measures are effective in capturing disagreements within a population and suggests future work to enhance their robustness against manipulation."
        }
    ],
    "similarity_score": 0.5094859305780226,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-1142_cogni/papers/Measuring and Controlling Divisiveness in Rank Aggregation.json"
}