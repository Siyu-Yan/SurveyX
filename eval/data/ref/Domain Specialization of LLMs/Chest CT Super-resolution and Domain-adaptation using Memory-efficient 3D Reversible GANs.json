{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1908.00295",
    "title": "Chest CT Super-resolution and Domain-adaptation using Memory-efficient 3D Reversible GANs",
    "abstract": "Recently, paired (e.g. Pix2pix) and unpaired (e.g. CycleGAN) image-to-image translation methods have shown effective in medical imaging tasks. In practice, however, it can be difficult to apply these deep models on medical data volumes, such as from MR and CT scans, since such data volumes tend to be 3-dimensional and of a high spatial resolution pushing the limits of the memory constraints of GPU hardware that is typically used to train these models. Recent studies in the field of invertible neural networks have shown that reversible neural networks do not require to store intermediate activations for training. We use the RevGAN model that makes use of this property to perform memory-efficient partially-reversible image-to-image translation. We demonstrate this by performing a 3D super-resolution and a 3D domain-adaptation task on chest CT data volumes.",
    "bib_name": "vanderouderaa2019chestctsuperresolutiondomainadaptation",
    "md_text": "Medical Imaging with Deep Learning 2019\n# Chest CT Super-resolution and Domain-adaptation using Memory-efficient 3D Reversible GANs\nTycho F. A. van der Ouderaa1,2 tychovdo@gmail.co Daniel E. Worrall1 d.e.worrall@uva.n Bram van Ginneken2 bram.vanginneken@radboudumc.n\nTycho F. A. van der Ouderaa1,2 Daniel E. Worrall1 Bram van Ginneken2\nTycho F. A. van der Ouderaa1,2 tychovdo@gmail.com Daniel E. Worrall1 d.e.worrall@uva.nl Bram van Ginneken2 bram.vanginneken@radboudumc.nl 1 University of Amsterdam, Amsterdam, The Netherlands 2 Diagnostic Image Analysis Group, Radboud UMC, Nijmegen, The Netherlands\n1 University of Amsterdam, Amsterdam, The Netherlands 2 Diagnostic Image Analysis Group, Radboud UMC, Nijmegen, The Netherlands\n# 1. Introduction\nRecently, paired (e.g. Pix2pix (Isola et al., 2017)) and unpaired (e.g. CycleGAN (Zhu et al., 2017)) image-to-image translation methods have shown effective in medical imaging tasks (Yi et al., 2018) (Wolterink et al., 2017). In practice, however, it can be difficult to apply these deep models on medical data volumes, such as from MR and CT scans, since such data volumes tend to be 3-dimensional and of a high spatial resolution pushing the limits of the memory constraints of GPU hardware that is typically used to train these models. Recent studies in the field of invertible neural networks have shown that reversible neural networks do not require to store intermediate activations for training (Gomez et al., 2017). We use the RevGAN model (van der Ouderaa and Worrall, 2019) that makes use of this property to perform memory-efficient partially-reversible image-to-image translation. We demonstrate this by performing a 3D super-resolution and a 3D domain-adaptation task on chest CT data volumes. 2. Problem Statement\nThe tasks addressed in this paper relates to CT imaging of the chest. Recent scanners allow for high-resolution scans with isotropic voxel sizes around or below 0.5 mm3 and this requires the reconstruction of image matrices consisting of slices of 1024\u00d71024 pixels, contrary to the traditionally used slices of 512\u00d7512 pixels. In these high-resolution scans, fine parenchymal details such as small airway walls, vasculature and lesion texture, are better visible. At the same time, the vast majority of scans available today for training networks consist of 512 matrices and often thicker slices, around 2mm. In addition, a wide variety of CT reconstruction kernels are used in practice, from more noisy high frequency kernels to smoother (soft kernels), and both traditional filtered backprojection as well as iterative reconstruction methods, varying between scanner vendors, are used (Mets et al., 2012). To produce robust and accurate image processing results, it is therefore desirable to pre-process chest CT scans to a standardized high resolution, and to remove the structural differences resulting from the use of different reconstruction algorithms. We aim to provide a proof-of-principle that we can use reversible networks to create a model capable of preprocessing CT scans to high resolution with a standardized appearance.\nc\u20dd2019 T.F.A. van der Ouderaa, D.E. Worrall & B. van Ginneken.\ntychovdo@gmail.com d.e.worrall@uva.nl\n1 x 128 x 128 x 128 1 x 128 x 128 x 128 32 x 128 x 128 x 128 32 x 128 x 128 x 128 64 x 64 x 64 x 64 64 x 64 x 64 x 64 C C\u20131 EncX EncY DecX DecY 3x3x3 3x3x3 5x5x5 5x5x5 5x5x5 5x5x5 3x3x3 3x3x3 Figure 1: Illustration of the model: Encoders EncX (green) and EncY (blue) lift/encode from the image space features spaces \u02dcX and \u02dcY . Decoders DecX (red) and DecY (purple) project/decode back to X and Y . The invertible mapping C transforms between \u02dcX and \u02dcY . 3. Method To perform memory-efficient image-to-image translation in 3D, we adapt the RevGAN model (van der Ouderaa and Worrall, 2019) that combines the Pix2pix loss (Isola et al., 2017) in Equation 1 for paired training or the CycleGAN loss (Zhu et al., 2017) in Equation 2 for unpaired training with a 3D architectures (Figure 1) and a reversible core to lower memory usage during training. For a more extensive description of the model losses, including a description of LGAN, LL1 and Lcyc, we refer to the original RevGAN paper. Paired Loss For paired training, we combine the LGAN loss with the L1 loss:\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0c3c/0c3c9c6b-a8d0-49ef-acbd-bf55856b8e9f.png\" style=\"width: 50%;\"></div>\n# 3. Method\nTo perform memory-efficient image-to-image translation in 3D, we adapt the RevGAN model (van der Ouderaa and Worrall, 2019) that combines the Pix2pix loss (Isola et al., 2017) in Equation 1 for paired training or the CycleGAN loss (Zhu et al., 2017) in Equation 2 for unpaired training with a 3D architectures (Figure 1) and a reversible core to lower memory usage during training. For a more extensive description of the model losses, including a description of LGAN, LL1 and Lcyc, we refer to the original RevGAN paper. Paired Loss For paired training, we combine the LGAN loss with the L1 loss:\nUnpaired Loss For unpaired training, we combine the LGAN loss with the Lcyc loss: Lunpaired(F, G) = LGAN(G, DX) + LGAN(F, DY ))\n+ \u03bbLcyc(G, F)\n \u03bb parameter determines the relative importance of the terms in the losses.\nThe \u03bb parameter determines the relative importance of the terms in the losse 4. Data\nSuper-resolution The Super-resolution dataset contains 18 train volumes and 5 test volumes each consisting of 671 (\u00b149) slices of size 1024 \u00d7 1024 obtained with a high-end Canon CT scanner (Aquilion ONE). We train for 125 epochs on 128\u00d7128\u00d7128 patches that were normalized in the range [-1, 1], uniformly redistributed from [-1150, 350] Hounsfield Units (HU). The source domain was generated by aggressively down-sampling 4 times in the z-dimension and 2 times in the x and y dimensions (corresponding to a typically used resolution of 512 by 512). Domain-adaptation The Domain-adaptation dataset contains 17 CT scans for training and 3 CT scans for testing from The National Lung Screening Trial (NLST) (Team, 2011). All scans were obtained by a Siemens scanner and both a smooth (B30f) and a sharper (B50f) reconstruction kernel were available. Each scan contains an average of 169 (\u00b114.7) axial 512\u00d7512 slices. We train for 125 epochs on 64\u00d764\u00d764 patches that were normalized in a range of [-1, 1], uniformly redistributed from [-1150, 350] HU.\n(1)\n(2)\nChest CT Super-resolution and Domain-adaptation using Memory-efficient 3D Reversible GANs\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/705c/705caeee-6c64-4b23-ac15-764f4fae9f58.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: Visualization of a full and patched coronal slice of the first volume in the Superresolution test set. From left to right: low-resolution input, trilinear up-sampling, paired 3D-RevGAN, unpaired 3D-RevGAN and high-resolution ground-truth.</div>\nQualitative Results In Figure 2, we present a comparison between trilinear up-sampling, paired RevGAN and unpaired RevGAN. Upon closer inspection of the more detailed structures in the CT volumes, we find that the model produces visually compelling results and often is able to correctly fill-in parenchymal details such as small airway walls, vasculature and tissue texture. The output, however, is still far from perfect, which we account to the fact that the input has been down-sampled heavily. We expect even better results when the input source images are of a higher resolution. Quantitative Results As we can see from Table 1, we are able to increase performance by adding (+R) reversible blocks, without increasing memory cost. In Table 2, we show memory savings resulting from reversible layers.\nModel\nSuper-resolution (LR\u2192HR)\nDomain-adaptation (B50f\u2192B30f)\nMAE\nPSNR\nSSIM\nMAE\nPSNR\nSSIM\nUnpaired\n0.24 \u00b1 0.007\n15.43 \u00b1 0.39\n0.44 \u00b1 0.008\n0.14 \u00b1 0.003\n14.56 \u00b1 0.22\n0.28 \u00b1 0.004\nUnpaired+2R\n0.23 \u00b1 0.014\n16.43 \u00b1 0.44\n0.50 \u00b1 0.024\n0.13 \u00b1 0.003\n17.44 \u00b1 0.20\n0.29 \u00b1 0.003\nPaired\n0.18 \u00b1 0.001\n15.89 \u00b1 0.16\n0.46 \u00b1 0.008\n0.14 \u00b1 0.001\n18.29 \u00b1 0.15\n0.33 \u00b1 0.007\nPaired+2R\n0.15 \u00b1 0.000\n18.19 \u00b1 0.08\n0.48 \u00b1 0.008\n0.10 \u00b1 0.001\n23.24 \u00b1 0.16\n0.46 \u00b1 0.009\n<div style=\"text-align: center;\">Table 1: Mean and variance2 of MAE, PSNR and SSIM scores. We can improve performance, using deeper models at the same level of memory complexity as shallow models.</div>\nTable 1: Mean and variance2 of MAE, PSNR and SSIM scores. We can improve performance, using deeper models at the same level of memory complexity as shallow models.\nDepth\nModel\nActivations (Ours)\nActivations (Naive)\n0\n630.0\n+ 2312.4\n(+ 2316.6)\n1\n644.0\n+ 2312.4\n(+ 2719.2)\n2\n652.0\n+ 2312.4\n(+ 3919.3)\n4\n700.0\n+ 2312.4\n(+ 4319.2)\n8\n748.0\n+ 2312.4\n(+ 5519.5)\nDepth\nModel\nActivations (Ours)\nActivations (Naive)\n0\n630.0\n+ 2312.4\n(+ 2316.6)\n1\n644.0\n+ 2312.4\n(+ 2719.2)\n2\n652.0\n+ 2312.4\n(+ 3919.3)\n4\n700.0\n+ 2312.4\n(+ 4319.2)\n8\n748.0\n+ 2312.4\n(+ 5519.5)\nTable 2: Memory usage (MiB) of 3D-RevGAN model on GPU on a Nvidia Tesla K40m GPU. Note that the memory cost to store activations stays constant for deeper models.\nTable 2: Memory usage (MiB) of 3D-RevGAN model on GPU on a Nvidia Tesla K40m GPU. Note that the memory cost to store activations stays constant for deeper models. 6. Conclusion\nThis study provides a proof-of-principle for learned 3D pre-processing of CT scans to high resolution with a standardized appearance. We use the RevGAN model to successfully perform memory-intensive 3D domain-adaptation and 3D super-resolution tasks, using paired and unpaired data. Thereby, this study provides additional evidence that reversibility can be useful in practical settings to lower memory requirements of deep models. Future research should determine how well the model generalizes beyond the data used in this study.\n# Acknowledgements\nWe are grateful to the Diagnostic Image Analysis Group (DIAG) of the Radboud Univer sity Medical Center and the Netherlands Organisation for Scientific Research (NWO) fo supporting this research and providing computational resources.\n# References\nAidan N Gomez, Mengye Ren, Raquel Urtasun, and Roger B Grosse. The reversible residual network: Backpropagation without storing activations. In Advances in Neural Information Processing Systems, pages 2214\u20132224, 2017. Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. arXiv preprint, 2017. OM Mets, PA De Jong, B Van Ginneken, HA Gietema, and JWJ Lammers. Quantitative computed tomography in copd: possibilities and limitations. Lung, 190(2):133\u2013145, 2012. National Lung Screening Trial Research Team. The national lung screening trial: overview and study design. Radiology, 258(1):243\u2013253, 2011. Tycho FA van der Ouderaa and Daniel E Worrall. Reversible gans for memory-efficient image-to-image translation. arXiv preprint arXiv:1902.02729, 2019. Jelmer M Wolterink, Anna M Dinkla, Mark HF Savenije, Peter R Seevinck, Cornelis AT van den Berg, and Ivana I\u02c7sgum. Deep mr to ct synthesis using unpaired data. In International Workshop on Simulation and Synthesis in Medical Imaging, pages 14\u201323. Springer, 2017. Xin Yi, Ekta Walia, and Paul Babyn. Generative adversarial network in medical imaging: A review. arXiv preprint arXiv:1809.07294, 2018. Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. arXiv preprint, 2017.\nAidan N Gomez, Mengye Ren, Raquel Urtasun, and Roger B Grosse. The reversible residual network: Backpropagation without storing activations. In Advances in Neural Information Processing Systems, pages 2214\u20132224, 2017. Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. arXiv preprint, 2017. OM Mets, PA De Jong, B Van Ginneken, HA Gietema, and JWJ Lammers. Quantitative computed tomography in copd: possibilities and limitations. Lung, 190(2):133\u2013145, 2012. National Lung Screening Trial Research Team. The national lung screening trial: overview and study design. Radiology, 258(1):243\u2013253, 2011. Tycho FA van der Ouderaa and Daniel E Worrall. Reversible gans for memory-efficient image-to-image translation. arXiv preprint arXiv:1902.02729, 2019. Jelmer M Wolterink, Anna M Dinkla, Mark HF Savenije, Peter R Seevinck, Cornelis AT van den Berg, and Ivana I\u02c7sgum. Deep mr to ct synthesis using unpaired data. In International Workshop on Simulation and Synthesis in Medical Imaging, pages 14\u201323. Springer, 2017. Xin Yi, Ekta Walia, and Paul Babyn. Generative adversarial network in medical imaging: A review. arXiv preprint arXiv:1809.07294, 2018. Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. arXiv preprint, 2017.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of memory constraints in applying deep learning models to high-resolution 3D medical imaging data, specifically chest CT scans. Previous methods have struggled to manage the volume and resolution of such data, necessitating a breakthrough approach to enhance processing capabilities.",
        "problem": {
            "definition": "The problem focuses on the challenge of processing high-resolution chest CT scans, which require reconstruction of image matrices of 1024x1024 pixels, while most training data consists of lower resolution 512x512 matrices.",
            "key obstacle": "The main difficulty is the lack of available high-resolution training data and the variability in CT reconstruction algorithms, which complicates the standardization of image processing results."
        },
        "idea": {
            "intuition": "The idea stems from leveraging reversible neural networks that eliminate the need to store intermediate activations during training, thus addressing memory limitations.",
            "opinion": "The proposed method utilizes a memory-efficient 3D reversible GAN (RevGAN) to preprocess chest CT scans to a standardized high resolution.",
            "innovation": "The key innovation lies in the adaptation of the RevGAN model, which integrates a reversible core to reduce memory usage while performing image-to-image translation tasks."
        },
        "method": {
            "method name": "3D Reversible GAN",
            "method abbreviation": "3D RevGAN",
            "method definition": "A model that combines paired and unpaired image-to-image translation losses with a reversible architecture to facilitate memory-efficient training.",
            "method description": "The method enables effective 3D super-resolution and domain adaptation of chest CT scans while minimizing memory usage.",
            "method steps": "1. Collect high-resolution CT scan data. 2. Preprocess the data using reversible GAN architecture. 3. Train the model using paired or unpaired loss functions. 4. Evaluate the model on test data.",
            "principle": "The effectiveness of the method is based on the principle of reversibility in neural networks, allowing for efficient memory usage during training without compromising performance."
        },
        "experiments": {
            "evaluation setting": "The experiments utilized two datasets: one for super-resolution with 18 training and 5 test volumes from a Canon CT scanner, and another for domain adaptation with 17 training and 3 test scans from the National Lung Screening Trial.",
            "evaluation method": "Performance was assessed using metrics such as Mean Absolute Error (MAE), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity Index (SSIM), comparing results against baseline methods."
        },
        "conclusion": "The study demonstrates the feasibility of using reversible networks for high-resolution preprocessing of chest CT scans, achieving significant memory efficiency and promising results in both super-resolution and domain adaptation tasks.",
        "discussion": {
            "advantage": "The primary advantage of the proposed method is its ability to maintain high performance in image processing tasks while significantly reducing memory requirements compared to traditional methods.",
            "limitation": "A notable limitation is that the model's performance is still influenced by the quality of input images, which were heavily down-sampled in this study.",
            "future work": "Future research should focus on improving the model's generalizability and exploring its application to other medical imaging modalities and datasets."
        },
        "other info": {
            "acknowledgements": "The authors acknowledge the support from the Diagnostic Image Analysis Group (DIAG) and the Netherlands Organisation for Scientific Research (NWO) for providing computational resources."
        }
    },
    "mount_outline": [
        {
            "section number": "1.2",
            "key information": "The paper discusses the concept of domain adaptation in the context of high-resolution chest CT scans, emphasizing its critical role in enhancing model performance for medical imaging tasks."
        },
        {
            "section number": "2.1",
            "key information": "The paper details the architecture of the 3D Reversible GAN (RevGAN), which is designed to facilitate memory-efficient training for processing high-resolution medical images."
        },
        {
            "section number": "2.2",
            "key information": "The study highlights how the 3D RevGAN method enables effective domain adaptation for chest CT scans while minimizing memory usage, thus improving performance in medical imaging."
        },
        {
            "section number": "3.1",
            "key information": "The paper presents innovations in large language models through the adaptation of the RevGAN model, which integrates a reversible architecture to enhance image processing capabilities."
        },
        {
            "section number": "4.1",
            "key information": "The paper describes the method of fine-tuning the 3D RevGAN for domain adaptation, focusing on its ability to preprocess chest CT scans to a standardized high resolution."
        },
        {
            "section number": "6.3",
            "key information": "The paper discusses challenges related to model generalization in medical imaging, noting that the performance is influenced by the quality of input images, which were heavily down-sampled."
        },
        {
            "section number": "6.4",
            "key information": "The study addresses issues of bias and fairness in the context of medical imaging, particularly concerning the variability in CT reconstruction algorithms and training data availability."
        }
    ],
    "similarity_score": 0.5554169088001838,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-15-0239_large/papers/Chest CT Super-resolution and Domain-adaptation using Memory-efficient 3D Reversible GANs.json"
}