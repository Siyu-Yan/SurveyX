{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2407.07487",
    "title": "Review-LLM: Harnessing Large Language Models for Personalized Review Generation",
    "abstract": "Product review generation is an important task in recommender systems, which could provide explanation and persuasiveness for the recommendation. Recently, Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modeling and generating ability, which could be applied in review generation. However, directly applying the LLMs for generating reviews might be troubled by the \u201cpolite\u201d phenomenon of the LLMs and could not generate personalized reviews (e.g., negative reviews). In this paper, we propose Review-LLM that customizes LLMs for personalized review generation. Firstly, we construct the prompt input by aggregating user historical behaviors, which include corresponding item titles and reviews. This enables the LLMs to capture user interest features and review writing style. Secondly, we incorporate ratings as indicators of satisfaction into the prompt, which could further improve the model\u2019s understanding of user preferences and the sentiment tendency control of generated reviews. Finally, we feed the prompt text into LLMs, and use Supervised Fine-Tuning (SFT) to make the model generate personalized reviews for the given user and target item. Experimental results on the real-world dataset show that our fine-tuned model could achieve better review generation performance than existing close-source LLMs.",
    "bib_name": "peng2024reviewllmharnessinglargelanguage",
    "md_text": "# Review-LLM: Harnessing Large Language Models for Personalized Review Generation\nQiyao Peng1, Hongtao Liu2, Hongyan Xu3, Qing Yang2, Minglai Shao1, Wenjun Wan 1 School of New Media Communication, Tianjin University, China  \nyao Peng1, Hongtao Liu2, Hongyan Xu3, Qing Yang2, Minglai Shao1, Wen 1 School of New Media Communication, Tianjin University, China 2 Du Xiaoman Financial, Beijing, China 3 College of Intelligence and Computing, Tianjin University, China 1{qypeng, shaoml}@tju.edu.cn 2{liuhongtao01, yangqing}@duxiaoman.com 3{hongyanxu, wjwang}@tju.edu.cn\n# Abstract\nProduct review generation is an important task in recommender systems, which could provide explanation and persuasiveness for the recommendation. Recently, Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modeling and generating ability, which could be applied in review generation. However, directly applying the LLMs for generating reviews might be troubled by the \u201cpolite\u201d phenomenon of the LLMs and could not generate personalized reviews (e.g., negative reviews). In this paper, we propose Review-LLM that customizes LLMs for personalized review generation. Firstly, we construct the prompt input by aggregating user historical behaviors, which include corresponding item titles and reviews. This enables the LLMs to capture user interest features and review writing style. Secondly, we incorporate ratings as indicators of satisfaction into the prompt, which could further improve the model\u2019s understanding of user preferences and the sentiment tendency control of generated reviews. Finally, we feed the prompt text into LLMs, and use Supervised Fine-Tuning (SFT) to make the model generate personalized reviews for the given user and target item. Experimental results on the real-world dataset show that our fine-tuned model could achieve better review generation performance than existing close-source LLMs.\narXiv:2407.07487v1\n# 1 Introduction\nOnline e-commerce platforms (e.g., Amazon.com) usually offer users opportunities to share reviews for items they have purchased (Sun et al., 2020). These reviews typically contain rich user preference information and detailed item attributes (McAuley and Leskovec, 2013), which can inform users about the item and improve recommendation accuracy. However, many users only provide a rating for the item but no review after purchasing the item. Therefore, review generation task has attracted more attentions (Lu et al., 2018).\nMost existing methods are based on the encoderdecoder neural network framework (Li et al., 2019, 2020; Kim et al., 2020). Earlier methods utilize discrete attribute information about users and items to generate reviews (Tang et al., 2016; Dong et al., 2017; Ni et al., 2017; Zang and Wan, 2017). For example, Tang et al. (Tang et al., 2016) utilize user/item IDs, and rating as input information, and use the RNN-based decoder for generating reviews. Recent works consider using the text information to help generating reviews, such as item titles, and historical reviews of users/items, etc (Ni and McAuley, 2018; Li and Tuzhilin, 2019). Ni et al. (Ni and McAuley, 2018) propose ExpansionNet, which also integrates phrase information from item titles and review summaries into the encoder for generating reviews. Li et al. (Li and Tuzhilin, 2019) propose a RevGAN model to generate controllable and personalized reviews from item descriptions and sentiment labels. Recently, owing to the strong reasoning and learning capabilities exhibited by Large Language Models (LLMs) (Achiam et al., 2023; Touvron et al., 2023), many researchers are extending LLMs applications in other domains, such as Recommender Systems (RS) (Xu et al., 2024). Motivated by this, in this paper, we want to preliminary explore how to extend the LLMs (e.g., Llama-3) to the review generation. Compared with other traditional generation tasks (such as poem generation), applying LLMs for the review generation in the ecommerce platforms is more challenging due to the lack of personalized information. First, most existing large language models are usually pre-trained at the corpus-level and might not capture the review style and habits of the users. This might cause the generated review to be inconsistent with user\u2019s previous reviews. Second, users are dissatisfied with many items and the corresponding reviews should be negative. However, the generated text by the LLMs is usually \u201cpolite\u201d (Touvron et al., 2023),\nwhich might lead to the model generating positive reviews for the user\u2019s dissatisfaction. Hence, in this paper, we design a framework (Review-LLM) for harnessing the LLMs to generate personalized reviews. Specifically, we reconstruct the model input via aggregating the user behavior sequence, including the item titles and corresponding reviews. In this way, the model could learn user interest features and review writing styles from semantically rich text information. Furthermore, the user\u2019s rating of the item can be used to indicate the user\u2019s satisfaction with the item. We integrate this information into the prompt input accordingly. In this way, the large language model can better perceive whether users like different items, and may prevent the model from generating more \u201cpolite\u201d reviews. Finally, we feed the input prompt text into the LLMs (Llama-3), which is subsequently fine-tuned using Supervised FineTuning (SFT) to output the review for target items. For experiments, we design different difficulty levels review generation testing dataset to verify the effectiveness of different models.\n# 2 Method\n# 2.1 Problem Formulation\nGiven the user u, item v, rating r, and user\u2019s historical interaction, review generation aims to automatically generate personalized reviews for the user u towards the target item v. Especially, the user\u2019s historical interaction is a sequence of items that the user purchased, which can be denoted as Hu = {v1, v2, \u00b7 \u00b7 \u00b7 , vh}, where h is the number of items. And corresponding rating score sequence Ru = {r1, r2, \u00b7 \u00b7 \u00b7 , rh}, where h is the number of ratings. The i-th item title and corresponding review are denoted as: T u i = {w1, w2, \u00b7 \u00b7 \u00b7 , wN} and Eu i = {w1, w2, \u00b7 \u00b7 \u00b7 , wM} respectively, where N and M are their lengths. We denote the generated review as \u02c6Y = {w1, w2, \u00b7 \u00b7 \u00b7 , wL} and L is the length; the reference review is denoted as Y = {w1, w2, \u00b7 \u00b7 \u00b7 , wL\u2032} and L\u2032 is the length.\n# 2.2 Review-LLM\nIn this section, we introduce Review-LLM for generating reviews. The key is to enhance the LLMs to learn more personalized user interest features and review writing styles based on the histories. Specifically, we propose to construct a prompt text for training the LLM-based model using a supervised fine-tuning approach. As shown in Figure 1, the\nprompt text composes of the following parts: 1) Generation Instruction: Its role is to instruct the LLMs to consider both the user\u2019s preference and historical behaviors to complete the generation task. The generation task is structured as an output of the review for the target item; 2) Input: This contains the items the user has interacted with, including the item title, review, and rating; 3) The user purchased a new item: This contains the target item title and the corresponding rating; 4) Response: This is the generated review for the target item. Then, we use the following SFT training loss to train the LLM-based review generation model:\n(1)\nwhere wi is the i-th word in the generated review and L is the length of that. The probability p(wi|w<i) is calculated by the LLM model following the next-token prediction paradigm. During the training process, we utilize the Low-Rank Adaptation (LoRA) (Hu et al., 2021) for ParameterEfficient Fine-Tuning (PEFT), which can greatly reduce the number of trainable parameters. During inference, we remove the review of the target item in the 4) Response. Then we input this modified prompt into the large language model to generate the review for the target item.\n# 3 Experiments\n# 3.1 Experimental Setting\nIn this paper, we select five open-source 5-core recommendation datasets from Amazon dataset 1, including \u201cArts, Crafts and Sewing\u201d, \u201cOffice items\u201d, \u201cMusical Instruments\u201d, \u201cToys and Games\u201d and \u201cVideo Games\u201d. We only remain users with more than 10 historical interactions and less than 30 historical interactions. We timely sort user interactions, then employ the last review as the reference review, and treat others as historical interactions. Then, we randomly select 1000 samples from each dataset as the training set and 200 samples as simple evaluation data from the remaining data. Furthermore, we select 200 negative reviews from each dataset as hard evaluation data to test the model\u2019s ability to generate negative reviews.\n1https://cseweb.ucsd.edu/~jmcauley/datasets/ amazon_v2/\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/da7c/da7c6385-c9a8-4bd4-aeb7-dbfac1063a2c.png\" style=\"width: 50%;\"></div>\nGiven input, including the items purchased by the user historically, and corresponding reviews and ratings. Please generate a review for the new  item purchased by the user, drawing from their historical reviews and ratings. Keep in mind that lower ratings typically result in poorer reviews.\n<div style=\"text-align: center;\">Figure 1: An example of input prompt for Review-LLM.</div>\nWe conduct experiments using a cluster composed of 4*A800 80GB GPUs. We select Llama-38b 2 as the base model. And, we conduct the SFT training based on PyTorch and PEFT library (Mangrulkar et al., 2022) and use the LoRA (Hu et al., 2021) with a rank equal to 8. In addition, we use the Adam optimizer with learning rate of 5e-6 and batch size of 1 for SFT, and we set gradient accumulation steps as 2. We conduct each experiment independently and repeat it 5 times, and report the average results.\n# 3.2 Baselines and Evaluation Metrics\nWe compare Review-LLM with: (i) closed-source models such as GPT-3.5-Turbo, GPT-4o (Achiam et al., 2023); (ii) open-source models such as, Llama-3-8b (Touvron et al., 2023). To evaluate the performance of different models, we select ROUGE-1/L (Lin, 2004) and BERT (Kenton and Toutanova, 2019) similar score (BertScore) as evaluation metrics. ROUGE-n measures the n-gram similarity while BertScore measures the semantic similarity in the embedding space between the generated reviews and the reference reviews. We use the sentence transformers (Reimers and Gurevych, 2019) to compute the BertScore. Besides, we conduct a human evaluation experiment to test whether the generated reviews are semantically consistent with the reference reviews.\n# 3.3 Overall Performance\nTable 1 compares the performance of our method with several baselines and ablations. It is noted that the GPT-3.5-Turbo and GPT-4o are always better than Llama-3-8b, the reason is that the GPT-series\n2https://llama.meta.com/llama3/\nTable 1: Simple evaluation. w/ rating means the prompt contains ratings and w/o rating is vice.\n<div style=\"text-align: center;\">Table 1: Simple evaluation. w/ rating means the prompt contains ratings and w/o rating is vice.</div>\nMethod\nMetric\nROUGE-1\nROUGE-L\nBertScore (mean)\nGPT-3.5-turbo (w/ rating)\n15.99\n9.84\n41.52\nGPT-3.5-turbo (w/o rating)\n16.00\n9.81\n41.37\nGPT-4o (w/ rating)\n12.80\n8.47\n40.12\nGPT-4o (w/o rating)\n15.41\n11.22\n41.73\nLlama-3-8b (w/ rating)\n12.23\n8.23\n31.30\nLlama-3-8b (w/o rating)\n13.82\n9.59\n30.46\nReview-LLM (w/ rating)\n31.15\n26.88\n49.52\nReview-LLM (w/o rating)\n30.47\n26.38\n48.56\n<div style=\"text-align: center;\">Table 2: Hard evaluation. w/ rating means the prompt contains ratings and w/o rating is vice.</div>\nMethod\nMetric\nROUGE-1\nROUGE-L\nBertScore (mean)\nGPT-3.5-turbo (w/ rating)\n17.62\n10.70\n37.45\nGPT-3.5-turbo (w/o rating)\n16.07\n9.89\n37.25\nGPT-4o (w/ rating)\n16.66\n9.86\n39.21\nGPT-4o (w/o rating)\n14.51\n8.73\n38.64\nLlama-3-8b (w/ rating)\n13.47\n8.05\n28.38\nLlama-3-8b (w/o rating)\n13.11\n7.89\n26.96\nReview-LLM (w/ rating)\n21.93\n16.63\n39.35\nReview-LLM (w/o rating)\n17.82\n13.50\n35.89\nmodels have a larger number of parameters and are pre-trained on massive data, which could learn more general knowledge. Besides, we find that some baselines without ratings perform better than with ratings, while our fine-tuning method is the opposite. We argue that this is because the user rating information is further pre-trained in our method while baselines not. Overall, our method ReviewLLM outperforms all methods (including GPT-3.5Turbo and GPT-4o) across all metrics, demonstrating the effectiveness of using the item title, review, and rating to personalized fine-tune.\n# 3.4 Negative Review Performance\nIn our method, we employ user rating information to strengthen the model\u2019s understanding of user\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/31ee/31eea6e7-2cec-4580-a7c5-d6c117b45e14.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">GPT-3.5-turbo GPT-4o Llama3-8bReview-LLM Models 0.0</div>\nFigure 2: Human Evaluation. The bar is the mean of the model performance, and the error bar represents the max and min accuracy of the model.\npreferences for different items to achieve more personalized review generation. In this part, we test the performance of the model on the constructed hard testing set. The different model performance is shown in Table 2. From the results, we can find that all model performance has decreased compared with Table 1. In particular, using Llama38b for inference directly, BertScore is reduced to 26.96. We argue that this is because the LLMs might be polite, resulting in insufficient negative information captured during generating reviews. Besides, methods with ratings outperform methods without ratings on semantic similarity, especially Review-LLM, which further confirms the necessity of fusing the rating information for personalized review generation.\n# 3.5 Human Evaluation\nIn this part, we conduct the human evaluation to test the model performance of review generation. Considering that the generated texts with rating information usually have higher semantic similarity than those without, we only compare the models with rating information here. We randomly select 100 reference reviews and generated reviews from the simple testing set, and hire 10 Ph.D. students who are familiar with review/text generation to evaluate the similarity between generated reviews and reference reviews. If the reference review is semantically similar to the generated reviews, it is marked as 1, otherwise it is marked as 0. Figure 2 shows the percentage of generated reviews marked as 1. From the results, we can see that the designed fine-tuning data and framework could improve the quality of generated reviews and increase their semantic similarity to the reference reviews.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6b15/6b15e860-cf61-4ae4-9b23-5228d0e3af77.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3: Case Study.</div>\n# 3.6 Case Study\nTo demonstrate the effect of Review-LLM on generating reviews more intuitively, we select the generated reviews (from Review-LLM, GPT-4o, GPT3.5-Turbo) and the real review for visualization shown in Figure 3. First, we can find the review generated by our model is semantically similar to the real review and brief. In contrast, reviews derived by GPT-3.5-Turbo/GPT-4o are too long and may not be suitable for e-commerce platforms. Second, the generated review of Review-LLM better reflects review writing styles and user sentiment towards the item (we marked those in blue font). This demonstrates that our model could generate high-quality personalized reviews effectively by unifying rich user information with LLMs.\n# 4 Conclusion\nThis paper presents a framework that leverages Large Language Models (LLMs) for personalized review generation in recommender systems. By aggregating user historical behaviors, including item titles, reviews, and ratings, we construct a comprehensive input prompt to capture user preferences and review writing style. In this way, the model could mitigate the generation of overly polite reviews. Then, we utilize the low-rank adaptation for parameter-efficient fine-tuning, enabling the LLMs to generate reviews for candidate items through supervised fine-tuning. Experimental results show that our fine-tuning method outperforms GPT-3.5Turbo and GPT-4o in review generation.\n# 5 Limitation\n(1) Different individuals may focus on different aspects of a product, such as price, quality, appearance, or durability. While the proposed framework leverages user historical behaviors to capture comprehensive user interest features, it may not fully capture the diversity of individual preferences. (2) The framework primarily focuses on capturing user preferences from historical behaviors without considering the dynamics of user interactions over time. User preferences and writing styles can evolve, and incorporating temporal dynamics could potentially improve the accuracy and personalization of review generation.\n# References\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774. Li Dong, Shaohan Huang, Furu Wei, Mirella Lapata, Ming Zhou, and Ke Xu. 2017. Learning to generate product reviews from attributes. In ECAL, pages 623\u2013632. Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. 2021. Lora: Low-rank adaptation of large language models. In International Conference on Learning Representations. Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of NAACL-HLT, pages 4171\u20134186. Jihyeok Kim, Seungtaek Choi, Reinald Kim Amplayo, and Seung-won Hwang. 2020. Retrieval-augmented controllable review generation. In Proceedings of the 28th International Conference on Computational Linguistics, pages 2284\u20132295. Junyi Li, Siqing Li, Wayne Xin Zhao, Gaole He, Zhicheng Wei, Nicholas Jing Yuan, and Ji-Rong Wen. 2020. Knowledge-enhanced personalized review generation with capsule graph neural network. In CIKM, pages 735\u2013744. Junyi Li, Wayne Xin Zhao, Ji-Rong Wen, and Yang Song. 2019. Generating long and informative reviews with aspect-aware coarse-to-fine decoding. In ACL, pages 1969\u20131979. Pan Li and Alexander Tuzhilin. 2019. Towards controllable and personalized review generation. In EMNLP, pages 3228\u20133236.\nChin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pages 74\u201381. Yichao Lu, Ruihai Dong, and Barry Smyth. 2018. Why i like it: multi-task learning for recommendation and explanation. In Proceedings of the 12th ACM Conference on Recommender Systems, pages 4\u201312. Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and Benjamin Bossan. 2022. Peft: State-of-the-art parameterefficient fine-tuning methods. https://github. com/huggingface/peft. Julian McAuley and Jure Leskovec. 2013. Hidden factors and hidden topics: understanding rating dimensions with review text. In Proceedings of the 7th ACM conference on Recommender systems, pages 165\u2013172. Jianmo Ni, Zachary C Lipton, Sharad Vikram, and Julian McAuley. 2017. Estimating reactions and recommending products with generative models of reviews. In IJCNLP, pages 783\u2013791. Jianmo Ni and Julian McAuley. 2018. Personalized review generation by expanding phrases and attending on aspect-aware representations. In ACL, pages 706\u2013711. Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. Peijie Sun, Le Wu, Kun Zhang, Yanjie Fu, Richang Hong, and Meng Wang. 2020. Dual learning for explainable recommendation: Towards unifying user preference prediction and review generation. In Proceedings of The Web Conference 2020, pages 837\u2013 847. Jian Tang, Yifan Yang, Sam Carton, Ming Zhang, and Qiaozhu Mei. 2016. Context-aware natural language generation with recurrent neural networks. arXiv preprint arXiv:1611.09900. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971. Lanling Xu, Junjie Zhang, Bingqian Li, Jinpeng Wang, Mingchen Cai, Wayne Xin Zhao, and Ji-Rong Wen. 2024. Prompting large language models for recommender systems: A comprehensive framework and empirical analysis. arXiv preprint arXiv:2401.04997. Hongyu Zang and Xiaojun Wan. 2017. Towards automatic generation of product reviews from aspectsentiment scores. In Proceedings of the 10th International Conference on Natural Language Generation, pages 168\u2013177.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of personalized review generation in recommender systems, highlighting the limitations of existing methods that rely on encoder-decoder neural networks and the challenges posed by the 'polite' phenomenon of Large Language Models (LLMs) which often fail to generate negative reviews.",
        "problem": {
            "definition": "The problem is to automatically generate personalized reviews for users based on their historical interactions with items, including ratings and previous reviews.",
            "key obstacle": "The main challenge is that existing LLMs are typically pre-trained on a general corpus and do not capture individual user review styles or sentiments, leading to the generation of overly polite reviews that do not reflect user dissatisfaction."
        },
        "idea": {
            "intuition": "The idea is inspired by the need to personalize review generation by leveraging user historical behaviors and ratings to inform the LLM about user preferences and sentiment.",
            "opinion": "The proposed idea, Review-LLM, customizes LLMs for generating personalized reviews by aggregating user behavior data and incorporating ratings into the input prompts.",
            "innovation": "The key innovation lies in the construction of a prompt that integrates user historical interactions and ratings, allowing the model to generate reviews that are more aligned with user sentiments, including negative feedback."
        },
        "method": {
            "method name": "Review-LLM",
            "method abbreviation": "RLLM",
            "method definition": "Review-LLM is a framework that utilizes Large Language Models to generate personalized reviews by aggregating user historical behaviors and ratings into a structured prompt.",
            "method description": "The method involves fine-tuning LLMs using prompts constructed from user interactions and ratings to generate contextually relevant reviews.",
            "method steps": [
                "Construct a prompt that includes user historical interactions and target item information.",
                "Feed the constructed prompt into the LLM.",
                "Use Supervised Fine-Tuning (SFT) to adapt the model to generate personalized reviews."
            ],
            "principle": "This method is effective because it allows the LLM to learn user-specific preferences and writing styles, thus generating reviews that reflect the user's true sentiments."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted using five open-source 5-core recommendation datasets from Amazon, focusing on users with 10 to 30 historical interactions, with 1000 samples for training and 200 for evaluation.",
            "evaluation method": "The performance of Review-LLM was assessed using ROUGE and BertScore metrics, along with human evaluation to determine semantic similarity between generated and reference reviews."
        },
        "conclusion": "The experimental results demonstrate that Review-LLM outperforms existing models, including GPT-3.5 and GPT-4, in generating personalized reviews, effectively addressing the limitations of prior methods.",
        "discussion": {
            "advantage": "The primary advantage of Review-LLM is its ability to generate reviews that are more personalized and reflective of user sentiments, including negative reviews, by leveraging user historical data.",
            "limitation": "A limitation of the method is that it may not fully capture the diversity of individual user preferences and does not account for the dynamics of user interactions over time.",
            "future work": "Future research could focus on incorporating temporal dynamics of user preferences and expanding the framework to better capture diverse aspects of user interests."
        },
        "other info": {
            "info1": "The framework employs Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning.",
            "info2": {
                "info2.1": "The fine-tuning process uses a learning rate of 5e-6 and a batch size of 1.",
                "info2.2": "The experiments were conducted on a cluster of 4*A800 80GB GPUs."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "This paper addresses the issue of personalized review generation in recommender systems, highlighting the limitations of existing methods that rely on encoder-decoder neural networks."
        },
        {
            "section number": "1.2",
            "key information": "The proposed idea, Review-LLM, customizes LLMs for generating personalized reviews by aggregating user behavior data and incorporating ratings into the input prompts."
        },
        {
            "section number": "2.1",
            "key information": "The problem is to automatically generate personalized reviews for users based on their historical interactions with items, including ratings and previous reviews."
        },
        {
            "section number": "3.2",
            "key information": "Review-LLM is a framework that utilizes Large Language Models to generate personalized reviews by aggregating user historical behaviors and ratings into a structured prompt."
        },
        {
            "section number": "4.1",
            "key information": "The method involves fine-tuning LLMs using prompts constructed from user interactions and ratings to generate contextually relevant reviews."
        },
        {
            "section number": "5.1",
            "key information": "The primary advantage of Review-LLM is its ability to generate reviews that are more personalized and reflective of user sentiments, including negative reviews, by leveraging user historical data."
        },
        {
            "section number": "10.1",
            "key information": "A limitation of the method is that it may not fully capture the diversity of individual user preferences and does not account for the dynamics of user interactions over time."
        },
        {
            "section number": "11",
            "key information": "The experimental results demonstrate that Review-LLM outperforms existing models, including GPT-3.5 and GPT-4, in generating personalized reviews."
        }
    ],
    "similarity_score": 0.7962200375397458,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Review-LLM_ Harnessing Large Language Models for Personalized Review Generation.json"
}