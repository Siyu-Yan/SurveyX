{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2407.20352",
    "title": "Designing Time-Series Models With Hypernetworks & Adversarial Portfolios",
    "abstract": " Abstract\nAbstract\nThis article describes the methods that achieved 4th and 6th place in the forecasting and investment challenges, respectively, of the M6 competition, ultimately securing the 1st place in the overall duathlon ranking. In the forecasting challenge, we tested a novel meta-learning model that utilizes hypernetworks to design a parametric model tailored to a specific family of forecasting tasks. This approach allowed us to leverage similarities observed across individual forecasting tasks while also acknowledging potential heterogeneity in their data generating processes. The model\u2019s training can be directly performed with backpropagation, eliminating the need for reliance on higher-order derivatives and is equivalent to a simultaneous search over the space of parametric functions and their optimal parameter values. The proposed model\u2019s capabilities extend beyond M6, demonstrating superiority over state-ofthe-art meta-learning methods in the sinusoidal regression task and outperforming conventional parametric models on time-series from the M4 competition. In the investment challenge, we adjusted portfolio weights to induce greater or smaller correlation between our submission and that of other participants, depending on the current ranking, aiming to maximize the probability of achieving a good rank. While this portfolio strategy can increase the probability of securing a favorable rank, it paradoxically exhibits negative expected returns. Keywords: M6 forecasting competition, Meta-learning, Multi-task learning, Hypernetworks\n[cs.LG]\n# 1. Introduction\n1. Introduction\nThe M6 Financial Forecasting Competition (see Makridakis et al., 2022) spanned from March 2022 to February 2023 and focused on a universe of 100 assets: 50 S&P 500 stocks and 50 international ETFs. In the forecasting challenge, participants were tasked with predicting probabilities for each asset\u2019s next 4-week returns falling into one of five quintiles relative to other assets in the unive",
    "bib_name": "stank2024designingtimeseriesmodelshypernetworks",
    "md_text": "# Designing Time-Series Models With Hypernetworks & Adversarial Portfolios\nFilip Stan\u02c7ek1 CERGE-EI\nFilip Stan\u02c7ek1\nul 2024\nCERGE-EI\n29 Jul \n# Abstract\nAbstract\nThis article describes the methods that achieved 4th and 6th place in the forecasting and investment challenges, respectively, of the M6 competition, ultimately securing the 1st place in the overall duathlon ranking. In the forecasting challenge, we tested a novel meta-learning model that utilizes hypernetworks to design a parametric model tailored to a specific family of forecasting tasks. This approach allowed us to leverage similarities observed across individual forecasting tasks while also acknowledging potential heterogeneity in their data generating processes. The model\u2019s training can be directly performed with backpropagation, eliminating the need for reliance on higher-order derivatives and is equivalent to a simultaneous search over the space of parametric functions and their optimal parameter values. The proposed model\u2019s capabilities extend beyond M6, demonstrating superiority over state-ofthe-art meta-learning methods in the sinusoidal regression task and outperforming conventional parametric models on time-series from the M4 competition. In the investment challenge, we adjusted portfolio weights to induce greater or smaller correlation between our submission and that of other participants, depending on the current ranking, aiming to maximize the probability of achieving a good rank. While this portfolio strategy can increase the probability of securing a favorable rank, it paradoxically exhibits negative expected returns. Keywords: M6 forecasting competition, Meta-learning, Multi-task learning, Hypernetworks\n[cs.LG]\n# 1. Introduction\n1. Introduction\nThe M6 Financial Forecasting Competition (see Makridakis et al., 2022) spanned from March 2022 to February 2023 and focused on a universe of 100 assets: 50 S&P 500 stocks and 50 international ETFs. In the forecasting challenge, participants were tasked with predicting probabilities for each asset\u2019s next 4-week returns falling into one of five quintiles relative to other assets in the universe. The accuracy of these predictions was assessed using the ranked probability score (RPS) loss after the 4-week period had passed. In the investment challenge, participants were required to sub-\n1filip.stanek@cerge-ei.cz CERGE-EI, a joint workplace of Charles University and the Economics Institute of the Czech Academy of Sciences, Politickych veznu 7, 111 21 Prague, Czech Republic.\nmit portfolio weights for the upcoming 4-week interval. These portfolios were then evaluated based on riskadjusted returns (IR). Additionally, participants competed in a duathlon, which combined both forecasting and investment challenges. The duathlon ranking was computed as an arithmetic mean of participants\u2019 ranks in the forecasting and investment challenges. This article describes the methods we employed for our submissions, which achieved 4th place in the forecasting challenge, 6th place in the investment challenge, and ultimately secured the 1st place in the duathlon. In the forecasting challenge, we tested a novel hypernetwork meta-learning architecture capable of constructing the optimal parametric model for a given family of similar but not necessarily identical data generating processes (DGPs henceforth). This method, while broadly applicable, is especially well-suited for timeseries forecasting, where the number of observations is\ntypically insufficient to apply nonparametric methods on a per-series basis, but where multiple realizations of similar (but not necessarily ex-ante identical) timeseries are available. In particular, in the case of M6, this method allows us to perform a search over the space of prediction functions parameterized by some latent parameter vector specific to each asset, as opposed to finding a single prediction function for all assets, as one would do when applying a conventional nonparametric model on pooled data. The latent parameter vector can absorb heterogeneity in DGPs across assets, hence improving performance and even allowing to leverage data on additional assets not specified by organizers without concerns that their DGPs are too dissimilar to the original M6 asset universe. The quintile predictions, broadly speaking, encode two types of information. First, the relative size of predictions for the 1st and 2nd quintiles, as opposed to the 4th and 5th, provides information about whether the asset is likely to over-perform or under-perform relative to other assets. Second, the relative size of the 1st and 5th quintiles, as opposed to the 2nd, 3rd, and 4th, generally encodes information about volatility, with assets having high predicted probabilities of both the 1st and 5th quintiles being likely to end up with more extreme returns compared to other assets. In our case, the good performance of the model in terms of RPS is entirely driven by predicting volatility. Consequently, our initial efforts to transform these predictions into portfolios with consistently above-normal expected IR proved unsuccessful. In the investment challenge, due to a lack of better alternatives, we instead attempted to discretionary adjust the level of risk (as measured by the correlation between our IR and the IRs of competitors) based on our current rank within the global leaderboard. This involved assuming more risk when the probability of achieving a favorable rank was low and less risk when a sufficiently good rank on the leaderboard had been attained. Simulations, as well as bootstrap exercises, indicate that such an approach can indeed substantially improve the probability of securing top ranks in the leaderboard, despite paradoxically exhibiting a very poor IR in expectation. This highlights that the task of attaining the highest expected IR and that of maximizing the probability of success in the investment challenge may not necessarily be identical, and could even be at odds with each other. The remainder of the article is structured as follows. Section 2 focuses on the forecasting challenge, with subsection 2.1 introducing the proposed meta-learning model, and subsection 2.2 detailing how the model was\napplied in the M6 competition. Section 3 focuses on the investment challenge, with subsections 3.1 and 3.2 outlining the principles that guided the decisions, and subsection 3.3 discussing the actual investment decisions made during the competition. Section 4 concludes. To validate the model\u2019s effectiveness beyond the M6 competition, Appendices A and B evaluate its performance on sinusoidal regression and the M4 dataset. Appendices C and D contain supplementary materials and proofs, respectively.2\n# 2. Forecasting challenge\n# 2.1. Model3 2.1.1. Motivation\n# 2.1. Model3\n# 2.1.1. Motivation\nAccording to the classification by Januschowski et al. (2020), time-series forecasting approaches can be broadly divided into two strains. The conventional approach, known as local modeling, involves selecting the most appropriate parametric model for a given family of forecasting tasks, often based on expert judgment. This model is then applied to each individual observed series independently. On the other hand, global models consider all observed time-series jointly. In extreme cases, this can be done via pooling, thus disregarding the information regarding which data belong to which series altogether and estimating a single global model (see, e.g., Montero-Manso and Hyndman, 2021). However, it is often beneficial to utilize this information to help account for possible heterogeneity among the DGPs underlying the series, an approach aptly dubbed the localization of global models (Godahewa et al., 2021). This is typically performed by grouping the series either with time-series clustering techniques based on time-series features (Bandara et al., 2020) or directly according to model performance (Smyl and Kuber, 2016; Smyl, 2020) and estimating a specialized global model on each cluster. By adjusting the number of such clusters, one can then regulate the degree of globality/locality. We present an alternative method that helps bridge the gap between these two extremes. A global model, which instead of deriving a single forecasting function for all time-series, outputs a function parameterized by a latent parameter vector specific to each series, thereby acknowledging the potential heterogeneity\n2A replication repository for this article is available at https: //github.com/stanek-fi/M6_article. The original repository, containing the unaltered scripts used for the submissions, is available at https://github.com/stanek-fi/M6. 3An early version of this section appeared in a pre-print Stan\u02c7ek (2023a).\nof DGPs. Accounting for heterogeneity through the latent parameter space, rather than clustering, offers the advantage of equally accommodating a mixture of several different types of DGPs as well as family of continuously varying DGPs. Alternatively, this approach can also be viewed as a data-driven alternative to manually designing a parametric model for a group of related prediction tasks, an endeavor which typically requires considerable statistical expertise and domain knowledge. Specifically, by connecting an encoder-decoder network that accepts a task identifier to the parameters of another network responsible for processing inputs and generating predictions for that task, we enable a simultaneous search across the space of parametric functions and their associated parameter values. Importantly, the resulting hyper-network allows for complete backpropagation and does not rely on the computation of higher-order derivatives for training, unlike alternative approaches (see, e.g., Finn et al., 2017; Li et al., 2017). This allows, even with relatively limited computational resources, to design a parametric model that is finely tuned for a specific family of tasks, using the allotted degrees of freedom per task to capture the variability between tasks. Abstracting from the time-series nature of the data, the method belongs to a broader category of metalearning and/or multi-task learning methods, depending on how exactly it is deployed in practice. Meta-learning aims at designing/training a model based on multiple observed tasks so that it performs well when adapted with training data of yet unseen tasks from the same family, and then evaluated on the test data of that task. In contrast, multi-task learning aims to achieve optimal performance on new data from tasks that were used for the initial training. For an excellent review of these two closely related fields, please refer to Hospedales et al. (2021), Huisman et al. (2021), or Zhang and Yang (2022), respectively. In this section, we will formulate the problem in terms of the meta-learning objective, as it is typically a more relevant paradigm for time-series forecasting. Following the notation of Hospedales et al. (2021), we denote a task as T \u201c tDtrain, Dvalu.4 This task consists of data generated by some DGP split into a training set Dtrain \u201c tpxt, ytquK t\u201c1 used for estimating model parameters, and a validation set Dval \u201c tpxt, ytquN t\u201cK`1 for which we aim to make predictions. The vector xt P Rdx\n4Hospedales et al. (2021) allow for a slightly more general setup in which the loss function may also differ across tasks. However, this level of generality is not necessary for our purposes, so we suppress it for the ease of exposition.\ntypically contains lagged values of yt P Rdy or some transformation of these values. Tasks are distributed according to an unknown distribution ppT q.\nIn the framework, a model consists of two components: the prediction function\n\u02c6yt \u201c f\u03c9pxt; \u02c6\u03b8q\nwhich outputs predictions of yt based on the predictors xt, and the estimation function\n(2)\nwhich outputs the vector of task-specific parameters \u02c6\u03b8 P \u0398 given the observations Dtrain. Both functions, f\u03c9p\u00a8q and \u03ba\u03c9p\u00a8q, are further parameterized by a vector of meta parameters \u03c9 P \u2126, which are not directly dependent on the task T and generally encompass any prior decisions regarding the model (e.g., the choice of an appropriate model and its particular specification, estimation procedures, regularization techniques applied when estimating \u02c6\u03b8 etc.). To clearly differentiate between the meta parameters \u03c9 and the task-specific parameters \u03b8, we will refer to the latter as mesa parameters, following Hubinger et al. (2021).\nThe quality of the model is assessed by the loss incurred on the evaluation set, denoted by LpDval; \u02c6\u03b8, \u03c9q, with\nLpD; \u02c6\u03b8, \u03c9q \u201c 1 |D| \u00ff pxt,ytqPD \u03b3 ` yt, f\u03c9pxt; \u02c6\u03b8q\n(3)\nwhere the function \u03b3 measures the discrepancy between yt and the prediction \u02c6yt. Typically, to align the process of finding the optimal parameters \u03b8, the estimation \u02c6\u03b8 \u201c \u03ba\u03c9pDtrainq is likewise performed by numerically minimizing the incurred loss over the training set:\n\u02c6\u03b8 \u201c \u03ba\u03c9pDtrainq \u00ab arg min \u03b8P\u0398 LpDtrain; \u03b8, \u03c9q.\n(4)\nOftentimes, the information contained in \u03c9 regarding which forecasting function f\u03c9p\u00a8q to use and the most appropriate estimation function \u03ba\u03c9p\u00a8q is determined through expert judgment, based on informal prior knowledge regarding the task and/or ad-hoc hyperparameter tuning. By considering a family of tasks distributed according to ppT q, we can formalize the problem of finding the most suitable model; \u03c9 such that, when observing Dtrain and adapting accordingly through \u02c6\u03b8, the expected performance on yet unobserved\n(5)\nSolving this problem is not feasible as the distribution ppT q is unknown. However, given a collection of M observed tasks tT pmquM m\u201c1, it is, at least in theory, possible to solve the finite sample equivalent of the problem instead:\n(6)\n# 2.1.2. Architecture\n2.1.2. Architecture The bi-level optimization problem presented in Eq. 6 is generally computationally demanding. It may be feasible to estimate t\u02c6\u03b8pmquM m\u201c1 for a limited set of different model specifications \u2126\u201c t\u03c9iud\u2126 i\u201c1, and choose the model f\u03c9ip\u00a8q that yields the best out-of-sample performance over tDpmq val uM m\u201c1. However, this approach quickly becomes untenable when the set \u2126is large or even uncountable, for example, when considering a continuum of possible models rather than a limited set of predefined model specifications. In addressing this problem, we adopt the following two simplifying assumptions:\nA1: The estimation function \u03ba\u03c9p\u00a8q outputs the global minimizer of the in-sample loss:\n(7)\n(8)\nA2: The training is conducted using a train-train split:\n(9)\nAssumption A1 is pragmatically motivated by our aim, which is finding optimal parametric models. This is in stark contrast to the widely popular family of metalearning approaches derived from MAML (Finn et al., 2017) that primarily concentrate on estimation routines.\nThere, \u03c9 typically represents the initial value of \u03b8 used in the estimation routine \u03ba\u03c9 or some additional information on how to adapt from \u03b8 (see, for example, Finn et al. (2017), Li et al. (2017), and Park and Oliva (2019)). Assumption A2 implies that the training is not conducted with the train-val split (i.e., with Dpmq val in the outer optimization problem and Dpmq train in the inner optimization problem), which is typical for meta-learning. Instead, it is done with a train-train split (i.e., using Dpmq train in both the outer and inner optimization problems), as is common in multi-task learning. In this setup, the validation datasets Dpmq val are still utilized, but typically for early stopping of the training process rather than being directly included in the objective function. This assumption is substantial because the training process, in this case, may not strictly correspond to way the model will be deployed in practice. That is, to the situation when observing a completely new task, T pM`1q, and being asked to adapt the model through \u03b8pM`1q based on DpM`1q train to predict y in DpM`1q val while keeping \u03c9 fixed. Despite this, it appears justifiable in light of studies that demonstrate that for meta-learning, the commonly adopted train-val split might not always be preferable to a simpler train-train split (Bai et al., 2021) and that meta-learning and multi-task learning problems are closely connected (Wang et al., 2021) The introduction of these assumptions substantially simplifies the optimization problem, as shown in the following proposition.\nProposition 1. Under assumptions A1 and A2, there exist functions fp\u00a8; \u03b2q : Rdx \u00d1 Rdy parameterized by \u03b2 P B and gp\u00a8; \u03c9q : \u0398 \u00d1 B parameterized by \u03c9 P \u2126, such that the solution of\n(10)\ncoincides with the solution of the bilevel optimization problem introduced in Eq. 6.\nThe proposition demonstrates that under A1 and A2, the bilevel optimization problem in Eq. 6 collapses to a much simpler, single-level optimization problem. In this equivalent formulation, the model f\u03c9p\u00a8, \u03b8pmqq is conveniently separated into two components: the base model fp\u00a8; \u03b2pmqq, parameterized by \u03b2pmq, which pro-\ncesses features to generate predictions, and a meta module gp\u03b8pmq; \u03c9q, which, based on the mesa parameter vector \u03b8pmq, outputs the corresponding \u03b2pmq. Thus, in effect, Proposition 1 allows for a simultaneous search over both parametric functions f\u03c9 and their corresponding mesa parameters t\u03b8pmquM m\u201c1. To allow for maximal flexibility, we express both the base model fp\u00a8; \u03b2q and the meta module gp\u00a8; \u03c9q as feedforward neural networks. The total size of the network fp\u00a8; \u03b2q, represented by d\u03b2 \u201c cardp\u03b2q , controls the level of complexity with which the predicted values \u02c6yt depend on the input xt. The size of the mesa parameters d\u03b8 \u201c cardp\u03b8q corresponds to the number of degrees of freedom allotted to each task m and thus regulates the degree of globality/locality of the model.5 Finally, the size of the network gp\u00a8; \u03c9q, represented by d\u03c9 \u201c cardp\u03c9q, controls the nonlinearity of the model\u2019s response to mesa parameters \u03b8pmq. Network g does not necessarily have to be fully connected. To reduce computational complexity, it is possible to leave some output nodes as orphaned constants, allowing the mesa parameters \u03b8pmq to affect only a part of the base model f, such as only its last layers.6 Importantly, given that the optimization problem in Eq. 10 is unconstrained and that both the meta parameters \u03c9 and the task-specific mesa parameters t\u03b8pmquM m\u201c1 are optimized at the same level, the standard backpropagation techniques can be applied, considerably facilitating the training of the model. When implementing the model, it is convenient to equivalently express the array of mesa parameters t\u03b8pmquM m\u201c1 as a single neural network layer without any constants or nonlinearity. This layer takes, as input, the one-hot encoding of the task q \u201c em and outputs the corresponding vector of mesa parameters \u03b8pmq \u201c r\u03b8p1q, ... , \u03b8pMqsq. The entire model can then be expressed as depicted in Figure 1. For brevity, we will refer to the model simply as MtMs henceforth, emphasizing the simultaneous training of both global meta parameters \u03c9 and task-specific mesa parameters t\u03b8pmquM m\u201c1. Despite being trained under the multi-task learning paradigm, the model can be deployed for both multitask and meta-learning problems. For multi-task learning, the model can be used as is without any further optimization. By providing more data from an already 5If setting d\u03b8 \u201c 1 would still yield too much flexibility, it is also possible to further regularize the mesa parameters. Allowing the regularization penalty to tend towards infinity renders the adaptation via \u03b8 ineffective, causing the model to collapse into a pure global model. 6This is motivated by the fact that adaptation predominantly occurs by altering the head of the network (Raghu et al., 2019; Lin et al., 2020).\n5If setting d\u03b8 \u201c 1 would still yield too much flexibility, it is also possible to further regularize the mesa parameters. Allowing the regularization penalty to tend towards infinity renders the adaptation via \u03b8 ineffective, causing the model to collapse into a pure global model. 6This is motivated by the fact that adaptation predominantly occurs by altering the head of the network (Raghu et al., 2019; Lin et al., 2020).\nobserved task m m, predictions can be made using f \u02c6\u03c9p\u00a8; \u02c6\u03b8pmqq \u201c fp\u00a8; gp\u02c6\u03b8pmq; \u02c6\u03c9qq with the corresponding estimated mesa parameter vector \u02c6\u03b8pmq. For meta-learning applications, we leverage Proposition 1, which states that the solution \u02c6\u03c9 from Eq. 10 can be, under simplifying conditions A1 and A2, interpreted as a parametric model f \u02c6\u03c9p\u00a8; \u03b8q \u201c fp\u00a8; gp\u03b8; \u02c6\u03c9qq that, out of all competing parametric models \u03c91 P \u2126, delivers the smallest expected loss on a new task T pM`1q. To predict on this previously unobserved task, it is therefore sufficient to perform optimization over the space of task-specific mesa parameters \u03b8 P \u0398:\n\u02c6\u03b8pM`1q \u201c arg min \u03b8P\u0398 1 K K\u00ff t\u201c1 \u03b3pypM`1q t , fpxpM`1q t ; gp\u03b8; \u02c6\u03c9qqq, (11)\n(11)\n# while holding the model representation \u02c6\u03c9 fixed.\nNote that this optimization is performed only in the low-dimensional space Rd\u03b8 and can be done using either backpropagation or conventional numerical optimization methods. In this sense, it is completely analogous to finding parameters of any other parametric model. The only difference is that the functional form of the model f \u02c6\u03c9p\u00a8; \u03b8q, as represented by \u02c6\u03c9, is not presupposed by the researcher but instead derived in a data-driven way specifically for the given family of prediction problems ppT q in the initial meta-learning phase. Similar to a conventional parametric model manually crafted by a human expert, the parameter vector \u03b8 typically influence the prediction function f \u02c6\u03c9p\u00a8; \u03b8q \u201c fp\u00a8; gp\u03b8; \u02c6\u03c9qq in an interpretable way, as demonstrated in the applications later presented in this article (see Appendix A, Appendix B). Furthermore, though not pursued in this article, the fact that \u02c6\u03b8pM`1q is an extremum estimator allows for inference regarding model parameters, provided that regularity conditions are met. This method belongs to the strain of meta-learning research where hypernetworks/embeddings are used to perform adaptation to individual tasks at a lowerdimensional manifold of the parameter space (see, e.g., Lee and Choi, 2018; Zintgraf et al., 2019; Zhao et al., 2020; Flennerhag et al., 2020; von Oswald et al., 2022; Nava et al., 2023; Ramanarayanan et al., 2023). The main point of differentiation is that in these studies, hypernetworks are generally used to facilitate finetuning of network weights while retaining the MAML paradigm of bilevel optimization, where the inner optimization is restricted to a few gradient steps due to computational constraints. In contrast to this approach of fine-tuning network weights, MtMs sidestep the bilevel problem formulation by virtue of assumption\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4ce6/4ce6f958-f581-4b05-bfc4-8e96585ab214.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: A diagram of the MtMs model for an illustrative example with 6 features and 5 tasks. The process of generating forecasts proceeds from the right to left. First, a one-hot encoded vector q, denoting to which task the observation belongs, is multiplied by a matrix of mesa parameters p\u03b8p1q, ... , \u03b8pMqq to extract the corresponding task-specific mesa parameter vector \u03b8. This vector is then passed to the meta module gp\u03b8; \u03c9q to generate task-specific parameters \u03b2 of the base model fpx; \u03b2q. Lastly, the network fpx; \u03b2q is used to process the corresponding feature vector x and generate the prediction \u02c6y.</div>\nA2, which, in turn, allows one to interpret mesa parameters t\u03b8pmquM m\u201c1 as global optimizers of some underlying parametric model crafted specifically for the family of tasks ppT q. This is essential, as multistep task adaptation has been shown to be crucial in meta-learning (Lin et al., 2020). In this respect, the model is closely related to the seminal work of Shamsian et al. (2021), where a similar architecture with a custom training algorithm (pFedHN) is proposed for the task of personalized federated learning. To demonstrate that the applicability of MtMs is not limited only to financial time-series forecasting as in the case of M6, we also test its performance in two other environments, once under the metalearning evaluation and once under the multi-task learning evaluation. These additional demonstrations, available in the Appendices, allow us to compare the model\u2019s performance with established benchmarks. In Appendix A, we apply MtMs to the problem of sinusoidal regression, a synthetic problem originally proposed by Finn et al. (2017) to test the performance of MAML. This environment has since been frequently used to compare competing meta-learning methods. In this environment, MtMs almost perfectly recover the underlying unobserved parametric model, and in out-of-\nsample evaluation, it substantially outperforms conventional meta-learning approaches such as MAML (Finn et al., 2017), Meta-SGD (Li et al., 2017), MC (Park and Oliva, 2019), and MH (Zhao et al., 2020). This unparalleled performance stems from the fact that for the derived parametric model, represented by \u02c6\u03c9, prediction functions f \u02c6\u03c9p\u00a8; \u03b8q \u201c fp\u00a8; gp\u03b8; \u02c6\u03c9qq with varying mesa parameter \u03b8 almost perfectly mimic the various functions used to generate the data. Consequently, when this derived parametric model is applied to a previously unseen task, only a handful of observations DpM`1q train are needed to unambiguously estimate \u02c6\u03b8pM`1q and hence precisely pinpoint the particular function used to simulate the given task. In Appendix B, we apply MtMs under the multi-task learning paradigm to the time-series from the M4 forecasting competition, following the evaluation framework of Montero-Manso and Hyndman (2021). A simple linear model localized via MtMs outperforms both the corresponding global model applied on pooled data and models localized via clustering for the majority of series. Moreover, this very simple parametric linear model derived in a data-driven way through MtMs outperforms conventional widely used local models such\nas ETS (Hyndman et al., 2002) and auto.arima (Hyndman and Khandakar, 2008) on the majority of series. Interestingly, the heterogeneity identified and modeled via \u03b8 seems to be primarily in the degree to which the time-series are persistent and exhibit seasonal patterns. In the next subsection, we describe the primary application of MtMs discussed in this article: the forecasting challenge of the M6 competition.\n# 2.2. Application to the M6 competition7\nIn the context of the forecasting challenge in the M6 competition, each task m represents a single asset. The variable ypmq t P R5 serves as an indicator for the quintile to which the returns of asset m belong within the 4-week interval t, and xpmq t is a feature vector used for prediction.\n# 2.2.1. Data augmention\nTo enhance training stability and performance, we augment the dataset with assets beyond the 100 specified in the M6 universe. Data augmentation is particularly advantageous for the MtMs model, as even if additional assets have substantially different DGPs from those in the M6 universe, these variations are likely to be absorbed by \u03b8pmq. We augment the original 50 stocks and 50 ETFs with an additional 450 stocks and 450 ETFs. These assets are selected from a pool of assets with sufficient trading activity8 (must be at least 0.5 times the minimal trading activity observed in the M6 universe) and price history (must span from at least 2015 to the current date) to match the volatility observed in the M6 universe (the top 450 stocks/ETFs with the highest likelihood of their volatility being observed among the stocks/ETFs in the M6 universe are selected). Finally, the additional 450 stocks and 450 ETFs were randomly divided into 9 additional M6-like universes in order to compute quintiles ypmq t of returns.9 In addition to augmentation across the dimension M, we calculate quintiles ypmq t and features xpmq t for 4-week intervals shifted by 1, 2, and 3 weeks relative to the actual start of the competition (2022-03-07). Assuming\n7The model specification evolved slightly during the competition. This section details the model\u2019s state as of the 12th and final submission. For the evolution of the model, please refer to the accompanying repository. 8Measured by the product of the daily traded volume and the closing price. 9Note that computing quintiles based on all 900 additional assets at once does not generally align with the original objective.\nthe time-series ypmq t and xpmq t are stationary, such augmentation does not alter the objective in any way and allows us to effortlessly quadruple the amount of data per asset m, further enhancing the stability of the training process.\n# 2.2.2. Features\nAs features xpmq t , we utilize an indicator for whether a given asset is an ETF, its own lagged 4-week returns and volatilities (up to lag 7), and an array of technical trading indicators from the TTR package (Ulrich, 2021), calculated based on historical prices. We opt for TTR because it offers a unified interface, allowing us to generate a diverse set of features programmatically without requiring manual adjustments. A complete list of all 81 features is provided in Table C.3.10 Finally, we impute missing values with medians, and normalize the features to zero mean and unit variance.\n# 2.2.3. Model & training\nThe base model fp\u00a8; \u03b2q is a feedforward neural network comprising two hidden layers with 32 and 8 units, featuring leaky ReLU nonlinearity and a dropout rate of 0.2. The output layer has 5 units and utilizes a softmax transform. The meta module gp\u00a8; \u03c9q is a trivial feedforward network with no hidden layers or nonlinearity. One mesa parameter (d\u03b8 \u201c 1) is allotted to each asset, influencing the weights and biases of the final layer in fp\u00a8; \u03b2q. The architecture of the entire model is displayed in Figure 2. To train the model, we utilize data from 2000 to 2022 for training, reserving the remaining data for testing. Given the high sensitivity of hypernetworks to their initialization (Beck et al., 2023), our training process consists of two steps. In the first step, the base model is trained on pooled data without taking into account which data belongs to which task. This training is conducted under the RPS loss using the Adam optimizer with a learning rate of 0.01, a minibatch size of 200, and early stopping. In the second step, the trained weights from the first step serve as an initialization for the bias of the meta module gp\u00a8; \u03c9q. Meanwhile, the weights of the meta module are initialized uniformly on the interval r\u00b41, 1s, and mesa parameters t\u03b8pmquM m\u201c1 are set to 0. This means that the optimization begins from a point where the\n10Some indicators are multivariate and/or are computed with different lengths of the rolling window. The feature selection process involved initially training an XGBoost model (Chen et al., 2023) using all available technical trading indicators from TTR and subsequently pruning the least important features.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9ad6/9ad63269-f40d-472e-982a-51bc92b4fd78.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: A diagram of the MtMs model applied to M6. In the case of M6, there are 1000 tasks/assets (100 specified by the organizers and 900 from the additional 9 auxiliary M6-like datasets). Each asset is allotted one univariate mesa parameter \u03b8, which, through the meta module gp\u03b8; \u03c9q, determines the parameters \u03b2 of the network fpx; \u03b2q. This network then processes the corresponding feature vector x to generate the prediction \u02c6y. The meta module gp\u03b8; \u03c9q is a trivial single-layer neural network that connects \u03b8 to the weights and biases of the last layer of the network f; \u03b2connected. The remaining nodes corresponding to parameters \u03b2orphaned are not influenced by \u03b8 and are hence constant across all tasks/assets.</div>\nMtMs model is already proficient at predicting ypmq t , and the objective now is primarily to capture any systematic differences among the DGPs of individual assets through the mesa parameters t\u03b8pmquM m\u201c1. The optimization is carried out iteratively using the Adam optimizer, with gradually decreasing learning rates (values t0.01, 0.001, 0.001, 0.0005, 0.0003, 0.0001, 0.00005u), minibatches consisting of 100 randomly selected assets and early stopping. We employ this repeated training scheme because MtMs can be challenging to train, with the optimizer often struggling to adjust the model weights for improved test loss on the initial attempt. Multiple iterations are typically required. Finally, to make predictions, we can readily employ estimated mesa parameters \u02c6\u03b8pmq corresponding to the original asset universe without any further training (i.e., multi-task learning deployment).\n# 2.2.4. Post-processing & predictions\nAlthough the rankings of individual assets are intrinsically related (with exactly 20 assets belonging to each quintile within each universe), we choose to disregard this dependence and submit predictions \u02c6ypmq t \u201c fpxpmq t , gpp\u03b8pmq; p\u03c9qq without any post-processing or fur-\nAlthough the rankings of individual assets are intrinsically related (with exactly 20 assets belonging to each quintile within each universe), we choose to disregard this dependence and submit predictions \u02c6ypmq t \u201c fpxpmq t , gpp\u03b8pmq; p\u03c9qq without any post-processing or fur-\nther adjustments.11 While harmonizing the predictions could potentially yield performance improvements, we did not pursue this as the universe\u2019s size of 100 assets is adequate to ensure that ypmq t is at least approximately unrelated in this regard. Interestingly, despite performing well when measured by RPS loss (0.15689 over the duration of the competition), the predictions generated by the model contain surprisingly little directional information. This severely limits their practical utility for forming investment portfolios, except for risk management purposes. Figure 3 displays the predicted probabilities of the 1st (resp. 2nd) quintile plotted against predicted probabilities of the 5th (resp 4th) quintile for individual assets throughout the competition. Predictions generally traverse along the diagonal line, implying that an increased probability of exceptionally good performance, relative to other assets, is accompanied by an increased probability of exceptionally poor performance, and vice versa, thus failing to provide any clear recommenda-\n11The only exceptions are the predictions for the DRE stock during submissions 10-12. After DRE stock was acquired by PLD, it exhibited zero price changes from that point forward. To address this, we overrode the predictions with observed frequencies with which a hypothetical asset with zero returns would belong to individual quintiles.\ntions on which positions to take. This finding appears to align with the efficient market hypothesis (see, e.g., Malkiel, 2005), which posits that it is impossible to achieve abnormal returns based on information contained in the price history.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b226/b226afa8-da88-433a-ad3f-d2ca8df6efee.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\n<div style=\"text-align: center;\">Figure 3: Predicted probabilities of the 1st quintile plotted against the probabilities of the 5th quintile (upper panel) and predicted probabilities of the 2nd quintile plotted against the probabilities of the 4th quintile (lower panel).</div>\nDisentangling the precise causes of the model\u2019s relatively good performance is challenging. However, the training metrics suggest that the considered assets are relatively homogenous. The most significant improvements over naive predictions were achieved through\njoint training, with adaptation playing a secondary role. MtMs nonetheless still provided the advantage of using a much broader universe of assets for training without concerns about their dissimilarity to the assets specified by the organizers.\n# 3. Investment challenge\nBefore the start of the competition, we made several attempts to systematically transform quintile predictions into portfolio weights. These attempts ranged from a parametric approach that combined information about the marginal distributions with the correlation structure using copulas to a fully nonparametric approach. However, perhaps unsurprisingly, given the notorious difficulty of achieving abnormal returns and given the results displayed in Figure 3, none of these approaches passed backtesting. In general, the predictability of quintiles of rank does not necessarily imply predictability of expected returns; many DGPs for asset returns with identical means are compatible with non-uniform and predictable quintiles. Even the minor asymmetries in quintile predictions12 occasionally observed in Figure 3 are not necessarily indicative of mean predictability. They could, and likely are, given our inability to capitalize on them, caused by a varying degree of asymmetry in the distribution of returns across different assets. Given the failure to produce investment decisions that consistently attained abnormal returns, we opted to use the investment challenge as ancillary to the prediction challenge. The decisions were made on a discretionary basis and were primarily guided by two principles. First, the portfolio weights were scaled to gain a small but certain advantage. Second, the signs of the positions were strategically altered depending on the current ranking to improve the chances of securing a good enough rank in the duathlon challenge.\n# 3.1. Scaling\nGiven a collection portfolio weights twpmq t uM m\u201c1 for M assets submitted at time t, we can consider the decomposition:\n(12)\n12I.e., a situations in which \u02c6Ppquintilepmq t \u201c 1q \u2030 \u02c6Ppquintilepmq t 5q or \u02c6Ppquintilepmq t \u201c 2q \u2030 \u02c6Ppquintilepmq t \u201c 4q.\nHere, \u02dcwpmq t is a scaleless portfolio weight, and \u03b1t is the overall scaling factor at time t. The objective function (see Makridakis et al., 2022) involves a log transform, which, due to its concavity, penalizes extreme returns more severely. Therefore, irrespective of t \u02dcwpmq t uM m\u201c1, it is desirable to set \u03b1t as small as possible to minimize the dispersion of returns prior to standardization. Setting \u03b1t \u201c 0.25 results in a very modest but certain advantage over \u03b1t \u201c 1. In the case of an equal-weighted long portfolio, this amounts to approximately 0.07 IR per 4-week interval (see Fig. C.7).\n# 3.2. Strategic positions\nTo maximize the probability of securing the top rank, it is desirable to take more risky positions when one ranks poorly in the public leaderboard, attempting to improve otherwise hopeless positions. Conversely, more conservative positions might be warranted if one already holds a sufficiently good rank and only wishes to maintain it. However, because the objective is defined in terms of risk-adjusted returns, it is challenging to directly control risk by forming portfolios with varying degrees of return variability. To circumvent this issue, we attempted to leverage the competitive nature of the competition, where only relative performance matters, and the fact that participants were primarily taking long positions.13 Let us denote the number of long positions in the portfolio at time t as n` t and the number of short positions as n\u00b4 t . By varying the proportion of short positions in the portfolio n\u00b4 t {pn` t `n\u00b4 t q, one can control the extent to which returns of the submitted portfolio would be negatively or positively correlated with the returns of other participants at large. This allowed us to either increase the chances of rapidly climbing or descending the leaderboard (if achieving a top rank was otherwise unlikely) or reduce the risk of losing an already satisfactory ranking to a competitor (if a sufficiently good rank had already been achieved). A formalization of this type of approach as a dynamic programming problem, along with an analysis of its performance, can be found in (Stan\u02c7ek, 2023b). The simu-\n13Despite the submitted positions of individual teams being private, the number of participants submitting predominantly long positions can be approximately inferred from the public leaderboard by observing for how many participants their monthly IR is of the same sign as that of the equal-weighted long benchmark portfolio in each month. A slightly more rigorous approach, though not pursued at the time of the competition, is to match properties of simulated IR with the actually observed IR in the leaderboard via the method of simulated moments (McFadden, 1989), as in Stan\u02c7ek (2023b).\nlations suggest that employing such an adversarial portfolio strategy can significantly improve the likelihood of achieving a favorable rank. This effect is particularly notable for the highest rankings; the probability of securing the 1st place is approximately 3 times higher than expected by chance, comparable to that of a participant consistently generating double the market returns. The advantage for less extreme placements is less pronounced, with the probability of securing the 20th place or better being approximately 1.5 times higher than expected by chance. However, this improvement comes at the expense of negative expected returns and a disproportionately higher probability of achieving an extremely poor rank due to its reliance on aggressive shorting and martingale-like risk-taking.\n# 3.3. Investment decisions\nThroughout the competition, we maintained |wpmq t | \u201c 0.0025, with only the signs of the weights being manipulated. Figure 4 presents a comprehensive overview of the submitted portfolio weights, returns of individual assets, and the overall portfolio returns for our submissions, along with the returns of reference portfolios for comparison. In submissions 1-4, n\u00b4 t was set to 0. Starting from submission 5, it became apparent that scaling alone would be insufficient to secure a top rank, and that some risk indeed needed to be taken. During submissions 57, n\u00b4 t was set to 10 to induce greater dispersion between our returns and those of competitors. As the strategy described in section 3.2 provides no guidelines regarding which particular assets one should short, we selected them using an ad hoc rule according to the difference of predicted probabilities of the lowest and the highest quintile. Unsurprisingly, these choices turned out no better than if one would be selecting at random (see Fig. 4). In response to the gradually worsening position in the duathlon leaderboard, n\u00b4 t was set to 100 in submission 8. Coincidentally, returns during that period were predominantly negative, which substantially improved our ranking. For the remainder of the competition, submissions 9-12, n\u00b4 t was set again to 0 to induce a positive correlation with returns of possible contenders and hence minimize the probability of losing an already sufficiently good rank. While the strategy described in Subsection 3.2 can, to some degree, increase the probability of securing a relatively good rank (and likewise, a bad rank), it should be emphasized that the realized rank is, in our case, still predominantly the result of mere chance. In particular, by optimally selecting n\u00b4 t , one may, in a stylized environment, increase the chances of ranking in the top 20\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1f75/1f758592-b754-4160-af96-e9a5e81fc7e3.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Portfolio weights and the overall performance of the portfolio across individual submissions. Performance of the M6 dummy portfolio and the average performance of participants for comparison.</div>\nFigure 4: Portfolio weights and the overall performance of the portfolio across individual submissions. Performance of the M6 dummy portfolio and the average performance of participants for comparison.\nin the investment challenge (and, therefore, securing 1st place in the duathlon, with the forecasting challenge results held constant) from 0.12 to 0.19 (upper estimate, see (Stan\u02c7ek, 2023b)). While a non-negligible improvement, it is still very far from a guaranteed outcome.\n# 4. Conclusions\nWe describe our methods for the forecasting and investment challenges in the M6 forecasting competition, which secured 4th and 6th place, respectively, ultimately winning 1st place in the duathlon. For the forecasting challenge, we employed a metalearning/multi-task learning model based on hypernetworks. This approach enables the creation of a parametric model specifically optimized for a particular family of prediction problems. In this way, the model\u2019s parameters are used to capture any between-task variability, while features of the DGP that are approximately invariant across tasks are learned from the pooled data. The resulting quintile predictions yield good performance in terms of RPS loss. However, they seem to provide no useful information about the expected values of returns. For the investment challenge, we attempted to increase our chances of securing a good rank by employing a simple strategy, which aims to maximize/minimize the dispersion of the differences between our IR and the IRs of other competitors, depending on our current position in the public leaderboard. Finally, despite the promising results, it\u2019s important to exercise caution and not place undue focus on topperforming approaches. The performance of any approach, despite being measured over the span of one year, is still partially obscured by statistical noise, making it difficult to determine if one model truly outperforms another in expectation. The top-performing participants, by the very fact that they secured good rankings, were likely more fortunate than others. In the case of the investment challenge, our own simulations suggest that achieving the 6th rank would likely not be repeated if the competition were held again. The same caveat also applies to our results in the forecasting challenge, although here, the fact that the MtMs model also outperforms state-of-the-art meta-learning approaches on the sinusoidal regression problem (Appendix A) and that it performs excellently on M4 (Appendix B) certainly shows great promise. An evident and natural extension of this work is to evaluate MtMs on other widely recognized metalearning problems, such as few-shot image classification (using datasets like Omniglot (Lake et al., 2011)\nand Mini-ImageNet (Ravi and Larochelle, 2016)) or reinforcement learning (2D navigation and locomotion (see, e.g., Finn et al., 2017)).\n# 5. Acknowledgments\nOur sincere appreciation goes to the M6 organizers for their dedication in coordinating this challenging year-long competition. We also extend our gratitude to Spyros Makridakis, Evangelos Spiliotis, and Fotios Petropoulos for their insightful comments, which have greatly improved this article.\n# Appendix A. Sinusoidal regression\nTo evaluate the potential of the MtMs to find the most appropriate parametric model for a given family of prediction problems, we consider a simulation exercise originally proposed by Finn et al. (2017) to test the performance of MAML. Since then, this environment has frequently been used to compare competing metalearning methods. The problem involves predicting y P R based on x P R, where each task\u2019s data follows a sine wave with randomly sampled amplitude and phase. Importantly, phase and amplitude are not observed directly, making it challenging to infer the underlying family of functions due to the limited number of observations per task and substantial heterogeneity across tasks. In particular, the tasks T pmq \u201c tDpmq train, Dpmq val u are generated according to the following DGP:14\n(A.1)\nThe goal is to find the best model that can predict ypmq i based on xpmq i for i \u0105 K after observing only K observations Dpmq train, as measured by the mean squared error:\n(A.2)\n14As the sinusoidal regression is a cross-sectional exercise, we index individual observations by i rather than t to highlight that they are conditionally IID.\nFor fair comparison, we follow Finn et al. (2017) and set the base model to be a feedforward neural network with two hidden layers of size 40 and ReLU nonlinearities. The number of mesa parameters, d\u03b8, is set to 2 and the meta module gp\u00a8; \u03c9q is a simple fully connected feedforward network with no hidden layers or non-linearities. MtMs is first trained via the Adam optimizer with a learning rate of 0.001 and minibatches of 100 tasks on M \u201c 1000 randomly generated tasks15 with K observations. After the initial meta-learning phase to identify the most suitable parametric model, the resulting model with fixed \u02c6\u03c9 is evaluated on 600 previously unseen tasks. For each new task m1 with K observed datapoints Dpm1q train, a two-dimensional optimization for \u02c6\u03b8pm1q P R2 is performed (using the Adadelta optimizer with a learning rate of 0.001) in order to find the mesa-parameter vector most suitable for the sampled task. The estimated \u02c6\u03b8pm1q is then used to make predictions on Dpm1q val . Other simulation details follow Zhao et al. (2020) and are available in the replication repository. Table A.1 shows the mean squared error achieved by the MtMs for 5-shot learning and 10-shot learning. For comparison, we include the losses of commonly used meta-learning methods on this task (the performance of competing methods is taken from Park and Oliva (2019) and Zhao et al. (2020)). The proposed MtMs model outperforms all benchmark methods by an order of magnitude for both 5-shot learning and 10-shot learning of the sinusoidal task. In fact, the losses are in both cases very close to the theoretical minimum of 0, indicating that the MtMs is capable of recovering the data-generating process to such a degree that, when faced with only as few as 5 observations pxpm1q i , ypm1q i q from task m1, it is able to almost perfectly infer ypm1q i as a function of xpm1q i for the whole range r\u00b45, 5s.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/81e5/81e56cd5-f1b7-418e-998b-1cce8f84deca.png\" style=\"width: 50%;\"></div>\nMethod\nK \u201c 5\nK \u201c 10\nMAML (Finn et al., 2017)\n0.686\u02d80.070\n0.435\u02d80.039\nLayerLR (Park and Oliva, 2019)\n0.528\u02d80.068\n0.269\u02d80.027\nMeta-SGD (Li et al., 2017)\n0.482\u02d80.061\n0.258\u02d80.026\nMC1 (Park and Oliva, 2019)\n0.426\u02d80.054\n0.239\u02d80.025\nMC2 (Park and Oliva, 2019)\n0.405\u02d80.048\n0.201\u02d80.020\nMH (Zhao et al., 2020)\n0.501\u02d80.082\n0.281\u02d80.072\nMtMs (ours)\n0.022\u02d80.003\n0.014\u02d80.001\n<div style=\"text-align: center;\">Table A.1: Losses for sinusoidal task Mean squared errors and corresponding 95% confidence intervals for different meta-learning methods. Bold text indicates the best-performing model.</div>\n15Fewer than the 70,000 tasks originally used in Finn et al. (2017 and in the follow-up studies.\nThe fact that the sinusoidal regression problem is univariate allows us to conveniently visualize the type of parametric model learned from the data during the initial meta-learning phase. Figure A.5 shows predictions of the model f\u03c9px; \u03b8q as a function of x for different values of mesa-parameters \u03b8. As is apparent from Figure A.5, the plotted prediction functions closely resemble different sine waves, indicating that MtMs is indeed capable of correctly inferring that each generated task follows a sine function with varying phase and amplitude. However, the mesa parameters \u03b8 \u201c r\u03b8r1s, \u03b8r2ssJ explaining the variability between tasks do not directly correspond to the amplitude A and phase b. Instead, \u03b8r1s regulates the amplitude (negatively), but to a lesser degree, it also regulates the phase (positively), while \u03b8r2s primarily regulates the phase (positively) and, to a lesser degree, it also regulates the amplitude. This is not surprising, as there are infinitely many parametric models that are observationally equivalent to the DGP described in Eq. A.1. In particular, any two vectors in R2 that are linearly independent are capable of spanning the whole space of rb, As just as well as the basis vectors used in Eq. A.1. The MtMs hence generally converges to one of these equivalent parametrizations, not necessarily to the exact same parametrization used to simulate the data.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c431/c4312ccf-8ad9-42c8-be10-696947cef37b.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure A.5: MtMs predictions for sinusoidal task (K \u201c 5) Plots of f\u03c9px; \u03b8q as a function of x for different values of the mesa parameter vector \u03b8. In the upper panel, the first mesa parameter \u03b8r1s varies while \u03b8r2s is fixed to its median value \u00b40.013. In the lower panel, the second mesa parameter \u03b8r2s varies while \u03b8r1s is fixed to its median value 0.017.</div>\nAdmittedly, the sinusoidal regression problem is rel-\natively favorable to MtMs because the data are generated deterministically using a clearly defined lowdimensional model, and MtMs is, at its core, a method for recovering unknown parametric models. Nonetheless, the fact that MtMs is capable of achieving unparalleled, near-oracle performance even when using fewer tasks than previous studies clearly demonstrates its capacity to identify and model the latent variability among the observed tasks.\n# Appendix B. M4\nTo assess the ability of the MtMs model to localize global time-series forecasting models in more general settings than those encountered in M6, we also perform an extensive evaluation on the data from the M4 forecasting competition (Makridakis et al., 2020). We follow the evaluation framework of Montero-Manso and Hyndman (2021), who demonstrated the surprising performance of simple global models, including a simple pooled OLS with lagged values of the time series as regressors. We extend this forecasting exercise by exploring the extent to which the performance of the pooled OLS can be improved through localization via timeseries clustering and MtMs. Following Montero-Manso and Hyndman (2021), we focus on time-series with yearly, quarterly, monthly, and weekly frequencies (for forecast horizons of 6, 8, 18, and 13, respectively, using the recursive forecasting scheme) and use the MASE loss function with scaling applied as a preprocessing step. The feature vectors contain lagged values of the given time-series: xpmq t \u201c rypmq t\u00b41, ypmq t\u00b42, . . . , ypmq t\u00b4dxsJ. For a time-series m of length dm, the design matrix is defined as Xpmq \u201c rxpmq dx`1, xpmq dx`2, . . . , xpmq dm sJ, and the dependent variable vector is ypmq \u201c rypmq dx`1, ypmq dx`2, . . . , ypmq dm sJ. By stacking typmquM m\u201c1 and tXpmquM m\u201c1, one can obtain the design matrix and dependent variable vector for pooled regression to estimate the pooled \u03b2 for all time-series of a given frequency. Likewise, after performing timeseries clustering to account for heterogeneity across series, one can obtain \u03b2 for each cluster of similar series. To mimic the same settings with MtMs, we set fpx; \u03b2pmqq \u201c xJ\u03b2pmq, and define gp\u03b8; \u03c9q as a simple neural network with no hidden layer or nonlinearity: \u03b2pmq \u201c gp\u03b8pmq; \u03c9q \u201c \u03c9b `\u03c9w\u03b8pmq, where \u03c9b P Mpdx, 1q and \u03c9w P Mpdx, d\u03b8q. The predictions for time-series m can hence be expressed as\n(B.1)\nThis expression reveals that this special case of MtMs is analogous to performing PCA in the latent space of unobservable true regression coefficients t\u03b2\u02dapmquM m\u201c1. The bias vector \u03c9b captures the central tendency of t\u03b2\u02dapmquM m\u201c1 and corresponds to the action of demeaning variables prior to PCA. The column vectors of matrix \u03c9w are optimized to best explain the variability of the true unobserved t\u03b2\u02dapmquM m\u201c1, analogous to the loading vectors of individual principal components. The taskspecific parameter vector \u03b8pmq measures the exposure to variance-explaining factors \u03c9wr:, is for a given timeseries, and corresponds to the row m of the score matrix from PCA. Similarly to PCA, dimensionality reduction can be performed by choosing the number of factors (d\u03b8) used to explain the variability of t\u03b2\u02dapmquM m\u201c1. Choosing d\u03b8 \u201c 0 is equivalent to estimating a pooled regression on the time-series, whereas choosing d\u03b8 = dx is equivalent to estimating a separate regression for each time-series m. In practice, given that the DGPs of many time-series are likely similar, only a handful of factors \u03c9wr:, is are necessary to successfully explain most of the variability across time-series. Note that unlike principal component regression (see, e.g., Hadi and Ling, 1998), where the dimensionality reduction is performed on the pooled design matrix as a preprocessing step, here the reduction is performed in the latent space of regression coefficients jointly with the estimation. In this sense, it is similar to reduced-rank regression (Izenman, 1975), with the exception that we are searching for a lowerdimensional representation of a set of regression coefficients across multiple tasks/time-series, rather than within a single dataset with multiple dependent variables. Table B.2 displays the average MASE for OLS localized via MtMs with d\u03b8 \u201c 2 on the M4 datasets. To facilitate training, we leverage the fact that the optimal tt\u03c9b, \u03c9wu, t\u03b8pmquM m\u201c1u can be derived iteratively in closed form under the L2 loss16, and use these estimates to initialize MtMs. After initialization, the training is performed using backpropagation with the Adam optimizer, a learning rate of 0.001 and a minibatch size\n16Eq. B.1 can be expressed for all tasks m simultaneously as \u02c6y \u201c Xp\u02dc\u03b8 b Idx`1qvecp\u03c9q where \u02c6y \u201c \u201c \u02c6yp1qJ, . . . , \u02c6ypMqJ\u2030J, X \u201c blkdiagptXpmquM m\u201c1q, \u03c9 \u201c r\u03c9b, \u03c9ws, \u03b8 \u201c \u201c \u03b8p1q, . . . , \u03b8pMq\u2030J, and \u02dc\u03b8 \u201c r1, \u03b8s. This leads to first-order conditions for vecp\u03c9q: vecp\u03c9q \u201c ` HJH \u02d8\u00b41 HJy where y \u201c \u201c yp1qJ, . . . , ypMqJ\u2030J and H \u201c Xp\u02dc\u03b8 b Idx`1q. First-order conditions for t\u03b8pmquM m\u201c1 are t\u03b8pmq \u201c ` QJQ \u02d8\u00b41 QJpypmq \u00b4 Xpmq\u03c9bquM m\u201c1 where Q \u201c Xpmq\u03c9w. By iterating over these two sets of first-order conditions, tt\u03c9b, \u03c9wu, t\u03b8pmquM m\u201c1u converge to their joint optimal values.\nof 1000 time-series under the MASE loss. For comparison with conventional localization techniques, we cluster time-series into t2iu10 i\u201c2 clusters using k-means on stl features (seasonality & trend), entropy and acf features (autocorrelation) from the tsfeatures package (Hyndman et al., 2023) and estimate regression coefficients for each cluster individually. For each frequency, the number of lags dx is set to the maximum value according to the shortest series, following the setup of Montero-Manso and Hyndman (2021). For reference, we also include the performance of OLS on the pooled dataset and two widely used local models: ETS (Hyndman et al., 2002) and auto.arima (Hyndman and Khandakar, 2008). With the exception of the yearly frequency, where localization provides only marginal improvements and where the two degrees of freedom per series likely lead to over-fitting, OLS localized via MtMs outperforms non-localized OLS and OLS localized via clustering across all cluster sizes. Furthermore, for all frequencies except yearly, the simple linear parametric model derived in a data-driven way via MtMs, namely:\n(B.2)\n<div style=\"text-align: center;\">with t\u03c9b, \u03c9wu fixed, outperforms conventional and more complex local models crafted by human experts.</div>\nmodel\nYearly\nQuarterly\nMonthly\nWeekly\nETS\n3.478\n1.164\n0.948\n2.513\nauto.arima\n3.407\n1.161\n0.929\n2.542\nOLS (pooled)\n3.059\n1.222\n0.957\n2.275\nOLS (2 clusters)\n3.011\n1.218\n0.950\n2.246\nOLS (4 clusters)\n2.990\n1.225\n0.953\n2.179\nOLS (8 clusters)\n3.020\n1.229\n0.949\n2.194\nOLS (16 clusters)\n3.075\n1.220\n0.952\n2.181\nOLS (32 clusters)\n3.132\n1.214\n0.950\nOLS (64 clusters)\n3.188\n1.210\n0.949\nOLS (128 clusters)\n3.258\n1.205\n0.943\nOLS (256 clusters)\n3.304\n1.201\n0.939\nOLS (512 clusters)\n3.402\n1.197\n0.936\nOLS (1024 clusters)\n3.538\n1.197\n0.930\nOLS (localized via MtMs)\n4.050\n1.133\n0.911\n2.104\nTable B.2: Losses for the M4 datasets Mean MASE losses for individual models on yearly, quarterly, monthly, and weekly datasets from the M4 competition. Bold text indicates the best-performing model for each frequency. Losses of OLS with more than 16 clusters for the weekly frequency are not available due to an insufficient number of observations to estimate OLS on all clusters.\nSimilarly to sinusoidal regression, the simple structure of the model allows us to visualize the heterogeneity across DGPs identified in the datasets. As an example, Figure B.6 displays the column vectors \u03c9wr:, 1s and \u03c9wr:, 2s for the monthly frequency. Parameter \u03b8r2s primarily regulates the persistence of the DGP (positively affecting the dependence on lag 1) and seasonality (neg-\natively affecting the dependence on lags t12, 24, 36u). To a lesser extent, it also captures seasonality at lag 6, likely driven by time-series with bi-annual seasonal behavior. Parameter \u03b8r1s also regulates persistence (negatively) and seasonality (negatively), but in addition appears to influence the decay of seasonal behavior, as evidenced by the gradually decreasing values of \u03c9wr:, 1s corresponding to lags t13, 14, 25, 26, 37, 38u. By varying these two parameters \u03b8r1s and \u03b8r2s, one can approximately span the space of regression coefficients corresponding to DGPs encountered in the M4 monthly dataset.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4074/4074bb8f-eacb-41bd-8017-c9eef34f653a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure B.6: Estimated column vectors of \u03c9w for the M4 monthly dataset</div>\nAppendix C. Supplementary materials\n# Appendix D. Proofs\nAppendix D. Proofs\nProof of Proposition 1. Define gp\u03b8pmq; \u03c9q \u201c t\u03b8pmq, \u03c9u and fp\u00a8, \u03b2pmqq \u201c f\u03b2pmqr2sp\u00a8; \u03b2pmqr1sq with B \u201c \u0398 \u02c6 \u2126. Under A1 and A2, the bilevel optimization problem in\nSource\nFeature\nTransformation\nown\nVolatility(lag = [1,2,3,4,5,6,7])\nown\nReturn(lag = [1,2,3,4,5,6,7])\nown\nIsETF\nTTR\nADX\nTTR\naroon\nTTR\nATR(n=[7, 14, 28])\nNorm.\nTTR\nBBands\nNorm.\nTTR\nCCI\nTTR\nchaikinAD\ndiff(1)\nTTR\nchaikinVolatility\nTTR\nCLV\nTTR\nCMF\nTTR\nCMO\nTTR\nCTI\nTTR\nDEMA\nNorm.\nTTR\nDonchianChannel\nNorm.\nTTR\nEMA\nNorm.\nTTR\nEVWMA\nNorm.\nTTR\nGMMA(short=10, long=[30, 60])\nNorm.\nTTR\nHMA\nNorm.\nTTR\nKST\nTTR\nMACD\nTTR\nMFI\nTTR\nOBV\ndiff(1)\nTTR\nPBands\nNorm.\nTTR\nROC\nTTR\nRSI\nTTR\nrunPercentRank(n=100)\nTTR\nSMI\nTTR\nSNR(n=[20,60])\nTTR\nTDI\nNorm.\nTTR\nTRIX\nTTR\nultimateOscillator\nTTR\nVHF\nTTR\nvolatility\nTTR\nwilliamsAD\ndiff(1)\nTTR\nWPR\nTTR\nZLEMA\nNorm.\nTable C.3: Features xpmq t used as input to the model. The transformation \u201cNorm.\u201d indicates that the feature is normalized by the price of the asset while the transformation \u201cdiff(1)\u201d denotes first differencing.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/573d/573d4611-b154-4622-a402-c888777b23c1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure C.7: The difference in IRt for the long equal-weighted portfolio as a function of the scaling \u03b1t. Decreasing the scaling linearly improves IRt.</div>\n(D.1)\nThe assumption of existence and uniqueness of the inner optimization problems (A1) guarantees that the objective Qp\u03c9, t\u03ba\u03c9pDpmq trainquM m\u201c1q is properly defined. Let us denote the set of solutions to the bilevel problem (Eq. D.1) as \u2126\u02da B \u0102 \u2126, and the \u03c9 component of the set of solutions to the single-level problem (Eq. 10) as \u2126\u02da S . The fact that \u2126\u02da B \u201c \u2126\u02da S directly stems from the fact that the individual components pmq of the outer optimization objective Qp\u00a8q coincide with the inner optimization objectives: Let \u03c9\u02da P \u2126B. By virtue of optimality, @\u03c9 P \u2126: Qp\u03c9\u02da, t\u03ba\u03c9\u02dapDpmq trainquM m\u201c1q \u010f Qp\u03c9, t\u03ba\u03c9pDpmq trainquM m\u201c1q. From the definition of \u03ba\u03c9 and the additivity of Qp\u00a8q, it also holds @\u03c9 P \u2126@t\u03b8pmquM m\u201c1 P \u0398M : Qp\u03c9, t\u03ba\u03c9pDpmq trainquM m\u201c1q \u010f Qp\u03c9, t\u03b8pmquM m\u201c1q. Combining these, we obtain @\u03c9 P \u2126@t\u03b8pmquM m\u201c1 P \u0398M : Qp\u03c9\u02da, t\u03ba\u03c9\u02dapDpmq trainquM m\u201c1q \u010f Qp\u03c9, t\u03b8pmquM m\u201c1q which implies \u03c9\u02da P \u2126S . Let \u03c9\u02da P \u2126S , and let t\u03b8\u02dapmquM m\u201c1 P \u0398M be the corresponding \u03b8 component of the solution. By virtue of optimality, @\u03c9 P \u2126@t\u03b8pmquM m\u201c1 P \u0398M : Qp\u03c9\u02da, t\u03b8\u02dapmquM m\u201c1q \u010f Qp\u03c9, t\u03b8pmquM m\u201c1q. Since \u03ba\u03c9pDpmq trainq P \u0398, it follows that @\u03c9 P \u2126: Qp\u03c9\u02da, t\u03b8\u02dapmquM m\u201c1q \u010f Qp\u03c9, t\u03ba\u03c9pDpmq trainquM m\u201c1q. From the definition of \u03ba\u03c9 and additivity of Qp\u00a8q, it also holds Qp\u03c9\u02da, t\u03ba\u03c9\u02dapDpmq trainquM m\u201c1q \u010f Qp\u03c9\u02da, t\u03b8\u02dapmquM m\u201c1q. Combining these, we obtain @\u03c9 P \u2126 : Qp\u03c9\u02da, t\u03ba\u03c9\u02dapDpmq trainquM m\u201c1q \u010f Qp\u03c9, t\u03ba\u03c9pDpmq trainquM m\u201c1q, which implies \u03c9\u02da P \u2126B.\n# References\nBai, Y., Chen, M., Zhou, P., Zhao, T., Lee, J., Kakade, S., Wang, H., Xiong, C., 2021. How Important is the Train-Validation Split in Meta-Learning?, in: International Conference on Machine Learning, PMLR. pp. 543\u2013553. Bandara, K., Bergmeir, C., Smyl, S., 2020. Forecasting across time series databases using recurrent neural networks on groups of similar series: A clustering approach. Expert Systems with Applications 140, 112896. doi:10.1016/j.eswa.2019.112896.\nBeck, J., Jackson, M.T., Vuorio, R., Whiteson, S., 2023. Hypernetworks in Meta-Reinforcement Learning, in: Proceedings of The 6th Conference on Robot Learning, PMLR. pp. 1478\u20131487. Chen, T., He, T., Benesty, M., Khotilovich, V., Tang, Y., Cho, H., Chen, K., Mitchell, R., Cano, I., Zhou, T., Li, M., Xie, J., Lin, M., Geng, Y., Li, Y., Yuan, J., implementation), X.c.b.X., 2023. Xgboost: Extreme Gradient Boosting. Finn, C., Abbeel, P., Levine, S., 2017. Model-Agnostic MetaLearning for Fast Adaptation of Deep Networks, in: Proceedings of the 34th International Conference on Machine Learning, PMLR. pp. 1126\u20131135. Flennerhag, S., Rusu, A.A., Pascanu, R., Visin, F., Yin, H., Hadsell, R., 2020. Meta-Learning with Warped Gradient Descent. doi:10. 48550/arXiv.1909.00025, arXiv:1909.00025. Godahewa, R., Bandara, K., Webb, G.I., Smyl, S., Bergmeir, C., 2021. Ensembles of localised models for time series forecasting. Knowledge-Based Systems 233, 107518. doi:10.1016/j. knosys.2021.107518. Hadi, A.S., Ling, R.F., 1998. Some Cautionary Notes on the Use of Principal Components Regression. The American Statistician 52, 15\u201319. doi:10.1080/00031305.1998.10480530. Hospedales, T., Antoniou, A., Micaelli, P., Storkey, A., 2021. Metalearning in neural networks: A survey. IEEE transactions on pattern analysis and machine intelligence 44, 5149\u20135169. Hubinger, E., van Merwijk, C., Mikulik, V., Skalse, J., Garrabrant, S., 2021. Risks from Learned Optimization in Advanced Machine Learning Systems. arXiv:1906.01820. Huisman, M., van Rijn, J.N., Plaat, A., 2021. A survey of deep metalearning. Artificial Intelligence Review 54, 4483\u20134541. doi:10. 1007/s10462-021-10004-4. Hyndman, R., Montero-Manso, P., O\u2019Hara-Wild, M., Talagala, T., Wang, E., Yang, Y., Taieb, S.B., Hanqing, C., Lake, D.K., Laptev, N., Moorman, J.R., Zhang, B., 2023. Tsfeatures: Time Series Feature Extraction. Hyndman, R.J., Khandakar, Y., 2008. Automatic Time Series Forecasting: The forecast Package for R. Journal of Statistical Software 27, 1\u201322. doi:10.18637/jss.v027.i03. Hyndman, R.J., Koehler, A.B., Snyder, R.D., Grose, S., 2002. A state space framework for automatic forecasting using exponential smoothing methods. International Journal of Forecasting 18, 439\u2013454. doi:10.1016/S0169-2070(01)00110-8. Izenman, A.J., 1975. Reduced-rank regression for the multivariate linear model. Journal of Multivariate Analysis 5, 248\u2013264. doi:10. 1016/0047-259X(75)90042-1. Januschowski, T., Gasthaus, J., Wang, Y., Salinas, D., Flunkert, V., Bohlke-Schneider, M., Callot, L., 2020. Criteria for classifying forecasting methods. International Journal of Forecasting 36, 167\u2013 177. doi:10.1016/j.ijforecast.2019.05.008. Lake, B., Salakhutdinov, R., Gross, J., Tenenbaum, J., 2011. One shot learning of simple visual concepts, in: Proceedings of the Annual Meeting of the Cognitive Science Society. Lee, Y., Choi, S., 2018. Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace, in: Proceedings of the 35th International Conference on Machine Learning, PMLR. pp. 2927\u2013 2936. Li, Z., Zhou, F., Chen, F., Li, H., 2017. Meta-SGD: Learning to Learn Quickly for Few-Shot Learning. doi:10.48550/arXiv.1707. 09835, arXiv:1707.09835. Lin, Z., Zhao, Z., Zhang, Z., Baoxing, H., Yuan, J., 2020. To Learn Effective Features: Understanding the Task-Specific Adaptation of MAML . Makridakis, S., Gaba, A., Hollyman, R., Petropoulos, F., Spiliotis, E., Swanson, N., 2022. The M6 Financial Duathlon Competition Guidelines. Makridakis, S., Spiliotis, E., Assimakopoulos, V., 2020. The M4\nCompetition: 100,000 time series and 61 forecasting methods. International Journal of Forecasting 36, 54\u201374. doi:10.1016/j. ijforecast.2019.04.014. Malkiel, B.G., 2005. Reflections on the Efficient Market Hypothesis: 30 Years Later. Financial Review 40, 1\u20139. doi:10.1111/j. 0732-8516.2005.00090.x. McFadden, D., 1989. A Method of Simulated Moments for Estimation of Discrete Response Models Without Numerical Integration. Econometrica 57, 995\u20131026. doi:10.2307/1913621, arXiv:1913621. Montero-Manso, P., Hyndman, R.J., 2021. Principles and algorithms for forecasting groups of time series: Locality and globality. International Journal of Forecasting 37, 1632\u20131653. doi:10.1016/j. ijforecast.2021.03.004. Nava, E., Kobayashi, S., Yin, Y., Katzschmann, R.K., Grewe, B.F., 2023. Meta-Learning via Classifier(-free) Diffusion Guidance. doi:10.48550/arXiv.2210.08942, arXiv:2210.08942. Park, E., Oliva, J.B., 2019. Meta-curvature. Advances in Neural Information Processing Systems 32. Raghu, A., Raghu, M., Bengio, S., Vinyals, O., 2019. Rapid learning or feature reuse? towards understanding the effectiveness of maml. arXiv preprint arXiv:1909.09157 arXiv:1909.09157. Ramanarayanan, S., Palla, A., Ram, K., Sivaprakasam, M., 2023. Generalizing supervised deep learning MRI reconstruction to multiple and unseen contrasts using meta-learning hypernetworks. Applied Soft Computing 146, 110633. doi:10.1016/j.asoc.2023. 110633. Ravi, S., Larochelle, H., 2016. Optimization as a model for fewshot learning, in: International Conference on Learning Representations. Shamsian, A., Navon, A., Fetaya, E., Chechik, G., 2021. Personalized Federated Learning using Hypernetworks, in: Proceedings of the 38th International Conference on Machine Learning, PMLR. pp. 9489\u20139502. Smyl, S., 2020. A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting. International Journal of Forecasting 36, 75\u201385. doi:10.1016/j.ijforecast. 2019.03.017. Smyl, S., Kuber, K., 2016. Data preprocessing and augmentation for multiple short time series forecasting with recurrent neural networks, in: 36th International Symposium on Forecasting. Stan\u02c7ek, F., 2023a. A Note on the M6 Forecasting Competition: Designing Parametric Models with Hypernetworks. doi:10.2139/ ssrn.4355794. Stan\u02c7ek, F., 2023b. A Note on the M6 Forecasting Competition: Rank Optimization. doi:10.2139/ssrn.4527154. Ulrich, J., 2021. TTR: Technical Trading Rules. von Oswald, J., Henning, C., Grewe, B.F., Sacramento, J., 2022. Continual learning with hypernetworks. doi:10.48550/arXiv.1906. 00695, arXiv:1906.00695. Wang, H., Zhao, H., Li, B., 2021. Bridging multi-task learning and meta-learning: Towards efficient training and effective adaptation, in: International Conference on Machine Learning, PMLR. pp. 10991\u201311002. Zhang, Y., Yang, Q., 2022. A Survey on Multi-Task Learning. IEEE Transactions on Knowledge and Data Engineering 34, 5586\u20135609. doi:10.1109/TKDE.2021.3070203. Zhao, D., Kobayashi, S., Sacramento, J., von Oswald, J., 2020. MetaLearning via Hypernetworks, in: Zhao, Dominic; Kobayashi, Seijin; Sacramento, Jo\u02dcao; von Oswald, Johannes (2020). MetaLearning via Hypernetworks. In: 4th Workshop on Meta-Learning at NeurIPS 2020 (MetaLearn 2020), Virtual Conference, 11 December 2020, IEEE., IEEE, Virtual Conference. doi:10.5167/ uzh-200298. Zintgraf, L., Shiarli, K., Kurin, V., Hofmann, K., Whiteson, S., 2019.\nFast context adaptation via meta-learning, in: International Conference on Machine Learning, PMLR. pp. 7693\u20137702.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of financial forecasting and investment strategies within the M6 competition, highlighting the limitations of previous methods and the necessity for a more adaptable and efficient approach.",
        "problem": {
            "definition": "The problem focuses on predicting the next 4-week returns of 100 assets and optimizing portfolio weights to maximize risk-adjusted returns.",
            "key obstacle": "Existing methods often fail to effectively capture the heterogeneity in data generating processes across different assets, limiting their predictive power."
        },
        "idea": {
            "intuition": "The idea arose from the observation that a meta-learning approach could leverage similarities across forecasting tasks while accommodating differences in data generating processes.",
            "opinion": "The proposed method utilizes hypernetworks to create a parametric model tailored to the specific forecasting tasks, allowing for better adaptation to varying data characteristics.",
            "innovation": "This method distinguishes itself by employing a simultaneous search over prediction functions and their optimal parameters, enabling effective backpropagation without higher-order derivatives."
        },
        "method": {
            "method name": "MtMs",
            "method abbreviation": "MtMs",
            "method definition": "A meta-learning framework that constructs a hypernetwork capable of generating task-specific parametric models for time-series forecasting.",
            "method description": "The MtMs model employs hypernetworks to optimize predictions across a family of related forecasting tasks.",
            "method steps": [
                "Train the base model on pooled data to capture general trends.",
                "Initialize the meta module with trained weights and optimize task-specific parameters.",
                "Utilize backpropagation for efficient training across tasks."
            ],
            "principle": "The effectiveness of the method stems from its ability to model the heterogeneity in data generating processes, allowing for more accurate predictions and better performance in forecasting."
        },
        "experiments": {
            "evaluation setting": "The evaluation involved the M6 competition dataset, which included 100 assets, with predictions assessed using ranked probability score (RPS) loss and investment performance measured by information ratio (IR).",
            "evaluation method": "The performance was evaluated by comparing the predictions of the MtMs model against baseline methods and assessing the rankings achieved in the competition."
        },
        "conclusion": "The proposed methods secured 4th place in the forecasting challenge and 6th place in the investment challenge, ultimately achieving 1st place in the duathlon, demonstrating the model's effectiveness in both tasks.",
        "discussion": {
            "advantage": "The main advantage of the MtMs approach is its flexibility in adapting to diverse time-series data, enabling superior predictive performance compared to conventional methods.",
            "limitation": "Despite its strengths, the model's predictions contain limited directional information, which restricts their utility for forming investment portfolios.",
            "future work": "Future research should explore the application of the MtMs model to other meta-learning challenges and refine its capabilities for better investment decision-making."
        },
        "other info": {
            "acknowledgments": "The authors thank the M6 organizers and contributors for their support throughout the competition."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "This paper addresses the issue of financial forecasting and investment strategies within the M6 competition, highlighting the limitations of previous methods and the necessity for a more adaptable and efficient approach."
        },
        {
            "section number": "1.2",
            "key information": "Existing methods often fail to effectively capture the heterogeneity in data generating processes across different assets, limiting their predictive power."
        },
        {
            "section number": "2.1",
            "key information": "The problem focuses on predicting the next 4-week returns of 100 assets and optimizing portfolio weights to maximize risk-adjusted returns."
        },
        {
            "section number": "2.2",
            "key information": "The MtMs model employs hypernetworks to optimize predictions across a family of related forecasting tasks."
        },
        {
            "section number": "3.1",
            "key information": "The evaluation involved the M6 competition dataset, which included 100 assets, with predictions assessed using ranked probability score (RPS) loss and investment performance measured by information ratio (IR)."
        },
        {
            "section number": "5.4",
            "key information": "The main advantage of the MtMs approach is its flexibility in adapting to diverse time-series data, enabling superior predictive performance compared to conventional methods."
        },
        {
            "section number": "6.4",
            "key information": "Future research should explore the application of the MtMs model to other meta-learning challenges and refine its capabilities for better investment decision-making."
        }
    ],
    "similarity_score": 0.5726711679138479,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-0214_large/papers/Designing Time-Series Models With Hypernetworks & Adversarial Portfolios.json"
}