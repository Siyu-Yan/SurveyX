{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2406.07640",
    "title": "When is an Embedding Model More Promising than Another?",
    "abstract": "Embedders play a central role in machine learning, projecting any object into numerical representations that can, in turn, be leveraged to perform various downstream tasks. The evaluation of embedding models typically depends on domain-specific empirical approaches utilizing downstream tasks, primarily because of the lack of a standardized framework for comparison. However, acquiring adequately large and representative datasets for conducting these assessments is not always viable and can prove to be prohibitively expensive and time-consuming. In this paper, we present a unified approach to evaluate embedders. First, we establish theoretical foundations for comparing embedding models, drawing upon the concepts of sufficiency and informativeness. We then leverage these concepts to devise a tractable comparison criterion (information sufficiency), leading to a task-agnostic and self-supervised ranking procedure. We demonstrate experimentally that our approach aligns closely with the capability of embedding models to facilitate various downstream tasks in both natural language processing and molecular biology. This effectively offers practitioners a valuable tool for prioritizing model trials.",
    "bib_name": "darrin2024embeddingmodelpromisinganother",
    "md_text": "# When is an Embedder More Promising than Another?\n\u2020Maxime DARRIN\u22c6,1,2,3,4 \u2020Philippe FORMONT1,2,4,5 Ismail BEN AYED1,5 Jackie Chi Kit CHEUNG2,3 Pablo PIANTANIDA1,2,4,6 1International Laboratory on Learning Systems, 2Mila - Quebec AI Institute, 3McGill University 4Universit\u00e9 Paris-Saclay, 5\u00c9cole de technologie sup\u00e9rieure (ETS), 6CNRS, CentraleSup\u00e9lec maxime.darrin@mila.quebec, philippe.formont@mila.quebec\n# Abstract\nEmbedders play a central role in machine learning, projecting any object into numerical representations that can, in turn, be leveraged to perform various downstream tasks. The evaluation of embedding models typically depends on domain-specific empirical approaches utilizing downstream tasks, primarily because of the lack of a standardized framework for comparison. However, acquiring adequately large and representative datasets for conducting these assessments is not always viable and can prove to be prohibitively expensive and time-consuming. In this paper, we present a unified approach to evaluate embedders. First, we establish theoretical foundations for comparing embedding models, drawing upon the concepts of sufficiency and informativeness. We then leverage these concepts to devise a tractable comparison criterion (information sufficiency), leading to a task-agnostic and self-supervised ranking procedure. We demonstrate experimentally that our approach aligns closely with the capability of embedding models to facilitate various downstream tasks in both natural language processing and molecular biology. This effectively offers practitioners a valuable tool for prioritizing model trials.\narXiv:2406.07640v\n# 1 Introduction\nEmbeddings are a prominent tool in machine learning and are used in multiple fields, such as natural language processing [64, 83], computer vision [93, 59, 12, 53] or bioinformatics [67, 3, 23, 112]. These models embed objects such as images, texts, or molecules into numerical representations that can be used to perform numerous downstream tasks by preserving key features of the object [76, 111]. Depending on the data modalities, intended purpose, and available resources, embedders showcase a wide variety of architectures, training settings (unsupervised, supervised, self-supervised, etc.), objectives (masked language modeling, contrastive learning, etc.) [20, 100, 78, 112, 39], and datasets [65, 86, 31, 38, 5, 117]. And more recently, foundation models have become a natural starting point to create embedders [21, 106, 52, 73]. This diversity and variety of options makes selecting the most promising embedders for a data distribution challenging [75]. Most work evaluates embedders focusing on the performance they enable on a finite set of downstream tasks [85, 17, 90, 91, 81, 24]. Nevertheless, this evaluation process encounters two primary limitations. Firstly, it is not scalable concerning the number of embedders and tasks, as it requires fitting a downstream model for each task. Hence, prioritizing the evaluation of the most promising models becomes essential to mitigate computational costs. Secondly, acquiring high-quality labels can be a time-consuming and notably expensive endeavor in various applications. To overcome these limitations, in this paper, we explore task-agnostic evaluation metrics for embedders relying solely on pairwise comparisons between embedders, i.e., without the need for labeled data in downstream tasks.\nore specifically, our contributions can be summarized as follows: 1. An innovative theoretical framework for comparing embedding models: We cast the problem of ranking embedders into the noisy communication channels ordering (Sec. 2.2) and statistical experiments comparison settings (Sec. 2.3). We exploit the notions of sufficiency and informativeness and relax them, leveraging the concept of deficiency introduced by Le Cam [63] (Sec. 2.4), which is reframed to account for concepts and features. These concepts provide us with tools to establish an embedder ranking. 2. A practical relaxation: Estimating deficiency from data samples presents significant challenges. We propose the concept of information sufficiency (IS), which quantifies the information required to simulate one embedder from another (Sec. 3). We estimate the information efficiency to get a task-agnostic and label-free comparison tool for embedders evaluation. 3. Extensive experimental validation: The expected IS correlates with the ability of embedders to enable a wide range of downstream tasks. In NLP (Sec. 5) and molecular modeling (Sec. 6), our method respectively achieves Spearman ranking correlations of 0.90 (56 tasks) and 0.94 (31 tasks); providing an efficient model trial prioritization tool for practitioners.\n# 1.1 Related works\nEmbedding evaluation. Embedding evaluation is mainly performed based on a limited set of downstream tasks [22, 91, 81, 24], for which the embeddings are used as inputs to smaller models. Therefore, embedders evaluation is field- and task-specific. In NLP, [41, 85] they rely on a limited set of tasks; more recently, the Massive Text Embedding Benchmark (MTEB) [75] followed this task-oriented trend and offered standardized test bed for embedders encompassing various downstream tasks in NP. Devising statistical tests to compare models and learning algorithms has a long history [30]. However, most works propose statistical tests relying on the performance of the downstream tasks of interests [60, 11]. Other works study the expressiveness of embedders and connect it to performance on downstream tasks [107, 25], but mostly focus on geometrical properties of the high dimensional representation in self-supervised learning settings [2, 42, 45]. Probing. While probing methods do not aim at comparing embedders, they evaluate their representations to discover what these models have learned. They train small models on the internal representations of large models to perform specific downstream tasks. These procedures allow researchers to assess what information is present and recoverable from these embeddings [10, 1, 88, 84]. Other work proposed measuring mutual information (MI) between internal representations and labels. It has been used to evaluate the difficulty of a dataset as the predictiveness of the labels using the features [35]. For instance, [97] evaluates the utility of representations in astrophysics to predict physical properties. Following this trend, [54] leverages the point-wise MI between Gaussian distributions to evaluate text-to-images and image-to-text generative models. However, none of these methods have focused on comparing embedders in the general case to the best of our knowledge.\n# 2 Theoretical Foundations for Comparing Embedding Models\n# 2.1 Background and notation\nWe assume that all considered spaces are standard Borel [28] Each such space U is equipped with its Borel \u03c3-algebra B(U). The set of all probability measures on U is denoted by P(U) The total variation distance between P and Q is denoted by \u2225P \u2212Q\u2225TV. Given a joint probability measure PXY induced by two random variables X \u2208X and U \u2208U, the Mutual Information [27] is denoted by I(X; U). A Markov (or transition probability) kernel between X and U is a mapping PU|X : B(U) \u00d7 X \u2192[0, 1]. The space of all such PU|X is denoted by K(U|X) and (M \u25e6PU|X)(Z|x) indicates the composition of Markov kernels M \u2208K(Z|U) and PU|X \u2208K(U|X). For further details, refer to Appendix A.\n# 2.2 Sufficiency and informativeness ordering of embedding models\nWe aim to compare embedding models without relying on labeled data for downstream tasks. Let us consider two embedding models represented by their Markov kernels (or transition probabilities) PU|X \u2208K(U|X) and PZ|X \u2208K(Z|X), any target set Y of (discrete or continuous) concepts and\nfeature space X with joint probability measure PY X \u2208P(Y \u00d7 X) induced by random varia (Y, X) \u2208Y \u00d7 X, as illustrated in Figure 1. First, we study the question:\nWhat sufficient conditions must be met by the embedding model U relative to Z to guarantee that I(Y ; U) \u2a7eI(Y ; Z) for all probability distributions PY X ?\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/42dd/42dd34af-c623-47a1-a929-61c0784b2477.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(embedder Z)</div>\nFigure 1: Communicating a concept y \u2208Y over two embedding models with prediction \u03c1Z(Z).\n<div style=\"text-align: center;\">Figure 1: Communicating a concept y \u2208Y over two embedding models with prediction \u03c1Z(Z).</div>\nU and Z, respectively. This process is illustrated in Figure 1. It naturally satisfies the Markov chain Y \u2194X \u2194(U, Z). A desirable property is that the embedding models U and Z retain as much pertinent information as feasible to predict Y . We shall be interested in the underlying information relationships between those embedding models that can be interpreted as channel U being \"more informative\" for communicating Y than channel Z. The first attempt to introduce an ordering between communication channels appears in Shannon [94]. K\u00f6rner and Marton later introduced [57] the concepts of \"less noisy\" (or more informative) and \"degraded\" (or sufficiency) orderings between channels. Definition 1 (Sufficiency and informativeness orderings [57]). Let PU|X and PZ|X be two Markov kernels (embedding models). \u2022 Sufficiency U \u227dS Z. The embedding model PU|X is said to be \"sufficient\" for the embedding model PU|X (or Z to be degraded w.r.t. U) if and only if there exists another Markov kernel M \u2208T (Z|U) such that \u2225M\u25e6PU|X \u2212PZ|X\u2225TV = 0, i.e. Z can be simulated from U using M without information loss). \u2022 More informative U \u227dI Z. The embedding model PU|X is said to be \"more informative\" (or less noisy) than PZ|X if and only if the embedding models always satisfy the inequality I(Y ; U) \u2a7eI(Y ; Z), \u2200PY X \u2208P(Y \u00d7 X). Proposition 1 (Relationships of sufficiency and information). The following relationships hold: (i) Sufficiency \u21d2informativeness. If the embedding model PU|X is sufficient for the embedding model PZ|X, i.e. U \u227dS Z, then U \u227dI Z. However, Informativeness \u21cfsufficiency. (ii) Informativeness \u21d2higher capacity to distinguish concepts. If the embedding model PU|X is more informative than embedding model PZ|X, i.e. U \u227dI Z, then KL \ufffd PU|Y (\u00b7|y0)\u2225PU|Y (\u00b7|y1) \ufffd \u2a7eKL \ufffd PZ|Y (\u00b7|y0)\u2225PZ|Y (\u00b7|y1) \ufffd , for any pair of concepts and all probability distributions.\nU and Z, respectively. This process is illustrated in Figure 1. It naturally satisfies the Markov chain Y \u2194X \u2194(U, Z). A desirable property is that the embedding models U and Z retain as much pertinent information as feasible to predict Y . We shall be interested in the underlying information relationships between those embedding models that can be interpreted as channel U being \"more informative\" for communicating Y than channel Z. The first attempt to introduce an ordering between communication channels appears in Shannon [94]. K\u00f6rner and Marton later introduced [57] the concepts of \"less noisy\" (or more informative) and \"degraded\" (or sufficiency) orderings between channels. Definition 1 (Sufficiency and informativeness orderings [57]). Let PU|X and PZ|X be two Markov kernels (embedding models). \u2022 Sufficiency U \u227dS Z. The embedding model PU|X is said to be \"sufficient\" for the embedding model PU|X (or Z to be degraded w.r.t. U) if and only if there exists another Markov kernel M \u2208T (Z|U) such that \u2225M\u25e6PU|X \u2212PZ|X\u2225TV = 0, i.e. Z can be simulated from U using M without information loss). \u2022 More informative U \u227dI Z. The embedding model PU|X is said to be \"more informative\" (or less noisy) than PZ|X if and only if the embedding models always satisfy the inequality I(Y ; U) \u2a7eI(Y ; Z), \u2200PY X \u2208P(Y \u00d7 X).\n\ufffd |\u00b7|\u2225|\u00b7| \ufffd \ufffd |\u00b7|\u2225|\u00b7| for any pair of concepts (y0, y1) \u2208Y \u00d7 Y and all probability distributi\nRemark 1. An immediate consequence of claim (i) is that the sufficient condition between embedding models implies that the embedding model U is more informative than the embedding model Z relative to all target concepts in Y over all possible data distributions: I(Y ; U) \u2a7eI(Y ; Z), for all probability distributions PY X. Although U being more informative than Z does not necessarily imply U \u227dS Z [57, 66]; (ii) states that being more informative ensures a higher statistical discrimination capacity between any pairs of target concepts (for further discussion, see Sec. B.2). Motivated by the concepts of sufficiency and informativeness between embedding models, we can inquire about their statistical consequences for a learner conducting an inference task on these embeddings. More precisely, given a finite set of concepts Y, if U \u227dS Z, is the Bayes risk expected to be smaller when the inference is based on U than when it is based on Z?\nFrom an information-theoretic perspective [27], the quality of an embedding model can be likened to the capacity of a noisy communication channel with an uncoded input (e.g., a text, a molecule...), where a downstream task of interest is performed at the output (the embedding) of the channel. Let Y \u2208Y represent the message (the source) to be communicated over both channels; X represents the transmitted signal; and PU|X and PZ|X the communication channels with outputs\nThe pursuit of comparing statistical experiments originated from the seminal paper by Bohnenblust, Shapley, and Sherman [16], followed by subsequent contributions by Blackwell [13, 14]. They formally established the relationships between sufficiency (Def. 1) and inference procedures.\nIn our framework, a statistical experiment [13] consists of a mathematical abstraction (see Appendix A for further details) intended to represent a downstream task where a learner aims at inferring a concept y \u2208Y from the embeddings U or Z. Deciding what embedder should be used to perform a given task is too general. In this work, we do not take into account the computational cost or the size of an embedder and solely focus on the following question:\n# What are the necessary and sufficient conditions that ensure that employing the embedding U for any task PY X leads to lower risk compared to using the embedding Z?\n# What are the necessary and sufficient conditions that ensure that employing the embedding U for any task PY X leads to lower risk compared to using the embedding?\nWhat are the necessary and sufficient conditions that ensure that employing the embedding U for any task PY X leads to lower risk compared to using the embedding Z?\nDrawing parallels with the theoretical framework established for comparing statistical experiments, a relationship can be derived between the concept of sufficiency and the expected risk for a specific task (see Sec. B.5 for further discussion).\nDrawing parallels with the theoretical framework established for comparing statistical experiments, a relationship can be derived between the concept of sufficiency and the expected risk for a specific task (see Sec. B.5 for further discussion). We concentrate on the scenario where Y consists of a finite number of concepts (e.g., classification tasks), as it is a significant case in its own right [104] and provide fundamental insights for the present work. The next Proposition states an important relation between the concept of sufficiency and the expected Bayes risk on any classification task. Proposition 2 (Comparison of embedding models through Bayes risks). Given two embedding models PU|X \u2208K(U|X) and PZ|X \u2208K(Z|X), the following statements are equivalent: (i) The embedding model PU|X is sufficient relative to PZ|X, i.e. U \u227dS Z. (ii) For all probability measures PY X on finite alphabets Y \u00d7 X, the expected Bayes risks satisfy inf \u03c1U:U\u2192P(Y) Pr \ufffd \u03c1Y (U) \u0338= Y \ufffd \u2a7d inf \u03c1Z:Z\u2192P(Y) Pr \ufffd \u03c1Z(Z) \u0338= Y \ufffd .\nWe concentrate on the scenario where Y consists of a finite number of concepts (e.g., classification tasks), as it is a significant case in its own right [104] and provide fundamental insights for the present work. The next Proposition states an important relation between the concept of sufficiency and the expected Bayes risk on any classification task. Proposition 2 (Comparison of embedding models through Bayes risks). Given two embedding models PU|X \u2208K(U|X) and PZ|X \u2208K(Z|X), the following statements are equivalent:\n(ii) For all probability measures PY X on finite alphabets Y \u00d7 X, the expected Bayes risks satisfy inf \u03c1U:U\u2192P(Y) Pr \ufffd \u03c1Y (U) \u0338= Y \ufffd \u2a7d inf \u03c1Z:Z\u2192P(Y) Pr \ufffd \u03c1Z(Z) \u0338= Y \ufffd .\n\ufffd \ufffd \ufffd \ufffd Remark 2. In other words, if we can fully simulate an embedder Z from another embedder U, the expected risk across all potential classification tasks cannot be greater when using U compared to Z. The proof of this Proposition is given in Sec. B.3. It is worth mentioning that various versions of this result are available in the literature [104]. However, our extension here, in a simpler setting, incorporates concepts and features into the experiment comparison framework.\n# 2.4 Challenges in ranking embedding models and their deficiency\nAccording to the notion of \"sufficiency\", we can distinguish the three following possibilities: \u2022 Equivalence: U \u227dS Z and Z \u227dS U denoted U \u2248Z. U and Z can simulate each other. \u2022 Comparability: U \u227dS Z but Z \u0338\u227dS U only Z can be simulated from U. \u2022 Non-comparability: U \u0338\u227dS Z and Z \u0338\u227dS U, neither U nor Z can simulate each other.\nAccording to the notion of \"sufficiency\", we can distinguish the three following possibilities: \u2022 Equivalence: U \u227dS Z and Z \u227dS U denoted U \u2248Z. U and Z can simulate each other. \u2022 Comparability: U \u227dS Z but Z \u0338\u227dS U only Z can be simulated from U. \u2022 Non-comparability: U \u0338\u227dS Z and Z \u0338\u227dS U, neither U nor Z can simulate each other. Our results up to now only account for the two first possibilities. However, two embedders are generally not comparable (Sec. B.4). This issue was addressed by Le Cam [63], who introduced the notion of \"deficiency\". Definition 2. The deficiency \u03b4(P \u2192P) of P relative to P is defined as [63]\n\u2022 Equivalence: U \u227dS Z and Z \u227dS U denoted U \u2248Z. U and Z can simulate each other. \u2022 Comparability: U \u227dS Z but Z \u0338\u227dS U only Z can be simulated from U. \u2022 Non-comparability: U \u0338\u227dS Z and Z \u0338\u227dS U, neither U nor Z can simulate each other.\n \u0338 \u0338 Our results up to now only account for the two first possibilities. However, two embedders are generally not comparable (Sec. B.4). This issue was addressed by Le Cam [63], who introduced the\n \u0338 \u0338 Our results up to now only account for the two first possibilities. However, two embedders a generally not comparable (Sec. B.4). This issue was addressed by Le Cam [63], who introduced th notion of \"deficiency\". Definition 2. The deficiency \u03b4(PU|X \u2192PZ|X) of PZ|X relative to PU|X is defined as [63]\n\u03b4(PU|X \u2192PZ|X) \u225c inf M\u2208K(Z|U) \u2225M \u25e6PU|X \u2212PZ|X\u2225TV,\nwhere the infimum is taken over all Markov kernels (or transition probabilities) M \u2208K(Z|U), mapping stochastically U and Z, and \u03b4 measures error between the simulated and true embedders. \u03b4 indicates how well one model can be reconstructed from the other, it induces a natural relaxation of the sufficiency where the reconstruction does not have to be perfect1 for us to obtain guarantees on\nwhere the infimum is taken over all Markov kernels (or transition probabilities) M \u2208K(Z|U), mapping stochastically U and Z, and \u03b4 measures error between the simulated and true embedders.\nwhere the infimum is taken over all Markov kernels (or transition probabilities) M \u2208K(Z|U), mapping stochastically U and Z, and \u03b4 measures error between the simulated and true embedders. \u03b4 indicates how well one model can be reconstructed from the other, it induces a natural relaxation of the sufficiency where the reconstruction does not have to be perfect1 for us to obtain guarantees on 1If U \u227dS, Z, then \u03b4(PZ|X \u2192PU|X) = 0, while if U \u0338\u227dS Z, then \u03b4(PZ|X \u2192PU|X) > 0.\nthe downstream tasks performance (See Corollary 1). It avoids the non-comparability problem by evaluating \"how much information\" we lose when passing from one model to the other one. Le Cam [63] showed that, for a given task Y , the deficiency \u03b4(PU|Y \u2192PZ|Y ) is directly related to the expected Bayes risks on the task (see Sec. B.6). We extend this result to the comparison of two embedding models PU|X and PZ|X in a task-agnostic manner and build the relation to the expected Bayes risks for any classification task Y , defined as RU(Y ) \u225c inf \u03c1U:U\u2192P(Y) Pr \ufffd \u03c1U(U) \u0338= Y \ufffd . Corollary 1. Given two embedding models PU|X and PZ|X, the following statements are equivalent: (i) The deficiency \u03b4(PU|X \u2192PZ|X) \u2a7d\u03f5. (ii) For any probability distribution PY X on finite alphabets Y \u00d7 X, there exists \u03f5 > 0 satisfying RU(Y ) \u2212\u03f5|X| \u2a7dRZ(Y ). The proof of this Corollary is relegated to Sec. B.3. Remark 3. In particular, we can infer that for any classification task Y , the expected Bayes risk of the embedding model U is upper bounded by the expected Bayes risk of the embedding model Z:\nthe downstream tasks performance (See Corollary 1). It avoids the non-comparability problem by evaluating \"how much information\" we lose when passing from one model to the other one. Le Cam [63] showed that, for a given task Y , the deficiency \u03b4(PU|Y \u2192PZ|Y ) is directly related to the expected Bayes risks on the task (see Sec. B.6). We extend this result to the comparison of two embedding models PU|X and PZ|X in a task-agnostic manner and build the relation to the expected Bayes risks for any classification task Y , defined as RU(Y ) \u225c inf \u03c1U:U\u2192P(Y) Pr \ufffd \u03c1U(U) \u0338= Y \ufffd . Corollary 1. Given two embedding models PU|X and PZ|X, the following statements are equivalent: (i) The deficiency \u03b4(PU|X \u2192PZ|X) \u2a7d\u03f5. (ii) For any probability distribution PY X on finite alphabets Y \u00d7 X, there exists \u03f5 > 0 satisfying\nLe Cam [63] showed that, for a given task Y , the deficiency \u03b4(PU|Y \u2192PZ|Y ) is directly related to the expected Bayes risks on the task (see Sec. B.6). We extend this result to the comparison of two embedding models PU|X and PZ|X in a task-agnostic manner and build the relation to the expected Bayes risks for any classification task Y , defined as RU(Y ) \u225c inf \u03c1U:U\u2192P(Y) Pr \ufffd \u03c1U(U) \u0338= Y \ufffd . Corollary 1. Given two embedding models PU|X and PZ|X, the following statements are equivalent: (i) The deficiency \u03b4(PU|X \u2192PZ|X) \u2a7d\u03f5. (ii) For any probability distribution PY X on finite alphabets Y \u00d7 X, there exists \u03f5 > 0 satisfying RU(Y ) \u2212\u03f5|X| \u2a7dRZ(Y ). The proof of this Corollary is relegated to Sec. B.3. Remark 3. In particular, we can infer that for any classification task Y , the expected Bayes risk of the embedding model U is upper bounded by the expected Bayes risk of the embedding model Z: RU(Y ) \u2212RZ(Y ) \u2a7d|X|\u03b4(PU|X \u2192PZ|X), for all distributions PY X, and similarly, |RU(Y ) \u2212RZ(Y )| \u2a7d|X| max \ufffd \u03b4(PU|X \u2192PZ|X), \u03b4(PZ|X \u2192PU|X) \ufffd , for all distributions PY X. If both deficiencies are small, the resulting expected Bayes risks of the embedding models U and Z will be close to each other for any target task Y .\nRU(Y ) \u2212\u03f5|X| \u2a7dRZ(Y ). The proof of this Corollary is relegated to Sec. B.3. Remark 3. In particular, we can infer that for any classification task Y , the expected Bayes risk of the embedding model U is upper bounded by the expected Bayes risk of the embedding model Z: RU(Y ) \u2212RZ(Y ) \u2a7d|X|\u03b4(PU|X \u2192PZ|X), for all distributions PY X, and similarly, |RU(Y ) \u2212RZ(Y )| \u2a7d|X| max \ufffd \u03b4(PU|X \u2192PZ|X), \u03b4(PZ|X \u2192PU|X) \ufffd , for all distributions PY X. If both deficiencies are small, the resulting expected Bayes risks of the embedding models U and Z will be close to each other for any target task Y .\nR \u2212||R The proof of this Corollary is relegated to Sec. B.3. Remark 3. In particular, we can infer that for any classification task Y , the expected Bayes risk of the embedding model U is upper bounded by the expected Bayes risk of the embedding model Z: RU(Y ) \u2212RZ(Y ) \u2a7d|X|\u03b4(PU|X \u2192PZ|X), for all distributions PY X, \ufffd \ufffd\n# uantifying Information Sufficiency Between Embedding M\nWe want to compare embedding models using the concept of deficiency, leveraging Prop. 2 and Corollary 1. These propositions suggest that the performance on any classification task of an embedding model U relative to the model Z is bounded by \u03b4(PU|X \u2192PZ|X). However, estimating the deficiency from data samples is notably challenging [95], and while upper bounds derivation exists, they do not necessarily make it tractable.\n# 3.1 Estimating Information Sufficiency\nThe deficiency \u03b4(PU|X \u2192PZ|X) between two embedding models PU|X and PZ|X, measures how well U can be used to simulate Z using a Markov kernel M \u2208K(Z|U). This section aims to build a tractable proxy for this reconstruction cost. To this end, we estimate how much we can reduce the uncertainty about Z by observing U by learning an appropriate Markov kernel. This corresponds to the information sufficiency [29, 4] and can be interpreted as the information-theoretic counterpart of the deficiency. The information deficiency between U and Z is then defined as: Definition 3 (Information sufficiency). The information sufficiency IS(U \u2192Z), relative to parametric classes of distributions F\u0398(Z) and K\u0398(Z|U) (multivariate Gaussian mixtures [82]) is defined: \ufffd \ufffd\n\ufffd \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd Remark 4. When the information sufficiency IS(U \u2192Z) is large, it signifies that U offers a substantial amount of information to simulate Z, a proxy for a small deficiency. Conversely, when IS(U \u2192Z) is lower, it implies that the channel PZ|Y is subject to considerable noise or randomness, leading to a greater loss of statistical information.\n\ufffd \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd Remark 4. When the information sufficiency IS(U \u2192Z) is large, it signifies that U offers a substantial amount of information to simulate Z, a proxy for a small deficiency. Conversely, when IS(U \u2192Z) is lower, it implies that the channel PZ|Y is subject to considerable noise or randomness, leading to a greater loss of statistical information. We hence attempt to simulate Z from U by learning a Markov kernel M \u2208K\u0398(Z|U), via a mixture of multivariate Gaussians, and measure the uncertainty reduction it induces.\nWe hence attempt to simulate Z from U by learning a Markov kernel M \u2208K\u0398(Z|U), via a mixture of multivariate Gaussians, and measure the uncertainty reduction it induces.\nPairwise embedder evaluation. For set of embbeders (Zk)k represented by their Markov kernels {PZk|X}k, we compute the pairwise information sufficiency IS(Zk \u2192Zl). The pairwise information sufficiency matrix defines the adjacency matrix of a directed graph of embedders (Figure 2). Corollary 1 shows that embedders sharing high information sufficiency are expected to perform similarly on any downstream tasks, motivating the identification of communities in the graph. While the graph construction is in O(N 2); where N is the number of embedders, it is in practice tractable for a reasonable number of embedders (the reader is referred to Sec. E.5) for more details).\n(1)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5381/5381fc27-1d9c-454e-80d7-4f8cc2c6be23.png\" style=\"width: 50%;\"></div>\nPractical embedding evaluation. We construct the set of all information sufficiency using Zk: SIS (k) = {IS(Zk \u2192Zl)}l\u0338=k. We build our information sufficiency score (IS score) by taking the median of SIS (k). Details on the IS score\u2019s estimation, such as the motivation behind the median choice, can be found in Sec. E.1.\nFigure 2: Pairwise IS for text embedders.\n# 4 Experimental Setup\nWe aim to evaluate the practical utility of the IS score to rank and select the best embedders for a given data distribution. We compare this ranking to those obtained on various downstream tasks. Our experimental protocol is divided into three main steps:\nWe aim to evaluate the practical utility of the IS score to rank and select the best embedders for a given data distribution. We compare this ranking to those tained on various downstream tasks. Our experimental protocol is divided into three main steps: 1. We evaluate the IS score of the models by identifying a large and diverse dataset that is supposed to be representative of the data distribution of interest. 2. We train a small feedforward neural network (\u03c1Zk) per embedder PZk|X to perform each downstream task and record its performances (R2 score for regression, AUROC/accuracy for binary/multiclass classification). 3. We compare the models\u2019 performances on the downstream tasks and the IS score by measuring three types of correlations: the Pearson correlation, the Spearman correlation, and the Kendall-Tau coefficient.2\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/efee/efeeea75-de96-48bb-89e5-99e1b2c5965b.png\" style=\"width: 50%;\"></div>\n\u03f1p\n\u03f1s\n\u03c4\nRetrieval (15 datasets)\n0.89\n0.89\n0.69\nClassification (12 datasets)\n0.92\n0.88\n0.73\nClustering (11 datasets)\n0.86\n0.85\n0.66\nSTS (10 datasets)\n0.92\n0.83\n0.63\nReranking (4 datasets)\n0.84\n0.78\n0.64\nAverage (56 datasets)\n0.94\n0.90\n0.73\nAdditional Classif (8 datasets)\n0.89\n0.84\n0.66\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a807/a807ccad-68c7-422a-aa9b-7cf7d6a8abf7.png\" style=\"width: 50%;\"></div>\nFigure 3: Correlation between IS scores and downstream task performances in (a) NLP and (b Molecular Modelling. \u03f1p is the Pearson correlation, \u03f1s is the spearman correlation, and \u03c4 is th Kendall-Tau coefficient. See Sec. C.3.1 for unaggregated results in NLP and Sec. D.3 in molecula modeling.\nFigure 3: Correlation between IS scores and downstream task performances in (a) NLP and (b) Molecular Modelling. \u03f1p is the Pearson correlation, \u03f1s is the spearman correlation, and \u03c4 is the Kendall-Tau coefficient. See Sec. C.3.1 for unaggregated results in NLP and Sec. D.3 in molecular\nFor the experiments in molecular modeling, in each subset regression and classi e, we do not compute the Pearson correlation to avoid mixing scores obtained for\n\u03f1p\n\u03f1s\n\u03c4\nAbsorption (8 datasets)\n-\n0.89\n0.70\nDistribution (3 datasets)\n-\n0.89\n0.70\nMetabolism (8 datasets)\n-\n0.94\n0.79\nExcretion (3 datasets)\n-\n0.77\n0.60\nToxicity (9 datasets)\n-\n0.92\n0.75\nADMET (31 datasets)\n-\n0.94\n0.80\nDTI (1496 tasks) see Sec. D.4\n-\n0.88\n0.70\n<div style=\"text-align: center;\">(b) Molecular Modelling</div>\n(b) Molecular Modelling\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fa04/fa04934c-b73b-4eeb-b0b6-11df003950ad.png\" style=\"width: 50%;\"></div>\n# 5 Text Embeddings Evaluation\n# 5.1 Experimental setting\nEmbedders & Datasets. We compared 34 models with different training objectives, training datasets, and architectures. We included embedders derived from modern LLM such as LLaMA [106], Mistral [52], Gemma [102], Croissant [37] and T5 encoders [77]; common embedders derived from BERT architectures [31, 38, 85] or RobERTa [41] and embedders trained on specific embeddings objectives such Angle [64], Stella4, E5 models [113], LaBSE [38]. A comprehensive list of the models can be found in Sec. C.1, Tab. 1 with their main characteristics and links to the Huggingface Hub for reproducibility. We used them to extract embeddings for many different datasets from the MTEB benchmark such as Banking77 [19], Sickr [122], Amazon polarity [72], SNLI [120] and IMDB [70]. We provide the datasets statistics in Sec. C.1, Tab. 2.\nDownstream tasks evaluation. We rely on the results released on the MTEB leaderboard5 an compare our rankings to the rankings and scores obtained by the different models on the different task We evaluate additional tasks that are not included in the MTEB benchmark, such as tweet_eval [ 74, 7, 109, 9], DAIR Emotion [92], agnews topic classification [123], Clinc intent detection [62 PAWS-X [118] and Rotten Tomatoes [79].\n# 5.2 Model\u2019s Information Sufficiency analysis\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9e00/9e00e389-5dfd-4fd2-b51a-06fa65769765.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Figure 4a, presents the information sufficiency directed graph and the induced communities. Figure 4b displays the performance on additional downstream tasks and models not evaluated in the MTEB leaderboard. Figure 4c shows that instruction finetuning positively impacts the models\u2019 performance on the downstream tasks and that this improvement is captured by IS.</div>\nCorrelation with downstream tasks performance. The MTEB Benchmark offers a natural starting point to compare models\u2019 ranking according to their performance on downstream tasks and their IS score. In Figure 3c, we show that the IS score of an embedder correlates positively with its performance on a wide range of downstream tasks, from classification and similarity tasks to retrieval and clustering tasks. Overall, our IS score correlates strongly with MTEB\u2019s average score (Spearman correlation of 0.90 and a Pearson correlation of 0.94, see Figure 3c) and with the subtask\n4https://huggingface.co/infgrad/stella-base-en-v2 5https://huggingface.co/spaces/mteb/leaderboard\nperformance Figure 3a). We extended our experiments to a more extensive set of models not included in the MTEB benchmark and observed a similar trend (Figure 4b). Per-datasets results are reported in Sec. C.3.1 and ablations in Sec. C.3.2. All our results show that our estimation of the information sufficiency between models is a good proxy for the performance of the models on a wide range of tasks.\nEmbedder communities. The pair-wise information sufficiency evaluation between the models can be used to cluster them into communities [15](Figure 4a, Figure 2)6. We observe that the extracted clusters group together models that are similar in their training objectives and architectures. LLM-based models such as LLaMA, Mistral, Gemma, and Croissant are clustered together, while BERT-based models share another cluster. Similarly, models trained specifically for embedding purposes, such as UAE-Large-V1 and ember-v1, are grouped together. This suggests that the ordering induced by information sufficiency is meaningful and can be used to identify models with similar properties and behaviors. Consistently with Corollary 1, we observe that the performance of the models on the downstream tasks is similar within the same cluster (Figure C.3.5). In addition, we found that it captures improvements by both steps of pretraining and instruction fine-tuning (Figure 4c, Sec. C.3.2)\n# 6 Molecular Modeling\n# 6.1 Experimental setting\nEmbedders. To process molecular data, embedders can leverage different representations of the molecules, providing an interesting benchmark to evaluate the IS score. We evaluated models derived from the molecular representation learning literature, summed up in Sec. D.1. We considered various input modalities such as string representations (SMILES [114], SELFIES [58]), 2D-graphs by using graph neural networks (GNNs), and 3D-representations (using the TorchMD-net architecture [80]). We added a randomly initialized baseline GNN model that was not trained on any dataset. Datasets. To evaluate the information sufficiency between embedders, we compared the models on the ZINC 250k dataset[50], designed to gather compounds that could be relevant to a wide range of therapeutic projects. This dataset contains 250k commercially available compounds meant to be used in diverse therapeutic projects. Downstream tasks. We evaluated the embedders on 31 downstream tasks extracted from the Therapeutic Data Commons [49] platform. This section focuses on ADMET tasks (Absorption, Distribution, Metabolism, Excretion, and Toxicity). Results on Drug-Target interaction tasks can be found in Sec. D.4. Datasets collected are split into a training, validation, and test set, following the scaffold-split strategy, further described in see Sec. D.3.\n# 6.2 Model\u2019s Information Sufficiency analysis\nGlobal results. The IS score ranking is consistent with the results of the embedders on the ADMET downstream tasks, achieving a Spearman correlation of 0.95 and a Kendall-tau coefficient of 0.80, as reported in Figure 3d. Detailed results for each of the 31 tasks are available in Sec. D.3 in Tab. 6. Table 3b shows the correlation between the IS score rankings and the performances obtained on the ADMET tasks within each category. High correlations are achieved within most task categories, especially when large tasks are available (containing an important number of molecules). On excretion tasks, the correlation is lower (below 0.8), which can be explained by the fact that these tasks are the most challenging regression tasks available, where the fine-tuned models reach the lowest R2 scores between 0 and 0.2 (see Sec. D.3). Most / Least promising models. We observe in Figure 5b that the most promising models are the (Chem)Bert-MTR models[3]7 and MolR[112], the former trained on SMILES representations to predict a variety of computationally available molecular properties, and the latter trained on 2D graphs to preserve equivalence of molecules w.r.t chemical reactions. Surprisingly, these models share high predictive mutual information (being assigned to the same Louvain community in Figure 5a),\nWe rely on the Louvain community detection implementation from networkx[43] BertMTR-XM stands for a (Chem)Bert-MTR model trained on XM molecules.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f933/f933ffd7-7c72-421b-b669-b368039a9d00.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 5: (a) Pairwise information sufficiency graph between the embedders. The center color represents the ability to simulate other models, while the surrounding colors represent the ability to be simulated by other models. Red indicates a high ability to simulate or be simulated, while blue indicates a low ability. (b) Mean rank of the models (ordered by IS score) on downstream tasks.</div>\nsuggesting that they capture similar information despite significant differences in their training methods. These models also appear to be the most competitive on the ADMET tasks. On the other hand, and consistently with Sun et al. [99]\u2019s observation, training methods for 2D-GNNs such as following attribute masking and context prediction objective are deemed as the least informative according to the IS score. This is explained by the simplicity of these pretraining objectives for this data modality. These methods are also among the least competitive methods on the ADMET downstream tasks. NLP-inspired models. (Chem)Bert-MLM [3], MolBert [36] and (Chem)GPT[40] leverage masked language model objective applied to string representations (SMILES and SELFIES). Unsurprisingly, as seen in Figure 5a, these models are clustered, suggesting they capture similar information. However, they fail to simulate other models in the pool, resulting in low IS scores, a result consistent with the known limitations of these pretraining objectives [23, 105]. A noticeable exception is (Chem)GPT-1.2B (the biggest model of the pool by far), which displays a significantly higher IS score. \"Not-trained\" GNN. Figure 5b helps visualize the performances of the different models relative to our baseline \"Not-trained\" GNN. Surprisingly, some models are ranked less promising than this baseline by the IS score. However, all of these less promising models obtain poorer performances on the downstream tasks. Similarly, except for InfoGraph [98], every model ranked more promising than the \"Not-trained\" GNN baseline and obtained better results on ADMET tasks. This surprising result validates evaluation of the IS score w.r.t this baseline.\n# 7 Limitations and Conclusions\nWe proposed a principled approach to embedding model evaluation by framing model ranking as a variation of comparing statistical experiments. Utilizing concepts of sufficiency, informativeness, and deficiency, we developed mathematically grounded metrics for pairwise comparisons between embedders without relying on labeled data in downstream tasks. Our tractable relaxation, termed information sufficiency, demonstrated strong correlations with rankings based on downstream task performance in extensive experiments. Although successful, our method still has at least two primary limitations. First, its effectiveness depends on the number and diversity of available embedders (see Sec. E.4). Future work could explore using randomly initialized embedders (random projections) instead of pre-trained ones. Second, we can enhance our proxy for predicting the deficiency between models by exploring better methods (e.g., estimating the f-divergence) to directly learn the Markov kernel that minimizes the total variation distance, which we leave for future research.\n# Acknowledgments\nThis work was granted access to the HPC resources of IDRIS under the allocation 2023AD011013290R2 made by GENCI, and enabled by support provided by Calcul Quebec and the Digital Research Alliance of Canada. We warmly thank Heitor Rapela and Banafsheh Karimian for their advice and comments about our work. We also owe a special highlight to Lo\u00efc Fosse for the many discussions and hindsights he provided and for the subsequent follow-up projects.\n[1] Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, and Yoav Goldberg. Fine-grained analysis of sentence embeddings using auxiliary prediction tasks. In International Conference on Learning Representations. International Conference on Learning Representations, ICLR, 2017. [2] Kumar K Agrawal, Arnab Kumar Mondal, Arna Ghosh, and Blake Richards. \\alpha-req : Assessing representation quality in self-supervised learning by measuring eigenspectrum decay. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 17626\u201317638. Curran Associates, Inc., 2022. [3] Walid Ahmad, Elana Simon, Seyone Chithrananda, Gabriel Grand, and Bharath Ramsundar. Chemberta-2: Towards chemical foundation models, 2022. [4] Suguru Arimoto. Information-theoretical considerations on estimation problems. Information and control, 19(3):181\u2013194, 1971. [5] Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann LeCun, and Nicolas Ballas. Self-supervised learning from images with a joint-embedding predictive architecture, 2023. [6] Simon Axelrod and Rafael G\u00f3mez-Bombarelli. Geom, energy-annotated molecular conformations for property prediction and molecular generation. Scientific Data, 9(1):185, 2022. [7] Francesco Barbieri, Jose Camacho-Collados, Luis Espinosa-Anke, and Leonardo Neves. TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification. In Proceedings of Findings of EMNLP, 2020. [8] Francesco Barbieri, Jose Camacho-Collados, Francesco Ronzano, Luis Espinosa-Anke, Miguel Ballesteros, Valerio Basile, Viviana Patti, and Horacio Saggion. Semeval 2018 task 2: Multilingual emoji prediction. In Proceedings of The 12th International Workshop on Semantic Evaluation, pages 24\u201333, 2018. [9] Valerio Basile, Cristina Bosco, Elisabetta Fersini, Debora Nozza, Viviana Patti, Francisco Manuel Rangel Pardo, Paolo Rosso, and Manuela Sanguinetti. SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter. In Proceedings of the 13th International Workshop on Semantic Evaluation, pages 54\u201363, Minneapolis, Minnesota, USA, 2019. Association for Computational Linguistics. 10] Yonatan Belinkov. Probing classifiers: Promises, shortcomings, and advances. Computational Linguistics, 48(1):207\u2013219, 2022. 11] Alessio Benavoli, Giorgio Corani, Janez Demsar, and Marco Zaffalon. Time for a change: a tutorial for comparing multiple classifiers through bayesian analysis, 2017. 12] Usha Bhalla, Alex Oesterling, Suraj Srinivas, Flavio P. Calmon, and Himabindu Lakkaraju. Interpreting clip with sparse linear concept embeddings (splice), 2024. 13] David Blackwell. Comparison of experiments. In Proceedings of the second Berkeley symposium on mathematical statistics and probability, volume 2, pages 93\u2013103. University of California Press, 1951. 14] David Blackwell. Equivalent comparisons of experiments. The Annals of Mathematical Statistics, 24(2):265\u2013272, 1953. 15] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008, oct 2008. 16] H. Frederic Bohnenblust, Lloyd S. Shapley, and Seymour Sherman. Reconnaissance in game theory. 1949. 17] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre.\n[18] Nathan Brown, Marco Fiscato, Marwin H.S. Segler, and Alain C. Vaucher. Guacamol: Benchmarking models for de novo molecular design. Journal of Chemical Information and Modeling, 59(3):1096\u20131108, March 2019. [19] I\u00f1igo Casanueva, Tadas Temcinas, Daniela Gerz, Matthew Henderson, and Ivan Vulic. Efficient intent detection with dual sentence encoders. In Proceedings of the 2nd Workshop on NLP for ConvAI - ACL 2020, mar 2020. Data available at https://github.com/PolyAI-LDN/taskspecific-datasets. [20] Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, and Sanjiv Kumar. Pre-training tasks for embedding-based large-scale retrieval, 2020. [21] Chang Che, Qunwei Lin, Xinyu Zhao, Jiaxin Huang, and Liqiang Yu. Enhancing multimodal understanding with clip-based image-to-text transformation, 2024. [22] Yanqing Chen, Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. The expressive power of word embeddings, 2013. [23] Seyone Chithrananda, Gabriel Grand, and Bharath Ramsundar. Chemberta: Large-scale self-supervised pretraining for molecular property prediction, 2020. [24] Hyunjin Choi, Judong Kim, Seongho Joe, and Youngjune Gwon. Evaluation of bert and albert sentence embedding performance on downstream nlp tasks, 2021. [25] Ching-Yao Chuang, Antonio Torralba, and Stefanie Jegelka. The role of embedding complexity in domain-invariant representations, 2019. [26] Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li\u00f2, and Petar Veli\u02c7ckovi\u00b4c. Principal neighbourhood aggregation for graph nets. In Advances in Neural Information Processing Systems, 2020. [27] T. M. Cover and J. A. Thomas. Elements of Information Theory. Wiley, New York, NY, 2nd edition, 2006. [28] H. Crauel. Random Probability Measures on Polish Spaces. Taylor & Francis, 2002. [29] Morris H DeGroot. Uncertainty, information, and sequential experiments. The Annals of Mathematical Statistics, 33(2):404\u2013419, 1962. [30] Janez Dem\u0161ar. Statistical comparisons of classifiers over multiple data sets. The Journal of Machine learning research, 7:1\u201330, 2006. [31] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding, 2019. [32] Jian Du, Shanghang Zhang, Guanhang Wu, Jose M. F. Moura, and Soummya Kar. Topology adaptive graph convolutional networks, 2018. [33] David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael G\u00f3mez-Bombarelli, Timothy Hirzel, Al\u00e1n Aspuru-Guzik, and Ryan P. Adams. Convolutional networks on graphs for learning molecular fingerprints, 2015. [34] Peter Ertl and Ansgar Schuffenhauer. Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions. J. Cheminformatics, 1:8, 2009. [35] Kawin Ethayarajh, Yejin Choi, and Swabha Swayamdipta. Understanding dataset difficulty with V-usable information, 2022. [36] Benedek Fabian, Thomas Edlich, H\u00e9l\u00e9na Gaspar, Marwin Segler, Joshua Meyers, Marco Fiscato, and Mohamed Ahmed. Molecular representation learning with language models and domain-relevant auxiliary tasks, 2020. [37] Manuel Faysse, Patrick Fernandes, Nuno M. Guerreiro, Ant\u00f3nio Loison, Duarte M. Alves, Caio Corro, Nicolas Boizard, Jo\u00e3o Alves, Ricardo Rei, Pedro H. Martins, Antoni Bigata Casademunt, Fran\u00e7ois Yvon, Andr\u00e9 F. T. Martins, Gautier Viaud, C\u00e9line Hudelot, and Pierre Colombo. Croissantllm: A truly bilingual french-english language model, 2024. [38] Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. Languageagnostic bert sentence embedding, 2022.\n[39] Shikun Feng, Yuyan Ni, Yanyan Lan, Zhi-Ming Ma, and Wei-Ying Ma. Fractional denoising for 3D molecular pre-training. In Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 9938\u20139961. PMLR, 23\u201329 Jul 2023. [40] Nathan C. Frey, Ryan Soklaski, Simon Axelrod, Siddharth Samsi, Rafael G\u00f3mez-Bombarelli, Connor W. Coley, and Vijay Gadepally. Neural scaling of deep chemical models. Nature Machine Intelligence, 5(11):1297\u20131305, November 2023. Publisher: Nature Publishing Group. [41] Tianyu Gao, Xingcheng Yao, and Danqi Chen. Simcse: Simple contrastive learning of sentence embeddings, 2022. [42] Quentin Garrido, Randall Balestriero, Laurent Najman, and Yann Lecun. Rankme: Assessing the downstream performance of pretrained self-supervised representations by their rank, 2023. [43] Aric Hagberg, Pieter Swart, and Daniel S Chult. Exploring network structure, dynamics, and function using networkx. Technical report, Los Alamos National Lab.(LANL), Los Alamos, NM (United States), 2008. [44] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs, 2018. [45] Bobby He and Mete Ozay. Exploring the gap between collapsed; whitened features in selfsupervised learning. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 8613\u20138634. PMLR, 17\u201323 Jul 2022. [46] Weihua Hu, Matthias Fey, Hongyu Ren, Maho Nakata, Yuxiao Dong, and Jure Leskovec. Ogb-lsc: A large-scale challenge for machine learning on graphs, 2021. [47] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. arXiv preprint arXiv:2005.00687, 2020. [48] Ziniu Hu, Yuxiao Dong, Kuansan Wang, Kai-Wei Chang, and Yizhou Sun. Gpt-gnn: Generative pre-training of graph neural networks. In Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2020. [49] Kexin Huang, Tianfan Fu, Wenhao Gao, Yue Zhao, Yusuf Roohani, Jure Leskovec, Connor W Coley, Cao Xiao, Jimeng Sun, and Marinka Zitnik. Therapeutics data commons: Machine learning datasets and tasks for drug discovery and development. Proceedings of Neural Information Processing Systems, NeurIPS Datasets and Benchmarks, 2021. [50] John J. Irwin and Brian K. Shoichet. ZINC \u2013 A Free Database of Commercially Available Compounds for Virtual Screening. Journal of chemical information and modeling, 45(1):177\u2013 182, 2005. [51] Clemens Isert, Kenneth Atz, Jos\u00e9 Jim\u00e9nez-Luna, and Gisbert Schneider. Qmugs: Quantum mechanical properties of drug-like molecules, 2021. [52] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L\u00e9lio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timoth\u00e9e Lacroix, and William El Sayed. Mistral 7b, 2023. [53] Apoorv Khandelwal, Luca Weihs, Roozbeh Mottaghi, and Aniruddha Kembhavi. Simple but effective: Clip embeddings for embodied ai, 2022. [54] Jin-Hwa Kim, Yunji Kim, Jiyoung Lee, Kang Min Yoo, and Sang-Woo Lee. Mutual information divergence: A unified metric for multimodal generative models, 2022. [55] Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li, Benjamin A Shoemaker, Paul A Thiessen, Bo Yu, Leonid Zaslavsky, Jian Zhang, and Evan E Bolton. PubChem 2023 update. Nucleic Acids Research, 51(D1):D1373\u2013D1380, 10 2022. [56] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017. [57] J. Korner and K. Marton. Comparison of two noisy channels, 1977.\n[58] Mario Krenn, Florian H\u00e4se, AkshatKumar Nigam, Pascal Friederich, and Alan Aspuru-Guzik. Self-referencing embedded strings (selfies): A 100Machine Learning: Science and Technology, 1(4):045024, October 2020. [59] Yugo Kubota, Daichi Haraguchi, and Seiichi Uchida. Impression-clip: Contrastive shapeimpression embedding for fonts, 2024. [60] Alexandre Lacoste, Fran\u00e7ois Laviolette, and Mario Marchand. Bayesian comparison of machine learning algorithms on single and multiple datasets. In Artificial Intelligence and Statistics, pages 665\u2013675. PMLR, 2012. [61] Greg Landrum, Paolo Tosco, Brian Kelley, sriniker, gedeck, NadineSchneider, Riccardo Vianello, Ric, Andrew Dalke, Brian Cole, AlexanderSavelyev, Matt Swain, Samo Turk, Dan N, Alain Vaucher, Eisuke Kawashima, Maciej W\u00f3jcikowski, Daniel Probst, guillaume godin, David Cosgrove, Axel Pahl, JP, Francois Berenger, strets123, JLVarjo, Noel O\u2019Boyle, Patrick Fuller, Jan Holst Jensen, Gianluca Sforna, and DoliathGavid. rdkit/rdkit: 2020_03_1 (Q1 2020) Release, March 2020. [62] Stefan Larson, Anish Mahendran, Joseph J. Peper, Christopher Clarke, Andrew Lee, Parker Hill, Jonathan K. Kummerfeld, Kevin Leach, Michael A. Laurenzano, Lingjia Tang, and Jason Mars. An evaluation dataset for intent classification and out-of-scope prediction. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019. [63] L Le. Sufficiency and approximate sufficiency. The Annals of Mathematical Statistics, pages 1419\u20131455, 1964. [64] Xianming Li and Jing Li. Angle-optimized text embeddings, 2023. [65] Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, and Meishan Zhang. Towards general text embeddings with multi-stage contrastive learning. arXiv preprint arXiv:2308.03281, 2023. [66] Dennis V Lindley. On a measure of the information provided by an experiment. The Annals of Mathematical Statistics, 27(4):986\u20131005, 1956. [67] Shengchao Liu, Hanchen Wang, Weiyang Liu, Joan Lasenby, Hongyu Guo, and Jian Tang. Pre-training molecular graph representation with 3d geometry. In International Conference on Learning Representations, 2022. [68] Tiqing Liu, Yuhmei Lin, Xin Wen, Robert N. Jorissen, and Michael K. Gilson. Bindingdb: a web-accessible database of experimentally determined protein\u2013ligand binding affinities. Nucleic Acids Research, 35:D198\u2013D201, 12 2006. [69] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach, 2019. [70] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 142\u2013150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics. [71] Hadrien Mary, Emmanuel Noutahi, DomInvivo, Lu Zhu, Michel Moreau, Steven Pak, Desmond Gilmour, Shawn Whitfield, t, Valence-JonnyHsu, Honor\u00e9 Hounwanou, Ishan Kumar, Saurav Maheshkar, Shuya Nakata, Kyle M. Kovary, Cas Wognum, Michael Craig, and DeepSource Bot. datamol-io/datamol: 0.12.3, January 2024. [72] Julian McAuley and Jure Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. In Proceedings of the 7th ACM Conference on Recommender Systems, RecSys \u201913, page 165\u2013172, New York, NY, USA, 2013. Association for Computing Machinery. [73] Rui Meng, Ye Liu, Shafiq Rayhan Joty, Caiming Xiong, Yingbo Zhou, and Semih Yavuz. Sfr-embedding-mistral:enhance text retrieval with transfer learning. Salesforce AI Research Blog, 2024. [74] Saif Mohammad, Felipe Bravo-Marquez, Mohammad Salameh, and Svetlana Kiritchenko. Semeval-2018 task 1: Affect in tweets. In Proceedings of the 12th international workshop on semantic evaluation, pages 1\u201317, 2018.\n[75] Niklas Muennighoff, Nouamane Tazi, Lo\u00efc Magne, and Nils Reimers. Mteb: Massive text embedding benchmark, 2023. [76] Kevin P. Murphy. Machine learning : a probabilistic perspective. MIT Press, Cambridge, Mass. [u.a.], 2013. [77] Jianmo Ni, Gustavo Hern\u00e1ndez \u00c1brego, Noah Constant, Ji Ma, Keith B. Hall, Daniel Cer, and Yinfei Yang. Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models, 2021. [78] Zhihong Pan, Xin Zhou, and Hao Tian. Extreme generative image compression by learning text embedding from diffusion models. arXiv preprint arXiv:2211.07793, 2022. [79] Bo Pang and Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the ACL, 2005. [80] Raul P. Pelaez, Guillem Simeon, Raimondas Galvelis, Antonio Mirarchi, Peter Eastman, Stefan Doerr, Philipp Th\u00f6lke, Thomas E. Markland, and Gianni De Fabritiis. Torchmd-net 2.0: Fast neural network potentials for molecular simulations, 2024. [81] Christian S. Perone, Roberto Silveira, and Thomas S. Paula. Evaluation of sentence embeddings in downstream and linguistic probing tasks, 2018. [82] Georg Pichler, Pierre Colombo, Malik Boudiaf, G\u00fcnther Koliander, and Pablo Piantanida. A differential entropy estimator for training neural networks, 2022. [83] Tiago Pimentel, Clara Meister, and Ryan Cotterell. On the usefulness of embeddings, clusters and strings for text generator evaluation, 2023. [84] Tiago Pimentel, Josef Valvoda, Rowan Hall Maudslay, Ran Zmigrod, Adina Williams, and Ryan Cotterell. Information-theoretic probing for linguistic structure. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4609\u20134622, 2020. [85] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bertnetworks, 2019. [86] Nils Reimers and Iryna Gurevych. Making monolingual sentence embeddings multilingual using knowledge distillation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 11 2020. [87] R. Tyrrell Rockafellar. Convex analysis. Princeton Mathematical Series. Princeton University Press, Princeton, N. J., 1970. [88] Anna Rogers, Olga Kovaleva, and Anna Rumshisky. A primer in bertology: What we know about how bert works. Transactions of the Association for Computational Linguistics, 8:842\u2013 866, 2021. [89] Yu Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying Wei, Wenbing Huang, and Junzhou Huang. Self-supervised graph transformer on large-scale molecular data. Advances in Neural Information Processing Systems, 33, 2020. [90] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad Norouzi. Photorealistic text-toimage diffusion models with deep language understanding, 2022. [91] Joaquim Santos, Bernardo Consoli, and Renata Vieira. Word embedding evaluation in downstream tasks and semantic analogies. In Nicoletta Calzolari, Fr\u00e9d\u00e9ric B\u00e9chet, Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, H\u00e9l\u00e8ne Mazo, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 4828\u20134834, Marseille, France, May 2020. European Language Resources Association. [92] Elvis Saravia, Hsien-Chi Toby Liu, Yen-Hao Huang, Junlin Wu, and Yi-Shin Chen. CARER: Contextualized affect representations for emotion recognition. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3687\u20133697, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. [93] Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki. Laion-400m: Open dataset of clip-filtered 400 million image-text pairs. arXiv preprint arXiv:2111.02114, 2021.\n[94] Claude E. Shannon. A note on a partial ordering for communication channels. Information and Control, 1(4):390\u2013397, 1958. [95] A.N. Shiri?aev and V.G. Spokoiny. Statistical Experiments and Decisions: Asymptotic Theory. Advanced series on statistical science & applied probability. World Scientific, 2000. [96] Hannes St\u00e4rk, Dominique Beaini, Gabriele Corso, Prudencio Tossou, Christian Dallago, Stephan G\u00fcnnemann, and Pietro Li\u00f2. 3d infomax improves gnns for molecular property prediction. arXiv preprint arXiv:2110.04126, 2021. [97] Ce Sui, Xiaosheng Zhao, Tao Jing, and Yi Mao. Evaluating summary statistics with mutual information for cosmological inference, 2023. [98] Fan-Yun Sun, Jordan Hoffman, Vikas Verma, and Jian Tang. Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization. In International Conference on Learning Representations, 2019. [99] Ruoxi Sun, Hanjun Dai, and Adams Wei Yu. Does gnn pretraining help molecular representation? In Advances in Neural Information Processing Systems (NeurIPS), 2022. [100] Duyu Tang, Furu Wei, Bing Qin, Nan Yang, Ting Liu, and Ming Zhou. Sentiment embeddings with applications to sentiment analysis. IEEE Transactions on Knowledge and Data Engineering, 28(2):496\u2013509, 2016. [101] Jing Tang, Agnieszka Szwajda, Sushil Shakyawar, Tao Xu, Petteri Hintsanen, Krister Wennerberg, and Tero Aittokallio. Making sense of large-scale kinase inhibitor bioactivity data sets: A comparative and integrative analysis. Journal of Chemical Information and Modeling, 54(3):735\u2013743, 2014. [102] Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi\u00e8re, Mihir Sanjay Kale, Juliette Love, Pouya Tafti, L\u00e9onard Hussenot, Pier Giuseppe Sessa, Aakanksha Chowdhery, Adam Roberts, Aditya Barua, Alex Botev, Alex Castro-Ros, Ambrose Slone, Am\u00e9lie H\u00e9liou, Andrea Tacchetti, Anna Bulanova, Antonia Paterson, Beth Tsai, Bobak Shahriari, Charline Le Lan, Christopher A. ChoquetteChoo, Cl\u00e9ment Crepy, Daniel Cer, Daphne Ippolito, David Reid, Elena Buchatskaya, Eric Ni, Eric Noland, Geng Yan, George Tucker, George-Christian Muraru, Grigory Rozhdestvenskiy, Henryk Michalewski, Ian Tenney, Ivan Grishchenko, Jacob Austin, James Keeling, Jane Labanowski, Jean-Baptiste Lespiau, Jeff Stanway, Jenny Brennan, Jeremy Chen, Johan Ferret, Justin Chiu, Justin Mao-Jones, Katherine Lee, Kathy Yu, Katie Millican, Lars Lowe Sjoesund, Lisa Lee, Lucas Dixon, Machel Reid, Maciej Miku\u0142a, Mateo Wirth, Michael Sharman, Nikolai Chinaev, Nithum Thain, Olivier Bachem, Oscar Chang, Oscar Wahltinez, Paige Bailey, Paul Michel, Petko Yotov, Rahma Chaabouni, Ramona Comanescu, Reena Jana, Rohan Anil, Ross McIlroy, Ruibo Liu, Ryan Mullins, Samuel L Smith, Sebastian Borgeaud, Sertan Girgin, Sholto Douglas, Shree Pandya, Siamak Shakeri, Soham De, Ted Klimenko, Tom Hennigan, Vlad Feinberg, Wojciech Stokowiec, Yu hui Chen, Zafarali Ahmed, Zhitao Gong, Tris Warkentin, Ludovic Peran, Minh Giang, Cl\u00e9ment Farabet, Oriol Vinyals, Jeff Dean, Koray Kavukcuoglu, Demis Hassabis, Zoubin Ghahramani, Douglas Eck, Joelle Barral, Fernando Pereira, Eli Collins, Armand Joulin, Noah Fiedel, Evan Senter, Alek Andreev, and Kathleen Kenealy. Gemma: Open models based on gemini research and technology, 2024. [103] Erik Torgersen. Comparison of Statistical Experiments. Encyclopedia of Mathematics and its Applications. Cambridge University Press, 1991. [104] Erik Nikolai Torgersen. Comparison of experiments when the parameter space is finite. Zeitschrift f r Wahrscheinlichkeitstheorie und Verwandte Gebiete, 16(3):219\u2013249, 1970. [105] Mirko Torrisi, Saeid Asadollahi, Antonio De la Vega de Leon, Kai Wang, and Wilbert Copeland. Do chemical language models provide a better compound representation? In NeurIPS 2023 Workshop on New Frontiers of AI for Drug Discovery and Development, 2023. [106] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut\n[94] Claude E. Shannon. A note on a partial ordering for communication channels. Information and Control, 1(4):390\u2013397, 1958. [95] A.N. Shiri?aev and V.G. Spokoiny. Statistical Experiments and Decisions: Asymptotic Theory. Advanced series on statistical science & applied probability. World Scientific, 2000. [96] Hannes St\u00e4rk, Dominique Beaini, Gabriele Corso, Prudencio Tossou, Christian Dallago, Stephan G\u00fcnnemann, and Pietro Li\u00f2. 3d infomax improves gnns for molecular property prediction. arXiv preprint arXiv:2110.04126, 2021. [97] Ce Sui, Xiaosheng Zhao, Tao Jing, and Yi Mao. Evaluating summary statistics with mutual information for cosmological inference, 2023. [98] Fan-Yun Sun, Jordan Hoffman, Vikas Verma, and Jian Tang. Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization. In International Conference on Learning Representations, 2019. [99] Ruoxi Sun, Hanjun Dai, and Adams Wei Yu. Does gnn pretraining help molecular representation? In Advances in Neural Information Processing Systems (NeurIPS), 2022. 100] Duyu Tang, Furu Wei, Bing Qin, Nan Yang, Ting Liu, and Ming Zhou. Sentiment embeddings with applications to sentiment analysis. IEEE Transactions on Knowledge and Data Engineering, 28(2):496\u2013509, 2016. 101] Jing Tang, Agnieszka Szwajda, Sushil Shakyawar, Tao Xu, Petteri Hintsanen, Krister Wennerberg, and Tero Aittokallio. Making sense of large-scale kinase inhibitor bioactivity data sets: A comparative and integrative analysis. Journal of Chemical Information and Modeling, 54(3):735\u2013743, 2014. 102] Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi\u00e8re, Mihir Sanjay Kale, Juliette Love, Pouya Tafti, L\u00e9onard Hussenot, Pier Giuseppe Sessa, Aakanksha Chowdhery, Adam Roberts, Aditya Barua, Alex Botev, Alex Castro-Ros, Ambrose Slone, Am\u00e9lie H\u00e9liou, Andrea Tacchetti, Anna Bulanova, Antonia Paterson, Beth Tsai, Bobak Shahriari, Charline Le Lan, Christopher A. ChoquetteChoo, Cl\u00e9ment Crepy, Daniel Cer, Daphne Ippolito, David Reid, Elena Buchatskaya, Eric Ni, Eric Noland, Geng Yan, George Tucker, George-Christian Muraru, Grigory Rozhdestvenskiy, Henryk Michalewski, Ian Tenney, Ivan Grishchenko, Jacob Austin, James Keeling, Jane Labanowski, Jean-Baptiste Lespiau, Jeff Stanway, Jenny Brennan, Jeremy Chen, Johan Ferret, Justin Chiu, Justin Mao-Jones, Katherine Lee, Kathy Yu, Katie Millican, Lars Lowe Sjoesund, Lisa Lee, Lucas Dixon, Machel Reid, Maciej Miku\u0142a, Mateo Wirth, Michael Sharman, Nikolai Chinaev, Nithum Thain, Olivier Bachem, Oscar Chang, Oscar Wahltinez, Paige Bailey, Paul Michel, Petko Yotov, Rahma Chaabouni, Ramona Comanescu, Reena Jana, Rohan Anil, Ross McIlroy, Ruibo Liu, Ryan Mullins, Samuel L Smith, Sebastian Borgeaud, Sertan Girgin, Sholto Douglas, Shree Pandya, Siamak Shakeri, Soham De, Ted Klimenko, Tom Hennigan, Vlad Feinberg, Wojciech Stokowiec, Yu hui Chen, Zafarali Ahmed, Zhitao Gong, Tris Warkentin, Ludovic Peran, Minh Giang, Cl\u00e9ment Farabet, Oriol Vinyals, Jeff Dean, Koray Kavukcuoglu, Demis Hassabis, Zoubin Ghahramani, Douglas Eck, Joelle Barral, Fernando Pereira, Eli Collins, Armand Joulin, Noah Fiedel, Evan Senter, Alek Andreev, and Kathleen Kenealy. Gemma: Open models based on gemini research and technology, 2024. 103] Erik Torgersen. Comparison of Statistical Experiments. Encyclopedia of Mathematics and its Applications. Cambridge University Press, 1991. 104] Erik Nikolai Torgersen. Comparison of experiments when the parameter space is finite. Zeitschrift f r Wahrscheinlichkeitstheorie und Verwandte Gebiete, 16(3):219\u2013249, 1970. 105] Mirko Torrisi, Saeid Asadollahi, Antonio De la Vega de Leon, Kai Wang, and Wilbert Copeland. Do chemical language models provide a better compound representation? In NeurIPS 2023 Workshop on New Frontiers of AI for Drug Discovery and Development, 2023. 106] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut\nLavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models, 2023. [107] Anton Tsitsulin, Marina Munkhoeva, and Bryan Perozzi. Unsupervised embedding quality evaluation, 2023. [108] Alexandre B Tsybakov. Introduction to Nonparametric Estimation. Springer series in statistics. Springer, Dordrecht, 2009. [109] Cynthia Van Hee, Els Lefever, and V\u00e9ronique Hoste. Semeval-2018 task 3: Irony detection in english tweets. In Proceedings of The 12th International Workshop on Semantic Evaluation, pages 39\u201350, 2018. [110] Petar Veli\u02c7ckovi\u00b4c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, and Yoshua Bengio. Graph attention networks. In International Conference on Learning Representations, 2018. [111] Luke Vilnis and Andrew McCallum. Word representations via gaussian embedding. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. [112] Hongwei Wang, Weijiang Li, Xiaomeng Jin, Kyunghyun Cho, Heng Ji, Jiawei Han, and Martin D. Burke. Chemical-reaction-aware molecule representation learning. In International Conference on Learning Representations, 2022. [113] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. Text embeddings by weakly-supervised contrastive pre-training. arXiv preprint arXiv:2212.03533, 2022. [114] David Weininger. SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules. Journal of Chemical Information and Computer Sciences, 28(1):31\u201336, February 1988. Publisher: American Chemical Society. [115] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations, 2019. [116] Minghao Xu, Hang Wang, Bingbing Ni, Hongyu Guo, and Jian Tang. Self-supervised graphlevel representation learning with local and global structure. arXiv preprint arXiv:2106.04113, 2021. [117] Nianzu Yang, Kaipeng Zeng, Qitian Wu, Xiaosong Jia, and Junchi Yan. Learning substructure invariance for out-of-distribution molecular representations. In Advances in Neural Information Processing Systems (NeurIPS), 2022. [118] Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge. PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification. In Proc. of EMNLP, 2019. [119] Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen. Graph contrastive learning with augmentations. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 5812\u20135823. Curran Associates, Inc., 2020. [120] Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier. From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. Transactions of the Association for Computational Linguistics, 2:67\u201378, 2014. [121] Sheheryar Zaidi, Michael Schaarschmidt, James Martens, Hyunjik Kim, Yee Whye Teh, Alvaro Sanchez-Gonzalez, Peter Battaglia, Razvan Pascanu, and Jonathan Godwin. Pretraining via denoising for molecular property prediction. In International Conference on Learning Representations, 2023. [122] Li Zhang, Steven Wilson, and Rada Mihalcea. Multi-label transfer learning for multi-relational semantic similarity. In Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019). Association for Computational Linguistics, 2019.\n123] Xiang Zhang, Junbo Jake Zhao, and Yann LeCun. Character-level convolutional networks for text classification. In NIPS, 2015.\n[123] Xiang Zhang, Junbo Jake Zhao, and Yann LeCun. Character-level convolutional networks for text classification. In NIPS, 2015.\n# Appendix\nTable of Contents\nA Background and Notation\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d4a6/d4a660a3-cd41-45f3-8a43-9ae952c1b141.png\" style=\"width: 50%;\"></div>\n# D Molecular Experiment Details\nD.1 Embedders considered . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  D.2 Details on the information sufficiency estimation . . . . . . . . . . . . . . .  D.3 Complementary results on ADMET tasks . . . . . . . . . . . . . . . . . . .  D.4 Drug target Interaction prediction . . . . . . . . . . . . . . . . . . . . . . . \nE.1 Estimation method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.2 Hyperparameter selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.3 Impact of the task size . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.4 Impact of the number of models . . . . . . . . . . . . . . . . . . . . . . . . . . E.5 Computational ressources . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n# A Background and Notation\nWe consider all alphabets to be standard Borel [28] (i.e., isomorphic to a Borel subspace of a Polish space), encompassing virtually all practical scenarios. Each such space Y is equipped with its Borel \u03c3-algebra B(Y). The set of all probability measures on Y is denoted by P(Y). The total variation distance between P and Q in P(Y) is defined as\nand the Kullback\u2013Leibler divergence is defined by \uf8f1\n\uf8f3 Given a joint probability measure PXY in P(X\u00d7Y) induced by two random variables X \u2208X and Y \u2208 Y with product measures PXPY , the Mutual Information is defined as I(X; Y ) = KL \ufffd PXY \u2225PXPY \ufffd . If PX \u2208P(X) is a probability measure induced by X \u2208X, the Differential Entropy is defined by \ufffd\n\ufffd where \u00b5 denotes the Lebesgue measure. Similarly, it is possible to define the conditional entropy of Y given X which is denoted by h(Y |X). The mutual information satisfies the identities I(X; Y ) = h(Y ) \u2212h(Y |X) = h(X) \u2212h(X|Y ) and h(Y |X) \u2a7dh(Y ) (see [27] for further details). A Markov (or transition probability) kernel between X and Y is a mapping T : B(Y) \u00d7 X \u2192[0, 1], satisfying T(\u00b7|x) \u2208P(Y) for all x \u2208X and T(B|\u00b7) being a measurable function on X for any B \u2208B(Y). The space of all such T is denoted by K(Y|X). In cases where both Y and X are finite, any K(Y|X) is represented as a stochastic matrix with elements T(y|x),",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of evaluating embedding models in machine learning, focusing on the lack of a standardized framework for comparison and the challenges associated with acquiring large, representative datasets for assessments.",
        "problem": {
            "definition": "The problem is the difficulty in effectively comparing embedding models due to their diverse architectures and the reliance on domain-specific downstream task performance.",
            "key obstacle": "The main challenge is the scalability of evaluation methods, which require fitting downstream models for each task, making it computationally expensive and time-consuming."
        },
        "idea": {
            "intuition": "The idea stems from the need for a task-agnostic evaluation metric that can assess embedders without relying on labeled data from downstream tasks.",
            "opinion": "The proposed idea involves a theoretical framework based on the concepts of sufficiency and informativeness to rank embedding models.",
            "innovation": "The key innovation is the introduction of 'information sufficiency' as a tractable comparison criterion that allows for self-supervised ranking of embedders."
        },
        "method": {
            "method name": "Information Sufficiency",
            "method abbreviation": "IS",
            "method definition": "Information sufficiency quantifies the information required to simulate one embedding model from another, providing a means to compare models without labeled data.",
            "method description": "The method establishes a ranking of embedding models based on their information sufficiency, which correlates with their performance on downstream tasks.",
            "method steps": [
                "Define the embedding models and their Markov kernels.",
                "Estimate the information sufficiency between pairs of embedding models.",
                "Rank the models based on their information sufficiency scores."
            ],
            "principle": "The method is effective because it leverages theoretical foundations to measure how much information one model can provide to simulate another, thereby reflecting their comparative performance."
        },
        "experiments": {
            "evaluation setting": "The experiments involved comparing 34 different embedding models across various datasets and downstream tasks, including natural language processing and molecular biology.",
            "evaluation method": "Performance was assessed using correlations between the information sufficiency scores and the results of downstream tasks, employing metrics such as Pearson, Spearman, and Kendall-Tau."
        },
        "conclusion": "The experiments demonstrate that the proposed information sufficiency method provides a reliable means of ranking embedding models, correlating strongly with their performance on multiple downstream tasks.",
        "discussion": {
            "advantage": "The primary advantage of the proposed method is its ability to evaluate models without the need for labeled data, making it scalable and efficient.",
            "limitation": "A limitation is that the effectiveness of the method relies on the number and diversity of available embedding models, which can impact the robustness of the evaluation.",
            "future work": "Future research could explore the use of randomly initialized embedders and improve the estimation of deficiency between models to enhance the accuracy of comparisons."
        },
        "other info": {
            "acknowledgments": "This work was supported by the HPC resources of IDRIS and contributions from various researchers for advice and insights."
        }
    },
    "mount_outline": [
        {
            "section number": "2.2",
            "key information": "The paper addresses the issue of evaluating embedding models in machine learning, focusing on the lack of a standardized framework for comparison and the challenges associated with acquiring large, representative datasets for assessments."
        },
        {
            "section number": "3.4",
            "key information": "The proposed method, Information Sufficiency, quantifies the information required to simulate one embedding model from another, providing a means to compare models without labeled data."
        },
        {
            "section number": "4.3",
            "key information": "The experiments involved comparing 34 different embedding models across various datasets and downstream tasks, including natural language processing."
        },
        {
            "section number": "7.1",
            "key information": "The main challenge is the scalability of evaluation methods, which require fitting downstream models for each task, making it computationally expensive and time-consuming."
        },
        {
            "section number": "7.2",
            "key information": "Future research could explore the use of randomly initialized embedders and improve the estimation of deficiency between models to enhance the accuracy of comparisons."
        }
    ],
    "similarity_score": 0.6223528836105612,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/When is an Embedding Model More Promising than Another_.json"
}