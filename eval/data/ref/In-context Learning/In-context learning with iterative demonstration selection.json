{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2310.09881",
    "title": "In-Context Learning with Iterative Demonstration Selection",
    "abstract": "Spurred by advancements in scale, large language models (LLMs) have demonstrated strong few-shot learning ability via in-context learning (ICL). However, the performance of ICL has been shown to be highly sensitive to the selection of few-shot demonstrations. Selecting the most suitable examples as context remains an ongoing challenge and an open problem. Existing literature has highlighted the importance of selecting examples that are diverse or semantically similar to the test sample while ignoring the fact that the optimal selection dimension, i.e., diversity or similarity, is task-specific. Based on how the test sample is answered, we propose Iterative Demonstration Selection (IDS) to leverage the merits of both dimensions. Using zero-shot chain-of-thought reasoning (Zero-shot-CoT), IDS iteratively selects examples that are diverse but still strongly correlated with the test sample as ICL demonstrations. Specifically, IDS applies Zero-shot-CoT to the test sample before demonstration selection. The output reasoning path is then used to choose demonstrations that are prepended to the test sample for inference. The generated answer is followed by its corresponding reasoning path for extracting a new set of demonstrations in the next iteration. After several iterations, IDS adopts majority voting to obtain the final result. Through extensive experiments on tasks including reasoning, question answering, and topic classification, we demonstrate that IDS can consistently outperform existing ICL demonstration selection methods.",
    "bib_name": "qin2024incontextlearningiterativedemonstration",
    "md_text": "Chengwei Qin\u2020*, Aston Zhang\u2663, Chen Chen\u2020, Anirudh Dagar\u2663,Wenming Ye\u2663 \u2020Nanyang Technological University,\u2663Amazon Web Services\n# Abstract\nSpurred by advancements in scale, large language models (LLMs) have demonstrated strong few-shot learning ability via in-context learning (ICL). However, the performance of ICL has been shown to be highly sensitive to the selection of few-shot demonstrations. Selecting the most suitable examples as context remains an ongoing challenge and an open problem. Existing literature has highlighted the importance of selecting examples that are diverse or semantically similar to the test sample while ignoring the fact that the optimal selection dimension, i.e., diversity or similarity, is task-specific. Based on how the test sample is answered, we propose Iterative Demonstration Selection (IDS) to leverage the merits of both dimensions. Using zero-shot chain-of-thought reasoning (Zero-shot-CoT), IDS iteratively selects examples that are diverse but still strongly correlated with the test sample as ICL demonstrations. Specifically, IDS applies Zero-shotCoT to the test sample before demonstration selection. The output reasoning path is then used to choose demonstrations that are prepended to the test sample for inference. The generated answer is followed by its corresponding reasoning path for extracting a new set of demonstrations in the next iteration. After several iterations, IDS adopts majority voting to obtain the final result. Through extensive experiments on tasks including reasoning, question answering, and topic classification, we demonstrate that IDS can consistently outperform existing ICL demonstration selection methods.\n 23 Jun 2024\n# 1 Introduction\nWith the recent advancements in scaling up model parameters, large language models (LLMs) showcase promising results on a variety of few-shot tasks through in-context learning (ICL), where the\n*Correspondence to Chengwei Qin <chengwei003@e.ntu.edu.sg> and Aston Zhang <az@astonzhang.com>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bc69/bc69a7f7-443a-4615-9ae5-053fbd012b16.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Output Technology</div>\nFigure 1: Illustration of in-context learning (ICL) on topic classification. A frozen large language model directly generates the topic \u2018Technology\u2019 for the test sample \u2018OpenAI ...\u2019 by taking the demonstrations and the test sample as input. model is expected to directly generate the output of the test sample without updating parameters. This is achieved by conditioning on a manually designed prompt consisting of an optional task description and a few demonstration examples (Brown et al., 2020). Fig. 1 shows an example describing how LLMs perform ICL on the topic classification task. Given a few text-topic pairs as demonstrations, ICL combines them with the test sample as input, to the LLM for inference. The output, i.e., \u2018Technology\u2019, is generated by the model autoregressively without any parameter updates. Despite the effectiveness, the performance of ICL has been shown to be highly sensitive to the selection of demonstration examples (Zhao et al., 2021). Different sets of demonstrations can yield performance ranging from nearly random to comparable with state-of-the-art models (Gao et al., 2021; Lu et al., 2022). To alleviate the above issue, researchers in ICL have proposed a number of methods to select a set of examples as few-shot demonstrations (Rubin et al., 2022; Liu et al., 2022; Li and Qiu, 2023; Wang et al., 2023b; Li et al., 2023a; Ma et al., 2023; An et al., 2023b). However,\nfor LLMs for which parameters or detailed output distributions are not available (Sun et al., 2022), it is still a common practice to randomly select examples or select examples that are semantically similar to the test sample as demonstrations, i.e., considering diversity or similarity. While several approaches investigate the combination of similarity and diversity when prompting with explanations, exploring compositional generalization, or choosing examples for annotation (Ye et al., 2023b; An et al., 2023a; Su et al., 2023), it is not yet clear how to determine and leverage the optimal dimension for different tasks in ICL and how the rationale for answering the query benefits the balance between these two dimensions. Actually, the optimal dimension for selecting demonstration examples is task-specific. As we will show in \u00a74, the diversity dimension is superior to the similarity dimension on CommonsenseQA while the similarity dimension outperforms the diversity dimension on AGNews and BoolQ. Thus, it is unreasonable to claim that one dimension is consistently better than the other across different tasks. To fully leverage the merits of both dimensions, we propose Iterative Demonstration Selection (IDS) for ICL (Fig. 2) by utilizing how the test sample is answered. IDS can iteratively select demonstration examples that are diverse but still have a strong correlation with the test sample through zero-shot chain-of-thought reasoning (Zero-shot-CoT) (Kojima et al., 2022). Specifically, Zero-shot-CoT, e.g., \u201cLet\u2019s think step by step.\u201d, is first applied to the test sample before selecting demonstrations to obtain a reasoning path. The training examples that are most semantically similar to the generated reasoning path are then selected as demonstrations. They are prepended to the test sample for inference. Note that IDS ensures that the generated answer is accompanied by the reasoning path through designed prompts. The new reasoning path is then used for extracting another set of demonstration examples by semantic similarity in the next iteration. After a few iterations, IDS adopts majority voting to obtain the final result. Empirical results on tasks spanning mathematical reasoning, commonsense reasoning, logical reasoning, question answering, and topic classification show that IDS can consistently outperform previous ICL demonstration selection baselines. In summary, our main contributions are:\n\u2022 We consider both the diversity and similarity\ndimensions of ICL demonstration selection for LLMs. We identify that the optimal dimension for selecting demonstrations is task-specific and propose Iterative Demonstration Selection (IDS) based on how the test query is answered to fully leverage the merits of both dimensions.\n\u2022 With extensive experiments and analysis, we demonstrate the effectiveness of IDS on a variety of tasks.\n# 2 Related Work\nThis work mainly explores how to select few-shot in-context learning demonstrations for LLMs by leveraging Zero-shot-CoT. In light of this, we review four lines of research that form the basis of this work: few-shot learning, in-context learning basics, demonstration selection for in-context learning, and chain-of-thought reasoning.\n# 2.1 Few-shot Learning\nFew-shot learning aims to learn tasks with only a few labeled samples, which results in a big challenge, i.e., over-fitting, for models as they typically require large amounts of data for training. Prior methods to address over-fitting mainly focused on augmenting the few-shot data (Gao et al., 2020; Qin and Joty, 2022), reducing the hypothesis space (Triantafillou et al., 2017; Hu et al., 2018), or optimizing the strategy for searching the best hypothesis (Ravi and Larochelle, 2017; Finn et al., 2017). More recently, LLMs have demonstrated strong few-shot learning ability through in-context learning without any parameter updates (Brown et al., 2020).\n# 2.2 In-context Learning\nBrown et al. (2020) first showed that a frozen GPT3 model can achieve impressive results on a variety of few-shot NLP tasks through conditioning on manually designed prompts consisting of task descriptions and several demonstration examples. Since then many efforts have been made on incontext learning (ICL) (Dong et al., 2022). Chen et al. (2022); Min et al. (2022a); Wei et al. (2023a) demonstrated that the ICL ability of language models can be further improved through self-supervised or supervised training. Some analytical studies attempted to understand what factors affect ICL performance (Zhao et al., 2021; Shin et al., 2022; Wei et al., 2022a; Min et al., 2022b; Yoo et al., 2022; Wei et al., 2023b) and why ICL works (Xie et al.,\n2022; Olsson et al., 2022; Li et al., 2023b; Pan et al., 2023; Dai et al., 2023). Other ongoing research on ICL has also explored (i) demonstration designing, including demonstration selection (Liu et al., 2022; Rubin et al., 2022; Wang et al., 2023b), demonstration ordering (Lu et al., 2022), and demonstration formatting (Wei et al., 2022b; Wang et al., 2022c; Zhou et al., 2023; Zhang et al., 2023a), (ii) applications of ICL (Ding et al., 2022; Meade et al., 2023; Zheng et al., 2023), and (iii) ICL beyond text (Wang et al., 2023c; Huang et al., 2023; Zhu et al., 2023; Wang et al., 2023a).\n# 2.3 Demonstration Selection for In-context Learning\nThe performance of ICL has been shown to be highly sensitive to the selection of demonstration examples (Zhao et al., 2021). Existing methods to solve this problem can be mainly divided into two categories. First, unsupervised methods rely on pre-defined metrics. Liu et al. (2022) proposed to select the closest neighbors as demonstrations. In contrast, Levy et al. (2022) selected diverse demonstrations to improve in-context compositional generalization. More recent studies have explored leveraging the output distributions or predictive uncertainty of language models to select few-shot demonstrations (Wu et al., 2022; Nguyen and Wong, 2023; Li and Qiu, 2023; Ma et al., 2023; Ling et al., 2024; Xu and Zhang, 2024) or self-generating demonstrations (Chen et al., 2023). Second, supervised methods involve model training. Rubin et al. (2022); Ye et al. (2023a); Li et al. (2023a); Luo et al. (2023); Wang et al. (2024) proposed to learn to retrieve demonstration examples. Wang et al. (2023b) posited LMs as implicit topic models to facilitate demonstration selection. In addition, some studies (Zhang et al., 2022; Scarlatos and Lan, 2023) attempted to select demonstrations based on reinforcement learning. However, it is still a common practice to randomly select examples or select examples that are semantically similar to the test sample as demonstrations for LLMs for which parameters or detailed output distributions are not available (Sun et al., 2022). Several methods investigated the combination of diversity and similarity in different scenarios, e.g., prompting with explanations (Ye et al., 2023b), choosing examples for annotation (Su et al., 2023) and exploring compositional generalization (An et al., 2023a). Nevertheless, it remains unclear to us how to determine and leverage the optimal dimension\nfor different tasks in ICL and how the reason for answering the test sample benefits the balance between the two dimensions, which motivates us to propose our simple but effective approach (IDS).\n# 2.4 Chain-of-Thought Reasoning\nChain-of-thought (CoT) reasoning induces LLMs to produce intermediate reasoning steps before generating the final answer (Wei et al., 2022b). Depending on whether there are manually designed demonstrations, current CoT reasoning methods mainly include Manual-CoT and Zero-shot-CoT. In Manual-CoT, human-labeled reasoning paths are used to perform CoT reasoning (Wei et al., 2022b; Zhou et al., 2022; Wang et al., 2022b; Li et al., 2022; Wang et al., 2022a). In contrast, LLMs leverage self-generated rationales for reasoning in Zero-shot-CoT (Kojima et al., 2022; Zelikman et al., 2022; Zhang et al., 2023a; Diao et al., 2023). The ongoing research on CoT reasoning has also explored (i) multimodal reasoning (Zhang et al., 2023b; Wu et al., 2023), (ii) distilling knowledge from LLMs (Ho et al., 2022; Fu et al., 2023), and (iii) iterative optimization (Shinn et al., 2023; Madaan et al., 2023; Paul et al., 2023).\n# 3 Problem Formulation\nGiven the test set Dtest and the training set Dtrain, the goal of ICL demonstration selection is to find an optimal subset S = {(x1, y1), ..., (xk, yk)} (kshot) of Dtrain as demonstration examples for each test sample (\u02c6xi, \u02c6yi) to maximize the overall task performance on Dtest. More formally, the optimal selection method \u02dch is defined as:\n(1)\n([()]) where H is the hypothesis space for searching demonstration examples, h(Dtrain, \u02c6xi, \u02c6yi) refers to demonstrations selected for (\u02c6xi, \u02c6yi) using h, [, ] stands for concatenation, and \u03b4a,b is the Kronecker delta function: \u03b4a,b = 1 if a equals b, otherwise \u03b4a,b = 0. In this work, we aim to find the optimal method \u02dch by leveraging Zero-shot-CoT.\n# 4 What Makes Good In-Context Demonstrations?\nAs demonstrated in previous work (Zhao et al., 2021), the overall task performance is highly sensitive to the selection method h. Different sets\n<div style=\"text-align: center;\">CommonsenseQA BoolQ AGNews</div>\nCommonsenseQA BoolQ AGNews\nSimilar-ICL-Consistency (Similarity)\n76.0\n85.0\n90.0\nRandom-ICL-Voting (Diversity)\n79.0\n84.0\n88.0\nTable 1: Results of different methods on CommonsenseQA, BoolQ and AGNews. The optimal dimension for selecting ICL demonstrations is task-specific.\nof demonstration examples can yield significantly different performance. For example, Zhang et al. (2022) show that the minimum and maximum ICL performance due to random sampling differs by > 30% on 4 classification tasks, which emphasizes the importance of selecting good demonstrations for LLMs. A natural question is: what makes good incontext demonstrations? For LLMs, it is still a common practice to select a subset S consisting of examples that are diverse or semantically similar to the test sample as demonstrations, i.e., considering the diversity or similarity of S. To investigate whether one dimension is consistently better than the other one across different tasks, we conduct some pilot experiments on CommonsenseQA (Talmor et al., 2019), BoolQ (Clark et al., 2019) and AGNews (Zhang et al., 2015). Specifically, we randomly sample 100 examples from the original test set for experiments and conduct 4-shot learning using GPT-3.5 (gpt-3.5-turbo). Following Zhang et al. (2023a), we use SentenceBERT (Reimers and Gurevych, 2019) to encode all samples. For each test sample, the SimilarICL method selects the top-4 similar training data based on cosine similarity while the Random-ICL method randomly samples 4 training examples as few-shot demonstrations. Inspired by Wang et al. (2022b), we apply self-consistency with 3 decoding paths (temperature 0.7) to Similar-ICL (named Similar-ICL-Consistency) and run Random-ICL 3 times before majority voting (named RandomICL-Voting) to improve the robustness. The results of different methods on four datasets are reported in Table 1. We can observe that the diversity dimension outperforms the similarity dimension on CommonsenseQA while the similarity dimension is superior to the diversity dimension on BoolQ and AGNews. Therefore, the optimal dimension for selecting demonstration examples is task-specific. Thus, it is unreasonable to claim that one dimension is consistently better than the other one in ICL demonstration selection. Intuitively, semantically similar examples can help the model correctly answer the test query\nas they might share similar input-output patterns with the test sample which could unleash GPT3.5\u2019s power of text generation. To further understand why the similarity dimension underperforms the diversity dimension on CommonsenseQA, we present a case study in Table 2. We can see that the answer of the final demonstration example extracted by Similar-ICL-Consistency, i.e., \u2018most buildings\u2019 is also in the options list of the test sample, which misleads the decision process of the model, leading to a wrong answer. In addition, the selected demonstrations might not include enough important information as high similarity also results in redundancy. Considering the strengths and weaknesses of both dimensions, we aim to design a method that can select demonstration examples that are diverse (minimizing misleading information) but still strongly correlated with the test sample, which is introduced in the next section.\n# 5 Iterative Demonstration Selection\nBased on the observations and considerations in \u00a74, we introduce Iterative Demonstration Selection (IDS) for ICL demonstration selection by leveraging how the test sample is answered (see Fig. 2 for an illustration). Intuitively, the demonstrations that are similar to the reason for answering a sample are strongly correlated with this sample. Therefore, we propose to incorporate zero-shot chain-of-thought reasoning (Zero-shot-CoT) into IDS to iteratively select demonstration examples that are diverse but still have a strong correlation with the test sample. Specifically, for each test sample \u02c6xi, IDS mainly consists of four steps:\n1. We apply Zero-shot-CoT, i.e., \u201cLet\u2019s think step by step.\u201d to the test sample \u02c6xi before selecting demonstrations to obtain a reasoning path R.\n2. The reasoning path R is then used to select top-k (k is the number of shot) most semantically similar training examples {(x1, y1), ..., (xk, yk)} as few-shot demonstrations. We use Sentence-BERT (Reimers and Gurevych, 2019) to encode the reasoning path R and training examples to obtain the contextual representations and use cosine similarity to measure the similarity between representations.\n3. The selected k training examples {(x1, y1), ..., (xk, yk)} are then prepended to the test sample \u02c6xi for ICL. During inference, we\nSimilar-ICL-Consistency\nRandom-ICL-Voting\nWhich choice is the correct answer to the question?\nWhich choice is the correct answer to the question?\nExamples:\nQuestion: If you have cleaned off dust here it may be dif-\nficult to do your homework where? Answer Choices: (A)\ndesktop (B) closet (C) most buildings (D) surface of earth\n(E) stove\nAnswer: A\nQuestion: Where is dust likely to be under? Answer Choices:\n(A) closet (B) ground (C) windowsill (D) attic (E) carpet\nAnswer: E\nQuestion: Where would you find a dustbin that is being\nused? Answer Choices: (A) utility closet (B) ground (C)\ncupboard (D) broom closet (E) kitchen\nAnswer: E\nQuestion: Dust accumulates where? Answer Choices: (A)\nceiling (B) library (C) surface of earth (D) most buildings\n(E) desktop\nAnswer: D\nExamples:\nQuestion: She had a busy schedule, she had to run errands\nand pick up the kids the second she did what? Answer\nChoices: (A) make time for (B) take money (C) go outdoors\n(D) leave work (E) field\nAnswer: D\nQuestion: What is the worst outcome of an injury? Answer\nChoices: (A) cause death (B) cause bleeding (C) falling\ndown (D) become infected (E) claim insurance\nAnswer: A\nQuestion: Mom said that Sarah should stay in bed until she\nwas able to go to school again. What did mom say to Sarah\nwhen she tried to get up? Answer Choices: (A) you\u2019re sick\n(B) were sick (C) more rest (D) rest more (E) get back under\nthe covers\nAnswer: A\nQuestion: John got a raise, but he lost rank. Overall, it was a\ngood what? Answer Choices: (A) demotion (B) push down\n(C) go off strike (D) lower (E) go off strike\nAnswer: A\nThe response should follow the format: Answer: {A, B, C,\nD or E}\nThe response should follow the format: Answer: {A, B, C,\nD or E}\nHere is the test data.\nHere is the test data.\nQuestion: John wanted to clean all of the dust out of his\nplace before settling down to watch his favorite shows. What\nmight he hardest do dust? Answer Choices: (A) closet (B)\nunder the bed (C) television (D) attic (E) most buildings\nQuestion: John wanted to clean all of the dust out of his\nplace before settling down to watch his favorite shows. What\nmight he hardest do dust? Answer Choices: (A) closet (B)\nunder the bed (C) television (D) attic (E) most buildings\nAnswer: E \u2717\nAnswer: D \u2713\nTable 2: Examples of Similar-ICL-Consistency (first decoding path) and Random-ICL-Voting (first run) for constructing demonstration examples. The upper part is the input to LLMs, including few-shot demonstrations, and the lower part is the predicted answer. Similar-ICL-Consistency gives the wrong answer \u2018most buildings\u2019 which is actually the output of the final demonstration example, indicating that the decision process of the model is misled by this similar sample.\nensure that the generated answer \u02c6A is accompanied by its corresponding reasoning path \u02c6R through designed prompts, e.g., \u201cThe response should follow the format: Topic: {world, sports, business or technology}\\nReason: {reason}\u201d. Note that Zero-shot-CoT is also applied in this step to improve the quality of generated reasoning paths. After ICL, we go back to Step 2 for iterations using the new reasoning path \u02c6R.\n# 4. After q rounds of iterations between Step 2 and 3, we adopt majority voting on all \u02c6A to obtain the final result \u02c6Afinal.\nObviously, the selected demonstration examples are strongly correlated with the original test sample, i.e., achieving similarity, as they are selected by the generated reasoning paths (see Appendix A.4 for quantitative analysis of reasoning paths). And they can be different during iterations to achieve diversity because the reasoning paths vary in different iterations. Note that there is no reasoning path in\n<div style=\"text-align: center;\">Random-ICL-Voting</div>\nAlgorithm 1 Selection process of IDS\nRequire: Training set Dtrain, test set Dtest, LLM\u03b8, number of\ndemonstrations k, number of iterations q and answer set\n\u02c6Aall = \u2205\n1: ENCODE all samples in Dtrain using Sentence-BERT\n\u25b7\nEncode training set\n2: for \u02c6xi in Dtest do\n3:\nAPPLY Zero-shot-CoT to \u02c6xi to obtain the reasoning\npath R\n\u25b7Zero-shot-CoT\n4:\nfor j = 1, . . . , q do\n5:\nENCODE R using Sentence-BERT\n\u25b7Encode\nreasoning path\n6:\nUSE R to select top-k most similar examples S =\n{(x1, y1), ..., (xk, yk)} from Dtrain as demonstrations \u25b7\nKNN selection\n7:\n(\u02c6A, \u02c6R) = LLM\u03b8(S, \u02c6xi)\n\u25b7ICL with\nZero-shot-CoT\n8:\nR = \u02c6R, \u02c6Aall = \u02c6Aall \u222a{\u02c6A} \u25b7Update reasoning\npath and answer set\n9:\nend for\n10:\nADOPT majority voting for \u02c6Aall to obtain the final\nresult \u02c6Afinal for the test sample \u02c6xi\n\u25b7Majority voting\n11: end for\nfew-shot demonstrations (as shown in the green part in Fig. 2). The reasoning path only exists in\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7beb/7beb44f6-01e1-4dab-93cc-9638b762dee0.png\" style=\"width: 50%;\"></div>\nFigure 2: Illustration of our proposed Iterative Demonstration Selection (IDS). IDS first applies Zero-shot-CoT to the test sample to obtain a reasoning path, which is then used to select few-shot demonstrations from trainin examples through KNN. The selected demonstration examples are prepended to the test sample for ICL. To obtai the new reasoning path for extracting another set of demonstrations in the next iteration, an instruction for outpu format is inserted before the test sample. After several iterations, IDS uses majority voting to obtain the final resul\nthe output of LLMs. In addition, we illustrate the whole selection process in Alg. 1 and show the instructions and input formats of different types of tasks for ICL in Appendix A.1.\n# 6 Experiments\nIn this section, we first describe the tasks and datasets, and then introduce methods compared in our work. Finally, we present the experimental results.\n# 6.1 Experimental Setup\nTasks and Datasets We mainly investigate 6 different datasets covering 5 representative task categories: mathematical reasoning (GSM8K (Cobbe et al., 2021) and MATH (Hendrycks et al., 2021)), commonsense reasoning (CommonsenseQA (Talmor et al., 2019)), logical reasoning (LogiQA (Liu et al., 2020)), question answering (BoolQ (Clark et al., 2019)) and topic classification (AGNews (Zhang et al., 2015)). For each dataset, we randomly sample at most 10000 examples from the\noriginal training set as Dtrain and at most 2000 test examples as Dtest for evaluating the performance of selected demonstrations. The detailed information of different datasets is shown in Appendix A.2. To reduce the randomness, we run every experiment five times with different random seeds (resulting in different training and test samples if not using the whole set) and report the average results. Without specification, we use k = 4 number of demonstrations following Wang et al. (2023b) and set the number of iterations q to 3.\n(gpt-3.5-turbo) as the LLM and compare our IDS with the following methods in the experiments for selecting ICL demonstrations:\n Top-k-Consistency (Liu et al., 2022) selects the top-k semantically similar examples from the training set Dtrain as demonstrations for each test sample and applies self-consistency (Wang et al., 2022b) with q decoding paths (temperature 0.7) to match the number of iterations. Following Zhang et al. (2023a), all samples are encoded by Sentence-BERT (Reimers and Gurevych, 2019)\nMethod\nBoolQ\nGSM8K\nMATH\nCommonsenseQA\nLogiQA\nAGNews\nAverage\nVote-k\n86.7\u00b10.7\n76.5\u00b10.5\n35.7\u00b10.2\n75.2\u00b10.3\n45.4\u00b10.3\n88.1\u00b11.2\n67.9\u00b10.2\nMMR\n86.4\u00b10.8\n75.5\u00b10.7\n34.8\u00b10.3\n74.9\u00b10.2\n44.7\u00b10.3\n87.6\u00b11.1\n67.3\u00b10.3\nG-fair-Prompting\n84.8\u00b10.7\n76.9\u00b10.6\n34.6\u00b10.3\n75.5\u00b10.3\n43.8\u00b10.4\n88.9\u00b11.0\n67.4\u00b10.2\nSkill-KNN\n85.9\u00b10.5\n76.5\u00b10.3\n35.1\u00b10.2\n75.2\u00b10.2\n44.6\u00b10.2\n88.7\u00b10.9\n67.7\u00b10.1\nTop-k-Consistency\n87.1\u00b10.2\n76.1\u00b10.5\n35.6\u00b10.3\n74.5\u00b10.2\n45.7\u00b10.4\n89.3\u00b10.8\n68.1\u00b10.1\nRandom-Voting\n87.3\u00b10.6\n75.6\u00b10.4\n35.4\u00b10.1\n77.0\u00b10.2\n45.1\u00b10.3\n87.0\u00b11.6\n67.9\u00b10.2\nCluster-Voting\n86.4\u00b10.7\n76.8\u00b10.3\n34.9\u00b10.4\n76.5\u00b10.3\n44.1\u00b10.3\n86.8\u00b11.2\n67.6\u00b10.3\nIDS\n87.8\u00b10.8\n78.5\u00b10.4\n37.5\u00b10.2\n78.1\u00b10.1\n46.9\u00b10.2\n89.8\u00b10.8\n69.8\u00b10.1\nTable 3: Accuracy (%) of different methods on 6 datasets. Bold indicates the best result. IDS is consistently better than all previous baselines.\nTop-k-Consistency IDS Random-Voting\nAverage Similarity Score\n0.68\n0.48\n0.32\nTable 4: Average similarity scores between test examples and the corresponding selected demonstrations of three methods (Top-k-Consistency, IDS and RandomVoting).\nto obtain contextual representations for calculating the cosine similarity.\n\u2022 Random-Voting randomly selects k examples from Dtrain as few-shot demonstrations for every test sample and runs experiments q times before majority voting.\n Cluster-Voting partitions Dtrain into k clusters and selects a representative example from each cluster to form demonstrations. Following Zhang et al. (2023a), we choose the sample closest to the centroid in each cluster as the representative example. Same as Random-Voting, after running experiments q times, Cluster-Voting adopts majority voting to obtain the final result.\nBesides, we also compare IDS with several latest ICL demonstration selection approaches: Vote-k (Su et al., 2023), MMR (Ye et al., 2023b), G-fairPrompting (Ma et al., 2023) and Skill-KNN (An et al., 2023b) (see Appendix A.3 for more details of baselines). Similar to Top-k-Consistency, we apply self-consistency to these baselines to match the number of iterations q. Note that we find that simultaneously generating answers and reasoning paths can improve the ICL performance in general even if the target task is not a reasoning task in the conventional sense, e.g., topic classification. Therefore, we apply the same prompt, e.g., \u201cThe response should follow the format: Topic: {world, sports, business or technology}\\nReason: {reason}\u201d, and Zero-shot-CoT to baseline methods.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9d53/9d533585-5a17-4d98-8412-f9b5cac7a40f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3: Accuracy (%) of Top-k-Consistency and IDS with different numbers of reasoning paths or iterations.</div>\n# 6.2 Main Results\nTable 3 shows the average performance scores of different methods on all investigated datasets. From the results, we can observe that \u2022 Our proposed IDS consistently outperforms previous baselines on all datasets with a negligible increase in API request cost (Zero-shot-CoT in the first step), which demonstrates that our method can indeed effectively and efficiently select better ICL demonstration examples by incorporating the reason for answering the test query. \u2022 On average, IDS yields about 1.7% performance boost compared with the best baseline Topk-Consistency as it can fully leverage the merits of both selection dimensions (diversity and similarity). While the performance gain on a few simple benchmarks looks somewhat small (because the baseline results are already pretty high, e.g., the baseline performance of BoolQ and AGNews is above 85%), IDS performs much better than baselines on more complex tasks. For example, IDS can bring an average relative improvement of about 4% on mathematical reasoning tasks compared with Top-k-Consistency. To delve deeper into how different dimensions are leveraged in selected demonstrations, we report the average similarity scores between test samples and the corresponding demonstrations of different\nGPT-3.5 GPT-4\nTop-k-Consistency\n68.3\n73.9\nIDS\n69.9\n75.4\nTable 5: Accuracy (%) of Top-k-Consistency and IDS with different LLMs (GPT-3.5 and GPT-4). For GPT-4, we randomly sample 200 test examples per dataset due to the high cost.\nmethods in Table 4. Specifically, we randomly select 500 test examples for each dataset and use Sentence-BERT to obtain contextual representations for calculating similarity scores. We can see that the average similarity score of IDS is between that of Top-k-Consistency and Random-Voting, indicating that it can indeed strike a balance between two selection dimensions (see Appendix A.5 for more analysis on the diversity of the selected demonstration examples).\n# 6.3 Analysis\nDifferent Numbers of Iterations Our experiments and analysis so far use q = 3 iterations. To verify whether the performance gain of IDS is consistent across different numbers of iterations, we conduct controlled experiments with q = {1, 5, 7}. The average results of the 6 datasets with a randomly selected seed are reported in Fig. 3. IDS consistently outperforms the best baseline Top-kConsistency with different q (even q = 1, i.e., without voting), emphasizing the importance of rationales in selecting demonstration examples. Interestingly, the performance of ICL does not always improve with the number of iterations, which might be because increased iterations can also lead to unnecessary noise; we provide an in-depth analysis in Appendix A.6.\nRobustness to Model Types To demonstrate the robustness of IDS to model types, we conduct controlled experiments with GPT-4. Specifically, we randomly select one seed and sample 200 test examples per dataset for experiments due to the expensive cost. From the average results shown in Table 5, we can observe that IDS still achieves better performance than Top-k-Consistency when using GPT-4 as the LLM, showing its robustness to different LLMs.\nGeneralization to Open-source LLMs To better verify the generalization ability of IDS, we use vLLM (Kwon et al., 2023) to serve Llama-2chat models (Touvron et al., 2023) for experiments\nBoolQ\nGSM8K\n7B\n13B 70B\n7B\n13B 70B\nTop-k-Consistency 77.1 81.3 84.2 14.6 24.8 49.6\nIDS\n78.5 82.2 85.4 16.6 27.1 51.4\nTable 6: Accuracy (%) of different methods with Llama2-chat models.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2b72/2b7223b0-5424-417a-b862-2a6916cf6367.png\" style=\"width: 50%;\"></div>\nFigure 4: Several case studies of model responses. We color correct outputs in green, and wrong outputs in red. and compare IDS with Top-k-Consistency on two datasets: BoolQ and GSM8K. We randomly sample 500 test examples for experiments and report the results in Table 6, which demonstrates that IDS can successfully generalize to open-source LLMs of different sizes. Case Study To further understand the advantage of IDS, we show several cases in Fig. 4. As shown in the upper part of the figure, IDS can iteratively select more diverse demonstration examples than Top-k-Consistency which may be able to correct errors from previous iterations. Compared with Random-Voting, IDS can find examples that share more similar input-output patterns with the test sample to induce the LLM to generate correct answers (the lower part of the figure). In addition, we show the results with different numbers of demonstrations, the robustness of IDS to different embedding models and Zero-shot-CoT triggers, and the results on two additional datasets in Appendix A.7 \u223cA.10, respectively.\n# 7 Conclusion\nIn this work, we have introduced Iterative Demonstration Selection (IDS) that can iteratively select examples that are diverse but still strongly correlate with the test sample as demonstrations to improve the performance of in-context learning (ICL) by\nleveraging the rationale for answering the test sample. Extensive experimental results and analysis show that IDS can consistently outperform previous ICL demonstration selection baselines.\n# Limitations\nThis work has several limitations. First, due to the inference cost of ChatGPT, we do not conduct experiments on the entire test set. Besides, we include 6 datasets covering 5 different task types in this work. A further improvement could be to explore more diverse types of tasks.\n# References\nShengnan An, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng, Jian-Guang Lou, and Dongmei Zhang. 2023a. How do in-context examples affect compositional generalization? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 11027\u2013 11052, Toronto, Canada. Association for Computational Linguistics. Shengnan An, Bo Zhou, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng, Weizhu Chen, and Jian-Guang Lou. 2023b. Skill-based few-shot selection for in-context learning. arXiv preprint arXiv:2305.14210. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165. Mingda Chen, Jingfei Du, Ramakanth Pasunuru, Todor Mihaylov, Srini Iyer, Veselin Stoyanov, and Zornitsa Kozareva. 2022. Improving in-context few-shot learning via self-supervised training. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3558\u20133573, Seattle, United States. Association for Computational Linguistics. Wei-Lin Chen, Cheng-Kuang Wu, Yun-Nung Chen, and Hsin-Hsi Chen. 2023. Self-ICL: Zero-shot in-context learning with self-generated demonstrations. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 15651\u2013 15662, Singapore. Association for Computational Linguistics. Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. 2019. BoolQ: Exploring the surprising difficulty of natural yes/no questions. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2924\u20132936, Minneapolis, Minnesota. Association for Computational Linguistics.\nShengnan An, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng, Jian-Guang Lou, and Dongmei Zhang. 2023a. How do in-context examples affect compositional generalization? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 11027\u2013 11052, Toronto, Canada. Association for Computational Linguistics. Shengnan An, Bo Zhou, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng, Weizhu Chen, and Jian-Guang Lou. 2023b. Skill-based few-shot selection for in-context learning. arXiv preprint arXiv:2305.14210. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165. Mingda Chen, Jingfei Du, Ramakanth Pasunuru, Todor Mihaylov, Srini Iyer, Veselin Stoyanov, and Zornitsa Kozareva. 2022. Improving in-context few-shot learning via self-supervised training. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3558\u20133573, Seattle, United States. Association for Computational Linguistics. Wei-Lin Chen, Cheng-Kuang Wu, Yun-Nung Chen, and Hsin-Hsi Chen. 2023. Self-ICL: Zero-shot in-context learning with self-generated demonstrations. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 15651\u2013 15662, Singapore. Association for Computational Linguistics. Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. 2019. BoolQ: Exploring the surprising difficulty of natural yes/no questions. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2924\u20132936, Minneapolis, Minnesota. Association for Computational Linguistics.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168. Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Shuming Ma, Zhifang Sui, and Furu Wei. 2023. Why can gpt learn in-context? language models implicitly perform gradient descent as meta-optimizers. In ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models. Shizhe Diao, Pengcheng Wang, Yong Lin, and Tong Zhang. 2023. Active prompting with chain-ofthought for large language models. arXiv preprint arXiv:2302.12246. Bosheng Ding, Chengwei Qin, Linlin Liu, Lidong Bing, Shafiq Joty, and Boyang Li. 2022. Is gpt-3 a good data annotator? arXiv preprint arXiv:2212.10450. Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey for in-context learning. arXiv preprint arXiv:2301.00234. Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pages 1126\u20131135. PMLR. Yao Fu, Hao Peng, Litu Ou, Ashish Sabharwal, and Tushar Khot. 2023. Specializing smaller language models towards multi-step reasoning. arXiv preprint arXiv:2301.12726. Tianyu Gao, Adam Fisch, and Danqi Chen. 2021. Making pre-trained language models better few-shot learners. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3816\u20133830, Online. Association for Computational Linguistics. Tianyu Gao, Xu Han, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin, and Maosong Sun. 2020. Neural snowball for few-shot relation learning. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pages 7772\u2013 7779. AAAI Press. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv preprint arXiv:2103.03874.\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv preprint arXiv:2103.03874.\nNamgyu Ho, Laura Schmid, and Se-Young Yun. 2022. Large language models are reasoning teachers. arXiv preprint arXiv:2212.10071. Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan Liu, and Maosong Sun. 2018. Few-shot charge prediction with discriminative legal attributes. In Proceedings of the 27th International Conference on Computational Linguistics, pages 487\u2013498, Santa Fe, New Mexico, USA. Association for Computational Linguistics. Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao Lv, Lei Cui, Owais Khan Mohammed, Qiang Liu, et al. 2023. Language is not all you need: Aligning perception with language models. arXiv preprint arXiv:2302.14045. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. In Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022). Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with pagedattention. In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles. Itay Levy, Ben Bogin, and Jonathan Berant. 2022. Diverse demonstrations improve in-context compositional generalization. arXiv preprint arXiv:2212.06800. Xiaonan Li, Kai Lv, Hang Yan, Tianyang Lin, Wei Zhu, Yuan Ni, Guotong Xie, Xiaoling Wang, and Xipeng Qiu. 2023a. Unified demonstration retriever for incontext learning. arXiv preprint arXiv:2305.04320. Xiaonan Li and Xipeng Qiu. 2023. Finding supporting examples for in-context learning. arXiv preprint arXiv:2302.13539. Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen. 2022. On the advance of making language models better reasoners. arXiv preprint arXiv:2206.02336. Yingcong Li, Muhammed Emrullah Ildiz, Dimitris Papailiopoulos, and Samet Oymak. 2023b. Transformers as algorithms: Generalization and stability in in-context learning. Chen Ling, Xujiang Zhao, Wei Cheng, Yanchi Liu, Yiyou Sun, Xuchao Zhang, Mika Oishi, Takao Osaki, Katsushi Matsuda, Jie Ji, Guangji Bai, Liang Zhao, and Haifeng Chen. 2024. Uncertainty decomposition and quantification for in-context learning of large language models. In 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/77e1/77e1883e-24e6-421c-8505-01c4138c063e.png\" style=\"width: 50%;\"></div>\nChen Ling, Xujiang Zhao, Wei Cheng, Yanchi Liu, Yiyou Sun, Xuchao Zhang, Mika Oishi, Takao Osaki, Katsushi Matsuda, Jie Ji, Guangji Bai, Liang Zhao, and Haifeng Chen. 2024. Uncertainty decomposition and quantification for in-context learning of large language models. In 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7d4b/7d4bf778-a583-432d-bca8-6184991d405b.png\" style=\"width: 50%;\"></div>\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022b. Rethinking the role of demonstrations: What makes in-context learning work? In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 11048\u201311064,\nAbu Dhabi, United Arab Emirates. Association for Computational Linguistics.\nTai Nguyen and Eric Wong. 2023. In-context example selection with influences. arXiv preprint arXiv:2302.11042.\nChengwei Qin and Shafiq Joty. 2022. Continual fewshot relation learning via embedding space regularization and data augmentation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2776\u20132789, Dublin, Ireland. Association for Computational Linguistics.\nSachin Ravi and Hugo Larochelle. 2017. Optimization as a model for few-shot learning. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net.\nBERT: Sentence embeddings using Siamese BERTnetworks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982\u20133992, Hong Kong, China. Association for Computational Linguistics.\nOhad Rubin, Jonathan Herzig, and Jonathan Berant. 2022. Learning to retrieve prompts for in-context learning. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2655\u20132671, Seattle, United States. Association for Computational Linguistics.\nElvis Saravia, Hsien-Chi Toby Liu, Yen-Hao Huang, Junlin Wu, and Yi-Shin Chen. 2018. CARER: Contextualized affect representations for emotion recognition. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3687\u20133697, Brussels, Belgium. Association for Computational Linguistics.\nicl: Sequential retrieval of in-context examples with reinforcement learning. arXiv preprint arXiv:2305.14502. Seongjin Shin, Sang-Woo Lee, Hwijeen Ahn, Sungdong Kim, HyoungSeok Kim, Boseop Kim, Kyunghyun Cho, Gichang Lee, Woomyoung Park, Jung-Woo Ha, and Nako Sung. 2022. On the effect of pretraining corpora on in-context learning by a large-scale language model. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5168\u20135186, Seattle, United States. Association for Computational Linguistics. Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023. Reflexion: Language agents with verbal reinforcement learning. Preprint, arXiv:2303.11366. Hongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, and Tao Yu. 2023. Selective annotation makes language models better few-shot learners. In The Eleventh International Conference on Learning Representations. Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, and Xipeng Qiu. 2022. Black-box tuning for language-model-as-a-service. In International Conference on Machine Learning, pages 20841\u201320855. PMLR. Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A question answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4149\u20134158, Minneapolis, Minnesota. Association for Computational Linguistics. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288. Eleni Triantafillou, Richard Zemel, and Raquel Urtasun. 2017. Few-shot learning through an information retrieval lens. arXiv preprint arXiv:1707.02610. Chengyi Wang, Sanyuan Chen, Yu Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo Chen, Yanqing Liu, Huaming Wang, Jinyu Li, et al. 2023a. Neural codec language models are zero-shot text to speech synthesizers. arXiv preprint arXiv:2301.02111. Liang Wang, Nan Yang, and Furu Wei. 2024. Learning to retrieve in-context examples for large language models. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages\nLiang Wang, Nan Yang, and Furu Wei. 2024. Learning to retrieve in-context examples for large language models. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages\n1752\u20131767, St. Julian\u2019s, Malta. Association for Computational Linguistics. Xinyi Wang, Wanrong Zhu, and William Yang Wang. 2023b. Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning. arXiv preprint arXiv:2301.11916. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022a. Rationaleaugmented ensembles in language models. arXiv preprint arXiv:2207.00747. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022b. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022c. Self-instruct: Aligning language model with self generated instructions. arXiv preprint arXiv:2212.10560. Zhendong Wang, Yifan Jiang, Yadong Lu, Yelong Shen, Pengcheng He, Weizhu Chen, Zhangyang Wang, and Mingyuan Zhou. 2023c. In-context learning unlocked for diffusion models. arXiv preprint arXiv:2305.01115. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a. Emergent abilities of large language models. Transactions on Machine Learning Research. Survey Certification. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022b. Chain of thought prompting elicits reasoning in large language models. In Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022). Jerry Wei, Le Hou, Andrew Lampinen, Xiangning Chen, Da Huang, Yi Tay, Xinyun Chen, Yifeng Lu, Denny Zhou, Tengyu Ma, et al. 2023a. Symbol tuning improves in-context learning in language models. arXiv preprint arXiv:2305.08298. Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, et al. 2023b. Larger language models do in-context learning differently. arXiv preprint arXiv:2303.03846. Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112\u20131122, New Orleans, Louisiana. Association for Computational Linguistics.\nChenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. 2023. Visual chatgpt: Talking, drawing and editing with visual foundation models. arXiv preprint arXiv:2303.04671. Zhiyong Wu, Yaoxiang Wang, Jiacheng Ye, and Lingpeng Kong. 2022. Self-adaptive in-context learning. arXiv preprint arXiv:2212.10375. Sang Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. 2022. An explanation of in-context learning as implicit bayesian inference. In International Conference on Learning Representations. Shangqing Xu and Chao Zhang. 2024. Misconfidencebased demonstration selection for llm in-context learning. arXiv preprint arXiv:2401.06301. Jiacheng Ye, Zhiyong Wu, Jiangtao Feng, Tao Yu, and Lingpeng Kong. 2023a. Compositional exemplars for in-context learning. arXiv preprint arXiv:2302.05698. Xi Ye, Srinivasan Iyer, Asli Celikyilmaz, Veselin Stoyanov, Greg Durrett, and Ramakanth Pasunuru. 2023b. Complementary explanations for effective in-context learning. In Findings of the Association for Computational Linguistics: ACL 2023, pages 4469\u20134484, Toronto, Canada. Association for Computational Linguistics. Kang Min Yoo, Junyeob Kim, Hyuhng Joon Kim, Hyunsoo Cho, Hwiyeol Jo, Sang-Woo Lee, Sang-goo Lee, and Taeuk Kim. 2022. Ground-truth labels matter: A deeper look into input-label demonstrations. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 2422\u2013 2437, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. Eric Zelikman, Yuhuai Wu, and Noah D Goodman. 2022. Star: Bootstrapping reasoning with reasoning. arXiv preprint arXiv:2203.14465. Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level convolutional networks for text classification. Advances in neural information processing systems, 28:649\u2013657. Yiming Zhang, Shi Feng, and Chenhao Tan. 2022. Active example selection for in-context learning. arXiv preprint arXiv:2211.04486. Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2023a. Automatic chain of thought prompting in large language models. In The Eleventh International Conference on Learning Representations (ICLR 2023). Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. 2023b. Multimodal chain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language models. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 12697\u201312706. PMLR.\nDeyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023. Minigpt-4: Enhancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592.\n# A Appendix\n# A.1 Instructions and Input Formats of Different Tasks\nWe show the instructions and input formats of different types of tasks for in-context learning in Fig. 5.\n# A.2 Datasets Information\nWe show the detailed information of different datasets in Table 7.\n# A.3 Details of Baselines\nIn this work, we compare IDS with the following latest ICL demonstration selection approaches:\n\u2022 Vote-k (Su et al., 2023) is an unsupervised, graphbased selective annotation method used for selecting and annotating diverse, representative examples. The annotated examples then serve as a pool for demonstration retrieval. \u2022 MMR (Ye et al., 2023b) proposes a maximal marginal relevance-based approach for demonstration selection. \u2022 G-fair-Prompting (Ma et al., 2023) leverages greedy search to select the example with the highest fairness score at each step.\n\u2022 Skill-KNN (An et al., 2023b) generates skillbased descriptions for test queries and then uses these descriptions to select similar examples as demonstrations.\n# A.4 Measure of Reasoning Path Correlation\nWe report the average similarity score between test samples and the corresponding generated reasoning paths (scorereason), the average similarity score between test samples and randomly selected training examples (scorerandom), and the average similarity score between test samples and the most similar training examples (scoresimilar) in Table 8. For each dataset, we randomly select 500 test samples and use Sentence-BERT for similarity calculation. We can observe that scorereason is slightly worse than scoresimilar and much higher than scorerandom, indicating that the generated reasoning path is indeed strongly correlated with the test sample.\n# A.5 Analysis on Demonstration Diversity\nIn addition to the average similarity score between test samples and demonstrations, we further calculate the following metrics for IDS and Top-kConsistency:\n(2)\n\u2223\u2223 ()/(\u2223\u2223) where S is the set of the selected demonstration examples, and g is the function of measuring similarity. Q calculates the average pairwise similarity score of the demonstrations, which can be used to reflect whether they are diverse from each other. As can be seen from the results in Table 9, the average pairwise similarity score of IDS is much lower than that of Top-k-Consistency, verifying the diversity of demonstration examples selected by IDS.\n# A.6 Noise Caused by Increased Iterations\nAs observed from Fig. 3, the performance of ICL does not always improve with the number of iterations. We speculate that this is because too many iterations may also lead to unnecessary noise. As the number of iterations increases, the demonstrations selected in the latest iteration are more likely to have been chosen in previous iterations. Therefore, if these demonstrations result in wrong answers in previous iterations, these errors may be propagated to later iterations, i.e., unnecessary noise caused by increased iterations. To better verify our hypothesis, we calculate (i) the proportion of demonstrations selected in iteration 5 or 7 that\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/67ec/67ec9953-3cc0-4e81-af55-e239d20b7b41.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 5: Instructions and input formats of five different categories of tasks (topic classification, question answerin commonsense reasoning, logical reasoning, and mathematical reasoning) for ICL. For Zero-shot-CoT in the fir step of IDS, there is no demonstration example and the instruction \u201cHere is the test data.\u201d.</div>\nBoolQ\nGSM8K\nMATH\nCommonsenseQA\nLogiQA\nAGNews\n# Training Samples\n9427 (full)\n7473(full)\n5000\n9741 (full)\n7376(full)\n10000\n# Test Samples\n2000\n1000\n1000\n1221 (full)\n500\n1000\nTable 7: Deailed information of different datasets. # refers to \u2018the number of\u2019 and \u2018full\u2019 means the wh that different random seeds do not result in different samples if the whole set is used.\nTable 7: Deailed information of different datasets. # refers to \u2018the number of\u2019 and \u2018full\u2019 means the whole set. Note that different random seeds do not result in different samples if the whole set is used.\nscorereason scorerandom scoresimilar\nAverage Similarity Score\n0.59\n0.32\n0.68\nTable 8: Comparison between different average similarity scores.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fc8c/fc8c12d8-26a8-4e75-ad07-8f5fa65afeb6.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Table 9: Comparison of average pairwise similarity scores of demonstrations selected by different methods.</div>\nwere also chosen in previous iterations (Proppre), and (ii) the proportion of demonstrations selected in iteration 5 or 7 that were chosen in previous iterations and resulted in wrong answers (Propwrong pre ). We can see from Table 10 that the results of the 7th iteration are much higher than those of the 5th iteration, indicating the correctness of our claim.\n# A.7 Different Numbers of Demonstrations\nWhile we use k = 4 demonstration examples for all experiments, we also evaluate the effectiveness\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/424c/424cc497-40f8-4059-853b-0927401663fe.png\" style=\"width: 50%;\"></div>\nIteration\n5\n7\nProppre\n31.9% 60.4%\nPropwrong\npre\n13.1% 38.7%\nTable 10: Comparison between different iterations.\n2\n4\n6\n8\nTop-k-Consistency 68.0 68.3 68.5 68.4\nIDS\n69.4 69.9 69.9 69.7\nTable 11: Accuracy (%) of Top-k-Consistency and IDS with different numbers of demonstrations k.\nTable 11: Accuracy (%) of Top-k-Consistency and IDS with different numbers of demonstrations k.\nof IDS with different k. We randomly choose one seed for experiments and report the average results of the 6 datasets in Table 11. We can see that IDS consistently outperforms Top-k-Consistency with different numbers of demonstrations. In addition, more demonstrations do not guarantee better ICL performance, which is consistent with the observation in Wang et al. (2023b).\nBoolQ CommonsenseQA GSM8K\nTop-k-Consistency\n86.0\n75.4\n75.8\nIDS\n87.2\n78.0\n77.6\nTable 12: Accuracy (%) of different methods with OpenAI embedding model (text-embedding-ada-002) on three datasets.\nDefault Trigger1 Trigger2\nIDS\n70.1\n70.3\n70.0\nTable 13: Accuracy (%) of IDS with different Zero-shotCoT triggers.\n# A.8 Robustness to Embedding Models\nInstead of using Sentence-BERT, we also explore adopting the OpenAI embedding model (textembedding-ada-002) as the encoder. Specifically, we conduct experiments on 3 datasets: BoolQ, CommonsenseQA and GSM8K. For each dataset, we randomly sample 500 test examples and compare IDS with the baseline Top-k-Consistency. The results reported in Table 12 demonstrate IDS\u2019s robustness to different embedding models.\n# A.9 Robustness to Zero-shot-CoT Triggers\nTo verify the robustness of IDS to Zero-shot-CoT triggers, we conduct controlled experiments with two new triggers: \u201cLet\u2019s work this out in a step by step way to be sure we have the right answer.\u201d (Trigger1) and \u201cLet\u2019s solve this problem step by step\u201d (Trigger2). Specifically, we randomly sample 500 test examples per dataset for experiments and report the average results in Table 13, which demonstrates that IDS is indeed robust to different Zero-shot-CoT triggers.\n# A.10 Two Additional Datasets\nTo better demonstrate the generalization ability of IDS, we further conduct experiments on two additional datasets: MNLI (natural language inference) (Williams et al., 2018) and Emotion (emotion classification) (Saravia et al., 2018). The comparison between IDS and the baseline Top-k-Consistency is shown in Table 14, which verifies the strong generalizability of IDS.\nMNLI Emotion\nTop-k-Consistency\n65.7\n58.1\nIDS\n67.4\n60.3\nTable 14: Results on two additional datasets.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of selecting suitable examples for in-context learning (ICL) in large language models (LLMs), highlighting the sensitivity of ICL performance to the choice of demonstration examples and the necessity for a new method to optimize this selection process.",
        "problem": {
            "definition": "The problem defined is the challenge of selecting the most effective few-shot demonstrations for ICL, which can significantly affect model performance across various tasks.",
            "key obstacle": "The main obstacle is the lack of a systematic approach to determine whether diversity or similarity is more beneficial for demonstration selection, as existing methods often rely on either dimension without task-specific optimization."
        },
        "idea": {
            "intuition": "The idea is inspired by the observation that the optimal selection dimension for demonstrations is task-specific, and that leveraging both diversity and similarity can enhance ICL performance.",
            "opinion": "The proposed idea, Iterative Demonstration Selection (IDS), iteratively chooses examples that are diverse yet strongly correlated with the test sample, utilizing the reasoning generated from the test sample.",
            "innovation": "The innovation lies in the iterative nature of IDS, where it combines zero-shot chain-of-thought reasoning with demonstration selection, allowing for adaptive selection based on the output reasoning path."
        },
        "method": {
            "method name": "Iterative Demonstration Selection",
            "method abbreviation": "IDS",
            "method definition": "IDS is a method that selects demonstration examples for ICL by iteratively applying reasoning to identify diverse yet relevant examples based on the test sample.",
            "method description": "IDS selects demonstrations through a process that combines zero-shot chain-of-thought reasoning with iterative refinement of selected examples.",
            "method steps": [
                "Apply zero-shot chain-of-thought reasoning to the test sample to generate a reasoning path.",
                "Select the top-k training examples that are semantically similar to the reasoning path as demonstrations.",
                "Prepend the selected demonstrations to the test sample for inference.",
                "Iterate the above steps, updating the reasoning path and selecting new demonstrations based on the output."
            ],
            "principle": "The effectiveness of IDS is grounded in the idea that reasoning paths can guide the selection of relevant demonstrations, ensuring that selected examples are both diverse and closely related to the test query."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted across six datasets covering various tasks, including mathematical reasoning, commonsense reasoning, logical reasoning, question answering, and topic classification, with a focus on the performance of IDS compared to existing methods.",
            "evaluation method": "Performance was measured through accuracy across different datasets, with multiple runs to ensure robustness and consistency in results."
        },
        "conclusion": "The experiments demonstrate that IDS consistently outperforms previous ICL demonstration selection methods, confirming its effectiveness in enhancing model performance through better demonstration selection.",
        "discussion": {
            "advantage": "IDS stands out due to its ability to adaptively select demonstrations that balance diversity and similarity, leading to improved performance across various tasks.",
            "limitation": "The method's limitations include the inference cost associated with using large language models and the restricted scope of datasets utilized in the experiments.",
            "future work": "Future research could explore the application of IDS to a wider variety of tasks and datasets, as well as investigate ways to further optimize the demonstration selection process."
        },
        "other info": {
            "info1": "The method was tested with multiple iterations to assess the impact on performance.",
            "info2": {
                "info2.1": "IDS shows robustness across different model types, including GPT-4.",
                "info2.2": "The method is adaptable to various embedding models and zero-shot chain-of-thought triggers."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "3.3",
            "key information": "The proposed method, Iterative Demonstration Selection (IDS), selects demonstration examples for in-context learning by iteratively applying reasoning to identify diverse yet relevant examples based on the test sample."
        },
        {
            "section number": "3.1",
            "key information": "IDS adapts to various contexts by balancing diversity and similarity in demonstration selection, which enhances in-context learning performance across different tasks."
        },
        {
            "section number": "4.1",
            "key information": "The design of prompts can be significantly influenced by the demonstration selection process, as IDS uses zero-shot chain-of-thought reasoning to guide the selection of relevant examples."
        },
        {
            "section number": "6.2",
            "key information": "The limitations of IDS include the inference cost associated with using large language models and the restricted scope of datasets utilized in the experiments."
        },
        {
            "section number": "5.2",
            "key information": "The evaluation setting for IDS included various tasks such as question answering, demonstrating its application in real-world scenarios."
        }
    ],
    "similarity_score": 0.7216033815655294,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2330_in-co/papers/In-Context Learning with Iterative Demonstration Selection.json"
}