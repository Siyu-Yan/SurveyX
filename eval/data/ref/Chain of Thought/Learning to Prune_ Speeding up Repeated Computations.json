{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1904.11875",
    "title": "Learning to Prune: Speeding up Repeated Computations",
    "abstract": "It is common to encounter situations where one must solve a sequence of similar computational problems. Running a standard algorithm with worst-case runtime guarantees on each instance will fail to take advantage of valuable structure shared across the problem instances. For example, when a commuter drives from work to home, there are typically only a handful of routes that will ever be the shortest path. A naive algorithm that does not exploit this common structure may spend most of its time checking roads that will never be in the shortest path. More generally, we can often ignore large swaths of the search space that will likely never contain an optimal solution.\n  We present an algorithm that learns to maximally prune the search space on repeated computations, thereby reducing runtime while provably outputting the correct solution each period with high probability. Our algorithm employs a simple explore-exploit technique resembling those used in online algorithms, though our setting is quite different. We prove that, with respect to our model of pruning search spaces, our approach is optimal up to constant factors. Finally, we illustrate the applicability of our model and algorithm to three classic problems: shortest-path routing, string search, and linear programming. We present experiments confirming that our simple algorithm is effective at significantly reducing the runtime of solving repeated computations.",
    "bib_name": "alabi2019learningprunespeedingrepeated",
    "md_text": "# Learning to Prune: Speeding up Repeated Computations\nDaniel Alabi Harvard University alabid@g.harvard.edu Adam Tauman Kalai Microsoft Research noreply@microsoft.com Katrina Ligett Hebrew University katrina@cs.huji.ac.il Cameron Musco Microsoft Research amusco@microsoft.com Christos Tzamos University of Wisconsin-Madison tzamos@wisc.edu Ellen Vitercik Carnegie Mellon University vitercik@cs.cmu.edu\n# April 29, 2019\nAbstract\nIt is common to encounter situations where one must solve a sequence of similar computational problems. Running a standard algorithm with worst-case runtime guarantees on each instance will fail to take advantage of valuable structure shared across the problem instances. For example, when a commuter drives from work to home, there are typically only a handful of routes that will ever be the shortest path. A na\u00a8\u0131ve algorithm that does not exploit this common structure may spend most of its time checking roads that will never be in the shortest path. More generally, we can often ignore large swaths of the search space that will likely never contain an optimal solution. We present an algorithm that learns to maximally prune the search space on repeated computations, thereby reducing runtime while provably outputting the correct solution each period with high probability. Our algorithm employs a simple explore-exploit technique resembling those used in online algorithms, though our setting is quite different. We prove that, with respect to our model of pruning search spaces, our approach is optimal up to constant factors. Finally, we illustrate the applicability of our model and algorithm to three classic problems: shortest-path routing, string search, and linear programming. We present experiments confirming that our simple algorithm is effective at significantly reducing the runtime of solving repeated computations.\narXiv:1904.11875v1\n# 1 Introduction\nConsider computing the shortest path from home to work every morning. The shortest path may vary from day to day\u2014sometimes side roads beat the highway; sometimes the bridge is closed due to construction. However, although San Francisco and New York are contained in the same road network, it is unlikely that a San Francisco-area commuter would ever find New York along her shortest path\u2014the edge times in the graph do not change that dramatically from day to day. With this motivation in mind, we study a learning problem where the goal is to speed up repeated computations when the sequence of instances share common substructure. Examples include repeatedly computing the shortest path between the same two nodes on a graph with varying edge weights, repeatedly computing string matchings, and repeatedly solving linear programs with mildly varying objectives. Our work is in the spirit of recent work in data-driven algorithm selection [e.g., Gupta and Roughgarden, 2017, Balcan et al., 2017, 2018a,b] and online learning [e.g., CesaBianchi and Lugosi, 2006, although with some key differences, which we discuss below].\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d95c/d95c6039-9a95-4c3e-b3a6-6340c22a0f86.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: A standard algorithm computing the shortest path from the upper to the lower star will explore many nodes (grey), even nodes in the opposite direction. Our algorithm learns to prune to a subgraph (black) of nodes that have been included in prior shortest paths.</div>\nThe basis of this work is the observation that for many realistic instances of repeated problems, vast swaths of the search space may never contain an optimal solution\u2014perhaps the shortest path is always contained in a specific region of the road network; large portions of a DNA string may never contain the patterns of interest; a few key linear programming constraints may be the only ones that bind. Algorithms designed to satisfy worst-case guarantees may thus waste substantial computation time on futile searching. For example, even if a single, fixed path from home to work were best every day, Dijkstra\u2019s algorithm would consider all nodes within distance di from home on day i, where di is the length of the optimal path on day i, as illustrated in Figure 1. We develop a simple solution, inspired by online learning, that leverages this observation to the maximal extent possible. On each problem, our algorithm typically searches over a small, pruned subset of the solution space, which it learns over time. This pruning is the minimal subset containing all previously returned solutions. These rounds are analogous to \u201cexploit\u201d rounds in online learning. To learn a good subset, our algorithm occasionally deploys a worst-case-style algorithm, which explores a large part of the solution space and guarantees correctness on any instance. These rounds are analogous to \u201cexplore\u201d rounds in online learning. If, for example, a single fixed path were always optimal, our algorithm would almost always immediately output that path, as it would be the only one in its pruned search space. Occasionally, it would run a full Dijkstra\u2019s computation to check if it should expand the pruned set. Roughly speaking, we prove that our algorithm\u2019s solution is almost always correct, but its cumulative runtime is not much larger than that of running an optimal algorithm on the maximally-pruned search space in hindsight. Our results hold for worst-case sequences of problem instances, and we do not make any distributional assumptions. In a bit more detail, let f : X \u2192Y be a function that takes as input a problem instance x \u2208X and returns a solution y \u2208Y . Our algorithm receives a sequence of inputs from X. Our high-level goal is to correctly compute f on almost every round while minimizing runtime. For example, each x \u2208X might be a set of graph edge weights for some fixed graph G = (V, E) and f(x) might be the shortest s-t path for some vertices s and t. Given a sequence x1, . . . , xT \u2208X, a worst-case algorithm would simply compute and return f(xi) for every instance xi. However, in many application domains, we have access to other functions mapping X to Y , which are faster to compute. These simpler functions are defined by subsets S of a universe U that represents the entire search space. We call each subset a \u201cpruning\u201d of the search space. For example, in the shortest paths problem, U equals the set E of edges and a pruning S \u2282E is a subset of the edges. The function corresponding to S, which we denote fS : X \u2192Y , also takes as input edge weights x, but\nreturns the shortest path from s to t using only edges from the set S. By definition, the function that is correct on every input is f = fU. We assume that for every x, there is a set S\u2217(x) \u2286U such that fS(x) = f(x) if and only if S \u2287S\u2217(x) \u2013 a mild assumption we discuss in more detail later on. Given a sequence of inputs x1, . . . , xT , our algorithm returns the value fSi(xi) on round i, where Si is chosen based on the first i inputs x1, . . . , xi. Our goal is two fold: first, we hope to minimize the size of each Si (and thereby maximally prune the search space), since |Si| is often monotonically related to the runtime of computing fSi(xi). For example, a shortest path computation will typically run faster if we consider only paths that use a small subset of edges. To this end, we prove that if S\u2217is the smallest set such that fS\u2217(xi) = f(xi) for all i (or equivalently,1 S\u2217= \ufffdT i=1 S\u2217(xi)), then\nwhere the expectation is over the algorithm\u2019s randomness. At the same time, we seek to minimize the the number of mistakes the our algorithm makes (i.e., rounds i where f(xi) \u0338= fSi(xi)). We prove that the expected fraction of rounds i where fSi(xi) \u0338= f(xi) is O(|S\u2217|/ \u221a T). Finally, the expected runtime2 of the algorithm is the expected time required to compute fSi(xi) for i \u2208[T], plus O(|S\u2217| \u221a T) expected time to determine the subsets S1, . . . , ST . We instantiate our algorithm and corresponding theorem in three diverse settings\u2014shortestpath routing, linear programming, and string matching\u2014to illustrate the flexibility of our approach. We present experiments on real-world maps and economically-motivated linear programs. In the case of shortest-path routing, our algorithm\u2019s performance is illustrated in Figure 1. Our algorithm explores up to five times fewer nodes on average than Dijkstra\u2019s algorithm, while sacrificing accuracy on only a small number of rounds. In the case of linear programming, when the objective function is perturbed on each round but the constraints remain invariant, we show that it is possible to significantly prune the constraint matrix, allowing our algorithm to make fewer simplex iterations to find solutions that are nearly always optimal.\n# 1.1 Related work\nOur work advances a recent line of research studying the foundations of algorithm configuration. Many of these works study a distributional setting [Ailon et al., 2011, Clarkson et al., 2014, Gupta and Roughgarden, 2017, Kleinberg et al., 2017, Balcan et al., 2017, 2018a,b, Weisz et al., 2018]: there is a distribution over problem instances and the goal is to use a set of samples from this distribution to determine an algorithm from some fixed class with the best expected performance. In our setting, there is no distribution over instances: they may be adversarially selected. Additionally, we focus on quickly computing solutions for polynomial-time-tractable problems rather than on developing algorithms for NP-hard problems, which have been the main focus of prior work. Several works have also studied online algorithm configuration without distributional assumptions from a theoretical perspective [Gupta and Roughgarden, 2017, Cohen-Addad and Kanade, 2017, Balcan et al., 2018b]. Before the arrival of any problem instance, the learning algorithm fixes a class of algorithms to learn over. The classes of algorithms that Gupta and Roughgarden [2017], and Cohen-Addad and Kanade [2017], and Balcan et al. [2018b] study are infinite, defined by real-valued parameters. The goal is to select parameters at each timestep while minimizing\n1We explain this equivalence in Lemma 3.1. 2As we will formalize, when determining S1, . . . , ST , our algorithm must compute the smallest set S such that fS(xi) = f(xi) on some of the inputs xi. In all of the applications we discuss, the total runtime required for these computations is upper bounded by the total time required to compute fSi(xi) for i \u2208[T].\nregret. These works provide conditions under which it is possible to design algorithms achieving sublinear regret. These are conditions on the cost functions mapping the real-valued parameters to the algorithm\u2019s performance on any input. In our setting, the choice of a pruning S can be viewed as a parameter, but this parameter is combinatorial, not real-valued, so the prior analyses do not apply. Several works have studied how to take advantage of structure shared over a sequence of repeated computations for specific applications, including linear programming [Banerjee and Roy, 2015] and matching [Deb et al., 2006]. As in our work, these algorithms have full access to the problem instances they are attempting to solve. These approaches are quite different (e.g., using machine classifiers) and highly tailored to the application domain, whereas we provide a general algorithmic framework and instantiate it in several different settings. Since our algorithm receives input instances in an online fashion and makes no distributional assumptions on these instances, our setting is reminiscent of online optimization. However, unlike the typical online setting, we observe each input xi before choosing an output yi. Thus, if runtime costs were not a concern, we could always return the best output for each input. We seek to trade off correctness for lower runtime costs. In contrast, in online optimization, one must commit to an output yi before seeing each input xi, in both the full information and bandit settings [see, e.g., Kalai and Vempala, 2005, Awerbuch and Kleinberg, 2008]. In such a setting, one cannot hope to return the best yi for each xi with significant probability. Instead, the typical goal is that the performance over all inputs should compete with the performance of the best fixed output in hindsight.\n# 2 Model\nWe start by defining our model of repeated computation. Let X be an abstract set of problem instances and let Y be a set of possible solutions. We design an algorithm that operates over T rounds: on round i, it receives an instance xi \u2208X and returns some element of Y . Definition 2.1 (Repeated algorithm). Over T rounds, a repeated algorithm A encounters a sequence of inputs x1, x2, . . . , xT \u2208X. On round i, after receiving input xi, it outputs A(x1:i) \u2208Y , where x1:i denotes the sequence x1, . . . , xi. A repeated algorithm may maintain a state from period to period, and thus A(x1:i) may potentially depend on all of x1, ..., xi. We assume each problem instance x \u2208X has a unique correct solution (invoking tie-breaking assumptions as necessary; in Section 6, we discuss how to handle problems that admit multiple solutions). We denote the mapping from instances to correct solutions as f : X \u2192Y . For example, in the case of shortest paths, we fix a graph G and a pair (s, t) of source and terminal nodes. Each instance x \u2208X represents a weighting of the graph\u2019s edges. The set Y consists of all paths from s to t in G. Then f(x) returns the shortest path from s to t in G, given the edge weights x (breaking ties according to some canonical ordering of the elements of Y , as discussed in Section 6). To measure correctness, we use a mistake bound model [see, e.g., Littlestone, 1987]. Definition 2.2 (Repeated algorithm mistake bound). The mistake bound of the repeated algorithm A given inputs x1, . . . , xT is\nWe start by defining our model of repeated computation. Let X be an abstract set of problem instances and let Y be a set of possible solutions. We design an algorithm that operates over T rounds: on round i, it receives an instance xi \u2208X and returns some element of Y .\nDefinition 2.1 (Repeated algorithm). Over T rounds, a repeated algorithm A encounters a sequence of inputs x1, x2, . . . , xT \u2208X. On round i, after receiving input xi, it outputs A(x1:i) \u2208Y , where x1:i denotes the sequence x1, . . . , xi. A repeated algorithm may maintain a state from period to period, and thus A(x1:i) may potentially depend on all of x1, ..., xi.\nMT (A, x1:T ) = E \ufffdT \ufffd i=1 1[A(x1:i) \u0338= f(xi)] \ufffd\nwhere the expectation is over the algorithm\u2019s random choice\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1231/12312d60-ee58-4436-8095-7ae85b7ebfbd.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) Original unweighted graph G.</div>\n<div style=\"text-align: center;\">Figure 2: Repeated shortest paths and optimal pruning of a graph G. If the shortest path was always s-b-e-t or s-b-d-t, it would be unnecessary to search the entire graph for each instance.</div>\nTo minimize the number of mistakes, the na\u00a8\u0131ve algorithm would simply compute the function f(xi) at every round i. However, in our applications, we will have the option of computing other functions mapping the set X of inputs to the set Y of outputs that are faster to compute than f. Broadly speaking, these simpler functions are defined by subsets S of a universe U, or \u201cprunings\u201d of U. For example, in the shortest paths problem, given a fixed graph G = (V, E) as well as source and terminal nodes s, t \u2208V , the universe is the set of edges, i.e., U = E. Each input x is a set of edge weights and f(x) computes the shortest s-t path in G under the input weights. The simpler function corresponding to a subset S \u2282E of edges also takes as input weights x, but it returns the shortest path from s to t using only edges from the set S (with fS(x) = \u22a5if no such path exists). Intuitively, the universe U contains all the information necessary to compute the correct solution f(x) to any input x, whereas the function corresponding to a subset S \u2282U can only compute a subproblem using information restricted to S. Let fS : X \u2192Y denote the function corresponding to the set S \u2286U. We make two natural assumptions on these functions. First, we assume the function corresponding to the universe U is always correct. Second, we assume there is a unique smallest set S\u2217(x) \u2286U that any pruning must contain in order to correctly compute f(x). These assumptions are summarized below.\nGiven a sequence of inputs x1, . . . , xT , our algorithm returns the value fSi(xi) on round i, where the choice of Si depends on the first i inputs x1, . . . , xi. In our applications, it is typically faster to compute fS over fS\u2032 if |S| < |S\u2032|. Thus, our goal is to minimize the number of mistakes the algorithm makes while simultaneously minimizing E [\ufffd|Si|]. Though we are agnostic to the specific runtime of computing each function fSi, minimizing E [\ufffd|Si|] roughly amounts to minimizing the search space size and our algorithm\u2019s runtime in the applications we consider. We now describe how this model can be instantiated in three classic settings: shortest-path routing, string search, and linear programming.\nShortest-path routing. In the repeated shortest paths problem, we are given a graph G = (V, E) (with static structure) and a fixed pair s, t \u2208V of source and terminal nodes. In period i \u2208[T], the algorithm receives a nonnegative weight assignment xi : E \u2192R\u22650. Figure 2 illustrates the pruning model applied to the repeated shortest paths problem. For this problem, the universe is the edge set (i.e., U = E) and S is a subset of edges in the graph. The set X consists of all possible weight assignments to edges in the graph G and Y \u22862E \u222a{\u22a5} is\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4a1c/4a1c13cb-bfce-4632-8581-9951274153e1.png\" style=\"width: 50%;\"></div>\nthe set of all paths in the graph, with \u22a5indicating that no path exists. The function f(x) returns the shortest s-t path in G given edge weights x. For any S \u2286U, the function fS : X \u2192Y computes the shortest s-t path on the subgraph induced by the edges in S (breaking ties by a canonical edge ordering). If S does not include any s-t path, we define fS(x) = \u22a5. Part 1 of Assumption 2.1 holds because U = E, so fU computes the shortest path on the entire graph. Part 2 of Assumption 2.1 also holds: since fS : X \u2192Y computes the shortest s-t path on the subgraph induced by the edges in S (breaking ties by some canonical edge ordering), we can see that fS(xi) = S\u2217(xi) if and only if S\u2217(xi) \u2286S. To \u201ccanonicalize\u201d the algorithm so there is always a unique solution, we assume there is a given ordering on edges and that ties are broken lexicographically according to the path description. This is easily achieved by keeping the heap maintained by Dijkstra\u2019s algorithm sorted not only by distances but also lexicographically. Linear programming. We consider computing argmaxy\u2208Rn \ufffd xT y : Ay \u2264b \ufffd , where we assume that (A, b) \u2208Rm\u00d7n \u00d7 Rm is fixed across all times steps but the vector xi \u2208X \u2286Rn defining the objective function xT i y may differ for each i \u2208[T]. To instantiate our pruning model, the universe U = [m] is the set of all constraint indices and each S \u2286U indicates a subset of those constraints. The set Y equals Rn \u222a{\u22a5}. For simplicity, we assume that the set X \u2286Rn of objectives contains only directions x such that there is a unique solution y \u2208Rn that is the intersection of exactly n constraints in A. This avoids both dealing with solutions that are the intersection of more than n constraints and directions that are under-determined and have infinitely-many solutions forming a facet. See Section 6 for a discussion of this issue in general. Given x \u2208Rn, the function f computes the linear program\u2019s optimal solution, i.e., f(x) = argmaxy\u2208Rn \ufffd xT y : Ay \u2264b \ufffd . For a subset of constraints S \u2286U, the function fS computes the optimal solution restricted to those constraints, i.e., fS(x) = argmaxy\u2208Rn{xT y : ASy \u2264bS}, where AS \u2208R|S|\u00d7n is the submatrix of A consisting of the rows indexed by elements of S and bS \u2208R|S| is the vector b with indices restricted to elements of S. We further write fS(x) = \u22a5 if there is no unique solution to the linear program (which may happen for small sets S even if the whole LP does have a unique solution). Part 1 of Assumption 2.1 holds because AU = A and bU = b, so it is indeed the case that fU = f. To see why part 2 of Assumption 2.1 also holds, suppose that fS(x) = f(x). If f(x) \u0338= \u22a5, the vector fS(x) must be the intersection of exactly n constraints in AS, which by definition are indexed by elements of S. This means that S\u2217(x) \u2286S. String search. In string search, the goal is to find the location of a short pattern in a long string. At timestep i, the algorithm receives a long string qi of some fixed length n and a pattern pi of some fixed length m \u2264n. We denote the long string as qi = \ufffd q(1) i , . . . , q(n) i \ufffd and the pattern as pi = \ufffd p(1) i , . . . , p(m) i \ufffd . The goal is to find an index j \u2208[n \u2212m + 1] such that pi = \ufffd q(j) i , q(j+1) i , . . . , q(j+m\u22121) i \ufffd . The function f returns the smallest such index j, or \u22a5if there is no match. In this setting, the set X of inputs consists of all string pairs of length n and m (e.g., {A, T, G, C}n\u00d7m for DNA sequences) and the set Y = [n \u2212m + 1] is the set of all possible match indices. The universe U = [n \u2212m + 1] also consists of all possible match indices. For any S \u2286U, the function fS(qi, pi) returns the smallest index j \u2208S such that pi = \ufffd q(j) i , q(j+1) i , . . . , q(j+m\u22121) i \ufffd , which we denote j\u2217 i . It returns \u22a5if there is no match. We can see that part 1 of Assumption 2.1 holds: fU(q, p) = f(q, p) for all (q, p) \u2208X, since fU checks every index in [n \u2212m + 1] for a match. Moreover, part 2 of Assumption 2.1 holds because fU(xi) = fS(xi) if and only if S\u2217(xi) = {j\u2217 i } \u2286S.\n# 3 The algorithm\nWe now present an algorithm (Algorithm 1), denoted A\u2217, that encounters a sequence of inputs x1, . . . , xT one-by-one. At timestep i, it computes the value fSi(xi), where the choice of Si \u2286U depends on the first i inputs x1, . . . , xi. We prove that, in expectation, the number of mistakes it makes (i.e., rounds where fSi(xi) \u0338= f(xi)) is small, as is \ufffdT i=1 |Si|. Our algorithm keeps track of a pruning of U, which we call \u00afSi at timestep i. In the first round, the pruned set is empty ( \u00afS1 = \u2205). On round i, with some probability pi, the algorithm computes the function fU(xi) and then computes S\u2217(xi), the unique smallest set that any pruning must contain in order to correctly compute fU(xi). (As we discuss in Section 3.1, in all of the applications we consider, computing S\u2217(xi) amounts to evaluating fU(xi).) The algorithm unions S\u2217(xi) with \u00afSi to create the set \u00afSi+1. Otherwise, with probability 1 \u2212pi, it outputs f \u00afSi(xi), and does not update the set \u00afSi (i.e., \u00afSi+1 = \u00afSi). It repeats in this fashion for all T rounds.\nAlgorithm 1 Our repeated algorithm A\u2217\n1: \u00afS1 \u2190\u2205\n2: for i \u2208{1, . . . , T} do\n3:\nReceive input xi \u2208X.\n4:\nWith probability pi, output fU(xi). Compute S\u2217(xi) and set \u00afSi+1 \u2190\u00afSi \u222aS\u2217(xi).\n5:\nOtherwise (with probability 1 \u2212pi), output f \u00afSi(xi) and set \u00afSi+1 \u2190\u00afSi.\nIn the remainder of this section, we use the notation S\u2217to denote the smallest set such that fS\u2217(xi) = f(xi) for all i \u2208[T]. To prove our guarantees, we use the following helpful lemma: Lemma 3.1. For any x1, . . . , xT \u2208X, S\u2217= \ufffdT i=1 S\u2217(xi). Proof. First, we prove that S\u2217\u2287\u222aT i=1S\u2217(xi). For a contradiction, suppose that for some i \u2208[T], there exists an element j \u2208S\u2217(xi) such that j \u0338\u2208S\u2217. This means that fS\u2217(xi) = f(xi), but S\u2217\u0338\u2287S\u2217(xi), which contradicts Assumption 2.1: S\u2217(xi) is the unique smallest subset of U such that for any set S \u2286U, f(xi) = fS(xi) if and only if S\u2217(xi) \u2286S. Therefore, S\u2217\u2287\u222aT i=1S\u2217(xi). Next, let C = \u222aT i=1S\u2217(xi). Since S\u2217(xi) \u2286C, Assumption 2.1 implies that f(xi) = fC(xi) for all i \u2208[T]. Based on the definition of S\u2217and the fact that S\u2217\u2287C, we conclude that S\u2217= C = \u222aT i=1S\u2217(xi).\nTheorem 3.2. For any p \u2208(0, 1] such that pi \u2265p for all i \u2208[T] and any inputs x1, . . . , xT Algorithm 1 has a mistake bound of\nProof. Let S1, . . . , ST be the sets such that on round i, Algorithm 1 computes the function fSi. Consider any element e \u2208S\u2217. Let NT (e) be the number of times e \u0338\u2208Si but e \u2208S\u2217(xi) for some i \u2208[T]. In other words, NT (e) = |{i : e \u0338\u2208Si, e \u2208S\u2217(xi)}|. Every time the algorithm makes a mistake, the current set Si must not contain some e \u2208S\u2217(xi) (otherwise, Si \u2287S\u2217(xi), so the algorithm would not have made a mistake by Assumption 2.1). This means that every time the algorithm makes a mistake, NT (e) is incremented by 1 for at least one e \u2208S\u2217= \u222aT i=1S\u2217(xi). Therefore, \ufffd\nMT (A\u2217, x1:T ) \u2264 \ufffd e\u2208S\u2217 E[NT (e)],\n(1)\nwhere the expectation is over the random choices of Algorithm 1. For any element e \u2208S\u2217, let i1, . . . , it be the iterations where for all \u2113\u2208[t], e \u2208S\u2217(xi\u2113). By definition, NT (e) will only be incremented on some subset of these rounds. Suppose NT (e) is incremented by 1 on round ir. It must be that e \u0338\u2208Sir, which means Sir \u0338= U, and thus Sir = \u00afSir. Since e \u0338\u2208\u00afSir, it must be that e \u0338\u2208\u00afSi\u2113for \u2113\u2264r since \u00afSir \u2287\u00afSir\u22121 \u2287\u00b7 \u00b7 \u00b7 \u2287\u00afSi1. Therefore, in each round i\u2113with \u2113< r, Algorithm 1 must not have computed S\u2217(xi\u2113), because otherwise e would have been added to the set \u00afSi\u2113+1. We can bound the probability of these bad events as\nP \ufffd Sir = \u00afSir and Algorithm 1 does not compute S\u2217(xi\u2113) for \u2113< r \ufffd = r \ufffd \u2113=1 (1 \u2212pi\u2113) \u2264(1 \u2212p)r.\nP \ufffd Sir = \u00afSir and Algorithm 1 does not compute S\u2217(xi\u2113) for \u2113< r \ufffd = \ufffd \u2113=1 (1 \u2212pi\u2113) \u2264(1 \u2212p)r.\nAs a result,\nCorollary 3.3. Algorithm 1 with pi = 1 \u221a i has a mistake bound of MT (A\u2217, x1:T ) \u2264|S\u2217| \u221a T.\nIn the following theorem, we prove that the mistake bound in Theorem 3.2 is nearly tight. In particular, we show that for any k \u2208{1, . . . , T} there exists a random sequence of inputs x1, . . . , xT such that E [|S\u2217|] \u2248k and MT (A\u2217, x1:T ) = k(1\u2212p)(1\u2212(1\u2212p/k)T ) p . This nearly matches the upper bound from Theorem 3.2 of\nThe full proof is in Appendix A. In Section 4, we show that in fact, A\u2217achieves a near optimal tradeoff between runtime and pruned subset size over all possible pruning-based repeated algo-\nThe full proof is in Appendix A. In Section 4, we show that in fact, A\u2217achieves a near optimal tradeoff between runtime and pruned subset size over all possible pruning-based repeated algorithms. Theorem 3.4. For any p \u2208(0, 1], any time horizon T, and any k \u2208{1, . . . , T}, there is a random sequence of inputs to Algorithm 1 such that\nTheorem 3.4. For any p \u2208(0, 1], any time horizon T, and any k \u2208{1, . . . , T}, there is a random sequence of inputs to Algorithm 1 such that\nE[MT (A\u2217, x1:T )] = k(1 \u2212p)(1 \u2212(1 \u2212p/k)T ) p\nE[MT (A\u2217, x1:T )] = k(1 \u2212p)(1 \u2212(1 \u2212p/k)T ) p .\nThe expectation is over the sequence of inputs.\nProof sketch. We base this construction on shortest-path routing. There is a fixed graph G = (V, E) where V consists of two vertices labeled s and t and E consists of k edges labeled {1, . . . , k}, each of which connects s and t. The set X = \ufffd x(1), . . . , x(k)\ufffd consists of k possible edge weightings. Under the edge weights x(i), the edge i has a weight of 0 and all other edges j \u0338= i have a weight of 1. We prove the theorem by choosing an input at each round uniformly at random from X.\n(2)\nIn Theorem 3.2, we bounded the expected number of mistakes Algorithm 1 makes. Next, we bound E \ufffd1 T \ufffd|Si| \ufffd , where Si is the set such that Algorithm 1 outputs fSi(xi) in round i (so either Si = \u00afSi or Si = U, depending on the algorithm\u2019s random choice). In our applications, minimizing E \ufffd1 T \ufffd|Si| \ufffd means minimizing the search space size, which roughly amounts to minimizing the average expected runtime of Algorithm 1. Theorem 3.5. For any inputs x1, . . . , xT , let S1, . . . , ST be the sets such that on round i, Algorithm 1 computes the function f. Then\nIn Theorem 3.2, we bounded the expected number of mistakes Algorithm 1 makes. Next, we bound E \ufffd1 T \ufffd|Si| \ufffd , where Si is the set such that Algorithm 1 outputs fSi(xi) in round i (so either Si = \u00afSi or Si = U, depending on the algorithm\u2019s random choice). In our applications, minimizing E \ufffd1 T \ufffd|Si| \ufffd means minimizing the search space size, which roughly amounts to minimizing the average expected runtime of Algorithm 1.\nTheorem 3.5. For any inputs x1, . . . , xT , let S1, . . . , ST be the sets such that on round i, Algorithm 1 computes the function fSi. Then\nTheorem 3.5. For any inputs x1, . . . , xT , let S1, . . . , ST be the sets su rithm 1 computes the function fSi. Then\nwhere the randomness is over the coin tosses of Algorithm 1. Proof. We know that for all i, Si = U with probability pi and Si = \u00afSi with probability 1 \u2212pi. Therefore,\nProof. We know that for all i, Si = U with probability pi and Si = \u00afSi with probability 1 \u2212pi. Therefore,\nwhere the final inequality holds because \u00afSi \u2286S\u2217for all i \u2208[T].\nwhere the final inequality holds because \u00afSi \u2286S\u2217for all i \u2208[T]. If we set pi = 1/ \u221a i for all i, we have the following corollary, since \ufffdT i=1 pi \u22642 \u221a T. Corollary 3.6. Given a set of inputs x1, . . . , xT , let S1, ..., ST be the sets such that on round i Algorithm 1 computes the function fSi. If pi = 1 \u221a i for all i \u2208[T], then\n  If we set pi = 1/ \u221a i for all i, we have the following corollary, since \ufffdT i=1 pi \u22642 \u221a T. Corollary 3.6. Given a set of inputs x1, . . . , xT , let S1, ..., ST be the sets such that on round i, Algorithm 1 computes the function fSi. If pi = 1 \u221a i for all i \u2208[T], then\nIf we set pi = 1/ \u221a i for all i, we have the following corollary, since \ufffdT i=1 pi \u22642 \u221a T.\n \ufffd Corollary 3.6. Given a set of inputs x1, . . . , xT , let S1, ..., ST be the sets such that on round i, Algorithm 1 computes the function fSi. If pi = 1 \u221a i for all i \u2208[T], then\nre the expectation is over the random choices of Algorithm 1\n# 3.1 Instantiations of Algorithm 1\nWe now revisit and discuss instantiations of Algorithm 1 for the three applications outlined in Section 2: shortest-path routing, linear programming, and string search. For each problem, we describe how one might compute the sets S\u2217(xi) for all i \u2208[T].\nShortest-path routing. In this setting, the algorithm computes the true shortest path f(x) using, say, Dijkstra\u2019s shortest-path algorithm, and the set S\u2217(x) is simply the union of edges in that path. Since S\u2217= \u222aT i=1S\u2217(xi), the mistake bound of |S\u2217| \u221a T given by Corollary 3.3 is particularly strong when the shortest path does not vary much from day to day. Corollary 3.6 guarantees that the average edge set size run through Dijkstra\u2019s algorithm is at most |S\u2217| + 2(|E|\u2212|S\u2217|) \u221a T . Since the worst-case running time of Dijkstra\u2019s algorithm on a graph G\u2032 = (V \u2032, E\u2032) is \u02dcO(|V \u2032| + |E\u2032|), minimizing the average edge set size is a good proxy for minimizing runtime.\nLinear programming. In the context of linear programming, computing the set S\u2217(xi) is equivalent to computing f(x) and returning the set of tight constraints. Since S\u2217= \u222aT i=1S\u2217(xi), the mistake bound of |S\u2217| \u221a T given by Corollary 3.3 is strongest when the same constraints are tight across most timesteps. Corollary 3.6 guarantees that the average constraint set size considered in each round is at most |S\u2217| + 2(m\u2212|S\u2217|) \u221a T , where m is the total number of constraints. Since many well-known solvers take time polynomial in |Si| to compute fSi, minimizing E [\ufffd|Si|] is a close proxy for minimizing runtime.\nLinear programming. In the context of linear programming, computing the set S\u2217(xi) is equivalent to computing f(x) and returning the set of tight constraints. Since S\u2217= \u222aT i=1S\u2217(xi), the mistake bound of |S\u2217| \u221a T given by Corollary 3.3 is strongest when the same constraints are tight across most timesteps. Corollary 3.6 guarantees that the average constraint set size considered in each round is at most |S\u2217| + 2(m\u2212|S\u2217|) \u221a T , where m is the total number of constraints. Since many well-known solvers take time polynomial in |Si| to compute fSi, minimizing E [\ufffd|Si|] is a close proxy for minimizing runtime. String search. In this setting, the set S\u2217(qi, pi) consists of the smallest index j such that pi = \ufffd q(j) i , q(j+1) i , . . . , q(j+m\u22121) i \ufffd , which we denote j\u2217 i . This means that computing S\u2217(qi, pi) is equivalent to computing f(qi, pi). The mistake bound of |S\u2217| \u221a T = \ufffd\ufffd\u222aT i=1 {j\u2217 i } \ufffd\ufffd\u221a T given by Corollary 3.3 is particularly strong when the matching indices are similar across string pairs. Corollary 3.6 guarantees that the average size of the searched index set in each round is at most |S\u2217| + 2(n\u2212|S\u2217|) \u221a T . Since the expected average running time of our algorithm using the na\u00a8\u0131ve string-matching algorithm  E \ufffd m \ufffdT \ufffd  E \ufffd 1 \ufffdT \ufffd\nString search. In this setting, the set S\u2217(qi, pi) consists of the smallest index j such that pi = \ufffd q(j) i , q(j+1) i , . . . , q(j+m\u22121) i \ufffd , which we denote j\u2217 i . This means that computing S\u2217(qi, pi) is equivalent to computing f(qi, pi). The mistake bound of |S\u2217| \u221a T = \ufffd\ufffd\u222aT i=1 {j\u2217 i } \ufffd\ufffd\u221a T given by Corollary 3.3 is particularly strong when the matching indices are similar across string pairs. Corollary 3.6 guarantees that the average size of the searched index set in each round is at most |S\u2217| + 2(n\u2212|S\u2217|) \u221a T . Since the expected average running time of our algorithm using the na\u00a8\u0131ve string-matching algorithm to compute fSi is E \ufffd m T \ufffdT i=1 |Si| \ufffd , minimizing E \ufffd 1 T \ufffdT i=1 |Si| \ufffd amounts to minimizing runtime.\n# \ufffd \ufffd Lower bound on the tradeoff between acc\n# \ufffd \ufffd nd on the tradeoff between accuracy and \nWe now prove a lower bound on the tradeoff between runtime and the number of mistakes made by any repeated algorithm. We analyze a shortest path problem with two nodes s and t connected by m + 1 parallel edges (E = [m + 1]). Thus, all paths are single edges. For any m \u22651 and T > 1, consider the following distribution \u00b5m,T over T-tuples of edge weights in R(m+1)\u00d7T :\n\u2022 An edge e \u2208[m] and integer r \u2208[2T] are chosen uniformly at random. The weight on edge e is 1 on periods preceding r and 0 from periods r or later. \u2022 The weight on every other edge in [m] \\ {e} is 1 on every period.\nNote that because r \u2208[2T], with probability 1/2, r > T and edge m+1 will be the unique shortest path (S\u2217= {m + 1}) for all T periods. Otherwise, S\u2217= {e, m + 1}. We say that an algorithm A inspects an edge e on period i if it examines the memory location associated with that edge. Theorem 4.1. Fixing m \u22651 and any even integer T > 1, any repeated algorithm A must satisfy: E[m + number of inspections made by A] \u00b7 E[1 + number of mistakes made by A] \u2265mT/8, where the expectation is over the random edge weights and the randomness of the algorithm. The total number of inspections the algorithm A makes is clearly a lower bound on its total runtime, so Theorem 4.1 demonstrates a tradeoff between runtime and accuracy. This theorem is tight up to constant factors, as can be seen by the trivial algorithm that inspects every edge until it encounters a 0 on some edge e and then outputs that edge henceforth, which makes no mistakes and runs in expected time \u0398(mT). Conversely, the algorithm that always outputs edge m + 1 does not make any inspections and makes \u0398(T) expected mistakes. Finally our algorithm, when run with fixed p, achieves at most \u0398(1/p) expected mistakes and makes an expected \u0398(pmT) number of inspections and hence matches this tradeoff, up to constant factors. The proof of Theorem 4.1 is deferred until Appendix B.\nNote that because r \u2208[2T], with probability 1/2, r > T and edge m+1 will be the unique shortest path (S\u2217= {m + 1}) for all T periods. Otherwise, S\u2217= {e, m + 1}. We say that an algorithm A inspects an edge e on period i if it examines the memory location associated with that edge. Theorem 4.1. Fixing m \u22651 and any even integer T > 1, any repeated algorithm A must satisfy: E[m + number of inspections made by A] \u00b7 E[1 + number of mistakes made by A] \u2265mT/8, where the expectation is over the random edge weights and the randomness of the algorithm. The total number of inspections the algorithm A makes is clearly a lower bound on its total runtime, so Theorem 4.1 demonstrates a tradeoff between runtime and accuracy. This theorem is\nThe total number of inspections the algorithm A makes is clearly a lower bound on its total runtime, so Theorem 4.1 demonstrates a tradeoff between runtime and accuracy. This theorem is tight up to constant factors, as can be seen by the trivial algorithm that inspects every edge until it encounters a 0 on some edge e and then outputs that edge henceforth, which makes no mistakes and runs in expected time \u0398(mT). Conversely, the algorithm that always outputs edge m + 1 does not make any inspections and makes \u0398(T) expected mistakes. Finally our algorithm, when run with fixed p, achieves at most \u0398(1/p) expected mistakes and makes an expected \u0398(pmT) number of inspections and hence matches this tradeoff, up to constant factors. The proof of Theorem 4.1 is deferred until Appendix B.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0c2b/0c2b3254-1254-466a-8310-6a802fecac8e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e9f7/e9f768c4-36ba-4c64-a2a9-718930b027e8.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3296/3296b569-fdca-42d0-a4a4-3a553de14bbf.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) Top line: average number of nodes Dijkstra\u2019s algorithm explores. Bottom line: average number of nodes Algorithm 1 explores.</div>\n<div style=\"text-align: center;\">(a) Grey nodes: the nodes visited by Dijkstra\u2019s algorithm. Black nodes: the nodes in our algorithm\u2019s pruned subgraph.</div>\nFigure 3: Empirical evaluation of Algorithm 1 applied to shortest-path routing in Pittsburgh (Figures 3a and 3b) and linear programming (Figure 3c).\n# 5 Experiments\nn, we present experimental results for shortest-path routing a\nent experimental results for shortest-path routing and linear \nn this section, we present experimental results for shortest-pa\nShortest-path routing. We test Algorithm 1\u2019s performance on real-world street maps, which we access via Python\u2019s OSMnx package [Boeing, 2017]. Each street is an edge in the graph and each intersection is a node. The edge\u2019s weight is the street\u2019s distance. We run our algorithm for 30 rounds (i.e., T = 30) with pi = 1/ \u221a i for all i \u2208[T]. On each round, we randomly perturb each edge\u2019s weight via the following procedure. Let G = (V, E) be the original graph we access via Python\u2019s OSMnx package. Let x \u2208R|E| be a vector representing all edges\u2019 weights. On the ith round, we select a vector ri \u2208R|E| such that each component is drawn i.i.d. from the normal distribution with a mean of 0 and a standard deviation of 1. We then define a new edge-weight vector xi such that xi[j] = 1{x[j]+ri[j]>0} (x[j] + ri[j]) . In Appendix C, we experiment with alternative perturbation methods. In Figures 3a and 3b, we illustrate our algorithm\u2019s performance in Pittsburgh. Figure 3a illustrates the nodes explored by our algorithm over T = 30 rounds. The goal is to get from the upper to the lower star. The nodes colored grey are the nodes Dijkstra\u2019s algorithm would have visited if we had run Dijkstra\u2019s algorithm on all T rounds. The nodes colored black are the nodes in the pruned subgraph after the T rounds. Figure 3b illustrates the results of running our algorithm a total of 5000 times (T = 30 rounds each run). The top (orange) line shows the number of nodes Dijkstra\u2019s algorithm explored averaged over all 5000 runs. The bottom (blue) line shows the average number of nodes our algorithm explored. Our algorithm returned the incorrect path on a 0.068 fraction of the 5000 \u00b7 T = 150, 000 rounds. In Appendix C, we show a plot of the average pruned set size as a function of the number of rounds. Linear programming. We generate linear programming instances representing the linear relaxation of the combinatorial auction winner determination problem. See Appendix C for the specific form of this linear relaxation. We use the Combinatorial Auction Test Suite (CATS) [Leyton-Brown et al., 2000] to generate these instances. This test suite is meant to generate instances that are realistic and economically well-motivated. We use the CATS generator to create an initial instance with an objective function defined by a vector x and constraints defined by a matrix A and a vector b. On each round, we perturb the objective vector as we describe in Appendix C.2.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bc04/bc0479c5-6f42-46e4-9e6d-058beb85c241.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(c) Top line: average number of simplex iterations the simplex algorithm makes. Bottom line: average number of simplex iterations Algorithm 1 makes.</div>\nFrom the CATS \u201cArbitrary\u201d generator, we create an instance with 204 bids and 538 goods which has 204 variables and 946 constraints. We run Algorithm 1 for 30 rounds (T = 30) with pi = 1/ \u221a i for all i \u2208[T], and we repeat this 5000 times. In Figure 3c, the top (orange) line shows the number of simplex iterations the full simplex algorithm makes averaged over all 5000 runs. The bottom (blue) line shows the number of simplex iterations our algorithm makes averaged over all 5000 runs. We solve the linear program on each round using the SciPy default linear programming solver [Jones et al., 2001\u2013], which implements the simplex algorithm [Dantzig, 2016]. Our algorithm returned the incorrect solution on a 0.018 fraction of the 5000\u00b7T = 150, 000 rounds. In Appendix C, we show a plot of the average pruned set size as a function of the number of rounds.\n# 6 Multiple solutions and approximations\nIn this work, we have assumed that each problem has a unique solution, which we can enforce by defining a canonical ordering on solutions. For string matching, this could be the first match in a string as opposed to any match. For shortest-path routing, it is not difficult to modify shortest-path algorithms to find, among the shortest paths, the one with lexicographically \u201csmallest\u201d description given some ordering of edges. Alternatively, one might simply assume that there is exactly one solution, e.g., no ties in a shortest-path problem with real-valued edge weights. This latter solution is what we have chosen for the linear programming model, for simplicity. It would be natural to try to extend our work to problems that have multiple solutions, or even to approximate solutions. However, addressing multiple solutions in repeated computation rapidly raises NP-hard challenges. To see this, consider a graph with two nodes, s and t, connected by m parallel edges. Suppose the goal is to find any shortest path and suppose that in each period, the edge weights are all 0 or 1, with at least one edge having weight 0. If Zi is the set of edges with 0 weight on period i, finding the smallest pruning which includes a shortest path on each period is trivially equivalent to set cover on the sets Zi. Hence, any repeated algorithm handling problems with multiple solutions must address this computational hardness.\n# 7 Conclusion\nWe propose an algorithm for quickly solving a series of related problems. Our algorithm learns irrelevant regions of the solution space that may be pruned across instances. With high probability, our algorithm makes few mistakes, and it may prune large swaths of the search space. For problems where the solution can be checked much more quickly than found (such as linear programming), one can also check each solution and re-run the worst-case algorithm on the few errors to ensure zero mistakes. In other cases, there is a tradeoff between the mistake probability and runtime.\n# Acknowledgments\nThis work was supported in part by Israel Science Foundation (ISF) grant #1044/16, a subcontract on the DARPA Brandeis Project, and the Federmann Cyber Security Center in conjunction with the Israel national cyber directorate.\nNir Ailon, Bernard Chazelle, Kenneth L. Clarkson, Ding Liu, Wolfgang Mulzer, and C. Seshadhri. Self-improving algorithms. SIAM J. Comput., 40(2):350\u2013375, 2011. Baruch Awerbuch and Robert Kleinberg. Online linear optimization and adaptive routing. J. Comput. Syst. Sci., 74(1):97\u2013114, 2008. Maria-Florina Balcan, Vaishnavh Nagarajan, Ellen Vitercik, and Colin White. Learning-theoretic foundations of algorithm configuration for combinatorial partitioning problems. Proceedings of the Conference on Learning Theory (COLT), 2017. Maria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch. Proceedings of the International Conference on Machine Learning (ICML), 2018a. Maria-Florina Balcan, Travis Dick, and Ellen Vitercik. Dispersion for data-driven algorithm design, online learning, and private optimization. Proceedings of the IEEE Symposium on Foundations of Computer Science (FOCS), 2018b. Ashis Gopal Banerjee and Nicholas Roy. Efficiently solving repeated integer linear programming problems by learning solutions of similar linear programming problems using boosting trees. Technical Report MIT-CSAIL-TR-2015-00, MIT Computer Science and Artificial Intelligence Laboratory, 2015. Geoff Boeing. OSMnx: New methods for acquiring, constructing, analyzing, and visualizing complex street networks. Computers, Environment and Urban Systems, 65:126\u2013139, 2017. Nicolo Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, learning, and games. Cambridge university press, 2006. Kenneth L. Clarkson, Wolfgang Mulzer, and C. Seshadhri. Self-improving algorithms for coordinatewise maxima and convex hulls. SIAM J. Comput., 43(2):617\u2013653, 2014. Vincent Cohen-Addad and Varun Kanade. Online Optimization of Smoothed Piecewise Constant Functions. In Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS), 2017. George Dantzig. Linear programming and extensions. Princeton University Press, 2016. Supratim Deb, Devavrat Shah, and et al. Fast matching algorithms for repetitive optimization: An application to switch scheduling. In Proceedings of the Conference on Information Sciences and Systems (CISS), 2006. Rishi Gupta and Tim Roughgarden. A PAC approach to application-specific algorithm selection. SIAM J. Comput., 46(3):992\u20131017, 2017. Eric Jones, Travis Oliphant, Pearu Peterson, et al. SciPy: Open source scientific tools for Python, 2001\u2013. URL http://www.scipy.org/. [Online; accessed January 2019]. Adam Tauman Kalai and Santosh Vempala. Efficient algorithms for online decision problems. J. Comput. Syst. Sci., 71(3):291\u2013307, 2005.\nRobert Kleinberg, Kevin Leyton-Brown, and Brendan Lucier. Efficiency through procrastination: Approximately optimal algorithm configuration with runtime guarantees. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), 2017. Kevin Leyton-Brown, Mark Pearson, and Yoav Shoham. Towards a universal test suite for combinatorial auction algorithms. In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC), 2000. Nick Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. Machine Learning, 2(4):285\u2013318, 1987. Gell\u00b4ert Weisz, Andr\u00b4es Gy\u00a8orgy, and Csaba Szepesv\u00b4ari. LEAPSANDBOUNDS: A method for approximately optimal algorithm configuration. In Proceedings of the International Conference on Machine Learning (ICML), 2018.\n# A Proofs from Section 3\nTheorem 3.4. For any p \u2208(0, 1], any time horizon T, and any k \u2208{1, . . . , T}, there is a random sequence of inputs to Algorithm 1 such that\nand its expected mistake bound with pi = p for all i \u2208[T] is\nE[MT (A\u2217, x1:T )] = k(1 \u2212p)(1 \u2212(1 \u2212p/k)T ) p\nE[MT (A\u2217, x1:T )] = k(1 \u2212p)(1 \u2212(1 \u2212p/k)T ) p .\nThe expectation is over the sequence of inputs.\nProof. We base our construction on the shortest path problem. There is a fixed graph G = (V, E where V = {s, t} consists of two vertices labeled s and t and E consists of k edges labeled {1, . . . , k} each of which connects s and t. The set X = \ufffd x(1), . . . , x(k)\ufffd \u2282{0, 1}k consists of k possible edg weightings, where \ufffd\nIn other words, under the edge weights xi, the edge i has a weight of 0 and all other edges j \u0338= i have a weight of 1. The shortest path from s to t under the edge weights x(i) consists of the edge i and has a total weight of 0. Therefore, f \ufffd x(i)\ufffd = S\u2217\ufffd x(i)\ufffd = {i}. Given any non-empty subset of edges S \u2286E, fS \ufffd x(i)\ufffd = {i} if i \u2208S, and otherwise breaks ties according to a fixed but arbitrary tie-breaking rule. To construct the random sequence of inputs from the theorem statement, in each round i we choose the input xi uniformly at random from the set X. Therefore, letting S\u2217= \u222aT i=1S\u2217(xi), E[|S\u2217|] = k \ufffd 1 \u2212 \ufffd 1 \u22121 k \ufffdT \ufffd , because when throwing T balls uniformly at random into k bins, the expected number of empty bins is k \ufffd 1 \u22121 k \ufffdT . We now prove that\nE[MT (A\u2217, x1:T )] = k(1 \u2212p)(1 \u2212(1 \u2212p/k)T ) p ,\nwhere the expectation is over the sequence of inputs. To this end, let S1, . . . , ST that at round i, Algorithm 1 outputs fSi(xi).\nE[MT (A\u2217, x1:T )] = T \ufffd i=1 P[Mistake made at round i] = T \ufffd i=1 k \ufffd j=1 P[Si = \u00afSi, x(j) = xi, and j \u0338\u2208\u00afSi] = T \ufffd i=1 k \ufffd j=1 P[j \u0338\u2208\u00afSi | Si = \u00afSi and x(j) = xi] \u00b7 P[Si = \u00afSi and x(j) = xi] = T \ufffd i=1 k \ufffd j=1 P[j \u0338\u2208\u00afSi | Si = \u00afSi and x(j) = xi] \u00b7 P[Si = \u00afSi] \u00b7 P[x(j) = xi] = (1 \u2212p) k T \ufffd i=1 k \ufffd j=1 P[j \u0338\u2208\u00afSi | Si = \u00afSi and x(j) = xi]. Analyzing a single summand, P[j \u0338\u2208\u00afSi | Si = \u00afSi and x(j) = xi] = i\u22121 \ufffd t=0 Pr[xj is the input on exactly t rounds before round i and on those rounds = i\u22121 \ufffd t=0 \ufffdi \u22121 t \ufffd\ufffd1 \u2212p k \ufffdt \ufffd 1 \u22121 k \ufffdi\u22121\u2212t = \ufffd 1 \u2212p k \ufffdi\u22121 .\n= \u2212 \ufffd t=0 Pr[xj is the input on exactly t rounds before round i and on those rounds, S\u2113= \u00afS = i\u22121 \ufffd t=0 \ufffdi \u22121 t \ufffd\ufffd1 \u2212p k \ufffdt \ufffd 1 \u22121 k \ufffdi\u22121\u2212t\n\ufffd Therefore,\nas claimed.\n# B Proof of lower bound\nTheorem 4.1. Fixing m \u22651 and any even integer T > 1, any repeated algorithm A must satisfy: E[m + number of inspections made by A] \u00b7 E[1 + number of mistakes made by A] \u2265mT/8, where the expectation is over the random edge weights and the randomness of the algorithm.\nProof. First, consider a deterministic algorithm A. We say that A inspects edge e on period i if it examines the memory location for edge e\u2019s weight on period i. Let n be the total number of edges that would be inspected during the first T periods if r > T, which is well defined since when r > T, the weights are all fixed and hence the choices of the deterministic algorithm on the first T periods are fixed. In fact, since r > T with probability 1/2 the expected number of inspections is at least n/2. We next observe that before A has inspected an edge whose weight is 0, WLOG we may assume that A chooses edge m + 1 \u2013 this minimizes its expected number of mistakes since edge m + 1 has probability at least 1/2 of being the best conditional on any number of weight-1 inspections. (Once it inspects a 0 on e, of course runtime and mistakes are minimized by simply choosing e henceforth without any further inspections or calculations.) Let B \u2286[m] \u00d7 [T] be the set of edges and times that are not inspected by A (excluding edge m + 1). We now bound the expected number of mistakes in terms of b = |B| = mT \u2212n. We no longer assume r > T, but we can still use n as it is well defined. For each (e\u2032, r\u2032) \u2208B, there will be a mistake on r\u2032 if e = e\u2032 and r \u2264r\u2032 and (e, r), (e, r + 1), . . . , (e, r\u2032) \u2208B. Hence, we divide B into a collection I of maximal consecutive intervals, Iaij = {(a, i), (a, i + 1), . . . , (a, j)} \u2286B, where either i = 1 or (a, i \u22121) \u0338\u2208B and j = T or (a, j + 1) \u0338\u2208B. Let b = |B| denote the total length of all such intervals, which is b = mT \u2212n. For any such interval I \u2208I, there is a probability of |I|/(2mT) that (e, r) \u2208I, because there is a 1/2 probability that r \u2264T and, conditional on this, (e, r) is uniform from [m] \u00d7 [T]. Moreover, conditional on (e, r) \u2208I, the expected number of mistakes is (1 + |I|)/2 because this is the expected length of the part of the interval that is at or after r. Hence, the expected number of mistakes is,\nThe number of intervals is at most N = m + n because: (a) with no inspections, there are m intervals, (b) each additional inspection can create at most 1 interval by splitting an interval into two, and (c) there are n edge-period inspections. By the convexity of the function f(x) = x2 and (3), the lower-bound on expected number of mistakes from above is at least,\nusing b = mT \u2212n and simple arithmetic. This gives the lower bound on,\nE(e,r)[m + number of inspections] \u00b7 E(e,r)[1 + total mistakes] \u2265(m + n/2) mT 4(m + n) \u2265mT 8 ,\nistic A. To complete the proof, we need to show that the above holds, in ized A as well. For a given randomized algorithm Az with random bits z,\nas required for deterministic A. To complete the proof, we need to show that the above holds, in expectation, for randomized A as well. For a given randomized algorithm Az with random bits z, we can consider two quantities,\nVz = E(e,r)[m + number of inspections of Az] and Wz = E(e,r)[1 + total mistakes of Az].\nNow, we know that for all specific z, Az is a deterministic algorithm and hence VzWz \u2265mT/8 for all z. Finally note that the set S = {(V, W) \u2208R2 + | V W \u2265mT/8} is a convex set and since (Vz, Wz) \u2208S for all z, (Ez[Vz], Ez[Wz]) \u2208S by convexity.\n(3)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f8f1/f8f12510-eeea-4541-9663-1c9df2eef992.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9f1c/9f1c72af-dbda-439c-93e7-763a7671701c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Average size of the pruned set \u00afSi in Algorithm 1.</div>\n# C Additional information about experiments\nFigure 4 illustrates the average size of the pruned set \u00afSi in Algorithm 1, which we ran a total of 5000 times, with T = 30 rounds each run. Figure 4a corresponds to shortest-path routing and Figure 4b corresponds to linear programming, with the same setup as described in Section 5.\n# C.1 Shortest-path routing\nIn Figure 5, we present several additional experiments using varying perturbation methods. Figures 5a and 5b have the same experimental setup as in the main body except we employ a Gaussian distribution with smaller variance. We run our algorithm for thirty rounds (i.e., T = 30) with pi = 1/ \u221a i for all i \u2208[T]. On each round, we randomly perturb each edge\u2019s weight via the following procedure. Let G = (V, E) be the original graph we access via Python\u2019s OSMnx package. Let x \u2208R|E| be a vector representing all edges\u2019 weights. On the ith round, we select a vector ri \u2208R|E| such that each component is drawn i.i.d. from the normal distribution with a mean of 0 and a standard deviation of 1/2. We then define a new edge-weight vector xi such that xi[j] = 1{x[j]+ri[j]>0} (x[j] + ri[j]) . Our algorithm returned the incorrect path on a 0.034 fraction of the 5000 \u00b7 T = 150, 000 rounds. In the remaining panels of Figure 5, we employ the uniform distribution rather than the Gaussian distribution. In Figures 5c and 5d, we run our algorithm for thirty rounds (i.e., T = 30) with pi = 1/ \u221a i for all i \u2208[T]. On each round, we randomly perturb each edge\u2019s weight via the following procedure. Let G = (V, E) be the original graph we access via Python\u2019s OSMnx package. Let x \u2208R|E| be a vector representing all edges\u2019 weights. Let wi = min{x[i], 1/2}. On the ith round, we select a vector ri \u2208R|E| such that each component is drawn from the uniform distribution over [\u2212wi, wi]. We then define a new edge-weight vector xi such that xi[j] = x[j] + ri[j]. Our algorithm returned the incorrect path on a 0.003 fraction of the 5000 \u00b7 T = 150, 000 rounds. In Figures 5e and 5f, we use the same procedure except wi = min{x[i], 1}. In that setting, our algorithm returned the incorrect path on a 0.001 fraction of the 5000 \u00b7 T = 150, 000 rounds.\n<div style=\"text-align: center;\">(b) Average pruned set size for linear programming.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6e3b/6e3bcd19-8deb-467d-9d85-f1ef63cb43be.png\" style=\"width: 50%;\"></div>\n(a) Gaussian perturbation with a standard deviation of 1/2. Top line: average number of nodes Dijkstra\u2019s algorithm explores. Bottom line: average number of nodes Algorithm 1 explores.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ef8b/ef8b36ad-351f-4955-bf03-724e8392334b.png\" style=\"width: 50%;\"></div>\n(c) Uniform perturbation with support [\u22121/2, 1/2]. Top line: average number of nodes Dijkstra\u2019s algorithm explores. Bottom line: average number of nodes Algorithm 1 explores.\n<div style=\"text-align: center;\">(c) Uniform perturbation with support [\u22121/2, 1/2]. Top line: average number of nodes Dijkstra\u2019s algorithm explores. Bottom line: average number of nodes Algorithm 1 explores.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2a3e/2a3e48cf-cc2c-43b7-95e7-14c7f20b0f09.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(e) Uniform perturbation with support [\u22121, 1]. Top line: average number of nodes Dijkstra\u2019s algorithm explores. Bottom line: average number of nodes Algorithm 1 explores.</div>\n5: Shortest path routing experiments using varying perturba\nt path routing experiments using varying perturbation metho\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7b32/7b327e2f-05d5-4bdd-8081-66b17f223129.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) Gaussian perturbation with a standard deviation of 1/2. Average pruned set size for shortest path routing.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/22c6/22c63bde-e80c-49d6-b387-9818c7839483.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(d) Uniform perturbation with support [\u22121/2, 1/2]. Average pruned set size for shortest path routing.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d9c0/d9c04490-1216-4adc-a3e8-cd4f8064db6a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(f) Uniform perturbation with support [\u22121/2, 1/2]. Average pruned set size for shortest path routing.</div>\n# C.2 Linear programming\nWe use the CATS generator to create an initial instance with an objective function defined by a vector x and constraints defined by a matrix A and a vector b. On the ith round, we select a new objective vector xi such that each component xi[j] is drawn independently from the normal distribution with a mean of x[j] and a standard deviation of 1. We run our algorithm for twenty rounds (i.e., T = 30) with pi = 1 \u221a i for all i \u2208[T].\nWinner determination. Suppose there is a set {1, . . . , m} of items for sale and a set {1, . . . , n} of buyers. In a combinatorial auction, each buyer i submits bids vi(b) for any number of bundles b \u2286{1, . . . , m}. The goal of the winner determination problem is to allocate the goods among the bidders so as to maximize social welfare, which is the sum of the buyers\u2019 values for the bundles they are allocated. We can model this problem as a integer program by assigning a binary variable xi,b for every buyer i and every bundle b they submit a bid vi(b) on. The variable xi,b is equal to 1 if and only if buyer i receives the bundle b. Let Bi be the set of all bundles b that buyer i submits a bid on. An allocation is feasible if it allocates no item more than once (\ufffdn i=1 \ufffd b\u2208Bi,j\u220bb xi,b \u22641 for all j \u2208{1, . . . , m}) and if each bidder receives at most one bundle (\ufffd b\u2208Bi xi,b \u22641 for all i \u2208{1, . . . , n}). Therefore, the integer program is:\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/752b/752b9c01-bfc4-4863-9cd0-5f788830686b.png\" style=\"width: 50%;\"></div>\nTo transform this integer program into a linear program, we simply require that xi,b \u2208[0, 1] fo all i \u2208[n] and all b \u2208Bi.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of optimizing repeated computations in scenarios where similar computational problems arise, highlighting the inefficiencies of standard algorithms that do not exploit shared structures across these problems. Previous methods have struggled to effectively utilize this commonality, necessitating a new approach to improve efficiency.",
        "problem": {
            "definition": "The problem is defined as the need to compute solutions for a sequence of similar instances where the underlying structure remains constant, but specific parameters vary, such as edge weights in shortest path problems.",
            "key obstacle": "The main difficulty lies in the fact that existing algorithms often explore unnecessary portions of the search space, leading to wasted computational resources and time."
        },
        "idea": {
            "intuition": "The intuition behind the proposed method is that many instances of repeated problems share a common substructure, allowing for significant portions of the search space to be pruned, thereby reducing the computational burden.",
            "opinion": "The proposed idea is to develop an algorithm that learns to prune the search space effectively over repeated computations, ensuring that only relevant portions are explored while maintaining correctness.",
            "innovation": "The key innovation of this method is its ability to learn from previous computations to optimize future searches, contrasting with traditional approaches that do not adapt based on past instances."
        },
        "method": {
            "method name": "Learning to Prune",
            "method abbreviation": "LP",
            "method definition": "The method leverages a learning-based approach to prune the search space for repeated computations, using a combination of exploration and exploitation techniques.",
            "method description": "The core of the method involves learning a pruned subset of the solution space that contains previously returned solutions, optimizing the search process for similar future instances.",
            "method steps": [
                "Initialize the pruned set as empty.",
                "For each round, receive a new input instance.",
                "With a certain probability, compute the full solution and update the pruned set with the minimal necessary subset.",
                "Otherwise, output the solution based on the current pruned set."
            ],
            "principle": "The effectiveness of this method stems from its ability to significantly reduce the search space by focusing on previously relevant solutions, thus minimizing runtime while ensuring high probability of correctness."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted using real-world datasets for shortest-path routing and linear programming, comparing the proposed method against standard algorithms like Dijkstra's.",
            "evaluation method": "Performance was assessed by measuring the number of nodes explored and the correctness of the solutions returned across multiple runs."
        },
        "conclusion": "The proposed algorithm demonstrates significant improvements in runtime efficiency for repeated computations while maintaining high accuracy, showing that learning-based pruning can effectively optimize search processes.",
        "discussion": {
            "advantage": "The primary advantage of the proposed approach is its ability to adaptively learn from previous computations, leading to substantial reductions in search space and computational time.",
            "limitation": "One limitation is that the method may not perform as well in scenarios where the problem instances vary drastically, as the learning may not generalize effectively.",
            "future work": "Future research could explore enhancing the learning mechanisms to better handle diverse problem instances and investigate extensions to problems with multiple solutions."
        },
        "other info": {
            "acknowledgments": "This work was supported by various grants and projects, including the Israel Science Foundation and the DARPA Brandeis Project.",
            "related work": "The paper builds upon recent advancements in algorithm configuration and online learning, distinguishing itself by focusing on non-distributional settings and repeated computations."
        }
    },
    "mount_outline": [
        {
            "section number": "5.3",
            "key information": "The proposed algorithm demonstrates significant improvements in runtime efficiency for repeated computations while maintaining high accuracy, showing that learning-based pruning can effectively optimize search processes."
        },
        {
            "section number": "4.1",
            "key information": "The proposed idea is to develop an algorithm that learns to prune the search space effectively over repeated computations, ensuring that only relevant portions are explored while maintaining correctness."
        },
        {
            "section number": "2.3",
            "key information": "The paper addresses the issue of optimizing repeated computations in scenarios where similar computational problems arise, highlighting the inefficiencies of standard algorithms that do not exploit shared structures across these problems."
        },
        {
            "section number": "6.2",
            "key information": "The primary advantage of the proposed approach is its ability to adaptively learn from previous computations, leading to substantial reductions in search space and computational time."
        },
        {
            "section number": "3.3",
            "key information": "The method leverages a learning-based approach to prune the search space for repeated computations, using a combination of exploration and exploitation techniques."
        }
    ],
    "similarity_score": 0.5324737811235069,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-1142_cogni/papers/Learning to Prune_ Speeding up Repeated Computations.json"
}