{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2305.09679",
    "title": "Adversarial Security and Differential Privacy in mmWave Beam Prediction in 6G networks",
    "abstract": "In the forthcoming era of 6G, the mmWave communication is envisioned to be used in dense user scenarios with high bandwidth requirements, that necessitate efficient and accurate beam prediction. Machine learning (ML) based approaches are ushering as a critical solution for achieving such efficient beam prediction for 6G mmWave communications. However, most contemporary ML classifiers are quite susceptible to adversarial inputs. Attackers can easily perturb the methodology through noise addition in the model itself. To mitigate this, the current work presents a defensive mechanism for attenuating the adversarial attacks against projected ML-based models for mmWave beam anticipation by incorporating adversarial training. Furthermore, as training 6G mmWave beam prediction model necessitates the use of large and comprehensive datasets that could include sensitive information regarding the user's location, differential privacy (DP) has been introduced as a technique to preserve the confidentiality of the information by purposefully adding a low sensitivity controlled noise in the datasets. It ensures that even if the information about a user location could be retrieved, the attacker would have no means to determine whether the information is significant or meaningless. With ray-tracing simulations for various outdoor and indoor scenarios, we illustrate the advantage of our proposed novel framework in terms of beam prediction accuracy and effective achievable rate while ensuring the security and privacy in communications.",
    "bib_name": "krishna2023adversarialsecuritydifferentialprivacy",
    "md_text": "# Adversarial Security and Differential Privacy in mmWave Beam Prediction in 6G networks\nGhanta Sai Krishna\u2217, Kundrapu Supriya \u2217, Sanskar Singh\u2217, Sabur Baidya\u2020 \u2217Department of Computer Science, IIIT Naya Raipur, India \u2020Department of Computer Science and Engineering, University of Louisville, KY, USA 20102@iiitnr.edu.in, kundrapu20100@iiitnr.edu.in, sanskar21102@iiitnr.edu.in, sabur.baidya@louis\nAbstract\u2014In the forthcoming era of 6G, the mmWave communication is envisioned to be used in dense user scenarios with high bandwidth requirements, that necessitate efficient and accurate beam prediction. Machine learning (ML) based approaches are ushering as a critical solution for achieving such efficient beam prediction for 6G mmWave communications. However, most contemporary ML classifiers are quite susceptible to adversarial inputs. Attackers can easily perturb the methodology through noise addition in the model itself. To mitigate this, the current work presents a defensive mechanism for attenuating the adversarial attacks against projected MLbased models for mmWave beam anticipation by incorporating adversarial training. Furthermore, as training 6G mmWave beam prediction model necessitates the use of large and comprehensive datasets that could include sensitive information regarding the user\u2019s location, differential privacy (DP) has been introduced as a technique to preserve the confidentiality of the information by purposefully adding a low sensitivity controlled noise in the datasets. It ensures that even if the information about a user location could be retrieved, the attacker would have no means to determine whether the information is significant or meaningless. With ray-tracing simulations for various outdoor and indoor scenarios, we illustrate the advantage of our proposed novel framework in terms of beam prediction accuracy and effective achievable rate while ensuring the security and privacy in communications. Index Terms\u2014mmWave, massive MIMO, Beamforming, Adversarial ML, Differential Privacy\n# I. INTRODUCTION\nI. INTRODUCTION\nThe advancement in the modern emerging applications with the need of ultra high bandwidth and low latency has propelled the rapid progress in the cellular wireless communication technologies in contemporary years. Millimeter-wave (mmWave) came up as one of the major technologies in the 5G cellular communications supporting this high quality-of-service (QoS) demands, using massive Multiple-Input Multiple-Output (massive-MIMO) employing dense smaller antenna clusters. Now, as the cellular technologies are progressing towards 6G, incorporating artificial intelligence (AI) [1] supporting predictive communications and resource allocations become apparent including in mmWave beamforming. The classic beam search is more complicated since each antenna element must be controlled. To reduce the complexity of beam search, a beam codebook can be used with predictive information. One of the main challenges in the mmWave beamforming communications is improving bandwidth efficiency while taking into consideration the issue of reducing cost and signal loss [2] and\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/291a/291aa342-5ac3-41fb-8526-7fdb95f82d68.png\" style=\"width: 50%;\"></div>\nfinding the optimal mmWave beam [3]. Several studies have been conducted recently in the area of mmWave beamforming communications, depending on the need and limitations. Beamforming prediction using deep learning (DL) is susceptible to attacks using adversarial machine learning [4]. The architecture of 5G networks is fraught with difficulties [5], one of which is a security system for beamforming prediction. Furthermore, different beamforming models in next generation (i.e. 6G) are difficult to design and implement. In order to increase the overall system efficiency in 6G solutions, as AIbased methods, particularly deep learning (DL) techniques [6] are used, security concerns arise due to adversarial attack. The current studies in this domain focus primarily on developing AI models, but security issues have still been a major challenge. Privacy of the user\u2019s location is another major concern while the transmission of the beams. Differential Privacy [7] can be employed during training of the ML model so that anonymity of the user can be maintained. Herein, we create a novel ML-based framework (fig. 1) to jointly train for adversarial security and differential privacy for mmWave beam prediction and demonstrate the performance of our framework in various communication scenarios. The main contributions of this work are summarized below. \u2022 To the best of our knowledge this is the first work on adversarial security and differential privacy together on the mmWave beam prediction. \u2022 We identify the tradeoff between the degree of adversarial security and differential privacy by introducing controlled noise in joint training with a novel ML-based framework. \u2022 We evaluate our framework extensively in various indoor and outdoor senarios through ray-tracing simulations.\n# II. RELATED WORKS\nA wide range of attacks have been implemented in recent years to study adversarial ML in telecommunications which includes beamforming [8], beam selection [9] and channel estimation [10]. In the past, adversarial attacks have been performed and analyzed using a variety of image datasets, but more recently, the Deep-MIMO dataset [11], which was primarily created for mmWave and large MIMO systems, has been utilized to generate adversarial attacks. The majority of the research in the pertinent literature has focused on mmWave communication, developing various beamforming techniques and performance while ignoring issues with security and privacy. Yang et al. [12] presented a sophisticated 6G network design with AI assistance that can handle a number of services including discovery, automatic network adjustment, smart service provisioning, etc. Additionally, it covers AI-based techniques for effectively enhancing network efficiency in 6G networks, such as mobility, and spectrum management. Catak et al. [13] presented an adversarial training-based mitigation technique for adversarial attacks against 6G ML models for mmWave beam prediction. The transmitted signal has been adjusted with a modified Fast Gradient Signed Method (FGSM) attack. The findings of adversarial training on two distinct models \u2014 defended and undefended, show that the defended model under attack has nearly identical mean square errors (MSE) to the undefended model not under attack. There hasn\u2019t been any research on differential privacy in this area up to this point, but it has been extensively studied in the wireless communications industry. The authors in [14], proposed a fresh split learning (SL) approach that doesn\u2019t upload the raw data throughout inference and learning and solves the beam selection problem. To improve generalisation reliability and efficiency to quasi identically distributed data, it leverages the based feature mix approach. The evaluation\u2019s findings shown that, the suggested MPSL outperforms the conventional SL and federated learning approach in terms of test performance. In contrast to the above studies, our work considers stronger whitebox attack techniques than FGSM such as MI-FGSM, PGD and Iterative PGD attacks while showcasing the impacts of attacks in the 6G based beamforming. To this, defensive mechanisms are also introduced in order to mitigate the influence of adversarial perturbations on classifier performance. The previously proposed solutions also tend to rely heavily on the prior knowledge of user\u2019s location, which allows attackers to deduce sensitive information from the dataset. Herein, Differential Privacy (DP) is applied to mathematically induce a noise in the anticipated beam so that resulting beam is still accurate enough to generate aggregate insights of user\u2019s location while also maintaining the privacy of individual users.\n# III. SYSTEM MODEL\nThis section presents a deep learning-based coordinated beamforming mmWave system and describes the system model\u2019s functionalities, including downlink transmission, ef-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c39e/c39ea656-45c5-4984-b1fe-75166ac6b448.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 2. Layout of the mmWave beamforming network</div>\nfective achievable rate, and deep learning model. The key necessities of utilising the DL model are also highlighted.\n# A. Downlink Transmission\nContemplate the mmWave communication system depicted in fig. 2, where X represents the count of base stations (BSs) with A antennas feeding user equipment(UE) or a mobile station with one antenna. These BSs are all linked to a cloud processing unit. A signal sg = [sg1, sg2, ..., sgK] is transmitting with K additional secondary modulated signals (sub-carriers). In order to sustain transmission in multi-antenna wireless communications, a code vector vk = [vk,1, vk,2, ..., vk,X]T is utilised to precode the transmitted signal with a digital precoder at the cloud processing unit. Furthermore, the Kpoint Inverse Fast Fourier Transform (IFFT) technique is employed to transform the retrieved transmitted signal into the time domain. The time-domain analogue beamforming fx (i.e., Beam steering vector) is applied by every BS and then transmits the resulting signal. Accordingly, the baseband signal at the k-th subcarrier from the x-th BS may be depicted as:\n(1)\nThe downlink retreived signal at the kth subcarrier is denoted by: X \ufffd\n(2)\nwhere jk denote the additive white Gaussian noise having variance as \u03c32 for kth subcarrier. The channel vector between xth BS and the user is depicted through hk,x.\nB. Deep Learning to estimate RF beamforming vectors\n# B. Deep Learning to estimate RF beamforming vecto\nDeep learning (DL) has lately been employed in physical layer communications applications [15] such as signal identification, channel estimation and precoding design and CSI feedback. Utilizing the potential advantages of DL techniques in wireless communications results in a sophisticated strategy for training of massive MIMO channels and scanning of a huge proportion of narrow beams. The DL model anticipates the BSs beamforming vectors straight from the retrieved signal at the scattered BSs with the utilization of omni or quasi-omni beam patterns. These are utilized to examine the diffraction and reflection of the pilot signal.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2ae3/2ae34ce9-da7a-48ec-a294-4ff16c13af1e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 3. Redeemed omni beams to the DL based codeword prediction model</div>\n1) Model Architecture: The proposed architecture consists of beamforming prediction models to be located within the BSs in our system model. The cloud is simply in charge of precoding and transmitting the sent signals to the BSs in order to devise a less complex solution. For each beam coherence time TBC,sequences of recurrent uplink training pilot of the form \ufffd spilot k \ufffdK k=1 is transmitted by the user. Beam coherence time is referred to as the average period that the beam remains aligned. The retrieved pilot sequences are combined on a radio frequency beamforming vector and sent to the cloud via BSs. Pilot signals are used to characterize the prediction channel. The cloud feeds the omni-retrieved signals Comni k,x , \u2200x from all of the BSs into the DL algorithm and instructs the pretrained neural network to determine the optimal beamforming vector which further tries to boost the potential rate as in \ufffd \ufffd\n(3)\n\ufffd \ufffd\ufffd \ufffd\ufffd where, hk,x represents the channel coefficient matrix for xth BS at the kth subcarrier and op illustrate the channel coefficient for omni-beams. The DL model is trained in realtime to comprehend the inherent relationship among the rates of the various RF beamforming vectors and the Orthogonal Frequency-Division Multiplexing(OFDM) omni-retrieved signals collected simultaneously at each BS, that further serve as a distinctive confirmation of the user\u2019s location. Eventually, the BS terminals utilize the anticipated RF beamforming vectors f DL x to aggregate the uplink pilot sequences and predict the potent channel hT k,xf DL x , \u2200n, that are then employed to generate the beamforming vectors from the cloud baseband. 2) DNN Training: The Deep Neural Network employed in the present work comprises of 7 fully-connected feed forward layer with ReLU as the activation function. It is worth noting that the output of each dense layer is normalized batch-wise before being sent to the subsequent layer. A layer is introduced with drop-out to guarantee regularisation and prevent the chance of over-fitting in the neural network. The DNN architecture implemented in the current study is shown in the fig. 3.\n# C. Effective Achievable Rate\nIdeal channel estimation knowledge fulfills the best attainable rate; yet, because due to the huge amount of antennas, channel state information necessitates a significant training overhead. Also, as the user traverses, the RF beamforming\nvector and channel information must be revised. The channel beam coherence time, TB and channel coherence time TC could be utilized to address these concerns. Furthermore, the beams remain aligned during the length of beam coherence TB and TB is often larger than TC. For users with greater mobility, the time period TB reduces, resulting in a reduced data throughput for the same beam training overhead and beamforming codebook vectors. The first Tt is required for beamforming drafting and training the channel, while the remainder is dedicated to data transmission. Hence, the effective achievable rate can be elucidated as follows.\n(4)\n\uf8ed \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \uf8f8 The effective achievable rate (EAR) must be maximized to construct a model having coherent channel training and beamforming architecture. Therefore, the final problem formulation can be defined as : \ufffd \ufffd\n(5) (6) (7)\nHere C represents the quantized codebook for the BSs RF beamforming vectors and FR is the RF precoding matrix, FRF = blkdiag (v1, v2, . . . , vX) \u2208VXA\u00d7X. Working through these equations culminates in an answer for a minimal channel training overhead and the generation of the beamforming vectors to yield the highest attainable rate.\n# IV. RESEARCH METHODOLOGY\n# A. Adversarial Attack Models\nAdversarial ML is an attack strategy to deceive neural network(NN) models by providing input that has been cleverly altered with a slight change to generate a breakdown inside the models. The attacker subtly modifies the query to obtain the desired result from a production-deployed model instead of changing the training instances. This is a violation of model input integrity, which results in fuzzing-style attacks, compromising the model\u2019s classification performance. Recently, numerous white-box adversarial attacks have been proposed to alter models\u2019 prediction by introducing minute carefully designed perturbations. Some of the state-of-the-art (SOTA) attack practice (i.e. FGSM [16], Momentum Iterative FGSM, PGD [17] and Iterative PGD) will be utilized to evaluate the performance of defense models in this paper, which will be briefly introduced as follows. 1) Fast Gradient Sign Method (FGSM) attack: It is a typical one-step attack algorithm designed to target neural networks by utilizing the training gradients. Here, instead of reducing the loss by altering the weights based on the backpropagated gradients, it adjusts the input data y to maximize the adversarial loss L(\u03b8, y, z) based on the same backpropagated gradients for some model parameter \u03b8. The FGSM-attack can be formulated as follows: y = y + \u03f5 \u00b7 sign (\u2207L (\u03b8, y, z)) , (8)\nwhere z is the ground truth label for y, yt+1 is the new adversarial instance that maximizes the classifier hypothesis loss and \u03f5 denotes the magnitude of the perturbation applied. 2) Momentum Iterative FGSM attack: Iterative FGSM [18] is an improvised version of FGSM which apply gradient updates iteratively. MI-FGSM is more transferable than IFGSM since it accumulates the gradients of each iteration to stabilize the update direction and avoid superfluous local maxima. \u2207L (\u03b8, y, z)\n(9)\nHere, Gt\u22121 is the cummulative gradient up to the (t \u22121)-th iteration with G0 = 0 and a decay factor of \u00b5 . Also, \u03b1 = \u03f5/T represents a small step size, and T is the number of iterations. 3) Projected Gradient Descent attack: PGD could well be regarded of as an enhanced variant of I-FGSM being devoid of constraint \u03b1. The PGD projects the adversarial samples learned from each iteration onto the benign samples\u2019 neighbour in order to restrict the adversarial perturbations. As a result, the adversarial perturbation size is less than \u03f5.\n(10)\nwhere Proj gives the projection of the revised adversarial sample onto the neighbour and an acceptable range. Iterative PGD (IPGD) is an extended version of PGD that seeks to apply PGD repeatedly during the network\u2019s training phase.\n# B. Adversarial Training\nAdversarial training (AT) is an inherent defensive approach against adversarial samples to increase the resilience of a neural network by training it with adversarial examples, or on mix of clean and adversarial samples. AT strategy is shown to be coherent while defending the models from adversarial attacks [17]. It can be well generalised as a min-max optimization problem which can be elucidated as: \ufffd \ufffd\n(11)\nwhere D() represents distance metric between initial input yt and it\u2019s adversarial variant yt+1 while h\u03b8() depicts the neural network based classifier model. Thus, once the model is trained under several attacks, adversarial samples are generated by the model, that are merged with information from genuine \u2019good\u2019 users and fed again to the training cycle. The training procedure is finished when the model achieves the stable state.\n# C. Differential Privacy\nDP is a mathematical strategic tool for purposely introducing noise into a dataset, ensuring plausible deniability to any individual whose data may be exploited to harm them while yet being able to compute desired statistics with high accuracy. Consider any two beamforming databases as d and d\u2032 taken from DeepMIMOv2, that differ precisely in one record of user location. If Kf is a function used to answer to location query\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/64fe/64feaeee-5426-4d86-8bd0-76ae121eda3b.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 4. Top-View of all the Scenarios [11]</div>\nf, then Kf provides \u03f5\u2217-differential privacy if with probability 1, for any r \u2286Range (Kf) the following occurs:\n(13)\n\ufffd \ufffd \ufffd \ufffd Here, \u03f5\u2217is the privacy budget which specifies an upperbound on privacy loss of user\u2019s location information. This work employs DP-SGD which achieves privacy by clipping the gradients and then adding the noise proportionally.\nWe evaluate our proposed framework using the DeepMIMOv2 dataset which is explicitly determined by the ray tracing scenarios and the parameters set. A ray-tracing scenario \u2018R\u2019 incorporates a range of access points/BSs and clients that are spatially distributed inside an indoor or outdoor surroundings. BSs and clients in the ray-tracing scenario often contain omni or quasi-omni transmitters. The ray-tracing simulation produces performance indicators for each stream between every sender and receiver antennas. An enormous amount of base stations and clients have been included in the ray-tracing scenarios so that we can increase the size of the dataset for machine learning applications. To generate the dataset, we must provide two inputs to the data generation code: raytracing scenarios and the parameter set as mentioned already. 1) Ray-Tracing Scenarios: We extract the ray-tracing outcomes for the DeepMIMOv2 data using Wireless InSite by Remcom\u2019s precise ray-tracing simulator. Ray-tracing simulations produce channel parameters which accurately reflect the placements of transmitter, components, geometry of the environment, etc. 2) Dataset Parameters: Various communication parameters, e.g., number of active base stations, active users, antenna spacing, bandwidth, etc are variable in ray-tracing scenarios. The Table I represents the parameters that have been used for generating dataset from different ray-tracing scenarios.\n# B. Experiments on Different Cases\nThe proposed model has been evaluated on the basis of 2 separate cases for all the 6 individual scenarios shown in fig. 4. The varied cases can be illustrated as: \u2022 Non-Private Model under attacks (C1) : This case reflects various attack methodologies applied on the undefended\n<div style=\"text-align: center;\">TABLE I PARAMETERS USED IN DIFFERENT SCENARIOS IN DEPPMIMOV2 DA</div>\nP DMV2\nParameters\nDescription\nO1 Scenario\nO1 Blockage Scenario\nO2 Scenario\nI1 Scenario\nI2 Scenario\nI3 Scenario\nActive BS\nBase stations to be activated\n1,2\n1,2\n1,2\n1\n1\n1,2\nActive Users\nActivating a group of users\n100 -300\n100-700\n700 - 800\n200 - 400\n100 - 500\n600 - 1000\nNumber of BS Antennas\nNumber of antennas\n1,32,8\n1,32,8\n1,32,8\n1,32,8\n1,32,8\n1,32,8\nAntenna Spacing\nDistance between the base sta-\ntion transimitter gird elements\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nBandwidth\nBandwidth in Gigahertz\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nNumber of Paths\n5 paths w/ highest recv. power\n5\n5\n5\n5\n5\n5\nParameters\nDescription\nO1 Scenario\nO1 Blockage Scenario\nO2 Scenario\nI1 Scenario\nI2 Scenario\nI3 Scenario\nActive BS\nBase stations to be activated\n1,2\n1,2\n1,2\n1\n1\n1,2\nActive Users\nActivating a group of users\n100 -300\n100-700\n700 - 800\n200 - 400\n100 - 500\n600 - 1000\nNumber of BS Antennas\nNumber of antennas\n1,32,8\n1,32,8\n1,32,8\n1,32,8\n1,32,8\n1,32,8\nAntenna Spacing\nDistance between the base sta-\ntion transimitter gird elements\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nBandwidth\nBandwidth in Gigahertz\n0.5\n0.5\n0.5\n0.5\n0.5\n0.5\nNumber of Paths\n5 paths w/ highest recv. power\n5\n5\n5\n5\n5\n5\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/570e/570e6958-e05a-4c2e-b550-abab4c5f2553.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 5. Effective Achievable Rate of RF beamforming DL model in all the Scenarios</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/23b5/23b56daf-207e-48ff-acab-2766de4d96a2.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 6. MSE in RF beamforming DL model in all the Scenarios</div>\nnon-private beamforming codebook prediction model. Then the undefended model is trained adversarially to explore the variances obtained in training phase. \u2022 Private Model under attacks (C2): This case examines the same attack techniques employed over an defended DP model. Similar to C1, it also draws the impact of the attacks after the undefended DP model has been defended using adversarial training. Hence, two models (i.e. non-private and private) were developed corresponding to the above mentioned respective case instances. The optimum set of tuned hyper-parameters are employed in both the model\u2019s architecture are displayed in Table II.\n<div style=\"text-align: center;\">TABLE II TUNED HYPER-PARAMETERS FOR THE BEAM PREDICTION MODEL</div>\nHyper-parameter\nWithout Privacy\nWith Privacy\nNumber of beams\n512\n512\nEpochs\n10\n15\nBatch Size\n100\n100\nDropout Rate\n0.05\n0.05\nLearning Rate\n0.25\n0.0005\nHidden Layers\n4\n4\nOptimizer\nRMSprop\nDP-SGD\nApproximately thirty-five thousand non-perturbed instances are utilized for training both models. The experimental analysis of adversarial attacks and differential privacy has been performed regarding Effective Achievable Rate (EAR) and Mean Squared Error (MSE). The EAR has been recorded for private and non-private models under 6 FGSM attacks with\nvariable parameters in various scenarios and variable training dataset size, as illustrated in Fig. 5. In the unsecure C1, four FGSM attacks were successful, whereas, in secure C2, only two were successful in the I1 scenario. Similar results have been observed in the other scenarios, which depict that the private model has more capability to resist adversarial attacks. Fig. 6 illustrates the obtained MSE scores under \u03f5 budget in indoor and outdoor scenarios with FGSM attack instances for both cases (C1 and C2). The plot shows that after a specific \u03f5 value, the adversarially trained RF beamforming model\u2019s MSE values become quasi-static. On the contrary, the MSE values of the undefended models remain elevated over the MSE values of adversarially trained models irrespective of the scenario. In differentially private models, unsecure and adversarially trained performance is distinguishable compared to non-private models.\n# C. Tradeoff of \u03f5 between AT and DP\nThe present section discusses about the differences between both variant of noises described in this study. Introduction of noise (\u03f5) by the attacker implies a carefully computed petrurbations whose main task is to mislead the network. In this case, as the \u03f5 value gets larger, it becomes relatively easy to deceive the network. Nevertheless, as a result of this trade-off, the perturbations become more apparent. \u03f5\u2217notion has been mentioned in the context of DP where \u03f5\u2217is a metric of privacy loss after a differential change is applied\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4631/4631809d-d1b8-4788-b969-84f9b99e080c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 7. Tradeoff of \u03f5 for C1 and C2 model</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/26d6/26d6add0-33da-4ba5-8421-18767654a8f9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 8. Performance of Adversarially Trained Private and Non-Private Models</div>\nin beamforming dataset. A smaller \u03f5\u2217will yield better privacy but less accurate response. The tradeoff relationship between the epsilon values for AT and DP have been showcased using C1 and C2 models MSE scores under \u03f5 budget in the fig. 7. The model\u2019s performance will increase with an increase in the privacy budget, and will decrease with an increase in epsilon in indoor and outdoor scenarios. Fig. 8 represents the performance of Adversarially Trained Private and Non-Private Models on six-ray tracing scenarios. The differential privacy played a positive role in decreasing the impacts of adversarial attacks, the increase in performance with the differentially private model is approximately eight times the non-private model. This can be calculated by estimating the distance between the private and non-private data points in the scatterplot of Fig. 8.\n# VI. CONCLUSION\nThe privacy and security of 6G mmWave beamforming are crucial due to its significant role in both present and future applications. Leveraging such architecture with DL subjects it to the danger of adversarial samples and user\u2019s location knowledge retrieval by attackers, which have not received proper attention in the pertinent literature. The present work uses DeepMIMOv2 dataset as a benchmarking tool in the domain of mmWave communication. Several indoor as well as outdoor scenarios of the ray-tracing simulations have been employed for the experiments. The study has been conducted by considering 2 separate cases to demonstrate the impact of DP in enhancing the confidentiality of user\u2019s location information. The procured results demonstrate that the initial model in both the cases are susceptible to various attack instances such as FGSM, MI-FGSM, PGD and Iterative PGD.\nTo this, the beamforming DL model is iteratively supplemented by the adversarial samples. This mitigation strategy ensues that repetitive adversarial training proficiently improves the RF beamforming codebook anticipation performance and generates a much efficient predictive model.\nACKNOWLEDGMENT\nThis work is partially supported by the US National Science Foundation (EPSCoR #1849213).\n# REFERENCES\n",
    "paper_type": "method",
    "attri": {
        "background": "The paper discusses the challenges in mmWave communication for 6G networks, particularly the need for efficient beam prediction methods that are resilient to adversarial attacks while ensuring user privacy through differential privacy techniques.",
        "problem": {
            "definition": "The problem addressed is the susceptibility of machine learning classifiers used in mmWave beam prediction to adversarial attacks, which can compromise the accuracy and reliability of the predictions.",
            "key obstacle": "The core obstacle is the difficulty in developing robust models that can withstand adversarial inputs while also protecting sensitive user location data during the training process."
        },
        "idea": {
            "intuition": "The idea is inspired by the need to enhance the security and privacy of mmWave beam prediction models in the face of adversarial machine learning threats.",
            "opinion": "The proposed solution involves a novel machine learning framework that integrates adversarial training and differential privacy to improve the robustness of beam prediction models.",
            "innovation": "The primary innovation lies in the joint application of adversarial security and differential privacy in mmWave beam prediction, addressing both security and privacy concerns simultaneously."
        },
        "method": {
            "method name": "Adversarially Trained Differentially Private Beam Prediction",
            "method abbreviation": "AT-DP-BP",
            "method definition": "This method combines adversarial training and differential privacy to enhance the accuracy and security of mmWave beam prediction models against adversarial attacks.",
            "method description": "The method involves training a deep learning model on a dataset augmented with adversarial examples while ensuring user privacy through the addition of controlled noise.",
            "method steps": [
                "Collect and preprocess the mmWave beam prediction dataset.",
                "Introduce adversarial samples into the training data using various adversarial attack techniques.",
                "Apply differential privacy by adding noise to the dataset to protect user location information.",
                "Train the machine learning model using the augmented dataset.",
                "Evaluate the model's performance against adversarial attacks."
            ],
            "principle": "The effectiveness of this method is based on the principle that adversarial training enhances model resilience by exposing it to potential attacks during training, while differential privacy ensures that individual user data remains confidential."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted using the DeepMIMOv2 dataset, simulating various indoor and outdoor scenarios with multiple base stations and users to evaluate the model's performance under adversarial attacks.",
            "evaluation method": "The performance of the proposed method was assessed by measuring the Effective Achievable Rate (EAR) and Mean Squared Error (MSE) under different adversarial attack scenarios."
        },
        "conclusion": "The experiments demonstrated that the proposed framework significantly improves the resilience of mmWave beam prediction models against adversarial attacks while maintaining user privacy, showing promising results in both indoor and outdoor scenarios.",
        "discussion": {
            "advantage": "The key advantage of the proposed approach is its ability to enhance both the security and privacy of mmWave beam prediction models, making them more robust against adversarial threats.",
            "limitation": "A limitation of the method is the potential trade-off between the level of differential privacy and the model's accuracy, as higher privacy may lead to reduced performance.",
            "future work": "Future research should explore optimizing the trade-off between adversarial security and differential privacy, as well as extending the framework to other applications in wireless communications."
        },
        "other info": {
            "acknowledgment": "This work is partially supported by the US National Science Foundation (EPSCoR #1849213)."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper discusses the challenges in mmWave communication for 6G networks, particularly the need for efficient beam prediction methods that are resilient to adversarial attacks while ensuring user privacy through differential privacy techniques."
        },
        {
            "section number": "1.2",
            "key information": "The core obstacle is the difficulty in developing robust models that can withstand adversarial inputs while also protecting sensitive user location data during the training process."
        },
        {
            "section number": "3.4",
            "key information": "The proposed solution involves a novel machine learning framework that integrates adversarial training and differential privacy to improve the robustness of beam prediction models."
        },
        {
            "section number": "6.1",
            "key information": "The effectiveness of this method is based on the principle that adversarial training enhances model resilience by exposing it to potential attacks during training, while differential privacy ensures that individual user data remains confidential."
        },
        {
            "section number": "7.1",
            "key information": "A limitation of the method is the potential trade-off between the level of differential privacy and the model's accuracy, as higher privacy may lead to reduced performance."
        },
        {
            "section number": "7.2",
            "key information": "Future research should explore optimizing the trade-off between adversarial security and differential privacy, as well as extending the framework to other applications in wireless communications."
        }
    ],
    "similarity_score": 0.609556062855489,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Adversarial Security and Differential Privacy in mmWave Beam Prediction in 6G networks.json"
}