{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2310.17394",
    "title": "PSP: Pre-Training and Structure Prompt Tuning for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are powerful in learning semantics of graph data. Recently, a new paradigm \"pre-train and prompt\" has shown promising results in adapting GNNs to various tasks with less supervised data. The success of such paradigm can be attributed to the more consistent objectives of pre-training and task-oriented prompt tuning, where the pre-trained knowledge can be effectively transferred to downstream tasks. Most existing methods are based on the class prototype vector framework. However, in the few-shot scenarios, given few labeled data, class prototype vectors are difficult to be accurately constructed or learned. Meanwhile, the structure information of graph is usually exploited during pre-training for learning node representations, while neglected in the prompt tuning stage for learning more accurate prototype vectors. In addition, they generally ignore the impact of heterophilous neighborhoods on node representation and are not suitable for heterophilous graphs. To bridge these gaps, we propose a novel pre-training and structure prompt tuning framework for GNNs, namely PSP, which consistently exploits structure information in both pre-training and prompt tuning stages. In particular, PSP 1) employs a dual-view contrastive learning to align the latent semantic spaces of node attributes and graph structure, and 2) incorporates structure information in prompted graph to construct more accurate prototype vectors and elicit more pre-trained knowledge in prompt tuning. We conduct extensive experiments on node classification and graph classification tasks to evaluate the effectiveness of PSP. We show that PSP can lead to superior performance in few-shot scenarios on both homophilous and heterophilous graphs. The implemented code is available at https://github.com/gqq1210/PSP.",
    "bib_name": "ge2024psppretrainingstructureprompt",
    "md_text": "# PSP: Pre-Training and Structure Prompt Tuning for Graph Neural Networks\nQingqing Ge1, Zeyuan Zhao1, Yiding Liu2, Anfeng Cheng2, Xiang Li1 (\ufffd), Shuaiqiang Wang2, and Dawei Yin2\n1 School of Data Science and Engineering, East China Normal University, China {qingqingge, zeyuanzhao}@stu.ecnu.edu.cn xiangli@dase.ecnu.edu.cn 2 Baidu Inc., China {liuyiding.tanh, anfcheng2, shqiang.wang}@gmail.com yindaei@acm.org\nAbstract. Graph Neural Networks (GNNs) are powerful in learning semantics of graph data. Recently, a new paradigm \u201cpre-train & prompt\u201d has shown promising results in adapting GNNs to various tasks with less supervised data. The success of such paradigm can be attributed to the more consistent objectives of pre-training and task-oriented prompt tuning, where the pre-trained knowledge can be effectively transferred to downstream tasks. Most existing methods are based on the class prototype vector framework. However, in the few-shot scenarios, given few labeled data, class prototype vectors are difficult to be accurately constructed or learned. Meanwhile, the structure information of graph is usually exploited during pre-training for learning node representations, while neglected in the prompt tuning stage for learning more accurate prototype vectors. In addition, they generally ignore the impact of heterophilous neighborhoods on node representation and are not suitable for heterophilous graphs. To bridge these gaps, we propose a novel pre-training and structure prompt tuning framework for GNNs, namely PSP, which consistently exploits structure information in both pre-training and prompt tuning stages. In particular, PSP 1) employs a dual-view contrastive learning to align the latent semantic spaces of node attributes and graph structure, and 2) incorporates structure information in prompted graph to construct more accurate prototype vectors and elicit more pre-trained knowledge in prompt tuning. We conduct extensive experiments on node classification and graph classification tasks to evaluate the effectiveness of PSP. We show that PSP can lead to superior performance in few-shot scenarios on both homophilous and heterophilous graphs. The implemented code is available at https://github.com/gqq1210/PSP.\nKeywords: Graph Neural Networks \u00b7 Pre-training \u00b7 Prompt \u00b7 Few-sho\n# 1 Introduction\nGraph Neural Networks (GNNs) have been widely applied in a variety of fields, such as social network analysis [5], financial risk control [26], and recommender\nsystems [27], where both structural and attribute information are learned via message passing on the graphs [11]. Recently, extensive efforts [6,12] have been made to design graph pre-training methods, which are further fine-tuned for various downstream tasks. Nevertheless, inconsistent objectives of pre-training and fine-tuning often leads to catastrophic forgetting during downstream adaptation [33], especially when the downstream supervised data is too scarce to be easily over-fitted. To bridge this gap, many prompt tuning methods for GNNs [20,14,33,21,4,30,1,31,22] h also been proposed to achieve remarkable performance in few-shot learning tasks on graphs. In particular, the key insight of these methods is to freeze the pretrained model (i.e., GNN) and introduce extra task-specific parameters, which learns to exploit the pre-trained knowledge for downstream tasks. For example, GPPT [20] and GraphPrompt [14] pre-train a GNN model based on the link prediction task, then they take the class prototype vectors and the readout function as parameters respectively to reformulate the downstream node/graph classification task into the same format as link prediction. Despite the initial success, a clear limitation in these existing models is that graph structure, as the key ingredient in pre-training, is under-explored when constructing class prototype vectors in prompt tuning, which limits their effectiveness in unleashing pre-trained knowledge. In particular, their task-specific parameters (e.g., class prototype vectors or readout functions) are usually learned only with few labeled data. They fail to consider the relationships between the task and the massive unlabeled data, which could also provide rich pre-trained knowledge that is very useful for the task at hand. This is even more important when the labeled data is scarce, e.g., few-shot node classification. As shown in Figure 1 (b), existing methods that directly use the average embeddings of labeled nodes/graphs as the class prototype representations can easily be undermined by noisy/outlier data when the number of labeled nodes is scarce. In contrast, facilitating class representation learning with structural connections between class prototype vectors and unlabeled nodes could help solve this issue (as shown in Figure 1 (d)). Moreover, most existing methods are designed for homophilous graphs, relying excessively on the graph structural information while disregarding the impact of heterophilous neighborhoods on node representations. This adversely affects the model performance on heterophilous graphs. In this paper, we propose a novel Pre-training and Structure Prompt tuning (PSP) framework, which unifies the objectives of pre-training and prompt tuning for GNNs and integrates structural information in both pre-training and prompt tuning stages to construct more accurate prototype vectors. For pretraining, inspired by [13], we separate attribute and structural information, employing dual-view contrastive learning to align the latent semantic spaces of node attributes and graph structure. Specifically, one view is implemented with MLP, which only uses node attributes in the graph. The other view adopts GNN to leverage both node attributes and structural information of the graph. For downstream prompt-tuning, we fix the learned parameters of MLP and GNN\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ed35/ed35d399-2277-4c17-8cee-47874853268e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(c) PSP before prompt tuning (d) PSP after prompt tuning</div>\n<div style=\"text-align: center;\">(c) PSP before prompt tuning</div>\nFig. 1: The construction of class prototype vectors. The colored areas contain the labeled nodes for training. The circles represent nodes, and the triangles represent class prototype vectors for node classification task. The solid black lines and gray dashed lines denote the original edges in the graph and the new weighted edges, respectively. For each node, the dashed line in red or green denotes the edges with the largest weight to the class prototype vector.\nin the pre-training stage, add class prototype vectors as new nodes to the raw graph and introduce structural connections between prototype vectors and original nodes as prompts to learn more accurate prototype vectors (see Figure 1 (c)). Note that weights associated with these connections are parameters to be learned. In the training phase, we use representations of labeled nodes/graphs calculated by MLP as anchors, and representations of prototype vectors obtained through GNN as positive/negative samples. Specifically, the prototype vector in the same class as the anchor is considered as positive sample, while prototype vectors in other classes serve as negative samples. Then, contrastive learning between nodes/graphs (MLP-based view) and prototype vectors (GNN-based view) is performed to learn prompt parameters. As a result, we unify the objectives of pre-training and prompt tuning. After prompt tuning, the nodes and their corresponding class prototypes are learned to have higher weights on the edges, as shown in Figure 1(d). We also experimentally show the results in Figure 5 of Section 5.5. Based on the learned weights, for each prototype vector, GNN formulates its embedding by weighted-aggregating information from its neighboring nodes, i.e., all the nodes in the raw graph. This helps learn better prototype vectors by leveraging both labeled nodes and massive unlabeled nodes in the graph, which is particularly useful in few-shot scenarios. Finally, in the testing stage, node/graph classification can be conducted via comparing the similarity of representations between node/graph and the prototype vectors. Compared with existing graph prompt tuning methods, our method is more desirable in learning better prototype vectors, as we leverage both labeled nodes and massive unlabeled nodes in the graph, which is particularly useful in few-shot scenarios. We further highlight that our prompt tuning method is applicable to\nboth homophilous and heterophilous graphs. First, node/graph representations computed from MLP-based view are not affected by structural heterophily. Second, prototype vectors calculated from GNN-based view are based on the learned weights in structure prompt tuning, which takes all nodes in the raw graph as neighbors and learns to assign large (small) weights to those in the same (different) class. As such, the computation of prototype vectors is less affected by graph heterophily. To summarize, our main contributions in this paper are: \u2013 We propose an effective graph pre-training and prompt tuning framework PSP, which unifies the objectives of pre-training and prompt tuning. \u2013 We present a novel prompt tuning strategy, which introduces a learnable structure prompt to learn high-quality class prototype vectors and enhance model performance on both homophilous and heterophilous graphs. \u2013 We extensively demonstrate the effectiveness of PSP with different benchmark datasets on both node classification and graph classification. In particular, we vary the number of labeled training data and show that PSP can lead to better performance in challenging few-shot scenarios.\n# 2 Related work\n# 2.1 Graph Pre-training\nInspired by the remarkable achievements of pre-trained models in Natural Language Processing (NLP) [15] and Computer Vision (CV) [19], graph pre-training [28] emerges as a powerful paradigm that leverages self-supervision on label-free graphs to learn intrinsic graph properties. Some effective and commonly-used pre-training strategies include node-level comparison [32], edge-level pretext [9], and graph-level contrastive learning [29]. Recently, there are also some newly proposed pre-training methods [8,16]. However, these approaches do not consider the gap between pre-training and downstream objectives, which limits their generalization ability to handle different tasks.\n# 2.2 Prompt-based Learning\nThe training strategy \u201cpre-train & fine-tune\u201d is widely used to adapt pre-trained models onto specific downstream tasks. However, this strategy ignores the inherent gap between the objectives of pre-training and diverse downstream tasks, where the knowledge learned via pre-training could be forgotten or ineffectively leveraged for downstream tasks, leading to poor performance. To bridge this gap, NLP proposes a new paradigm, namely \u201cpre-train & prompt\u201d. These methods freeze the parameters of the pre-trained models and introduce additional learnable components in the input space, thereby enhancing the compatibility between inputs and pre-trained models. On graph data, there are a handful of studies that adopt prompt tuning to learn more generalizable GNNs. GPPT [20] relies on edge prediction as the pre-training task and reformulates the downstream task as edge prediction by introducing task tokens\nfor node classification. GraphPrompt [14] proposes a unified framework based on subgraph similarity and link prediction, hinging on a learnable prompt to actively guide downstream tasks using task-specific aggregation in readout function. and computes class prototype vectors via supervised prototypical contrastive learning. GPF [4] extends the node embeddings with additional task-specific prompt parameters, and can be applied to the pre-trained GNN models that employ any pre-training strategy. ProG [21] reformulates node-level and edge-level tasks to graph-level tasks, and introduces the meta-learning technique to the graph prompt tuning study. Despite their success, we observe that most of them utilize the structure information in pre-training, while ignoring it in downstream prompt tuning stage for learning more accurate prototype vectors. This restricts their effectiveness to fully utilize pre-trained knowledge stored in the entire graph. In particular, their task-specific parameters are usually learned only with labeled nodes while massive unlabeled nodes are disregarded, leading to poor performance in more challenging few-shot scenarios. In addition, they ignore the impact of heterophilous neighborhoods on node representation and are not suitable for heterophilous graphs. In this paper, our proposed PSP employs a dual-view contrastive learning and integrates structure information in both pre-training and prompt tuning stage to construct more accurate prototype vectors, achieving superior performance in few-shot learning tasks on both homophilous and heterophilous graphs.\n# 3 Preliminary\nGraph. We denote a graph as G = (V, E), where V = {vi}N i=1 is a set of N nodes and E \u2286V \u00d7 V is a set of edges. We also define A \u2208RN\u00d7N as the adjacency matrix of G, where Aij = 1 if vi and vj are connected in G, and Aij = 0 otherwise. Each node vi in the graph is associated with an F-dimensional feature vector xi \u2208R1\u00d7F , and the feature matrix of all nodes is defined as X \u2208RN\u00d7F . Research problem. In this paper, we investigate the problem of graph pretraining and prompt tuning, which learns representations of graph data via pretraining, and transfer the pre-trained knowledge to solve downstream tasks, such as node classification and graph classification. Moreover, we further consider the scenarios where downstream tasks are given limited supervision, i.e., k-shot classification. For each class, only k labeled samples (i.e., nodes or graphs) are provided as training data. Prompt tuning of pre-trained models. Given a pre-trained model, a set of learnable prompt parameters \u03b8 and a labeled task dataset D, we fix the parameters of the pre-trained model and only optimize \u03b8 with D for the downstream graph tasks.\n# 4 Proposed Method\nIn this paper, we propose a novel graph pre-training and structure prompt tuning framework, namely PSP, which unifies the objectives of pre-training and prompt\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1904/1904dbf4-9a73-43eb-8622-3cae428727bd.png\" style=\"width: 50%;\"></div>\nFig. 2: Overall framework of PSP. Top: pre-training. Middle: prompt tuning  node classification. Bottom: prompt tuning for graph classification.\n<div style=\"text-align: center;\">Fig. 2: Overall framework of PSP. Top: pre-training. Middle: prompt tuning for node classification. Bottom: prompt tuning for graph classification.</div>\ntuning for GNNs and integrates structure information in both pre-training and prompt tuning stage to achieve better performance in more challenging few-shot scenarios. The overall framework of PSP is shown in Figure 2.\n# 4.1 Graph Pre-training\nFor graph data, both node attributes and structural information are critical for revealing the underlying semantics of graph during the pre-training phase. Inspired by the success of LINKX [13] that separately learns node embeddings from attributes and graph structure for heterophilous graphs, we design a dualview contrastive learning method to align the latent semantic spaces of node attributes and graph structure. The upper part of Figure 2 shows the dual-view pre-training paradigm. In particular, one view is implemented with MLP, which only uses node attributes in the graph, while the other adopts GNN to leverage both node attributes and structural information of the graph. Formally, we define the node representations computed by the two views as:\n# Z(1) = MLP(X) and Z(2) = GNN(X, A),\nwhere Z(1) \u2208RN\u00d7D and Z(2) \u2208RN\u00d7D have the same latent dimensionality D. To optimize the MLP and GNN, we leverage a contrastive loss function Lpre to maximize the similarity between the two representations of the same node, denoted as z(1) i and z(2) i for node vi. For an anchor z(1) i , other node representations z(2) j are considered as negative samples. More specifically, we formulate\n(1)\ne-Training and Structure Prompt Tuning for Graph Neural Networks\ne loss as the normalized temperature-scaled cross entropy loss [2] a\n\ufffd where N is the number of nodes, \u03c4 is a temperature parameter, and sim(\u00b7) is implemented with cosine similarity. In general, the dual-view contrastive pretraining can exploit both attribute and structure information of graph to encode generalizable knowledge in the output node embeddings. In the next subsection, we introduce graph structure prompt tuning that leverages such knowledge in downstream classification tasks.\n# 4.2 Graph Structure Prompt Tuning\nNext, we demonstrate how we freeze the pre-trained model and adapt it to different downstream tasks on graph. In particular, we propose a novel method, namely structure prompt tuning, which considers the structure relationships between the graph data and the task at hand. Compared to existing graph prompt tuning methods, the structure relationships in our method allow the task to more effectively leverage the pre-trained knowledge embedded in the graph data. In the following, we elaborate the structure prompt tuning method on two representative tasks, i.e., node classification and graph classification.\nNode Classification Our method is based on the prototype-based framework [14,33], which learns a prototype embedding vector pc for each node class c \u2208{1, 2, ..., C}. In particular, our method comprises three steps: 1) structure prompting, 2) prompt initialization, and 3) prompt tuning. Step 1: Structure prompting. For all the class prototypes, the main idea of our method is to consider them as virtual nodes, and connect them to all the original nodes V in the graph G, as shown in Figure 1(c). More specifically, we add a total number of C prototype nodes (denoted as P = {pc}C c=1) and N \u00d7 C weighted edges (denoted as W) to construct a prompted graph G\u2032 as\nStep 2: Prompt initialization. Next, we define the attributes and edge weights for the prototype nodes. In particular, we simply initialize the attributes for each prototype pc as the averaged attribute vector of labeled nodes in class c:\nwhere Dc \u2286D denotes labeled nodes of class c in the training set. For the newly added edges that connect P and V, we adopt dot product to initialize their weights W \u2208RN\u00d7C as:\nwhere Dc \u2286D denotes labeled nodes of class c in the training set. For the newly added edges that connect P and V, we adopt dot product to initialize their weightsRN\u00d7C as:\n(2)\n(3)\n(4)\n(5)\nwhere Z(2) denotes node embeddings derived from the pre-trained GNN and P represents the prototype vectors with the c-th row pc = 1 |Dc| \ufffd (vi,c)\u2208Dc z(2) i . During the subsequent prompt tuning step, the parameters of the pre-trained model are frozen, and the weight matrix W is considered as the only task-specific parameter to be learned. Step 3: Prompt tuning. We conduct prompt tuning on the prompted graph G\u2032 using the same form of contrastive loss function as in Equation 2, while keeping the node representations fixed and only optimize the prototype embeddings. Formally, given a labeled dataset D for the downstream task, the prompt tuning loss is defined as follows:\n# \ufffd where pc is parameterized by W and we have:\n\ufffd where pc is parameterized by W and we have:\nP = GNN([X, XP ], [A, W]).\nHere, X represents the original node features in graph G, XP \u2208RC\u00d7F represents the prototype features, and [A, W] \u2208RN\u00d7(N+C) represents the new adjacency matrix of G\u2032. Notably, unlike conventional methods that directly consider P as learnable parameters, we parameterize P with their structural connections with the graph data, i.e., the added edges W. In other words, only W would be optimized as parameters when minimizing Lpro, which learns to aggregate pre-trained knowledge from all the nodes in the graph to formulate prototype embeddings.\nGraph Classification Our method can also be adapted to graph classification with minor changes in each step. In structure prompting, for each graph instance Gi and a prototype node pc, the added edges between any vi \u2208Vi and pc share the same weight. As such, the prompt tuning of graph classification also has N \u00d7 C parameters, where N is the number of graphs here. In prompt initialization, we introduce an average-based readout function on node level representations Z(1) and Z(2) to compute the graph-level representation S(1) and S(2), respectively, as shown in Figure 2. Then, we can use Equation 5 to initialize W with Z(2) replaced by S(2). In prompt tuning, we also replace Z(1) by S(1) in Equation 6 for optimizing graph-level classification tasks.\nRemarks In our proposed PSP method, it worth noting that the weights of pre-trained model are frozen for downstream tasks, and the prompt tuning is parameterized by the learnable adjacency matrix W \u2208RN\u00d7C. Compared with most existing studies where the prototype vectors are directly optimized on few labeled data, this allows the prototype vectors to aggregate pre-trained knowledge from massive unlabeled nodes for more effective task adaptation.\n(6)\n(7)\n<div style=\"text-align: center;\">Table 1: Statistics of the datasets</div>\nTable 1: Statistics of the datasets\nCora CiteSeer PubMed ogbn-arxiv Chameleon Actor ENZYMES PROTEINS COX2 BZR COLLAB\nGraph\n1\n1\n1\n1\n1\n1\n600\n1,113\n467\n405\n5000\nGraph classes\n-\n-\n-\n-\n-\n-\n6\n2\n2\n2\n3\nAvg. nodes\n2,708\n3,327\n19,717\n169,343\n2,277\n7,600\n32.63\n39.06\n41.22 35.75\n74.49\nAvg. edges\n5,429\n4,732\n44,338\n1,166,243\n31,421\n26,752\n62.14\n72.82\n43.45 38.36 2457.78\nNode features 1433\n3703\n500\n128\n2325\n931\n18\n1\n3\n3\n367\nNode classes\n7\n6\n3\n40\n5\n5\n3\n3\n-\n-\n-\nTask (N/G)\nN\nN\nN\nN\nN\nN\nN,G\nG\nG\nG\nG\n# 4.3 Inference\nIn the inference stage, classification is performed by comparing the similarity of representations between node/graph (from MLP-based view) and prototype vectors (from GNN-based view) from different classes. The class corresponding to the prototype vector with the largest similarity is taken as the final prediction of the node/graph. We use node classification as an example to explain in detail. By comparing the node representation with each class prototype vector pc, we can get the predicted class probability by:\n\ufffd where the highest-scored class is chosen as the prediction. From Equation 8, we see that the computation aligns well with objectives in Equations 2 and 6.\n# 5 Experiments\nIn this section, we conduct extensive experiments on node classification and graph classification tasks with 11 benchmark datasets to evaluate PSP.\n# 5.1 Experimental Setup\nDatasets. We evaluate the performance of PSP using various benchmark datasets with diverse properties, including homophilous graphs [11,7]: Cora, CiteSeer, PubMed, ogbn-arxiv, and heterophilous graphs [18,14,17]: Chameleon, Actor, ENZYMES, PROTEINS, COX2, BZR, COLLAB. We summarize these datasets in Table 1. Note that the \u201cTask\u201d row indicates the type of downstream task, where \u201cN\u201d represents node classification and \u201cG\u201d represents graph classification. Baselines. To evaluate the proposed PSP, we compare it with 4 categories of state-of-the-art approaches as follows. Supervised models: GCN [11] and GAT [23]. They use the labeled data to learn GNNs, which are then directly applied for the classification tasks. Graph pre-training models: EdgeMask [24] and GraphCL [29]. Following the transfer learning strategy of \u201cpre-train & fine-tune\u201d, the pre-trained models are fine-tuned on the downstream tasks. Graph few-shot learning models: CGPN [25] and Meta-PN [3]. They are\n(8)\nTable 2: Accuracy (%) on node classification with masking ratio of 50%. W highlight the best score on each dataset in bold. OOM denotes the out-of-th\n<div style=\"text-align: center;\">Table 2: Accuracy (%) on node classification with masking ratio of 50%. We highlight the best score on each dataset in bold. OOM denotes the out-of-the-</div>\nmemory error.\nMethods\nCora\nCiteSeer\nPubMed\nogbn-arxiv\nChameleon\nActor\nGCN\n71.78 \u00b1 0.50\n52.15 \u00b1 0.27\n65.05 \u00b1 0.15\n64.19 \u00b1 0.59\n30.38 \u00b1 1.21\n18.67 \u00b1 1.94\nGAT\n74.94 \u00b1 1.26\n59.50 \u00b1 0.61\n69.30 \u00b1 0.97\n63.97 \u00b1 0.69\n29.14 \u00b1 0.79\n20.85 \u00b1 1.37\nEdgeMask\n76.38 \u00b1 0.89\n65.49 \u00b1 0.90\n71.29 \u00b1 0.66\n64.86 \u00b1 0.67\n30.89 \u00b1 1.15\n21.76 \u00b1 0.95\nGraphCL\n76.73 \u00b1 0.91\n65.94 \u00b1 1.20\n72.03 \u00b1 1.54\n65.87 \u00b1 0.82\n27.37 \u00b1 1.40\n22.18 \u00b1 1.24\nCGPN\n74.62 \u00b1 0.99\n65.32 \u00b1 1.17\n67.38 \u00b1 1.43\nOOM\n31.12 \u00b1 2.07\n21.91 \u00b1 0.39\nMeta-PN\n76.89 \u00b1 1.05\n65.80 \u00b1 1.13\n69.75 \u00b1 1.11\n57.37 \u00b1 0.79\n30.08 \u00b1 1.25\n19.16 \u00b1 1.04\nGPPT\n77.16 \u00b1 1.35\n65.81 \u00b1 0.97\n72.23 \u00b1 1.22\n66.13 \u00b1 0.44\n31.28 \u00b1 0.65\n22.07 \u00b1 0.81\nGraphPrompt 68.43 \u00b1 0.58\n61.11 \u00b1 1.24\n72.63 \u00b1 1.72\n59.13 \u00b1 0.59\n31.67 \u00b1 1.19\n21.11 \u00b1 1.35\nGPF\n62.20 \u00b1 0.93\n60.78 \u00b1 1.17\n68.81 \u00b1 0.95\n56.04 \u00b1 0.97\n29.31 \u00b1 1.68\n20.56 \u00b1 1.09\nProG\n72.49 \u00b1 1.04\n65.33 \u00b1 0.93\n73.70 \u00b1 1.49\n67.80 \u00b1 1.65\n31.75 \u00b1 1.25\n22.82 \u00b1 1.03\nPSP\n77.62 \u00b1 1.29 67.52 \u00b1 0.95 75.94 \u00b1 1.06 69.20 \u00b1 0.73 34.08 \u00b1 1.26 25.47 \u00b1 0.82\nspecially designed for few-shot scenarios. Graph prompt models: GPPT [20], GraphPrompt [14], GPF [4] and ProG [21]. They adopt the \u201cpre-train & prompt\u201d paradigm, where the pre-trained models are frozen, and task-specific learnable prompts are introduced and trained in the downstream tasks. Note that we use GraphCL as the pre-training model for GPF. We also notice that SGL-PT [33] and VNT [22] are recent methods in the similar topic. However, both of them do not release their codes. For fairness, we do not take them as baselines. Implementation details. To train PSP, we adopt the Adam optimizer [10], where the learning rate and weight decay in the pre-training stage are fixed as 1e-4. We set the number of both graph neural layers and multilayer perceptron layers as 2. We set the hidden dimension for node classification as 128, and for graph classification as 32. Other hyper-parameters are fine-tuned on the validation set by grid search. In the prompt tuning stage, the learning rate is adjusted within {0.0001, 0.001, 0.01, 0.1}, the weight decay is chosen from {1e-5, 1e-4, 1e-3, 1e-2} and the dropout rate is selected from the range [0.2, 0.8]. Further, for those non-prompt-based competitors, some of their results are directly reported from [20] and [14] (i.e., node classification with 50% masking ratio and graph classification). For other cases and prompt-based models, we fine-tune hyperparameters with the codes released by their original authors. For fair comparison, we report the average results with standard deviations of 5 runs for node classification experiments, while the setting of graph classification experiments follows [14]. We run all the experiments on a server with 32G memory and a single Tesla V100 GPU.\n# 5.2 Node classification\nExperimental setting. For homophilous graph datasets, we use the official splitting of training/validation/testing [11]. For heterophilous graph datasets, we randomly sample 20 nodes per class as training set and validation set, respec-\n<div style=\"text-align: center;\">Table 3: Accuracy (%) on few-shot node classification.</div>\nTable 3: Accuracy (%) on few-shot node classification.\nMethods\nCora\nCiteSeer\nPubMed\nENZYMES\nChameleon\nActor\nGCN\n57.83 \u00b1 5.90 49.69 \u00b1 4.39 63.16 \u00b1 4.56\n61.49 \u00b1 12.87\n27.88 \u00b1 5.77\n20.69 \u00b1 2.96\nGAT\n60.34 \u00b1 4.15 52.85 \u00b1 3.69 64.26 \u00b1 3.17\n59.94 \u00b1 2.86\n26.97 \u00b1 4.85\n20.93 \u00b1 2.67\nEdgeMask\n64.10 \u00b1 2.79 55.23 \u00b1 3.17 65.89 \u00b1 4.26\n56.17 \u00b1 14.39\n23.76 \u00b1 3.74\n18.03 \u00b1 2.48\nGraphCL\n65.89 \u00b1 3.45 58.37 \u00b1 4.74 69.06 \u00b1 3.24\n58.73 \u00b1 16.47\n22.25 \u00b1 3.14\n19.56 \u00b1 1.15\nCGPN\n66.73 \u00b1 2.87 57.14 \u00b1 3.75 65.68 \u00b1 2.38\n66.52 \u00b1 16.18\n27.17 \u00b1 2.16\n20.68 \u00b1 0.99\nMeta-PN\n66.65 \u00b1 3.15 58.20 \u00b1 2.94 67.18 \u00b1 3.12\n55.92 \u00b1 13.28\n25.83 \u00b1 2.64\n18.31 \u00b1 1.95\nGPPT\n64.55 \u00b1 3.72 55.63 \u00b1 2.55 70.07 \u00b1 6.07\n53.79 \u00b1 17.46\n28.91 \u00b1 3.23\n20.88 \u00b1 1.69\nGraphPrompt 63.91 \u00b1 2.43 53.42 \u00b1 4.98 68.93 \u00b1 3.93\n67.04 \u00b1 11.48\n26.35 \u00b1 3.50\n20.50 \u00b1 2.45\nGPF\n63.52 \u00b1 5.39 54.31 \u00b1 5.21 63.98 \u00b1 3.54\n60.13 \u00b1 15.37\n27.38 \u00b1 3.62\n19.32 \u00b1 2.52\nProG\n65.68 \u00b1 4.29 59.07 \u00b1 2.73 64.57 \u00b1 3.81\n57.22 \u00b1 17.41\n29.18 \u00b1 4.53\n21.43 \u00b1 3.27\nPSP\n68.65 \u00b1 2.17 61.7 \u00b1 4.21 72.23 \u00b1 4.20 72.86 \u00b1 14.58 33.23 \u00b1 3.80 24.74 \u00b1 2.79\ntively. The remaining nodes which are not sampled will be used for evaluation. Following the setting of [20], we randomly mask 50% of the training labels, which corresponds to 10-shot for datasets except ogbn-arxiv. Results. Table 2 summarizes the results, from which we see that: (1) Supervised learning methods generally perform worse than pre-training methods and prompt methods. This is because the annotations required by supervised frameworks are not enough. In contrast, pre-training approaches are usually facilitated with more prior knowledge, alleviating the need for labeled data. However, these pre-training methods still face an inherent gap between the training objectives of pre-training and downstream tasks. Pre-trained models may suffer from catastrophic forgetting during downstream adaptation. Therefore, we can find that compared with pre-training approaches, prompt-based methods usually achieve better performance. (2) Our proposed PSP outperforms all the baselines on node classification. This is because PSP bridges the gap between the pre-training stage and the down-stream prompt tuning stage, leveraging graph structure prompt to provide more information from the massive unlabeled nodes and being applicable to both homophilous and heterophilous graphs.\n# 5.3 Few-shot node classification\nExperimental setting. To explore more challenging few-shot node classification settings, we assign a much smaller number of labeled data as the training data for each class. Specifically, for ENZYMES, we follow existing study [14] to only choose graphs that consist of more than 50 nodes, which ensures there are sufficient labeled nodes for testing. On each graph, we randomly sample 1 node per class for training and validation, respectively. The remaining nodes which are not sampled will be used for testing. For Cora, CiteSeer and PubMed, we randomly sample 3 nodes per class for training, while the validation and test sets follow the official splitting [11]. For Chameleon and Actor, we randomly sample\n3 nodes per class for training and validation respectively, while the remaining nodes which are not sampled are used for testing. Results. Table 3 illustrates the results. From the table, we see that: (1) In the extremely few-shot scenarios, PSP can still achieve superior performance. Taking ENZYMES as an example, the accuracy of PSP is 5.82% higher than the runner-up. This is because PSP uses graph structure information to optimize the prototype vectors, so when the training set is extremely small, the prototype vectors can also be accurate by capturing the underlying information of other unlabeled nodes. In contrast, few-shot learning models may suffer from inaccurate pseudo labels and other methods fail to consider the relationship between the task and the massive unlabeled data. (2) Our proposed PSP achieves larger improvements in heterophilous graphs. PSP achieves a largest improvement of 2.97% in homogeneous graphs while 5.82% in heterophilous graphs. This is because in the downstream prompt tuning stage of PSP, node representations computed from MLP-based view are not affected by the structural heterophily. Also, the graph structure prompt reduces the adverse influence from graph heterophily. Therefore, the prototype vector calculated from GNN-based view are more accurate. In contrast, other methods are susceptible to structure heterophily and can only achieve sub-optimal results.\n# 5.4 Few-shot graph classification\nFollowing the setting of [14], we conduct 5-shot tasks. The results are listed in Table 4, from which we observe that our proposed PSP significantly outperforms the baselines on these datasets. This again demonstrates the effectiveness of our proposed method. Notably, as both node and graph classification tasks share the same pre-trained model on ENZYMES, the superior performance of PSP on both types of tasks further demonstrates that the gap between different tasks is better addressed by our unified framework.\n# 5.5 Model Analysis\nWe further analyse several aspects of our model. The following experiments are conducted on the 3-shot node classification and 5-shot graph classification. Ablation study on training paradigm. We conduct an ablation study that compares variants of PSP with different pre-training and prompt tuning strategies: (1) We directly fine-tune the pre-trained models on the tasks, instead of prompt tuning. We call this variant PSP-ft (with fine-tune). (2) For downstream tasks, we remove the prompt tuning process and only use the mean embedding vectors of the labeled data as the prototype vectors to perform classification. We call this variant PSP-np (no prompt). (3) We replace our proposed dual-view contrastive learning in pre-training with GraphCL, i.e., the pre-trained encoder is GNN, while the downstream tasks still use our proposed graph structure prompt. We call this variant PSP-CL (with GraphCL as the pre-training model). Figure 3 shows the results of this study, we observe that\n<div style=\"text-align: center;\">Table 4: Accuracy (%) on graph classification.</div>\nTable 4: Accuracy (%) on graph classification.\nMethods\nENZYMES\nPROTEINS\nCOX2\nBZR\nCOLLAB\nGCN\n20.37 \u00b1 5.24 54.87 \u00b1 11.20 51.37 \u00b1 11.06 56.16 \u00b1 11.07 50.62 \u00b1 7.13\nGAT\n15.90 \u00b1 4.13 48.78 \u00b1 18.46 51.20 \u00b1 27.93 53.19 \u00b1 20.61 51.08 \u00b1 7.59\nInfoGraph\n20.90 \u00b1 3.32\n54.12 \u00b1 8.20\n54.04 \u00b1 9.45\n57.57 \u00b1 9.93\n52.13 \u00b1 8.71\nGraphCL\n28.11 \u00b1 4.00\n56.38 \u00b1 7.24 55.40 \u00b1 12.04 59.22 \u00b1 7.42\n52.81 \u00b1 9.05\nCGPN\n24.75 \u00b1 5.71\n53.68 \u00b1 9.15\n52.16 \u00b1 9.37\n58.24 \u00b1 8.47\n50.05 \u00b1 6.91\nMeta-PN\n21.05 \u00b1 4.58\n54.17 \u00b1 8.36 52.83 \u00b1 10.26 56.37 \u00b1 13.15 51.71 \u00b1 7.12\nGPPT1\n-\n-\n-\n-\n-\nGraphPrompt 31.45 \u00b1 4.32\n64.42 \u00b1 4.37\n59.21 \u00b1 6.82\n61.63 \u00b1 7.68\n55.16 \u00b1 6.24\nGPF\n32.65 \u00b1 5.73\n57.16 \u00b1 5.96\n61.62 \u00b1 7.47\n59.17 \u00b1 6.18\n53.91 \u00b1 8.25\nProG\n29.18 \u00b1 3.09\n60.98 \u00b1 7.49\n61.96 \u00b1 6.35\n63.71 \u00b1 5.25\n54.93 \u00b1 7.24\nPSP\n33.57 \u00b1 4.72 64.95 \u00b1 5.86 65.71 \u00b1 5.34 68.58 \u00b1 7.57 57.29 \u00b1 6.17\n \n1 GPPT[20] lacks a unified effort to address graph classification tasks.\n<div style=\"text-align: center;\">Table 5: Varying the ratio of added edges on few-shot node classification. \u2193/\u2191 means the decreasing/improvement compared with the accuracy of runner-up.</div>\nmeans the decreasing/improvement compared with the accuracy of runner-up.\nrunner-up\n0%\n0.1%\n1%\n5%\n10%\n50%\n100%\nCora\n65.89\u00b13.45 65.06\u00b13.77 \u219365.72\u00b13.14 \u219367.50\u00b12.38 \u219167.46\u00b12.45 \u219167.88\u00b12.83 \u219168.62\u00b12.67 \u219168.68\u00b12.17 \u2191\nPubMed\n70.07\u00b16.07 70.84\u00b15.31 \u219170.32\u00b13.95 \u219171.62\u00b14.34 \u219170.94\u00b14.40 \u219171.42\u00b14.70 \u219172.24\u00b14.33 \u219173.23\u00b14.20 \u2191\nChameleon 29.18\u00b14.53 25.22\u00b13.09 \u219330.92\u00b13.07 \u219133.41\u00b13.38 \u219133.30\u00b12.36 \u219133.07\u00b13.79 \u219132.09\u00b12.20 \u219133.97\u00b13.22 \u2191\n(1) PSP-np always performs the worst among all the variants, showing the effectiveness of our proposed graph structure prompt. PSP-ft achieves better performance than PSP-np, which is because PSP-ft is parameterized. (2) PSP achieves comparable results to PSP-CL in homogeneous graph and clearly outperforms PSP-CL in heterophilous graph. This is because our pretraining method uses MLP and GNN for contrastive learning, where MLP is not affected by the heterophily of the graph. In contrast, PSP-CL is susceptible to structure heterophily. Varying the number of the shots. For node classification, we vary the number of shots between 1 and 10. For graph classification, we vary the number of shots between 1 and 30. We compare PSP with several competitive baselines in Figure 4. In general, PSP consistently outperforms the baselines, especially when the number of shots is few. We further notice that when the number of shots is relatively large, PSP can be surpassed by graphCL on graph classification, especially on COX2. This could be contributed to more available training data on COX2, where 30 shots per class implies that 12.85% of the 467 graphs are used for training. This is not our target few-shot scenario. Varying the ratio of added edges. Our prompt tuning method is parameterized by the added edges between original nodes and prototype vectors, where the weights of added edges are learnable. We hereby study the impact of the ratio of newly added edges (i.e., parameters) r. To vary the number of edges, we first\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4277/4277df82-1b75-4194-8255-08308a9536e2.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 3: The ablation study on training paradigm.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6fca/6fcae91f-4d3d-427d-830b-3764218445a2.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 4: (a)(b): varying the number of shots for node classification. (c)(d): varying the number of shots for graph classification.</div>\nrandomly select rN nodes outside the training set. During prompt tuning, we next combine the rN nodes with Nt training nodes as the set of nodes that add connections with all the C prototypes. Following this setting, we conduct 3-shot node classification on 4 datasets. The results are shown in Table 5. Surprisingly, we observe that for Cora and Chameleon, PSP can surpass the runner-up when r = 1% and 0.1%, respectively. For PubMed, PSP can outperform the runner-up even when r = 0. This shows that our prompt tuning model can achieve superior performance with only a small number of parameters (Nt + rN)C, where r is a small number. Therefore, PSP is promising in scaling to large graphs. Visualization of learned edge weights. We visualize the weight matrix W of the added edges after prompt tuning. As shown in Figure 5, for each node, its edge connected to the corresponding class prototype is more likely to have a larger weight. Hence, the prototype vectors are very accurate by aggregating massive unlabeled data which contains rich pre-trained knowledge to reflect the semantics of the task labels.\n# 6 conclusion\nIn this paper, we proposed PSP, a novel pre-training and structure prompt tuning framework for GNNs, which unified the objectives of pre-training and prompt\nPSP: Pre-Training and Structure Prompt Tuning for Graph Neural Networks\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7481/7481cbbc-9af4-4736-bd62-d086dc2152a3.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) After Prompt Tuning</div>\n<div style=\"text-align: center;\">Fig. 5: The weights of added edges between nodes and class prototype vector before and after prompt tuning.</div>\ntuning for GNNs and integrated structural information in both pre-training and prompt tuning stages to construct more accurate prototype vectors. For pretraining, we proposed a dual-view contrastive learning to align the latent semantic spaces of node attributes and graph structure. For downstream prompt tuning, we proposed to learn the structural connection between the prototype vectors and the graph, and then leveraged the learned structural information to perform better in few-shot tasks. Finally, we conducted extensive experiments and showed that PSP significantly outperforms various state-of-the-art baselines on both homophilous and heterophilous graphs, especially on few-shot scenarios.\n# 7 Acknowledgement\nThis work is supported by National Natural Science Foundation of China No. 62202172 and Shanghai Science and Technology Committee General Program No. 22ZR1419900.\n# References\n1. Chen, M., Liu, Z., Liu, C., Li, J., Mao, Q., Sun, J.: Ultra-dp: Unifying graph pre-training with multi-task graph dual prompt. arXiv preprint arXiv:2310.14845 (2023) 2. Chen, T., Kornblith, S., Norouzi, M., Hinton, G.: A simple framework for contrastive learning of visual representations. In: International conference on machine learning. pp. 1597\u20131607. PMLR (2020) 3. Ding, K., Wang, J., Caverlee, J., Liu, H.: Meta propagation networks for graph few-shot semi-supervised learning. In: AAAI. vol. 36, pp. 6524\u20136531 (2022) 4. Fang, T., Zhang, Y., Yang, Y., Wang, C., Chen, L.: Universal prompt tuning for graph neural networks. arXiv preprint arXiv:2209.15240 (2022) 5. Hamilton, W., Ying, Z., Leskovec, J.: Inductive representation learning on large graphs. NeurIPS 30 (2017) 6. Hou, Z., Liu, X., Cen, Y., Dong, Y., Yang, H., Wang, C., Tang, J.: Graphmae: Self-supervised masked graph autoencoders. In: KDD. pp. 594\u2013604 (2022)\n1. Chen, M., Liu, Z., Liu, C., Li, J., Mao, Q., Sun, J.: Ultra-dp: Unifying graph pre-training with multi-task graph dual prompt. arXiv preprint arXiv:2310.14845 (2023) 2. Chen, T., Kornblith, S., Norouzi, M., Hinton, G.: A simple framework for contrastive learning of visual representations. In: International conference on machine learning. pp. 1597\u20131607. PMLR (2020) 3. Ding, K., Wang, J., Caverlee, J., Liu, H.: Meta propagation networks for graph few-shot semi-supervised learning. In: AAAI. vol. 36, pp. 6524\u20136531 (2022) 4. Fang, T., Zhang, Y., Yang, Y., Wang, C., Chen, L.: Universal prompt tuning for graph neural networks. arXiv preprint arXiv:2209.15240 (2022) 5. Hamilton, W., Ying, Z., Leskovec, J.: Inductive representation learning on large graphs. NeurIPS 30 (2017) 6. Hou, Z., Liu, X., Cen, Y., Dong, Y., Yang, H., Wang, C., Tang, J.: Graphmae: Self-supervised masked graph autoencoders. In: KDD. pp. 594\u2013604 (2022)\n7. Hu, W., Fey, M., Zitnik, M., Dong, Y., Ren, H., Liu, B., Catasta, M., Leskovec, J.: Open graph benchmark: Datasets for machine learning on graphs. NeurIPS 33, 22118\u201322133 (2020) 8. Hu, Z., Dong, Y., Wang, K., Chang, K.W., Sun, Y.: Gpt-gnn: Generative pretraining of graph neural networks. In: KDD. pp. 1857\u20131867 (2020) 9. Jin, W., Derr, T., Liu, H., Wang, Y., Wang, S., Liu, Z., Tang, J.: Selfsupervised learning on graphs: Deep insights and new direction. arXiv preprint arXiv:2006.10141 (2020) 10. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014) 11. Kipf, T.N., Welling, M.: Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016) 12. Li, X., Ye, T., Shan, C., Li, D., Gao, M.: Seegera: Self-supervised semi-implicit graph variational auto-encoders with masking. In: WebConf. pp. 143\u2013153 (2023) 13. Lim, D., Hohne, F., Li, X., Huang, S.L., Gupta, V., Bhalerao, O., Lim, S.N.: Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods. NeurIPS 34, 20887\u201320902 (2021) 14. Liu, Z., Yu, X., Fang, Y., Zhang, X.: Graphprompt: Unifying pre-training and downstream tasks for graph neural networks. In: WebConf. pp. 417\u2013428 (2023) 15. Long, S., Cao, F., Han, S.C., Yang, H.: Vision-and-language pretrained models: A survey. arXiv preprint arXiv:2204.07356 (2022) 16. Lu, Y., Jiang, X., Fang, Y., Shi, C.: Learning to pre-train graph neural networks. In: AAAI. vol. 35, pp. 4276\u20134284 (2021) 17. Morris, C., Kriege, N.M., Bause, F., Kersting, K., Mutzel, P., Neumann, M.: Tudataset: A collection of benchmark datasets for learning with graphs. arXiv preprint arXiv:2007.08663 (2020) 18. Pei, H., Wei, B., Chang, K.C.C., Lei, Y., Yang, B.: Geom-gcn: Geometric graph convolutional networks. arXiv preprint arXiv:2002.05287 (2020) 19. Qiu, X., Sun, T., Xu, Y., Shao, Y., Dai, N., Huang, X.: Pre-trained models for natural language processing: A survey. Science China Technological Sciences 63(10), 1872\u20131897 (2020) 20. Sun, M., Zhou, K., He, X., Wang, Y., Wang, X.: Gppt: Graph pre-training and prompt tuning to generalize graph neural networks. In: KDD. pp. 1717\u20131727 (2022) 21. Sun, X., Cheng, H., Li, J., Liu, B., Guan, J.: All in one: Multi-task prompting for graph neural networks (2023) 22. Tan, Z., Guo, R., Ding, K., Liu, H.: Virtual node tuning for few-shot node classification. arXiv preprint arXiv:2306.06063 (2023) 23. Veli\u010dkovi\u0107, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., Bengio, Y.: Graph attention networks. arXiv preprint arXiv:1710.10903 (2017) 24. Veli\u010dkovi\u0107, P., Fedus, W., Hamilton, W.L., Li\u00f2, P., Bengio, Y., Hjelm, R.D.: Deep graph infomax. arXiv preprint arXiv:1809.10341 (2018) 25. Wan, S., Zhan, Y., Liu, L., Yu, B., Pan, S., Gong, C.: Contrastive graph poisson networks: Semi-supervised learning with extremely limited labels. NeurIPS 34, 6316\u20136327 (2021) 26. Wang, D., Lin, J., Cui, P., Jia, Q., Wang, Z., Fang, Y., Yu, Q., Zhou, J., Yang, S., Qi, Y.: A semi-supervised graph attentive network for financial fraud detection. In: ICDM. pp. 598\u2013607. IEEE (2019) 27. Wu, S., Sun, F., Zhang, W., Xie, X., Cui, B.: Graph neural networks in recommender systems: a survey. ACM Computing Surveys 55(5), 1\u201337 (2022) 28. Xia, J., Zhu, Y., Du, Y., Li, S.Z.: A survey of pretraining on graphs: Taxonomy, methods, and applications. arXiv preprint arXiv:2202.07893 (2022)\n29. You, Y., Chen, T., Sui, Y., Chen, T., Wang, Z., Shen, Y.: Graph contrastive learning with augmentations. NeurIPS 33, 5812\u20135823 (2020) 30. Yu, X., Liu, Z., Fang, Y., Liu, Z., Chen, S., Zhang, X.: Generalized graph prompt: Toward a unification of pre-training and downstream tasks on graphs. arXiv preprint arXiv:2311.15317 (2023) 31. Yu, X., Zhou, C., Fang, Y., Zhang, X.: Multigprompt for multi-task pre-training and prompting on graphs. arXiv preprint arXiv:2312.03731 (2023) 32. Zhu, Y., Xu, Y., Yu, F., Liu, Q., Wu, S., Wang, L.: Graph contrastive learning with adaptive augmentation. In: WebConf. pp. 2069\u20132080 (2021) 33. Zhu, Y., Guo, J., Tang, S.: Sgl-pt: A strong graph learner with graph prompt tuning. arXiv preprint arXiv:2302.12449 (2023)\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of adapting Graph Neural Networks (GNNs) to various tasks with limited supervised data through a new paradigm called 'pre-train & prompt'. Existing methods often struggle with the construction of class prototype vectors in few-shot scenarios and neglect the structural information of graphs during prompt tuning, particularly in heterophilous graphs. The proposed PSP framework aims to unify pre-training and prompt tuning while effectively utilizing structural information.",
        "problem": {
            "definition": "The problem addressed is the effective adaptation of GNNs in few-shot learning scenarios, particularly the challenge of accurately constructing class prototype vectors with limited labeled data.",
            "key obstacle": "A major difficulty is the inability of existing methods to effectively incorporate structural information during prompt tuning, leading to inaccurate prototype vectors and poor performance on heterophilous graphs."
        },
        "idea": {
            "intuition": "The idea stems from the observation that existing methods fail to leverage the structural relationships in the graph for better prototype representation, particularly when labeled data is scarce.",
            "opinion": "The proposed PSP framework integrates structural information during both pre-training and prompt tuning, aiming to construct more accurate prototype vectors.",
            "innovation": "PSP innovatively employs dual-view contrastive learning to align node attributes and graph structure, enhancing the effectiveness of prototype learning in both homophilous and heterophilous graphs."
        },
        "method": {
            "method name": "Pre-training and Structure Prompt Tuning",
            "method abbreviation": "PSP",
            "method definition": "PSP is a framework that combines pre-training and prompt tuning for GNNs, utilizing structural information to improve the accuracy of class prototype vectors.",
            "method description": "The method unifies pre-training and prompt tuning stages while leveraging structural information to enhance few-shot learning performance.",
            "method steps": [
                "1. Dual-view contrastive learning for pre-training using node attributes and graph structure.",
                "2. Adding class prototype vectors as virtual nodes in the graph with structural connections.",
                "3. Optimizing prototype embeddings during prompt tuning using a contrastive loss."
            ],
            "principle": "The method is effective because it integrates both labeled and unlabeled data through structural prompts, allowing for better representation learning in few-shot scenarios."
        },
        "experiments": {
            "evaluation setting": "Extensive experiments were conducted on 11 benchmark datasets, including both homophilous and heterophilous graphs, to evaluate the performance of PSP in node and graph classification tasks.",
            "evaluation method": "The performance of PSP was assessed by comparing its accuracy against several state-of-the-art approaches in node classification and graph classification under various settings, including few-shot learning."
        },
        "conclusion": "The proposed PSP framework significantly outperforms existing methods on both homophilous and heterophilous graphs in few-shot scenarios, demonstrating its effectiveness in bridging the gap between pre-training and prompt tuning.",
        "discussion": {
            "advantage": "PSP effectively utilizes structural information to improve the accuracy of class prototype vectors, leading to superior performance in few-shot learning tasks.",
            "limitation": "The method may still face challenges in extremely heterogeneous graphs or scenarios where the underlying graph structure is not well-defined.",
            "future work": "Future research could explore further enhancements in leveraging structural information and expanding the framework's applicability to more complex graph structures."
        },
        "other info": {
            "acknowledgement": "This work is supported by National Natural Science Foundation of China No. 62202172 and Shanghai Science and Technology Committee General Program No. 22ZR1419900.",
            "code": "The implemented code is available at https://github.com/gqq1210/PSP."
        }
    },
    "mount_outline": [
        {
            "section number": "2.1",
            "key information": "The problem addressed is the effective adaptation of Graph Neural Networks (GNNs) in few-shot learning scenarios, particularly the challenge of accurately constructing class prototype vectors with limited labeled data."
        },
        {
            "section number": "2.2",
            "key information": "PSP is a framework that combines pre-training and prompt tuning for GNNs, utilizing structural information to improve the accuracy of class prototype vectors."
        },
        {
            "section number": "3.1",
            "key information": "PSP innovatively employs dual-view contrastive learning to align node attributes and graph structure, enhancing the effectiveness of prototype learning in both homophilous and heterophilous graphs."
        },
        {
            "section number": "6.4",
            "key information": "The method may still face challenges in extremely heterogeneous graphs or scenarios where the underlying graph structure is not well-defined."
        },
        {
            "section number": "7.1",
            "key information": "Future research could explore further enhancements in leveraging structural information and expanding the framework's applicability to more complex graph structures."
        }
    ],
    "similarity_score": 0.5318432048712312,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-0746_artif/papers/PSP_ Pre-Training and Structure Prompt Tuning for Graph Neural Networks.json"
}