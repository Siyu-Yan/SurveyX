{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2405.05445",
    "title": "Large Language Model Enhanced Machine Learning Estimators for Classification",
    "abstract": "Pre-trained large language models (LLM) have emerged as a powerful tool for simulating various scenarios and generating output given specific instructions and multimodal input. In this work, we analyze the specific use of LLM to enhance a classical supervised machine learning method for classification problems. We propose a few approaches to integrate LLM into a classical machine learning estimator to further enhance the prediction performance. We examine the performance of the proposed approaches through both standard supervised learning binary classification tasks, and a transfer learning task where the test data observe distribution changes compared to the training data. Numerical experiments using four publicly available datasets are conducted and suggest that using LLM to enhance classical machine learning estimators can provide significant improvement on prediction performance.",
    "bib_name": "wu2024largelanguagemodelenhanced",
    "md_text": "# Large Language Model Enhanced Machine Learning Estimators for Classification\nYuhang Wu1, Yingfei Wang2, Chu Wang3, and Zeyu Zheng1 1Department of Industrial Engineering and Operations Research, University of California Berkeley 2Foster School of Business, University of Washington 3Amazon\nYuhang Wu1, Yingfei Wang2, Chu Wang3, and Zeyu Zheng\nPre-trained large language models (LLM) have emerged as a powerful tool for simulating various scenarios and generating output given specific instructions and multimodal input. In this work, we analyze the specific use of LLM to enhance a classical supervised machine learning method for classification problems. We propose a few approaches to integrate LLM into a classical machine learning estimator to further enhance the prediction performance. We examine the performance of the proposed approaches through both standard supervised learning binary classification tasks, and a transfer learning task where the test data observe distribution changes compared to the training data. Numerical experiments using four publicly available datasets are conducted and suggest that using LLM to enhance classical machine learning estimators can provide significant improvement on prediction performance.\n# 1. Introduction\nClassification is a fundamental task in supervised machine learning, common across a wide array of applications. It involves training a model on a dataset where each instance is assigned a specific class label. When presented with a new, unlabeled instance, the trained model is expected to accurately predict the instance\u2019s class. To illustrate, consider a classification problem aimed at predicting whether a customer will find a product relevant online. In this problem, each instance involves two-fold information on (i) customer needs, e.g., reflected by the search queries of the customer and other attributes, and (ii) product attributes, including title, description, and/or images of the product. In the training dataset, each instance is labelled with one of the two classifying categories: \u201crelevant\u201d or \u201cnot relevant\u201d. There are a wide range of well-established machine learning methods for such classification tasks, ranging from logistic regression, tree-based methods, to neural-networks, among many other; see Efron and Hastie (2021). These methods are typically trained and calibrated using the training dataset. Once trained, they serve as estimators to predict the labels of new, unlabeled instances. On the other hand, the emergence of pre-trained large language models (LLMs) offers an additional approach to these classification tasks, capable of functioning as estimators with or without additional fine-tuning on task-specific data. For instance, GPT Radford et al. (2018) by OpenAI\ncan serve as an estimator by simply taking an instance (comprising customer query and product information) as input and generating a prediction on whether the product is relevant to the customer\u2019s needs. Moreover, prompt engineering and fine-tuning can further enhance the model\u2019s performance on specific classification tasks. This work is motivated by the following questions. Can we integrate LLM to classical machine learning methods to significantly enhance the performance, compared to the separate use of LLM or the separate use of a classical machine learning model? What are the different ways of doing such integration, and how do they perform compared to benchmarks? We deliver the following results and analysis in this work. 1. We analyze the linear combination of an LLM model and a machine learning (ML) model. We observe that generally LLM predictions are more reliable than that of a machine learning model on borderline data. We then develop an adaptive weighted linear combination of LLM and ML to further enhance the performance via the heavier use of LLM on those regions where ML shows less confidence. 2. By treating LLM predictions as additional group information, we apply model calibration methods to classical machine learning models. This method is straightforward to carry out and can be used upon any classical machine learning model. 3. We consider the integration of LLM and ML on a transfer learning classification tasks. For the transfer learning task with covariate shift, we improve the machine learning model by augmenting the training data with additional samples from the target distribution, where the labels of those samples are generated by LLM. We then train a machine learning model on the augmented dataset to obtain better performance on the target distribution. 4. We illustrate the empirical performances of our methods on four public datasets, including tasks such as relevance prediction, emotion recognition and hate speech detection. Numerical results show that all our methods perform better than only using LLM or only using a classical machine learning model. We would like to add some discussions before proceeding to the main sections of this work. The advantage of leveraging LLMs to enhance classical ML methods comes from two primary sources. Firstly, LLMs can serve as a variance reduction tool in addition to a classical machine learning model trained on the dataset. The use of LLMs in this context draws a close analogy to the method of control variates as a variance reduction tool in simulation literature; refer to Asmussen and Glynn (2007). We also note that the use of LLM in a classical data-driven method creates additional needs for input data uncertainty analysis, and leave that for future discussions; see Song et al. (2014), Feng and Song (2019). Secondly, LLMs can enhance model accuracy by leveraging their knowledge on a broader range of data; see M\u00f8ller et al. (2023), Gao et al. (2023), Chen et al.\n(2024). This aspect is particularly beneficial for improving classical ML models in transfer learning tasks.\n# 2. Problem formulation and notation\nIn this work, we focus on binary classification problems, using the task of predicting relevance as a representative example to illustrate our approach. The mathematical formulation for this task is consistent with other tasks, and we will further discuss in the numerical experiments section. The classification task is formulated as follows. The training data are given by {(queryi,producti,labeli)} n i=1. Here, queryi consists of the searching content of a customer, e.g. \u201cmodern outdoor furniture\u201d. Next, producti consists of a set of product information that includes product description, product features and possibly product image. The labeli denoted the true relevance label of \u201crelevant\u201d or \u201cirrelevant\u201d, usually obtained by manual annotation validated by several independent human annotators. For classification tasks, embeddings are utilized to derive embedded vectors of queryi and producti, denoted by vi1 \u2208Rd1,vi2 \u2208Rd2. The feature covariate xi is then given by concatenating vi1 and vi2 as xi = concat(vi1,vi2) \u2208Rd, where d = d1 + d2. In text-based classification, it\u2019s also common to concatenate text strings using a special token before vectorization. We do not consider the fine-tuning of LLM at this stage, and simply consider the integration of a simple machine learning model and a pre-trained LLM model without fine tuning. The training dataset is then given by Dtrain = {(xi,yi)} n i=1, where xi (1 \u2264i \u2264n) \u2208Rd are features and yi (1 \u2264i \u2264n) \u2208{0,1} are the relevance label. Here it is set that yi = 0 if labeli is relevant, and yi = 1 for the irrelevant label. This formulation is generic for a wide range of binary classification problems. One can train a classical machine learning model \u02c6fn(\u00b7) on Dtrain, where \u02c6fn : Rd \u2192[0,1] maps the feature xi to a score between 0 and 1, where the score represents the chance of irrelevance. If \u02c6yi = \u02c6fn(xi) \u22640.5, one predicts \u201crelevant\u201d and otherwise \u201cirrelevant\u201d. The test set is given by Dtest = {(xi,yi)}n+m i=n+1 and a trained machine learning model is evaluated by Ltest = 1 m \ufffdn+m i=n+1 l (yi, \u02c6yi) for some loss function l(\u00b7,\u00b7). In addition to the classical machine learning model, in this work we also use a pre-trained large language model (LLM) to predict yi. The LLM is given the input of a query-product pair and asked to output a score between 0 and 1 representing how likely the LLM evaluates the query and product as irrelevant. We denote the output of LLM for the i-th pair as zi \u2208[0,1] for i = 1,\u00b7\u00b7\u00b7 ,n + m.\n# 3. Integrating LLM into a Classical ML Estimator\nOne naive way to utilize LLM is to treat it as a trained model, so zi (1 \u2264i \u2264n + m) are jus estimators of yi (1 \u2264i \u2264n + m), in addition to the classical trained machine learning (ML) model\ne.g., logistic regression. Then a first thought is to combine the two models (LLM and classical ML) to create a better ensemble model (noted as LLM-ML in this work). This is a standard combination task and can be executed by several methods. We illustrate such combination task by examining a simple linear combination of ML and LLM estimators. We first discuss a straightforward approach using a fixed constant weight. We then demonstrate through empirical data analysis that the performance can be enhanced by employing an adaptive weighting strategy, which adjusts the weights according to the prediction scores generated by the ML estimator. Such adaptive weighting strategy carries the thought that LLM may be more heavily used for instances where the classical ML is not that certain of.\n3.1. Linear combination of ML and LLM estimators To combine the ML estimator and LLM estimator, one simple method is to consider the linear combination with constant weight, i.e.,\nTo combine the ML estimator and LLM estimator, one simple method is to consider the linear combination with constant weight, i.e.,\nwith some weight \u03b1 \u2208[0,1]. The choice of \u03b1 can be determined through standard cross validation procedure as follows. By randomly splitting Dtrain as \u222ak i=jDj train for some k \u2208N+, we can train k machine learning models \u02c6f j n(\u00b7) for j = 1,\u00b7\u00b7\u00b7 ,k, where \u02c6f j n(\u00b7) is trained on \u222ak i=1,i\u0338=jDi train. Then the best weight \u03b1\u2217is given by\nIf we omit the superscript j and denote \u02c6f j n(xi) by \u02c6ycv i , for the l2 loss l(x,y) = (x\u2212y)2, this procedure is equivalent to regress {yi \u2212zi}n i=1 on {\u02c6ycv i \u2212zi}n i=1, which gives \u02c6\u03b1l2 n = \ufffdn i=1(yi\u2212zi)(\u02c6ycv i \u2212zi) (\u02c6ycv i \u2212zi)2 . Informally speaking, if we assume (xi,zi,yi) i.i.d. \u223cP for some distribution P on Rd \u00d7 [0,1]2, and assume that \u02c6fn converges to some f0 as n \u2192+\u221e, then we will have\nwhich is the minimizer of the mean-squared error MSEL(\u03b1) = E[\u03b1f0(X) + (1 \u2212\u03b1)Z \u2212Y ] 2 , so MSEL(\u03b1\u2217) \u2264MSEL(0) = E(Z \u2212Y )2 and MSEL(\u03b1\u2217) \u2264MSEL(1) = E(f0(X) \u2212Y )2, which means the asymptotic behaviour of the LLM-ML ensemble estimator is no worse than two baseline estimators\nwhich is the minimizer of the mean-squared error MSEL(\u03b1) = E[\u03b1f0(X) + (1 \u2212\u03b1)Z \u2212Y ] 2 , so MSEL(\u03b1\u2217) \u2264MSEL(0) = E(Z \u2212Y )2 and MSEL(\u03b1\u2217) \u2264MSEL(1) = E(f0(X) \u2212Y )2, which means the asymptotic behaviour of the LLM-ML ensemble estimator is no worse than two baseline estimators. 3.2. Linear combination with adaptive weights One can improve this method by taking \u03b1 to be dependent on \u02c6yi as \u03b1(\u02c6yi). Consider the following visualization results in Figure 1. Here t-SNE Hinton and Roweis (2002) is a statistical method\nOne can improve this method by taking \u03b1 to be dependent on \u02c6yi as \u03b1(\u02c6yi). Consider the following visualization results in Figure 1. Here t-SNE Hinton and Roweis (2002) is a statistical method\n(1)\n(2)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/dea5/dea53598-da9d-42f1-a0e9-bb6cc84e4c14.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1 t-SNE visualization of an illustration data set</div>\nfor visualizing high-dimensional data by giving each sample a location in a two-dimensional map. We can see the classical machine learning model sometimes does not do well on the boundary of relevant samples and irrelevant samples, and many of such errors are made when the prediction score \u02c6yi is close to 0.5. On the contrary, the LLM model shows different patterns, in the sense that its accuracy is relatively stable even for those borderline data. We refer to the red circles in the figure for some illustration. This motivates us to take \u03b1(\u02c6yi) to be larger when \u02c6yi is close to 0 or 1, and if \u02c6yi is close to 0.5, which indicates xi is likely to located on the boundary, we set it to be smaller. In this case, the LLM-ML estimator is given as an adaptive weighted linear combination of two estimator:\n\u02c6yAL i = \u03b1(\u02c6yi) \u00b7 \u02c6yi + (1 \u2212\u03b1(\u02c6yi)) \u00b7 zi.\nWe would expect \u03b1(\u00b7) : [0,1] \u2192[0,1] to be a decreasing function on [0,0.5], and then increases on [0.5,1]. By taking a predetermined hypothesis space A \u2282{\u03b1|\u03b1 : [0,1] \u2192[0,1]} for all possible choices of \u03b1(\u00b7) we are interested, the choice of \u03b1(\u00b7) can similarly be determined through cross validation as what we just did for a fixed \u03b1. To see this, we can now modify (2) as:\n(3)\nwhere \u02c6ycv i = \u02c6f j n(xi) and by slightly abusing the notation \u02c6\u03b1n is now a function in A. We now consider the choice of A. A large A such as all continuous functions from [0,1] to [0,1] {\u03b1|\u03b1 : [0,1] \u2192[0,1],\u03b1 \u2208C} will make the optimization problem in (4) intractable and can easily lead to overfit, but a simple A such as all constant functions on [0,1] will just give a fixed weight and cannot fully use the strength of LLM. In this work, we consider the class of piecewise constant functions, i.e.\n\ufffd here r \u2208N+ is a pre-determined positive integer and Ii(1 \u2264i \u2264r) is a partition of [0,1]. For simplicity, we take Ii = [ i\u22121 r , i r) for 1 \u2264i \u2264r \u22121 and Ir = [ r\u22121 r ,1]. In this case, (4) can now be formulated as:\n\ufffd here r \u2208N+ is a pre-determined positive integer and Ii(1 \u2264i \u2264r) is a partition of [0,1]. For simplicity, we take Ii = [ i\u22121 r , i r) for 1 \u2264i \u2264r \u22121 and Ir = [ r\u22121 r ,1]. In this case, (4) can now be\nThis is equivalent to solve r optimization problems for samples with indices in {i|\u02c6ycv i \u2208Ij}(j = 1,\u00b7\u00b7\u00b7 ,r) separately, and each of them is what we just discussed in last part. If we are using l2 loss then clearly this piecewise constant weight function gives an MSE no larger than any fixed constant weight.\n# 4. Calibration with LLM\nIn this section, we consider calibrating a classical ML model (e.g., logistic regression) with LLM. We start by introducing some backgrounds on calibration, then we discuss how to use LLM to calibrate a classical ML model.\n(4)\n(5)\n(6)\n# 4.1. Background on calibration Suppose our data are realizations of (X,Y ) \u223cD with Y \u2208{0,1}, and the model is f. Ideally, we hope to find a model such that\n# Suppose our data are realizations of (X,Y ) \u223cD with Y \u2208{0,1}, and the model is f. Ideally, we hope to find a model such that\nf(x) = P(Y = 1|X = x). (Informally)\nHowever, this is generally unrealistic and there are at least two reasons. First, for each fixed x, the label is already determined, and there is no randomness so the probability in the RHS is not well-defined. Second, the domain of X in our scenario consists of pairs of query and item, and each of them comes from an extremely large set of English words, so it is generally impossible to find such a function with limited samples. Calibration is a tractable condition that can be viewed as a coarsening of the condition above. Definition 1. (Calibration) For (X,Y ) \u223cD, the bias of f at the p-th level set is defined as\n\u2206p(f) \u225cED[Y \u2212f(X)|f(X) = p].\nIf \u2206p(f) \u22610, we say that f is calibrated w.r.t. D. We omit the subscript D when there is no\nIf \u2206p(f) \u22610, we say that f is calibrated w.r.t. D. We omit the subscript D when there is no ambiguity. Intuitively, calibration can be considered as a minimal condition for a model f to be good, in the sense that the probability of Y = 1 conditional on f(x) = p is indeed p. For each model f, if it is not calibrated, we can define \u02c6f(x) = f(x) + \u2206f(x)(f) and it is straightforward to verify that \u02c6f is calibrated. However, it is infeasible to conditional on f(X) = p in practice with finite samples, and a simple strategy is to do discretization on a uniform grid and calibrate f on the grid. Specifically, we define the uniform grid [ 1 M ] = { i m}M i=0 for some M \u2208N+, and define\n# This rounds the output of f to the grid [ 1 M ] and can be viewed as a discretization of [0,1]. Now, for our data {(xi,yi)}n i=1, we can construct the calibration of f as\nThis rounds the output of f to the grid [ 1 M ] and can be viewed as a discretization of [0,1]. Now, for our data {(xi,yi)}n i=1, we can construct the calibration of f as\n\u02c6f (M)(x) = f(x) + \u02c6\u2206f\u2032(x)(f),\nwhere \u02c6\u2206f\u2032(x)(f) can be estimated through data by calculating the mean of yi \u2212f(xi) conditional on the value of f \u2032(xi). We refer to Roth (2022) for more theoretical results of \u02c6f (M).\nAbove calibration procedure only involves the model f, and we now integrate LLM into this procedure. In this scenario, we assume our data are realizations of (X,Z,Y ) \u223cP, where Z \u2208[0,1] is the output of LLM. We have a ML model f and we want to use it to construct a improved\n(7)\n(8)\n(9)\n(10)\nmodel, which takes X and Z as inputs and generates a prediction for Y . We start by introducing an enhanced version of Definition 1, which is also known as the \u201cmulti-accuracy\u201d condition in Kim et al. (2019). Definition 2. (Multi-accuracy with LLM) Suppose (X,Z,Y ) \u223cP, A model f is multi-accurate w.r.t. Z if\nIf we treat Z as a covariate, then Definition 2 can be viewed as a condition for a model f to be consistent conditional on the covariate. Now, with both Definition 1 and 2, we want to construct some \u02c6f M,M\u2032 from f such that \u02c6f M,M\u2032 is calibrated and multi-accurate. Again it is infeasible to conditional on Z if Z is continuously distributed with finite samples, so we consider a discretization similar as what we did in (9). Let [ 1 M\u2032 ] = { i m}M i=0 for some M \u2032 \u2208N+, and define\n\ufffd\ufffd for p = i M (0 \u2264i \u2264M) and q = j M\u2032 (0 \u2264j \u2264M \u2032). Also define\n\ufffd \ufffd Then one simple way to construct some \u02c6f M,M\u2032 is to make sure \u2206p,q( \u02c6f M,M\u2032,f) = 0 for all p,q. Informally speaking, if \u2206p,q( \u02c6f M,M\u2032,f) = 0 for all p,q then \u02c6f M,M\u2032 is calibrated and multi-accurate up to some discretization error. This naturally leads to the following choice:\nwhere\n\ufffd is the empirical mean of Y \u2212f(X) conditional on Sp,q(f) with samples in the training set. Then if we assume {(xi,zi,yi)}n+m i=1 i.i.d. \u223cP, we have\nwhich is exactly what we want. While (14) gives one way to construct a function that is both calibrated and multi-accurate up to some discretization error, the problem is that it involves calculating (M + 1) \u00d7 (M \u2032 + 1)\n(11)\n(12)\n(13)\n(14)\n(15)\n(16)\nconditional means for Sp,q(f). When M and M \u2032 are large, this quantity may be of the same order of the sample size n or even larger, making the estimation of conditional means not precise enough This motivates the following choice. We take\nwhere \u02c6wi,0(0 \u2264i \u2264M) and \u02c6wj,1(0 \u2264j \u2264M \u2032) are determined by the following optimization problem:\nSince this is a least square linear regression problem, the solution always exists. For any solution the optimality conditions give:\nso E \ufffd Y \u2212\u02c6f M,M\u2032 2 (X) \ufffd\ufffd\ufffdf \u2032(X) \ufffd = 0, which implies \u02c6f M,M\u2032 2 is calibrated up to some discretization error. Similarly, it is also multi-accurate up to some discretization error. The construction of \u02c6f M,M\u2032 2 only requires the estimation of M + M \u2032 + 2 parameters, which is much smaller than (M + 1) \u00d7 (M \u2032 + 1) parameters for \u02c6f M,M\u2032 1 , and can thus mitigate issues such as large estimation error and overfitting in \u02c6f M,M\u2032 1 .\nAlgorithm 2 Calibrate ML model with LLM\n1: Input: Dtrain = {(xi,zi,yi)}n\ni=1, M,M \u2032 \u2208N+;\n2: Train a ML model f(\u00b7) on {(xi,yi)}n\ni=1.\n3: Output: the calibration of f(\u00b7) given by \u02c6f M,M\u2032\n1\n(\u00b7) in (14) or \u02c6f M,M\u2032\n2\n(\u00b7) in (17).\n# 5. Transfer learning with LLM\nRecall that in Figure 1 we saw that LLM can perform more stable than a classical ML model, this motivates us to apply LLM to transfer learning, where the training distribution of the model can be different from that of its application. Such transfer learning tasks can be challenging to a classical ML model. Again consider the relevance label prediction task, suppose that there are no or very few samples in the labeled training set that contains products related to \u201cbed\u201d, but the test datasets contain a large number of products related to \u201cbed\u201d. This can happen in applications where a new type of product is introduced to the platform. We would expect that the classical ML model may not do well on the test datasets because the model has not seen much information about \u201cbed\u201d. One\n(17)\n(18)\n(19)\npossible remedy is to utilize LLM to augment the training set for the bed category by adding data labeled with predictions from the LLM. This can be formulated as follows. Suppose we have a training set Dtrain = {(xi,yi)}n i=1 i.i.d. \u223cP1, and we train a ML model \u02c6fn \u2208F on Dtrain for some model class F. We want to evaluate its performance by its expected loss on P2 w.r.t. some loss function l: E(X,Y )\u223cP2 \ufffd l( \u02c6fn(X),Y ) \ufffd . Here we assume P1 = PX,1 \u00d7PY |X and P2 = PX,2 \u00d7PY |X, where PX,l (l = 1,2) are two distributions of X on its domain X and the conditional distribution of Y |X is given by PY |X and is the same for P1 and P2. This scenario is usually referred as covariate shift Sugiyama et al. (2007). While we do not have other labeled training data, we are accessible to sample more X as we want, that is to say, we can augment the training set by adding {(xi,zi)}n+m i=n+1 for some xi and m \u2208N+ as we want. With the augmented training set, we can train a new ML model \u02c6fn,m as follows:\nHere l(\u00b7,\u00b7) is the loss we are interested, and l0(\u00b7,\u00b7) is some weak-supervised loss that can be viewed as a relaxation of l(\u00b7,\u00b7). The rational is that the label of {xi}n+m i=n+1 are generated from LLM and may be biased and noisy, so a relaxed loss such as l0(x,y) = min\u03b5\u2208[\u2212a,a] l (x,y + \u03b5) for some a \u22650 gives looser penalization on those samples. Regarding the choice of {xi}n+m i=n+1, suppose we sample them from some distribution PX,3. Let the probability density function of PX,3 be pi(x) for i = 1,2,3, then in the ideal case we would expect\nwhich then gives a choice of P3 as\nHowever, in order to make sure p3(x) \u22650, we need m \u2265supx p1(x)\u2212p2(x) p2(x) n. When the quantity in the RHS is large, we will need lots of labels generated from LLM, which may not be a reasonable choice. In the extreme scenario that p2(x) = 0 and p1(x) > 0, it is impossible to find a p3(x) \u2208[0,1] satisfying (22). Thus, in these scenarios, a heuristic choice such as p3(x) \u221dmax \ufffd p2(x) + n m (p2(x) \u2212p1(x)),0 \ufffd or simply p3(x) = p2(x) may be better. In Section 6.3, we illustrate our method in the scenario that the supports of p1(\u00b7) and p2(\u00b7) are disjoint, and we show that a naive choice of p3(x) = p2(x) can already significantly improve the performance of the classical machine learning model.\n(20)\n(21)\n(22)\nAlgorithm 3 Transfer learning with LLM\n1: Input: Dtrain = {(xi,zi,yi)}n\ni=1 and a training distribution P1, a target distribution P2, m \u2208N+;\n2: Choose a sampling distribution PX,3 based on P1 and P2, sample {xi}n+m\ni=n+1.\n3: Label {xi}n+m\ni=n+1 with LLM to obtain {(xi,zi)}n+m\ni=n+1\n4: Train a ML model \u02c6fn,m on {(xi,yi)}n\ni=1 \u222a{(xi,zi)}n+m\ni=n+1.\n5: Output: \u02c6fn,m.\n2: Choose a sampling distribution PX,3 based on P1 and P2, sample {xi}n+m i=n+1. 3: Label {xi}n+m i=n+1 with LLM to obtain {(xi,zi)}n+m i=n+1 4: Train a ML model \u02c6fn,m on {(xi,yi)}n i=1 \u222a{(xi,zi)}n+m i=n+1. 5: Output: \u02c6fn,m.\n6. Numerical experiments We now illustrate the performances of the proposed LLM-ML integration methods through numerical experiments with public datasets. In Section 6.1, we provide the information of the datasets in use. In Section 6.2, we compare the performances of the proposed methods in Section 3 and 4. In Section 6.3, we consider the transfer learning task in Section 5. Our code is available at https://github.com/wyhArturia/llm_enhanced_ml. 6.1. Datasets We illustrate our methods on four public datasets. For predicting relevance labels, we use the Wayfair Annotation DataSet (WANDS) Chen et al. (2022). WANDS is a discriminative, reusable, and fair human-labeled dataset. It is one of the biggest publicly available search relevance dataset and is effective in evaluating and discriminating between different models. It consists of 480 queries, 42994 products, and 233000 annotated query-product relevance labels. We also use the following three public datasets: Yelp\u2019s dataset (https://www.yelp.com/dataset), Emotion dataset Saravia et al. (2018) and Hate speech dataset De Gibert et al. (2018). All of them are NLP classification tasks and have similar formulations as the relevance label prediction task as described in the manuscript. 6.2. Combined estimators and calibration with LLM We first illustrate the LLM-ML combined estimators in Section 3 and the calibrated estimators in Section 4 on four datasets. We randomly split each dataset into a training set and a testing set, and we compare the performances of following methods on testing sets: 1. The large language model method (LLM): directly use GPT-3.5-Turbo-Instruct to classify the input instance. The prompt for each task consists of step-by-step instructions such as key indicators, evaluation rules, examples and quality checks. All prompts are provided in our code. 2. The machine learning method (ML): for each training set which consists of word vectors and labels, we train a logistic regression model and apply it to the testing set for predictions. We use this simple machine learning model for illustration purposes, as we are mainly focus on how to use LLM to improve the ML model instead of the performance of the ML model.\n3. Naive linear combination of LLM and ML methods (Linear): our method in Section 3.1 that uses a linear combination of LLM and ML estimators with a fixed weight. The weight is estimated through least square method on the training set. 4. Adaptive weighted linear combination (AdaLinear): our method in Section 3.2 that uses a linear combination of LLM and ML estimators with a piecewise constant weight function. The weight function is estimated through least square method on the training set. The number of pieces r is also tuned on the training set, but its value will not affect the performance too much as long as it is not too small (r = 1) or too large (r > 20). 5. Calibrated estimator with LLM (Calibration): our method in Section 4.2 that calibrates the ML estimator with LLM predictions. Since our LLM predictions are binary, we take M \u2032 = 2. The value of M is tuned on the training set. We use the construction in (14) for simplicity. The results are given as follows:\n<div style=\"text-align: center;\">Test accuracy of different methods on four datasets</div>\nTable 1\nTest accuracy of different methods on four datasets\nLLM\nML\nLinear AdaLinear(r) Calibration(M)\nWANDS\n0.775\n0.803\n0.838\n0.846(4)\n0.840(10)\nYelp\n0.724\n0.691\n0.739\n0.742(4)\n0.743(20)\nEmotion\n0.759\n0.799\n0.806\n0.812(10)\n0.806(10)\nHate\n0.672\n0.717\n0.720\n0.724(4)\n0.731(12)\nFrom the above results we can see that, on all four datasets, our three methods (Linear, Ada Linear and Calibration) that utilizing both ML and LLM estimators perform better than only use LLM or ML. The AdaLinear method performs better than the Linear method, which is reasonable as Linear is a special case of AdaLinear. AdaLinear and Calibration have comparable performances indicating that both model ensemble and calibration are reasonable ways to enhance ML models with LLM.\n# 6.3. Transfer learning with LLM\n6.3. Transfer learning with LLM We now consider the task of transfer learning with LLM in Section 5. In order to illustrate the performance of our method, we manually construct a table dataset and a bed dataset from the WANDS dataset and are provided in our code. We compare the performances of following methods on testing sets: 1. The large language model method (LLM): directly use GPT-3.5-Turbo to classify the input instances, similar as that in Section 6.2. 2. The machine learning model for the table dataset (MLTable): we train a logistic regression model on 1000 word vectors in the table dataset. We would expect this ML model works well on the table dataset, but may not do well on the bed dataset.\n3. Naive linear combination of LLM and ML methods (Linear): our method in Section 3.1 that uses a linear combination of LLM and MLTable methods with a fixed weight, similar as that in Section 6.2. We use this as one baseline method. The reason we do not use an adaptive weight function is that, we can only calculate the weight function on the training set, which can lead to overfitting as the target distribution is different from the training set. 4. The transfer learning method with LLM discussed in Section 5 (Transfer(m)): we randomly add m bed samples and corresponding labels generated by LLM into our table dataset, then train a logistic regression model on all 10000 + m word vectors. With the notations in Section 5, this is equivalent to take p3(x) = p2(x). We uses a table testing set and a bed testing set to evaluate these methods. The results are given as follows:\n<div style=\"text-align: center;\">Table 2 Test accuracy of four methods on two datasets</div>\nLLM MLTable Linear Transfer(5000) Transfer(10000) Transfer(15000)\nTable\n0.738\n0.915\n0.923\n0.910\n0.910\n0.911\nBed\n0.753\n0.721\n0.737\n0.784\n0.786\n0.786\nWe can see that the Transfer method always performs better than LLM and MLTable on the bed dataset with a small sacrifice on its performance on the table dataset, regardless of the choice of m. However, the choice of m is subtle and can still affect the performance of our method. The linear combination of LLM and MLTable can perform well on the table dataset, but is not robust to the covariate shift and is not as good as our Transfer method on the bed dataset.\nlinear combination of LLM and MLTable can perform well on the table dataset, but is not robust to the covariate shift and is not as good as our Transfer method on the bed dataset. 7. Conclusion We conclude the work by discussing some unexplored aspects of this work. Our goal is to show that LLM can enhance a classification machine learning method for classification problems. We have selected the standard logistic regression method as the benchmark machine learning method. We believe that the exact size of improvement brought by LLM will vary by choosing different machine learning methods as benchmark. Also, the performance of LLM can vary by using different prompts. We did not push on prompt engineering to figure out the best way to design prompts to max out the LLM potential. The proposed approaches in this work may be further expanded by integrating prompt engineering and fine tuning with certain training data.\n# 7. Conclusion\n# References\nAsmussen S, Glynn PW (2007) Stochastic simulation: algorithms and analysis, volume 57 (Springer). Chen Y, Liu S, Liu Z, Sun W, Baltrunas L, Schroeder B (2022) Wands: Dataset for product search relevan assessment. European Conference on Information Retrieval, 128\u2013141 (Springer).\nChen Z, Mao H, Li H, Jin W, Wen H, Wei X, Wang S, Yin D, Fan W, Liu H, et al. (2024) Exploring the potential of large language models (llms) in learning on graphs. ACM SIGKDD Explorations Newsletter 25(2):42\u201361. De Gibert O, Perez N, Garc\u00b4\u0131a-Pablos A, Cuadros M (2018) Hate speech dataset from a white supremacy forum. arXiv preprint arXiv:1809.04444 . Efron B, Hastie T (2021) Computer age statistical inference, student edition: algorithms, evidence, and data science, volume 6 (Cambridge University Press). Feng BM, Song E (2019) Efficient input uncertainty quantification via green simulation using sample path likelihood ratios. 2019 Winter Simulation Conference (WSC), 3693\u20133704 (IEEE). Gao Y, Sheng T, Xiang Y, Xiong Y, Wang H, Zhang J (2023) Chat-rec: Towards interactive and explainable llms-augmented recommender system. arXiv preprint arXiv:2303.14524 . Hinton GE, Roweis S (2002) Stochastic neighbor embedding. Advances in neural information processing systems 15. Kim MP, Ghorbani A, Zou J (2019) Multiaccuracy: Black-box post-processing for fairness in classification. Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society, 247\u2013254. M\u00f8ller AG, Aarup Dalsgaard J, Pera A, Aiello LM (2023) Is a prompt and a few samples all you need? using gpt-4 for data augmentation in low-resource classification tasks. arXiv e-prints arXiv\u20132304. Radford A, Narasimhan K, Salimans T, Sutskever I, et al. (2018) Improving language understanding by generative pre-training . Roth A (2022) Uncertain: Modern topics in uncertainty estimation. Saravia E, Liu HCT, Huang YH, Wu J, Chen YS (2018) CARER: Contextualized affect representations for emotion recognition. Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 3687\u20133697 (Brussels, Belgium: Association for Computational Linguistics), URL http: //dx.doi.org/10.18653/v1/D18-1404. Song E, Nelson BL, Pegden CD (2014) Advanced tutorial: Input uncertainty quantification. Proceedings of the Winter Simulation Conference 2014, 162\u2013176 (IEEE). Sugiyama M, Krauledat M, M\u00a8uller KR (2007) Covariate shift adaptation by importance weighted cross validation. Journal of Machine Learning Research 8(5).\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of enhancing classical supervised machine learning methods for classification problems by integrating pre-trained large language models (LLMs). Previous methods have primarily relied on traditional machine learning techniques, which often struggle in scenarios with borderline data. The emergence of LLMs presents a new opportunity to improve prediction performance significantly.",
        "problem": {
            "definition": "The problem focuses on binary classification tasks, particularly predicting the relevance of products based on customer queries and product attributes.",
            "key obstacle": "Existing classification methods often fail to provide reliable predictions on borderline data, where the distinction between classes is not clear."
        },
        "idea": {
            "intuition": "The idea stems from the observation that LLM predictions are more reliable than traditional machine learning predictions in uncertain scenarios.",
            "opinion": "The proposed idea is to combine LLMs with classical machine learning methods to improve overall prediction accuracy and reliability.",
            "innovation": "The primary innovation lies in the adaptive integration of LLM predictions with classical machine learning models, allowing for dynamic adjustments based on the confidence of the ML model."
        },
        "method": {
            "method name": "LLM-ML Integration",
            "method abbreviation": "LLM-ML",
            "method definition": "This method integrates pre-trained LLMs with classical machine learning models to enhance classification performance.",
            "method description": "The core of the method involves combining predictions from LLMs and classical ML models using adaptive weighting strategies.",
            "method steps": [
                "Train a classical machine learning model on the dataset.",
                "Obtain predictions from the LLM for the same dataset.",
                "Combine predictions using a linear combination with adaptive weights based on the confidence of the ML model."
            ],
            "principle": "The method is effective because it leverages the strengths of both LLMs and classical ML models, particularly in scenarios where the latter is less confident."
        },
        "experiments": {
            "evaluation setting": "The evaluation was conducted using four publicly available datasets, including the Wayfair Annotation DataSet (WANDS), Yelp's dataset, Emotion dataset, and Hate speech dataset. Baseline methods included traditional ML and LLM-only approaches.",
            "evaluation method": "Performance was assessed through accuracy comparisons across different methods on the test sets, and results were analyzed using numerical experiments."
        },
        "conclusion": "The experiments demonstrated that integrating LLMs with classical machine learning methods significantly improves prediction performance across various classification tasks, suggesting a promising direction for future research and applications.",
        "discussion": {
            "advantage": "The key advantages of the proposed approach include improved prediction accuracy, particularly on borderline data, and the ability to leverage LLMs as a variance reduction tool.",
            "limitation": "Limitations include potential overfitting when using adaptive weights and the reliance on the quality of LLM predictions, which may introduce noise.",
            "future work": "Future research could explore further enhancements through prompt engineering and the fine-tuning of LLMs on specific tasks to maximize their potential."
        },
        "other info": [
            {
                "info1": "The proposed methods were validated through extensive numerical experiments.",
                "info2": {
                    "info2.1": "The code for the experiments is available at https://github.com/wyhArturia/llm_enhanced_ml.",
                    "info2.2": "The methodologies can be adapted for various classification tasks beyond those studied."
                }
            }
        ]
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "This paper addresses the issue of enhancing classical supervised machine learning methods for classification problems by integrating pre-trained large language models (LLMs)."
        },
        {
            "section number": "1.2",
            "key information": "The proposed idea is to combine LLMs with classical machine learning methods to improve overall prediction accuracy and reliability."
        },
        {
            "section number": "2.1",
            "key information": "The problem focuses on binary classification tasks, particularly predicting the relevance of products based on customer queries and product attributes."
        },
        {
            "section number": "2.3",
            "key information": "The primary innovation lies in the adaptive integration of LLM predictions with classical machine learning models, allowing for dynamic adjustments based on the confidence of the ML model."
        },
        {
            "section number": "3.2",
            "key information": "The method integrates pre-trained LLMs with classical machine learning models to enhance classification performance."
        },
        {
            "section number": "4.2",
            "key information": "The core of the method involves combining predictions from LLMs and classical ML models using adaptive weighting strategies."
        },
        {
            "section number": "10.2",
            "key information": "Future research could explore further enhancements through prompt engineering and the fine-tuning of LLMs on specific tasks to maximize their potential."
        }
    ],
    "similarity_score": 0.7761163651341577,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Large Language Model Enhanced Machine Learning Estimators for Classification.json"
}