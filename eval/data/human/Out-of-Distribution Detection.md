# A Comprehensive Review of Trends, Applications and Challenges In Out-of-Distribution Detection  

Navid Ghassem $\mathrm{a}$ , Ehsan Fazl-Ersia,∗  

$_{a}$ Computer Engineering department, Ferdowsi University of Mashhad, Mashhad, Iran.  

# Abstract  

With recent advancements in artificial intelligence, its applications can be seen in every aspect of humans’ daily life. From voice assistants to mobile healthcare and autonomous driving, we rely on the performance of AI methods for many critical tasks; therefore, it is essential to assert the performance of models in proper means to prevent damage. One of the shortfalls of AI models in general, and deep machine learning in particular, is a drop in performance when faced with shifts in the distribution of data. Nonetheless, these shifts are always expected in real-world applications; thus, a field of study has emerged, focusing on detecting out-of-distribution data subsets and enabling a more comprehensive generalization. Furthermore, as many deep learning based models have achieved near-perfect results on benchmark datasets, the need to evaluate these models’ reliability and trustworthiness for pushing towards real-world applications is felt more strongly than ever. This has given rise to a growing number of studies in the field of out-of-distribution detection and domain generalization, which begs the need for surveys that compare these studies from various perspectives and highlight their straightens and weaknesses. This paper presents a survey that, in addition to reviewing more than 70 papers in this field, presents challenges and directions for future works and offers a unifying look into various types of data shifts and solutions for better generalization.  

Keywords: Dataset Shift, Domain Generalization, Out of Distribution  

Detection, Open Set Recognition, Novelty Detection, Adversarial Examples  

# 1. Introduction  

Arguably, the ultimate goal of any data scientist is to discover the underlying distribution of data through empirical analysis of available samples [1]. This originates a flaw, the assumption that samples are enough to make decisions on the shape of the underlying distribution. In reality, though, samples can be at best enough to make a model work under a closed-world assumption (an environment where the absence of information is interpreted as negative information [2]).  

The whole foundation of machine learning (ML) is based on the assumption that identically and independently distributed (i.i.d) data will be available in test time, an assumption that, sadly, can not be held true in many real-world scenarios [3]. Nowadays, ML and deep learning (DL) algorithms are used in every aspect of life. The entire closed-world and i.i.d assumptions are violated when using these algorithms in real-world scenarios. Many algorithms that have already solved their task and even have outperformed human benchmarks fail dramatically on deployment [4]. The reasoning behind their poor performance can be due to changes in data, i.e., distribution shifts.  

The effect of these changes can be seen in all types of applications, such as medical diagnosis [5] or autonomous driving [6]. Sometimes, the slightest changes in data, such as changes in weather conditions for autonomous cars, can cause the model to perform unacceptable [7]. The problem can be even more severe when models are faced with new classes of data, and then they make a certain decision about them [8]. Even some exploit similar flaws to add small perturbations, not even noticeable by the human eye, to images and mislead models to make wrong decisions [9].  

Research on solving these issues has been going on for some time. Many keywords and work directions have investigated different aspects of these problems and solutions. Interpretable and explainable decisions, Trustworthy AI,  

Open-set Recognition, Uncertainty analysis, Model Calibration, Domain Generalization, and many other directions have been investigated, aiming to make an AI system capable of withstanding challenges faced in open-world scenarios. Many researchers have already investigated these paths and come up with solutions to help toward this goal.  

This field of research still lags behind other directions and aspects of ML. There are well-known benchmarks for making a model for image classification, and nearly all papers and works agree on metrics, notation, and evaluations. However, in distribution shifts, still many papers differ from others in these terms, making their comparison more difficult; thus, more works are considered parallel instead of building on top of another. Lack of a unified definition, notation, and benchmarks are all parts of the problems.  

The main objective of this survey is to bring together a review of important works to unify different methodologies and looks at the problem at hand and serve as a starting point for researchers and ultimately and hopefully, pave the path for the creation of robust and trustworthy AI systems. To carry out these goals, we have reviewed more than 70 papers and focused on top-tier venues such as NeruIPS and ICML and prestigious journals to review important works and ideas. The primary objectives of this work are as follows :  

• Introducing a notation and a graphical model to look at distribution shifts • Reviewing datasets, benchmarks and metrics to create a more plug-andplay mean for researchers in this field • Analysing trends and importance of each research direction in this field • Investigating challenges and possible future directions  

The rest of the paper is structured as follows. First, the search strategy for finding papers is presented in the next section of the paper. The third section of the paper is devoted to presenting the history and related works; the description of the main ideas of methods is presented here. Next, a section is added on notation and definitions. A review of papers is presented in section five, with section six discussing challenges and future directions based on these papers. Lastly, section seven concludes the paper.  

# 2. Search Strategy and Review Structure  

To properly form this survey, we categorized our scope of work into four different problems and then searched for papers in each. For every category, a subsection is assigned to investigate different aspects of the problem and its applications. Description of datasets and benchmarks, remarkable ideas, and review of papers are presented here. These subsections are formed as disjoint as possible, so readers can focus on the problem they intended with the least amount of reading possible. Keywords were selected for each problem empirically by analyzing keywords of a few prior works, all of which are listed in subsections of section 5. For each problem, 15-20 papers are reviewed, making a total of 70 papers. Papers are selected in a way to represent essential aspects of their group. To this end, we have selected papers in a way that:  

• Most cited papers (cite/year) • Recent papers (2020-2022) • Important and remarkable works • Different applications and data type  

To select a diverse group of papers to represent various ideas, trends, and applications of each category, we have selected them from top-tier venues such as ICML and NeurIPS and prestigious journals. The last search for the paper was conducted on Aug 31st, 2022, and search keywords were selected empirically by analyzing keywords of a few related works for each problem.  

# 3. Related Work and History  

Analyzing shifts in the distribution of data and finding instances different from the rest of the dataset is not a recent trend, and its footstep can be found in older literature; in different names such as concept drift [10] and concept shift [11], outlier, and novelty detection [12], and covariate shift [13] to name a few. An influential paper by Moreno-Torres et al. [14] in 2012 tried to unify the notation used to describe dataset shifts in classification problems and gave a comprehensive analysis of the causes of each type of shift.  

The number of papers and works done to tackle challenges in the field implies how important these issues are, yet the path to solving all these issues is still long. The course of research also dramatically changed in the era of deep learning, as the models could process massive datasets. Moreover, many deep learning methods have already passed human benchmarks, and they are one step closer to being used for real-world applications; however, the nature of distribution shifts in open-world scenarios can hold them back. This has drawn the attention of many researchers in recent years toward this field.  

OOD samples and distribution shifts can occur due to many factors; the first one being changes in the environment, such as changes in weather, e.g., the model is trained on images taken on sunny days, then tested in rainy conditions. Another simple and well-known example is day-vs-night images. Detecting changes also might become harder, such as differences between images produced by imaging devices of different hospitals. As long as these changes are predictable, data augmentation (DA) can help the model to generalize well to them, yet they are not always known, or creating a DA method for them is complicated. One example is the transformation of real images to sketches, which is easily achievable by extracting edges; however, the reverse is significantly harder. In the past few years, some models have achieved extraordinary performances for the unpaired image-to-image classification, such as CycleGAN [15] which has shed light on creating working DA methods, but unaccounted changes in the environment still remain an issue in need of handling.  

The following reason behind these shifts can be seen in changes in the nature of events. A model trained to classify between different types of brain tumors does not anticipate any data points not to have tumors or to have other types of disease, and they are also generally not evaluated on outlier data points.  

Nonetheless, when faced with new types of data, they may produce results with high certainty. There are simple methods taken for tackling this challenge, such as introducing outliers as another class to the model, yet the number of possibilities for other events might become countless, particularly for problems such as face recognition.  

After events and environmental changes, the most recognized and infamous cause behind OOD samples is noise. Having a source of noise affecting data is generally inevitable, and it is also usually accepted and accounted for in ML literature. Works on detecting outliers have been a field of research for a long, and its methods are usually considered well-developed.  

The last cause of change is rooted within the behavior of the agent itself. This is mainly the case where an adversary agent attacks a machine learning algorithm. In adversarial attacks, the agent usually changes the image slightly, which is not noticeable to a human observer, but it changes the prediction of the model entirely. Arguably, these small changes can also be viewed as noises added to images, yet noise comes from a random process, while on the contrary, these perturbations are created with intention and in a specific way to mislead the model; thus we have also given them a category totally for themselves.  

Given all these reasons behind changes and shifts in the distribution of data, papers can be categorized into a few groups based on the problem they are tackling. The next section of the paper gives an overview of each problem and reviews works done for that. There are already a few surveys reviewing papers on out-of-distribution detection and distribution shifts [16, 17, 8, 18, 19, 20, 21], yet these papers mainly focus on one problem deeply, or their literature does not contain more recent trends and publications. Nevertheless, the interested reader is encouraged and also referred to read those surveys, specifically when focusing on one of the problems.  

There are a few approaches one can take when working on the detection and generalization of models for OOD data, a list of them is as follows:  

# 3.1. Information theory backed models  

Information theory and probability theory provide many tools that are naturally made to test distribution matching. In the simplest form, getting KL divergence between the output of a classifier and uniform distribution or using extreme value theory (EVT) [22] are used to detect OOD samples. In more advanced methods, however, tools such as mutual information (MI) [23], or complexity of data [24] are seen to be used numerously. This category is also quite popular among researchers, given that their methods can usually be used without further training a neural net.  

# 3.2. Reconstruction Error  

Taking data into a latent space and then taking it back to the main space is an idea used by autoencoders to learn a robust representation of data in a smaller latent space [25]. Reconstruction-based methods work to utilize the idea that models trained on some data will generate huge reconstruction errors on OOD samples. This simple idea has been used on many ML and statistical algorithms, from PCA [26] to variational autoencoders [27].  

# 3.3. Density and Distance-based  

Similar to reconstruction-based methods, these methods also usually benefit from how data are in a latent (or feature) space. Here, the method usually requires some training data to learn how data are distributed; then, OOD samples are detected by finding different behavior from training data in latent space. Some of these methods explicitly work by finding the distance, while others first learn the density of in-samples and then find the divergence from the dense segment of the distribution, yet arguably they both are working similarly.  

# 3.4. Generative  

Generative methods mostly became popular in the past few years, courtesy of the outstanding performance of GANs [28] and other generative models in image generation. These methods also are intrinsically density-based, given that most generative models aim to learn the underlying distribution of data, whether explicitly or implicitly. Using a discriminator of GAN or using the generator to generate similar in-samples to train the model further are amongst the most popular approaches when it comes to using GANs to detect OOD, but using other generative models such as VAEs is also investigated in research papers.  

![](images/31a66229d437d202e678ea833b5ef39b547dde6bf0963a0611f565430eede20c.jpg)  
Figure 1: SCM Model For Data  

# 3.5. Novel methods  

Researchers in OOD detection literature use various directions and approaches While the four mentioned category is more commonly seen in papers, many novel ideas do not belong to them. Disentangled representation learning [29], causal learning [30], and concept learning [31] are some examples. Compared to other paradigms, these usually have a more recent model as the backbone of their structure, yet they are limited by the weaknesses of their underlying model, which can be numerous given their newness.  

# 4. Notation and Definitions  

In this section of the paper, a mathematical look is given to distribution shifts in a search for boundaries between different problem settings. Firstly, we look into how previous works have categorized change, and then we propose a  

new look to resolve a few issues of prior ones with the help of a structural causal model (SCM) [32].  

# 4.1. Distribution Shifts - an Overview  

In this section of the paper, a mathematical overview is presented on the categorization of shifts by prior works. Firstly, as an influential pioneer in defining distribution shifts, we consider [14] look into how shifts differ from each other, then we attend the issues with this model in a quest for a new one.  

In [14], distribution shifts are defined as times where the distribution of data $(P(x,y))$ for train and test are not the same, or in other words, $P_{t r a i n}(x,y)\neq$ $P_{t e s t}(x,y)$ . As this paper investigated distribution shifts in classification problems, $x$ is defined as data points sampled from an underlying distribution ( $x\sim X$ ), and y is a class label ( $y\in Y=\{y_{1},y_{2},\cdot\cdot\cdot,y_{n}\})$ ; however, this notation can be used for other types of problems such as regression as well, merely by a few changes. To not make things complicated, we merely assume an underlying classification problem and continue with defined notation.  

In the paper, problems are categorized into two groups, places where an $X\rightarrow$ $Y$ causal link holds, i.e., credit card fraud detection. The other group is $X\leftarrow$ $Y$ , such as medical diagnosis, where the disease causes the symptoms. Given this, the joint distribution can be calculated by $P(X)P(Y|X)$ or $P(Y)P(X|Y)$ , respectively. Now, the types of shifts are analyzed:  

• Covariate shift: Only happens in $X~\rightarrow~Y$ setting, when $P_{t r a i n}(y|x)\,=$ $P_{t e s t}(y|x)$ but $P_{t r a i n}(x)\neq P_{t e s t}(x)$   
• Prior probability shift: Only happens in $X\leftarrow Y$ setting, when $P_{t r a i n}(x|y)=$ $P_{t e s t}(x|y)$ but $P_{t r a i n}(y)\neq P_{t e s t}(y)$   
• Concept shift (concept drift): Happens in both settings, in first by $P_{t r a i n}(y|x)\neq$ $P_{t e s t}(y|x)$ when $P_{t r a i n}(x)\,=\,P_{t e s t}(x)$ and in second when $P_{t r a i n}(x|y)\neq$ $P_{t e s t}(x|y)$ when $P_{t r a i n}(y)=P_{t e s t}(y)$   
• Otherwise: where no equality holds true.  

There are a few issues with this look at data distribution:  

1. Given the type of problem, one needs to find which setting applies.   
2. Semantic shifts (such as the introduction of a new class) can be welldefined only within the second setting.   
3. When switching to more complected spaces such as images and collecting datasets empirically instead of creating them, holding equality in distribution becomes impossible, and most of the problems come from the last category.  

Given that these shifts are direct consequences of some unobserved variables, we try to make a new look by adding those variables to the causal model.  

# 4.2. Distribution Shifts - a new look  

Considering the previous view of the causal model behind data, the only variables are $X$ and $Y$ , or in other words, observation and label, and the two possible causal links are whether $X\rightarrow Y$ or $X\leftarrow Y$ . Here, we try to create a more complicated causal model for data with two goals in mind; first, the direction of causal links should be the same for any types of data, and second, to factor in different causes behind distribution shifts. Figure 1 shows our suggested causal model.  

Here, we first removed any link between observation and label. By doing this, our structure becomes similar for any type of dataset. Next, we have added a node called the event. This event can be a class label; in other words, the event is what the model aims to recognize from the observation. Next, we need to add another node for the environment, showing the domain or environment effect directly. It is self-evident that the environment causally affects the observation, but also it should be noted that change in environment can cause a change in the distribution of events, even introducing new ones. Next, we have added a node for noise, but the source of noise can be uncontrollable and natural, such as noises in measurement systems, or it can be due to actions of an adversary agent, which is also added to the SCM.  

There are a few points that need to be clarified about this graph as well; first, noise can also be causally related to environment and event, but we have obviated the overhead of considering all those links by making the uncontrollable noise an un-observed node. Next, noise can also affect labels, but that is not within the scope of OOD literature; therefore, we have also removed that relation as well.  

Finally, the whole distribution can be viewed as:  

$$
P(X,Y,E n v,E v e n t,N o i s e)
$$  

and thus, distribution shifts can occur by a shift in $P(E n v)$ , $P(E v e n t)$ , $P(N o i s e)$ , or a combination of them.  

# 5. Reviews  

This section of the paper is devoted to reviewing papers, divided based on the problem they try to solve. First, in each subsection, a description of the problem, benchmarks, and evaluation metrics is presented. Then, for each subsection, a table summarizes papers in that problem setting.  

# 5.1. Domain Generalization  

In this problem setting, mainly the domain (environment) from which the data is sampled changes between training and testing. In other words, changes happen by a shift in $P(E n v)$ . Figure 2 shows an example of these types of changes when looking from top to bottom. While the class labels are the same amongst all different domains, some concept shift exists between them.  

Image is the most investigated type of data for domain generalization; a few also investigated other types of data such as time-series [33]. The reasoning behind this lies within the definition of domain and domain changes; anyone has an intuition of differences when they face a painting in comparison to natural scenery, but the effects of changes in data gathering equipment in different hospitals [34] is not similar to this. Naturally, datasets are also mainly on the image. Table 1 provides details on some of the main benchmark datasets of this field.  

![](images/0ee1a972c83db5419061ec166d7520bcafdae7c93f7b24c4cf3d83ffa729029f.jpg)  
Figure 2: Illustration of a few examples from DomainNet dataset.  

Table 1: Domain Generalization Datasets.   


<html><body><table><tr><td>Dataset</td><td>Number of Domains</td><td>Total Number of Images</td><td>Description</td></tr><tr><td>RotatedMNIST [35]</td><td>6</td><td>6000</td><td>Each domain is created by rotating MNIST images with an specific angle</td></tr><tr><td>ColoredMNIST [36]</td><td>3</td><td>60000 (all MNIST)</td><td>Digits are colored in Green or Red with high correlation to digits.Ratio of correlation is diferent between environments</td></tr><tr><td>VLCS [37]</td><td>4</td><td>10729</td><td>Created by selecting images from four different dataset. Selected classes are : bird, car, chair, dog, person.</td></tr><tr><td>PACS [38]</td><td>4</td><td>9991</td><td>Domains are: Photo, Art Painting, Cartoon, Sketch - selected from seven classes</td></tr><tr><td>Office-Home [39]</td><td>4</td><td>15500</td><td>Domains are: Art, Clipart, Product(object without background), Real-World. 65 Classes are presented</td></tr><tr><td>DomainNet [40]</td><td>6</td><td>around 600000</td><td>Images are from 345 classes and domains are: clipart, real, sketch, infograph, painting, quickdraw.</td></tr></table></body></html>  

Table 2: Review of Works -Domain Generalization   


<html><body><table><tr><td>Work</td><td>Datasets</td><td>Method Type</td><td>Method</td><td>Advantages</td><td>Disadvantages</td></tr><tr><td>[33]</td><td>Self-Defined</td><td>Novel (Causal)</td><td>Firstly, a graphical model is created to show relation between environment and agent,then after considering the local independencies,a hand-tailored loss is calculated and minimized.</td><td>Working on time-series, generalizable to other problems</td><td>Assumptions about Domain, lack of comparison to others</td></tr><tr><td>[41]</td><td>Colored-Mnist, WILDS</td><td>Information</td><td>First,the paper proposes that a calibrated predictor on a few environment does not use any spurious features by providing mathematical intuition, then a few mechanism for model calibration are tested</td><td>Focusing on spurious correlation, can be applied on almost any model</td><td>Training environments require to be different to some extent</td></tr><tr><td>[42]</td><td>PACS,VLCS, OfficeHome, TerraIncognita, DomainBed PACS,VLCS,</td><td>Novel (Optimization)</td><td>The idea is to seek flatter minima while minimizing the loss function of the model to improve the generalizability</td><td>Applicable to many tasks, simple intuition</td><td>Method weakness in finding flat minimas, weakness in utilizing to domain-specific information</td></tr><tr><td>[43]</td><td>DomainNet, OfficeHome, Digit-DG Digits-DG,</td><td>Novel (Knowledge Distillation)</td><td>An student network is trained on augmented data from other domain by a teacher seeing the main domain, meanwhile a generative model is trained for domain augmentation</td><td>Domain augmentation, domain-robust representation</td><td>Leave-one-out evaluation is used which does not show model performance when training domain is fixed</td></tr><tr><td>[44]</td><td>PACS, OfficeHome ColoredMNIST,</td><td>Generative</td><td>A domain-transformation network is trained to create data from unseen domain and then synthetic data are used to train classifier First,the problem is transformed into</td><td>Domain-transfer network can also be used for data augmentation</td><td>Requires data from target domain</td></tr><tr><td>[45]</td><td>Camelyon17-WILDS, FMoW-WILDS, PACS PACS,VLCS,</td><td>Information</td><td>an optimization problem where constraints are defined to consider information invariancy between domains, then a solution is proposed</td><td>Convergence guarantee, testing on breast cancer dataset</td><td>Complicated method which prevents others to improve upon</td></tr><tr><td>[46]</td><td>OfficeHome, ImageNet-Sketch Self-Defined,</td><td>Information</td><td>Neurons with high-activations or high-gradient are shuted down while training</td><td>Ease of implementation,applicablity to many tasks</td><td>Neurons learn to correlate with most important features,and spurious correlation is a challenge</td></tr><tr><td>[47] </td><td>Amazon reviews</td><td>Density</td><td>Minimizing a loss to reach a representation of data where source and target distribution are indistinguishable</td><td>A pioneer,test on text image and synthetic data</td><td>Requires data from both domains</td></tr><tr><td>[48]</td><td>Office [49]</td><td>Information</td><td>Using linear transformation for aligning second-order statistics of distributions (for non-deep please refer to [50])</td><td>A pioneer,ease of implementation</td><td>Linearity assumptions, requires data from target domain</td></tr></table></body></html>  

<html><body><table><tr><td>[51]</td><td>Self-Defined</td><td>Density</td><td>Training a generative model for creating data from different path to generalize models for financial markets</td><td>Working On financial data, introduction of path as domain</td><td>Assumptions about domain, focusing On generative quality and not performance for generalization</td></tr><tr><td>[52]</td><td>Self-Defined</td><td>Information</td><td>Model aims to learn domain-invariant information by attention sharing while training a domain-discriminator and learning the domain specific information separately</td><td>working with time-series, considering scenarios such as cold-start</td><td>Only focusing on adaptation, only works on single-variate time-series</td></tr><tr><td>[53]</td><td>Medical Self-Defined</td><td>Various</td><td>Testing a few other model,not introducing One</td><td>Medical data, extensive evaluation and comparison of models</td><td>Assumption that data recorded in different years are from different domains</td></tr><tr><td>[38]</td><td>PACS, VLCS</td><td>Information</td><td>Undo-bias [54] idea is extended to NNs, then a low rank parameterization method is applied to reduce number of parameters</td><td>Introducing new benchmark, works better on high-shift datasets compared to prior works</td><td>Requires data from a few domains</td></tr><tr><td>[55]</td><td>Synthetic, GvHD</td><td>Information</td><td>Firstly distributional variance (DV) is defined as a measure of divergence between domains, then an orthogonal transform is found from feature space to latent space which minimize DV A generative model is proposed to generate</td><td>A pioneer,latent space transformation can be used to improve other algorithms</td><td>Requires data from a few domains</td></tr><tr><td>[23]</td><td>Digits, PACS, Corrupted CIFAR10</td><td>Generative Information</td><td>data from different domains by minimizing the MI between generated data and samples (to diversify） and maximizing MI between samples of same class to keep semantics</td><td>Works on single domain generalization</td><td>Computationally expensive, comprations are not totally fair as other methods do not focus on single domain generalization</td></tr><tr><td>[56]</td><td>CASIA-MFSD, Oulu-NPU, Replay-Attack, MSU-MFSD PACS,</td><td>Generative</td><td>A GAN model is improved for any-spoofing by forcing the discriminator to also distinguish between different domains</td><td>Simple intuition, improvement on mentionedtask</td><td>Requires a few diverse domains to generalize enough for task at hand</td></tr><tr><td>[57]</td><td>Digits-DG, VLCS, OfficeHome</td><td>Information, Density, Novel</td><td>Firstly,a domain classifier is trained on some pseudo domain labels, which is used to normalize features, then semantic information is learned and extracted using prototypical relation modeling [58]</td><td>Does not require domain labels, A pioneer on using prototypical relation modeling</td><td>Requires data from a few domains, computationally expensive</td></tr><tr><td>[69]</td><td>Digits, CIFAR-10-C, PACS</td><td>Novel (Meta-Features)</td><td>A process is proposed to learn meta features (visual words) from convolutional features by minimizing a reconstruction loss and classify inputs based on best-match meta-features</td><td>Robust Representation of input data, Method can be also used to learn visual words for other OOD tasks</td><td>No constraint is introduced for disentanglement of meta features which might cause problem in domain shifts with huge change in distribution of classes</td></tr></table></body></html>  

<html><body><table><tr><td>[60]</td><td>Rotated MNIST, PACS, VLCS, Camelyon17-WILDS</td><td>Novel (Disentanglement)</td><td>Method tries todisentangle features showing semantic and variation information,former being extractedbyanencoder trying toclassifyimages andlatterbyadecoderusingdifferentvariation informationtogeneratesemanticallysamedata</td><td>Does not require domain labels, Canbeusedtofindvariation between domains</td><td>Requiresdatafromafewdomains</td></tr><tr><td>[61]</td><td>PACS, Synthetic</td><td>Information</td><td>In each training iteration,model istrainedonafewoftrainingdomains aiming to improve on the rest of training domains aiming to generalizebetter tounseendomains</td><td>Simple intuition, the idea canbe applied onalmostanymodel</td><td>Requiresdatafromafewdomains</td></tr></table></body></html>  

Table 3: Review of Works - OSR   


<html><body><table><tr><td>Work</td><td>Datasets MNIST,</td><td>Method Type</td><td>Method</td><td>Advantages</td><td>Disadvantages</td></tr><tr><td>[62]</td><td>SVHN, CIFAR10, CIFAR+10, TinyImageNet</td><td>Density</td><td>Introducinga loss which forces data of same classes to form tight clusters in latent space</td><td>Interpretability of latent space, model is appicalbe to any task</td><td>Requires training</td></tr><tr><td>[63]</td><td>MNIST, SVHN, CIFAR10, CIFAR+10, TinyImageNet</td><td>Novel</td><td>Two models,one is a class placeholder, a neuron added to classification layer forcing the model to push the second-highest probability toward added neuron This is then used to distinguish in and out data & a data Placeholder,mimicing novel patterns with manifold mixup on latent embeddings</td><td>Simple intuition for class placeholders, small training overhead for class placeholder</td><td>Requires picking number of dummy classifier,data placeholder only working on embedding,requires training</td></tr><tr><td>[64]</td><td>MNIST, SVHN, CIFAR10, TinyImageNet</td><td>Generative</td><td>A GAN is trained on feature level by an outlier exposed dataset,aming to learn a discriminator that can assign robust likelihood by considering the outlier data as fake when training GAN</td><td>GAN is trained on feature level thus the model is computationally efficient</td><td>Requires outlier exposed dataset for training</td></tr><tr><td>[65]</td><td>MNIST, SVHN, CIFAR10, CIFAR+10, CIFAR+50, TinyImageNet</td><td>Various</td><td>This Work focuses on showing that performance of any model in closed-set classes is correlated with its OSR performance.</td><td>Improving closed-set performance, introducing semantic shift benchmark, theorical justification with help of model calibration literature</td><td>Analysis of differences in shape of feature space between closed-set and open-set models is missing</td></tr></table></body></html>  

<html><body><table><tr><td>[66]</td><td>MNIST, SVHN, CIFAR10, CIFAR+10, CIFAR+50, TinyImageNet</td><td>Reconstruction</td><td>An encoder-decoder network is trained,the encoder part is trained for classification while the decoder used to calculate reconstruction loss and detect open set examples</td><td>Sample intuition,the idea is easily applicable to any encoder-decoder model</td><td>Requires threshold selection, classifier information is not used</td></tr><tr><td>[67]</td><td>MNIST, SVHN, CIFAR10, TinyImageNet, DBpedia</td><td>Reconstruction</td><td>A combination of openmax score is used with distance in latent space to detect OS samples; latent vectors are generated using a model that tries to reconstruct data with latent-vectors</td><td>Distance in latent space is used instead of reconstruction loss</td><td>Computation overhead for reconstruction part of model</td></tr><tr><td>[68]</td><td>Caltech 256+ ImageNet, MNIST, LETTER Cityscapes,</td><td>Information</td><td>A probabilistic model is introduced which fits a weibull distribution on decision score of SVM classifiers,and outputs probability for each class; a final thresholding detects OS samples A dense neural network is used for feature extraction;</td><td>A pioneer,works on any model with score or probability output</td><td>Works on output of classification layer</td></tr><tr><td>[69]</td><td>StreetHazard, Vistas, WildDash 1</td><td>Novel</td><td>then features are used with labeled outlier data to train an OS detection network parallel to classification network</td><td>Working on semantic segmentation</td><td>Requires training, requires outlier data</td></tr><tr><td>[02]</td><td>MOCAP</td><td>Generative</td><td>A GAN is trained to generate fake data which is used to train the classifier to distinguish known class from unknown</td><td>Tested on human activity recognition dataset</td><td>Requires training, working on output of classification layer</td></tr><tr><td>[71]</td><td>Caltech 256+ ImageNet YaleB, MNIST,</td><td>Information</td><td>Similar to [68] with small changes in probability calculation Extreme Value Theory is used to model tail</td><td>Extensive testing with different classifiers</td><td>Works on output of classification layer Requires threshold selection,</td></tr><tr><td>[72]</td><td>UIUC, Caltech 256</td><td>Information</td><td>distribution of data to test hypotisis of data belonging to train classes The classifier assigns a likelihood score, which</td><td>Theoretical basis, superior results compared to other conventional ML models</td><td>works on output of classification layer</td></tr><tr><td>[73]</td><td>FERET</td><td>Information</td><td>is used to compute a peak-to-side ratio distribution (when samples are assigned to wrong classes); this distribution is used to find OS samples</td><td>A pioneer, works with many-classed problems (such as face recognition)</td><td>Approximations for likelihood score calculation,not tested against other means of scoring samples</td></tr><tr><td>[74]</td><td>MiniImageNet, TieredImageNet</td><td>Density</td><td>This paper works on making GFSL [75] method Task adaptive by automatic threshold selection</td><td>Works on few-shot problems, threshold-free model</td><td>Requires OS data</td></tr></table></body></html>  

<html><body><table><tr><td>[76]</td><td>MNIST, FashionMNIST, AudioMNIST, KMNIST, SVHN, CIFAR</td><td>Generative, Information</td><td>Firstly,a β-VAE is trained on dataset,then a class conditioned EVT is applied on latent space to test whether data is inlier or OS</td><td>Workin on latent space instead of reconstruction error,EVT instead of threshold selection,extensive testing</td><td>Requires training,requires model selection for each dataset</td></tr><tr><td>[22]</td><td>Self-Defined and collected Various</td><td>Density</td><td>SVM algorithm is edited to counter for OS samples by EVT Firstly,it is shown that by replacing softmax with sigmoid, confidence scores are reduced for OS samples, then classifier</td><td>Work on sensory data, work on lane change problem Applicable to any classification network,</td><td>Definitions of OS samples, method is not tested using benchmarks By increasing number of classes,</td></tr><tr><td>[78] [62]</td><td>Benchmark Datasets MNIST, SVHN, CIFAR10,</td><td>Information</td><td>is replaced with sigmoid-based one-vs- rest networks and using some rules, collective decision is drawn A new activation is introduced which is a combination of 3 sigmoid functions which aims</td><td>only requires training of last layer Only changes last layer of network,</td><td>computational demand also increases Requires hyper-parameter selection</td></tr><tr><td>[80] </td><td>CIFAR+10, CIFAR+50 Various touchless- biometric</td><td>Information Density</td><td>totighten the boundary for inlier samples in classification layer to detect OS samples In each iteration, a set of dataset is selected as support and another set as query, and meta feature extractors are updated distance of</td><td>can generate probability of OS Works on feature layer,</td><td>Computationally expensive,</td></tr><tr><td>[81]</td><td>datasets ImageNet-LT, Places-LT, Marine</td><td>Density</td><td>each query to respective meta sets First, a loss function is added to decrease inter-class similarities, by forcing them to shape a compact cluster, then a novelty detection algorithm is proposed</td><td>extracts robust features Focusing on OSR in Long-Tailed recognition</td><td>not tested on benchmarks Requires training</td></tr><tr><td>[82] </td><td>Species-LT SVHN, CIFAR10, CIFAR+10, CIFAR+50</td><td>Information</td><td>to find OS samples which also takes cluster size into account One neuron is added to the classification layer of network for OS samples; in training, two cross-entropy losses are minimized, one trying to match the output to coresponding class and second one matching the outputs after removing the neuron of correct class to OS neuron</td><td>Also tested for single domain generalization tasks, simple intuition</td><td>Requires training data to re-train the classifier</td></tr></table></body></html>  

While these datasets are the ones mostly used in research papers, they are mainly similar in the selection of domains and types of images. Some works have also presented datasets for other fields of study as well, such as satellite images [83] and breast cancer [84].  

In DG problems, generalization to a new domain is the primary goal of papers; thus, any metric of performance in the new domain can be used for evaluation, from simple metrics such as accuracy to expected calibration error [85]. By decreasing the number of domains used during training, the difficulty of the task at hand increases, the most common setting is one-vs-rest splitting (one domain for test, the rest for training). Meanwhile, the most challenging and also, at the same time, most interesting one is single-domain generalization. Also, if some training data from the test domain be available during training, the problem changes to domain adaptation [86], which is not within the scope of our study. Lastly, table 2 reviews work done on domain generalization.  

# 5.2. Open Set Recognition (OSR)  

Open set recognition is the task of detecting data from new/unseen classes. The possibility of new events is inevitable in open-world settings, as it is impractical to account for any probable event during the creation and training of the model. This problem can be viewed as shifts in $P(E v e n t)$ .  

Creating datasets for OSR model evaluation can be easily archived by removing one or more classes from the dataset during training and then considering it back during the test. To compare datasets, Scheirer et al. [87] suggested openness which aims to measure how open the underlying problem is. The following equation is used to calculate this metric:  

$$
O p e n n e s s=1-\sqrt{\frac{2*N_{T r a i n}}{N_{T e s t}+N_{T a r g e t}}}
$$  

Where $N_{T r a i n}$ is the number of classes used during training, $N_{T e s t}$ is the number of classes that will be observed during testing, and finally, the number of classes which needs to be correctly recognized in testing as $N_{T a r g e t}$ . In addition, to randomly remove some classes during training, to increase openness without further reducing the number of training classes, in CIFAR+ $N$ datasets, some non-overlapping classes are added to CIFAR10 from CIFAR100.  

In this problem setting, the main goal is to detect open set (OS) samples while making the fewest possible mistakes on in-lier data points. Therefore, two sets of metrics need to be defined, the first one evaluating performance on closed-set data (usually accuracy) and the second one for measuring OSR performance. However, the ratio of OS samples in test time is unknown; thus, every algorithm requires a sensitivity parameter to be set [88], which makes the area under the ROC curve (AUROC) fitted for the job. Finally, table 3 reviews work done on OSR.  

# 5.3. Outlier Detection and Adversarial Examples  

Moving to changes caused by shifts in $P(N o i s e)$ , outlier detection and adversarial examples are the next category we check.  

In an outlier detection setting, compared to other problems, usually, what causes the OOD sample is not a shift in $P(N o i s e)$ but the occurrence of an unlikely value. This has caused a problem in dataset creation in papers in this field, as many of them merely apply an OSR setting to their model and evaluate the model on their ability to recognize images from unseen classes. Nevertheless, server machine dataset (SMD) [89] is commonly used among researchers in this field, and many have worked on time-series and online outlier detection, which are the current trends.  

Next, adversarial examples are one of the best-known types of distribution shifts that affect the performance of deep neural networks dramatically. These data points are usually generated by adding a small perturbation to data; usually, these types of examples are not separable from main data by the human eye. These types are named adversarial examples, as they can be used for adversary purposes [9].  

Given the nature of challenges and limitations in attacking any system and the final goal of the attacker, there are plenty of possible adversary attacks. The underlying system might be a black box with only a limited number of possible accesses to it, or the data might go under preprocessing before being fed to the ML system. Many surveys [90, 21] have reviewed the adversarial examples and attacks on DL and ML systems on different types of data, and the interested reader can check them for further details on the topic. There are also many famous attacks such as L-Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) [91], fast gradient sign method (FGSM) [9] and basic iterative method (BIM) [92], and it is common to evaluate models against a few of them.  

As the models’ main aim here is to recognize outliers, evaluation metrics are similar to OSR. Also, for these two problem settings, there are two great python libraries: pyod [93] for outlier detection, and ART [94] for adversarial attacks. These libraries have implemented many of the algorithms in a plug-and-play fashion, which can be genuinely valuable to researchers. Table 4 reviews work done on outlier and adversarial attacks detection.  

# 5.4. General OOD  

As we categorize each problem and shift by the reason behind it, the inevitable question is, what if more than one cause is behind the change in the distribution of data?  

For example, consider a model trained on sketches of cars to be evaluated on real photos of all types of vehicles. General out of distribution detection, or OOD detection, aims to detect OOD samples in any case rather than merely focusing on a specific type of change. In this setting, generalization is also meaningless, given that the OOD sample might be from new events or even an outlier. Notably, adversarial attacks are usually not considered in OOD literature, given their difference in nature (intentional vs. unintentional changes).  

Also, it is noteworthy to mention that general OOD problems are not always harder than other categories. They are also easier to define in new settings, given that they do not require the assertion of the cause of changes to be merely one of the environment, event, or noise.  

In this setting, a usual approach is to consider one dataset as in-liers and another one as outliers. Mostly, the challenge in this setting is to find methods to achieve OOD detection without training a model and using an already learned model; thus, it is common to consider image net or imagenet1k as an inlier dataset. This selection is due to the fact that for most DL models, pre-trained networks on imagenet are available. Also, having outlier samples (mainly to see how the model behaves) or not can affect the difficulty of the problem at hand.  

To evaluate these models, similar to the OSR setting, AUROC is commonly used in research papers. The false-positive rate at $95\%$ true positive rate is also widely seen in research papers. A simple intuition behind this metric is setting the sensitivity on the model in a way to pass 95% of positive data and then measuring how many outliers have passed the filter. Finally, researchers also use the area under the precision-recall curve (AUPR) as a metric. Lastly, table 5 reviews work done on General OOD detection.  

Table 4: Review of Works - Outlier and Adversarial Attacks Detection   


<html><body><table><tr><td>ork</td><td>Datasets</td><td>Method Type</td><td>Method</td><td>Advantages</td><td>Disadvantages</td></tr><tr><td rowspan="2">5]</td><td>Synthetic, VIRAT Video,</td><td rowspan="2">Reconstruction</td><td>AmethodisproposedtolearnRPCAwith neural networks,which is used</td><td rowspan="2">Explainability of learnt parameters, speed compared to other works</td><td rowspan="2">Requires stopping criteria, requireshyperparameter selection</td></tr><tr><td>Ultrasound</td><td>to detect outliers</td></tr><tr><td rowspan="2">6]</td><td>Synthetic,</td><td rowspan="2">Information</td><td>This paper focuses on solving Q-death problem by introducing a memory decay term to</td><td>Online outlier detection, works on few-outlier environment</td><td rowspan="2">Requires hyper-parameter selection</td></tr><tr><td>SMD</td><td>existing methods</td><td></td></tr><tr><td rowspan="2">[6</td><td>SMD, SMAP,</td><td rowspan="2">Reconstruction</td><td>An RNN is combined with aVAE tolearn robust representationofdata,thenreconstructionerror</td><td>Variationalrepresentationlearning, entry-level outlier detection on</td><td rowspan="2">Complexity of model</td></tr><tr><td>MSL</td><td>is used to detect outliers OOD-ness of a few augmentation techniques are tested</td><td>multivariate time-series</td></tr><tr><td rowspan="2">7]</td><td>CIFAR10, CIFAR100,</td><td rowspan="2">Novel (Self-Supervision, Representation)</td><td>with discriminative ability of model after shift,then hardest are picked as main shift is encoded</td><td>Robustrepresentationtodiscriminate in and out distribution, improvement on harder</td><td rowspan="2">Testing shifts are created and picked by experts knowledge</td></tr><tr><td>Imagenet30</td><td>inSimCLR[98]losstolearnrobustrepresentation</td><td>OOD samples</td></tr><tr><td rowspan="2">9]</td><td>CIFAR10, CelebA,</td><td rowspan="2">Density</td><td>White noise test is used as a weak relaxation of</td><td>Unsupervised,possibility of incorporating prior knowledge about outlier distribution,</td><td rowspan="2">The underlying assumption is too weak,given that White Noise is weaker than martingale difference which is itself</td></tr><tr><td>TinyImageNet,</td><td>IID-ness to detect outliers with generative models outliers</td><td>Analysis on hard scenarios, where textual differences is minimized</td></tr><tr><td rowspan="2">00]</td><td>SVHN Countries,</td><td rowspan="2">Density</td><td rowspan="2">Mean-shift algorithmwith an outlier filtering step is used to cluster data and find</td><td rowspan="2">Works on many-outlier environments, fast</td><td rowspan="2">weaker thanIID Not tested on high-dimensional data like images</td></tr><tr><td>unbalance, and XOR from sipu datasets</td></tr></table></body></html>  

<html><body><table><tr><td></td><td>MNIST,</td><td colspan="5"></td></tr><tr><td>01]</td><td>Fashion-MNIST, SVHN, CIFAR-10,</td><td>Reconstruction</td><td>Images are transformedwithdata augmentation techniques before feeding to an autoencoder which aims to learn reconstruction while being invariant totransformation</td><td>More robust considered to simple reconstruction methods,trained with adaptive self-paced learning</td><td>Requires threshold selection, only works in environment where transformations aredefined</td></tr><tr><td>02]</td><td>CIFAR-100 30 different from ODDS and DAMI [103]</td><td>Density</td><td>First, empirical copula is used to fit a distribution to dataset,then the tail probability is calculate to reject or accept samples</td><td>Parameter-free,interpretability, works on high-dimensional data</td><td>Empirical copula might require a lot of data to fit a</td></tr><tr><td>04]</td><td>Stanford Dogs, FounderType-200, CUB-200-2010</td><td>Density</td><td>A loss function is proposed to force feature space to have a class-conditional gaussianity shape</td><td>Working onfeature space, proposed loss can be used for other tasks as well</td><td>distribution properly Computational overhead, only appicalbe to neural networks</td></tr><tr><td>05]</td><td>20 Newsgroups, 50 Class Reviews</td><td>Density</td><td>For each class of data, the classifier devides the space into 3 parts, namely, inside, outside and partial which forces the model to learn more compact</td><td>Simple intuition, can be changed into a loss</td><td>Working on input space, test settings are similar to OSR which makes comparison with other</td></tr><tr><td>06]</td><td>MNIST, CIFAR-10,</td><td>Information</td><td>sub-spaces Hilbert Schmidt Independence Criterion (HSIC）is used to estimatemutualinformation,and informationbottleneck</td><td>function for neural networks Works without adversarial examples</td><td>novelity detection methods invalid Computational overhead,using HSIC to estimate mutual information is not</td></tr><tr><td></td><td>CIFAR-100 SVHNN,</td><td></td><td>is introduced as a regularization term tomake model robust against adversarial examples A Gaussian classifier is used to compute confidence scores using</td><td>during training, low drop in discriminative performance Better AUC compared to softmax,</td><td>a new idea Requires training data,</td></tr><tr><td>07] 08]</td><td>CIFAR-10, CIFAR-100 MNIST, F-MNIST, CIFAR-10</td><td>Density Generative</td><td>Mahalanobis distance in each layer of network A generative model is used to model the distribution of hidden states(hidden neurons）of model which is later usedto detect adverarialexamples</td><td>introduction of an algorithm for calibration Works on feature space,tested againsed FGSM and DeepFool</td><td>requires to re-feed all data to network Requires training data, requires to re-feed all data to network</td></tr></table></body></html>  

<html><body><table><tr><td>VGGFace2, [60 MNIST,</td><td>Density</td><td></td><td>Firstly,using the inlier data,class centroidsforeachlayerofnetworkiscalculated, thendetectorsaretrainedtofind</td><td>Doesnotrequiretrainingfor basemodel,generalizabilitybetween</td><td>Requires adversarialtraining</td></tr><tr><td>0]</td><td>CIFAR-10 Market1501, DukeMTMC-ReID</td><td>Density</td><td>adversary examplesusing distances to thesecentroids Firstly,afew expertmodelsare selected, then itis shown empirically thanby analysingfirstK outputsofmodels,adifferenceisseenin query-supportrelations,support-supportrelations andcross-expertrelations</td><td>differetproblemsettings Focusing onre-identification, multi-modal(comparedto other single-model works)</td><td>Workingonoutputofclassification layer ofmodels, detectorrequires adversarialtraining</td></tr></table></body></html>  

Table 5: Review of Works - OOD detection   


<html><body><table><tr><td>Work</td><td>Datasets</td><td>MethodType</td><td>Method</td><td>Advantages</td><td>Disadvantages</td></tr><tr><td>[24] </td><td>A few vs CIFAR10</td><td>Density</td><td>Combining an upper-bound on Kolmogorov complexity withlikelihoodFromgenerativemodels</td><td>Ease ofimplementation, Workswithanygenerativemodelthat assigns likelihood</td><td>Using compression for guessing thecomplexityofdata</td></tr><tr><td>[111]</td><td>VariousDatasets Such as MNIST vs EachOther</td><td>Density/ Information</td><td>Instead of comparing model probabilities, statisticsfrommodelprobabilitiesare calculatedtofitamodelondensityofthem (bykerneldensityestimator or SVM),whichis then used to detect OOD samples</td><td>Doesnotrequirelabeled data or OODsamples,applicable to any trained model</td><td>Requires threshold selection, complicatedmathematicaltheory prevents other studiestobuild upon this one</td></tr><tr><td>[112]</td><td>CIFAR-10& CIFAR-100vS TinyImageNet, LSUN</td><td>Information</td><td>Smallperturbationsareaddedtoincreasethe softmax scores,then it is observed that this affectsin-liersmorethan OODsmaples whichisusedtodetectthem</td><td>Used widely asbaseline in other papers,works with any neuralnetwork</td><td>Requires threshold selection, works on outputofclassification layer, computational overhead of perturbationcalculation</td></tr></table></body></html>  

<html><body><table><tr><td>[113]</td><td>ImageNet-1k vs Places365, Textures, iNaturalist, SUN</td><td>Information</td><td>The activation's of penultimate layer outputs are truncated to limit the effect of noise, then an scoring function is applied to find OOD samples</td><td>Applicable to any pre-trained networks, can work with any scoring function such as ODIN[112]</td><td>Requires threshold selection, requires output of penultimate layer for training samples</td></tr><tr><td>[114]</td><td>AID, UCM, LCZ42</td><td>Information</td><td>A Dirichlet Prior Network (DPN） is trained with two losses, one for in-data which aims toincrease performance and another for OOD data to force an uniform output</td><td>Works in many-class problems, Tested on remote sensing data, test designs</td><td>Requires Training and OOD data</td></tr><tr><td>[115]</td><td>Fashion-MNIST vs MNIST, CIFAR-10 vs SVHN, Self-Defined SVHN,</td><td>Generative, Information</td><td>The idea is to cancel effect of background in likelihood calculation</td><td>Working on gnomic data, Visualization andinterpretation of results</td><td>LSTM model is tested for DNA data generation, which is not intrinsically generative, Requires Training</td></tr><tr><td>[116]</td><td>CIFAR-10, CIFAR-100 vs SVHN, Textures, Places365, LSUN, iSUN</td><td>Information</td><td>An energy score is calculated using probabilities provided by softmax output to find OOD samples</td><td>Simple intuition, no need to train networks</td><td>Works on output of classification layer,Requires threshold selection</td></tr><tr><td>[117]</td><td>MNIST, GTSRB</td><td>Density</td><td>Isolation forest (IF) outlier detection is applied to mid- level features of network to find OOD samples</td><td>Network does not require further training</td><td>Requires in-data to train IF, IF may not perform well on networks with high-dimensional layers, not tested against other state-of-the-art OOD detection methods</td></tr></table></body></html>  

<html><body><table><tr><td>[118]</td><td>KITTI vs NuScenes</td><td>Generative</td><td>A GAN is trained to create fake data similar to in-data, then a classifier is trained to generate uniform output for out-data and class label for in-data</td><td>Datasetusedforevaluation of model is new</td><td>Data sets might also include domain shift, GAN might create in- data</td></tr><tr><td>[119]</td><td>CIFAR-10, Places365</td><td>Information</td><td>Classification layer is trained to minimize total variation distance between output of outlier data and uniform distribution</td><td>Using new distance metric compared to other works</td><td>Requires outlier data, requires training (at least for classifier)</td></tr><tr><td>[34]</td><td>Dermatology Images Self-Defined</td><td>Information</td><td>Method consists of two stages, firstly, using four different pre-trained Resnet101s, representation of images in feature space is calculated, then a fine-to-coarse classifier is trained to classify inlier and outlier data and their classes</td><td>Working on medical data, focusing on small shifts caused by changes in condition</td><td>Requires some outlier for training, makes an assumption about having label for outlier data</td></tr><tr><td>[120]</td><td>CIFAR-10& CIFAR-100 vs TinyImagenet, LSUN - UCF101, HMDB51 CIFAR-10&</td><td>Density</td><td>FeaturesfromlayerbeforelastFCareforcedto shape as a union of 1d sub-spaces, then at test,spectral discrepancy between sample and vectors for predicted class are used to detect OOD</td><td>Working on Feature space</td><td>Requires Training data, Latent Space Size can effect performance</td></tr><tr><td>[121]</td><td>CIFAR-100 vs Textures, SVHN, Places365, LSUN, iSUN</td><td>Information</td><td>A Gaussian distribution is fitted on outputs of feature layer of network which is used to find in-distribution probabilities</td><td>Network does not require furthur training</td><td>Requires in-data to fit Gaussian, Requires threshold selection</td></tr></table></body></html>  

<html><body><table><tr><td>[122]</td><td>CIFAR10-LT, CIFAR100-LT Imagenet-LTvs afewbenchmarks</td><td>Density</td><td>AContrastivelearninglossiseditedtomerely pulldistancebetweenout-dataandtailin-data withoutconsideringheadin-data First,labelofinput is foundbyfeeding it tonetwork.Thenasmoothedversionofimageis fedtonetwork andanuncertainty score is calculated</td><td>Focusing onOODin Long-Tailedrecognition</td><td>Requires out-data duringtraining</td></tr><tr><td>[123]</td><td>Various behchmarks against eachother</td><td>Information</td><td>basedon itsoutputandlabelofimage which isusedtodetectOOD</td><td>Testedonvarious settings suchasadversarialsample detectionandnovelcorruption, doesnotrequiretraining</td><td>Works on output of classificationlayer</td></tr></table></body></html>  

# 6. Challenges and Future Directions  

In this section of the paper, we discuss our review’s findings and the challenges that still need to be addressed in future studies. While the last sections of the paper were mainly devoted to reviewing each work separately, here, we aim to discuss their findings as a whole to pave the path for new researchers in the field.  

Firstly, after looking at figure 3, it is observable that the most common type of method for OOD detection in papers is information theory backed ones. This is also a logical observation, given that these methods do not require training a new model compared to reconstruction or generative ones. As a result, this trend is expected to continue in the future. Also, Novel models have started appearing in the past couple of years, and their potential yet needs to be explored.  

![](images/e59fcba0a8749b0341162e84195220851e33b52aa2bca5b1987d5aa2d53fcbb8.jpg)  
Figure 3: Various types of methods and frequency of their appearance  

As for implementation, code availability, and testing, some libraries exist for each of these problem settings, and Github repositories of many of them are also available publicly. Consequently, code availability and result reproduction are not mainly a problem in this field of study; however, more recent papers focus on large datasets and models, which makes testing their models nearly impossible for individual researchers. Working on more compact models and benchmarks can help researchers dramatically.  

A few challenges still need to be addressed in evaluation and test settings. It is not easy to compare papers based on their findings without a unified protocol. A complete protocol must contain specific information about the dataset, its splits, metrics, and experiments. This can be viewed to some extent in papers, especially in the ones published in top-tier conferences and on domain generalization, and they mostly use the same protocol as their prior; nevertheless, designing a comprehensive experiment setting can be the focus of a future study.  

Next, mathematical analysis of the difficulty of tasks needs to be addressed. In OSR, the openness of a dataset is introduced as a metric to measure the difficulty of the task at hand; the missing of a similar measure can be felt in other problem settings. Moreover, for some problems such as domain generalization and OSR, other qualitative measures of difficulty can be introduced as well, as generalizing from real photos to sketches is usually considered a more challenging task than from quick-draw to sketches.  

Given the nature of OOD detection, it is expected for models which learn with fewer data to perform better. This can also be seen in model designing, as most of the methods currently do not limit themselves to a partial observation of training data (or no data at all). Moreover, some methods still use outlier data to train their model, which can be problematic when facing different behavior in OOD samples.  

The type of data used is also another challenge faced in OOD literature. As it is shown in the tables, image data is the most commonly used type of data, and others have been left behind. The introduction of datasets on time series, videos, and texts is a direction for future work, which can unveil other challenges that have not been seen yet.  

Long-Tailed recognition [124] has also emerged as another field of study that addresses recognition problems in classes with limited data points. Investigation of the performance of models in this setting and in few-shot learning problems is another direction for future works; notably, a few works have recently initiated this path, such as [81].  

Explainability [125] and interpretability [126] of models is another direction toward trustworthy AI, which focuses on making decisions of model rational. Investigation of how these models perform in OOD settings can be a direction for future studies. Also, these models can be used to explain how OOD detection methods work to improve them further.  

Finally, as Occam’s razor rule mentions, the best model is the simplest one. Nevertheless, simple intuition is not the strongest suit of OOD detection methods, and another direction for researchers can be working on the simplicity of models instead of improving the results of prior ones.  

# 7. Discussion and Conclusion  

In recent years, AI has dramatically changed the world and affected every human’s daily life. From voice assistants [127], and autonomous cars to scales of smart education and smart cities [128], traces of artificial intelligence can be seen almost everywhere. Even now, it can be predicted that applications of AI are still expecting exponential growth in their capabilities [129]; hence, another upsurge in their usage is anticipated. These methods are also expected to perform well in their tasks, as they are used in many critical sectors such as healthcare and military [130]. Moreover, some errors in the output of AI-based methods can also suffer from delayed error detection, such as mobile healthcare [131] where a patient might postpone his doctor appointments by getting wrong healthy results from his device.  

After years of research, there is still a visible gap between most of the research papers and real-world scenarios. Rigorously saying, in the field of ML, many of the papers suffer from proper test designing. The problem arises from the nature of the metrics used in these works, which are all based on the model’s performance in a closed-world, pre-defined, identically and independently distributed dataset. In reality, none of these three conditions can be guaranteed to hold in many real-world problems. Nevertheless, after being violated in new environments, current models perform sensibly poorly in their tasks. These problems, while essential to solve, can also be seen as a new field of research that is built upon the prior ones, a path aiming to make previously created models applicable in a realistic setting.  

Before moving to solve any problem, it is necessary to define expectations from the outcome of the proposed solutions. In OOD literature, the most straightforward definition of expectation from models is to perform well in any situation by assigning correct labels to known classes of data and detecting the unknown. However, this simplest definition is also the most challenging level to achieve. In the simplest form, we can expect models to detect any data which is from a different distribution than training data, and in a more complicated form, we might expect the model to generalize to new data; where some assumptions should be held, such as having enough information or diversity in training data, so the task becomes reasonable. Even after this, preventing models from relying on spurious correlations is challenging. Also, everyone should keep in mind that making mistakes is not the same as performing poorly, and any performance should be measured and evaluated by allowing a fraction of outputs to be wrong; this is rational given that humans also make mistakes all the time, and we still have a long way before competing against human benchmarks.  

Until now, we have discussed the importance of the problem at hand and what we expect from the solutions. The next logical topic of discussion is neighbor fields of study; and what makes them different. From one aspect, OOD literature contributes toward making trustworthy AI models, which makes it a neighbor with calibration [132] and reliability [133] research from a quantitative view and with model interpretation [126] and explainability [125] from a qualitative one. Moreover, from a mathematical view, OOD literature shares a considerable amount of ideas with works done on information and probability theory literature, such as distribution matching [134]. Lastly, OOD takes advantage of many recent ideas and trends in deep learning literature, such as disentangle representation learning [135] and causal learning [136].  

In this paper, we have reviewed more than 70 papers from different segments of OOD literature. In order to form this review, we have first shown how the literature is segmented into different problem settings and what makes each of them unique. By using an SCM, we have tried to clarify the differences and show the reasoning behind every type of change in data distribution. This helps researchers quickly find the best match for their application, given the behavior of their underlying environments. Moreover, we have discussed categories and types of methods applied in the literature. By reading sections III and IV of our paper, interested readers can get a short introduction to OOD literature, its segments, and proposed solutions.  

Next, we reviewed papers in detail in section 5. For each problem setting, a short discussion is presented, which gives enough information and intuition about the problem, benchmarks, and toolboxes that can also work as a headstart for researchers seeking a starting point for this field. Afterward, papers are reviewed in detail in a table for each segment; tables contain information about the type of method, a short summary of it, its advantages and disadvantages, and finally, used datasets. While some might argue that the dataset column is unnecessary in a review table, this can help researchers quickly find works to compare their methods.  

Looking at the tables, the first visible observations are about the types of methods used. Definitely, information theory based methods are the most common in all different categories of shifts. However, while comparing different problem settings, the second most used type of solution is usually unlike. As domain generalization is the only problem setting that pushes toward generalization (rather than detection), studies mainly use novel methods. The reasoning behind that can be seen in the nature of other types of solutions, which are intrinsically created for detecting and recognizing OOD data points. However, density and reconstruction-based methods are more popular in the rest of the problem categories. Also, generative methods are more often seen in recent papers; arguably, they have not yet been appropriately evaluated for the task at hand, but some ideas, such as domain augmentation, are worthy of mentioning and probably will be more analyzed in the future. Overall, for the choice of method, the best and most obvious one is the information theory backed ones, and after that, density and reconstruction based ones for detection and novel methods for generalization.  

Next, by looking at the advantage and disadvantage columns of the tables and simultaneously at the publication date of papers, we can observe that most of the papers can be considered as works in parallel with each other. This might help the literature by diversifying the solutions but causes a delay in solving the main problem. One solution to remedy this issue is introducing new challenges and benchmarks to help researchers compete against each other and also make them informed about the works of others faster. Moreover, in each problem setting, one common disadvantage of papers is focusing on easier problems and benchmarks, which makes their models not comparable with state-of-the-art methods. This is also resolved to some extent with the introduction of new benchmarks. Finally, a detailed analysis of the advantages and disadvantages of reviewed works is presented in section 6 of the manuscript, which aims to introduce directions for future works.  

Lastly, as mentioned, we presented challenges left for future works in section 6; by analyzing the works reviewed, we have tried to find places where the research is mostly missing and needed and suggest them as directions for future research. While we have tried to make this section as comprehensive as possible, the possibilities for future works are limitless; thus, the readers seeking ideas are encouraged to look at the disadvantage column of tables.  

To sum it up, we hope that our survey works as a starting point for new researchers in the field and provides a unifying look into the problem at hand for anyone working on OOD literature. Even though handling distribution shifts in ML literature is not new, works on more advanced DL techniques have started merely recently, and the field can be considered somewhat young. Hopefully, the next few years will hold many advancements for OOD detection, and many challenges will be addressed, making the models that we use in our everyday life more trustworthy.  

# References  

[1] C. M. Bishop, N. M. Nasrabadi, Pattern recognition and machine learning, Vol. 4, Springer, 2006.   
[2] C. M. Keet, Closed world assumption, Encyclopedia of Systems Biology (2013) 415–415.   
[3] M. Dundar, B. Krishnapuram, J. Bi, R. B. Rao, Learning classifiers when the training data is not iid., in: IJCAI, Vol. 2007, 2007, pp. 756–61.   
[4] A. Zhang, Z. C. Lipton, M. Li, A. J. Smola, Dive into deep learning, arXiv preprint arXiv:2106.11342.   
[5] J. P. Cohen, M. Hashir, R. Brooks, H. Bertrand, On the limits of crossdomain generalization in automated x-ray prediction, in: Medical Imaging with Deep Learning, PMLR, 2020, pp. 136–155.   
[6] A. Filos, P. Tigkas, R. McAllister, N. Rhinehart, S. Levine, Y. Gal, Can autonomous vehicles identify, recover from, and adapt to distribution shifts?, in: International Conference on Machine Learning, PMLR, 2020, pp. 3145–3153.   
[7] O¨ . Erkent, C. Laugier, Semantic segmentation with unsupervised domain adaptation under varying weather conditions for autonomous vehicles, IEEE Robotics and Automation Letters 5 (2) (2020) 3580–3587.   
[8] C. Geng, S.-j. Huang, S. Chen, Recent advances in open set recognition: A survey, IEEE transactions on pattern analysis and machine intelligence 43 (10) (2020) 3614–3631.   
[9] I. J. Goodfellow, J. Shlens, C. Szegedy, Explaining and harnessing adversarial examples, arXiv preprint arXiv:1412.6572.   
[10] G. Widmer, M. Kubat, Learning in the presence of concept drift and hidden contexts, Machine learning 23 (1) (1996) 69–101.   
[11] P. Vorburger, A. Bernstein, Entropy-based concept shift detection, in: Sixth International Conference on Data Mining (ICDM’06), IEEE, 2006, pp. 1113–1118.   
[12] B. Scholkopf, R. C. Williamson, A. Smola, J. Shawe-Taylor, J. Platt, Support vector method for novelty detection, Advances in neural information processing systems 12.   
[13] H. Shimodaira, Improving predictive inference under covariate shift by weighting the log-likelihood function, Journal of statistical planning and inference 90 (2) (2000) 227–244.   
[14] J. G. Moreno-Torres, T. Raeder, R. Alaiz-Rodrı´guez, N. V. Chawla, F. Herrera, A unifying view on dataset shift in classification, Pattern recognition 45 (1) (2012) 521–530.   
[15] J.-Y. Zhu, T. Park, P. Isola, A. A. Efros, Unpaired image-to-image translation using cycle-consistent adversarial networks, in: Proceedings of the IEEE international conference on computer vision, 2017, pp. 2223–2232.   
[16] J. Yang, K. Zhou, Y. Li, Z. Liu, Generalized out-of-distribution detection: A survey, arXiv preprint arXiv:2110.11334.   
[17] Z. Shen, J. Liu, Y. He, X. Zhang, R. Xu, H. Yu, P. Cui, Towards out-ofdistribution generalization: A survey, arXiv preprint arXiv:2108.13624.   
[18] K. Zhou, Z. Liu, Y. Qiao, T. Xiang, C. C. Loy, Domain generalization in vision: A survey, arXiv preprint arXiv:2103.02503.   
[19] J. Wang, C. Lan, C. Liu, Y. Ouyang, T. Qin, W. Lu, Y. Chen, W. Zeng, P. Yu, Generalizing to unseen domains: A survey on domain generalization, IEEE Transactions on Knowledge and Data Engineering.   
[20] A. Blazquez-Garcia, A. Conde, U. Mori, J. A. Lozano, A review on outlier/anomaly detection in time series data, ACM Computing Surveys (CSUR) 54 (3) (2021) 1–33.   
[21] H. Xu, Y. Ma, H.-C. Liu, D. Deb, H. Liu, J.-L. Tang, A. K. Jain, Adversarial attacks and defenses in images, graphs and text: A review, International Journal of Automation and Computing 17 (2) (2020) 151–178.   
[22] R. L. Smith, Extreme value theory, Handbook of applicable mathematics 7 (1990) 437–471.   
[23] Z. Wang, Y. Luo, R. Qiu, Z. Huang, M. Baktashmotlagh, Learning to diversify for single domain generalization, in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 834–843.   
[24] J. Serra, D. Alvarez, V. Gomez, O. Slizovskaia, J. F. Nunez, J. Luque, Input complexity and out-of-distribution detection with likelihood-based generative models, arXiv preprint arXiv:1909.11480.   
[25] I. Goodfellow, Y. Bengio, A. Courville, Deep learning, MIT press, 2016.   
[26] D. A. Jackson, Y. Chen, Robust principal component analysis and outlier detection with ecological data, Environmetrics: The official journal of the International Environmetrics Society 15 (2) (2004) 129–139.   
[27] S. Lin, R. Clark, R. Birke, S. Schonborn, N. Trigoni, S. Roberts, Anomaly detection for time series using vae-lstm hybrid model, in: ICASSP 2020- 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Ieee, 2020, pp. 4322–4326.   
[28] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio, Generative adversarial nets, Advances in neural information processing systems 27.   
[29] F. Trauble, E. Creager, N. Kilbertus, F. Locatello, A. Dittadi, A. Goyal. B. Scholkopf, S. Bauer, On disentangled representations learned from correlated data, in: International Conference on Machine Learning, PMLR, 2021, pp. 10401–10412.   
[30] W. Wang, X. Lin, F. Feng, X. He, M. Lin, T.-S. Chua, Causal representation learning for out-of-distribution recommendation, in: Proceedings of the ACM Web Conference 2022, 2022, pp. 3562–3571.   
[31] N. Kardan, A. Sharma, K. O. Stanley, Towards consistent predictive confidence through fitted ensembles, in: 2021 International Joint Conference on Neural Networks (IJCNN), IEEE, 2021, pp. 1–9.   
[32] M. Glymour, J. Pearl, N. P. Jewell, Causal inference in statistics: A primer, John Wiley & Sons, 2016.   
[33] Y. Hu, X. Jia, M. Tomizuka, W. Zhan, Causal-based time series domain generalization for vehicle intention prediction, in: 2022 International Conference on Robotics and Automation (ICRA), IEEE, 2022, pp. 7806–7813.   
[34] A. G. Roy, J. Ren, S. Azizi, A. Loh, V. Natarajan, B. Mustafa, N. Pawlowski, J. Freyberg, Y. Liu, Z. Beaver, et al., Does your dermatology classifier know what it doesn’t know? detecting the long-tail of unseen conditions, Medical Image Analysis 75 (2022) 102274.   
[35] M. Ghifary, W. B. Kleijn, M. Zhang, D. Balduzzi, Domain generalization for object recognition with multi-task autoencoders, in: Proceedings of the IEEE international conference on computer vision, 2015, pp. 2551–2559.   
[36] M. Arjovsky, L. Bottou, I. Gulrajani, D. Lopez-Paz, Invariant risk minimization, arXiv preprint arXiv:1907.02893.   
[37] C. Fang, Y. Xu, D. N. Rockmore, Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias, in: Proceedings of the IEEE International Conference on Computer Vision, 2013, pp. 1657–1664.   
[38] D. Li, Y. Yang, Y.-Z. Song, T. M. Hospedales, Deeper, broader and artier domain generalization, in: Proceedings of the IEEE international conference on computer vision, 2017, pp. 5542–5550.   
[39] H. Venkateswara, J. Eusebio, S. Chakraborty, S. Panchanathan, Deep hashing network for unsupervised domain adaptation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 5018–5027.   
[40] X. Peng, Q. Bai, X. Xia, Z. Huang, K. Saenko, B. Wang, Moment matching for multi-source domain adaptation, in: Proceedings of the IEEE/CVF international conference on computer vision, 2019, pp. 1406–1415.   
[41] Y. Wald, A. Feder, D. Greenfeld, U. Shalit, On calibration and out-ofdomain generalization, Advances in Neural Information Processing Systems 34.   
[42] J. Cha, S. Chun, K. Lee, H.-C. Cho, S. Park, Y. Lee, S. Park, Swad: Domain generalization by seeking flat minima, Advances in Neural Information Processing Systems 34.   
[43] F.-E. Yang, Y.-C. Cheng, Z.-Y. Shiau, Y.-C. F. Wang, Adversarial teacher-student representation learning for domain generalization, Advances in Neural Information Processing Systems 34.   
[44] K. Zhou, Y. Yang, T. Hospedales, T. Xiang, Deep domain-adversarial image generation for domain generalisation, in: Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34, 2020, pp. 13025–13032.   
[45] A. Robey, G. J. Pappas, H. Hassani, Model-based domain generalization, Advances in Neural Information Processing Systems 34 (2021) 20210– 20229.   
[46] Z. Huang, H. Wang, E. P. Xing, D. Huang, Self-challenging improves crossdomain generalization, in: European Conference on Computer Vision, Springer, 2020, pp. 124–140.   
[47] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. Marchand, V. Lempitsky, Domain-adversarial training of neural networks, The journal of machine learning research 17 (1) (2016) 2096– 2030.   
[48] B. Sun, K. Saenko, Deep coral: Correlation alignment for deep domain adaptation, in: European conference on computer vision, Springer, 2016, pp. 443–450.   
[49] K. Saenko, B. Kulis, M. Fritz, T. Darrell, Adapting visual category models to new domains, in: European conference on computer vision, Springer, 2010, pp. 213–226.   
[50] B. Sun, J. Feng, K. Saenko, Return of frustratingly easy domain adaptation, in: Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 30, 2016.   
[51] B. Da Silva, S. S. Shi, Style transfer with time series: Generating synthetic financial data, arXiv preprint arXiv:1906.03232.   
[52] X. Jin, Y. Park, D. C. Maddix, Y. Wang, X. Yan, Domain adaptation for time series forecasting via attention sharing, arXiv preprint arXiv:2102.06828.   
[53] L. L. Guo, S. R. Pfohl, J. Fries, A. E. Johnson, J. Posada, C. Aftandilian, N. Shah, L. Sung, Evaluation of domain generalization and adaptation on improving model robustness to temporal dataset shift in clinical medicine, Scientific reports 12 (1) (2022) 1–10.   
[54] A. Khosla, T. Zhou, T. Malisiewicz, A. A. Efros, A. Torralba, Undoing the damage of dataset bias, in: European Conference on Computer Vision, Springer, 2012, pp. 158–171.   
[55] K. Muandet, D. Balduzzi, B. Scholkopf, Domain generalization via invariant feature representation, in: International Conference on Machine Learning, PMLR, 2013, pp. 10–18.   
[56] T. Cai, F. Chen, W. Liu, X. Xie, Z. Liu, Face anti-spoofing via conditional adversarial domain generalization, Journal of Ambient Intelligence and Humanized Computing (2022) 1–14.   
[57] C. Chen, J. Li, X. Han, X. Liu, Y. Yu, Compound domain generalization via meta-knowledge encoding, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 7119–7129.   
[58] N. Ding, X. Wang, Y. Fu, G. Xu, R. Wang, P. Xie, Y. Shen, F. Huang, H.-T. Zheng, R. Zhang, Prototypical representation learning for relation extraction, arXiv preprint arXiv:2103.11647.   
[59] C. Wan, X. Shen, Y. Zhang, Z. Yin, X. Tian, F. Gao, J. Huang, X.-S. Hua, Meta convolutional neural networks for single domain generalization, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 4682–4691.   
[60] H. Zhang, Y.-F. Zhang, W. Liu, A. Weller, B. Scholkopf, E. P. Xing, Towards principled disentanglement for domain generalization, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 8024–8034.   
[61] D. Li, Y. Yang, Y.-Z. Song, T. Hospedales, Learning to generalize: Metalearning for domain generalization, in: Proceedings of the AAAI conference on artificial intelligence, Vol. 32, 2018.   
[62] D. Miller, N. Sunderhauf, M. Milford, F. Dayoub, Class anchor clustering: A loss for distance-based open set recognition, in: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2021, pp. 3570–3578.   
[63] D.-W. Zhou, H.-J. Ye, D.-C. Zhan, Learning placeholders for open-set recognition, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 4401–4410.   
[64] S. Kong, D. Ramanan, Opengan: Open-set recognition via open data generation, in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 813–822.   
[65] S. Vaze, K. Han, A. Vedaldi, A. Zisserman, Open-set recognition: A good closed-set classifier is all you need, arXiv preprint arXiv:2110.06207.   
[66] P. Oza, V. M. Patel, C2ae: Class conditioned auto-encoder for open-set recognition, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 2307–2316.   
[67] R. Yoshihashi, W. Shao, R. Kawakami, S. You, M. Iida, T. Naemura, Classification-reconstruction learning for open-set recognition, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 4016–4025.   
[68] L. P. Jain, W. J. Scheirer, T. E. Boult, Multi-class open set recognition using probability of inclusion, in: European Conference on Computer Vision, Springer, 2014, pp. 393–409.   
[69] P. Bevandi´c, I. Kresˇo, M. Orˇsic´, S. Sˇegvic´, Dense open-set recognition based on training with noisy negative images, Image and Vision Computing (2022) 104490.   
[70] Y. Yang, C. Hou, Y. Lang, D. Guan, D. Huang, J. Xu, Open-set human activity recognition based on micro-doppler signatures, Pattern Recognition 85 (2019) 60–69.   
[71] W. J. Scheirer, L. P. Jain, T. E. Boult, Probability models for open set recognition, IEEE transactions on pattern analysis and machine intelligence 36 (11) (2014) 2317–2324.   
[72] H. Zhang, V. M. Patel, Sparse representation-based open set recognition, IEEE transactions on pattern analysis and machine intelligence 39 (8) (2016) 1690–1696.   
[73] F. Li, H. Wechsler, Open set face recognition using transduction, IEEE transactions on pattern analysis and machine intelligence 27 (11) (2005) 1686–1697.   
[74] S. Huang, J. Ma, G. Han, S.-F. Chang, Task-adaptive negative envision for few-shot open-set recognition, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 7171–7180.   
[75] S. Gidaris, N. Komodakis, Dynamic few-shot visual learning without forgetting, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 4367–4375.   
[76] M. Mundt, I. Pliushch, S. Majumder, Y. Hong, V. Ramesh, Unified probabilistic deep continual learning through generative replay and open set recognition, Journal of Imaging 8 (4) (2022) 93.   
[77] D. J. Kim, J. S. Kim, J. H. Yang, S. C. Kee, C. C. Chung, Lane change intention classification of surrounding vehicles utilizing open set recognition, IEEE Access 9 (2021) 57589–57602.   
[78] J. Jang, C. O. Kim, Collective decision of one-vs-rest networks for openset recognition, IEEE Transactions on Neural Networks and Learning Systems.   
[79] D. T. Tran, N. Shimada, J.-H. Lee, Triple-sigmoid activation function for deep open-set recognition, IEEE Access 10 (2022) 77668–77678.   
[80] H. Shao, D. Zhong, Towards open-set touchless palmprint recognition via weight-based meta metric learning, Pattern Recognition 121 (2022) 108247.   
[81] J. Cai, Y. Wang, H.-M. Hsu, J.-N. Hwang, K. Magrane, C. S. Rose, Luna: Localizing unfamiliarity near acquaintance for open-set long-tailed recognition, in: Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36, 2022, pp. 131–139.   
[82] S. Yang, Y. Wang, K. Wang, S. Jui, J. van de Weijer, One ring to bring them all: Towards open-set recognition under domain shift, arXiv preprint arXiv:2206.03600.   
[83] G. Christie, N. Fendley, J. Wilson, R. Mukherjee, Functional map of the world, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018.   
[84] P. Bandi, O. Geessink, Q. Manson, M. Van Dijk, M. Balkenhol, M. Hermsen, B. E. Bejnordi, B. Lee, K. Paeng, A. Zhong, et al., From detection of individual metastases to classification of lymph node status at the patient level: the camelyon17 challenge, IEEE Transactions on Medical Imaging.   
[85] M. P. Naeini, G. Cooper, M. Hauskrecht, Obtaining well calibrated probabilities using bayesian binning, in: Twenty-Ninth AAAI Conference on Artificial Intelligence, 2015.   
[86] M. Wang, W. Deng, Deep visual domain adaptation: A survey, Neurocomputing 312 (2018) 135–153.   
[87] W. J. Scheirer, A. de Rezende Rocha, A. Sapkota, T. E. Boult, Toward open set recognition, IEEE transactions on pattern analysis and machine intelligence 35 (7) (2012) 1757–1772.   
[88] L. Neal, M. Olson, X. Fern, W.-K. Wong, F. Li, Open set learning with counterfactual images, in: Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 613–628.   
[89] Y. Su, Y. Zhao, C. Niu, R. Liu, W. Sun, D. Pei, Robust anomaly detection for multivariate time series through stochastic recurrent neural network, in: Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, 2019, pp. 2828–2837.   
[90] A. Chakraborty, M. Alam, V. Dey, A. Chattopadhyay, D. Mukhopadhyay, Adversarial attacks and defences: A survey, arXiv preprint arXiv:1810.00069.   
[91] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, R. Fergus, Intriguing properties of neural networks, arXiv preprint arXiv:1312.6199.   
[92] A. Kurakin, I. J. Goodfellow, S. Bengio, Adversarial examples in the physical world, in: Artificial intelligence safety and security, Chapman and Hall/CRC, 2018, pp. 99–112.   
[93] Y. Zhao, Z. Nasrullah, Z. Li, Pyod: A python toolbox for scalable outlier detection, Journal of Machine Learning Research 20 (96) (2019) 1–7. URL http://jmlr.org/papers/v20/19-011.html   
[94] M.-I. Nicolae, M. Sinn, M. N. Tran, B. Buesser, A. Rawat, M. Wistuba, V. Zantedeschi, N. Baracaldo, B. Chen, H. Ludwig, I. Molloy, B. Edwards, Adversarial robustness toolbox v1.2.0, CoRR 1807.01069. URL https://arxiv.org/pdf/1807.01069   
[95] H. Cai, J. Liu, W. Yin, Learned robust pca: A scalable deep unfolding approach for high-dimensional outlier detection, Advances in Neural Information Processing Systems 34.   
[96] Q. Rebjock, B. Kurt, T. Januschowski, L. Callot, Online false discovery rate control for anomaly detection in time series, Advances in Neural Information Processing Systems 34.   
[97] J. Tack, S. Mo, J. Jeong, J. Shin, Csi: Novelty detection via contrastive learning on distributionally shifted instances, Advances in neural information processing systems 33 (2020) 11839–11852.   
[98] T. Chen, S. Kornblith, M. Norouzi, G. Hinton, A simple framework for contrastive learning of visual representations, in: International conference on machine learning, PMLR, 2020, pp. 1597–1607.   
[99] Z. Wang, B. Dai, D. Wipf, J. Zhu, Further analysis of outlier detection with deep generative models.   
[100] J. Yang, S. Rahardja, P. Franti, Mean-shift outlier detection and filtering, Pattern Recognition 115 (2021) 107874.   
[101] Z. Cheng, E. Zhu, S. Wang, P. Zhang, W. Li, Unsupervised outlier detection via transformation invariant autoencoder, IEEE Access 9 (2021) 43991–44002.   
[102] Z. Li, Y. Zhao, N. Botta, C. Ionescu, X. Hu, Copod: copula-based outlier detection, in: 2020 IEEE International Conference on Data Mining (ICDM), IEEE, 2020, pp. 1118–1123.   
[103] G. O. Campos, A. Zimek, J. Sander, R. J. Campello, B. Micenkova, E. Schubert, I. Assent, M. E. Houle, On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study, Data mining and knowledge discovery 30 (4) (2016) 891–927.   
[104] J. Cheng, N. Vasconcelos, Learning deep classifiers consistent with finegrained novelty detection, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 1664–1673.   
[105] A. Shah, N. Azam, B. Ali, M. T. Khan, J. Yao, A three-way clustering approach for novelty detection, Information Sciences 569 (2021) 650–668.   
[106] Z. Wang, T. Jian, A. Masoomi, S. Ioannidis, J. Dy, Revisiting hilbertschmidt information bottleneck for adversarial robustness, Advances in Neural Information Processing Systems 34.   
[107] K. Lee, K. Lee, H. Lee, J. Shin, A simple unified framework for detecting out-of-distribution samples and adversarial attacks, Advances in neural information processing systems 31.   
[108] Z. Zheng, P. Hong, Robust detection of adversarial attacks by modeling the intrinsic properties of deep neural networks, Advances in Neural Information Processing Systems 31.   
[109] F. V. Massoli, F. Carrara, G. Amato, F. Falchi, Detection of face recognition adversarial attacks, Computer Vision and Image Understanding 202 (2021) 103103.   
[110] X. Wang, S. Li, M. Liu, Y. Wang, A. K. Roy-Chowdhury, Multi-expert adversarial attack detection in person re-identification using context inconsistency, in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 15097–15107.   
[111] W. Morningstar, C. Ham, A. Gallagher, B. Lakshminarayanan, A. Alemi, J. Dillon, Density of states estimation for out of distribution detection, in: International Conference on Artificial Intelligence and Statistics, PMLR, 2021, pp. 3232–3240.   
[112] S. Liang, Y. Li, R. Srikant, Enhancing the reliability of out-of-distribution image detection in neural networks, arXiv preprint arXiv:1706.02690.   
[113] Y. Sun, C. Guo, Y. Li, React: Out-of-distribution detection with rectified activations, Advances in Neural Information Processing Systems 34 (2021) 144–157.   
[114] J. Gawlikowski, S. Saha, A. Kruspe, X. X. Zhu, An advanced dirichlet prior network for out-of-distribution detection in remote sensing, IEEE Transactions on Geoscience and Remote Sensing 60 (2022) 1–19.   
[115] J. Ren, P. J. Liu, E. Fertig, J. Snoek, R. Poplin, M. Depristo, J. Dillon, B. Lakshminarayanan, Likelihood ratios for out-of-distribution detection, Advances in neural information processing systems 32.   
[116] W. Liu, X. Wang, J. Owens, Y. Li, Energy-based out-of-distribution detection, Advances in Neural Information Processing Systems 33 (2020) 21464–21475.   
[117] S. Luan, Z. Gu, L. B. Freidovich, L. Jiang, Q. Zhao, Out-of-distribution detection for deep neural networks with isolation forest and local outlier factor, IEEE Access 9 (2021) 132980–132989.   
[118] J. Nitsch, M. Itkina, R. Senanayake, J. Nieto, M. Schmidt, R. Siegwart, M. J. Kochenderfer, C. Cadena, Out-of-distribution detection for automotive perception, in: 2021 IEEE International Intelligent Transportation Systems Conference (ITSC), IEEE, 2021, pp. 2938–2943.   
[119] A.-A. Papadopoulos, M. R. Rajati, N. Shaikh, J. Wang, Outlier exposure with confidence control for out-of-distribution detection, Neurocomputing 441 (2021) 138–150.   
[120] A. Zaeemzadeh, N. Bisagno, Z. Sambugaro, N. Conci, N. Rahnavard, M. Shah, Out-of-distribution detection using union of 1-dimensional subspaces, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 9452–9461.   
[121] P. Morteza, Y. Li, Provable guarantees for understanding out-ofdistribution detection, in: Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 8, 2022.   
[122] H. Wang, A. Zhang, Y. Zhu, S. Zheng, M. Li, A. J. Smola, Z. Wang, Partial and asymmetric contrastive learning for out-of-distribution detection in long-tailed recognition, in: International Conference on Machine Learning, PMLR, 2022, pp. 23446–23458.   
[123] J. Lust, A. P. Condurache, Efficient detection of adversarial, out-ofdistribution and other misclassified samples, Neurocomputing 470 (2022) 335–343.   
[124] Z. Liu, Z. Miao, X. Zhan, J. Wang, B. Gong, S. X. Yu, Large-scale longtailed recognition in an open world, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 2537– 2546.   
[125] P. Angelov, E. Soares, Towards explainable deep neural networks (xdnn), Neural Networks 130 (2020) 185–194.   
[126] Q.-s. Zhang, S.-C. Zhu, Visual interpretability for deep learning: a survey, Frontiers of Information Technology & Electronic Engineering 19 (1) (2018) 27–39.   
[127] S. H. Hsieh, C. T. Lee, Hey alexa: examining the effect of perceived socialness in usage intentions of ai assistant-enabled smart speaker, Journal of Research in Interactive Marketing.   
[128] R. S. Lee, Artificial intelligence in daily life, Springer, 2020.   
[129] C. Calum, Artificial intelligence and the two singularities, Chapman and Hall/CRC, 2018.   
[130] N. Masuhr, Ai in military enabling applications, CSS Analyses in Security Policy 251.   
[131] Y. Yang, H. Wang, R. Jiang, X. Guo, J. Cheng, Y. Chen, A review of iotenabled mobile healthcare: Technologies, challenges, and future trends, IEEE Internet of Things Journal.   
[132] R. Krishnan, O. Tickoo, Improving model calibration with accuracy versus uncertainty optimization, Advances in Neural Information Processing Systems 33 (2020) 18237–18248.   
[133] Y. Balagurunathan, R. Mitchell, I. El Naqa, Requirements and reliability of ai in the medical context, Physica Medica 83 (2021) 72–78.   
[134] P. Schulte, G. Bocherer, Constant composition distribution matching, IEEE Transactions on Information Theory 62 (1) (2015) 430–434.   
[135] X. Liu, P. Sanchez, S. Thermos, A. Q. O’Neil, S. A. Tsaftaris, Learning disentangled representations in the imaging domain, Medical Image Analysis (2022) 102516.   
[136] B. Scholkopf, F. Locatello, S. Bauer, N. R. Ke, N. Kalchbrenner, A. Goyal, Y. Bengio, Toward causal representation learning, Proceedings of the IEEE 109 (5) (2021) 612–634.  