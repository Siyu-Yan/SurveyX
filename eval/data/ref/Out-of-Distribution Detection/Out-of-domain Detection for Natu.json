{
    "from": "google",
    "scholar_id": "woQx73HluW0J",
    "detail_id": null,
    "title": "Out-of-domain Detection for Natu",
    "abstract": "\n\nAbstract\u2014Natural Language Understanding (NLU) is a vital component of dialogue systems, and its ability to detect Out-ofDomain (OOD) inputs is critical in practical applications, since the acceptance of the OOD input that is unsupported by the current system may lead to catastrophic failure. However, most existing OOD detection methods rely heavily on manually labeled OOD samples and cannot take full advantage of unlabeled data. This limits the feasibility of these models in practical applications. In this paper, we propose a novel model to generate highquality pseudo OOD samples that are akin to IN-Domain (IND) input utterances and thereby improves the performance of OOD detection. To this end, an autoencoder is trained to map an input utterance into a latent code. Moreover, the codes of IND and OOD samples are trained to be indistinguishable by utilizing a generative adversarial network. To provide more supervision signals, an auxiliary classifier is introduced to regularize the generated OOD samples to have indistinguishable intent labels. Experiments show that these pseudo OOD samples generated by our model can be used to effectively improve OOD detection in NLU. Besides, we also demonstrate that the effectiveness of these pseudo OOD data can be further improved by efficiently utilizing unlabeled data.\nIndex Terms\u2014Natural language understanding, Out-of-domain detection, Dialogue system, Text classification.\n\nI. I NTRODUCTION\n\nN ATURAL Language Understanding (NLU) in dialog systems such as task-oriented dialog systems and intelligent personal assistants is vital for understanding users\u2019 input to make effective human-machine interaction. An NLU module maps unstructured text inputs to structured dialog acts and has a crucial influence on the downstream processing pipelines of a dialog system. Therefore, the reliability of NLU becomes a precursor to the success of dialog systems. Recently, various deep neural network-based NLU models are proposed, and some of thes",
    "bib_name": "Out-of-dom4",
    "md_text": "# Out-of-domain Detection for Natural Langua Understanding in Dialog Systems\n\nYinhe Zheng, Guanyi Chen, Minlie Huang\n\nAbstract\u2014Natural Language Understanding (NLU) is a vital component of dialogue systems, and its ability to detect Out-ofDomain (OOD) inputs is critical in practical applications, since the acceptance of the OOD input that is unsupported by the current system may lead to catastrophic failure. However, most existing OOD detection methods rely heavily on manually labeled OOD samples and cannot take full advantage of unlabeled data. This limits the feasibility of these models in practical applications. In this paper, we propose a novel model to generate highquality pseudo OOD samples that are akin to IN-Domain (IND) input utterances and thereby improves the performance of OOD detection. To this end, an autoencoder is trained to map an input utterance into a latent code. Moreover, the codes of IND and OOD samples are trained to be indistinguishable by utilizing a generative adversarial network. To provide more supervision signals, an auxiliary classifier is introduced to regularize the generated OOD samples to have indistinguishable intent labels. Experiments show that these pseudo OOD samples generated by our model can be used to effectively improve OOD detection in NLU. Besides, we also demonstrate that the effectiveness of these pseudo OOD data can be further improved by efficiently utilizing unlabeled data.\nIndex Terms\u2014Natural language understanding, Out-of-domain detection, Dialogue system, Text classification.\n\nI. I NTRODUCTION\n\nN ATURAL Language Understanding (NLU) in dialog systems such as task-oriented dialog systems and intelligent personal assistants is vital for understanding users\u2019 input to make effective human-machine interaction. An NLU module maps unstructured text inputs to structured dialog acts and has a crucial influence on the downstream processing pipelines of a dialog system. Therefore, the reliability of NLU becomes a precursor to the success of dialog systems. Recently, various deep neural network-based NLU models are proposed, and some of these models have been applied in real-world applications [1]\u2013[3].\n\nYinhe Zheng is with Samsung Research China - Beijing (SRC-B), Beijing 100102, China, and Tsinghua University, Beijing 100084, China. This work was done when he works as a post-doctor in a joint program of Tsinghua University and SRC-B (e-mail: yh.zheng@samsung.com, zhengyinhe1@163.com). Guanyi Chen is with the Department of Information and Computing Sciences, Utrecht University, 3584 CC Utrecht, Netherlands (email: g.chen@uu.nl). Minlie Huang is with the Institute for Artificial Intelligence, State Key Lab of Intelligent Technology and Systems, Beijing National Research Center for Information Science and Technology, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China (email: aihuang@tsinghua.edu.cn). This work was supported by the National Science Foundation of China (Grant No. 61936010/61876096) and the National Key R&D Program of China (Grant No. 2018YFC0830200). Manuscript received in 27-Oct-2019; revised in 33-Mar-2020. Corresponding author: Minlie Huang.\n\nMost existing neural NLU modules are built by following a closed-world assumption [4], [5], i.e., the data used in training and testing phrase are drawn from the same distribution. However, such an assumption is commonly violated in practical systems that are deployed in a dynamic or open environment. Specifically, practical NLU modules often encounter out-ofdomain (OOD) inputs that are not supported by the system and thus not observed in the training data. Wrongly accepting these inputs and executing undesired commands may trigger catastrophic failures, particularly in risk-sensitive applications where safety is the top priority, such as robots or self-driving cars. In order to address this issue, a more realistic assumption of open-world [4], [5] has been proposed. An NLU system built under this assumption should be able to not only correctly analyze in-domain (IND) inputs but also reliably reject OOD inputs that are not supported by the system. Various methods have been proposed to improve the OOD detection performance of neural NLU models [6]\u2013[10], and most of them follow a threshold-based protocol. Specifically, a detection score is computed for each input, and then a threshold is selected using a validation set. The inputs whose scores are lower than the threshold are considered to be OOD inputs and then rejected. A simple yet efficient approach is to use the maximum value of the Softmax output as the detection score [11], which has been demonstrated to work surprisingly well on the image classification tasks [12], and thus has been applied in many state-of-the-art systems [12], [13]. Further developments in this direction propose to add an extra entropy regularization (ER) term in the training objective, and significant performance improvement for OOD detection is reported when this ER term is optimized using a set of OOD data [14], [15]. However, collecting large-scale OOD data is usually difficult and expensive in practice, especially when dealing with the ever-changing open-world environment. This limits the feasibility of the ER technique in practical applications. To address this issue, some studies [14], [16] have proposed to generate pseudo OOD samples with a generative adversarial network (GAN) [17]. These generated samples can be used to optimize the ER term and thus improve the OOD detection performance. However, existing approaches only work in continuous space (such as generating OOD images or continuous feature vectors), whereas the input to NLU modules is usually a sequence of discrete tokens. It is yet to be explored to generate pseudo OOD samples in discrete spaces (like natural language) that can be effectively utilized to improve the OOD detection performance. Moreover, unlabeled data (i.e., a mixture of IND and OOD samples) are usually easier to obtain\n\nin practical applications (e.g., through user logs), but rarely utilized in existing OOD detection methods. It is attractive to take advantage of these unlabeled data to improve the OOD detection performance since we can expect to gain some prior knowledge about the testing OOD distribution through these unlabeled data. In this paper, we study how generated pseudo OOD samples and unlabeled data can facilitate OOD detection in NLU systems. We follow the simple and efficient approach to add an ER term in the training objective. However, we focus more on the way of generating high-quality pseudo OOD samples to effectively optimize this term. To this end, we propose a novel pseudo OOD sample generation model (POG) (depicted in Figure 1). The proposed model POG consists of three components: 1) a reconstruction module, 2) an adversarial generation module, and 3) an auxiliary classifier. In the reconstruction module, an encoder maps a text input into a latent code, and a decoder reconstructs the text from the latent code. A generator is then trained to produce fake latent codes, and a discriminator is trained to distinguish these fake codes from the real ones with an adversarial training process. In order to provide more supervision signals, an auxiliary classifier is further introduced to predict the correct labels associated with the reconstructed samples and to regularize the generated OOD samples to have indistinguishable labels. Experiments show that the OOD samples generated using our model can effectively improve the performance of OOD detection. We also demonstrate that unlabeled data can be used to train the reconstruction module and thus boost the effectiveness of the generated pseudo OOD samples. To summarize, our contributions are in three folds:\n1) We propose a novel model to generate pseudo OOD samples. The model consists of an autoencoder, an adversarial training component, and an auxiliary classifier. The generated samples can be used to effectively improve the OOD detection performance of NLU by optimizing the entropy regularization (ER) term in the training stage.\n2) The proposed model can take advantage of unlabeled data to improve the effectiveness of the generated OOD samples. This makes our model more suitable for practical applications.\n3) We evaluate the model on two datasets. Results show that our model can significantly outperform other competitive baselines for OOD detection.\n\n# II. R ELATED W ORK\n\nThe problem of OOD detection has been investigated in many contexts with different alias, such as \u201canomaly detection\u201d [15], \u201cone-class classification\u201d [18], [19], \u201copen-set recognition\u201d [20], or \u201cnovelty detection\u201d [21]. Significant results have been achieved by conventional methods in lowdimensional spaces [19], [22], and some of these methods have also been applied to NLU systems [23], [24]. Some recent neural models use only IND data for OOD detection. Most of these methods follow the threshold-based protocol, and various approaches for calculating the detection\n\nscores are devised. Popular approaches include modeling the probability density [8], [25], computing reconstruction losses [7], [26], [27], using classifier ensembles [13], [28], applying Bayesian models [29], relying on distances to nearestneighbors [9], [30], or even explicitly learning a detection score [31]. Some KNN-based methods are also applied to handle text inputs [32], [33]. However, most of these methods are computationally expensive either in training or inference, and cannot take full advantage of unlabeled data to improve the OOD detection performance. Some of these methods also require a tremendous amount of memories as the number of classes increases [33]. All these disadvantages limit the feasibility of these methods in practical applications. Another type of neural-based OOD detection model aims to utilize a set of OOD data in the training phase. Specifically, a special \u201cOOD\u201d label is added in a binary or multi-class classifier (e.g., [34]), and the inputs that fall into this special \u201cOOD\u201d class is rejected. However, the feasibility of this naive approach is limited in practice since suitable OOD data are usually hard to collect, and incorporating too many irrelevant OOD samples in training may cause a serious issue of data imbalance. Further, the OOD distribution is usually too broad to capture with these limited OOD data. Our study is also related to a large number of works on controllable text generation [35]\u2013[37], some of which also involve an adversarial training process [38], [39] and controls the generated content. However, most previous studies for controllable text generation aim to model a smooth representation space and produce fluent utterances within the data distribution, whereas our model targets at improving the OOD detection performance of an NLU system and tries to generate effective OOD samples that are not in the given data distribution. Another branch of related studies is the Positive and Unlabeled (PU) learning [40], in which a learning algorithm has only access to positive examples and unlabeled data. The difference between our study and PU learning models is that we aim to reject all samples that are not from IND classes. There is no guarantee that the unlabeled data can cover the entire OOD distribution, which is usually too large to tackle. However, the negative distribution considered in PU learning models is assumed to be completely covered by the unlabeled data. There are two closely relevant studies from Ryu et al. [16] and Lee et al. [14]. These studies utilize a GAN based generator to produce OOD samples when building the OOD detector. The major difference between our study and these works is that we focus on generating discrete token sequences, whereas previous works can only generate samples in the continuous space (e.g., images or continuous feature vectors). Moreover, our model can also utilize unlabeled data to improve OOD detection performance, while previous works only use IND data.\n\n# III. M ODEL\n\n# A. Task Definition\n\nIn this study, we aim at improving the OOD detection performance of a practical NLU module in a dialogue system.\n\nWe focus on the intent classification task since it is the most important role of an NLU module. These OOD inputs that are not supported by the current system are rejected once they are detected in the intent classification process. Our task can be formally defined as below: Given a set of IND data, which are drawn independently from an IND distribution P ind, i.e,\n\nand a set of unlabeled data, which are either drawn from the IND distribution P ind or the OOD distribution P ood, i.e.,\n\nD mix = {\u02c6 x 1, \u00b7 \u00b7 \u00b7, \u02c6 x n} \u223cP ind or P ood,\n\nwhere x i and \u02c6 x i represent utterances, and y i \u2208{l 1, \u00b7 \u00b7 \u00b7, l m} is x i \u2019s label (i.e., intent type). We aim to build an intent classifier which can (1) reject the input x if x is drawn from P ood, and (2) predict the correct intent type of x if it is from P ind. Note that in most cases, P ood is not known, or its underlying space is too large to explore. We cannot expect to capture the entire P ood with the limited OOD data sampled from D mix. However, we can expect to gain some prior knowledge about the OOD distribution with the help of D mix to improve the performance of OOD detection.\n\n# B. Classifier with Entropy Regularization\n\nIn this study, the threshold based approach is used for detecting OOD inputs. Similar to the method introduced in [11], we use the maximum value of the Softmax output as the OOD detection score. Specifically, the intent classifier is built with a Softmax output layer to predict an m-dimension distribution P \u03b8 (y | x) for each input utterance x:\n\nThe detection score for x is obtained by:\n\n(1)\n\nwhere \u03b8 denotes the parameters of the classifier, and m is the number of intent types in the NLU module. In order to determine whether an input utterance x is from P ind or P ood, a threshold t is chosen (usually based on the validation set). The input x is regarded as an IND sample and further processed by the system if Score (x) \u2265 t, otherwise it is determined to be an OOD sample and thus rejected by the system. Therefore, it is desirable for IND inputs to obtain higher detection scores, while OOD inputs to obtain lower detection scores. Usually, the intent classifier is trained by minimizing the cross-entropy loss:\n\n(2)\n\nMinimizing L ce (\u03b8) on D ind enforces the classifier to produce confident predictions on IND samples, which leads to high detection score. However, neural models trained based on the cross-entropy loss tend to be overconfident [41], which results in the fact that samples from P ood may also receive a high detection score [12] if they share similar patterns and phrases\n\nwith some IND samples. For example, consider a smartphone without a Bluetooth module. The intelligent assistant equipped on the phone may receive the OOD utterance \u201cTurn on the Bluetooth please\u201d from the user, who may not be familiar with the precise capability of the smartphone. This OOD input may receive a high detection score since the pattern \u201cTurn on ... please\u201d is commonly used in other IND inputs. This makes the IND and OOD inputs indistinguishable with the detection scores. In order to address this issue, a regularization term can be added to enforce a high entropy for the samples from P ood, i.e.,\n\n(3)\n\nwhere H is the Shannon entropy of the predicted distribution. This term is similar to the confidence loss used in [14] as it enforces the predicted distribution of OOD inputs closer to the uniform distribution, and thus leads to lower detection scores for OOD inputs. The total loss for the intent classifier is\n\nL cls (\u03b8) = L ce (\u03b8) + \u03b1 L ent (\u03b8)\n\n(4)\n\nwhere \u03b1 is a hyper-parameter to balance the contribution of the entropy regularization term. In this study, we set \u03b1 = 1 1. Note that in the original work of [15], L ent (\u03b8) is optimized with samples drawn from P ood. Ideally, we should sample all types of OOD inputs if we cannot obtain any prior knowledge for P ood. However, this is often infeasible, if not impossible, in practical applications. We thus propose to tackle this issue with a pseudo OOD sample generation module, which will be detailed in the next section.\n\nIn this section, we present a novel pseudo OOD sample generation (POG) model, which employs an adversarial generation process. The produced pseudo OOD samples can be used to evaluate the entropy regularization term L ent (\u03b8), thereby improving the performance of OOD detection. 1) Model Overview:  The overall architecture of the proposed POG model is shown in Figure 1. Three major components are included: 1) an autoencoder, 2) an adversarial generation module, and 3) an auxiliary classifier. The idea of generating effective pseudo OOD samples originates from this observation: most OOD samples look similar to IND inputs (i.e., sharing the same phrases or patterns) but do not correspond to any IND intents. Such OOD samples are usually harder to detect, and more efficient for improving the OOD detection performance if they are used to optimize the ER term [14]. Therefore, in this study, we use the autoencoder to map an input utterance x into a latent code z and use the adversarial generation module to imitate the real latent code z with a fake one \u02dc z. In this way, the generated utterance \u02dc x \u2032\nwill look similar to the reconstructed utterance x \u2032. Further, the auxiliary classifier is trained to predict the correct intent label associated with the reconstructed utterance x \u2032 and used to regularize the latent code generator to make sure the generated\n\n1 We also tried other values for \u03b1, but the experiments show that the final result is not sensitive to this value.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5e48/5e48f8fa-3a2c-4f27-b295-034fa47b2d42.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">hitecture of the pseudo OOD sample generation (POG) model. An encoder Enc \u03c6 transforms an input utterance x to a latent code z. A structs x \u2032 from z. A generator G \u03be is built to map a Gaussian noise to a fake latent code \u02dc z and a discriminator D \u03b7 distinguishes the fake code z with an adversarial training process. An auxiliary classifier AC \u03c9 is trained to predict the correct label associated with x \u2032, and G \u03be e gradients derived from AC \u03c9 which enforces utterance \u02dc x \u2032 generated from \u02dc z to follow an uniform distribution.\n</div>\nutterance \u02dc x \u2032 to have indistinguishable intent labels and thus being OOD. Each component is detailed below. 2) Autoencoder:  This component intends to capture a continuous latent space for the input utterances so that we can apply gradient-based approaches more easily. It contains two functions: An encoder Enc \u03c6 (parameterized by \u03c6) that maps an input utterance x to a latent code z, i.e.,\n\nand an decoder P \u03c8 (x | z) (parameterized by \u03c8) that reconstructs an utterance x \u2032 out of z. The autoencoder is trained by minimizing the reconstruction loss:\n\n(5)\n\nNote that in order to smooth the latent space, we add a Gaussian noise \u03f5 \u223cN (0, I) to z before feeding it to the decoder in the training phase, i.e., the input utterance x is first encoded into a continuous vector z, and then a noise \u03f5 is sampled from the standard normal distribution N (0, I). A reconstructed utterance x \u2032 is generated based on the latent code z + \u03f5 and the autoencoder is optimized to minimize the reconstruction loss shown in Eq.5. This approach is reported to be effective for smoothing the produced latent space of an autoencoder [38]. 3) Adversarial Generation Module: This component uses an adversarial training process to approximate the latent codes corresponding to the IND data. Two functions are involved: a generator G \u03be which maps a noise \u03f5 \u223cN to a latent code \u02dc z, i.e.,\n\nand a discriminator D \u03b7 which distinguishes the real latent code z from the generated latent code \u02dc z. Intuitively, the generator aims to fool the discriminator, while the discriminator aims to discriminate real codes from generated ones. Once the training is done, the generated latent code \u02dc z is expected to be able to produce utterances that are similar to the IND inputs. In this study, we train our generator and discriminator by minimizing the Wasserstein-1 distance [42] between the generated distribution and the data distribution. Specifically, the loss for the generator is\n\n(6)\n\nwhereas the loss for the discriminator is:\n\n(7)\n\nIn order to enforce the 1-Lipschitz constraint [42] on the discriminator D \u03b7, we employ the gradient penalty term as proposed in [43]:\n\n(8)\n\nwhere the sampling process from P \u02c6 x is approximated by uniformly interpolating between two random samples, one from the data distribution and another from the generated distribution [43]. 4) Auxiliary Classifier: This component of our model maps a decoded utterance to an m-dimension label distribution, where m is the number of IND intent labels. The parameters \u03c9 of the auxiliary classifier (AC) P \u03c9 (y | x \u2032) are optimized with the cross-entropy loss to predict the correct intent label associated with the utterances x \u2032 decoded from the \u201creal\u201d latent code. Specifically, for an IND input x i (with intent label y i) that is sampled from the training data, the corresponding \u201creal\u201d latent code z i = Enc \u03c6 (x i) is first generated using the encoder and a reconstructed utterance x \u2032 i is decoded based on z i. Then we feed the decoded utterance x \u2032 i to the AC and try to predict its intent label y i. The following loss is optimized:\n\n(9)\n\nFurther, we use the AC to guide our latent code generator G \u03be to produce latent codes that can be decoded into OOD samples, i.e., the generator G \u03be is optimized to enforce a high entropy for the predicted distribution of the AC on the utterance \u02dc x \u2032\ndecoded from the \u201cfake\u201d latent code. Specifically, we first sample a noise \u03f5 \u223cN from the standard normal distribution and generate a \u201cfake\u201d code \u02dc z = G \u03be (\u03f5) using the generator. An utterance \u02dc x \u2032 is decoded based on \u02dc z (i.e., \u02dc x \u2032 \u223c P \u03c8 (x | \u02dc z)) and the following loss is optimized:\n\n(10)\n\nwhere y denotes the intent type space. Note that the latent code generator G \u03be trained using the loss L g (\u03be) and L \u2032 ent (\u03be) is trying to accomplish two adversarial targets: First, the adversarial loss L g (\u03be) forces the generated\n\nAlgorithm 1 Training Procedure of POG\n1: for each training iteration do\n/* (1) Train the autoencoder (Enc\u03c6, Dec\u03c8)\nand the auxiliary classifier (AC\u03c9) */\n2:\nSample {xi, yi}M\ni=1 \u223cDind\n3:\nCompute zi = Enc\u03c6(xi), i = 1, \u00b7 \u00b7 \u00b7 , M\n4:\nAdd Gaussian noise zi \u2190\u2212zi + \u03f5, \u03f5 \u223cN(0, I)\n5:\nUpdate \u03c6, \u03c8 by minimizing Lrec(\u03c6, \u03c8)\n6:\nDecode x\u2032\ni \u223cP\u03c8(x|zi)\n7:\nUpdate \u03c9 by minimizing L\u2032ce(\u03c9)\n/* (2) Train the discriminator (D\u03b7) */\n8:\nSample {xi, yi}M\ni=1 \u223cDind, {\u03f5i}M\ni=1 \u223cN\n9:\nCompute zi = Enc\u03c6(xi), and \u02dczi = G\u03be(\u03f5i)\n10:\nUpdate \u03b7 by minimizing Ld(\u03b7) + Lgp(\u03b7)\n/* (3) Train the generator (G\u03be) */\n11:\nSample {\u03f5i}M\ni=1 \u223cN\n12:\nCompute \u02dczi = G\u03be(\u03f5i)\n13:\nUpdate \u03be by minimizing Lg(\u03be)\n14:\nDecode \u02dcx\u2032\ni \u223cP\u03c8(x|\u02dczi)\n15:\nUpdate \u03be by minimizing L\u2032ent(\u03be)\n16: end for\nlatent code to be close to the IND space, and thus makes the decoded utterance \u02dc x \u2032 looks similar to utterances in D ind; Second, the regularization loss L \u2032 ent (\u03be) ensures the intent associated with the decoded utterance \u02dc x \u2032 cannot be predicted by the AC. Specifically, L \u2032 ent (\u03be) reaches its minimum when the AC produces a uniform distribution, which means \u02dc x \u2032 does not belong to any existing intent labels. It is expected that these losses can guide our model to generate OOD samples near the IND distribution (i.e., look similar to the IND samples), thereby making the model more effective in OOD detection. The training process of the POG model is detailed in Algorithm 1. Note that the text sample \u02dc x \u2032 i which is decoded in Step 14 of Algorithm 1 is discrete and non-differentiable, which hinders the gradients back-propagating from the AC to the generator G \u03be through the loss L \u2032 ent (\u03be) in Step 15 . In order to address this issue, we use a continuous approximation approach to replace the token (i.e., one-hot vector) sampled at each time step in \u02dc x \u2032 i (in Step 14) and x \u2032 i (in Step 6) with the probability vector produced by the decoder P \u03c8 (x | z). These \u201csoft\u201d tokens are fed into the AC to make the whole computation process differentiable. Specifically, the word embedding fed at each time step of the AC is computed as an average over all the word embeddings weighted by the input probability distribution. Moreover, we also applied the temperature scaling technique to sharp the output distribution, i.e., the logits in each time step are divided by a temperature of t to produce the output distribution. In our experiments, the value of t decreases from 1 to 0 as the training proceeds. A small value of t sharpens the output distribution to make it close to a one-hot vector.\n\n# D. Utilizing Unlabeled Data\n\nIt is observed in previous studies that if the OOD data used in the training and testing phase are similar, the OOD\n\n<div style=\"text-align: center;\">Algorithm 2 Training Procedure of AEPOG\n</div>\nAlgorithm 2 Training Procedure of AEPOG\n1: Each training iteration additionally:\n/* (1b) Train the autoencoder (Enc\u03c6, Dec\u03c8) */\n2:\nSample {\u02c6xi}M\ni=1 \u223cDmix\n3:\nCompute zi = Enc\u03c6(\u02c6xi), i = 1, \u00b7 \u00b7 \u00b7 , M\n4:\nAdd Gaussian noise zi \u2190\u2212zi + \u03f5, \u03f5 \u223cN(0, I)\n5:\nUpdate \u03c6, \u03c8 by minimizing Lrec(\u03c6, \u03c8)\n/* (2b) Train the discriminator (D\u03b7) */\n6:\nSample {\u02c6xi}M\ni=1 \u223cDmix, {\u03f5i}M\ni=1 \u223cN\n7:\nCompute zi = Enc\u03c6(\u02c6xi), and \u02dczi = G\u03be(\u03f5i)\n8:\nUpdate \u03b7 by minimizing Ld(\u03b7) + Lgp(\u03b7)\ndetection performance is better [14], [15]. However, using human-labeled OOD data in Eq. 3 is expensive, and it is hard for the POG model to gain any prior knowledge about the testing OOD samples if only IND data is utilized. However, fortunately, the unlabeled data D mix, which are usually easier to collect, can help us to solve this issue. In this study, we augment the training process of the autoencoder in POG with the data from D mix. It is expected that the latent space produced by the autoencoder will be enriched with OOD samples, and the AC will lead the generator to focus on these OOD samples in the adversarial training process. Specifically, this involves adding a few additional steps in Algorithm 1, in particular, two steps are added in each training iteration: (1b) update \u03c6, \u03c8 with the reconstruction loss and (2b) update \u03b7 with the discriminator loss utilizing the data sampled from D mix. We denote the augmented model as AEPOG, and the corresponding training algorithm is shown in Algorithm 2. Experiments in Section IV demonstrate that the generated pseudo OOD utterances can be more effective at improving the OOD detection performance.\n\n# IV. E XPERIMENT\n\n# A. Dataset\n\nWe evaluated the proposed model on two datasets:\n1) OSQ dataset [44]: this dataset covers 150 IND intents and also provides a set of manually labeled Out-of-Scope Queries (OSQ) that are not supported by the current system. These out-of-scope queries are regarded as OOD data in our experiments.\n2) IPA dataset: this dataset contains a set of Chinese utterances that were collected and annotated in the development process of a commercialized Intelligent Personal Assistant (IPA) named Bixby 2. This dataset covers 67 domains, which can be further divided into 1,310 intents. In this study, 310 intents are randomly selected as the OOD intents, and the corresponding utterances are used as OOD data. Domain level labels are used for the IND utterances, i.e., 67 class labels are used for these IND data, and the utterances for each IND intent is assigned with the corresponding domain label.\n\nIEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING\n\n<div style=\"text-align: center;\">TABLE I S TATISTICS OF THE OSQ AND IPA DATASETS. D mix DENOTES A MIXTURE OF IND AND OOD DATA.\n</div>\n<div style=\"text-align: center;\">S TATISTICS OF THE OSQ AND IPA DATASETS. D mix DENOTES A MIXTURE OF IND AND OOD DATA.\n</div>\nTrain\nValidate\nTest\nOSQ\nDataset\nIND\n15.00K\n3.00K\n4.50K\nOOD\n-\n0.10K\n1.00K\nDmix\n10.25K\n-\n-\nIPA\nDataset\nIND\n28.90K\n3.60K\n3.60K\nOOD\n-\n1.20K\n1.20K\nDmix\n20.00K\n-\n-\ntest. In addition to the labeled data, some unlabeled data (i.e., a mixture of IND and OOD data) D mix were also collected for the AEPOG model. Specifically, for the OSQ dataset, a mixture of 10K IND data and 250 OOD data were used as D mix. For the IPA dataset, 20K unlabeled utterances were extracted from user logs and used as D mix. The partitions of the data used in our experiment are shown in Table I. Note that the data partition scheme for the IPA dataset to define OOD inputs ensures that the OOD and IND utterances have similar patterns. This simulates the actual situations that we have met in our real system, i.e., users may issue OOD utterances that are similar to IND utterances since they are not familiar with the precise capabilities of the system. This data partition scheme makes the OOD detection task more difficult, and it demonstrates a lower bound for the OOD detection performance of a real NLU system. Measuring and guaranteeing such lower bounds are essential for practical systems. In order to better demonstrate the performance of our method on the IPA dataset, we collect an extra set of test data, i.e., Chat dataset, for the models trained on the IPA dataset. This dataset covers a broad range of OOD utterances such as chitchat or nonsense, which are commonly received by a practical NLU system. The Chat dataset contains 1.2K utterances, and it is only used in the test phase of our experiment. The utterances in the Chat dataset are manually annotated based on the user logs.\n\n# B. Model Implementation\n\nOur text classifier was implemented using the CNN architecture [45]. Four kernel sizes (2, 3, 4, 5) were used, and each kernel had 128 feature maps. A three-layer MLP was added on top of the CNN feature, and the hidden size of each layer was 512. The vocabulary size was of 8.3K and 18.2K for the classifiers on the OSQ and IPA datasets, respectively. Note that the vocabulary we used covers all the tokens in the IND and OOD data. Pre-trained word vectors with the dimension of 100 were used to initialize the word embeddings. Specifically, 81.46% and 70.01% percent of word embeddings were initialized with the pre-trained word vectors for the IND and OOD datasets, respectively. The rest word embeddings were randomly initialized. All the classifier was trained for 30 epochs. For the POG model, the auxiliary classifier shared the same structure and hyper-parameter setting with the text classifier. The encoder and decoder were both implemented using\n\nOOD DETECTION PERFORMANCE ON THE OSQ DATASET. E ACH RESULT IN THIS TABLE IS AN AVERAGE OF TEN DIFFERENT RUNS. T HE NOTATION \u2191 MEANS HIGHER VALUES ARE BETTER, AND \u2193 MEANS LOWER VALUES ARE BETTER. T HE MODEL ER+AEPOG IS SIGNIFICANTLY BETTER THAN OTHER MODEL WITH p VALUE <0.01 (\u2020) AND p VALUE <0.05 (\u2217) USING T TEST\n\nModel\nAUROC\u2191\nAUPR\u2191\nFPR95\u2193\nFPR90\u2193\nCont. GAN\n52.22\u2020\n82.79\u2020\n94.40\u2020\n88.17\u2020\nMaha. Dis.\n67.14\u2020\n90.56\u2020\n91.94\u2020\n83.30\u2020\nLikelihood Ratio\n85.60\u2020\n96.07\u2020\n62.50\u2020\n43.40\u2020\nAE\n87.78\u2020\n96.98\u2020\n58.50\u2020\n40.10\u2020\nMSP\n92.86\u2020\n98.24\u2020\n39.72\u2020\n21.76\u2020\nEntropy\n92.82\u2020\n98.87\u2020\n31.91\u2020\n19.64\u2020\nKNN\n93.33\u2020\n98.20\u2020\n33.86\u2020\n18.78\u2020\nDOC\n94.24\u2020\n98.55\u2020\n30.02\u2020\n14.94\u2020\nODIN\n95.14\u2217\n98.84\u2217\n26.04\u2217\n11.70\u2020\nER+Perturb\n94.01\u2020\n98.55\u2020\n34.04\u2020\n15.32\u2020\nER+Mix\n93.48\u2020\n98.31\u2020\n33.16\u2020\n17.86\u2020\nER+POG\n95.41\u2217\n98.94\u2217\n25.00\u2217\n10.10\u2020\nER+AEPOG\n95.83\n99.05\n23.70\n9.50\nw.o. Noise\n94.03\u2217\n98.53\u2217\n35.22\u2020\n17.74\u2020\nw.o. Soft Token\n93.85\u2020\n98.53\u2217\n39.24\u2020\n17.88\u2020\nLSTM [46]. The hidden size of the LSTM used for the OSQ and IPA datasets was 100 and 256, respectively. The generator and discriminator were both four-layer MLPs activated with the Leaky ReLU function [47]. The MLP hidden size was 512 and 1024, and the vocabulary size was of 5.8K and 14.1K, respectively, for the OSQ and IPA datasets. It covers all the tokens in the IND training data. The POG and AEPOG models were trained for 80 epochs.\n\n# C. Baselines\n\nIn this work, we used several threshold-based OOD detectors as baselines. These baselines differ mainly in the way to calculate detection scores.\n1) MSP [11]: A text classifier with a Softmax output layer is trained, and the maximum Softmax output is used as the detection score (i.e., calculated using Eq. 1). The training objective of this classifier does not include the entropy regularization (ER) term.\n2) Entropy: The Shannon entropy of the predicted distribution for each input is used as the detection score. Higher entropy means higher uncertainty of the prediction, which indicates that the input sample may be from the OOD data.\n3) ODIN  [12]: The temperature scaling and input perturbation technique is applied to the text classifier as obtained in the previous MSP baseline, and the maximum Softmax output is used as the detection score. Note that small perturbations of each input are added to the last feature layer in this baseline.\n4) DOC [28]: m binary classifiers are built for m classes. The maximum confidence score predicted by these m classifiers is used as the detection score.\n5) KNN: The feature for each input sample is extracted using a pre-trained classifier (i.e., the classifier as obtained\n\nIEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING\n\nOOD DETECTION PERFORMANCE ON THE IPA DATASET. E ACH RESULT IN THIS TABLE IS AN AVERAGE OF TEN DIFFERENT RUNS. T HE NOTATION \u2191 MEANS HIGHER VALUES ARE BETTER, AND \u2193 MEANS LOWER VALUES ARE BETTER. T HE MODEL ER+AEPOG IS SIGNIFICANTLY BETTER THAN OTHER MODEL WITH p VALUE <0.01 (MARKED BY \u2020) AND p VALUE <0.05 (\u2217) USING T TEST\n\nModel\nAUROC\u2191\nAUPR\u2191\nFPR95\u2193\nFPR90\u2193\nCont. GAN\n58.06\u2020\n80.47\u2020\n91.51\u2020\n85.05\u2020\nMaha. Dis.\n45.65\u2020\n23.45\u2020\n95.01\u2020\n89.97\u2020\nLikelihood Ratio\n69.65\u2020\n86.21\u2020\n84.44\u2020\n74.46\u2020\nAE\n67.57\u2020\n85.91\u2020\n86.77\u2020\n74.79\u2020\nMSP\n72.66\u2020\n86.42\u2020\n77.79\u2020\n86.42\u2020\nEntropy\n72.87\u2020\n86.42\u2020\n88.15\u2020\n75.41\u2020\nKNN\n67.94\u2020\n82.62\u2020\n76.87\u2020\n63.43\u2020\nDOC\n71.68\u2020\n46.03\u2020\n79.40\u2020\n64.34\u2020\nODIN\n72.90\u2020\n86.53\u2020\n77.57\u2020\n63.28\u2020\nER+Perturb\n73.24\u2020\n86.89\u2217\n77.88\u2020\n63.30\u2020\nER+Mix\n33.71\u2020\n63.55\u2020\n96.44\u2020\n92.33\u2020\nER+POG\n73.83\u2020\n87.15\u2217\n76.17\u2020\n62.28\u2020\nER+AEPOG\n75.86\n87.95\n71.67\n56.78\nw/o Noise\n71.01\u2217\n85.10\u2217\n79.17\u2020\n65.17\u2020\nw/o Soft Token\n72.09\u2217\n86.31\u2217\n80.22\u2020\n65.07\u2020\nin the previous MSP baseline), and the Euclid distance of each feature vector to its nearest class is used as the detection score.\n6) Maha. Dis. [48]: The Mahalanobis distance is used to replace the Euclid distance in the previous KNN baseline.\n7) Cont. GAN [16]: A GAN-based model is trained to generate continuous OOD features to mimic features extracted from IND samples. The confidence of the discriminator is used as the detection score. A low confidence score suggests that the input sample may be from the OOD data.\n8) AE: An autoencoder is trained on the IND data, and the reconstruction error of each input is used as the detection score.\n9) Likelihood Ratio [9]: The likelihood ratio is used as the detection score. The background model is trained using perturbed IND samples, which are generated by randomly replacing tokens in the IND samples with a probability of 0.5 3.\n10) ER+Perturb: An ER term L ent (\u03b8) (Eq. 3) is added to the training objective of the classifier, and this term is optimized using perturbed IND samples. These perturbed samples are constructed in a similar way as in the previous Likelihood Ratio baseline.\n11) ER+Mix: The ER term in the training objective is optimized using the data from D mix. This baseline demonstrates a naive way to utilize D mix.\nOur baselines cover a variety of competitive OOD detection models that are currently available. Note that the text classifier nvolved in each baseline follows the same structure and hyper-parameter setting with our classification model (see Section IV-B), and the baseline AE and Likelihood Ratio\n\nOOD DETECTION PERFORMANCE ON THE IPA DATASET WHEN TESTING WITH THE C HAT DATASET. E ACH RESULT IN THIS TABLE IS AN AVERAGE OF TEN DIFFERENT RUNS. T HE NOTATION \u2191 MEANS HIGHER VALUES ARE BETTER, AND \u2193 MEANS LOWER VALUES ARE BETTER. T HE MODEL ER+AEPOG IS SIGNIFICANTLY BETTER THAN OTHER MODEL WITH p VALUE <0.01 (MARKED BY \u2020) AND p VALUE <0.05 (\u2217) USING T TEST\n\nModel\nAUROC\u2191\nAUPR\u2191\nFPR95\u2193\nFPR90\u2193\nCont. GAN\n69.80\u2020\n87.55\u2020\n90.77\u2020\n76.18\u2020\nMaha. Dis.\n73.85\u2020\n48.20\u2020\n73.96\u2020\n61.48\u2020\nLikelihood Ratio\n90.83\u2020\n96.63\u2020\n41.51\u2020\n27.37\u2020\nAE\n92.41\u2020\n97.21\u2020\n37.77\u2020\n18.97\u2020\nMSP\n88.41\u2020\n95.05\u2020\n52.30\u2020\n32.56\u2020\nEntropy\n89.02\u2020\n95.05\u2020\n37.56\u2020\n29.31\u2020\nKNN\n89.43\u2020\n95.02\u2020\n36.17\u2020\n22.91\u2020\nDOC\n93.03\u2020\n97.28\u2020\n35.44\u2020\n18.07\u2020\nODIN\n90.25\u2020\n95.67\u2020\n37.92\u2020\n24.29\u2020\nER+Perturb\n96.28\u2020\n98.72\u2217\n19.23\u2020\n10.80\u2020\nER+Mix\n92.76\u2020\n97.27\u2020\n38.44\u2020\n21.71\u2020\nER+POG\n98.53\u2217\n99.42\u2217\n7.70\u2217\n4.36\u2217\nER+AEPOG\n98.60\n99.46\n7.64\n4.24\nw/o Noise\n94.26\u2020\n98.07\u2020\n33.08\u2020\n18.56\u2020\nw/o Soft Token\n94.08\u2020\n98.06\u2020\n40.07\u2020\n16.96\u2020\nshare the same LSTM structure with our POG model. Several ablation tests are also performed to validate the effect of each component in our model:\n1) w/o Noise: The autoencoder is trained without adding the Gaussian noise in Eq. 5.\n2) w/o Soft Token: The loss L \u2032 ent (\u03be) in Eq. 10 is optimized without using the soft token approximation approach. We instead use the policy gradient algorithm to estimate the gradients through the sampling process of the decoder. Note that all the ablation studies are performed without using the unlabeled data D mix.\n\n# D. Metrics\n\nFor OOD detection, we used three common metrics [9], [11], [14], [15]:\n1) AUROC. The area under the receiver operating characteristic (ROC) curve; Higher values are better.\n2) AUPR. The area under the precision-recall curve when OOD inputs are treated as the positive samples; Higher values are better.\n3) FPR N. The false-positive rate (FPR) when the true positive rate (TPR) is N % 4. In this study, FPR95 and FPR90 are reported, since such settings are commonly used in practical systems. Lower values are better. Note that the metric FPR N is of more practical value in real-world applications since it evaluates the performance of an OOD detection module at a particular threshold. It is directly related to the performance of a deployed system. Lower FPR N means triggering fewer false alarms when the performance on the IND data is guaranteed with a precision of N % [15].\n4 Note that FPR= FP\nFP+TN, and TPR= TP\nTP+FN, where FP, TP, TN, FN is the number of false positives, true positives, true negatives, false negatives, respectively.\n\nIEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e9d0/e9d0e30b-560c-47f2-a520-d0411363e92b.png\" style=\"width: 50%;\"></div>\nFig. 2. ROC curves for the models on the IPA dataset. The model ER+AEPOG improves the AUROC of OOD detection compared to ER+POG, whereas a sharp decrease for the AUROC of OOD detection is observed for the model ER+Mix, which directly utilize D mix to optimize the ER term of the classifier.\n\n<div style=\"text-align: center;\">Fig. 2. ROC curves for the models on the IPA dataset. The model ER+AEPOG improves the AUROC of OOD detection compared to ER+POG, whereas a sharp decrease for the AUROC of OOD detection is observed for the model ER+Mix, which directly utilize D mix to optimize the ER term of the classifier.\n</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/010d/010dee1b-5bca-489b-b782-1ae03d8f55e4.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 3. ROC curves for the models on the OSQ dataset. We zooms in the upper-left corner of the ROC curves to facilitate a clearer view.\n</div>\nOn the contrary, the metrics AUPR and AUROC evaluate the performance across various thresholds. In other words, AUPR and AUROC are threshold independent.\n\nE. Effects of Generated Pseudo OOD Utterances\nFirst of all, we evaluated the effectiveness of the pseudo OOD utterances generated by our model POG when only IND data is available. More concretely, the POG model was trained and, meanwhile, a set of pseudo OOD utterances (with the same size of the IND training data) was sampled to optimize the ER term L ent (\u03b8) (i.e., Eq. 3). The performance of the resulting model (i.e., ER+POG) on the OSQ and IPA datasets is depicted in Table II and Table III, respectively. Table IV shows the test results on the Chat dataset for the models trained on the IPA dataset. It can be seen that our model outperforms all the baselines on both datasets significantly, which demonstrates the effectiveness of the generated pseudo OOD utterances. It is also interesting to see that: 1) Detecting OOD samples on the IPA dataset is more difficult compared to the OSQ dataset (see\n\nC LASSIFICATION ACCURACY ON IND INPUTS FOR EACH MODEL. E ACH RESULT IN THIS TABLE IS AN AVERAGE OF TEN DIFFERENT RUNS. T HE MODEL ER+AEPOG IS SIGNIFICANTLY BETTER THAN MOST OF OTHER MODELS WITH p VALUE <0.01 (MARKED BY \u2020) AND p VALUE <0.05 (\u2217) USING T TEST\n\nModel\nOSQ Dataset\nIPA Dataset\nCont. GAN\n70.43\u2020\n84.68\u2020\nMaha. Dis.\n82.36\u2020\n89.73\u2020\nMSP\n92.61\u2217\n91.19\nKNN\n81.05\u2020\n88.32\u2020\nDOC\n91.84\u2020\n89.20\u2020\nER+Perturb\n90.96\u2020\n91.22\nER+Mix\n89.77\u2020\n90.41\u2020\nER+POG\n93.31\n91.37\nER+AEPOG\n93.32\n91.40\nw/o Noise\n93.01\n91.34\nw/o Soft Token\n93.10\n90.96\u2217\nTable II and Table III). It is because that most OOD inputs in the IPA test data look similar to the IND inputs. Moreover, the models trained on the IPA dataset obtain a large performance gain when testing on the Chat dataset, especially on the FPR N metric. This validates our claim that the OOD utterances that look similar to IND utterances are more difficult to detect. Further, the fact that the proposed model ER+POG surpasses all the baselines on both datasets also proves its ability to handle various kinds of inputs with different distributions. 2) The results for the ablation studies validate the effect of the Gaussian noise and soft token approximation approach used in our study. A significant performance drop is observed on both datasets. 3) The proposed ER+POG model obtains large improvements on the FPR N metrics. In particular, the relative performance gain for FPR95 and FPR90 on the OSQ dataset reaches 4.16% and 15.84%, respectively, compared to the best performing baselines. Even on the more difficult IPA dataset, the relative performance gain also reaches 0.92% and 1.61% for FPR95 and FPR90, respectively. This indicates that the proposed model is more suitable in real-world applications since the metric FPR N directly reflects the performance of the deployed models. 4) The Cont. GAN baseline proposed in [16] only performs slightly better than random guesses. This shows that the confidence score of the discriminator is not efficient in detecting OOD inputs, and using GAN to generate continuous features is not helpful to improve the OOD detection performance in this baseline.\nIt is also worth mentioning that the performance of the NLU model on the IND input classification task is not affected if we optimize the ER term with utterances generated by the proposed model (see Table V). Notably, in some cases, the utterances generated by the proposed model even help to improve the classification accuracy of the NLU module on IND inputs. This may be because optimizing the ER term with utterances produced by the POG or AEPOG model helps to prevent the classifier from over-fitting, and it further demonstrates the effectiveness of the proposed model in practical applications.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7667/766704f5-2c77-498d-87b5-305663903965.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5eb2/5eb2a015-326c-40a3-a985-74580e8cdbec.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 5. Distributions of detection scores corresponding to the IND and OOD samples of the IPA dataset.\n</div>\nFig. 5. Distributions of detection scores corresponding to the IND and OOD samples of the IPA dataset.\n\n# F. Effects of Utilizing Unlabeled Data\n\nWe also verified the effectiveness of our model when a set of unlabeled data D mix is available. Specifically, an AEPOG model was trained by optimizing L rec (\u03c6, \u03c8) with the data from D mix (Algorithm 2), and the sampled pseudo OOD utterances were used to optimize L ent (\u03b8) when training the intent classifier. The performance of the resulting classifier on the OSQ and IPA datasets is shown in the last line of Table II and Table III, respectively.\n\nIt can be seen that the model ER+AEPOG surpasses all the other models significantly, especially on the FPR N metric. Particularly, on the OSQ dataset, the performance of the ER+AEPOG model improves 9.87% and 23.16% (relatively) compared to the best performing baselines on FPR95 and FPR90, respectively. On the IPA dataset, the performance improves 7.26% and 11.45% (relatively) for FPR95 and FPR90, respectively. This verifies our claim that the proposed AEPOG model can effectively utilize unlabeled data to improve the effectiveness of the generated OOD samples. Thus it is more suitable in practical applications. It is also interesting to see that the baseline model ER+Mix, which optimizes the ER term L ent (\u03b8) directly using the data from D mix when training the classifier, experiences a remarkable performance drop on all metrics, especially on the IPA dataset (see Figure 2). This indicates that the ER term itself cannot utilize D mix directly. It further demonstrates that the performance improvement obtained by the ER+AEPOG model attributes to the proposed AEPOG model since the proposed adversarial training process helps to produce more effective pseudo OOD samples to improve the OOD detection performance. Figure 3 shows the ROC curves obtained from these models on the OSQ dataset. The proposed ER+POG model surpasses all the baselines, and ER+AEPOG further improves the performance of OOD detection. Similar results are also obtained on the IPA dataset (see Figure 2). Note that the performance improvement of the ER+AEPOG model over the ER+POG model is relatively small on the OSQ dataset compared to the IPA dataset. This is partly because the OOD data only takes a small proportion (i.e., 2.44%) of D mix in the OSQ dataset, whereas about one third (33.33%) intents are randomly selected as OOD in the IPA dataset. We also analyzed the distribution of the detection scores obtained from different models on the OSQ and IPA datasets. Specifically, for the MSP model, the distributions corresponding to IND and OOD inputs are closely overlapped (see Figure 4a and Figure 5a). Marginal improvements are observed for the model ER+Perturb, which optimizes the ER term using randomly perturbed IND inputs (Figure 4b and Figure 5b). This indicates that the ER term helps to improve the OOD detection performance, but only to a limited extent. Better separation of the detection scores between the IND and OOD inputs is observed when the ER term is optimized with the pseudo OOD utterances generated by the POG model (Figure 4c and Figure 5c), and this separation is enlarged if the utterances generated by the AEPOG model are used (Figure 4d and Figure 5d). This indicates that the pseudo OOD utterances generated by the proposed model facilitate OOD detection, and the effectiveness of these pseudo OOD utterances can be further improved when utilizing the unlabeled data.\n\n# G. Feature Vectors for IND and OOD Inputs\n\nTo further investigate the benefit of the proposed model on OOD detection, we visualized the feature spaces of different intent classifiers on the OSQ dataset (see Figure 6). Specifically, we fed the test samples of the OSQ dataset to each intent\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ac78/ac780a07-68b1-454c-bb86-7342e3b172fd.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 6. t-SNE visualization of the features vectors associated with the test samples from the OSQ dataset.\n</div>\nclassifier and obtained the feature vector of each sample from the penultimate layer of the network. The t-SNE algorithm [49] was used to map these vectors into 2-dimensions. It can be seen that all the intent classifiers cluster features of the IND samples into separated groups. This coincides with the observation that all models obtain high classification performance on IND inputs (Table V). However, as to the OOD samples, the MSP model scatters the features of OOD samples around the features of IND samples (Figure 6a), making it hard for OOD detection. Whereas, the classifiers that are regularized by the ER term produce more distinguishable features for IND and OOD samples (Figure 6b). The utterances generated by the proposed POG and AEPOG model enhance this separation (Figure 6c and Figure 6d). This facilitates the detection of OOD inputs.\n\nTable VI shows some randomly selected cases of the pseudo OOD utterances generated by the proposed POG and AEPOG model on the OSQ dataset. It is interesting to see that the POG model can combine words and phrases from the IND samples (such as \u201cFrench\u201d or \u201cmy phone\u201d) in a grammatical way. This makes the produced pseudo OOD utterances look similar to the IND data but possess indistinguishable intents. Moreover, the AEPOG model can make use of phrases from the OOD data, and thus produces more effective utterances that can be used to improve the OOD detection performance.\n\n# V. C ONCLUSION\n\nIn this paper, we propose a novel model POG to generate pseudo OOD samples that can be used to improve the performance of OOD detection in an NLU module. An autoencoder is used to map each input utterance to a latent code, and an\n\n<div style=\"text-align: center;\">U TTERANCES SAMPLED FROM THE IND AND OOD TEST SET OF THE OSQ DATASET (I. E., HUMAN GENERATED UTTERANCES), AND THE PSEUDO OOD UTTERANCES GENERATED USING THE POG AND AEPOG MODEL.\n</div>\nIND Samples\nTranslate hello in French.\nLocate my phone please.\nSchedule a gas bill payment.\nHelp me change my insurance plan.\nI\u2019d like to improve my credit score.\nOOD Samples\nHow much is my car worth used.\nCan you add a bag to my reservation.\nHow do you fix a leaking sink.\nHow long do wire transfer take.\nWhen was Toyota created.\nGenerated by POG\nPlease obtain French.\nHow can make my phone get.\nWhat meetings can I schedule there.\nCan you help me an setting.\nI\u2019d like to include the email my my dinner.\nGenerated by AEPOG\nHow much is this payments please.\nHow good is my reservation like.\nHow do you divided for pork.\nTell me how long I taken for chilis off.\nWhen was today\u2019s name with delta vehicle.\nadversarial training process is employed to make the codes of OOD samples similar to those of IND samples. This makes the generated OOD samples look similar to IND samples. Further, an auxiliary classifier is introduced to regularize the generator and thereby ensures these generated pseudo OOD samples to have indistinguishable intents. Our experiments show that the pseudo OOD samples generated by the proposed POG model can be used to effectively improve the OOD detection performance of the NLU module by optimizing the ER term when training the NLU module. Further, it is also demonstrated that augmenting the training process of the autoencoder in the POG model improves the effectiveness of the generated pseudo OOD samples. As future works, we will explore this idea in classification problems for longer text since it is more challenging to generate longer documents for OOD detection. Also, note that our study focuses on detecting OOD inputs for the NLU module. It is worth exploring to equip other components of the task-oriented dialogue system, such as dialogue state tracking or dialogue management modules, with the ability to detect OOD inputs.\n\n# A CKNOWLEDGMENT\n\nThis work was supported by the National Science Foundation of China key project with grant No. 61936010 and regular project with grand No. 61876096, and the National Key R&D Program of China (Grant No. 2018YFC0830200). The first author would also like to thank Wonkwang Shin, Seonghan Ryu and Kyoung-Gu Woo for fruitful discussions, and thank the support provided by the Bixby development team.\n\n# R EFERENCES\n\n[1] Y.-B. Kim, D. Kim, A. Kumar, and R. Sarikaya, \u201cEfficient large-scale neural domain classification with personalized attention,\u201d in Proceeding\n\nof the 56th Annual Meeting of the Association for Computational Linguistics, 2018, pp. 2214\u20132224.\n[2] R. Sarikaya, \u201cThe technology behind personal digital assistants: An overview of the system architecture and key components,\u201d IEEE Signal Processing Magazine, vol. 34, no. 1, pp. 67\u201381, 2017.\n[3] K. M. Yoo, Y. Shin, and S.-g. Lee, \u201cData augmentation for spoken language understanding via joint variational generation,\u201d arXiv preprint arXiv:1809.02305, 2018.\n[4] G. Fei and B. Liu, \u201cBreaking the closed world assumption in text classification,\u201d in Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Jun. 2016, pp. 506\u2013514.\n[5] W. J. Scheirer, A. de Rezende Rocha, A. Sapkota, and T. E. Boult, \u201cToward open set recognition,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 35, no. 7, pp. 1757\u20131772, 2013.\n[6] A. Bendale and T. E. Boult, \u201cTowards open set deep networks,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 1563\u20131572.\n[7] S. Ryu, S. Kim, J. Choi, H. Yu, and G. G. Lee, \u201cNeural sentence embedding using only in-domain sentences for out-of-domain sentence detection in dialog systems,\u201d Pattern Recognition Letters, vol. 88, pp. 26\u201332, 2017.\n[8] E. Nalisnick, A. Matsukawa, Y. W. Teh, D. Gorur, and B. Lakshminarayanan, \u201cDo deep generative models know what they don\u2019t know?\u201d in International Conference on Learning Representations, 2019.\n[9] J. Ren, P. J. Liu, E. Fertig, J. Snoek, R. Poplin, M. A. DePristo, J. V. Dillon, and B. Lakshminarayanan, \u201cLikelihood ratios for out-ofdistribution detection,\u201d arXiv preprint arXiv:1906.02845, 2019.\n[10] A. Shafaei, M. Schmidt, and J. J. Little, \u201cDoes your model know the digit 6 is not a cat? a less biased evaluation of\u201d outlier\u201d detectors,\u201d arXiv preprint arXiv:1809.04729, 2018.\n[11] D. Hendrycks and K. Gimpel, \u201cA baseline for detecting misclassified and out-of-distribution examples in neural networks,\u201d Proceedings of International Conference on Learning Representations, 2017.\n[12] S. Liang, Y. Li, and R. Srikant, \u201cEnhancing the reliability of outof-distribution image detection in neural networks,\u201d in International Conference on Learning Representations, 2018.\n[13] A. Vyas, N. Jammalamadaka, X. Zhu, D. Das, B. Kaul, and T. L. Willke, \u201cOut-of-distribution detection using an ensemble of self supervised leave-out classifiers,\u201d in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 550\u2013564.\n[14] K. Lee, H. Lee, K. Lee, and J. Shin, \u201cTraining confidence-calibrated classifiers for detecting out-of-distribution samples,\u201d in International Conference on Learning Representations, 2018.\n[15] D. Hendrycks, M. Mazeika, and T. Dietterich, \u201cDeep anomaly detection with outlier exposure,\u201d Proceedings of the International Conference on Learning Representations, 2019.\n[16] S. Ryu, S. Koo, H. Yu, and G. G. Lee, \u201cOut-of-domain detection based on generative adversarial network,\u201d in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018, pp. 714\u2013718.\n[17] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, X. Bing, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, \u201cGenerative adversarial nets,\u201d in International Conference on Neural Information Processing Systems, 2014.\n[18] S. S. Khan and M. G. Madden, \u201cA survey of recent trends in one class classification,\u201d in Irish conference on artificial intelligence and cognitive science. Springer, 2009, pp. 188\u2013197.\n[19] S. S. Khan and M. G. Madden, \u201cOne-class classification: taxonomy of study and review of techniques,\u201d The Knowledge Engineering Review, vol. 29, no. 3, pp. 345\u2013374, 2014.\n[20] C. Geng, S.-j. Huang, and S. Chen, \u201cRecent advances in open set recognition: A survey,\u201d arXiv preprint arXiv:1811.08581, 2018.\n[21] M. Kliger and S. Fleishman, \u201cNovelty detection with gan,\u201d arXiv preprint arXiv:1802.10560, 2018.\n[22] M. A. F. Pimentel, D. A. Clifton, C. Lei, and L. Tarassenko, \u201cA review of novelty detection,\u201d Signal Processing, vol. 99, no. 6, pp. 215\u2013249, 2014.\n[23] I. Lane, T. Kawahara, T. Matsui, and S. Nakamura, \u201cOut-of-domain utterance detection using classification confidences of multiple topics,\u201d IEEE Transactions on Audio Speech and Language Processing, vol. 15, no. 1, pp. 150\u2013161, 2006.\n[24] G. Tur, A. Deoras, and D. Hakkani-T\u00a8ur, \u201cDetecting out-of-domain utterances addressed to a virtual personal assistant,\u201d in Proceedings of Interspeech, September 2014.\n\n[25] S. Pidhorskyi, R. Almohsen, and G. Doretto, \u201cGenerative probabilistic novelty detection with adversarial autoencoders,\u201d in Advances in Neural Information Processing Systems, 2018, pp. 6822\u20136833.\n[26] J. An and S. Cho, \u201cVariational autoencoder based anomaly detection using reconstruction probability,\u201d Special Lecture on IE, vol. 2, pp. 1\u2013 18, 2015.\n[27] I. Golan and R. El-Yaniv, \u201cDeep anomaly detection using geometric transformations,\u201d in  Advances in Neural Information Processing Systems, 2018, pp. 9758\u20139769.\n[28] L. Shu, H. Xu, and B. Liu, \u201cDOC: Deep open classification of text documents,\u201d in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, 2017, pp. 2911\u20132916.\n[29] A. Malinin and M. Gales, \u201cPredictive uncertainty estimation via prior networks,\u201d in Advances in Neural Information Processing Systems, 2018, pp. 7047\u20137058.\n[30] X. Gu, L. Akoglu, and A. Rinaldo, \u201cStatistical analysis of nearest neighbor methods for anomaly detection,\u201d arXiv preprint arXiv:1907.03813, 2019.\n[31] T. DeVries and G. W. Taylor, \u201cLearning confidence for outof-distribution detection in neural networks,\u201d arXiv preprint arXiv:1802.04865, 2018.\n[32] K. J. Oh, D. K. Lee, C. Park, Y. S. Jeong, S. Hong, S. Kwon, and H. J. Choi, \u201cOut-of-domain detection method based on sentence distance for dialogue systems,\u201d in IEEE International Conference on Big Data & Smart Computing, 2018.\n[33] H. Xu, S. L. Liu, Bing, and P. Yu, \u201cOpen-world learning and application to product classification,\u201d in Proceedings of the 2019 World Wide Web Conference on World Wide Web, 2019.\n[34] J.-K. Kim and Y.-B. Kim, \u201cJoint learning of domain classification and out-of-domain detection with dynamic class weighting for satisficing false acceptance rates,\u201d Proceedings of Interspeech, pp. 556\u2013560, 2018.\n[35] S. R. Bowman, L. Vilnis, O. Vinyals, A. Dai, R. Jozefowicz, and S. Bengio, \u201cGenerating sentences from a continuous space,\u201d in Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, 2016, pp. 10\u201321.\n[36] H. Bahuleyan, L. Mou, H. Zhou, and O. Vechtomova, \u201cStochastic Wasserstein autoencoder for probabilistic sentence generation,\u201d in  Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Minneapolis, Minnesota: Association for Computational Linguistics, Jun. 2019, pp. 4068\u20134076.\n[37] Y. Kim, K. Zhang, A. M. Rush, Y. LeCun et al., \u201cAdversarially regularized autoencoders,\u201d arXiv preprint arXiv:1706.04223, 2017.\n[38] S. Subramanian, S. R. Mudumba, A. Sordoni, A. Trischler, A. C. Courville, and C. Pal, \u201cTowards text generation with adversarially learned neural outlines,\u201d in Advances in Neural Information Processing Systems, 2018, pp. 7551\u20137563.\n[39] Z. Hu, Z. Yang, X. Liang, R. Salakhutdinov, and E. P. Xing, \u201cToward controlled generation of text,\u201d in Proceedings of the 34th International Conference on Machine Learning-Volume 70, 2017, pp. 1587\u20131596.\n[40] J. Bekker and J. Davis, \u201cLearning from positive and unlabeled data: A survey,\u201d arXiv preprint arXiv:1811.04820, 2018.\n[41] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger, \u201cOn calibration of modern neural networks,\u201d in Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017, pp. 1321\u20131330.\n[42] M. Arjovsky, S. Chintala, and L. Bottou, \u201cWasserstein generative adversarial networks,\u201d in International Conference on Machine Learning, 2017, pp. 214\u2013223.\n[43] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville, \u201cImproved training of wasserstein gans,\u201d in  Advances in Neural Information Processing Systems, 2017, pp. 5767\u20135777.\n[44] S. Larson, A. Mahendran, J. J. Peper, C. Clarke, A. Lee, P. Hill, J. K. Kummerfeld, K. Leach, M. A. Laurenzano, L. Tang, and J. Mars, \u201cAn evaluation for intent classification and out-of-scope prediction,\u201d in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, November 2019.\n[45] Y. Kim, \u201cConvolutional neural networks for sentence classification,\u201d arXiv preprint arXiv:1408.5882, 2014.\n[46] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.\n[47] A. L. Maas, A. Y. Hannun, and A. Y. Ng, \u201cRectifier nonlinearities improve neural network acoustic models,\u201d in  Proceedings of the International Conference on Machine Learning, 2013.\n[48] K. Lee, K. Lee, H. Lee, and J. Shin, \u201cA simple unified framework for detecting out-of-distribution samples and adversarial attacks,\u201d in\n\nIEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING\n\nAdvances in Neural Information Processing Systems, 2018, pp. 7167\u2013 7177.\n[49] L. v. d. Maaten and G. Hinton, \u201cVisualizing data using t-sne,\u201d Journal of machine learning research, vol. 9, no. Nov, pp. 2579\u20132605, 2008.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/069f/069f21f2-e3c4-4e4d-8ba7-957cd1d52f93.png\" style=\"width: 50%;\"></div>\nYinhe Zheng received his Ph.D. degree from China University of Geosciences (Beijing), Beijing, China, in 2017. He is currently working as a Post Doctor in a joint program of the Department of Computer Science and Technology, Tsinghua University, and Samsung Research China - Beijing (SRCB). His research interests include natural language processing and dialogue system, especially the tasks related to natural language understanding and natural language generation. He is the recipient of the Wuwenjun AI Award in 2019.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4ac9/4ac91313-90c6-462f-8aa9-f657c8521421.png\" style=\"width: 50%;\"></div>\nGuanyi Chen received his M.S. degree in artificial intelligence from University of Edinburgh, Edinburgh, Scotland, in 2016. He is currently a Ph.D candidate with the Department of Information and Computing Sciences, Utrecht University, Utrecht, Netherlands. His research interests mainly lie in natural language generation, especially the computational modeling of human language production.\n\nMinlie Huang  received his Ph.D. degree from Tsinghua University, Beijing, China, in 2006. He is currently an Associate Professor with the Department of Computer Science and Technology, Tsinghua University. His research interests include natural language processing, particularly in dialog systems, reading comprehension, and sentiment analysis. He has published more than 60 papers in premier conferences and journals (ACL, EMNLP, AAAI, IJCAI, WWW, SIGIR, etc.). His work on emotional chatting machines was reported by MIT Guardian, Nvidia, and many other mass media.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ee21/ee21f440-fc75-4d3c-8509-5588dd92a68a.png\" style=\"width: 50%;\"></div>\nTechnology Review, the Guardian, Nvidia, and many other mass media. He serves as standing reviewer for TACL, area chairs for ACL 2020/2016, EMNLP 2019/2014/2011, and Senior PC members for AAAI 2017-2020 and IJCAI 2017-2020, and reviewers for TASLP, TKDE, TOIS, TPAMI, etc. He is a nominee of ACL 2019 best demo papers, the recipient of IJCAI 2018 distinguished paper award, CCL 2018 best demo award, NLPCC 2015 best paper award, Hanvon Youngth Innovation Award in 2018, and Wuwenjun AI Award in 2019. He was supported by a NSFC key project , several NSFC regular projects, and many IT companies.\n\n",
    "paper_type": "method",
    "attri": {
        "background": "Natural Language Understanding (NLU) is a vital component of dialogue systems, and its ability to detect Out-of-Domain (OOD) inputs is critical in practical applications, since the acceptance of the OOD input that is unsupported by the current system may lead to catastrophic failure. Most existing OOD detection methods rely heavily on manually labeled OOD samples and cannot take full advantage of unlabeled data, limiting their feasibility in practical applications.",
        "problem": {
            "definition": "The problem addressed is the detection of OOD inputs in NLU systems, which often operate under a closed-world assumption, leading to potential catastrophic failures when encountering unsupported inputs.",
            "key obstacle": "The main obstacle is the reliance on manually labeled OOD samples, which are difficult and expensive to collect, preventing existing methods from effectively utilizing unlabeled data for OOD detection."
        },
        "idea": {
            "intuition": "The idea is inspired by the observation that many OOD samples resemble IND inputs but do not correspond to any IND intents, making them challenging to detect.",
            "opinion": "We propose a novel model that generates high-quality pseudo OOD samples that mimic IND input utterances to enhance OOD detection performance.",
            "innovation": "The primary innovation is the use of a generative adversarial network to create pseudo OOD samples in discrete spaces (natural language), which existing methods have not effectively explored."
        },
        "method": {
            "method name": "Pseudo OOD Sample Generation (POG)",
            "method abbreviation": "POG",
            "method definition": "POG is a model that generates pseudo OOD samples by training an autoencoder to map input utterances into latent codes, which are then used in an adversarial training framework to ensure generated samples resemble IND samples.",
            "method description": "The core of the method involves generating pseudo OOD samples that enhance OOD detection in NLU systems by optimizing the entropy regularization term during training.",
            "method steps": [
                "Train an autoencoder to encode utterances into latent codes.",
                "Use a generator to produce fake latent codes and a discriminator to distinguish between real and fake codes.",
                "Introduce an auxiliary classifier to regularize the intent labels of generated samples."
            ],
            "principle": "This method is effective as it generates OOD samples that closely resemble IND inputs, thus improving the model's ability to distinguish between IND and OOD inputs."
        },
        "experiments": {
            "evaluation setting": "The model was evaluated on the OSQ and IPA datasets, which include IND intents and corresponding OOD queries, with a mixture of labeled and unlabeled data.",
            "evaluation method": "Performance was assessed using metrics such as AUROC, AUPR, and false positive rates at specific thresholds, comparing against various baseline methods."
        },
        "conclusion": "The experiments demonstrate that the pseudo OOD samples generated by the POG model significantly improve OOD detection performance in NLU systems, indicating the model's effectiveness and practical applicability.",
        "discussion": {
            "advantage": "The key advantage of the proposed approach is its ability to generate high-quality pseudo OOD samples that enhance the performance of OOD detection models, particularly in challenging scenarios where OOD inputs resemble IND inputs.",
            "limitation": "A limitation of the method is that it may still struggle with OOD inputs that are significantly different from the IND distribution, as the model relies on the similarity to improve detection.",
            "future work": "Future research will explore extending this approach to longer text classification problems and integrating OOD detection capabilities into other components of dialogue systems."
        },
        "other info": {
            "acknowledgment": "This work was supported by the National Science Foundation of China and the National Key R&D Program of China.",
            "authors": [
                {
                    "name": "Yinhe Zheng",
                    "affiliation": "Samsung Research China - Beijing, Tsinghua University"
                },
                {
                    "name": "Guanyi Chen",
                    "affiliation": "Utrecht University"
                },
                {
                    "name": "Minlie Huang",
                    "affiliation": "Tsinghua University"
                }
            ]
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The acceptance of the OOD input that is unsupported by the current system may lead to catastrophic failure."
        },
        {
            "section number": "2.1",
            "key information": "The problem addressed is the detection of OOD inputs in NLU systems, which often operate under a closed-world assumption."
        },
        {
            "section number": "2.2",
            "key information": "Natural Language Understanding (NLU) is a vital component of dialogue systems."
        },
        {
            "section number": "3.5",
            "key information": "The primary innovation is the use of a generative adversarial network to create pseudo OOD samples in discrete spaces (natural language)."
        },
        {
            "section number": "4.1",
            "key information": "The main obstacle is the reliance on manually labeled OOD samples, which are difficult and expensive to collect."
        },
        {
            "section number": "6.1",
            "key information": "The core of the method involves generating pseudo OOD samples that enhance OOD detection in NLU systems by optimizing the entropy regularization term during training."
        },
        {
            "section number": "7.1",
            "key information": "A limitation of the method is that it may still struggle with OOD inputs that are significantly different from the IND distribution."
        },
        {
            "section number": "7.2",
            "key information": "Future research will explore extending this approach to longer text classification problems and integrating OOD detection capabilities into other components of dialogue systems."
        }
    ],
    "similarity_score": 0.710898301434409,
    "image": [
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5e48/5e48f8fa-3a2c-4f27-b295-034fa47b2d42.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e9d0/e9d0e30b-560c-47f2-a520-d0411363e92b.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/010d/010dee1b-5bca-489b-b782-1ae03d8f55e4.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7667/766704f5-2c77-498d-87b5-305663903965.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5eb2/5eb2a015-326c-40a3-a985-74580e8cdbec.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ac78/ac780a07-68b1-454c-bb86-7342e3b172fd.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/069f/069f21f2-e3c4-4e4d-8ba7-957cd1d52f93.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4ac9/4ac91313-90c6-462f-8aa9-f657c8521421.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ee21/ee21f440-fc75-4d3c-8509-5588dd92a68a.png"
    ],
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Out-of-domain Detection for Natu.json"
}