{
    "from": "google",
    "scholar_id": "fSxb8E2QGpkJ",
    "detail_id": null,
    "title": "Heterogeneous knowledge fusion: A novel approach for personalized recommendation via llm",
    "abstract": "# Heterogeneous Knowledge Fusion: A Novel Approach for Personalized Recommendation via LLM\n\n# Heterogeneous Knowledge Fusion: A Novel Approach for Personalized\n\nBIN YIN \u2217, JUNJIE XIE \u2217, YU QIN, ZIXIANG DING, and ZHIC XIANG LI \u2020 and WEI LIN, Unaffiliated, China\n\nBIN YIN \u2217, JUNJIE XIE \u2217, YU QIN, ZIXIANG DING, and ZHICHAO FENG, Meituan, China XIANG LI \u2020 and WEI LIN, Unaffiliated, China\n\nThe analysis and mining of user heterogeneous behavior are of paramount importance in recommendation systems. However, the\nconventional approach of incorporating various types of heterogeneous behavior into recommendation models leads to feature sparsity\nand knowledge fragmentation issues. To address this challenge, we propose a novel approach for personalized recommendation via\nLarge Language Model (LLM), by extracting and fusing heterogeneous knowledge from user heterogeneous behavior information. In\naddition, by combining heterogeneous knowledge and recommendation tasks, instruction tuning is performed on LLM for personalized\nrecommendations. The experimental results demonstrate that our method can effectively integrate user heterogeneous behavior and\nsignificantly improve recommendation performance.\nCCS Concepts: \u2022 Information systems \u2192 Recommender systems.\nAdditional Key Words and Phrases: Recommendation, Large Language Models\nACM Reference Format:\nBin Yin, JunJie Xie, Yu Qin, ZiXiang Ding, ZhiChao Feng, Xiang Li, and Wei Lin. 2023. Heterogeneous Knowledge Fusion: A Novel\nApproach for Personalized Recommendation via LLM. In Seventeenth ACM Conference on Recommender Systems (RecSys \u201923), September\n18\u201322, 2023, Singapore, Singapore. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3604915.3608874\n\nThe analysis and mining of user heterogeneous behavior are of paramount importance in recommendation systems. However, the\nconventional approach of incorporating various types of heterogeneous behavior into recommendation models leads to feature sparsity\nand knowledge fragmentation ",
    "bib_name": "yin2023heterogeneous",
    "md_text": "# Heterogeneous Knowledge Fusion: A Novel Approach for Personalized Recommendation via LLM\n\n# Heterogeneous Knowledge Fusion: A Novel Approach for Personalized\n\nBIN YIN \u2217, JUNJIE XIE \u2217, YU QIN, ZIXIANG DING, and ZHIC XIANG LI \u2020 and WEI LIN, Unaffiliated, China\n\nBIN YIN \u2217, JUNJIE XIE \u2217, YU QIN, ZIXIANG DING, and ZHICHAO FENG, Meituan, China XIANG LI \u2020 and WEI LIN, Unaffiliated, China\n\nThe analysis and mining of user heterogeneous behavior are of paramount importance in recommendation systems. However, the\nconventional approach of incorporating various types of heterogeneous behavior into recommendation models leads to feature sparsity\nand knowledge fragmentation issues. To address this challenge, we propose a novel approach for personalized recommendation via\nLarge Language Model (LLM), by extracting and fusing heterogeneous knowledge from user heterogeneous behavior information. In\naddition, by combining heterogeneous knowledge and recommendation tasks, instruction tuning is performed on LLM for personalized\nrecommendations. The experimental results demonstrate that our method can effectively integrate user heterogeneous behavior and\nsignificantly improve recommendation performance.\nCCS Concepts: \u2022 Information systems \u2192 Recommender systems.\nAdditional Key Words and Phrases: Recommendation, Large Language Models\nACM Reference Format:\nBin Yin, JunJie Xie, Yu Qin, ZiXiang Ding, ZhiChao Feng, Xiang Li, and Wei Lin. 2023. Heterogeneous Knowledge Fusion: A Novel\nApproach for Personalized Recommendation via LLM. In Seventeenth ACM Conference on Recommender Systems (RecSys \u201923), September\n18\u201322, 2023, Singapore, Singapore. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3604915.3608874\n\nThe analysis and mining of user heterogeneous behavior are of paramount importance in recommendation systems. However, the\nconventional approach of incorporating various types of heterogeneous behavior into recommendation models leads to feature sparsity\nand knowledge fragmentation issues. To address this challenge, we propose a novel approach for personalized recommendation via\nLarge Language Model (LLM), by extracting and fusing heterogeneous knowledge from user heterogeneous behavior information. In\naddition, by combining heterogeneous knowledge and recommendation tasks, instruction tuning is performed on LLM for personalized\nrecommendations. The experimental results demonstrate that our method can effectively integrate user heterogeneous behavior and\nsignificantly improve recommendation performance.\nCCS Concepts: \u2022 Information systems \u2192 Recommender systems.\n\nsignificantly improve recommendation performance.\nCCS Concepts: \u2022 Information systems \u2192 Recommender systems.\nAdditional Key Words and Phrases: Recommendation, Large Language Models\nACM Reference Format:\nBin Yin, JunJie Xie, Yu Qin, ZiXiang Ding, ZhiChao Feng, Xiang Li, and Wei Lin. 2023. Heterogeneous Knowledge Fusion: A Novel\nApproach for Personalized Recommendation via LLM. In Seventeenth ACM Conference on Recommender Systems (RecSys \u201923), September\n18\u201322, 2023, Singapore, Singapore. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3604915.3608874\n\nditional Key Words and Phrases: Recommendation, Large Language Models\n\nACM Reference Format:\nBin Yin, JunJie Xie, Yu Qin, ZiXiang Ding, ZhiChao Feng, Xiang Li, and Wei Lin. 2023. Heterogeneous Knowledge Fusion: A Novel\nApproach for Personalized Recommendation via LLM. In Seventeenth ACM Conference on Recommender Systems (RecSys \u201923), September\n18\u201322, 2023, Singapore, Singapore. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3604915.3608874\n\nBin Yin, JunJie Xie, Yu Qin, ZiXiang Ding, ZhiChao Feng, Xiang Li, and Wei Lin. 2023. Heterogeneous Knowledge Fusion: A Nove\nApproach for Personalized Recommendation via LLM. In Seventeenth ACM Conference on Recommender Systems (RecSys \u201923), September\n18\u201322, 2023, Singapore, Singapore. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3604915.3608874\n\n# 1 INTRODUCTION\n\nThe analysis and mining of user behavior is a crucial aspect in recommendation systems. In the context of Meituan\nWaimai, user behavior exhibits heterogeneous characteristics, including various behavior subjects, content, scenarios.\nThe current industry approach mostly involves continuously adding various heterogeneous behavior to the traditional\nrecommendation models, which brings two obvious problems. Firstly, the multitude of behavior subjects leads to\nsparse features that pose challenges to efficient modeling. Secondly, separating the modeling of user, merchant, and\ncommodity behavior ignores the fusion of heterogeneous knowledge among behavior. However, we have noticed that\nheterogeneous user behavior contain rich semantic knowledge, and using semantics to represent and reason about user\nbehavior can more effectively promote heterogeneous knowledge fusion and capture user interests.\nLLMs have shown remarkable capabilities in various fields, thanks to rich semantic knowledge and powerful\ninferential reasoning [1, 10]. We have designed a new user behavior modeling framework via LLM, which extracts and\nintegrates heterogeneous knowledge from heterogeneous behavior information of users, and transforms structured\nuser behavior into unstructured heterogeneous knowledge. In the field of recommendation, there have been some\nattempts to use LLM for personalized recommendation. Liu et al [5] have used LLM to express recommendation tasks\nin natural language based on context cues, but only adopt a single user behavior modeling, ignoring the fusion of user\n\u2217 Both authors contributed equally to this research. \u2020 Corresponding author.\n\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrig components of this work must be honored. For all other uses, contact the owner/author(s).\n\u00a9 2023 Copyright held by the owner/author(s). Manuscript submitted to ACM\n\ndigital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party work must be honored. For all other uses, contact the owner/author(s).\n\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).\n\u00a9 2023 Copyright held by the owner/author(s). Manuscript submitted to ACM\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4a92/4a9283ac-bd47-4ef6-beb3-d1970d8838f1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e190/e1907fd0-7839-4801-a6b4-37eb475100cb.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Stage 1 : Heterogeneous Knowledge Fusion\n</div>\nig. 1. The overall framework of HKFR, including heterogeneous knowledge fusion (left), fine-tuning and recommendation (right).\neterogeneous knowledge. In addition, there are differences between the training task of LLMs and the recommendation\nask, which requires fine-tuning for specific recommendation tasks. Therefore, we propose H eterogeneous K nowledge\nusion, a new approach of personalized R ecommendation via LLM (HKFR). Firstly, we design a new user behavior\nmodeling framework using LLM, which extracts and integrates heterogeneous knowledge from heterogeneous behavior\nnformation of users. Then we combine heterogeneous knowledge and design instruction datasets for recommendation\nasks to fine-tune LLM. Finally, using the constructed recommendation task instruction and heterogeneous knowledge\ns input and the fine-tuned LLM for calculation, we output the recommended features and results for users.\nIn summary, our contributions are as follows:\n\u2022 We propose a new paradigm for user modeling, which extracts and integrates heterogeneous knowledge from\nheterogeneous user behavior information, transforming structured user behavior into unstructured heterogeneous\nknowledge, effectively capturing user interests.\n\u2022 We construct a personalized recommendation model based on LLM, combining recommendation tasks and\nheterogeneous knowledge, fine-tuning LLM to make it more effective for tasks in recommendation scenarios.\n\u2022 We have conducted sufficient offline and online experiments on Waimai dataset, verifying that our approach can\nfully integrate heterogeneous user behavior and effectively improve recommendation performance.\n\n# 2 METHODOLOGY\n\n# 2.1 Heterogeneous Knowledge Fusion\n\nIn the stage of heterogeneous knowledge fusion, we utilize the rich semantic knowledge and powerful reasoning\nabilities of LLM to facilitate the integration of heterogeneous knowledge.\nIn the context of Meituan Waimai, user heterogeneous behavior includes: multiple behavior subjects, such as\nmerchants and products; multiple behavior contents, such as exposure, clicks, and orders; multiple behavior scenarios,\nsuch as APP homepage and mini-programs. To address diverse user heterogeneous behavior, we extract and structure\n\non: A Novel Approach for Personalized Recommendation via LLM RecSys \u201923, Septem\n\nuser behavior data from the database with users as the core. Then, in the prompt engineering module, we design and\nconstruct different structured templates for diverse user behavior, expressing heterogeneous behavior as templated text\nlanguage. Next, in the knowledge fusion module, we employ ChatGPT [6] to perform heterogeneous knowledge fusion\non the behavior text, obtaining heterogeneous knowledge text. The heterogeneous knowledge generated based on user\nbehavior will be used for the fine-tuning and recommendation stages of LLM.\n\n# 2.2 Instruction Tuning\n\nThe fine-tuning process aims to help LLM better understand heterogeneous knowledge and further improve its accuracy\nand adaptability in recommendation tasks [7]. We construct an instruction dataset based on the recommendation task\nand heterogeneous knowledge, which includes input, instruction, and output. The input is the heterogeneous knowledge\ngenerated in the Section 2.1. The instruction and output are a series of task descriptions and target results generated\nspecifically for recommendation. The instruction includes recommendations for user preferences on categories, price,\nand merchants, among others, while the output is the true label of the user\u2019s next order. Based on the constructed\ninstruction dataset, we perform instruction tuning on LLM. Specifically, we choose the open-source model ChatGLM-6B\n[2] as our base LLM and adopt the Lora method for fine-tuning [4].\n\n# 2.3 Recommendation\n\nGiven a user, retrieve user behavior heterogeneous knowledge from the database as input for LLM. Then, design\ninstruction based on the recommendation task, perform reasoning and calculations, and output the recommended\nresults for the user. These instructions include predicting user preferences for categories, prices, and other features,\nas well as their next click on a merchant. The predicted results can be output as direct recommendations in natural\nlanguage form and can also be used as semantic features to enhance the recommendation effect by concatenating with\nthe existing features in traditional recommendation models.\n\n# 3 EXPERIMENT\n\nIn order to evaluate the performance of the model, we select two different recommendation tasks: recommendin\ncategories and POIs (points of interest) to user.\n\n# 3.1 Implementation\n\nFor offline experiment, we select the dataset from March to April 2023 of Meituan Waimai, design 20 recommendation\ntask instructions, and construct a total of 100,000 users and 1 million instruction data. The testing set is selected from the\nsamples on May 9th, 2023, consisting of 10,000 instruction data with two tasks, recommending POIs and categories. Each\ndata includes user statistical features, POI features, user heterogeneous behavior sequence features, label, etc. Due to the\nlimitation of the input length, the user sequence length is limited to 300. Additionally, user and POI data are anonymized\nbefore being inputted into LLM. To evaluate the recommendation effectiveness, we select top-k HR and top-k NDCG,\nwith k=5, 10. To demonstrate the effectiveness of our method, we compare it with traditional recommendation methods\nCaser [9], BERT4Rec [8], and language models P5 [3], ChatGLM-6B [2].\n\n# 3.2 Results and Anaysis\n\nTable 1 displays the experimental results, which demonstrate that our model outperforms multiple baselines on the\nWaimai dataset with significant improvements. Compared with traditional sequential recommendation methods such\n\n<div style=\"text-align: center;\">Table 1. Experimental results on two recommendation tasks, with bold indicating the best results and italic indicating ablatio experiments.\"no-HKF\" means removing heterogeneous knowledge fusion, and \"no-IT\" means removing instruction tuning.\n</div>\nMethods\nCategory\nPOIs\nHR@5\nNDCG@5\nHR@10\nNDCG@10\nHR@5\nNDCG@5\nHR@10\nNDCG@10\nCaser\n0.1152\n0.1063\n0.2147\n0.1320\n0.0897\n0.0770\n0.1842\n0.1012\nBERT4Rec\n0.1217\n0.1140\n0.2196\n0.1440\n0.0875\n0.0744\n0.1811\n0.0995\nP5\n0.1416\n0.1384\n0.2477\n0.1589\n0.1218\n0.1159\n0.2187\n0.1260\nChatGLM-6B\n0.1074\n0.1019\n0.2038\n0.1254\n0.0785\n0.0720\n0.1702\n0.0872\n\ud835\udc3b\ud835\udc3e\ud835\udc39\ud835\udc45\ud835\udc5b\ud835\udc5c\u2212\ud835\udc3c\ud835\udc47\n0.1241\n0.1175\n0.2267\n0.1415\n0.1014\n0.0952\n0.2050\n0.1165\n\ud835\udc3b\ud835\udc3e\ud835\udc39\ud835\udc45\ud835\udc5b\ud835\udc5c\u2212\ud835\udc3b\ud835\udc3e\ud835\udc39\n0.1813\n0.1308\n0.2825\n0.1580\n0.1421\n0.0975\n0.2432\n0.1270\nHKFR\n0.2160\n0.1586\n0.3007\n0.1840\n0.1726\n0.1243\n0.2610\n0.1525\nas Caser and BERT4Rec, our model demonstrates superior performance. This is mainly attributed to the effective fusion\nof heterogeneous knowledge by LLM. Our approach also achieves the best performance compared to language models\nsuch as P5 and ChatGLM. This is mainly due to the fine-tuning of professional datasets, which effectively improves the\nmismatch between LLM and recommendation tasks.\nWe conduct several experiments to validate the effectiveness of key modules in our HKFR. Compared to \ud835\udc3b\ud835\udc3e\ud835\udc39\ud835\udc45 \ud835\udc5b\ud835\udc5c \u2212 \ud835\udc3b\ud835\udc3e\ud835\udc39,\nwhich removes the heterogeneous knowledge fusion stage, HKFR demonstrates superior performance. This is mainly\nattributed to the accurate capture of user interests by fusing heterogeneous knowledge. Compared to \ud835\udc3b\ud835\udc3e\ud835\udc39\ud835\udc45 \ud835\udc5b\ud835\udc5c \u2212 \ud835\udc3c\ud835\udc47,\nwhich removes the instruction tuning stage, HKFR achieves better results, indicating that instruction tuning can\neffectively promote LLM to adapt to downstream recommendation tasks.\nHKFR was applied to the Meituan Waimai recommendation system for online A/B testing, by utilizing the computed\nfeatures from the previous day\u2019s search query of users and inputting them into the real-time computation on the\ncurrent day. The experiment ran for a period of May 9, 2023 to May 19, 2023. The results indicate that HKFR achieved\nimprovements of 2.45% in CTR and 3.61% in GMV for cold start users, while there was no significant effect found\non other users. This is attributed to the insufficient catering expertise of LLM, which makes it challenging to fully\ncomprehend and integrate heterogeneous behavior. Further training of LLM in the catering domain is necessary to\naddress this limitation.\n\n# 4 CONCLUSION\n\nIn this article, we propose HKFR, a new approach of personalized recommendation via LLM, which is based on the\nfusion of heterogeneous knowledge. By leveraging the two stages of heterogeneous knowledge fusion and instruction\ntuning, HKFR can effectively model user heterogeneous behavior. Extensive experiments on the Waimai dataset have\nvalidated the ability of HKFR to improve recommendation performance. In the future, we will focus on further training\nHKFR in the catering domain to better integrate heterogeneous knowledge and enhance recommendation performance.\n\n# REFERENCES\n\n[1] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 (2022).\n[2] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. GLM: General language model pretraining with autoregressive blank infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers).\n\n[1] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 (2022).\n[2] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. GLM: General language model pretraining with autoregressive blank infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 320\u2013335.\n\n[3] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5). In Proceedings of the 16th ACM Conference on Recommender Systems. 299\u2013315.\n[4] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685 (2021).\n[5] Junling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan Zhang. 2023. Is ChatGPT a Good Recommender? A Preliminary Study. arXiv preprint arXiv:2304.10149 (2023).\n[6] OpenAI. 2023. GPT-4 Technical Report. CoRR abs/2303.08774 (2023). https://doi.org/10.48550/arXiv.2303.08774 arXiv:2303.08774 [7] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730\u201327744.\n[8] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management. 1441\u20131450.\n[9] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the eleventh ACM international conference on web search and data mining. 565\u2013573.\n[10] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023).\n\nReceived 1 June 2023; revised 29 June 2023; accepted 27 July 2023\n\n",
    "paper_type": "method",
    "attri": {
        "background": "The analysis and mining of user heterogeneous behavior are crucial in recommendation systems. Conventional methods lead to feature sparsity and knowledge fragmentation, necessitating a new approach for personalized recommendations.",
        "problem": {
            "definition": "The problem addressed in this paper is the ineffective integration of various types of user heterogeneous behavior in recommendation systems, which results in sparse features and fragmented knowledge.",
            "key obstacle": "The main challenge is the separation of user, merchant, and commodity behavior modeling, which prevents effective fusion of heterogeneous knowledge among these behaviors."
        },
        "idea": {
            "intuition": "The idea is inspired by the observation that heterogeneous user behavior contains rich semantic knowledge that can be leveraged to enhance recommendation systems.",
            "opinion": "The proposed idea involves using a Large Language Model (LLM) to extract and fuse heterogeneous knowledge from user behavior, transforming structured data into unstructured knowledge for better user modeling.",
            "innovation": "The key innovation lies in the combination of heterogeneous knowledge fusion and instruction tuning in LLMs, which differentiates this method from existing approaches that do not effectively integrate user behavior."
        },
        "method": {
            "method name": "Heterogeneous Knowledge Fusion for Recommendation (HKFR)",
            "method abbreviation": "HKFR",
            "method definition": "HKFR is a personalized recommendation approach that utilizes LLMs to integrate heterogeneous knowledge from diverse user behaviors.",
            "method description": "The method involves extracting heterogeneous knowledge from user behavior and fine-tuning LLMs for effective personalized recommendations.",
            "method steps": [
                "Extract user behavior data from the database.",
                "Design structured templates for different user behaviors.",
                "Use LLM to perform knowledge fusion on the structured behavior data.",
                "Construct an instruction dataset for fine-tuning based on the fused knowledge.",
                "Perform reasoning and generate recommendations using the fine-tuned LLM."
            ],
            "principle": "The effectiveness of this method is based on the rich semantic knowledge and reasoning capabilities of LLMs, which allow for better integration and understanding of heterogeneous user behaviors."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted using the Meituan Waimai dataset, with 100,000 users and 1 million instruction data, focusing on recommending categories and points of interest.",
            "evaluation method": "Performance was assessed using metrics such as top-k Hit Rate (HR) and Normalized Discounted Cumulative Gain (NDCG), comparing HKFR with traditional methods like Caser and BERT4Rec."
        },
        "conclusion": "The proposed HKFR method effectively models user heterogeneous behavior and improves recommendation performance, as validated by extensive experiments on the Waimai dataset. Future work will focus on enhancing the model's performance in the catering domain.",
        "discussion": {
            "advantage": "HKFR stands out due to its effective integration of heterogeneous knowledge, leading to superior performance compared to traditional recommendation methods.",
            "limitation": "The method may struggle with fully integrating heterogeneous behavior due to insufficient training in specific domains, such as catering.",
            "future work": "Future research will aim to further train HKFR in targeted domains to enhance its understanding and integration of user behaviors."
        },
        "other info": {
            "info1": "The paper was presented at the Seventeenth ACM Conference on Recommender Systems (RecSys \u201923) in Singapore.",
            "info2": {
                "info2.1": "Authors: Bin Yin, Junjie Xie, Yu Qin, Zixiang Ding, Zhichao Feng, Xiang Li, Wei Lin.",
                "info2.2": "Published in 2023, DOI: https://doi.org/10.1145/3604915.3608874"
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The analysis and mining of user heterogeneous behavior are crucial in recommendation systems. Conventional methods lead to feature sparsity and knowledge fragmentation, necessitating a new approach for personalized recommendations."
        },
        {
            "section number": "2.1",
            "key information": "The problem addressed in this paper is the ineffective integration of various types of user heterogeneous behavior in recommendation systems, which results in sparse features and fragmented knowledge."
        },
        {
            "section number": "3.2",
            "key information": "The proposed idea involves using a Large Language Model (LLM) to extract and fuse heterogeneous knowledge from user behavior, transforming structured data into unstructured knowledge for better user modeling."
        },
        {
            "section number": "4.1",
            "key information": "The effectiveness of the Heterogeneous Knowledge Fusion for Recommendation (HKFR) method is based on the rich semantic knowledge and reasoning capabilities of LLMs, which allow for better integration and understanding of heterogeneous user behaviors."
        },
        {
            "section number": "4.2",
            "key information": "HKFR is a personalized recommendation approach that utilizes LLMs to integrate heterogeneous knowledge from diverse user behaviors."
        },
        {
            "section number": "10.1",
            "key information": "The main challenge is the separation of user, merchant, and commodity behavior modeling, which prevents effective fusion of heterogeneous knowledge among these behaviors."
        },
        {
            "section number": "10.2",
            "key information": "Future research will aim to further train HKFR in targeted domains to enhance its understanding and integration of user behaviors."
        }
    ],
    "similarity_score": 0.7520401037840799,
    "image": [
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4a92/4a9283ac-bd47-4ef6-beb3-d1970d8838f1.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e190/e1907fd0-7839-4801-a6b4-37eb475100cb.png"
    ],
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Heterogeneous knowledge fusion_ A novel approach for personalized recommendation via llm.json"
}