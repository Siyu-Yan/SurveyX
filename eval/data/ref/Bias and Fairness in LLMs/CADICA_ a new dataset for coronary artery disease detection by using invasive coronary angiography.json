{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2402.00570",
    "title": "CADICA: a new dataset for coronary artery disease detection by using invasive coronary angiography",
    "abstract": "Coronary artery disease (CAD) remains the leading cause of death globally and invasive coronary angiography (ICA) is considered the gold standard of anatomical imaging evaluation when CAD is suspected. However, risk evaluation based on ICA has several limitations, such as visual assessment of stenosis severity, which has significant interobserver variability. This motivates to development of a lesion classification system that can support specialists in their clinical procedures. Although deep learning classification methods are well-developed in other areas of medical imaging, ICA image classification is still at an early stage. One of the most important reasons is the lack of available and high-quality open-access datasets. In this paper, we reported a new annotated ICA images dataset, CADICA, to provide the research community with a comprehensive and rigorous dataset of coronary angiography consisting of a set of acquired patient videos and associated disease-related metadata. This dataset can be used by clinicians to train their skills in angiographic assessment of CAD severity and by computer scientists to create computer-aided diagnostic systems to help in such assessment. In addition, baseline classification methods are proposed and analyzed, validating the functionality of CADICA and giving the scientific community a starting point to improve CAD detection.",
    "bib_name": "jimnezpartinen2024cadicanewdatasetcoronary",
    "md_text": "# CADICA: a new dataset for coronary artery disease detection by using invasive coronary angiography\nAriadna Jim\u00b4enez-Partinen1,3, Miguel A. Molina-Cabello1,3, Karl Thurnhofer-Hemsi1,3,4, Esteban J. Palomo1,3, Jorge Rodr\u00b4\u0131guez-Capit\u00b4an2,3,4, Ana I. Molina-Ramos2,3,4, and Manuel Jim\u00b4enez-Navarro2,3,4,5\n1 Department of Computer Languages and Computer Science. University of M\u00b4alaga, Bulevar Louis Pasteur, 35, M\u00b4alaga, Spain, 29071 2 Cardiology Deparment, Hospital Universitario Virgen de la Victoria, M\u00b4alaga, 29010, Spain 3 Instituto de Investigaci\u00b4on Biom\u00b4edica de M\u00b4alaga y Plataforma en Nanomedicina-IBIMA Plataforma BIONAND, C/ Severo Ochoa, 35, M\u00b4alaga TechPark, Campanillas, 29590, M\u00b4alaga, Spain 4 Centro de Investigaci\u00b4on Biom\u00b4edica en Red de Enfermedades Cardiovasculares (CIBERCV), Instituto de Salud Carlos III (ISCIII), Avenida Monforte de Lemos, 3-5. Pabell\u00b4on 11. Planta 0, 28029, Madrid, Spain 5 Facultad de Medicina, University of M\u00b4alaga, Bulevar Louis Pasteur, 37, 29071, M\u00b4alaga, Spain\n1 Department of Computer Languages and Computer Science. University of M\u00b4alaga, Bulevar Louis Pasteur, 35, M\u00b4alaga, Spain, 29071 2 Cardiology Deparment, Hospital Universitario Virgen de la Victoria, M\u00b4alaga, 29010, Spain 3 Instituto de Investigaci\u00b4on Biom\u00b4edica de M\u00b4alaga y Plataforma en Nanomedicina-IBIMA Plataforma BIONAND, C/ Severo Ochoa, 35, M\u00b4alaga TechPark, Campanillas, 29590, M\u00b4alaga, Spain 4 Centro de Investigaci\u00b4on Biom\u00b4edica en Red de Enfermedades Cardiovasculares (CIBERCV), Instituto de Salud Carlos III (ISCIII), Avenida Monforte de Lemos, 3-5. Pabell\u00b4on 11. Planta 0, 28029, Madrid, Spain 5 Facultad de Medicina, University of M\u00b4alaga, Bulevar Louis Pasteur, 37, 29071, M\u00b4alaga, Spain\nAbstract. Coronary artery disease (CAD) remains the leading cause of death globally and invasive coronary angiography (ICA) is considered the gold standard of anatomical imaging evaluation when CAD is suspected. However, risk evaluation based on ICA has several limitations, such as visual assessment of stenosis severity, which has significant interobserver variability. This motivates to development of a lesion classification system that can support specialists in their clinical procedures. Although deep learning classification methods are well-developed in other areas of medical imaging, ICA image classification is still at an early stage. One of the most important reasons is the lack of available and high-quality open-access datasets. In this paper, we reported a new annotated ICA images dataset, CADICA, to provide the research community with a comprehensive and rigorous dataset of coronary angiography consisting of a set of acquired patient videos and associated disease-related metadata. This dataset can be used by clinicians to train their skills in angiographic assessment of CAD severity, by computer scientists to create computer-aided diagnostic systems to help in such assessment, and to validate existing methods for CAD detection. In addition, baseline classification methods are proposed and analyzed, validating the functionality of CADICA with deep learning-based methods and giving the scientific community a starting point to improve CAD detection.\nKeywords: Invasive coronary angiography dataset \u00b7 cardiovascular artery disease \u00b7 classification \u00b7 deep learning \u00b7 medical images.\n# 1 Introduction\nCoronary artery disease (CAD) remains the leading cause of death globally [1, 2]. Clinical presentations of CAD are currently categorized as either acute coronary syndromes or chronic coronary syndromes, and assessing patients with suspected CAD is a significant component of healthcare costs [3]. Invasive coronary angiography (ICA) is considered the gold standard of anatomical imaging evaluation when CAD is suspected [4, 5]. ICA acquisition is based on introducing radiocontrast through a catheter inserted by a percutaneous incision in the femoral or brachial artery, situated in the groin and the arm, respectively. The radiocontrast agent enhances the visibility of coronary arteries, with cardiac angiography equipment, X-ray-based, the state of the arteries is shown, allowing the clinicians to evaluate it and conclude if there is a luminal obstruction. The presence of obstructive CAD in ICA, usually defined as a lesion greater than 70 percent, has been recognized as an unequivocal sign of a bad cardiovascular prognosis. In contrast, it was initially proposed that non-obstructive CAD (usually defined as a lesion less than 70 percent) could constitute a condition related to a good cardiovascular prognosis [6], but subsequent evidence has increasingly shown that it confers an adverse prognosis when compared to the prognosis in the absence of CAD [7, 8, 9]. Consequently, it is currently accepted that cardiovascular risk increases when the degree of stenosis increases. However, risk evaluation based on ICA has several limitations. There is enough evidence indicating that the visual assessment of stenosis severity alone has significant interobserver variability, so this visual assessment alone does not provide us with enough information upon which to base decisions about revascularization in many patients [10]. In addition to this, angiographic assessment of CAD severity is limited in providing consistent information regarding the physiological significance of coronary lesions. Angiography is especially limited in coronary stenoses of intermediate severity (40\u201370 percent obstruction), where it predicts functional significance in less than 50 percent of lesions [11]. Visual assessment of coronary angiography fails to adequately determine lesion significance because lumen stenosis is only one variable out of many that influence the flow limitation of coronary lesions [12]. Lesion length, collateral flow, and the amount and health of the myocardial bed supplied are other essential factors that are not readily assessed by coronary angiography [13]. In order to overcome the aforementioned limitations, current guidelines recommend the routine assessment of vessel physiology in the form of indices derived from invasive pressure wire, such as fractional flow reserve and the instantaneous wave-free ratio [4, 5]. Despite these recommendations, the implantation of these functional tests in clinical practice has been especially low [14]. Many medical image datasets have been provided to the research community with the aim of developing an algorithm that can serve as a computer-aided diagnosis system [15, 16, 17, 18]. However, there is a lack of available and highquality open-access datasets regarding ICA images because most related studies use private image sets [19]. Some are provided by an associated medical center and used for image segmentation tasks [20, 21], while others are focused on\ndetection and classification [22, 23]. None of them provides access to other researchers to their data, which is necessary to achieve advances in this field. The main contributions of this work can be listed as follows:\n\u2013 To provide the research community with a comprehensive and rigorous scientific coronary angiography dataset formed by a set of videos acquired from patients and metadata related to diseases associated with them. This dataset may serve medical doctors to train their skills in angiographic assessment of CAD severity, and computer scientists to create computer-aided diagnosis systems to help with that kind of evaluation and to validate and improve existing methods for CAD detection by training them on more data. \u2013 A set of resources for testing algorithms. Additionally, an exhaustive revision and expansion process of these tools will be carried out regularly. \u2013 To provide a study of the performance of known architectures using the dataset with the aim of classifying ICA images according to the presence of lesions. \u2013 To help the community to identify other related challenges to provide a focus for future research.\nThe rest of the paper is structured as follows: Section 2 describes the recent state-of-art works related to ICA. In Section 3, the most important details about the creation and organization of the CADICA dataset are given. The experimental results are shown in Section 4. A discussion is provided in Section 5. Finally, Section 6 is devoted to conclusions.\n# 2 Related works\nDeep learning has been thoroughly used for both classification and segmentation tasks in medical imaging, including in the area of cardiology, where the most common imaging modalities are MRI (magnetic resonance imaging), and X-raybased, such as CCTA (Coronary Computed Tomography Angiography) and ICA (Invasive Coronary Angiography) [24]. Specifically for ICA images, we found the work of Auet al. [25], which uses ICA images of the right coronary artery to detect and classify coronary stenosis. They implemented a complex method based on three phases with different networks to do it. First, they used a detection network, YOLONet, to localize the patch where is the lesion. Straightaway, the lesion is segmented using the U-Net model, and finally, it is classified by a small CNN as stenosis if the narrowing is higher than 70%. Nasr-Esfahani et al. [20] used patches from 44 coronary angiographies to set a system, composed of two CNNs based on learned kernels, which returns a segmentation probability map of the ICA images. Wu et al. [26] proposed a method to localize stenosis lesions in ICA image sequences based on three stages. For this study, 148 sequences of ICA images were employed. Firstly, the most appropriate frames from the complete sequence are selected using the U-Net architecture. Next, a deconvolutional single-shot\nmultibox detector localizes the possible boxes that contain stenosis, and finally, they designed a temporal module to determine which boxes are actually stenosis, considering the temporal sequence of the boxes selected. Zhang et al. [27] used the U-net architecture to implement the C-Unet model that is a deep learning-based solution to automatically extract the centerlines of blood vessels from ICA images, achieving a precision higher than 80%. Cong et al. [23] implemented a system completely automatically for the classification and location of ICA images, which had been clustered into the left coronary artery and right coronary artery, and the lesions were into categories depending on their grade. To start, an inception-v3 model classified the images according to the projection to which they belonged. Then, the ideal candidate frames were selected by a fusion between inception-v3 and LSTM (long-shortterm memory), these candidates were classified into predefined categories by another inception-v3 model adapted for it, and to conclude, they employed a class activation map to identify the regions in ICA images where the lesion could be located. Zhou et al. [22] proposed a method to classify ICA images with stenosis. To carry out the study, they employed 8731 right coronary artery images, and the procedure was formed by three stages. Firstly, by ResNet-18 structure was carried out to extract keyframes, which presents enough contrast and clarity, from video sequences, there were 6533 non-key frames and 2198 keyframes Secondly, a vessel segmentation was implemented by a U-Net model to get their masks. And thirdly, lesions were measured by the skeletonization of the vessels in masks. Moon et al. [28] classified the ICA images into normal and abnormal arteries if the narrowing is lower or higher than 50%, respectively. As in the previous work reported, in this study, the first phase was based on extracting key frames from sequences of ICA videos, 542 videos were used, and then, an inceptionv3 architecture was fed with these keyframes to can classify them into normal or abnormal. To finalize, stenosis lesions were visually localized using class activation mapping. These reported works have some aspects in common with the study that we had been carrying out, but most of them are focused on implementing segmentation or using patches to classify the images, instead of complete images. Also, some of them excluded images with more than one lesion or only classify obstructive lesions, they utilize smaller datasets, most of them are private datasets, the detail of the artery and projections used is omitted or a different annotation is implemented.\n# 3 CADICA dataset\nNext, the most important details about the creation and organization of the CADICA dataset are presented.\n# .1 Patient Selection\nThe dataset proposed in this work consists of 668 invasive coronary angiography videos from 42 patients, acquired at Hospital Universitario Virgen de la Victoria, M\u00b4alaga, Spain. They have been included within the regulation set by the local ethical committee of the hospital and patient consent was waived, because this is a retrospective study with anonymized data. Prerequisites and data selection have not been performed in order to impose clinical fidelity. Therefore, a wide variability of cases and acquisition configurations were implied, while some cases were laborious to tag. This way, the dataset exhibits a high variety of pathological cases and image quality. Table 1 summarizes the baseline and demographic characteristics of patients included in the dataset.\nTable 1. Demographic and baseline characteristics of the patients. Data are given as % or as median (interquartile range)\nAge (years)\n71.5 (58.25-78)\nSex (female-male)\n47.6% - 52.4%\nDiabetes mellitus\n40.5%\nDyslipidemia\n40.5%\nSmoker\n45.2%\nHigh blood pressure\n61.9%\nKidney failure\n14.3%\nHeart failure\n14.3%\nAtrial fibrillation\n4.8%\nLeft ventricular ejection fraction\nNormal (ejection fraction >55%)\n68.2%\nMild dysfunction (ejection fraction 45%-55%)\n9.8%\nModerate dysfunction (ejection fraction 45%-35%)\n0%\nSevere dysfunction (ejection fraction <35%)\n22%\nClinical indication for angiography\nChronic coronary syndrome\n4.9%\nNon-ST segment elevation acute coronary syndrome\n65.9%\nST segment elevation acute coronary syndrome\n29.3%\nNumber of vessels affected\n0\n23.8%\n1\n50%\n2\n14.3%\n3\n11.9%\nMaximum degree of the coronary artery involvement\n<20%\n14.3%\n20-50%\n66.7%\n>70%\n19%\n# 3.2 Acquisition Protocol\nThe invasive coronary angiography videos were acquired as Digital Imaging and Communication in Medicine (DICOM) files recorded at 10 frames per second and with different duration (4-8 seconds) depending on the projection used, but they were converted to PNG images for effortless management. The frame size of each video is 512 \u00d7 512 pixels, while the length of the videos varies from 1 to 151 frames. The cardiac angiography equipment used was Artis Zee (Siemens AG, Muenchen, Germany). The dose of radiation administered in each projection ranges between 5-50 mGy. The protocol normally used in each angiography included five projections for the left coronary artery (LCA), such as right anterior oblique (RAO) and left anterior oblique (LAO), both with cranial and caudal angulation, with some additional projections in case of diagnostic difficulties. The projections used for the right coronary artery (RCA) are LAO and RAO, with cranial and caudal angulation. Fig. 1 and 2 show examples of projections for the left coronary artery and the right coronary artery, respectively.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2484/24849017-5336-4040-904a-78cb22461b6b.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 1. Examples for left coronary artery (LCA).</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9c39/9c39bc04-fb26-4629-a869-05d3db124c72.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 2. Examples of projections for right coronary artery (RCA)</div>\n# 3.3 Label Protocol\nA team of cardiologists was involved in the annotation of the dataset, assisted by computer scientists. For each frame, those regions of interest are delimited by a bounding box and classified into categories. This way, for each region of interest, is provided the location of the top left corner of its bounding box, its width, its height, and the label of that region of interest. The possible categories are itemized in Table 2.\n<div style=\"text-align: center;\">Table 2. Categories into which lesions have been divided.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1884/18840356-f939-4c71-ab13-35d7209a1709.png\" style=\"width: 50%;\"></div>\nLabel Lesion range\np0 20\n<20%\np20 50\n[20%, 49%]\np50 70\n[50%, 69%]\np70 90\n[70%, 89%]\np90 98\n[90%, 98%]\np99\n99%\np100\n100%\nFor each video, a selection of keyframes is carried out. This selection contains the list of frames that exhibit a contrast with enough appearance in order to classify the patient correctly. Videos are organized by patients, where a certain number of videos have been collected for each patient. According to their coronary artery stenosis percentage, patients are grouped into three different categories: < 20% (mild), 20 - 50% (moderate), and > 70% (severe). Lesions of 100% imply a total occlusion of the vessel, while a 99% lesion presents a gap where the radiocontrast is imperceptible, but the continuation of the vessel is visible. Those lesions that had a narrowing between 50 to 70 percent are classified as obstructive in some studies [29] and non-obstructive in others [30], while lesions with a higher narrowing than 70 percent in the previous bibliography showed consensus that they should be taken as obstructive and classify as non-obstructive the lesions that are solidly taken as non-obstructive (20\u201350 per-cent). Fig. 3 exhibits some sample images from different patients according to their classification into these categories.\n# 3.4 Dataset Organization\nVideo Selection The presented dataset provides a total of 668 ICA videos. However, in some frames of these videos where CAD is present, the lesion is indiscernible, being difficult to use them for diagnosis. In order to obtain the best videos for CAD classification, a selection of 382 videos was performed. These videos have been chosen by the medical team, where CAD can be visually classified correctly. Thus, videos in which radiocontrast does not perfuse have not been selected for the classification task. The specifications of CADICA dataset\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d241/d2415030-269f-47fb-a6c2-fd4a00d1a8a9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 3. Samples of the 3 categories in which lesions are classified and delimited by a bounding box annotated.</div>\nare reported in Table 3, where the number of patients, videos, images from selected videos and labels from \u201clesion\u201d images are itemized. Please note that the number of labels is higher than the number of \u201clesion\u201d images since it can be more than one lesion in an image.\nMetadata The dataset also provides additional clinical data associated with each patient, such as if the patient suffers from diabetes, dyslipidemia, smoking, hypertension, another comorbidity (such as chronic obstructive pulmonary disease), renal insufficiency, heart failure, atrial fibrillation, or left ventricular ejection fraction. Other information such as age, gender, height, weight, and later event (such as non-cardiac death or heart attack) is also reported.\nStructure The CADICA dataset becomes a directory that contains the metadata.xlsx file, which is the file where the clinical data is located, as well as two main folders that differentiate the videos selected by the medical team for each patient: nonselectedVideos and selectedVideos. Inside each folder, there are several sub-directories with the naming convention pX where X is the ID of each patient, and vY, where Y is the ID of the video of that patient. The folder pX contains the following information:\n\u2013 vY : several sub-directories with the videos selected for that patient.\n<div style=\"text-align: center;\">(c) Severe</div>\n<div style=\"text-align: center;\">Table 3. Specifications of CADICA dataset: number of patients, videos, images from selected videos and labels from \u201clesion\u201d images.</div>\nTable 3. Specifications of CADICA dataset: number of patients, videos, images from elected videos and labels from \u201clesion\u201d images.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e19e/e19ee863-0060-42b6-9952-98e0fecbed35.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">\u2013 lesionVideos.txt: contains the IDs of the selected videos where appears at least one lesion which is labeled. \u2013 nonlesionVideos.txt: contains the IDs of the selected videos where there are no visible lesions.</div>\n\u2013 lesionVideos.txt: contains the IDs of the selected videos where appears at least one lesion which is labeled. \u2013 nonlesionVideos.txt: contains the IDs of the selected videos where there are no visible lesions.\n# The folder vY contains the following information:\n\u2013 input: a sub-directory containing a separate PNG file for each frame of the video. \u2013 pX vY selectedFrames.txt: contains the IDs of the keyframes for the medica team, for all the selected videos. \u2013 groundtruth: a sub-directory available only if there are lesions in that selected video.\nThe folder groundtruth contains the following information:\n\u2013 pX vY 000ZZ.txt: contains the bounding boxes and their category in each row. There are such files as frames in pX vY selectedFrames.txt. Bounding boxes are specified in the format [x, y, w, h], where (x, y) are the pixel coordinates of the top left corner, w is the width and h is the height of the bounding box. \u2013 pX vY groundTruthTable.mat: contains a table with the ground truth information of that video.\n# 4 Experiments\nGiven the provided dataset in this work, we did an exhaustive performance comparison to classify ICA images according to the presence of lesions, being a binary problem, where the method classifies between \u201cnon-lesion\u201d or \u201clesion\u201d (images with any label from Table 2).\n# 4.1 Evaluation metrics\nIn order to measure the performance of a method that classifies coronary angiography images according to their coronary artery stenosis percentage, several well-known metrics have been proposed. Let us consider the true positives or number of hits (TP), true negatives or correct rejections (TN), false negatives or misses (FN), and false positives or false alarms (FP). The selected metrics and their definitions are as follows:\nThe most representative measures are the Accuracy (Acc), the F-measure (Fm, also known as F1 score), and the Balanced Accuracy (Bal), which provide a good overall evaluation of the performance of a given method. All these measures represent the percentage of hits of the system by providing values in the interval [0, 1], where higher is better. Meanwhile, other measures are also implicitly considered such as the precision (PR), the recall (RC), and the specificity (SP). In order to analyze these metrics, FN must be considered against FP (lower is better), PR against RC (higher is better).\n# 4.2 Methods\nConvolutional Neural Networks In this study, different Convolutional Neural Networks (CNNs) are used to compare their performance to classify ICA images from CADICA into two classes, \u201clesion\u201d, which means that appears at least one lesion, and \u201cnon-lesion\u201d. CNN is a type of deep learning model incorporating at least one convolutional layer, whose purpose is to extract the features from the input image, triggering under a specific condition [31]. CNNs have become successful methods with great versatility of applications in several areas, including medical images, and to solve different problems, such as segmentation, localization, or classification. Also, CNNs are characterized by their transferability of knowledge by applying the transfer learning technique, which is based on employing classification models trained on large datasets, also named pre-trained networks, which are re-trained with a specific dataset to specialize them to the particular problem [32]. In this study no layer was frozen, so all weights were updated according to the input dataset information. Five known pre-trained CNN architectures are used in this study: The Residual Networks (ResNets) family [33] introduces the residual connection to the model, these shortcut connections allow skipping some layers in the\n(1)\n(2)\n(3)\nprocess. In particular, in this study ResNet-18 and ResNet-50 networks are used, which are characterized by being composed of 18 and 50 layers deep, respectively. MobileNet-V2 [34] is a mobile neural network optimized to considerably reduce the number of parameters, compared with other architectures, which decreases the computational load. The MobileNet architecture is based on depthwise separable convolutions, which are a combination of two layers. The first is depthwise convolution, which applies a single filter to the input without extracting features, and the second is named pointwise convolution, which creates a linear combination output with new features [35]. NasNet-Mobile is the smallest version of NasNet models. NasNet models are CNNs based on Neural Architecture Search (NAS), which consist of basic building blocks, called cells, optimized by reinforcement learning method [36]. DenseNet-201 is a deep network based on ensuring the maximum information flow between layers by dense blocks. Dense blocks are blocks of layers, where each layer is connected to all former layers, instead only to the previous one [37].\nData Preprocessing In CADICA there are 382 selected videos in total, of which two subgroups were done differentiating between views of the left (LCA) and right (RCA) coronary arteries. The subgroup of LCA views was composed of 216 videos, a total of 3,228 images, where 1,003 images were labeled as \u201cnon-lesion\u201d and 2,225 were labeled as \u201clesion\u201d. The subgroup of RCA views consisted of 118 videos, which is 2,077 images in total, whose labels were distributed as 617 images labeled as \u201cnonlesion\u201d and 1,460 labeled as \u201clesion\u201d. The input image of the pre-trained architectures selected is an RGB image of size 224 \u00d7 224 pixels. Thus, the first processing applied to all images was to resize them and use the color preprocessing to ensure that images have the number of channels required, in this case, three channels. To study the binary classification problem \u201clesion\u201d/\u201cnon-lesion\u201d, both sets had been divided into training (80%) and test (20%) sets. This division was done by videos, which means that 80% of the \u201cnon-lesion\u201d and \u201clesion\u201d videos were used for training and the 20% remaining for testing. This way, frames of the same video of the train set are unavailable for the test set, because frames of a video are very similar between them. Both sets have unbalanced distributions, which can cause the model to specialize in the majority class, in this case, \u201clesion\u201d, and be relatively inefficient at classifying the minority class, in this case, \u201cnon-lesion\u201d. To solve this issue a data augmentation strategy had been applied to the training sets. This data augmentation was done by using different random basic operations of the original images, detailed as follows:\n\u2013 Translations in the x and y axis of [-25,25] pixels randomly, Fig. 4(b). \u2013 Rotation using a random angle between [-25\u00ba,25\u00ba], Fig. 4(c). \u2013 Scaling of the images with a random scale factor in a range of [0.8,1.7], Fig 4(d).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/661e/661e442d-b606-44a2-810f-82094f9813cf.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">ig. 4. Examples of the modifications applied to the training sets to augm</div>\nModifications were applied to the training sets of both classes, \u201clesion\u201d and \u201cnon-lesion\u201d images, and to both subsets, LCA and RCA, equalizing and increasing them. Fig. 5 shows the original class distributions for LCA and RCA sets, and the final distributions obtained after data augmentation was implemented, obtaining 3640 and 2342 images of each class in the LCA set and in the RCA set, respectively.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9137/9137f6e3-21c3-44eb-990f-a57f383caf31.png\" style=\"width: 50%;\"></div>\nFig. 5. Class distribution for Left coronary Artery (LCA) and Right Coronary Artery (RCA) sets.\nExperimental Setup Several parameters can be tuned for training convolutional neural networks. The main ones that we were focusing on are reported below:\n<div style=\"text-align: center;\">(d) Scale</div>\n\u2013 Validation frequency: it is the number of iterations between evaluations of the training process. \u2013 Maximum number of epochs: indicates the maximum times that the full dataset is passed to the model to update its weights. \u2013 Optimizer or solver: is the algorithm applied to update the weights of the network to reduce the loss function. \u2013 Initial Learning Rate: establishes the rate that is going to use to start the learning procedure. \u2013 Batch size: specifies the number of samples, in this case, images, that are processed by the model in one iteration.\nDue to many options for possible combinations of training parameters, we started studying the behavior of the performance, establishing some values to tune the training parameters. To evaluate the progress in the tuning of the parameters, we used the performance metrics reported in section 4.1, focusing on F-measure, Balanced Accuracy, and Accuracy, because together they provide a global view of the performance. The LCA set was employed for this process because it is the largest and most complex set. Finally, the parameters selected were used to evaluate the RCA set too. The first parameters that we set were validation frequency in 50 iterations to evaluate the training process and the maximum number of epochs established in 10 epochs because the increase of it had an unsubstantial improvement compared to time-consuming. For the optimizer, we compared different algorithms: Adam (adaptive moment estimation), SGDM (stochastic gradient descent with momentum), and RMSProp (root mean square propagation). Besides, we proposed several rates for the initial learning rate: 0.01, 0.001, 0.0001, and 0.00001. For the batch size, two values were selected, 16 and 64. In total there are 24 possible combinations, to compare them, we implemented the stratified K-fold cross-validation. This technique is adequate to evaluate the performance in a reliable way because the results are averages from different partitions of the input dataset, so results are independent of the partition employed to validate. The proposed models were implemented in MATLAB R2022b on a computer system with an Intel Core i9-10900X processor, 128 GB of RAM, and NVIDIA GeForce RTX 3080 Ti GPU card. Firstly, we divided the training set of LCA subset into 5 boxes with samples of both classes, 80% for training the models and 20% as the validation set. For each model, the 24 combinations established were executed, except DenseNet201, which was only trained with batch size 16 because of memory settings. The obtained results for test sets, with the different possible combinations for each architecture, are shown in Tables 4, 5, and 6, where F-measure, Balanced Accuracy and Accuracy values for each combination are reported. In these tables, the best results for each model and batch size are shown in bold. By observing these tables, we can see how in general terms is better to choose low learning rates and a batch size of 16 instead of 64. Moreover, SGDM and RMSProp solvers obtained better results than Adam, especially for batch sizes of\nTable 4. F-measure results obtained on the test set for LCA images using 5-fold stratified cross-validation, five convolutional network architectures, and different values for batch size, initial learning rate, and optimizer. The best performances are shown in bold.\nModel\nInitial\nLearning Rate\nBatch Size 16\nBatch Size 64\nAdam\nSGDM\nRMSProp\nAdam\nSGDM\nRMSProp\nMobileNet-V2\n0.01\n0.758 \u00b1 0.033 0.776 \u00b1 0.028\n0.755 \u00b1 0.096\n0.767 \u00b1 0.036\n0.806 \u00b1 0.013\n0.720 \u00b1 0.052\n0.001\n0.798 \u00b1 0.035 0.800 \u00b1 0.025\n0.791 \u00b1 0.034\n0.812 \u00b1 0.024\n0.786 \u00b1 0.018\n0.807 \u00b1 0.024\n0.0001\n0.809 \u00b1 0.030 0.794 \u00b1 0.021\n0.818 \u00b1 0.015\n0.806 \u00b1 0.016\n0.800 \u00b1 0.010\n0.808 \u00b1 0.015\n0.00001\n0.810 \u00b1 0.014 0.785 \u00b1 0.010 0.820 \u00b1 0.015 0.810 \u00b1 0.009 0.766 \u00b1 0.011\n0.789 \u00b1 0.012\nResNet-18\n0.01\n0.737 \u00b1 0.054 0.739 \u00b1 0.038\n0.730 \u00b1 0.094\n0.747 \u00b1 0.047\n0.789 \u00b1 0.011\n0.731 \u00b1 0.065\n0.001\n0.782 \u00b1 0.020 0.798 \u00b1 0.020\n0.765 \u00b1 0.025\n0.784 \u00b1 0.013 0.794 \u00b1 0.016 0.762 \u00b1 0.017\n0.0001\n0.784 \u00b1 0.022 0.780 \u00b1 0.022 0.800 \u00b1 0.021\n0.783 \u00b1 0.029\n0.788 \u00b1 0.026\n0.775 \u00b1 0.014\n0.00001\n0.783 \u00b1 0.017 0.800 \u00b1 0.029\n0.789 \u00b1 0.019\n0.772 \u00b1 0.016\n0.770 \u00b1 0.016\n0.782 \u00b1 0.012\nResNet-50\n0.01\n0.655 \u00b1 0.057 0.777 \u00b1 0.027\n0.380 \u00b1 0.418\n0.755 \u00b1 0.006\n0.793 \u00b1 0.013\n0.713 \u00b1 0.097\n0.001\n0.773 \u00b1 0.020 0.774 \u00b1 0.012\n0.775 \u00b1 0.031\n0.772 \u00b1 0.042\n0.779 \u00b1 0.021\n0.746 \u00b1 0.055\n0.0001\n0.785 \u00b1 0.023 0.784 \u00b1 0.025 0.823 \u00b1 0.017\n0.806 \u00b1 0.024\n0.802 \u00b1 0.016 0.818 \u00b1 0.023\n0.00001\n0.797 \u00b1 0.037 0.796 \u00b1 0.026\n0.808 \u00b1 0.025\n0.782 \u00b1 0.040\n0.783 \u00b1 0.034\n0.777 \u00b1 0.024\nNasNet-Mobile\n0.01\n0.743 \u00b1 0.018 0.785 \u00b1 0.017\n0.712 \u00b1 0.105\n0.723 \u00b1 0.037 0.798 \u00b1 0.011 0.717 \u00b1 0.047\n0.001\n0.807 \u00b1 0.026 0.811 \u00b1 0.028 0.790 \u00b1 0.032\n0.790 \u00b1 0.027\n0.785 \u00b1 0.019\n0.753 \u00b1 0.050\n0.0001\n0.794 \u00b1 0.025 0.770 \u00b1 0.036\n0.803 \u00b1 0.017\n0.779 \u00b1 0.015\n0.750 \u00b1 0.021\n0.783 \u00b1 0.016\n0.00001\n0.778 \u00b1 0.008 0.714 \u00b1 0.011\n0.770 \u00b1 0.016\n0.773 \u00b1 0.006\n0.659 \u00b1 0.049\n0.765 \u00b1 0.010\nDenseNet-201\n0.01\n0.694 \u00b1 0.020 0.736 \u00b1 0.032\n0.666 \u00b1 0.103\n0.001\n0.761 \u00b1 0.032 0.799 \u00b1 0.019\n0.758 \u00b1 0.025\n0.0001\n0.797 \u00b1 0.036 0.774 \u00b1 0.012\n0.801 \u00b1 0.034\n0.00001\n0.806 \u00b1 0.025 0.826 \u00b1 0.017 0.794 \u00b1 0.014\n16, where the results with the Adam solver never overcome SGDM and RMSProp solvers. The configurations selected for each model are reported in Table 7. These configurations were chosen according to the results obtained in Tables 4, 5, and 6 with 5-fold cross-validation. The optimizer and the initial learning rate that more times get the highest results were selected. For instance, the best values for MobileNet-V2 with a batch size of 16 were achieved using the RMSProp solver and an initial learning rate of 0.00001 in the three tables. However, some models present different best configurations depending on the measure taken into account, e.g., ResNet-18 with a batch size of 16 obtained the best results using the RMSProp optimizer for F-measure and Balanced Accuracy, whereas the best optimizer was SGDM for Accuracy. In this case, the RMSProp optimizer is selected. Likewise, the chosen initial learning rate was 0.00001 for ResNet-18.\n# 4.3 Results\nThe experiments carried out to compare the performance of the different pretrained models to evaluate the functionality of the implemented dataset based on the selected configurations (Table 7) are summarized here. These configurations were employed to implement a 10-fold stratified cross-validation, where 90% of images were used for training the models and 10% to validate the training process. The experimental results using different neural models, batch size and image subgroups (LCA and RCA) are shown in Table 8, where Balanced accuracy, F-measure and Accuracy obtained in the test set are reported. In Table 8 are shown in bold the highest values obtained for each measure in both subsets. Note that the best results for Balanced Accuracy and Accuracy were obtained\nTable 5. Balanced Accuracy results obtained on the test set for LCA images using 5-fold stratified cross-validation, five convolutional network architectures, and different values for batch size, initial learning rate, and optimizer. The best performances are shown in bold.\nModel\nInitial\nLearning Rate\nBatch Size 16\nBatch Size 64\nAdam\nSGDM\nRMSProp\nAdam\nSGDM\nRMSProp\nMobileNet-V2\n0.01\n0.586 \u00b1 0.059 0.597 \u00b1 0.052\n0.514 \u00b1 0.029\n0.608 \u00b1 0.029\n0.610 \u00b1 0.024 0.578 \u00b1 0.041\n0.001\n0.656 \u00b1 0.040 0.644 \u00b1 0.052\n0.650 \u00b1 0.044\n0.660 \u00b1 0.073\n0.630 \u00b1 0.022 0.648 \u00b1 0.052\n0.0001\n0.667 \u00b1 0.034 0.643 \u00b1 0.035\n0.671 \u00b1 0.011\n0.665 \u00b1 0.014\n0.638 \u00b1 0.030 0.657 \u00b1 0.018\n0.00001\n0.682 \u00b1 0.020 0.618 \u00b1 0.013 0.688 \u00b1 0.024 0.678 \u00b1 0.027 0.590 \u00b1 0.020 0.662 \u00b1 0.012\nResNet-18\n0.01\n0.551 \u00b1 0.071 0.559 \u00b1 0.028\n0.492 \u00b1 0.034\n0.594 \u00b1 0.053\n0.625 \u00b1 0.028 0.582 \u00b1 0.120\n0.001\n0.609 \u00b1 0.037 0.618 \u00b1 0.023\n0.605 \u00b1 0.017\n0.636 \u00b1 0.050 0.656 \u00b1 0.040 0.583 \u00b1 0.033\n0.0001\n0.592 \u00b1 0.014 0.633 \u00b1 0.027\n0.623 \u00b1 0.017\n0.610 \u00b1 0.037\n0.632 \u00b1 0.037 0.583 \u00b1 0.027\n0.00001\n0.640 \u00b1 0.009 0.633 \u00b1 0.061 0.649 \u00b1 0.024\n0.615 \u00b1 0.025\n0.618 \u00b1 0.043 0.638 \u00b1 0.014\nResNet-50\n0.01\n0.558 \u00b1 0.026 0.592 \u00b1 0.029\n0.500 \u00b1 0.000\n0.578 \u00b1 0.050\n0.632 \u00b1 0.027 0.547 \u00b1 0.084\n0.001\n0.600 \u00b1 0.022 0.613 \u00b1 0.022\n0.564 \u00b1 0.055\n0.626 \u00b1 0.014\n0.642 \u00b1 0.034 0.577 \u00b1 0.037\n0.0001\n0.636 \u00b1 0.031 0.653 \u00b1 0.033\n0.645 \u00b1 0.041\n0.638 \u00b1 0.057 0.651 \u00b1 0.022 0.648 \u00b1 0.030\n0.00001\n0.659 \u00b1 0.060 0.623 \u00b1 0.039 0.679 \u00b1 0.033\n0.650 \u00b1 0.047\n0.600 \u00b1 0.066 0.642 \u00b1 0.023\nNasNet-Mobile\n0.01\n0.562 \u00b1 0.020 0.620 \u00b1 0.048\n0.531 \u00b1 0.039\n0.568 \u00b1 0.043\n0.639 \u00b1 0.018 0.597 \u00b1 0.024\n0.001\n0.626 \u00b1 0.045 0.686 \u00b1 0.034\n0.649 \u00b1 0.053\n0.610 \u00b1 0.047 0.647 \u00b1 0.034 0.597 \u00b1 0.049\n0.0001\n0.625 \u00b1 0.029 0.644 \u00b1 0.048 0.649 \u00b1 0.025\n0.637 \u00b1 0.033\n0.618 \u00b1 0.035 0.629 \u00b1 0.017\n0.00001\n0.621 \u00b1 0.010 0.583 \u00b1 0.025\n0.629 \u00b1 0.010\n0.620 \u00b1 0.013\n0.529 \u00b1 0.022 0.607 \u00b1 0.017\nDenseNet-201\n0.01\n0.537 \u00b1 0.084 0.597 \u00b1 0.067\n0.512 \u00b1 0.056\n0.001\n0.576 \u00b1 0.041 0.666 \u00b1 0.020\n0.611 \u00b1 0.033\n0.0001\n0.623 \u00b1 0.060 0.627 \u00b1 0.022\n0.669 \u00b1 0.059\n0.00001\n0.642 \u00b1 0.037 0.672 \u00b1 0.025 0.638 \u00b1 0.022\nwith the MobileNet-V2 model for LCA subset (0.673 and 0.732, respectively). However, for the RCA set the NasNet-Mobile model achieved the best Balanced Accuracy and Accuracy (0.658, and 0.744). According to the F-measure, the best results were obtained by the ResNet-50 in both subsets (0.814, and 0.830, respectively). To study the best suitable model for these inputs, a ranking was implemented to evaluate the results attained considering the three measures. The rankings obtained are reported in Fig. 6, scoring the methods by set and batch size. The scores were calculated by sorting the obtained values of a measure in ascending order since a higher value is better according to the considered measures, meaning that the highest value will be in the last position. The position indicates the obtained scores. There are five and four methods for batch sizes 16 and 64, respectively. Therefore, the maximum possible score is 15 points and 12, respectively, indicating that the method attained the highest values in the three measures. Focusing on the LCA set, Fig. 6(a) and 6(b), the best outcomes are produced by MobileNet-V2, obtaining 15 points and 11 points with a batch size of 16 and 64, respectively. Although comparing the results obtained in Table 8, the best result is produced with a batch size of 64, which reached the maximum balanced accuracy, 0.673, and the second best F-measure and Accuracy, 0.810 and 0.732, respectively. However, in the case of RCA set, Fig. 6(c) and 6(d), ResNet-18 and NasNetMobile are the architectures that obtain higher performance, being NasNetMobile with a batch size of 64 which returns the best Balanced Accuracy and\nTable 6. Accuracy results obtained on the test set for LCA images using 5-fold stratified cross-validation, five convolutional network architectures, and different values for batch size, initial learning rate, and optimizer. The best performances are shown in bold.\nModel\nInitial\nLearning Rate\nBatch Size 16\nBatch Size 64\nAdam\nSGDM\nRMSProp\nAdam\nSGDM\nRMSProp\nMobileNet-V2\n0.01\n0.659 \u00b1 0.037 0.678 \u00b1 0.041\n0.642 \u00b1 0.074\n0.674 \u00b1 0.035\n0.710 \u00b1 0.017\n0.626 \u00b1 0.045\n0.001\n0.716 \u00b1 0.040 0.713 \u00b1 0.039\n0.708 \u00b1 0.044\n0.730 \u00b1 0.041\n0.696 \u00b1 0.018\n0.722 \u00b1 0.033\n0.0001\n0.729 \u00b1 0.036 0.708 \u00b1 0.029\n0.739 \u00b1 0.017\n0.726 \u00b1 0.019\n0.712 \u00b1 0.018\n0.725 \u00b1 0.017\n0.00001\n0.733 \u00b1 0.018 0.692 \u00b1 0.012 0.745 \u00b1 0.021 0.732 \u00b1 0.013 0.667 \u00b1 0.014\n0.708 \u00b1 0.012\nResNet-18\n0.01\n0.629 \u00b1 0.069 0.634 \u00b1 0.037\n0.611 \u00b1 0.089\n0.653 \u00b1 0.055\n0.698 \u00b1 0.014\n0.634 \u00b1 0.091\n0.001\n0.687 \u00b1 0.021 0.705 \u00b1 0.025\n0.671 \u00b1 0.022\n0.697 \u00b1 0.023 0.712 \u00b1 0.025 0.661 \u00b1 0.017\n0.0001\n0.684 \u00b1 0.021 0.692 \u00b1 0.027\n0.708 \u00b1 0.023\n0.688 \u00b1 0.036\n0.699 \u00b1 0.033\n0.673 \u00b1 0.019\n0.00001\n0.697 \u00b1 0.018 0.710 \u00b1 0.043 0.705 \u00b1 0.022\n0.679 \u00b1 0.021\n0.679 \u00b1 0.026\n0.695 \u00b1 0.015\nResNet-50\n0.01\n0.572 \u00b1 0.030 0.678 \u00b1 0.030\n0.473 \u00b1 0.209\n0.653 \u00b1 0.017\n0.703 \u00b1 0.019\n0.617 \u00b1 0.064\n0.001\n0.676 \u00b1 0.023 0.681 \u00b1 0.017\n0.650 \u00b1 0.027\n0.685 \u00b1 0.043\n0.694 \u00b1 0.029\n0.646 \u00b1 0.570\n0.0001\n0.698 \u00b1 0.022 0.702 \u00b1 0.030 0.737 \u00b1 0.027\n0.717 \u00b1 0.038\n0.718 \u00b1 0.019 0.732 \u00b1 0.029\n0.00001\n0.715 \u00b1 0.050 0.705 \u00b1 0.031\n0.731 \u00b1 0.032\n0.699 \u00b1 0.049\n0.685 \u00b1 0.050\n0.692 \u00b1 0.028\nNasNet-Mobile\n0.01\n0.638 \u00b1 0.016 0.692 \u00b1 0.028\n0.613 \u00b1 0.074\n0.623 \u00b1 0.042 0.711 \u00b1 0.015 0.630 \u00b1 0.037\n0.001\n0.715 \u00b1 0.037 0.736 \u00b1 0.035 0.706 \u00b1 0.040\n0.695 \u00b1 0.039\n0.701 \u00b1 0.025\n0.659 \u00b1 0.056\n0.0001\n0.704 \u00b1 0.028 0.687 \u00b1 0.044\n0.718 \u00b1 0.021\n0.693 \u00b1 0.021\n0.661 \u00b1 0.028\n0.694 \u00b1 0.018\n0.00001\n0.687 \u00b1 0.008 0.621 \u00b1 0.017\n0.682 \u00b1 0.016\n0.682 \u00b1 0.007\n0.562 \u00b1 0.038\n0.670 \u00b1 0.014\nDenseNet-201\n0.01\n0.589 \u00b1 0.041 0.643 \u00b1 0.047\n0.569 \u00b1 0.081\n0.001\n0.658 \u00b1 0.039 0.719 \u00b1 0.020\n0.666 \u00b1 0.030\n0.0001\n0.705 \u00b1 0.049 0.685 \u00b1 0.015\n0.723 \u00b1 0.032\n0.00001\n0.719 \u00b1 0.034 0.746 \u00b1 0.024 0.706 \u00b1 0.019\nable 7. Selected configurations considering F-measure, Balanced Accuracy and Acuracy obtained with 5-fold stratified cross-validation.\n<div style=\"text-align: center;\">Table 7. Selected configurations considering F-measure, Balanced Accuracy and Accuracy obtained with 5-fold stratified cross-validation.</div>\nModel\nBatch Size Optimizer Initial Learning Rate\nMobileNet-V2\n16\nRMSprop 0.00001\n64\nAdam\n0.00001\nResNet-18\n16\nRMSprop 0.00001\n64\nSGDM\n0.001\nResNet-50\n16\nRMSprop 0.00001\n64\nRMSprop 0.0001\nNasNet-Mobile\n16\nSGDM\n0.001\n64\nSGDM\n0.01\nDenseNet-201\n16\nSGDM\n0.00001\nAccuracy values, 0.658 and 0.744, respectively, and the second best F-measure, 0.826, according to the attained results reported in Table 8.\n# 5 Discussion\nIn this section, some important aspects to be considered of our proposal are discussed.\nIn this section, some important aspects to be considered of our proposal are discussed.\n\u2013 In this work, all degrees of lesions are considered, while other studies only include severe lesions [25, 38] or exclude those images in which more than one lesion appears [25]. Nevertheless, our results indicate a fair-to-high performance, which means that the dataset is functional, but also that this classification task is complex and challenging.\nTable 8. Balanced Accuracy, F-measure, and Accuracy results obtained on the test set for LCA and RCA images using 10-fold stratified cross-validation, five convolutional network architectures, and different batch size. The highest values by columns are shown in bold.\nModel\nBatch\nSize\nLCA\nRCA\nBalanced Accuracy\nF-measure\nAccuracy\nBalanced Accuracy\nF-measure\nAccuracy\nMobileNet-V2\n16\n0.668 \u00b1 0.014\n0.805 \u00b1 0.013\n0.725 \u00b1 0.015\n0.648 \u00b1 0.023\n0.811 \u00b1 0.018\n0.726 \u00b1 0.023\n64\n0.673 \u00b1 0.026\n0.810 \u00b1 0.020 0.732 \u00b1 0.025\n0.641 \u00b1 0.041\n0.806 \u00b1 0.026\n0.719 \u00b1 0.034\nResNet-18\n16\n0.642 \u00b1 0.026\n0.796 \u00b1 0.024\n0.710 \u00b1 0.029\n0.658 \u00b1 0.043\n0.825 \u00b1 0.023\n0.743 \u00b1 0.031\n64\n0.632 \u00b1 0.013\n0.779 \u00b1 0.009\n0.691 \u00b1 0.010\n0.624 \u00b1 0.045\n0.792 \u00b1 0.031\n0.702 \u00b1 0.039\nResNet-50\n16\n0.664 \u00b1 0.035\n0.793 \u00b1 0.029\n0.713 \u00b1 0.036\n0.618 \u00b1 0.022\n0.799 \u00b1 0.009\n0.705 \u00b1 0.013\n64\n0.645 \u00b1 0.044\n0.814 \u00b1 0.021 0.728 \u00b1 0.029\n0.620 \u00b1 0.029\n0.830 \u00b1 0.025 0.738 \u00b1 0.031\nNasNet-Mobile\n16\n0.634 \u00b1 0.047\n0.789 \u00b1 0.023\n0.701 \u00b1 0.033\n0.651 \u00b1 0.054\n0.804 \u00b1 0.058\n0.723 \u00b1 0.067\n64\n0.637 \u00b1 0.043\n0.783 \u00b1 0.020\n0.696 \u00b1 0.029\n0.658 \u00b1 0.034\n0.826 \u00b1 0.033 0.744 \u00b1 0.039\nDenseNet-201\n16\n0.641 \u00b1 0.024\n0.802 \u00b1 0.022\n0.715 \u00b1 0.027\n0.633 \u00b1 0.037\n0.812 \u00b1 0.029\n0.723 \u00b1 0.037\n\u2013 Despite the fact that a Balanced Accuracy between 0.65 and 0.67 was obtained, it represents a good performance since this measure depends on specificity and recall, which quantifies an average of how correctly both classes are classified, and the \u201cnon-lesion\u201d class is worse classified than the \u201clesion\u201d class. This is due to the fact that there are fewer \u201cnon-lesion\u201d images than \u201clesion\u201d images, although data augmentation was applied to equalize both classes. Since the \u201clesion\u201d class includes all degrees of lesion, non-severe lesions can be incorrectly classified as \u201cnon-lesion\u201d. \u2013 Although the DenseNet model usually has a good performance [39, 40, 41], we could not evaluate it with a batch size of 64 due to memory requirements. Nevertheless, training this model with a batch size of 16 yielded good results in terms of F-measure. Therefore, better results will be expected by training with higher batch sizes. \u2013 Finally, for LCA images, the selected configurations outcomes similar results, where the MobileNet-V2 was the most suitable model independently of the batch size. However, the results reported a higher variability for RCA images, since the most suitable models depend on the batch size. Thus, ResNet-18 is the best model for batch size 16, whereas for batch size 64 it is the worst model. This could be because the selected configurations were chosen with 5fold cross-validation results for the LCA images, and these configurations were applied to classify the RCA images.\n# 6 Conclusions\nThe coronary dataset published in this work aims to provide the research community with a conscientious and exhaustive scientific resource. It can serve as a benchmark for both algorithm implementations and medical staff to train their abilities on angiographic assessment of CAD severity. Considering the researchers\u2019 feedback, a set of utilities and the already extensive dataset will be regularly revised and expanded. Experiments were designed to try the functionality of the dataset, which was divided into LCA and RCA images. Five well-known classification architec-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/afc1/afc10f67-e579-446e-9786-3186e4fa8519.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">ng of LCA set with batch size 16. (b) Ranking of LCA set with batch size</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d6ce/d6ce4ae1-0b9c-43b1-828f-a90c60ddcca3.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(c) Ranking of RCA set with batch size 16. (d) Ranking of RCA set with batch size 64.</div>\n<div style=\"text-align: center;\">Fig. 6. Ranking of methods considering F-measure, Balanced Accuracy and Accuracy obtained for the LCA and RCA subsets using batch sizes 16 and 64.</div>\ntures were trained and tested using augmented data to get an overview of the performance classification of the \u201clesion\u201d and \u201cnon-lesion\u201d images. Experiments showed that the most suitable models to solve this problem were MobileNetV2 for LCA images and NasNet-Mobile for RCA images, getting fair-to-high outcomes, around 80% F-measure and Accuracy, and 65% Balanced Accuracy. These results were obtained considering a wide range of lesion levels and support the idea that this classification task is complex, setting up a challenge for physicians and computer-aided diagnosis systems. Therefore, the provided dataset gives the scientific community a starting point to improve CAD detection.\nGiven the complexity of the classification problem posed, other architectures could be tested in order to keep evaluating the performance of different models. Also, future works will focus on classifying severe lesions images, as well as trying to identify each type of severity. The use of image patches to detect and classify the arteries present in this region will help to improve classification rates.\n# Declarations\nData availability\nCADICA dataset is open-access available at the Mendeley Data repository with the data identification number: 10.17632/p9bpx9ctcv.1, and direct URL to data: https://data.mendeley.com/datasets/p9bpx9ctcv/1.\n# Author Contibutions\nAll authors listed have made a substantial, direct, and intellectual contribution to the work, and approved it for publication.\n# Declaration of competing interest\nDeclaration of competing interest\nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n# Conflicts of Interest\nConflicts of Interest\nThe authors declare that they have no conflicts of interest to report regarding the present study\n# Acknowledgment\nThis work is partially supported by the Autonomous Government of Andalusia (Spain) under project UMA20-FEDERJA-108, project name Detection, characterization and prognosis value of the non-obstructive coronary disease with deep learning, and also by the Ministry of Science and Innovation of Spain, grant number PID2022-136764OA-I00, project name Automated Detection of Non Lesional Focal Epilepsy by Probabilistic Diffusion Deep Neural Models. It includes funds from the European Regional Development Fund (ERDF). It is also partially supported by the University of M\u00b4alaga (Spain) under grants B1-2019 01, project name Anomaly detection on roads by moving cameras; B1-2019 02, project name Self-Organizing Neural Systems for Non-Stationary Environments; B1-2021 20, project name Detection of coronary stenosis using deep learning applied to coronary angiography; B4-2022, project name Intelligent Clinical Decision Support System for Non-Obstructive Coronary Artery Disease in Coronarographies; B1-2022 14, project name Detecci\u00b4on de trayectorias an\u00b4omalas de veh\u00b4\u0131culos en c\u00b4amaras de tr\u00b4afico; and by the Fundaci\u00b4on Unicaja under project PUNI-003 2023, project name Intelligent System to Help the Clinical Diagnosis of Non-Obstructive Coronary Artery Disease in Coronary Angiography. The authors thankfully acknowledge the computer resources, technical expertise and assistance provided by the SCBI (Supercomputing and Bioinformatics) center of the University of M\u00b4alaga. They also gratefully acknowledge the\nsupport of NVIDIA Corporation with the donation of a RTX A6000 GPU with 48Gb. The authors also thankfully acknowledge the grant of the Universidad de M\u00b4alaga and the Instituto de Investigaci\u00b4on Biom\u00b4edica de M\u00b4alaga y Plataforma en Nanomedicina-IBIMA Plataforma BIONAND.\n# References\n[1] Sherry L Murphy et al. \u201cMortality in the United States, 2020\u201d. In: NCHS Data Brief 427 (2021). [2] Konstantinos V. Voudris and Clifford J. Kavinsky. \u201cAdvances in Management of Stable Coronary Artery Disease: the Role of Revascularization?\u201d eng. In: Current Treatment Options in Cardiovascular Medicine 21.3 (Mar. 2019), p. 15. issn: 1092-8464. doi: 10.1007/s11936-019-0720-9. [3] Antti Saraste et al. \u201cImaging in ESC clinical guidelines: chronic coronary syndromes\u201d. eng. In: European Heart Journal. Cardiovascular Imaging 20.11 (Nov. 2019), pp. 1187\u20131197. issn: 2047-2412. doi: 10.1093/ehjci/ jez219. [4] Juhani Knuuti et al. \u201c2019 ESC Guidelines for the diagnosis and management of chronic coronary syndromes: The Task Force for the diagnosis and management of chronic coronary syndromes of the European Society of Cardiology (ESC)\u201d. In: European Heart Journal 41.3 (Aug. 2019), pp. 407\u2013477. issn: 0195-668X. doi: 10.1093/eurheartj/ehz425. [5] Jean-Philippe Collet et al. \u201c2020 ESC Guidelines for the management of acute coronary syndromes in patients presenting without persistent STsegment elevation\u201d. en. In: European Heart Journal 42.14 (Apr. 2021), pp. 1289\u20131367. issn: 0195-668X, 1522-9645. doi: 10.1093/eurheartj/ ehaa575. (Visited on 07/30/2021). [6] H. G. Kemp et al. \u201cSeven year survival of patients with normal or near normal coronary arteriograms: a CASS registry study\u201d. eng. In: J Am Coll Cardiol 7.3 (Mar. 1986), pp. 479\u2013483. issn: 0735-1097. doi: 10.1016/ s0735-1097(86)80456-9. [7] Jorge Rodr\u00b4\u0131guez-Capit\u00b4an et al. \u201cPrognostic Implication of Non-Obstructive Coronary Lesions: A New Classification in Different Settings\u201d. eng. In: Journal of Clinical Medicine 10.9 (Apr. 2021), p. 1863. issn: 2077-0383. doi: 10.3390/jcm10091863. [8] Zhi Jian Wang et al. \u201cPrevalence and Prognosis of Nonobstructive Coronary Artery Disease in Patients Undergoing Coronary Angiography or Coronary Computed Tomography Angiography: A Meta-Analysis\u201d. eng. In: Mayo Clin Proc 92.3 (Mar. 2017), pp. 329\u2013346. issn: 1942-5546. doi: 10.1016/j.mayocp.2016.11.016. [9] Francesco Radico et al. \u201cDeterminants of long-term clinical outcomes in patients with angina but without obstructive coronary artery disease: a systematic review and meta-analysis\u201d. eng. In: European Heart Journal 39.23 (June 2018), pp. 2135\u20132146. issn: 1522-9645. doi: 10.1093/eurheartj/ ehy185.\n[1] Sherry L Murphy et al. \u201cMortality in the United States, 2020\u201d. In: NCHS Data Brief 427 (2021). [2] Konstantinos V. Voudris and Clifford J. Kavinsky. \u201cAdvances in Management of Stable Coronary Artery Disease: the Role of Revascularization?\u201d eng. In: Current Treatment Options in Cardiovascular Medicine 21.3 (Mar. 2019), p. 15. issn: 1092-8464. doi: 10.1007/s11936-019-0720-9. [3] Antti Saraste et al. \u201cImaging in ESC clinical guidelines: chronic coronary syndromes\u201d. eng. In: European Heart Journal. Cardiovascular Imaging 20.11 (Nov. 2019), pp. 1187\u20131197. issn: 2047-2412. doi: 10.1093/ehjci/ jez219. [4] Juhani Knuuti et al. \u201c2019 ESC Guidelines for the diagnosis and management of chronic coronary syndromes: The Task Force for the diagnosis and management of chronic coronary syndromes of the European Society of Cardiology (ESC)\u201d. In: European Heart Journal 41.3 (Aug. 2019), pp. 407\u2013477. issn: 0195-668X. doi: 10.1093/eurheartj/ehz425. [5] Jean-Philippe Collet et al. \u201c2020 ESC Guidelines for the management of acute coronary syndromes in patients presenting without persistent STsegment elevation\u201d. en. In: European Heart Journal 42.14 (Apr. 2021), pp. 1289\u20131367. issn: 0195-668X, 1522-9645. doi: 10.1093/eurheartj/ ehaa575. (Visited on 07/30/2021). [6] H. G. Kemp et al. \u201cSeven year survival of patients with normal or near normal coronary arteriograms: a CASS registry study\u201d. eng. In: J Am Coll Cardiol 7.3 (Mar. 1986), pp. 479\u2013483. issn: 0735-1097. doi: 10.1016/ s0735-1097(86)80456-9. [7] Jorge Rodr\u00b4\u0131guez-Capit\u00b4an et al. \u201cPrognostic Implication of Non-Obstructive Coronary Lesions: A New Classification in Different Settings\u201d. eng. In: Journal of Clinical Medicine 10.9 (Apr. 2021), p. 1863. issn: 2077-0383. doi: 10.3390/jcm10091863. [8] Zhi Jian Wang et al. \u201cPrevalence and Prognosis of Nonobstructive Coronary Artery Disease in Patients Undergoing Coronary Angiography or Coronary Computed Tomography Angiography: A Meta-Analysis\u201d. eng. In: Mayo Clin Proc 92.3 (Mar. 2017), pp. 329\u2013346. issn: 1942-5546. doi: 10.1016/j.mayocp.2016.11.016. [9] Francesco Radico et al. \u201cDeterminants of long-term clinical outcomes in patients with angina but without obstructive coronary artery disease: a systematic review and meta-analysis\u201d. eng. In: European Heart Journal 39.23 (June 2018), pp. 2135\u20132146. issn: 1522-9645. doi: 10.1093/eurheartj/ ehy185.\n[10] Nick Curzen et al. \u201cDoes routine pressure wire assessment influence management strategy at coronary angiography for diagnosis of chest pain?: the RIPCORD study\u201d. eng. In: Circ Cardiovasc Interv 7.2 (Apr. 2014), pp. 248\u2013255. issn: 1941-7632. doi: 10.1161/CIRCINTERVENTIONS.113. 000978. [11] Pim A. L. Tonino et al. \u201cFractional flow reserve versus angiography for guiding percutaneous coronary intervention\u201d. eng. In: The New England Journal of Medicine 360.3 (Jan. 2009), pp. 213\u2013224. issn: 1533-4406. doi: 10.1056/NEJMoa0807611. [12] E. J. Topol and S. E. Nissen. \u201cOur preoccupation with coronary luminology. The dissociation between clinical and angiographic findings in ischemic heart disease\u201d. eng. In: Circulation 92.8 (Oct. 1995), pp. 2333\u2013 2342. issn: 0009-7322. doi: 10.1161/01.cir.92.8.2333. [13] David A. Halon. \u201cCan angiography predict physiology?\u201d eng. In: International Journal of Cardiology 270 (Nov. 2018), pp. 74\u201375. issn: 1874-1754. doi: 10.1016/j.ijcard.2018.07.029. [14] Lavinia Gabara et al. \u201cCoronary Physiology Derived from Invasive Angiography: Will it be a Game Changer?\u201d eng. In: Interv Cardiol 15 (Apr. 2020), e06. issn: 1756-1485. doi: 10.15420/icr.2019.25. [15] Philipp Tschandl, Cliff Rosendahl, and Harald Kittler. \u201cThe HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions\u201d. In: Scientific data 5.1 (2018), pp. 1\u20139. [16] Noel CF Codella et al. \u201cSkin lesion analysis toward melanoma detection: A challenge at the 2017 international symposium on biomedical imaging (isbi), hosted by the international skin imaging collaboration (isic)\u201d. In: 2018 IEEE 15th international symposium on biomedical imaging (ISBI 2018). IEEE. 2018, pp. 168\u2013172. [17] Fabio A Spanhol et al. \u201cA dataset for breast cancer histopathological image classification\u201d. In: Ieee transactions on biomedical engineering 63.7 (2015), pp. 1455\u20131462. [18] Damian J Matuszewski and Ida-Maria Sintorn. \u201cTEM virus images: Benchmark dataset and deep learning classification\u201d. In: Computer Methods and Programs in Biomedicine 209 (2021), p. 106318. [19] Emmanuel Ovalle-Magallanes et al. \u201cImproving convolutional neural network learning based on a hierarchical bezier generative model for stenosis detection in X-ray images\u201d. In: Computer Methods and Programs in Biomedicine 219 (2022), p. 106767. [20] Ebrahim Nasr-Esfahani et al. \u201cSegmentation of vessels in angiograms using convolutional neural networks\u201d. In: Biomedical Signal Processing and Control 40 (2018), pp. 240\u2013251. [21] Kritika Iyer et al. \u201cAngionet: a convolutional neural network for vessel segmentation in X-ray angiography\u201d. In: Scientific Reports 11.1 (2021), p. 18066.\n[22] Chengyang Zhou et al. \u201cAutomated deep learning analysis of angiography video sequences for coronary artery disease\u201d. In: arXiv preprint arXiv:2101.12505 (2021). [23] Chao Cong et al. \u201cAutomated stenosis detection and classification in xray angiography using deep neural network\u201d. In: 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE. 2019, pp. 130 1308. [24] Yucheng Song et al. \u201cDeep learning-based automatic segmentation of images in cardiac radiography: a promising challenge\u201d. In: Computer Methods and Programs in Biomedicine (2022), p. 106821. [25] Benjamin Au et al. \u201cAutomated characterization of stenosis in invasive coronary angiography images with convolutional neural networks\u201d. In: arXiv preprint arXiv:1807.10597 (2018). [26] Wei Wu et al. \u201cAutomatic detection of coronary artery stenosis by convolutional neural network with temporal constraint\u201d. In: Computers in biology and medicine 118 (2020), p. 103657. [27] Xinyue Zhang et al. \u201cX-ray coronary centerline extraction based on CUNet and a multifactor reconnection algorithm\u201d. In: Computer Methods and Programs in Biomedicine 226 (2022), p. 107114. [28] Jong Hak Moon et al. \u201cAutomatic stenosis recognition from coronary angiography using convolutional neural networks\u201d. In: Computer methods and programs in biomedicine 198 (2021), p. 105819. [29] Tom Finck et al. \u201c10-year follow-up after coronary computed tomography angiography in patients with suspected coronary artery disease\u201d. In: JACC: Cardiovascular Imaging 12.7 Part 2 (2019), pp. 1330\u20131338. [30] Se Hun Kang et al. \u201cLong-term prognostic value of coronary CT angiography in asymptomatic type 2 diabetes mellitus\u201d. In: JACC: Cardiovascular Imaging 9.11 (2016), pp. 1292\u20131300. [31] Jian Wang et al. \u201cA review of deep learning on medical image analysis\u201d. In: Mobile Networks and Applications 26.1 (2021), pp. 351\u2013380. [32] Emmanuel Ovalle-Magallanes et al. \u201cTransfer learning for stenosis detection in X-ray coronary angiography\u201d. In: Mathematics 8.9 (2020), p. 1510. [33] Kaiming He et al. \u201cDeep residual learning for image recognition\u201d. In: Proceedings of the IEEE conference on computer vision and pattern recognition. 2016, pp. 770\u2013778. [34] Mark Sandler et al. \u201cMobilenetv2: Inverted residuals and linear bottlenecks\u201d. In: Proceedings of the IEEE conference on computer vision and pattern recognition. 2018, pp. 4510\u20134520. [35] Wannipa Sae-Lim, Wiphada Wettayaprasit, and Pattara Aiyarak. \u201cConvolutional neural networks using MobileNet for skin lesion classification\u201d. In: 2019 16th international joint conference on computer science and software engineering (JCSSE). IEEE. 2019, pp. 242\u2013247. [36] Narsi Reddy, Ajita Rattani, and Reza Derakhshani. \u201cComparison of deep learning models for biometric-based mobile user authentication\u201d. In: 2018\nIEEE 9th international conference on biometrics theory, applications and systems (BTAS). IEEE. 2018, pp. 1\u20136. [37] Gao Huang et al. \u201cDensely connected convolutional networks\u201d. In: Proceedings of the IEEE conference on computer vision and pattern recognition. 2017, pp. 4700\u20134708. [38] Yiwen Shu and Xiwen Wu. \u201cDeep Learning Based Coronary Angiography in Diagnosis of Myocardial Ischemia\u201d. In: Scientific Programming 2021 (2021). [39] Sebastian Guendel et al. \u201cLearning to recognize abnormalities in chest xrays with location-aware dense networks\u201d. In: Iberoamerican Congress on Pattern Recognition. Springer. 2018, pp. 757\u2013765. [40] Karl Thurnhofer-Hemsi and Enrique Dom\u00b4\u0131nguez. \u201cA convolutional neural network framework for accurate skin cancer detection\u201d. In: Neural Processing Letters 53.5 (2021), pp. 3073\u20133093. [41] Tavishee Chauhan, Hemant Palivela, and Sarveshmani Tiwari. \u201cOptimization and Fine-Tuning of DenseNet model for classification of Covid-19 cases in Medical Imaging\u201d. In: International Journal of Information Management Data Insights 1.2 (2021), p. 100020.\n",
    "paper_type": "benchmark",
    "attri": {
        "background": {
            "problem background": "Coronary artery disease (CAD) is the leading cause of death globally. Invasive coronary angiography (ICA) is the gold standard for evaluating CAD, but it has limitations such as interobserver variability in assessing stenosis severity. This highlights the need for a reliable benchmark to improve CAD assessment through better classification methods.",
            "purpose of benchmark": "The benchmark aims to provide a comprehensive dataset for comparing models and testing algorithms in the context of CAD detection, thereby supporting both clinical training and the development of computer-aided diagnostic systems."
        },
        "problem": {
            "definition": "The benchmark is designed to address the classification of coronary angiography images into categories based on the presence and severity of lesions, specifically distinguishing between 'lesion' and 'non-lesion' images.",
            "key obstacle": "Existing benchmarks are limited by small sizes, lack of access, and focus on specific lesion types, which restricts the development of robust CAD detection algorithms."
        },
        "idea": {
            "intuition": "The creation of the benchmark was motivated by the need for a high-quality, open-access dataset that encompasses a wide variety of CAD cases to facilitate both clinical training and algorithm development.",
            "opinion": "The authors believe that the benchmark will significantly impact the field by providing a valuable resource for researchers and clinicians, enhancing the understanding and diagnosis of CAD.",
            "innovation": "CADICA differs from previous benchmarks by including a larger and more diverse set of angiography videos, comprehensive annotations, and metadata related to patient conditions, thus offering a more holistic approach to CAD assessment.",
            "benchmark abbreviation": "CADICA"
        },
        "dataset": {
            "source": "The dataset was created from 668 invasive coronary angiography videos acquired from 42 patients at a hospital, following ethical guidelines.",
            "desc": "The CADICA dataset includes a total of 668 videos, with a selection process resulting in 382 high-quality videos suitable for classification tasks.",
            "content": "The dataset consists of video frames annotated with bounding boxes indicating regions of interest related to CAD severity, categorized based on lesion percentage.",
            "size": "382",
            "domain": "Cardiology",
            "task format": "Binary classification"
        },
        "metrics": {
            "metric name": "Accuracy, F1-score",
            "aspect": "Model performance in classifying images as 'lesion' or 'non-lesion'",
            "principle": "The metrics were chosen to provide a comprehensive evaluation of model performance, focusing on both overall accuracy and the balance between precision and recall.",
            "procedure": "Models were evaluated using a 10-fold stratified cross-validation, with metrics calculated based on true positives, true negatives, false positives, and false negatives."
        },
        "experiments": {
            "model": "Various convolutional neural networks (CNNs) including MobileNet-V2, ResNet-18, and NasNet-Mobile were tested.",
            "procedure": "Models were trained on the dataset using different configurations, including varying batch sizes and learning rates, while employing data augmentation to address class imbalance.",
            "result": "The experiments demonstrated that MobileNet-V2 and NasNet-Mobile achieved the best performance for the LCA and RCA subsets, respectively, with F-measure and accuracy around 80%.",
            "variability": "Variability was accounted for through the use of stratified cross-validation and data augmentation techniques."
        },
        "conclusion": "The CADICA dataset serves as a significant resource for the research community, providing a robust foundation for developing and validating CAD detection algorithms, while also enhancing clinical training in angiographic assessments.",
        "discussion": {
            "advantage": "The benchmark offers a comprehensive dataset that includes various lesion types and patient conditions, thereby improving the robustness of CAD detection algorithms.",
            "limitation": "The dataset may have limitations in representation, as it is based on a specific patient population and may not cover all potential variations in CAD presentations.",
            "future work": "Future research will focus on expanding the dataset, improving classification algorithms, and exploring the identification of specific lesion types and their severity."
        },
        "other info": []
    },
    "mount_outline": [
        {
            "section number": "2.1",
            "key information": "Algorithmic bias can occur in medical AI systems if the training data is not representative of the diverse patient population, potentially leading to misclassification of coronary artery disease (CAD) severity."
        },
        {
            "section number": "3.1",
            "key information": "The benchmark addresses the classification of coronary angiography images into categories based on the presence and severity of lesions, highlighting how biased data can lead to systematic discrimination in CAD assessment."
        },
        {
            "section number": "4.1",
            "key information": "The CADICA benchmark aims to provide a comprehensive dataset to ensure AI technologies in CAD detection align with clinical standards and societal values."
        },
        {
            "section number": "5.1",
            "key information": "Various convolutional neural networks (CNNs) including MobileNet-V2, ResNet-18, and NasNet-Mobile were tested to enhance the interpretability of model performance in classifying CAD severity."
        },
        {
            "section number": "6.1",
            "key information": "Responsible AI in the context of CAD detection involves ensuring that the algorithms are validated using a diverse dataset to minimize bias and improve accountability in clinical settings."
        },
        {
            "section number": "7.1",
            "key information": "The interconnections between algorithmic bias, ethical AI, and model interpretability are evident in the development of the CADICA benchmark, which seeks to improve the robustness of CAD detection algorithms through comprehensive data."
        },
        {
            "section number": "8.1",
            "key information": "Future research will focus on expanding the CADICA dataset and improving classification algorithms to address the challenges of representation and bias in CAD assessment."
        }
    ],
    "similarity_score": 0.564601606818376,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-15-0337_algor/papers/CADICA_ a new dataset for coronary artery disease detection by using invasive coronary angiography.json"
}