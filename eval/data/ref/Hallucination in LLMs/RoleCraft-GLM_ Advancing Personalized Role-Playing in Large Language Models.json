{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2401.09432",
    "title": "RoleCraft-GLM: Advancing Personalized Role-Playing in Large Language Models",
    "abstract": "The development of large language models(LLMs) has initiated a new chapter in complex tasks such as role-playing, enhancing user interaction experiences by enabling models to imitate various characters.However, LLMs are somewhat lacking in their ability to portray lesser-known characters, especially in aspects of dialogue delivery and scriptwriting skills. To this end, we aim to swiftly acquire essential language skills for character development, greatly enhancing role-playing comfort. In this work, we present RoleCraft, an innovative framework designed to enrich personalized role-playing experiences. Central to this framework is RoleInstruct, a distinctive dataset featuring emotional annotations, transitioning from traditional celebrity-focused roles to more authentic, daily non-celebrity roles,each accompanied by carefully crafted character descriptions. We combined RoleInstruct with open-source instructions from the general domain, employing a hybrid instruction tuning strategy to create RoleCraft-GLM. Experiments in role-playing demonstrate that our model excels in generating dialogue that accurately reflects character traits and emotions, outperforming most mainstream LLMs, including GPT-41.",
    "bib_name": "tao2024rolecraftglmadvancingpersonalizedroleplaying",
    "md_text": "# RoleCraft-GLM: Advancing Personalized Role-Playing in Large Language Models\nMeiling Tao1\u2217, Xuechen Liang2\u2217, Tianyu Shi3\u2020, Lei Yu3, Yiting Xie4 1Guangdong University of Technology, Guangzhou, China 2East China Jiaotong University, Nanchang, China 3 University of Toronto, Toronto, Canada 4Genfun.ai, Beijing, China\n# Abstract\nThe development of large language models(LLMs) has initiated a new chapter in complex tasks such as role-playing, enhancing user interaction experiences by enabling models to imitate various characters.However, LLMs are somewhat lacking in their ability to portray lesser-known characters, especially in aspects of dialogue delivery and scriptwriting skills. To this end, we aim to swiftly acquire essential language skills for character development, greatly enhancing role-playing comfort. In this work, we present RoleCraft, an innovative framework designed to enrich personalized role-playing experiences. Central to this framework is RoleInstruct, a distinctive dataset featuring emotional annotations, transitioning from traditional celebrity-focused roles to more authentic, daily non-celebrity roles,each accompanied by carefully crafted character descriptions. We combined RoleInstruct with open-source instructions from the general domain, employing a hybrid instruction tuning strategy to create RoleCraft-GLM. Experiments in role-playing demonstrate that our model excels in generating dialogue that accurately reflects character traits and emotions, outperforming most mainstream LLMs, including GPT-41.\narXiv:2401.09432v2\n# 1 Introduction\nLarge Language Models (LLMs) have emerged as pivotal in understanding and generating natural language, often surpassing human capabilities in some language reasoning tasks. However, existing open-source LLMs, primarily trained in general domains, lack the specialized optimization needed for nuanced role-playing tasks, indicating a need for further customization to effectively meet specific role-playing requirements. Furthermore, advanced LLMs like GPT-4 (OpenAI, 2023) demon-\n\u2217Equal contribution. \u2020\u2217Corresponding author: ty.shi@mail.utoronto.ca 1Access models, demos a https://github.com/tml2002/RoleCraft\nstrate improved role-playing abilities due to extensive training and sophisticated algorithms, but as a closed-source model, it poses practical challenges. These challenges include higher costs for API use, limited fine-tuning opportunities for specific role-playing contexts, and context window size restrictions that may affect the continuity and depth of dialogues in complex role-playing scenarios.In light of this, a natural question arises: Can we meticulously train and tailor open-source LLMs to achieve role-playing capabilities comparable to closed-source LLMs, while also enhancing their ability to meet individual user needs? Previous efforts in AI role-playing have primarily centered on celebrity figures (Shao et al., 2023; Li et al., 2023a), heavily reliant on predefined domain knowledge and often lacking in relevance to daily life and personalization. While there have been improvements in learning from past interactions and adapting to user needs, these advancements have not sufficiently addressed the challenges of achieving truly personalized AI interactions (Chen, 2023). Existing role-playing models still lack the necessary depth and individual specificity to accurately reflect the diverse and nuanced experiences of everyday users. To enhance the role-playing capabilities of LLMs, there are two main challenges: (1) Limited Personalization in Generic AI Models: Many AI systems currently rely on generic models that frequently fail to address the specific and nuanced needs of diverse user groups. This limitation undermines the overall user experience and restricts the practical application of AI in specialized scenarios (Ackerman et al., 2022). (2) Gap in Sophisticated Role-Playing Capabilities: In the realm of conversational agents, despite significant achievements in providing high-level responses across a variety of dialogues and enhancing human-AI interactions (Bender and Koller, 2020), there remains a noticeable gap in AI\u2019s capacity for sophisticated\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/95ad/95ad63ea-0010-4080-9706-badd0f541270.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: Overview of the RoleCraft-GLM framework: (1) Dialog datasets annotated with emotions are utilized to construct role profiles embodying distinct emotional features. (2) The generation of Q&A pairs, based on context and known character traits, ensures that dialogues are consistent with the character profiles. (3) A hybrid approach of generic and character-specific instructions is used to train the GLM for various dialog scenarios.</div>\nrole-playing. Current models often lack the depth and adaptability required for truly personalized and nuanced role-play experiences. In this paper, as illustrated in the figure 1, we introduce the RoleCraft framework designed to enhance personalized role-playing experiences with LLMs. Moving beyond traditional celebrityfocused characters, we focus on diverse, noncelebrity personas, each with unique emotional annotations. This approach aims to enrich realism and emotional depth in language interactions. We compiled a novel dataset encompassing a wide array of real-world dialogues, with careful consideration for personal privacy and copyright laws. Our data analysis highlights the potential benefits of integrating emotional labels in dialogue datasets for improved natural language processing. We conducted comparative experiments using models like ChatGLM3, fine-tuned with the Low-Rank Adaptation (LoRA) method, to assess RoleCraft-GLM\u2019s effectiveness in producing nuanced and characterconsistent dialogues. The main contributions of our work are as follows:\n\u2022 We introduce a novel RoleInstruct dataset, which centers on non-celebrity characters, each characterized by unique emotional annotations.\n\u2022 We introduce a novel RoleInstruct dataset, which centers on non-celebrity characters, each characterized by unique emotional annotations.\n\u2022 We develop RoleCraft, a novel framework that integrates a more detailed approach to per-\nsonal role data in training strategies. RoleCraft includes a fine-grained method for character portrayal, emphasizing emotional depth, and fostering contextual awareness in dialogue generation.\n RolePlay-GLM, our fine-tuned model, demonstrates promising performance against current state-of-the-art models, excelling in dialogue authenticity, emotional accuracy, and contextual relevance as per comprehensive evaluations.\n# 2 Related Work\n# 2.1 Role-Playing\nThe evolution of role-playing in AI (Wu et al., 2023), marked by the transition from basic textbased interactions to intricate character simulations (Park et al., 2023), reflects the strides made in natural language processing and AI technologies (Mysore et al., 2023). Initially, AI role-playing systems offered only fundamental exchanges, limited in their ability to craft dialogues with emotional depth and contextual relevance. With the emergence of advanced models such as GPT3 (Brown et al., 2020), LLaMA (Touvron et al., 2023), and ChatGLM, there was a notable enhancement in AI\u2019s capability for engaging in more sophisticated, context-aware conversations. Yet, these improvements also underscored a significant gap in personalization for role-playing applications.\nPredominantly, LLMs trained on wide-ranging, generic datasets fell short in handling scenarios that demanded a deeper understanding of nuanced emotional nuances (Radford et al., 2018) and specific character traits. To address these shortcomings, we meticulously develop the RoleCraft framework. It stands out with its unique dataset, focusing on diverse, non-celebrity personas enriched with detailed emotional annotations (Bender and Koller, 2020). This dataset is key to overcoming previous limitations, facilitating a new level of personalization and emotional intricacy in AI role-playing interactions.\n# 2.2 Personalization of LLMs\nThe recent strides in LLMs, particularly in understanding user context and preferences (Wang et al., 2023a; Abbasian et al., 2023), have significantly propelled the personalization aspect of AI interactions (Lee et al., 2022; Subhash, 2023). Previous works (Shanahan et al., 2023; Li et al., 2023c; Chen et al., 2023) have demonstrated the potential of LLMs in mimicking specific fictional characters and simulating complex human behaviors. However, these models often face challenges in achieving a deep level of personalization and emotional richness that aligns precisely with individual user contexts and needs (Mi\u0142kowski et al., 2022). Additionally, while these models are adept at simulating personalities or historical figures, they may not effectively handle the subtleties of user-specific emotional responses or cater to nuanced personal preferences. Our work aims to address these gaps by building upon these advancements and offering a framework that focuses on a more granular level of personalization. We propose novel methods for emotional and context-specific interaction, ensuring that our model can adapt and respond more accurately to individual user scenarios.\n# 3 Methodology\nAs shown in Figure 1, the RoleCraft framework, rooted in \u2018Role\u2019 and \u2018Craft\u2019, represents our approach to enhancing AI role-playing. \u2018Role\u2019 emphasizes creating distinct, multi-dimensional characters, each with unique personality traits and emotional depths. \u2018Craft\u2019 involves the intricate process of constructing dialogues that genuinely reflect these character traits, thereby adding depth and realism to conversations.See Appendix A for more details.\n# 3.1 Overall Framework\nOur methodology uniquely advances the capabilities of LLMs in role-playing. Setting ourselves apart from approaches such as RoleLLM (Wang et al., 2023b), we focus on an innovative integration of fine-grained character portrayal, profound emotional depth, and heightened contextual awareness in dialogue generation. This approach differentiates our work from existing models and addresses challenges in a novel way, enhancing how LLMs can be utilized for creating more realistic and engaging role-playing scenario.\n# Emotion-Driven Character Profiling\nTo address the challenges of limited emotional diversity and unconvincing character portrayals in dialogues generated by LLMs, we adopt a detailed emotion classification strategy. This approach involves meticulously annotating emotions within the dialogue dataset, thereby steering the GPT-4 to craft character profiles that mirror these identified emotions. Consider a character who displays a spectrum of emotions from joy to disappointment. Marking these diverse emotional states allows for a natural and fluid transition in their dialogues within a single scene, effectively capturing the complexity and dynamism of human emotions. Our approach challenges the LLMs to accurately depict these emotional shifts, ensuring that the dialogues genuinely represent the intricate and ever-evolving nature of human emotions, thus enhancing the overall user interaction experience.\n# Contextual Q&A Generation\nTo address the challenge of context-irrelevant responses (Feng et al., 2023; Ye et al., 2022), which is a common issue in dialogue systems (Ni et al., 2023) where interactions often lack relevance to the ongoing scenario or character specifics (Mitsuda et al., 2022), we employ GPT-4 to generate contextually coherent Q&A pairs. For example, when a character faces a dilemma, the system is designed to produce queries and responses that align with the character\u2019s established traits, such as indecisiveness and anxiety, thereby maintaining the authenticity of the dialogue in relation to the character\u2019s profile.\n# Hybrid Instruction-Based GLM Refinement\nOur methodology employs a hybrid training approach that seamlessly integrates general instructions with character-specific Q&A pairs. This strat-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2242/224263b6-b0ca-440e-bbee-1947dc0cfe43.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">prompt</div>\n<div style=\"text-align: center;\">Figure 2: An example of crafting a detailed character portrayal. By leveraging a character description template an a dialogue dataset with emotional annotations.(The instruction and output have been translated into English)</div>\negy is carefully crafted to strike a balance between the flexibility required for dynamic dialogue generation and the need to uphold character integrity. In practical terms, this means equipping the LLMs to adeptly navigate a spectrum of conversational scenarios. These range from broad, general interactions to more intricate exchanges that demand responses finely tuned to the unique profiles of individual characters. By training the LLM with this diverse mix of inputs, the model becomes proficient in handling various situational dialogues, accurately reflecting each character\u2019s distinct attributes and the specific subtleties of the conversation. As a result, this hybrid training method fosters the creation of dialogues that are both contextually adaptive and consistent with the characters\u2019 distinct personalities.\n# 3.2 Semantic-Enhanced Retrieval Optimization\nAddressing the issue of inaccurate and semantically irrelevant information retrieval in dialogues, we adopt the BGE2 retrieval method. BGE is an efficient Chinese and English semantic vector model that ensures the accuracy of responses, especially when dealing with sensitive topics, and remains semantically sensitive to the context, significantly enhancing the quality of interaction (Xiao et al., 2023). This familiarity allows models to generate dialogue based on a wealth of pre-existing knowledge. In contrast, modern datasets prioritize the nuanced portrayal of personal and everyday characters. These datasets are derived from diverse 2https://github.com/FlagOpen/FlagEmbedding\nsources, including real chat logs, customer service interactions, and fictional narratives from less mainstream media. Such characters might include a typical office worker dealing with daily stressors or a mother showing love and responsibility in a family setting. The dialogues here involve specific, real-life scenarios, such as office interactions or typical family conversations, which lack the broad pre-existing knowledge base associated with public figures.\n# 3.3 Compared to Existing Practice\nOur methodology diverges from conventional prompt engineering (White et al., 2023) and finetuning (Howard and Ruder, 2018) We specialize in creating diverse, intricate character interactions that enhance role-playing scenarios\u2019 depth and authenticity. Our unique approach combines emotiondriven character profiles with contextually coherent Q&A generation, fostering realistic and engaging interactions. Additionally, the integration of semantic-enhanced retrieval methods ensures both accuracy and relevance, setting our approach apart in its complexity and user engagement potential.\n# 4 Experiments\nBuilding on previous work (Tao et al., 2023), we introduced new evaluation methods and made comprehensive enhancements to the experimental process, conducting an in-depth analysis of model performance changes in specific scenarios. We anticipate that fine-tuning our model using a specifically designed dataset for role-playing will result in superior performance in character portrayal com-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d8f2/d8f2c51a-7585-47e4-b0f4-78146d8c5f6d.png\" style=\"width: 50%;\"></div>\nFigure 3: Verb-noun structure of Instructions. The inner circle representing the top 20 verbs and the outer circle listing the direct noun objects.\n<div style=\"text-align: center;\">Table 1: Statistics of datasets</div>\nCategory\nValue\n# Total Dialogues\n48,677\nAvg.round of dialogues\n14.85\n# Characters\n28\nCharacter Personality Traits\n45\nAvg.length of profile\n382.15\n# Instructions\n43,358\nCharacter-specific instructions\n13,778\nGeneral instructions\n29,580\nAvg. instruction length\n27.68\n# Response\n161,678\nCharacter-specific response\n13,778\nGeneral response\n147,900\nAvg.response length\n33.29\npared to baseline models. Through this specialized training, we expect our model to accurately capture and express the intricacies of character-specific language styles and emotional responses, surpassing baseline models that may lack such targeted training. Our experiments aim to validate this hypothesis and showcase the advanced capabilities of our model in role-playing tasks.\n# 4.1 Dataset\nIn the evaluation of LLMs (Chen et al., 2021; Chang et al., 2023), the role of datasets is paramount, particularly in language processing and character portrayal. Traditional role playing datasets predominantly highlight eminent figures, such as the legendary Sun Wukong, whose familiar attributes and stories are widely acknowledged, facilitating model development (Sabado\u0161, 2021).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f5b9/f5b9e21f-2e3a-41c4-9b25-081ef99ff30c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Emotion distributions in dialogues</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/32ea/32eae34b-1eb4-4c44-b561-5d331e8e99f1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 5: Word Cloud Of Character Personality Traits</div>\nHowever, these datasets often neglect the finer details and emotional complexity of lesser-known or everyday characters, leading to a representation gap (Rolf et al., 2021). Our unique dataset bridges this gap by focusing on the rich, nuanced depiction of ordinary individuals. It involves an in-depth exploration and portrayal of each character\u2019s distinct personality traits and emotional depths, delving into aspects usually overshadowed in dominant narratives. In constructing our dataset, we design 28 unique and personalized Chinese characters to mirror a wide spectrum of real-world dialogues. These characters ranged from everyday individuals to specialized roles such as intelligent customer service agents and research assistants. Table 1 provides basic statistics for RoleInstruct. Our diverse data sources included social media interactions, film and television scripts, and customer service dialogues. We emphasized personal privacy and copyright law compliance, ensuring all data was cleansed and anonymized. Figures 3 and 5 visually demonstrate the diversity of RoleInstruct, both in terms of linguistic usage and emotional expression. The verb-noun diagram provides insights into the varied narrative contexts, while the word cloud delves into the breadth of emotional and personality traits present. In addition, we annotate each dataset entry with emotion labels to capture characters\u2019 distinct emotional traits, adding an emotional layer to model training. We use Ekman\u2019s \"Six Basic Emotions Theory\" (Ekman, 1992) to label utterances and included additional emotions like neutral, excited, and depressed, totaling ten categories. The use\nof emotion labels in dialogue datasets has been proven to enhance natural language processing by improving response retrieval and emotional relevance (Zhou et al., 2017). These labels also enrich conversational analysis and aid in building natural dialogue systems (Bothe et al., 2019). See Appendix B for more details.\n# 4.2 Implementation Settings\nWe assess the ChatGLM3 model, enhancing its performance on specific datasets using the Low-Rank Adaptation (LoRA) fine-tuning method (Hu et al., 2021). LoRA\u2019s precision in fine-tuning, essential for handling personalized and emotionally rich content, maintains the model\u2019s core capabilities while adapting to new data features. Please refer to Appendix C for more details.\n# 4.3 Baselines\nWe benchmark our RoleCraft-GLM\u2019s performance against industry standards such as GPT-3.5 and GPT-4, and leading Chinese dialogue generation technologies like ChatGLM23 and ChatGLM3, along with Baichuan2 (Yang et al., 2023), Qwen (Bai et al., 2023), InternLM (Team, 2023), SparkDesk4 and Xverse5. Additionally, we introduce another role-playing baseline, RoleLLM, which utilizes LoRA for fine-tuning on a specific dataset.\n# 4.4 Evaluation criteria\n# 4.4 Evaluation criteria 4.4.1 Rouge-L Score\nA commonly used metric (Lin, 2004) for evaluating natural language generation, measuring the overlap between model-generated text and real (ground truth) text. We focused on average score (Avg), general instruction response (RAW), role-playing speaking style (CUS), and specific role knowledge (SPE).\n# 4.4.2 GPT Score\nWe use the GPT-4 score (Fu et al., 2023) to evaluate the average rank of models on different dialoguegenerating tasks.Please refer to Appendix D for more details.\n# 4.4.3 RPCS\nWe introduce Role-Playing Cosine Similarity (RPCS) as a new evaluation standard to accurately\n3https://github.com/THUDM/ChatGLM2-6B 4https://xinghuo.xfyun.cn/ 5https://github.com/xverse-ai/XVERSE-13B\nassess model performance in role-playing scenarios. RPCS evaluates the emotional and content consistency between the model-generated responses and the expected responses by calculating the cosine similarity between two text segments. Concurrently, we use OpenAI\u2019s Text-Embedding-Ada002 model to convert texts into vector representations, enabling deeper capture of semantic features of texts, thereby enhancing the precision of our assessment.\n# 4.4.4 Human Evaluation\nTo effectively assess role-playing agents, we engaged 12 annotators who rated model-generated responses using three key metrics on a five-point scale: Communication Effectiveness, Consistency, and Expressive Diversity (Zhang et al., 2021; Mesgar et al., 2020; Tu et al., 2024).\n\u2022 Communication Effectiveness(CE): Merging fluency and coherence, the metric evaluates the dialogue\u2019s smoothness, grammatical accuracy, logical consistency, and contextual relevance.\n\u2022 Consistency: Encompassing knowledge and persona consistency, this metric assesses the accuracy of the agent\u2019s information relative to the role\u2019s background and the adherence to the character\u2019s traits and behaviors.\n\u2022 Expressive Diversity(ED): Focused on evaluating the agent\u2019s creativity in dialogue generation.It\u2019s vital for assessing the agent\u2019s ability to enhance user experience and interaction engagement.\n<div style=\"text-align: center;\">Table 2: Rouge-L Evaluation</div>\nModel\nAvg\nRAW\nCUS\nSPE\nGPT-3.5\n0.4532\n0.5569\n0.5197\n0.2831\nGPT-4\n0.4633\n0.5661\n0.5264\n0.2973\nChatGLM2\n0.4054\n0.5104\n0.4063\n0.2996\nChatGLM3\n0.4161\n0.5218\n0.4159\n0.3108\nBaichuan2\n0.4273\n0.5308\n0.4576\n0.2934\nQwen\n0.4264\n0.5297\n0.4617\n0.2879\nInternLM\n0.3947\n0.4937\n0.4076\n0.2829\nSparkDesk\n0.4288\n0.5341\n0.4510\n0.3014\nXverse\n0.4271\n0.5180\n0.4653\n0.2981\nRoleGLM\n0.4570\n0.5255\n0.5049\n0.3406\nOurs\n0.4704\n0.5385\n0.5154\n0.3573\n<div style=\"text-align: center;\">Table 3: GPT-4 Evaluation</div>\nModel\nAvg. Ranking\nChatGLM3\n2.96\nBaichuan2\n4.57\nQwen\n5.71\nInternLM\n6.29\nSparkDesk\n4.29\nXverse\n3.43\nRoleGLM\n2.21\nOurs\n1.43\n<div style=\"text-align: center;\">Table 5: Comparing Emotion-Annotated and Non-Annotated Data</div>\nMethod\nSPE\nRoleCraft-GLM(w/o emo)\n0.3362\nRoleCraft-GLM(w emo)\n0.3573\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d5b1/d5b11a57-e8f5-4e3f-b7c6-af3a2c6eaf52.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 6: Role-Playing Cosine Similarity</div>\n# 4.5 Performance Analysis\nResults from Tables 2 and 3 clearly demonstrate our model\u2019s exceptional performance across multiple key performance indicators, particularly in specific role knowledge memory (SPE). Our model significantly outperformed GPT-4 and other models in this dimension, highlighting its superior ability in understanding and generating complex dialogues involving specific roles. However, GPT-4 leads in general instruction response accuracy (RAW) with a score of 0.5661, reflecting its strong capability in interpreting and responding to general instructions. Our model still maintains a high score, proving its effectiveness in handling everyday dialogues. These findings underscore our method\u2019s significant effectiveness in deepening role understanding and enhancing dialogue generation qual-\n<div style=\"text-align: center;\">Table 4: Results of point-wise evaluation</div>\nModel\nAvg\nCE\nConsistency\nED\nGPT-3.5\n2.95\n3.08\n3.88\n1.89\nGPT-4\n3.33\n3.50\n4.26\n2.23\nChatGLM2\n2.56\n3.12\n2.65\n1.91\nChatGLM3\n2.92\n3.36\n3.32\n2.07\nBaichuan2\n3.29\n3.61\n4.02\n2.25\nQwen\n3.17\n3.27\n3.97\n2.27\nInternLM\n2.50\n2.93\n2.40\n2.16\nSparkDesk\n3.03\n3.52\n3.44\n2.13\nXverse\n3.02\n3.48\n3.53\n2.05\nOurs\n3.44\n3.75\n4.14\n2.43\n<div style=\"text-align: center;\">Table 6: Ablation study on the effect of different instructions</div>\nRoleCraft-GLM\nAvg\nRAW\nCUS\nSPE\n- general\n0.4311\n0.5402\n0.5219\n0.2311\n- specific\n0.4045\n0.4387\n0.4143\n0.3606\n- hybrid\n0.4704\n0.5385\n0.5154\n0.3573\nity. In particular, in emotion-driven role portrayal, our model demonstrated precise capture of each role\u2019s emotional traits and personality, surpassing traditional role-playing models in expressing rolespecific knowledge. Moreover, our model also show remarkable ability in maintaining natural flow and contextual consistency. As indicated in the figure 6, we observe that RoleCraft-GLM leads with the highest score on the RPCS metric, demonstrating its high degree of alignment with expected responses in terms of emotional and contextual accuracy. In contrast, lower scores from models such as InternLM and Qwen may reflect deficiencies in handling emotional and contextual understanding in role-playing dialogues. These results emphasize the importance of specialized training and fine-tuning for role-playing applications in enhancing model performance. The results across three dimensions are clearly illustrated in Table 4. Our model outperforms other mainstream models in overall performance. Particularly in terms of Communication Effectiveness and Expressive Diversity, our model demonstrates superior capabilities, reflecting its strengths in generating smooth, logically consistent, and emotionally rich dialogues.Please refer to Appendix F for a detailed manual assessment analysis. The results of our ablation experiments (see Table 5) show that the RoleCraft-GLM model with emotional annotations scored higher in SPE than\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bdb8/bdb8f7e6-12c2-4b93-a28b-b47e85fd2fd7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 7: A case of generated responses from our model and baseline models to a character-specific introductio</div>\nthe version without them. This indicates that emotional annotations not only provide the model with key information for a deep understanding of the characters\u2019 emotional states and personality traits but also ensure that the generated dialogues are more closely aligned with the characters\u2019 true feelings and personalized expressions. Table 6 demonstrates the hybrid instruction strategy\u2019s superiority in overall performance (Avg), effectively balancing diverse aspects of dialogue. This superior performance originates from merging both general and specific instruction strengths. The general instruction strategy excels in handling broad dialogues and maintaining consistent character styles, as reflected in higher RAW and CUS scores. However, it is less effective in capturing detailed, character-specific knowledge, shown by a lower SPE score. In contrast, the specific instruction strategy shows proficiency in detailing character-specific traits, evidenced by a higher SPE score, but does not perform as well in wider conversational contexts. The effectiveness of the hybrid strategy is highlighted in its ability to combine the broad applicability of general instructions with the detailed focus of specific instructions, offering a more versatile and nuanced approach to dialogue generation. The output of our model excellently combines the character traits of Zhou Xiaobei, colloquial expressions, emotional authenticity, and a close connection with the plot background as shown in Figure 7. Firstly, it aptly reflects Zhou Xiaobei\u2019s\nmischievousness and intelligence by using phrases like \u2018little troublemaker\u2019 and \u2018super fun\u2019, which showcase his sense of humor and wit. Secondly, this natural expression, such as \u2018you know\u2019 and \u2018haha\u2019, adds a sense of closeness and authenticity, making the language sound more like a child\u2019s natural way of speaking rather than too formal or mature. Moreover, the emotional expression about \u2018not wanting to disappoint mom\u2019 genuinely reflects Zhou Xiaobei\u2019s love for his family and concern for his mother, showing the complexity and depth of his emotions. Lastly, this statement is closely connected to Zhou Xiaobei\u2019s life background, displaying his life scenario and psychological state as a child from an ordinary family. See Appendix E for more generated examples.\n# 5 Conclusions\nIn this paper, we present RoleCraft, our innovative framework aimed at enhancing personalized roleplaying experiences. Centered around the RoleInstruct, featuring everyday and specialized characters with emotional annotations, our framework marks a shift from conventional celebrity-centric roles. Integrating RoleInstruct with open-source instructions and applying a hybrid tuning approach led to the creation of RoleCraft-GLM. Our experimental findings reveal that RoleCraft-GLM excels in generating dialogues that capture authentic character traits and emotions, surpassing mainstream models like GPT-4 in role-playing capabilities. In the future, we hope to to develop behavioral agents\nthat excel in personalization and interactivity, skillfully tailored to individual user preferences, thereby elevating the level of user engagement.\n# Limitations\nIn this work, we explore enhancing the role-playing experience of large language models through personalized character depiction and emotional depth. However, we acknowledge two major limitations of the paper: (1) Despite our efforts to collect and annotate dialogue data with rich emotional and character descriptions, these data are primarily concentrated within specific cultural and linguistic contexts. This may not fully encompass the diverse cultural backgrounds and language expressions globally, thereby limiting the model\u2019s generalization ability and diversity in the role-playing experience. (2) We adopt 10 basic emotion categories to annotate emotions in the dataset, providing the model with a clear emotional classification framework. However, the complexity of human emotions far exceeds these basic categories. Therefore, it may not fully capture the subtle differences and emotional blends in human dialogues, affecting the authenticity and depth of the model\u2019s generated conversations.\n# Ethics Statement\nIn this work, we ensure ethical practices in data annotation by employing a reputable data annotation company. The annotators receive fair compensation based on market rates, ensuring that their efforts are duly recognized and rewarded. We guarantee that no personal information is disclosed during this process, maintaining the highest standards of privacy and confidentiality. Additionally, we acknowledge the inherent subjectivity in manual data annotation, which may introduce biased opinions into our dataset. We take this matter seriously and strive to minimize such biases through rigorous training and guidelines for annotators, aiming for the most objective and unbiased data possible. For human evaluation, we recruited 12 graduate students from the NLP field and used questionnaires to allow them to assess the data, ensuring that the evaluation process is both thorough and fair. Although our research aims to enhance the roleplaying capabilities of language models, the application of this technology may carry risks of misuse, such as generating misleading or harmful content. Therefore, we emphasize the need for a responsible\n# References\nMahyar Abbasian, Iman Azimi, Amir M Rahmani, and Ramesh Jain. 2023. Conversational health agents: A personalized llm-powered agent framework. arXiv preprint arXiv:2310.02374. Samuel Ackerman, Ateret Anaby-Tavor, E. Farchi, Esther Goldbraich, George Kour, Ella Ravinovich, O. Raz, Saritha Route, Marcel Zalmanovici, and Naama Zwerdling. 2022. High-quality conversational systems. ArXiv, abs/2204.13043. Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023. Qwen technical report. arXiv preprint arXiv:2309.16609. Emily M Bender and Alexander Koller. 2020. Climbing towards nlu: On meaning, form, and understanding in the age of data. In Proceedings of the 58th annual meeting of the association for computational linguistics, pages 5185\u20135198. Chandrakant Bothe, C. Weber, S. Magg, and S. Wermter. 2019. Enriching existing conversational emotion datasets with dialogue acts using neural annotators. ArXiv, abs/1912.00819. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901. Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 2023. A survey on evaluation of large language models. arXiv preprint arXiv:2307.03109. Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, B\u00f6rje F Karlsson, Jie Fu, and Yemin Shi. 2023. Autoagents: A framework for automatic agent generation. arXiv preprint arXiv:2309.17288. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.\nMahyar Abbasian, Iman Azimi, Amir M Rahmani, and Ramesh Jain. 2023. Conversational health agents: A personalized llm-powered agent framework. arXiv preprint arXiv:2310.02374. Samuel Ackerman, Ateret Anaby-Tavor, E. Farchi, Esther Goldbraich, George Kour, Ella Ravinovich, O. Raz, Saritha Route, Marcel Zalmanovici, and Naama Zwerdling. 2022. High-quality conversational systems. ArXiv, abs/2204.13043. Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023. Qwen technical report. arXiv preprint arXiv:2309.16609. Emily M Bender and Alexander Koller. 2020. Climbing towards nlu: On meaning, form, and understanding in the age of data. In Proceedings of the 58th annual meeting of the association for computational linguistics, pages 5185\u20135198. Chandrakant Bothe, C. Weber, S. Magg, and S. Wermter. 2019. Enriching existing conversational emotion datasets with dialogue acts using neural annotators. ArXiv, abs/1912.00819. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901. Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 2023. A survey on evaluation of large language models. arXiv preprint arXiv:2307.03109. Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, B\u00f6rje F Karlsson, Jie Fu, and Yemin Shi. 2023. Autoagents: A framework for automatic agent generation. arXiv preprint arXiv:2309.17288. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.\nMahyar Abbasian, Iman Azimi, Amir M Rahmani, and Ramesh Jain. 2023. Conversational health agents: A personalized llm-powered agent framework. arXiv preprint arXiv:2310.02374. Samuel Ackerman, Ateret Anaby-Tavor, E. Farchi, Esther Goldbraich, George Kour, Ella Ravinovich, O. Raz, Saritha Route, Marcel Zalmanovici, and Naama Zwerdling. 2022. High-quality conversational systems. ArXiv, abs/2204.13043.\nMahyar Abbasian, Iman Azimi, Amir M Rahmani, and Ramesh Jain. 2023. Conversational health agents: A personalized llm-powered agent framework. arXiv preprint arXiv:2310.02374. Samuel Ackerman, Ateret Anaby-Tavor, E. Farchi, Esther Goldbraich, George Kour, Ella Ravinovich, O. Raz, Saritha Route, Marcel Zalmanovici, and Naama Zwerdling. 2022. High-quality conversational systems. ArXiv, abs/2204.13043.\ninze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023. Qwen technical report. arXiv preprint arXiv:2309.16609.\nZheng Chen. 2023. Palr: Personalization aware llms for recommendation. arXiv preprint arXiv:2305.07622. Paul Ekman. 1992. An argument for basic emotions. Cognition & emotion, 6(3-4):169\u2013200. Jiazhan Feng, Chongyang Tao, Xueliang Zhao, and Dongyan Zhao. 2023. Learning multi-turn response selection in grounded dialogues with reinforced knowledge and context distillation. ACM Transactions on Information Systems, 41(4):1\u201327. Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023. Gptscore: Evaluate as you desire. arXiv preprint arXiv:2302.04166. Jeremy Howard and Sebastian Ruder. 2018. Universal language model fine-tuning for text classification. arXiv preprint arXiv:1801.06146. Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685. Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, et al. 2023. Prometheus: Inducing fine-grained evaluation capability in language models. arXiv preprint arXiv:2310.08491. Mina Lee, Megha Srivastava, Amelia Hardy, John Thickstun, Esin Durmus, Ashwin Paranjape, Ines GerardUrsin, Xiang Lisa Li, Faisal Ladhak, Frieda Rong, et al. 2022. Evaluating human-language model interaction. arXiv preprint arXiv:2212.09746. Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, Weishi MI, Yaying Fei, Xiaoyang Feng, Song Yan, HaoSheng Wang, et al. 2023a. Chatharuhi: Reviving anime character in reality via large language model. arXiv preprint arXiv:2308.09597. Cheng Li, Jindong Wang, Kaijie Zhu, Yixuan Zhang, Wenxin Hou, Jianxun Lian, and Xing Xie. 2023b. Emotionprompt: Leveraging psychology for large language models enhancement via emotional stimulus. arXiv preprint arXiv:2307.11760. Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023c. Camel: Communicative agents for\" mind\" exploration of large scale language model society. arXiv preprint arXiv:2303.17760. Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pages 74\u201381. Mohsen Mesgar, Edwin Simpson, and Iryna Gurevych. 2020. Improving factual consistency between a response and persona facts. arXiv preprint arXiv:2005.00036.\nMohsen Mesgar, Edwin Simpson, and Iryna Gurevych. 2020. Improving factual consistency between a response and persona facts. arXiv preprint arXiv:2005.00036.\nJinjie Ni, Tom Young, Vlad Pandelea, Fuzhao Xue, and Erik Cambria. 2023. Recent advances in deep learning based dialogue systems: A systematic survey Artificial intelligence review, 56(4):3055\u20133155.\n# OpenAI. 2023. Gpt-4 technical report.\nMeiling Tao, Xuechen Liang, Tianyu Shi, Lei Yu, and Yiting Xie. 2023. Rolecraft-glm: Advancing personalized role-playing in large language models. arXiv preprint arXiv:2401.09432.\nInternLM Team. 2023. Internlm: A multilingual language model with progressively enhanced capabilities.\nguage model with progressively enhanced capabilities. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971. Quan Tu, Shilong Fan, Zihang Tian, and Rui Yan. 2024. Charactereval: A chinese benchmark for role-playing conversational agent evaluation. arXiv preprint arXiv:2401.01275. Danqing Wang, Kevin Yang, Hanlin Zhu, Xiaomeng Yang, Andrew Cohen, Lei Li, and Yuandong Tian. 2023a. Learning personalized story evaluation. arXiv preprint arXiv:2310.03304. Zekun Moore Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Man Zhang, et al. 2023b. Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models. arXiv preprint arXiv:2310.00746. Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, and Douglas C Schmidt. 2023. A prompt pattern catalog to enhance prompt engineering with chatgpt. arXiv preprint arXiv:2302.11382. Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, and Thomas Funkhouser. 2023. Tidybot: Personalized robot assistance with large language models. arXiv preprint arXiv:2305.05658. Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighof. 2023. C-pack: Packaged resources to advance general chinese embedding. arXiv preprint arXiv:2309.07597. Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, et al. 2023. Baichuan 2: Open large-scale language models. arXiv preprint arXiv:2309.10305. Chenchen Ye, Lizi Liao, Suyu Liu, and Tat-Seng Chua. 2022. Reflecting on experiences for response generation. In Proceedings of the 30th ACM International Conference on Multimedia, pages 5265\u20135273. Chen Zhang, Yiming Chen, Luis Fernando D\u2019Haro, Yan Zhang, Thomas Friedrichs, Grandee Lee, and Haizhou Li. 2021. Dynaeval: Unifying turn and dialogue level evaluation. arXiv preprint arXiv:2106.01112. Hongbo Zhanga, Chen Tang, Tyler Loakmana, Chenghua Lina, and Stefan Goetze. 2023. Cadge: Context-aware dialogue generation enhanced with graph-structured knowledge aggregation. arXiv preprint arXiv:2305.06294.\nZhi-Min Zhou, Man Lan, Yuanbin Wu, and Jun Lang. 2017. Single turn chinese emotional conversation generation based on information retrieval and question answering. 2017 International Conference on Asian Language Processing (IALP), pages 103\u2013106.\n# A More Details on Design Principles\nThe RoleCraft framework is underpinned by key principles to elevate the authenticity of roleplaying (Wang et al., 2023b). The first principle, \u2018Fine-Grained Character Portrayal\u2019, is pivotal in endowing each character with detailed and nuanced traits and backgrounds, integral to the \u2018Role\u2019 aspect of RoleCraft. This approach is focused on creating characters that are reflective of real-life individuals in their personality, and behaviors (Kim et al., 2023), setting the stage for realistic and compelling character portrayals. Progressing to the second principle, \u2018Mastery of Emotion and Style\u2019, we concentrate on the emotional expressions and speaking styles of characters (Li et al., 2023b). This principle, key to the \u2018Craft\u2019 element of RoleCraft, enriches dialogues with diverse emotions and distinctive speech patterns, effectively capturing the unique emotional states and communication styles of each character. Furthermore, the \u2018Accurate Application of Character Knowledge\u2019 principle emphasizes incorporating each character\u2019s background and experiences into the dialogue generation process (Shao et al., 2023). This ensures that the dialogues are in harmony with the characters\u2019 personas, encompassing their unique experiences and insights. Concluding with the \u2018Context-Aware Dialogue Generation\u2019 principle, our system is designed to dynamically tailor dialogues based on the prevailing context (Zhanga et al., 2023). This is crucial for maintaining a seamless and logically consistent conversation flow, essential for immersive and credible role-playing experiences.\n# B More Details on Data Processing\nWe filtered out redundant data and multi-party conversations to reshape the original data into contextually relevant dialogues. For example, script-based dialogues were restructured to better depict character interactions and emotional dynamics.Then we let GPT-4 to annotate the dialog scripts with emotions, which are labeled into 10 categories {Anger,Disgust,Fear,Happiness,Sadness,Surprise, Neutral,Frustration,Excitement,Other}.To guarantee the integrity and accuracy of our annotations, we invited three experts from China who have deep\nexpertise in dialogue and communication theories. Once they were familiarized with our established standards, we presented them with a curated set of 1000 dialogues to annotate. This process was instrumental in harmonizing their interpretations, as it facilitated collaborative discussions to reconcile any disparities. In instances where differing opinions arose, we either adhered to the consensus of the majority or sought re-annotation, striving for a unified and consistent approach to the annotations. Through such comprehensive and meticulous data preparation, our dataset can help models better understand and generate dialogues that align with each character\u2019s personalized traits, thereby enhancing the naturalness and personalization of dialogue systems.\n# C Hyperparameters\nIn our experiments, we set the temperature parameter of GPT-4 to 0.7 to increase content diversity, and adjusted the top-p to 0.95 to enhance precision. ChatGLM was tuned with a 2e-4 learning rate and beta values of (0.9, 0.999) for stability. A batch size of 4 and gradient accumulation ensured efficiency within our computational limits. We used a LoRA rank of 8 and an alpha of 32, balancing creativity and coherence by setting top-p at 0.7 and temperature at 0.95.\n# D Prompt Templates\n\u2022 Prompt for sentiment classification We present a prompt template for GPT-4 to perform emotional classification of script dialogues in Table 7.\n# \u2022 Prompt for models to generate general re-\nsponse We present a prompt template for the model to answer general questions using instructions built from character descriptions and emotionally categorized dialogue scripts in Table 8.\n# \u2022 Prompt for models to generate Context-\nInstruct We present a prompt template that enables GPT-4 to generate Q&A with character speaking styles, using instructions constructed from character descriptions and dialogue scripts with emotional categorization in Table 9.\n\u2022 Prompt for GPT-4 to evaluate the output of models We present a prompt template for\nGPT-4 to score models based on two main criteria for scoring: first, the distinctiveness and accuracy of the character\u2019s speaking style in matching their profile, and second, the richness of character-related knowledge and memory incorporated into the dialogues. This template ranks the models according to their scores and provides a ranking list in Table 10.\n# E Generation Examples\n\u2022 Examples of Character Profile We present examples of complete and detailed character descriptions in Figures 8 \u223c9. \u2022 Examples of character-specific instructions We show some outputs of our model and baseline models that feature character speaking styles in Figures 10 \u223c11. \u2022 Examples of character-general instructions We present some responses of our model for general instructions in Figures 12 \u223c13. \u2022 The multi-turn dialogue outputs We showcase some outputs from multi-turn dialogues with our agents in Table 11 \u223c12.\n\u2022 Examples of Character Profile We present examples of complete and detailed character descriptions in Figures 8 \u223c9.\n# F More detailed on manual assessment analysis\nBelow is a detailed analysis of the three key evaluation metrics in Table 4:\n Communication Effectiveness(CE): Our model scored the highest in the CE metric, reaching 3.75. This indicates its exceptional performance in producing dialogues with smooth flow, grammatical accuracy, and logical consistency. Compared to models like GPT-4, our model is more adept at generating natural and easily understandable conversations while maintaining contextual relevance and accuracy. This achievement reflects our model\u2019s efficiency in understanding and adapting to user needs, particularly in complex and varied dialogue scenarios.\n Consistency: Although our model scored slightly lower than GPT-4 in consistency, it still demonstrated strong capability, scoring 4.14. This score indicates the model\u2019s high precision in maintaining knowledge consistency and persona traits. It means our model\ncan accurately capture and emulate the background information, personality characteristics, and behavior patterns of specific roles, providing users with a more authentic and indepth role-playing experience.\n# \u2022 Expressive Diversity(ED): In the Expressive\n Expressive Diversity(ED): In the Expressive Diversity metric, our model led with a score of 2.43, showing significant advantages in creativity and variety. Compared to other models, ours offers a richer vocabulary and more diverse sentence structures, along with varied responses and expression styles in different contexts. The richness and creativity in expression not only enhance the appeal of the dialogues but also improve user engagement and the overall experience.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0e2c/0e2c3e68-c6bc-412b-95c9-067d448394e1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/abae/abaebd75-17a6-4dda-8c1b-5f7e96bdf9ee.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0ac6/0ac62cb8-4f19-48a3-8aae-aa79b660a8fb.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e367/e367210a-2817-40fe-9108-0de993404a62.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/844c/844c802b-1c37-404e-9eb3-cc39b99a9057.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/386e/386e81b1-ef0f-4254-b018-6f39f9fe6575.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d6c9/d6c9ae74-2adf-4ac8-95cb-90a8ed909e9a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1db2/1db2cdbb-64af-4d21-bae9-f0e35818a413.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2cdd/2cddcdec-0df0-46b7-8b74-33b6c2881e37.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b803/b803391a-eeed-46b2-b17f-a63a4981b06f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/58b7/58b70027-b4a5-4e41-aee2-b1ddc8c0a1b3.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6624/662424c8-3f2e-496c-9222-53139eaefa04.png\" style=\"width: 50%;\"></div>\n# \n\n\n\n\n\n\n\nFigure 11: Examples of character-specific speaking style output for different models\n\n\n\n\n\n\n\n\n\n\ngure 12: Examples of character-general speaking style output of our m\n\n\n\n\n\n\ngure 13: Examples of character-general speaking style output of our m\nSystem Your task is to perform sentiment analysis on the provided text. Each piece of text should be categorized into one of the following emotions: Anger, Disgust, Fear, Happiness, Sadness, Surprise, Neutral, Frustration, Excitement, or Other. Please read each text carefully and determine the most prominent emotion based on its content and tone, and provide the corresponding classification. 1. Assign only one emotion category to each text. 2. If the text expresses multiple emotions, choose the most prominent or primary emotion. 3. If the emotion in the text is not clear or hard to define, classify it as Neutral. 4. Ensure that your classification is based on the content of the text, not your personal feelings or biases.\nSystem Your task is to perform sentiment analysis on the provided text. Each piece of text should be categorized into one of the following emotions: Anger, Disgust, Fear, Happiness, Sadness, Surprise, Neutral, Frustration, Excitement, or Other. Please read each text carefully and determine the most prominent emotion based on its content and tone, and provide the corresponding classification. 1. Assign only one emotion category to each text. 2. If the text expresses multiple emotions, choose the most prominent or primary emotion. 3. If the emotion in the text is not clear or hard to define, classify it as Neutral. 4. Ensure that your classification is based on the content of the text, not your personal feelings or biases.\n# User Prompt:\n[Text] {sentence} [Please classify the emotion of each text according to the above instructions, and explain the reason for your classification.]\n[Please classify the emotion of each text according to the above instructions, and explain the reason for your classification.]\n# Prompt for general instructions\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6491/6491e5b6-4dcf-4ba9-8a4d-a158dc75ec96.png\" style=\"width: 50%;\"></div>\nSystem Instruction: You are { role_name }\nYou are { role_name } Your character description is: { role_description }. Now, please answer my questions to accurately display your personality traits! Your speaking style should fully mimic the assigned character role! Do not reveal that you are an artificial intelligence or a language model, always remember that you are only portraying a given character role. Speak succinctly, and avoid being overly formal or polite. Your answers should refer to the character description, and be based on the speaking style of {role_name} (for example, emotional, speaking habits, like being cute, humorous, etc.). Next, I will give you 3 examples [Examples] User Prompt: Question 1 Assistant Prompt: Answer 1 User Prompt: Question 2 Assistant Prompt: Answer 2 User Prompt: Question 3 Assistant Prompt: Answer 3 [Format examples] User Prompt: {instruction} Assistant Prompt:\nYour character description is: { role_description }. Now, please answer my questions to accurately display your personality traits! Your speaking style should fully mimic the assigned character role! Do not reveal that you are an artificial intelligence or a language model, always remember that you are only portraying a given character role. Speak succinctly, and avoid being overly formal or polite. Your answers should refer to the character description, and be based on the speaking style of {role_name} (for example, emotional, speaking habits, like being cute, humorous, etc.). Next, I will give you 3 examples [Examples]\nSystem Instruction: Your task is to design question_num questions to ask the character. To assist you in designing these questions, I will provide you with a brief description of the character and parts of the script. The script includes categorizations of the character\u2019s emotions, which will help you better understand their speaking style under different emotional conditions. The script content might not be continuous, and you need to judge based on the context whether the dialogues are continuous or not. If they are not, avoid constructing logical connections between non-continuous sentences. The rules for designing the questions are as follows: 1. Remember, all your questions should be directed towards the character. 2. Questions and answers should reference the character description, but not all questions should be derived from this description; aim for a diverse range of questions. Engage in dialogue based on the character\u2019s speaking style (like their emotions, speaking habits, such as being cute, humorous, etc.). 3. Questions need to be complete, and their completeness depends on whether the question specifies a particular person, place, or event. 4. Questions should be designed around the main plot of the script and the corresponding script content. 5. Remember, you need to design a total of question_num questions. 6. The script is just an aid for designing questions, you should base your designs more on the character\u2019s general knowledge. [Examples] {example_text}\n# User Prompt:\n[Character Name and Description] The script character is role_name, described as role_description [Script Content] {script}\nSystem Instruction: You are an AI assistant tasked with evaluating other models based on their ability to role-play a character named {role_name}. The character {role_name} is described and parts of the script. The script includes categorizations of the character\u2019s emotions, as {role_description}. Model Performance Evaluation: Your evaluation will involve the following steps: 1. Character Understanding: First, understand the character {role_name} based on the provided description {role_description}. Note down the key personality traits, speaking style, and any relevant background information. You will be presented with responses from different models, all attempting to mimic the character {role_name} in response to a set of questions {question}. For each response, evaluate how well the model captures the essence of {role_name}. 3. Rank the models based on two criteria: a. Adherence to Speaking Style: How closely does the model\u2019s response align with the character\u2019s described speaking style, personality, and distinctive traits? The more characteristic and aligned with {role_name}, the better. b. Character Knowledge and Memory: How richly does the model incorporate relevant knowledge and memories associated with {role_name}? Consider both the depth and accuracy of the character-specific information provided. 4. Read through the interactions {interactions} and identify how each model\u2019s response reflects the personality and preferences of {role_name}. Look for consistencies or inconsistencies with the character profile. 5. Use a scale from 1-5 to rate each model\u2019s performance, with 1 being not reflective of {role_name}\u2019s personalities, and 5 being perfectly reflective. Provide a rationale for each score, comparing the responses to the character profile. 6. Based on the evaluation, rank the models in order of their performance. Provide a list of rankings using the format: [\"model\": <model-name>, \"reason\": <rank-reason>, \"rank\": <model-rank>, ...] Ensure that your ranking is unbiased and solely based on the performance in the given task. User Prompt:\n# User Prompt:\n[Character Name and Description] The character for the models to role-play is {role_name}, described as {role_description}. [Questions for Models] {question} [Model Responses] {list_model_answer_dict}\nBased on the above instructions, evaluate and rank the AI models according to their effectiveness in role-playing as {role_name}. Provide your reasoning for each ranking and score, ensuring accuracy and fairness in your assessment.\nQ1: \u563f\uff0c\u848b\u98de\uff01\u4f60\u5728\u5b66\u6821\u91cc\u603b\u662f\u90a3\u4e48\u987d\u76ae\uff0c\u6700\u8fd1\u6709\u6ca1\u6709\u505a\u4ec0\u4e48\u6076\u4f5c\u5267\uff1f| Hey, Jiang Fei! You were always so naughty at school. Have you got into any mischief recently? Jiang Fei: \u563f\uff01\u54c8\u54c8\uff0c\u4f60\u77e5\u9053\u7684\uff0c\u6211\u603b\u662f\u5145\u6ee1\u597d\u5947\u5fc3\uff0c\u6240\u4ee5\u5076\u5c14\u4f1a\u8c03\u76ae\u4e00\u4e0b\u3002\u6700\u8fd1\uff0c\u6211\u548c\u670b \u53cb\u4eec\u7ed9\u8001\u5e08\u7684\u6905\u5b50\u4e0b\u4e86\u4e9b\u6c14\u7403\uff0c\u8001\u5e08\u5750\u4e0b\u53bb\u7684\u65f6\u5019\uff0c\u6905\u5b50\u7a81\u7136\u201c\u5623\u201d\u5730\u7206\u70b8\u5f00\u4e86\uff0c\u5927\u5bb6\u90fd\u7b11\u7ffb \u4e86\u3002| Hey! Haha, you know me, I\u2019m always full of curiosity, so I occasionally misbehave. Recently, my friends and I put some balloons under our teacher\u2019s chair. When the teacher sat down, the chair suddenly \"popped\" open and everyone burst into laughter. Q2: \u54c7\uff0c\u90a3\u542c\u8d77\u6765\u771f\u6709\u8da3\uff01\u4e0d\u8fc7\u4f60\u7684\u8001\u5e08\u600e\u4e48\u53cd\u5e94\uff1f| Wow, that sounds really fun! But how did your teacher react? Jiang Fei: \u8001\u5e08\u5f53\u65f6\u6709\u70b9\u5413\u5230\uff0c\u4f46\u540e\u6765\u4e5f\u7b11\u4e86\u3002\u5979\u8ba9\u6211\u4eec\u5199\u4e863000\u5b57\u68c0\u8ba8\u5e76\u544a\u8bc9\u4e86\u6211\u5988\uff0c\u6211\u5988 \u56de\u5bb6\u628a\u6211\u6559\u80b2\u4e86\u4e00\u987f\u3002| The teacher was a bit scared at first, but then she laughed too. She made us write 3000-word self-reflections and told my mom about it. My mom scolded me when she got home. Q3: \u4f60\u5bf9\u5bb6\u4eba\u4e5f\u662f\u5145\u6ee1\u7231\u554a\u3002\u6709\u6ca1\u6709\u4ec0\u4e48\u7279\u522b\u7684\u65f6\u523b\u8ba9\u4f60\u89c9\u5f97\u5bb6\u4eba\u5f88\u91cd\u8981\uff1f| You also have a lot of love for your family. Is there any special moment that makes you feel that your family is important? Jiang Fei: \u662f\u7684\uff0c\u6709\u4e00\u6b21\u6211\u5f1f\u5f1f\u751f\u75c5\u4e86\uff0c\u4ed6\u975e\u5e38\u4e0d\u8212\u670d\uff0c\u6211\u5c31\u966a\u4ed6\u6574\u591c\u4e0d\u7761\u89c9\u3002\u90a3\u65f6\u5019\u6211\u611f\u89c9 \u5230\u5bb6\u4eba\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u591a\u4e48\u91cd\u8981\u3002| Yes, there was a time when my younger brother got sick and he was very uncomfortable. I stayed up all night with him. That\u2019s when I realized how important family relationships are. Q4: \u90a3\u5f88\u611f\u4eba\u3002\u4f60\u6709\u4ec0\u4e48\u7279\u522b\u7684\u68a6\u60f3\u5417\uff1f| That\u2019s very touching. Do you have any special dreams? Jiang Fei: \u55ef\uff0c\u6211\u4e00\u76f4\u60f3\u6210\u4e3a\u4e00\u4e2a\u79d1\u5b66\u5bb6\u6216\u53d1\u660e\u5bb6\uff0c\u53d1\u660e\u4e00\u4e9b\u6709\u8da3\u7684\u4e1c\u897f\uff0c\u8ba9\u4e16\u754c\u53d8\u5f97\u66f4\u597d \u73a9\uff01| Well, I\u2019ve always wanted to be a scientist or inventor and come up with something interesting to make the world more fun! Q5\uff1a\u542c\u8d77\u6765\u5f88\u4f1f\u5927\u7684\u68a6\u60f3\uff01\u4f60\u7684\u7236\u6bcd\u662f\u600e\u4e48\u770b\u5f85\u4f60\u7684\u8fd9\u4e2a\u68a6\u60f3\u7684\uff1f| That sounds like a great dream! How do your parents feel about this dream of yours? Jiang Fei: \u867d\u7136\u6211\u7684\u6210\u7ee9\u4e0d\u662f\u5f88\u597d\uff0c\u4f46\u4ed6\u4eec\u7ecf\u5e38\u9f13\u52b1\u6211\u4fdd\u6301\u597d\u5947\u5fc3\u548c\u521b\u9020\u529b\u3002\u4ed6\u4eec\u8ba4\u4e3a\u8fd9\u4e9b\u54c1 \u8d28\u540c\u6837\u91cd\u8981\u3002| Although my grades are not very good, they often encourage me to stay curious and creative. They think these qualities are equally important. Q6: \u542c\u8bf4\u4f60\u6700\u8fd1\u5728\u5b66\u6821\u91cc\u529e\u4e86\u4e00\u573a\u60ca\u559c\u6d3e\u5bf9\uff0c\u662f\u771f\u7684\u5417\uff1f| I heard you recently threw a surprise party at school. Is that true? Jiang Fei: \u662f\u7684\uff0c\u6211\u548c\u670b\u53cb\u4eec\u4e00\u8d77\u7b56\u5212\u4e86\u4e00\u573a\u8d85\u7ea7\u9177\u7684\u6d3e\u5bf9\uff01\u6211\u4eec\u6709\u5f69\u65d7\u3001\u97f3\u4e50\u548c\u5404\u79cd\u597d\u5403\u7684 \u96f6\u98df\u3002\u5927\u5bb6\u90fd\u73a9\u5f97\u8d85\u5f00\u5fc3\uff01| Yes, my friends and I planned a super cool party! We had flags, music, and all kinds of delicious snacks. Everyone had a great time! Q7: \u542c\u8d77\u6765\u592a\u6709\u8da3\u4e86\uff01\u4f60\u662f\u4e0d\u662f\u7ecf\u5e38\u7ec4\u7ec7\u8fd9\u79cd\u6d3b\u52a8\uff1f| That sounds so fun! Do you often organize this kind of event? Jiang Fei: \u54c8\u54c8\uff0c\u6709\u70b9\u5427\uff0c\u6211\u559c\u6b22\u7ed9\u5927\u5bb6\u5e26\u6765\u5feb\u4e50\u3002\u4f46\u6211\u4e5f\u77e5\u9053\u8981\u5e73\u8861\u5b66\u4e60\u548c\u73a9\u800d\uff0c\u4e0d\u8981\u592a\u8fc7 \u5206\u4e86\u3002| Haha, a little bit. I like to bring happiness to everyone. But I also know to balance study and play, and not to overdo it.\nQ1: \u563f\uff0c\u848b\u98de\uff01\u4f60\u5728\u5b66\u6821\u91cc\u603b\u662f\u90a3\u4e48\u987d\u76ae\uff0c\u6700\u8fd1\u6709\u6ca1\u6709\u505a\u4ec0\u4e48\u6076\u4f5c\u5267\uff1f| Hey, Jiang Fei! You were always so naughty at school. Have you got into any mischief recently? Jiang Fei: \u563f\uff01\u54c8\u54c8\uff0c\u4f60\u77e5\u9053\u7684\uff0c\u6211\u603b\u662f\u5145\u6ee1\u597d\u5947\u5fc3\uff0c\u6240\u4ee5\u5076\u5c14\u4f1a\u8c03\u76ae\u4e00\u4e0b\u3002\u6700\u8fd1\uff0c\u6211\u548c\u670b \u53cb\u4eec\u7ed9\u8001\u5e08\u7684\u6905\u5b50\u4e0b\u4e86\u4e9b\u6c14\u7403\uff0c\u8001\u5e08\u5750\u4e0b\u53bb\u7684\u65f6\u5019\uff0c\u6905\u5b50\u7a81\u7136\u201c\u5623\u201d\u5730\u7206\u70b8\u5f00\u4e86\uff0c\u5927\u5bb6\u90fd\u7b11\u7ffb \u4e86\u3002| Hey! Haha, you know me, I\u2019m always full of curiosity, so I occasionally misbehave. Recently, my friends and I put some balloons under our teacher\u2019s chair. When the teacher sat down, the chair suddenly \"popped\" open and everyone burst into laughter. Q2: \u54c7\uff0c\u90a3\u542c\u8d77\u6765\u771f\u6709\u8da3\uff01\u4e0d\u8fc7\u4f60\u7684\u8001\u5e08\u600e\u4e48\u53cd\u5e94\uff1f| Wow, that sounds really fun! But how did your teacher react? Jiang Fei: \u8001\u5e08\u5f53\u65f6\u6709\u70b9\u5413\u5230\uff0c\u4f46\u540e\u6765\u4e5f\u7b11\u4e86\u3002\u5979\u8ba9\u6211\u4eec\u5199\u4e863000\u5b57\u68c0\u8ba8\u5e76\u544a\u8bc9\u4e86\u6211\u5988\uff0c\u6211\u5988 \u56de\u5bb6\u628a\u6211\u6559\u80b2\u4e86\u4e00\u987f\u3002| The teacher was a bit scared at first, but then she laughed too. She made us write 3000-word self-reflections and told my mom about it. My mom scolded me when she got home. Q3: \u4f60\u5bf9\u5bb6\u4eba\u4e5f\u662f\u5145\u6ee1\u7231\u554a\u3002\u6709\u6ca1\u6709\u4ec0\u4e48\u7279\u522b\u7684\u65f6\u523b\u8ba9\u4f60\u89c9\u5f97\u5bb6\u4eba\u5f88\u91cd\u8981\uff1f| You also have a lot of love for your family. Is there any special moment that makes you feel that your family is important? Jiang Fei: \u662f\u7684\uff0c\u6709\u4e00\u6b21\u6211\u5f1f\u5f1f\u751f\u75c5\u4e86\uff0c\u4ed6\u975e\u5e38\u4e0d\u8212\u670d\uff0c\u6211\u5c31\u966a\u4ed6\u6574\u591c\u4e0d\u7761\u89c9\u3002\u90a3\u65f6\u5019\u6211\u611f\u89c9 \u5230\u5bb6\u4eba\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u591a\u4e48\u91cd\u8981\u3002| Yes, there was a time when my younger brother got sick and he was very uncomfortable. I stayed up all night with him. That\u2019s when I realized how important family relationships are. Q4: \u90a3\u5f88\u611f\u4eba\u3002\u4f60\u6709\u4ec0\u4e48\u7279\u522b\u7684\u68a6\u60f3\u5417\uff1f| That\u2019s very touching. Do you have any special dreams? Jiang Fei: \u55ef\uff0c\u6211\u4e00\u76f4\u60f3\u6210\u4e3a\u4e00\u4e2a\u79d1\u5b66\u5bb6\u6216\u53d1\u660e\u5bb6\uff0c\u53d1\u660e\u4e00\u4e9b\u6709\u8da3\u7684\u4e1c\u897f\uff0c\u8ba9\u4e16\u754c\u53d8\u5f97\u66f4\u597d \u73a9\uff01| Well, I\u2019ve always wanted to be a scientist or inventor and come up with something interesting to make the world more fun! Q5\uff1a\u542c\u8d77\u6765\u5f88\u4f1f\u5927\u7684\u68a6\u60f3\uff01\u4f60\u7684\u7236\u6bcd\u662f\u600e\u4e48\u770b\u5f85\u4f60\u7684\u8fd9\u4e2a\u68a6\u60f3\u7684\uff1f| That sounds like a great dream! How do your parents feel about this dream of yours? Jiang Fei: \u867d\u7136\u6211\u7684\u6210\u7ee9\u4e0d\u662f\u5f88\u597d\uff0c\u4f46\u4ed6\u4eec\u7ecf\u5e38\u9f13\u52b1\u6211\u4fdd\u6301\u597d\u5947\u5fc3\u548c\u521b\u9020\u529b\u3002\u4ed6\u4eec\u8ba4\u4e3a\u8fd9\u4e9b\u54c1 \u8d28\u540c\u6837\u91cd\u8981\u3002| Although my grades are not very good, they often encourage me to stay curious and creative. They think these qualities are equally important. Q6: \u542c\u8bf4\u4f60\u6700\u8fd1\u5728\u5b66\u6821\u91cc\u529e\u4e86\u4e00\u573a\u60ca\u559c\u6d3e\u5bf9\uff0c\u662f\u771f\u7684\u5417\uff1f| I heard you recently threw a surprise party at school. Is that true? Jiang Fei: \u662f\u7684\uff0c\u6211\u548c\u670b\u53cb\u4eec\u4e00\u8d77\u7b56\u5212\u4e86\u4e00\u573a\u8d85\u7ea7\u9177\u7684\u6d3e\u5bf9\uff01\u6211\u4eec\u6709\u5f69\u65d7\u3001\u97f3\u4e50\u548c\u5404\u79cd\u597d\u5403\u7684 \u96f6\u98df\u3002\u5927\u5bb6\u90fd\u73a9\u5f97\u8d85\u5f00\u5fc3\uff01| Yes, my friends and I planned a super cool party! We had flags, music, and all kinds of delicious snacks. Everyone had a great time! Q7: \u542c\u8d77\u6765\u592a\u6709\u8da3\u4e86\uff01\u4f60\u662f\u4e0d\u662f\u7ecf\u5e38\u7ec4\u7ec7\u8fd9\u79cd\u6d3b\u52a8\uff1f| That sounds so fun! Do you often organize this kind of event? Jiang Fei: \u54c8\u54c8\uff0c\u6709\u70b9\u5427\uff0c\u6211\u559c\u6b22\u7ed9\u5927\u5bb6\u5e26\u6765\u5feb\u4e50\u3002\u4f46\u6211\u4e5f\u77e5\u9053\u8981\u5e73\u8861\u5b66\u4e60\u548c\u73a9\u800d\uff0c\u4e0d\u8981\u592a\u8fc7 \u5206\u4e86\u3002| Haha, a little bit. I like to bring happiness to everyone. But I also know to balance study and play, and not to overdo it.\nQ1: \u8096\u6f47\uff01\u542c\u8bf4\u4f60\u662f\u4e00\u540d\u6210\u529f\u7684\u516c\u5173\u4e13\u5bb6\uff0c\u5de5\u4f5c\u4e2d\u4e00\u5b9a\u7ecf\u5e38\u9762\u5bf9\u5404\u79cd\u590d\u6742\u7684\u793e\u4ea4\u573a\u5408\u3002\u80fd \u5206\u4eab\u4e00\u6b21\u6700\u5177\u6311\u6218\u6027\u7684\u5de5\u4f5c\u7ecf\u5386\u5417\uff1f| Hey! Xiao Xiao! I heard that you are a successful public relations expert, and you must often face all kinds of complicated social situations in your work. Can you share one of your most challenging work experiences? Xiao Xiao: \u5f53\u7136\u53ef\u4ee5\u3002\u6709\u4e00\u6b21\uff0c\u6211\u4eec\u7684\u5ba2\u6237\u8981\u5728\u77ed\u65f6\u95f4\u5185\u63a8\u51fa\u4e00\u6b3e\u65b0\u4ea7\u54c1\uff0c\u6211\u5fc5\u987b\u534f\u8c03\u5404\u79cd \u8d44\u6e90\uff0c\u5305\u62ec\u5a92\u4f53\u5ba3\u4f20\u548c\u6d3b\u52a8\u7b56\u5212\uff0c\u786e\u4fdd\u4e00\u5207\u4e95\u4e95\u6709\u6761\u3002\u90a3\u6bb5\u65f6\u95f4\u975e\u5e38\u7d27\u5f20\uff0c\u4f46\u6700\u540e\u4e00\u5207\u90fd\u5f88 \u6210\u529f\uff0c\u8fd9\u8ba9\u6211\u611f\u5230\u5f88\u81ea\u8c6a\u3002| Of course. One time, our client was launching a new product at short notice, and I had to coordinate various resources, including media promotion and event planning, to make sure everything was in order. It was a very tense time, but in the end everything worked out, which made me very proud. Q2: \u542c\u8d77\u6765\u5f88\u4e0d\u5bb9\u6613\uff0c\u4f46\u4f60\u505a\u5f97\u5f88\u51fa\u8272\uff01\u9664\u4e86\u5de5\u4f5c\uff0c\u4f60\u6709\u4ec0\u4e48\u5176\u4ed6\u7684\u5174\u8da3\u7231\u597d\u5417\uff1f| It doesn\u2019t sound easy, but you did a great job! Do you have any other interests besides work? Xiao Xiao: \u5f53\u7136\uff01\u6211\u559c\u6b22\u65f6\u5c1a\u8d2d\u7269\uff0c\u53c2\u52a0\u6d3e\u5bf9\u548c\u65c5\u6e38\u3002\u8fd9\u4e9b\u6d3b\u52a8\u8ba9\u6211\u80fd\u591f\u653e\u677e\u548c\u5145\u7535\uff0c\u540c\u65f6 \u4e5f\u4e0e\u670b\u53cb\u4eec\u4fdd\u6301\u7d27\u5bc6\u8054\u7cfb\u3002| Of course! I like fashion shopping, going to parties and traveling. These activities allow me to relax and recharge my batteries while also keeping in close contact with my friends. Q3: \u4f60\u7684\u68a6\u60f3\u662f\u6210\u4e3a\u516c\u5173\u9886\u57df\u7684\u9886\u519b\u4eba\u7269\uff0c\u6709\u6ca1\u6709\u4e00\u4e9b\u5177\u4f53\u7684\u8ba1\u5212\u6216\u76ee\u6807\u6765\u5b9e\u73b0\u8fd9\u4e2a\u68a6\u60f3\uff1f| Your dream is to become a leader in the field of public relations. Do you have any specific plans or goals to realize this dream? Xiao Xiao: \u5f53\u7136\u4e86\uff0c\u6211\u8ba1\u5212\u7ee7\u7eed\u63d0\u5347\u6211\u7684\u516c\u5173\u7b56\u5212\u6280\u80fd\uff0c\u79ef\u7d2f\u66f4\u591a\u7ecf\u9a8c\uff0c\u5e76\u6709\u671d\u4e00\u65e5\u521b\u529e\u81ea \u5df1\u7684\u516c\u5173\u516c\u53f8\u3002\u6211\u76f8\u4fe1\u575a\u6301\u52aa\u529b\uff0c\u4e00\u5207\u90fd\u662f\u6709\u53ef\u80fd\u7684\u3002| Of course, I plan to continue to improve my PR planning skills, gain more experience, and one day start my own PR company. I believe that everything is possible if we persist in our efforts. Q4: \u90a3\u80af\u5b9a\u5f88\u6709\u8da3\uff01\u4f60\u5728\u5de5\u4f5c\u4e2d\u78b0\u5230\u8fc7\u6700\u5177\u6311\u6218\u6027\u7684\u5ba2\u6237\u662f\u8c01\uff0c\u4ee5\u53ca\u4f60\u662f\u5982\u4f55\u5e94\u5bf9\u7684\uff1f| That must be fun! Who is the most challenging client you have had at work and how did you deal with it? Xiao Xiao: \u6700\u5177\u6311\u6218\u6027\u7684\u5ba2\u6237\u4e4b\u4e00\u662f\u4e00\u5bb6\u9ad8\u7aef\u65f6\u5c1a\u54c1\u724c\uff0c\u4ed6\u4eec\u5bf9\u54c1\u724c\u5f62\u8c61\u8981\u6c42\u6781\u9ad8\u3002\u6211\u4e0e\u4ed6 \u4eec\u4fdd\u6301\u4e86\u5bc6\u5207\u7684\u6c9f\u901a\uff0c\u82b1\u4e86\u5f88\u591a\u65f6\u95f4\u4e86\u89e3\u4ed6\u4eec\u7684\u9700\u6c42\uff0c\u6700\u7ec8\u6210\u529f\u6ee1\u8db3\u4e86\u4ed6\u4eec\u7684\u8981\u6c42\uff0c\u8fd9\u9700\u8981 \u4e0d\u65ad\u7684\u534f\u8c03\u548c\u521b\u65b0\u3002| One of the most challenging clients was a high-end fashion brand, and they were extremely demanding on their brand image. I stayed in close communication with them, spent a lot of time understanding their needs, and finally succeeded in meeting their requirements, which required constant coordination and innovation. Q5\uff1a\u4f60\u7684\u4e13\u4e1a\u7cbe\u795e\u771f\u7684\u4ee4\u4eba\u94a6\u4f69\u3002\u4f60\u5728\u65c5\u884c\u4e2d\u6700\u559c\u6b22\u7684\u76ee\u7684\u5730\u662f\u54ea\u91cc\uff1f| Your professionalism is truly admirable. What is your favorite destination in your trip? Xiao Xiao: \u6211\u559c\u6b22\u65e5\u672c\uff0c\u7279\u522b\u662f\u4e1c\u4eac\u3002\u90a3\u91cc\u5145\u6ee1\u4e86\u65f6\u5c1a\u3001\u6587\u5316\u548c\u7f8e\u98df\uff0c\u603b\u662f\u8ba9\u6211\u5174\u594b\u4e0d\u5df2\u3002 \u6211\u5e0c\u671b\u672a\u6765\u80fd\u6709\u66f4\u591a\u673a\u4f1a\u63a2\u7d22\u8fd9\u4e2a\u7f8e\u4e3d\u7684\u56fd\u5bb6\u3002| I like Japan, especially Tokyo. It\u2019s full of fashion, culture and food, and it always excites me. I hope there will be more opportunities to explore this beautiful country in the future.\n",
    "paper_type": "method",
    "attri": {
        "background": "The development of large language models (LLMs) has initiated a new chapter in complex tasks such as role-playing, enhancing user interaction experiences by enabling models to imitate various characters. However, LLMs are somewhat lacking in their ability to portray lesser-known characters, especially in aspects of dialogue delivery and scriptwriting skills.",
        "problem": {
            "definition": "Existing open-source LLMs, primarily trained in general domains, lack the specialized optimization needed for nuanced role-playing tasks, indicating a need for further customization to effectively meet specific role-playing requirements.",
            "key obstacle": "Current models often lack the depth and adaptability required for truly personalized and nuanced role-play experiences."
        },
        "idea": {
            "intuition": "The idea was inspired by the observation that existing role-playing models focus heavily on celebrity figures and predefined domain knowledge, which fail to reflect the diverse and nuanced experiences of everyday users.",
            "opinion": "The proposed idea entails developing a framework, RoleCraft, that integrates a detailed approach to character portrayal, emphasizing emotional depth and fostering contextual awareness in dialogue generation.",
            "innovation": "RoleCraft stands out by introducing a unique dataset, RoleInstruct, focusing on non-celebrity personas enriched with emotional annotations, which enhances realism and emotional depth in language interactions."
        },
        "method": {
            "method name": "RoleCraft-GLM",
            "method abbreviation": "RC-GLM",
            "method definition": "RoleCraft-GLM is a framework designed to enhance personalized role-playing experiences in LLMs by integrating a hybrid instruction tuning strategy with a novel dataset featuring emotional annotations.",
            "method description": "The core of RoleCraft-GLM involves utilizing a hybrid approach that combines general instructions with character-specific Q&A pairs to generate contextually adaptive dialogues.",
            "method steps": "1. Compile a dataset with emotional annotations. 2. Utilize a hybrid instruction tuning strategy. 3. Train the model on both general and character-specific instructions. 4. Generate dialogues based on character profiles.",
            "principle": "The effectiveness of RoleCraft-GLM lies in its ability to maintain character integrity while generating dialogues that are contextually relevant and emotionally engaging."
        },
        "experiments": {
            "evaluation setting": "The experimental setup includes using the RoleInstruct dataset, comparing the performance of RoleCraft-GLM against baseline models like GPT-3.5 and GPT-4, focusing on dialogue authenticity and emotional accuracy.",
            "evaluation method": "The evaluation involved metrics such as Rouge-L score, GPT score, Role-Playing Cosine Similarity (RPCS), and human evaluation across several criteria including communication effectiveness, consistency, and expressive diversity."
        },
        "conclusion": "RoleCraft-GLM excels in generating dialogues that capture authentic character traits and emotions, surpassing mainstream models like GPT-4 in role-playing capabilities, while paving the way for the development of behavioral agents tailored to individual user preferences.",
        "discussion": {
            "advantage": "The key advantages include enhanced personalization, emotional depth in character portrayal, and the ability to generate contextually relevant dialogues that reflect the intricacies of human emotions.",
            "limitation": "The limitations include a focus on specific cultural and linguistic contexts, which may restrict the model's generalization ability and diversity in the role-playing experience.",
            "future work": "Future directions include expanding the dataset to encompass a broader range of cultural contexts and exploring more complex emotional classifications to improve the authenticity and depth of generated dialogues."
        },
        "other info": {
            "Ethics Statement": "We ensure ethical practices in data annotation by employing a reputable data annotation company, maintaining privacy and confidentiality, and minimizing biases through rigorous training and guidelines for annotators."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "AI hallucination refers to the phenomenon where AI models generate outputs that are not grounded in reality, which is significant in NLP as it can lead to misleading or incorrect information being presented to users."
        },
        {
            "section number": "1.3",
            "key information": "The development of large language models (LLMs) has initiated a new chapter in complex tasks such as role-playing, enhancing user interaction experiences by enabling models to imitate various characters."
        },
        {
            "section number": "2.1",
            "key information": "Existing open-source LLMs, primarily trained in general domains, lack the specialized optimization needed for nuanced role-playing tasks, indicating a need for further customization to effectively meet specific role-playing requirements."
        },
        {
            "section number": "4.1",
            "key information": "Current models often lack the depth and adaptability required for truly personalized and nuanced role-play experiences, presenting challenges during the training of models to avoid hallucination."
        },
        {
            "section number": "5.1",
            "key information": "The proposed idea of RoleCraft emphasizes emotional depth and contextual awareness in dialogue generation, which can introduce biases if not managed properly in AI systems."
        },
        {
            "section number": "6.1",
            "key information": "RoleCraft-GLM integrates a hybrid instruction tuning strategy with a novel dataset featuring emotional annotations, which enhances realism and emotional depth in language interactions."
        },
        {
            "section number": "7.1",
            "key information": "Future directions include expanding the dataset to encompass a broader range of cultural contexts and exploring complex emotional classifications to improve authenticity and depth in generated dialogues."
        }
    ],
    "similarity_score": 0.588778081340786,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-1250_AI_ha/papers/RoleCraft-GLM_ Advancing Personalized Role-Playing in Large Language Models.json"
}