{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2103.12701",
    "title": "A*+BFHS: A Hybrid Heuristic Search Algorithm",
    "abstract": "We present a new algorithm A*+BFHS for solving problems with unit-cost operators where A* and IDA* fail due to memory limitations and/or the existence of many distinct paths between the same pair of nodes. A*+BFHS is based on A* and breadth-first heuristic search (BFHS). A*+BFHS combines advantages from both algorithms, namely A*'s node ordering, BFHS's memory savings, and both algorithms' duplicate detection. On easy problems, A*+BFHS behaves the same as A*. On hard problems, it is slower than A* but saves a large amount of memory. Compared to BFIDA*, A*+BFHS reduces the search time and/or memory requirement by several times on a variety of planning domains.",
    "bib_name": "bu2021abfhshybridheuristicsearch",
    "md_text": "# A*+BFHS: A Hybrid Heuristic Search Algorithm Zhaoxing Bu, Richard E. Korf\nComputer Science Department University of California, Los Angeles Los Angeles, CA 90095 {zbu, korf}@cs.ucla.edu\nAbstract\nWe present a new algorithm A*+BFHS for solving problems with unit-cost operators where A* and IDA* fail due to memory limitations and/or the existence of many distinct paths between the same pair of nodes. A*+BFHS is based on A* and breadth-first heuristic search (BFHS). A*+BFHS combines advantages from both algorithms, namely A*\u2019s node ordering, BFHS\u2019s memory savings, and both algorithms\u2019 duplicate detection. On easy problems, A*+BFHS behaves the same as A*. On hard problems, it is slower than A* but saves a large amount of memory. Compared to BFIDA*, A*+BFHS reduces the search time and/or memory requirement by several times on a variety of planning domains.\n16 Dec \n# Introduction and Overview\nA* (Hart, Nilsson, and Raphael 1968) is a classic heuristic search algorithm that is used by many state-of-the-art optimal track planners (Katz et al. 2018; Franco et al. 2017, 2018; Martinez et al. 2018). One advantage of A* is duplicate detection. A* uses a Closed list and an Open list to prune duplicate nodes. A state is a unique configuration of the problem while a node is a data structure that represents a state reached by a particular path. Duplicate nodes represent the same state arrived at via different paths. The second advantage of A* is node ordering. A* always picks an Open node whose f-value is minimum among all Open nodes to expand next, which guarantees an optimal solution returned by A* when using an admissible heuristic. When using a consistent heuristic, A* expands all nodes whose f-value is less than the optimal solution cost (C\u2217). However, tie-breaking among nodes of equal f-value significantly affects the set of expanded nodes whose f-value equals C\u2217. It is common practice to choose an Open node whose h-value is minimum among all Open nodes with the same f-value, as this strategy usually leads to fewer nodes expanded. A survey of tie-breaking strategies in A* can be found in (Asai and Fukunaga 2016). A*\u2019s main drawback is its exponential space requirement as it stores in memory all nodes generated during the search. For example, A* can fill up 8 GB of memory in a few minutes on common heuristic search and planning domains. To\nsolve hard problems where A* fails due to memory limitations, researchers have proposed various algorithms, usually by forgoing A*\u2019s duplicate detection or node ordering. For example, Iterative-Deepening-A* (IDA*, Korf 1985) only has a linear memory requirement, at the price of no duplicate detection and a depth-first order within each search bound. However, IDA* may generate too many duplicate nodes on domains containing lots of distinct paths between the same pair of nodes, such as Towers of Hanoi and many planning domains, limiting its application. For example, in a grid graph, there are \ufffdm+n m \ufffd distinct shortest paths from node (0,0) to (m,n), and IDA* cannot detect these as duplicates. We introduce a new algorithm for solving problems with unit-cost operators, with many distinct paths between the same pair of nodes, where IDA* is not effective. First, we review previous algorithms. Second, we present A*+BFHS, which is based on A* and Breadth-First Heuristic Search (Zhou and Hansen 2004). Third, we present experimental results on 32 hard instances from 18 International Planning Competition (IPC) domains. On those problems, A*+BFHS is slower than A* but requires significantly less memory. Compared to BFIDA*, an algorithm that requires less memory than A*, A*+BFHS reduces the search time and/or memory requirement by several times, and sometimes by an order of magnitude, on a variety of domains.\n# Previous Work\nIDA* with a transposition table (IDA*+TT, Sen and Bagchi 1989; Reinefeld and Marsland 1994) uses a transposition table to detect duplicate nodes. However, IDA*+TT is outperformed by other algorithms on both heuristic search (Bu and Korf 2019) and planning domains (Zhou and Hansen 2004). A*+IDA* (Bu and Korf 2019) combines A* and IDA*, and is the state-of-the-art algorithm on the 24-Puzzle. It first runs A* until memory is almost full, then runs IDA* below each frontier node without duplicate detection. By sorting the frontier nodes with the same f-value in increasing order of h-values, A*+IDA* can significantly reduce the number of nodes generated in its last iteration. Compared to IDA*, we reported a reduction by a factor of 400 in the total number of nodes generated in the last iteration on all 50 24-Puzzle test cases in (Korf and Felner 2002). Similar to IDA*, A*+IDA* does not work well on domains with many\ndistinct paths between the same pair of nodes. Frontier search (Korf et al. 2005) is a family of heuristic search algorithms that work well on domains with many distinct paths between the same pair of nodes. Rather than storing all nodes generated, it stores only nodes that are at or near the search frontier, including all Open nodes and only one or two layers of Closed nodes. As a result, when a goal node is expanded, only the optimal cost is known. To reconstruct the solution path, frontier search keeps a middle layer of Closed nodes in memory. For example, we can save the Closed nodes at depth h(start)/2 as the middle layer. Each node generated below this middle layer has a pointer to its ancestor in the middle layer. After finding the optimal cost, a node in the middle layer that is on an optimal path is identified. Then the same algorithm can be applied recursively to compute the solution path from the start node to the middle node, and from the middle node to the goal node. In general, however, frontier search cannot prune all duplicates in directed graphs (Korf et al. 2005; Zhou and Hansen 2004). Divide-and-Conquer Frontier-A* (DCFA*, Korf and Zhang 2000) is a best-first frontier search based on A*. To reconstruct the solution path, DCFA* keeps a middle layer of Closed nodes that are roughly halfway along the solution path. DCFA* detects duplicates and maintains A*\u2019s node ordering, but its memory savings compared to A* is limited on domains where the Open list is larger than the Closed list. Breadth-First Heuristic Search (BFHS, Zhou and Hansen 2004) is a frontier search algorithm for unit-cost domains. BFHS also detects duplicates but uses a breadth-first node ordering instead of A*\u2019s best-first ordering. At first, assume the optimal cost C\u2217is known in advance. BFHS runs a breadth-first search (BFS) from the start node and prunes every generated node whose f-value exceeds C\u2217. To save memory, BFHS only keeps a few layers of nodes in memory. On undirected graphs, if we store the operators used to generate each node, and do not regenerate the parents of a node via the inverses of those operators, frontier search only needs to store two layers of nodes, the currently expanding layer and their child nodes (Korf et al. 2005). On directed graphs, one previous layer besides the above-mentioned two layers is usually stored to detect duplicates (Zhou and Hansen 2004). To reconstruct the solution path, Zhou and Hansen (2004) recommend saving the layer at the 3/4 point of the solution length as the middle layer instead of the layer at the halfway point, which usually requires more memory. As shown in (Zhou and Hansen 2004), on a domain where the Open list of A* is larger than the Closed list, BFHS usually ends up storing fewer nodes than DCFA*. In general, C\u2217is not known in advance. Zhou and Hansen (2004) proposed Breadth-First Iterative-Deepening-A* (BFIDA*), which runs multiple iterations of BFHS, each with a different f-bound, starting with the heuristic value of the start node. Similar to IDA*, the last iteration of BFIDA* is often significantly larger than previous iterations, so most search time is often spent on the last iteration. Compared to A*, BFHS and BFIDA* save significant memory but generate more nodes. The main drawback of BFHS and BFIDA* is that their node ordering is almost the\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ed3a/ed3ac2b8-1a43-40a1-8e26-b92a4049ad4d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: An example of A*+BFHS\u2019s search frontier. Numbers are f-values. Closed nodes are gray.</div>\nworst among different node ordering schemes. BFHS and BFIDA*\u2019s breadth-first ordering means they have to expand all nodes stored at a single depth before expanding any nodes in the next depth. As a result, they have to expand almost all nodes whose f-value equals C\u2217, excepting only some nodes at the same depth as the goal node, while A* may only expand a small fraction of such nodes due to its node ordering. Forward Perimeter Search (FPS, Sch\u00a8utt, D\u00a8obbelin, and Reinefeld 2013) builds a perimeter around the start node via BFS, then runs BFIDA* below each perimeter node. The authors only test FPS on the 24-Puzzle and 17-Pancake problem, and did not report any running time.\n# A*+BFHS\n# Algorithm Description\nWe propose A*+BFHS, a hybrid algorithm to solve problems with many paths between the same pair of nodes. A*+BFHS first runs A* until a storage threshold is reached, then runs a series of BFHS iterations on sets of frontier nodes, which are the Open nodes at the end of the A* phase. The BFHS phase can be viewed as a doubly nested loop. Each iteration of the outer loop, which we define as an iteration of the BFHS phase, corresponds to a different cost bound for BFHS. The first cost bound is set to the smallest f-value among all frontier nodes. In each iteration of the BFHS phase, we first partition the frontier nodes whose fvalue equals the cost bound into different sets according to their depths. Then the inner loop makes one call to BFHS on each set of frontier nodes, in decreasing order of their depths. This is done by initializing the BFS queue of each call to BFHS with all the nodes in the set. This inner loop continues until a solution is found or all calls to BFHS with the current bound fail to find a solution. After each call to BFHS on a set of frontier nodes, we increase the f-value of all nodes in the set to the minimum f-value of the nodes generated but not expanded in the previous call to BFHS. Figure 1 presents an example of the Open and Closed nodes at the end of the A* phase. Node S is the start node. All edge costs are 1 and the number next to each node is its f-value. Closed nodes are gray. The Open nodes B, E, F, H, I, J, K are the frontier nodes for the BFHS phase. A*+BFHS first makes a call to BFHS with a cost bound of 8 on all frontier nodes at depth 3, namely nodes H, I, J, K. If no solution is found, A*+BFHS updates the f-values of all these nodes to the minimum f-value of the nodes generated but\nnot expanded in that call to BFHS. A*+BFHS then makes a second call to BFHS with bound 8, starting with all frontier nodes at depth 2, namely nodes E and F. If no solution is found, A*+BFHS updates the f-values of these nodes, then makes a third call to BFHS with bound 8, starting with the frontier node B at depth 1. Suppose that no solution is found with bound 8, the updated f-values for nodes E, F, H, I, J, K are 9, and the updated f-value for node B is 10. A*+BFHS then starts a new iteration of BFHS with a cost bound of 9, making two calls to BFHS on nodes at depth 3 and 2 respectively. If the solution is found in the first call to BFHS with bound 9, BFHS will not be called again on nodes E and F. A*+BFHS is complete and admissible with admissible heuristics. A*+BFHS potentially makes calls to BFHS on all frontier nodes. When an optimal solution exists, one node on this optimal path serves as one of the start nodes for one of the calls to BFHS. Such a node is guaranteed to exist by A*\u2019s completeness and admissibility. When the cost bound for the calls to BFHS equals C\u2217, the optimal solution will be found, guaranteed by BFHS\u2019s completeness and admissibility. A state can be regenerated in separate calls to BFHS in the same iteration. To reduce such duplicates, we can decrease the number of calls to BFHS in each iteration by making each call to BFHS on a combined set of frontier nodes at adjacent depths. For the example in Figure 1, we can make one call to BFHS on the frontier nodes at depths 2 and 3 together instead of two separate calls to BFHS, by putting the frontier nodes at depth 3 after the frontier nodes at depth 2 in the initial BFS queue. In practice, we can specify a maximum number of calls to BFHS per iteration. Then in each iteration, we divide the number of depths of the frontier nodes by the number of calls to BFHS to get the number of depths for each call to BFHS. For example, if the depths of the frontier nodes range from 7 to 12 and we are limited to three calls to BFHS per iteration, each call to BFHS will start with frontier nodes at two depths. We used this strategy in our experiments. For each node generated in the BFHS phase, we check if it was generated in the A* phase. If so, we immediately prune the node if its current g-value in the BFHS phase is greater than or equal to its stored g-value in the A* phase. The primary purpose of the A* phase is to build a frontier set, so that A*+BFHS can terminate early in its last iteration. In the A* phase we have to reserve some memory for the BFHS phase. In our experiments, we first generated pattern databases or the merge-and-shrink heuristic, then allocated 1/10 of the remaining memory of 8 GB for the A* phase.\n# Comparisons to BFIDA* and FPS\nA*+BFHS\u2019s BFHS phase also uses the iterative deepening concept of BFIDA*, but there are two key differences. First, in each iteration, BFIDA* always makes one call to BFHS on the start node, while we call BFHS multiple times, each on a different set of frontier nodes. Second, in each iteration, we order the frontier nodes based on their depth, and run BFHS on the deepest frontier nodes first. These differences lead to one drawback and two advantages. The drawback is that A*+BFHS may generate more\nnodes than BFIDA*, as the same state can be regenerated in separate calls to BFHS in the same iteration. The first advantage is that A*+BFHS may terminate early in its last iteration. If A*+BFHS generates a goal node in the last iteration below a relatively deep frontier node, no frontier nodes above that depth will be expanded. Therefore, A*+BFHS may generate only a small number of nodes in its last iteration. In contrast, BFIDA* has to expand almost all nodes whose f-value is less than or equal to C\u2217in its last iteration. As a result, A*+BFHS can be faster than BFIDA*. The second advantage is that A*+BFHS\u2019s memory usage, which is the maximum number of nodes stored during the entire search, may be smaller than that of BFIDA* for two reasons. First, the partition of frontier nodes and separate calls to BFHS within the same iteration can reduce the maximum number of nodes stored in the BFHS phase. Second, BFIDA* stores the most nodes in its last iteration while A*+BFHS may store only a small number of nodes in the last iteration due to early termination. Thus, A*+BFHS may store the most nodes in the penultimate iteration instead. FPS looks similar to A*+BFHS, but there are several fundamental differences. First, FPS builds the perimeter using a breadth-first approach while A*+BFHS builds the frontier via a best-first approach. FPS can also dynamically extend the perimeter but this approach does not always speed up the search (Sch\u00a8utt, D\u00a8obbelin, and Reinefeld 2013). Second, in each iteration of FPS\u2019s BFIDA* phase, FPS makes one call to BFHS on each perimeter node. In contrast, in A*+BFHS each call to BFHS is on a set of frontier nodes. Third, FPS sorts the perimeter nodes at the same f-value using a maxtree-first or longest-path-first policy, while A*+BFHS sorts the frontier nodes at the same f-value in decreasing order of their depth. Fourth, FPS needs two separate searches for solution reconstruction while A*+BFHS only needs one.\n# Solution Reconstruction\nEach node generated in A*+BFHS\u2019s BFHS phase has a pointer to its ancestral frontier node. When a goal node is generated, the solution path from the start node to the ancestral frontier node is stored in the A* phase and only one more search is needed to reconstruct the solution path from the ancestral frontier node to the goal node. This subproblem is much easier than the original problem and we can use the same heuristic function as for the original problem. Therefore, we just use A* to solve this subproblem. In addition, since we know the optimal cost of this subproblem, we can prune any node whose f-value exceeds this cost. In BFIDA*, we have to solve two subproblems to recover the paths from the start node to the middle node and from the middle node to the goal node. Zhou and Hansen (2004) called BFHS recursively to solve these two subproblems. However, pattern database heuristics (PDB, Culberson and Schaeffer 1998) only store heuristic values to the goal state, and not between arbitrary pairs of states, which complicates finding a path to a middle node. Similar to A*+BFHS, we use A* to solve the second subproblem. For the first subproblem, we use A* to compute the path from the start node to the middle node using the same\nheuristic function as for the original problem, which measures the distance to the goal node, not the middle node. To save memory, we prune any node whose g-value is greater than or equal to the depth of the middle node, and any node whose f-value exceeds the optimal cost of the original problem. Since a deeper middle layer leads to more nodes stored in this approach, we saved the layer at the 1/4 point of the solution length as the middle layer instead of the 3/4 point. In this way, we do not need to build a new heuristic function for the middle node. In our experiments, the search time for solution reconstruction in BFIDA* was usually less than 1% of the total search time.\n# Experimental Results and Analysis\nWe implemented BFIDA*, A*+IDA*, and A*+BFHS in the planner Fast Downward 20.06 (Helmert 2006), using the existing code for node expansion and heuristic functions. A*+BFHS\u2019s A* phase reused the existing A* code. A* stores all nodes in one hash map. We used the same hash map implementation with the following difference. In each call to BFHS in both BFIDA* and A*+BFHS, we saved three layers of nodes for duplicate detection and we created one hash map for each layer of nodes. We did this because storing all nodes in one hash map in BFHS involves a lot of overhead, and is more complicated. Sch\u00a8utt, D\u00a8obbelin, and Reinefeld (2013) did not test FPS on planning domains and we do not know the optimal perimeter radius and sorting strategy for each domain, so we did not implement FPS. We solved about 550 problem instances from 32 unitcost domains. We present the results of A*, BFIDA*, and A*+BFHS on the 32 hardest instances. All remaining instances were easily solved by A*. We tested two A*+BFHS versions. A*+BFHS (\u221e) starts each call to BFHS on frontier nodes at a single depth. A*+BFHS (4) makes each call to BFHS on frontier nodes at multiple depths with at most four calls to BFHS in each iteration. All tests were run on a 3.33 GHz Intel Xeon X5680 CPU with 236 GB of RAM. We used the landmark-cut heuristic (LM-cut, Helmert and Domshlak 2009) for the satellite domain, the merge-and-shrink heuristic (M&S) with the recommended configuration (Sievers, Wehrle, and Helmert 2014, 2016; Sievers 2018) for the tpp and hiking14 domains, and the iPDB heuristic with the default configuration (Haslum et al. 2007; Sievers, Ortlieb, and Helmert 2012) for all other domains. We present the results in Table 1, where the first 26 instances are solved by A* and are sorted by A*\u2019s running time. The last 6 instances in Table 1 are those where A* terminated without finding a solution due to the limitation of the hash map size in Fast Downward 20.06, and are sorted by BFIDA*\u2019s running time. We ran each algorithm until it found the optimal cost and returned an optimal path. The first column gives the domain name and the instance ID. The second through fifth columns give the maximum number of nodes stored by each algorithm. For A*, this is the number of nodes stored at the end of the search. For BFIDA*, this is the largest sum of the number of nodes stored in all three layers of the search, plus the nodes stored in the 1/4 layer\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c1ba/c1ba286d-d4e4-41df-a1d5-69c12ffac54d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: A* vs. A*+BFHS in time and memory.</div>\nfor solution reconstruction. For A*+BFHS, this is the largest number of nodes stored in the BFHS phase plus the number of nodes stored in the A* phase. An underline means the specific algorithm needed more than 8 GB of memory to solve the problem. The last four columns are the running time in seconds, including the time for solution reconstruction but excluding the time spent on precomputing the heuristic functions, which is the same for all algorithms. For each instance, the smallest maximum number of stored nodes and shortest running time are indicated in boldface. For the last 6 instances where A* terminated without finding a solution, we report A*\u2019s number of nodes and running time when A* terminated, with a > symbol to indicate such numbers. For A*+IDA*, we set the stored nodes threshold for the A* phase to A*+BFHS\u2019s peak stored nodes. A*+IDA* was faster than A*+BFHS by a factor of 2 on tidybot11 18, but was slower than A*+BFHS by around 50% on mystery 14, a factor of 2 on visitall11 08-half, 4 on parking14 16 9-04, and 8 on snake18 17. Furthermore, A*+IDA* was ordersof-magnitude slower than A*+BFHS on domains such as blocks, depot, driverlog, hiking14, logistics00, pipesworldtankage, rovers, satellite, storage, termes18, and tpp. Thus we omit the results of A*+IDA* due to space limitations. We further compare the time and memory between A* and A*+BFHS in Figure 2, and between BFIDA* and A*+BFHS in Figure 3, where the x-axis is A*/BFIDA*\u2019s peak stored nodes over A*+BFHS\u2019s and the y-axis is A*/BFIDA*\u2019s running time over A*+BFHS\u2019s. Figure 2 contains the 26 instances solved by A* and Figure 3 contains all 32 instances. The red circles and green triangles correspond to A*+BFHS (4) and A*+BFHS (\u221e) respectively. The data points above the y = 1 line or to the right of the x = 1 line represent instances where A*+BFHS outperformed the comparison algorithm in terms of time or memory.\n# A*+BFHS vs. A*\nA* was the fastest on all problem instances that it solved, but also used the most memory. Among the 32 hardest problem instances we present, A* required more than 8 GB of memory on 22 instances and could not find a solution on 6 of those after running out of the hash map used by Fast\nPeak Stored Nodes\nTime (s)\nA*+BFHS\nA*+BFHS\nInstance\nA*\nBFIDA*\n(\u221e)\n(4)\nA*\nBFIDA*\n(\u221e)\n(4)\ndepot 14\n70,504,763\n17,042,841\n21,023,657\n22,882,537\n233\n1,708\n596\n475\ntermes18 05\n80,012,545\n9,370,587\n30,874,300\n30,076,170\n245\n4,796\n15,415\n3,319\nfreecell 06\n53,080,996\n38,054,162\n30,481,377\n35,120,076\n250\n1,883\n441\n561\nlogistics00 14-1\n57,689,357\n15,441,813\n19,472,255\n20,169,648\n255\n10,381\n1,160\n752\ndriverlog 12\n144,065,288\n35,034,406\n24,712,720\n30,270,816\n344\n1,676\n944\n631\nfreecell 07\n107,183,015\n77,196,602\n54,171,433\n58,058,327\n522\n6,416\n4,775\n3,769\ndepot 11\n172,447,963\n27,192,174\n37,977,775\n46,923,423\n550\n3,544\n7,314\n4,078\ntpp 11\n187,011,066\n93,759,836\n30,856,159\n33,368,912\n562\n7,214\n9,550\n2,426\nmystery 14\n139,924,686\n135,963,227\n20,302,860\n20,302,860\n578\n7,628\n839\n839\ntidybot11 17\n69,953,936\n42,080,838\n33,969,968\n37,090,062\n662\n3,684\n3,223\n2,694\nlogistics00 15-1\n82,161,805\n13,638,319\n18,827,830\n18,827,830\n663\n19,062\n4,897\n1,627\npipesworld-notankage 19\n123,553,926\n86,818,434\n42,192,503\n44,706,153\n727\n4,140\n2,072\n1,942\nparking14 16 9-01\n351,976,816\n183,832,715\n30,675,587\n51,147,740\n971\n6,236\n1,468\n1,290\nvisitall11 08-half\n407,182,291\n172,474,497\n34,406,966\n64,671,078\n1,045\n4,220\n2,233\n1,902\ntidybot11 16\n115,965,857\n86,095,996\n41,342,908\n57,026,598\n1,086\n5,512\n2,923\n3,080\nsnake18 08\n94,699,640\n44,231,998\n44,081,853\n51,166,308\n1,131\n14,877\n3,445\n3,192\nhiking14 2-2-8\n287,192,625\n42,570,885\n44,454,322\n53,148,260\n1,297\n10,847\n14,897\n9,696\npipesworld-tankage 14\n292,998,092\n158,262,429\n84,077,693\n103,288,306\n1,364\n10,609\n11,622\n6,896\nblocks 13-1\n555,864,249\n99,782,317\n54,601,577\n79,572,108\n1,540\n2,142\n2,817\n2,317\nparking14 16 9-03\n606,117,759\n291,822,896\n48,304,204\n63,455,874\n1,714\n10,059\n3,124\n2,679\ntidybot11 18\n175,574,760\n114,747,861\n40,540,308\n65,784,369\n1,730\n8,810\n5,410\n6,365\nblocks 13-0\n704,938,102\n137,821,868\n81,918,224\n126,629,640\n1,990\n2,977\n4,483\n3,378\nhiking14 2-3-6\n368,433,117\n124,686,777\n146,623,619\n148,357,537\n2,480\n42,379\n120,494\n76,603\npipesworld-notankage 20\n442,232,520\n301,349,348\n133,708,317\n148,029,967\n2,693\n15,245\n11,499\n10,629\nsnake18 17\n265,033,991\n60,041,363\n56,839,243\n73,365,792\n3,967\n20,418\n8,785\n8,916\nsatellite 08\n107,395,076\n20,846,202\n18,870,254\n19,763,323\n11,834\n398,884\n54,551\n56,296\nblocks 15-0\n>814,951,324\n113,471,990\n68,070,197\n106,482,059\n>2,284\n3,058\n4,889\n3,514\nstorage 17\n>799,907,374\n397,798,456\n118,138,352\n133,800,503\n>2,358\n19,086\n18,914\n11,354\ndriverlog 15\n>786,467,847\n453,643,579\n88,449,751\n123,602,679\n>1,853\n24,297\n15,311\n8,447\nrovers 09\n>801,124,989\n235,386,020\n96,100,365\n99,498,513\n>2,776\n25,336\n42,290\n16,770\nrovers 11\n>766,016,316\n274,612,697\n112,783,085\n113,594,902\n>2,378\n26,022\n43,538\n16,661\nparking14 16 9-04\n>770,874,998\n1,045,614,854\n156,758,802\n181,535,647\n>2,306\n37,701\n12,304\n9,813\nTable 1: Instances sorted by A* running time if solved by A*. Instances where A* terminated without solving the problem (marked by >) are sorted by BFIDA* running time. An underline means more than 8 GB of memory was needed. Smalles memory and shortest times are in boldface.\nDownward 20.06. On some of these instances, A* used 30 GB to 40 GB of memory before it terminated. This means A* cannot solve these 22 instances under the current IPC memory requirement, which is 8 GB. A*+BFHS required several times, sometimes an order of magnitude, less memory than A*. As a result, A*+BFHS only used more than 8 GB of memory on one instance. An interesting comparison is the space and time trade-off. For example, on parking14, A*+BFHS increased the running time by less than 100% while saving more than an order of magnitude in memory.\n# A*+BFHS vs. BFIDA*\nIn summary, on easy problems that A*+BFHS can solve in its A* phase, A*+BFHS behaves the same as A*, and is always faster than BFIDA*. We solved around 500 such problems, which are not included here due to space limitations. On the 32 hardest problems we present, A*+BFHS is faster than BFIDA* on 27 instances and at least twice as fast on 16 of those. Furthermore, A*+BFHS requires less memory than\nBFIDA* on 25 of the 32 instances and saves more than half the memory on 14 of those. In addition, these time and memory reductions exist on both the relatively easy and hard ones of the 32 instances presented, demonstrating that A*+BFHS is in general better than BFIDA* on very hard problems as well as easy problems. In the following paragraphs, we compare A*+BFHS with BFIDA* in four aspects: duplicate detection, node ordering, memory, and running time. Figure 4 compares the number of nodes generated prior to the last iteration of BFIDA* and A*+BFHS. For BFIDA*, this is the number of nodes generated in all but the last iteration. For A*+BFHS, this is the sum of nodes generated in its A* phase and all but the last iteration in its BFHS phase. The y-axis in Figure 4 is the number of nodes generated in BFIDA*\u2019s previous iterations divided by A*+BFHS\u2019s. We sort the 32 instances on the x-axis according to BFIDA*\u2019s running time, so the left-most instance is the easiest and the right-most instance is the hardest for BFIDA*. The data points above the y = 1 line represent instances where\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/52b8/52b8ab73-e072-4702-8168-3a9c55df4139.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">BFIDA* peak stored # / A*+BFHS peak stored #</div>\n<div style=\"text-align: center;\">Figure 3: BFIDA* vs. A*+BFHS in time and memory.</div>\nA*+BFHS generated fewer nodes than BFIDA* in the previous iterations. Compared to BFIDA*, A*+BFHS (4) generated a similar number of nodes in the previous iterations on most instances. Hiking14 2-3-6 is the only instance where A*+BFHS (4) generated at least twice as many nodes in the previous iterations as BFIDA*. However, A*+BFHS (\u221e) generated 2 to 7 times as many nodes in the previous iterations as BFIDA* on 11 instances. This contrast shows that, compared to BFIDA*, significantly more duplicate nodes can be generated by making each call to BFHS on frontier nodes at a single depth. However, most of those duplicate nodes can be avoided by making each call to BFHS on frontier nodes at multiple depths. A*+BFHS can generate fewer duplicate nodes than BFIDA* due to fewer BFHS iterations and making each call to BFHS on a set of frontier nodes. A*+BFHS reduced the number of nodes in previous iterations by around 50% on freecell 06 and snake18 17, and a factor of 4 on snake18 08. To our surprise, we found that on snake18 08, the number of nodes generated in the penultimate iteration of BFIDA* was twice as many as the sum of the nodes generated in A*+BFHS\u2019s A* phase and the penultimate iteration of the BFHS phase. This means a lot of duplicate nodes were generated in BFIDA*. Snake18 generates a directed graph, in which case frontier search cannot detect all duplicate nodes (Korf et al. 2005; Zhou and Hansen 2004). Compared to BFIDA*, A*+BFHS reduced the number of nodes in the last iteration significantly, and usually by several orders of magnitude, on 28 of the 32 instances. We present this comparison in Figure 5, where the y-axis is the number of nodes generated in BFIDA*\u2019s last iteration divided by A*+BFHS\u2019s. We also sort the 32 instances on the x-axis according to BFIDA*\u2019s running time, so the left-most instance is the easiest and the right-most instance is the hardest for BFIDA*. The data points above the y = 1 line represent instances where A*+BFHS generated fewer nodes than BFIDA* in the last iteration. Both A*+BFHS versions usually generated several orders of magnitude fewer nodes in the last iteration than BFIDA*, while A*+BFHS (\u221e) generated the fewest nodes on most instances. This large reduction proves that when ordering the frontier nodes by deepest-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a003/a003476f-5df8-491d-b101-fa4df90292b4.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Test instances sorted by BFIDA* running time</div>\nFigure 4: The number of nodes generated in BFIDA*\u2019s previous iterations vs. A*+BFHS\u2019s.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e7ea/e7ea57dc-31fe-43a4-9a90-90501db4aa9f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Test instances sorted by BFIDA* running time</div>\nFigure 5: The number of nodes generated in BFIDA*\u2019s last iteration vs. A*+BFHS\u2019s.\nfirst, A*+BFHS can terminate early in its last iteration. On the three blocks instances and depot 11, A*+BFHS did not terminate early in its last iteration because the ancestral frontier node of the goal had a relatively low g-value. In fact, A* generated the most nodes while expanding the Open nodes whose f = C\u2217on the three blocks instances, which shows that node ordering is also difficult for A* on those instances. In contrast, A* generated very few nodes while expanding the Open nodes whose f = C\u2217on depot 11, suggesting that A*+BFHS may terminate early in its last iteration given more memory for its A* phase. A*+BFHS\u2019s A* phase usually stored from 10 to 20 million nodes, with the exception of the snake18 domain where 40 to 50 million nodes were stored. Comparing the maximum number of stored nodes, A*+BFHS (\u221e) required less memory than BFIDA* on 25 instances and less than half the memory on 14 of those. For A*+BFHS (4), these two numbers are 23 and 11 respectively. In contrast, termes18 05 is the only instance where the maximum number of stored\nnodes of A*+BFHS was at least twice that of BFIDA*. Comparing the two versions of A*+BFHS, A*+BFHS (4) was usually faster, sometimes significantly, due to the reduction in duplicate nodes. Compared to BFIDA*, A*+BFHS (4) was slightly slower on four instances and 80% slower on one instance. On the other 27 instances, A*+BFHS (4) was faster than BFIDA*, and at least twice as fast on 16 of those. The large speedups usually were on the instances where BFIDA* generated the most nodes in its last iteration. The best result was on the logistics00 domain, where an order of magnitude speedup was achieved. This is because BFIDA* performed very poorly on this domain due to its breadth-first node ordering. Compared to BFIDA*, A*+BFHS (\u221e) was slower on 11 instances and at least twice as slow on three of those, but also at least twice as fast on 12 instances. The main reason for the slower cases is the presence of many duplicate nodes generated in certain domains.\n# Calling BFHS on Nodes at Multiple Depths\nComparing the two A*+BFHS versions, each has its pros and cons. A*+BFHS (4) always generated fewer duplicate nodes. Comparing the number of nodes generated in the previous iterations, A*+BFHS (\u221e) generated at least twice as many nodes on 7 instances. A*+BFHS (\u221e) generated significantly fewer nodes in the last iteration than A*+BFHS (4) on 22 instances. However, the number of nodes generated in the last iteration of A*+BFHS is usually only a small portion of the total nodes generated, so the large difference in the last iteration is not very important. A*+BFHS (4) stored a larger maximum number of nodes than A*+BFHS (\u221e) on almost all instances. However, the difference was usually small and never more than a factor of two. For the running time, the difference was usually less than 50%. Compared to A*+BFHS (\u221e), A*+BFHS (4) was faster by a factor of 3 on logistics00 15-1, 2.5 on rovers 09 and 11, 4.6 on termes18 05, 3.9 on tpp 11, and never more than 30% slower. In general, making each call to BFHS on frontier nodes at multiple depths increases both the memory usage and the number of nodes generated in the last iteration, but reduces the number of duplicate nodes and hence is often faster. Considering the memory and time trade-off, given a new problem, we recommend making each call to BFHS on frontier nodes at multiple depths. However, if we limit the number of calls to BFHS in each iteration to one, then A*+BFHS (1) will generate about the same number of nodes as BFIDA*, and early termination is no longer possible. Therefore, at least two calls should be used. So far, we have only limited BFHS to four calls in each iteration. Determining the optimal number of calls to BFHS is a subject for future work.\n# Heuristic Functions and Running Time\nFor each node generated, A* first does duplicate checking then looks up its heuristic value if needed. Thus for each state, A* only computes its heuristic value once, no matter how many times this state is generated. However, the situation is different in BFHS. Even in a single call to BFHS, a state\u2019s heuristic value may be calculated multiple times. For example, if a state\u2019s f-value is greater than the cost bound of BFHS, then this state is never stored in this call to BFHS and\nits heuristic value has to be computed every time it is generated. In addition, A* has only one hash map but our BFHS implementation has one hash map for each layer of nodes. Consequently, for each node generated, A* does only one hash map lookup while BFHS may have multiple lookups. Due to the above differences, the number of nodes generated per second of BFIDA* and A*+BFHS was smaller than that of A*. For the iPDB and M&S heuristics, this difference was usually less than a factor of two. For the LM-cut heuristic, A* was faster by a factor of four in terms of nodes generated per second on the satellite domain. This is because computing a node\u2019s LM-cut heuristic is much more expensive than iPDB and M&S heuristics. This contrast shows that the choice of heuristic function also plays an important role in comparing the running time of different algorithms.\nFuture work includes the following. First, test A*+BFHS on more unit-cost domains. Second, investigate what is the best memory threshold for the A* phase. Third, determine the optimal number of calls to BFHS in each iteration. Fourth, find other ways to partition the frontier nodes besides the current depth-based approach. If a set of frontier nodes is too large, we may split it into multiple smaller sets and make one call to BFHS on each such smaller set. This approach may reduce the maximum number of stored nodes but may generate more duplicate nodes. In addition, when we make each call to BFHS on frontier nodes at multiple depths, we may consider the number of frontier nodes at each depth so each call to BFHS is on a different number of depths instead of a fixed number. Fifth, use external memory such as magnetic disk or flash memory in A*+BFHS to solve very hard problems. For example, instead of allocating 1/10 of RAM for the A* phase, we can first run A* until RAM is almost full, then store both Open and Closed nodes in external memory and remove them from RAM. Then in the BFHS phase, we load back the set of frontier nodes for each call to BFHS from external memory. This A*+BFHS version would never perform worse than A*, since it is identical to A* until memory is exhausted, at which point the BHFS phase would begin.\n# Conclusions\nWe introduce a hybrid heuristic search algorithm A*+BFHS for solving problems with unit-cost operators that cannot be solved by A* due to memory limitations, nor IDA* due to the existence of many distinct paths between the same pair of nodes. A*+BFHS first runs A* until a user-specified storage threshold is reached, then runs multiple iterations of BFHS on the frontier nodes, which are the Open nodes at the end of the A* phase. Each iteration has a unique cost bound and contains multiple calls to BFHS. Each call to BFHS within the same iteration has the same cost bound but a different set of frontier nodes to start with. Within an iteration, frontier nodes are sorted deepest-first so that A*+BFHS can terminate early in its last iteration. On the around 500 easy problems solved, A*+BFHS behaves the same as A*, and is always faster than BFIDA*. On the 32 hard instances presented, A*+BFHS is slower than\nA* but uses significantly less memory. A*+BFHS is faster than BFIDA* on 27 of those 32 instances and at least twice as fast on 16 of those. Furthermore, A*+BFHS requires less memory than BFIDA* on 25 of those 32 instances and saves more than half the memory on 14 of those. Another contribution of this paper is a comprehensive testing of BFIDA* on many planning domains, which is lacking in the literature.\n# References\nAsai, M.; and Fukunaga, A. S. 2016. Tiebreaking Strategies for A* Search: How to Explore the Final Frontier. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA, 673\u2013679. AAAI Press. Bu, Z.; and Korf, R. E. 2019. A*+IDA*: A Simple Hybrid Search Algorithm. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019, 1206\u20131212. ijcai.org. Culberson, J. C.; and Schaeffer, J. 1998. Pattern Databases. Comput. Intell., 14(3): 318\u2013334. Franco, S.; Lelis, L. H.; Barley, M.; Edelkamp, S.; Martines, M.; and Moraru, I. 2018. The Complementary2 planner in the IPC 2018. IPC-9 planner abstracts, 28\u201331. Franco, S.; Torralba, \u00b4A.; Lelis, L. H. S.; and Barley, M. 2017. On Creating Complementary Pattern Databases. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI 2017, Melbourne, Australia, August 19-25, 2017, 4302\u20134309. ijcai.org. Hart, P. E.; Nilsson, N. J.; and Raphael, B. 1968. A Formal Basis for the Heuristic Determination of Minimum Cost Paths. IEEE Trans. Syst. Sci. Cybern., 4(2): 100\u2013107. Haslum, P.; Botea, A.; Helmert, M.; Bonet, B.; and Koenig, S. 2007. Domain-Independent Construction of Pattern Database Heuristics for Cost-Optimal Planning. In Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence, July 22-26, 2007, Vancouver, British Columbia, Canada, 1007\u20131012. AAAI Press. Helmert, M. 2006. The Fast Downward Planning System. J. Artif. Intell. Res., 26: 191\u2013246. Helmert, M.; and Domshlak, C. 2009. Landmarks, Critical Paths and Abstractions: What\u2019s the Difference Anyway? In Proceedings of the 19th International Conference on Automated Planning and Scheduling, ICAPS 2009, Thessaloniki, Greece, September 19-23, 2009. AAAI. Katz, M.; Sohrabi, S.; Samulowitz, H.; and Sievers, S. 2018. Delfi: Online planner selection for cost-optimal planning. IPC-9 planner abstracts, 57\u201364. Korf, R. E. 1985. Depth-First Iterative-Deepening: An Optimal Admissible Tree Search. Artif. Intell., 27(1): 97\u2013109. Korf, R. E.; and Felner, A. 2002. Disjoint pattern database heuristics. Artif. Intell., 134(1-2): 9\u201322. Korf, R. E.; and Zhang, W. 2000. Divide-and-ConquerFrontier Search Applied to Optimal Sequence Alignment. In Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on on Innovative\nApplications of Artificial Intelligence, July 30 - August 3, 2000, Austin, Texas, USA, 910\u2013916. AAAI Press / The MIT Press. Korf, R. E.; Zhang, W.; Thayer, I.; and Hohwald, H. 2005. Frontier search. J. ACM, 52(5): 715\u2013748. Martinez, M.; Moraru, I.; Edelkamp, S.; and Franco, S. 2018. Planning-PDBs planner in the IPC 2018. IPC-9 planner abstracts, 63\u201366. Reinefeld, A.; and Marsland, T. A. 1994. Enhanced Iterative-Deepening Search. IEEE Trans. Pattern Anal. Mach. Intell., 16(7): 701\u2013710. Sch\u00a8utt, T.; D\u00a8obbelin, R.; and Reinefeld, A. 2013. Forward Perimeter Search with Controlled Use of Memory. In IJCAI 2013, Proceedings of the 23rd International Joint Conference on Artificial Intelligence, Beijing, China, August 3-9, 2013, 659\u2013665. IJCAI/AAAI. Sen, A. K.; and Bagchi, A. 1989. Fast Recursive Formulations for Best-First Search That Allow Controlled Use of Memory. In Proceedings of the 11th International Joint Conference on Artificial Intelligence. Detroit, MI, USA, August 1989, 297\u2013302. Morgan Kaufmann. Sievers, S. 2018. Merge-and-Shrink Heuristics for Classical Planning: Efficient Implementation and Partial Abstractions. In Proceedings of the Eleventh International Symposium on Combinatorial Search, SOCS 2018, Stockholm, Sweden - 14-15 July 2018, 99. AAAI Press. Sievers, S.; Ortlieb, M.; and Helmert, M. 2012. Efficient Implementation of Pattern Database Heuristics for Classical Planning. In Proceedings of the Fifth Annual Symposium on Combinatorial Search, SOCS 2012, Niagara Falls, Ontario, Canada, July 19-21, 2012. AAAI Press. Sievers, S.; Wehrle, M.; and Helmert, M. 2014. Generalized Label Reduction for Merge-and-Shrink Heuristics. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July 27 -31, 2014, Qu\u00b4ebec City, Qu\u00b4ebec, Canada, 2358\u20132366. AAAI Press. Sievers, S.; Wehrle, M.; and Helmert, M. 2016. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics. In Proceedings of the Twenty-Sixth International Conference on Automated Planning and Scheduling, ICAPS 2016, London, UK, June 12-17, 2016, 294\u2013298. AAAI Press. Zhou, R.; and Hansen, E. A. 2004. Breadth-First Heuristic Search. In Proceedings of the Fourteenth International Conference on Automated Planning and Scheduling (ICAPS 2004), June 3-7 2004, Whistler, British Columbia, Canada, 92\u2013100. AAAI.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of solving problems with unit-cost operators where traditional algorithms like A* and IDA* fail due to memory limitations and the presence of many distinct paths between the same pair of nodes. The introduction of A*+BFHS aims to combine the strengths of both A* and breadth-first heuristic search (BFHS) to overcome these challenges.",
        "problem": {
            "definition": "The problem involves finding optimal paths in search spaces where existing algorithms struggle due to high memory requirements or the complexity introduced by multiple paths between nodes.",
            "key obstacle": "The main difficulty lies in the exponential space requirement of A*, which limits its application in scenarios with numerous duplicate nodes and paths, while IDA* fails to detect these duplicates, leading to inefficient searches."
        },
        "idea": {
            "intuition": "The idea for A*+BFHS emerged from the need to efficiently manage memory while maintaining effective search strategies in complex problem domains.",
            "opinion": "A*+BFHS is designed to first utilize A* for initial exploration until memory constraints are reached, followed by a series of BFHS iterations to explore frontier nodes more efficiently.",
            "innovation": "The key innovation of A*+BFHS is its hybrid approach that leverages A*'s optimal node ordering and BFHS's memory efficiency, facilitating better performance in hard problem instances."
        },
        "method": {
            "method name": "A*+BFHS",
            "method abbreviation": "A*+BFHS",
            "method definition": "A*+BFHS is a hybrid heuristic search algorithm that combines A* and breadth-first heuristic search techniques to solve problems with unit-cost operators efficiently.",
            "method description": "The method operates by initially running A* until a memory threshold is reached, followed by multiple iterations of BFHS on frontier nodes.",
            "method steps": [
                "Run A* until a specified memory threshold is reached.",
                "Identify frontier nodes at the end of the A* phase.",
                "For each cost bound, partition the frontier nodes by depth and execute BFHS on each partition.",
                "Update the f-values of nodes after each BFHS call based on the minimum f-value generated."
            ],
            "principle": "The effectiveness of A*+BFHS stems from its ability to balance memory usage and search efficiency by combining the strengths of A*'s node ordering with the memory savings of BFHS."
        },
        "experiments": {
            "evaluation setting": "The experimental setup involved solving about 550 problem instances from 32 unit-cost domains using A*, BFIDA*, and A*+BFHS, with comparisons made based on memory usage and running time.",
            "evaluation method": "The performance of A*+BFHS was assessed by measuring the maximum number of nodes stored and the total running time for each algorithm across the problem instances."
        },
        "conclusion": "A*+BFHS demonstrates that it can effectively solve problems that A* cannot due to memory constraints, while also outperforming BFIDA* in many instances, thus proving to be a valuable addition to heuristic search methodologies.",
        "discussion": {
            "advantage": "The primary advantages of A*+BFHS include significant memory savings compared to A* and improved performance over BFIDA* in many cases, making it suitable for a wider range of problem instances.",
            "limitation": "A*+BFHS may generate more nodes than BFIDA* due to its approach, potentially leading to increased computational overhead in some scenarios.",
            "future work": "Future research directions include testing A*+BFHS on more unit-cost domains, optimizing the memory threshold for A*, and exploring alternative ways to partition frontier nodes."
        },
        "other info": [
            {
                "info1": "The paper includes a comprehensive testing of BFIDA* across various planning domains, addressing a gap in existing literature."
            },
            {
                "info2": {
                    "info2.1": "The authors implemented the algorithms in the Fast Downward planner.",
                    "info2.2": "The experiments were conducted on a high-performance server with significant RAM to accommodate the memory-intensive nature of the algorithms."
                }
            }
        ]
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper addresses the issue of solving problems with unit-cost operators where traditional algorithms like A* and IDA* fail due to memory limitations and the presence of many distinct paths between the same pair of nodes."
        },
        {
            "section number": "1.2",
            "key information": "Evaluating large language models is crucial for ensuring their effectiveness and reliability, which parallels the need for assessing the performance of algorithms like A*+BFHS in solving complex search problems."
        },
        {
            "section number": "2.1",
            "key information": "Key concepts related to the paper include hybrid heuristic search algorithms, specifically the A*+BFHS method, which combines A* and breadth-first heuristic search techniques."
        },
        {
            "section number": "2.2",
            "key information": "The evolution of large language models can be likened to the development of heuristic search algorithms, where advancements aim to overcome limitations of traditional methods."
        },
        {
            "section number": "5.1",
            "key information": "The primary advantages of A*+BFHS include significant memory savings compared to A* and improved performance over BFIDA*, highlighting the importance of addressing bias and ethical considerations in model assessment."
        },
        {
            "section number": "5.3",
            "key information": "The paper discusses the limitations of A* and IDA*, which can be compared to the limitations of current evaluation metrics and benchmarks in large language models."
        },
        {
            "section number": "6.1",
            "key information": "Future research directions include testing A*+BFHS on more unit-cost domains and optimizing memory thresholds, indicating advancements in evaluation methodologies that could enhance model evaluation processes."
        }
    ],
    "similarity_score": 0.56242052925067,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-0214_large/papers/A_+BFHS_ A Hybrid Heuristic Search Algorithm.json"
}