{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2304.01622",
    "title": "An interpretability framework for Similar case matching",
    "abstract": "Similar Case Matching (SCM) plays a pivotal role in the legal system by facilitating the efficient identification of similar cases for legal professionals. While previous research has primarily concentrated on enhancing the performance of SCM models, the aspect of interpretability has been neglected. To bridge the gap, this study proposes an integrated pipeline framework for interpretable SCM. The framework comprises four modules: judicial feature sentence identification, case matching, feature sentence alignment, and conflict resolution. In contrast to current SCM methods, our framework first extracts feature sentences within a legal case that contain essential information. Then it conducts case matching based on these extracted features. Subsequently, our framework aligns the corresponding sentences in two legal cases to provide evidence of similarity. In instances where the results of case matching and feature sentence alignment exhibit conflicts, the conflict resolution module resolves these inconsistencies. The experimental results show the effectiveness of our proposed framework, establishing a new benchmark for interpretable SCM.",
    "bib_name": "lin2023interpretabilityframeworksimilarcase",
    "md_text": "# An interpretable similar case matching framework for legal applications\nNankai Lin1, Haonan Liu2, Jiajun Fang1, Dong Zhou3* and Aimin Yang1,4*\n1School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, 510006, Guangdong, China. 2 KTH Royal Institute of Technology, Stockholm, Sweden. 3School of Information Science and Technology, Guangdong University of Foreign Studies, Guangzhou, 510006, Guangdong, China. 4School of Computer Science and Intelligence Education, Lingnan Normal University, Zhanjiang, 524000, Guangdong, China.\n# *Corresponding author(s). E-mail(s): dongzhou@gdufs.edu.cn; amyang@gdut.edu.cn; Contributing authors: neakail@outlook.com; haonan.liu.edu@gmail.com; 653639791@qq.com;\nAbstract\nSimilar Case Matching (SCM) plays a pivotal role in the legal system by facilitating the efficient identification of similar cases for legal professionals. While previous research has primarily concentrated on enhancing the performance of SCM models, the aspect of interpretability has been overlooked. To bridge this gap, this study proposes an integrated pipeline framework for interpretable SCM. The framework comprises four modules: a judicial feature sentence identification module, a case matching module, a feature sentence alignment module, and a conflict resolution module. In contrast to current SCM methods, our framework extracts feature sentences within a case that contain essential information, conducts case matching based on these extracted features, and aligns the corresponding sentences in two cases to provide evidence of case similarity. In instances where the results of case matching and feature sentence alignment\n# Springer Nature 2021 LATEX template\nSpringer Nature 2021 LATEX template\nAn interpretable similar case matching framework\nexhibit conflicts, our framework successfully resolves these inconsistencies. The experimental results show the effectiveness of our proposed framework, establishing a new benchmark for interpretable SCM. Keywords: Similar Case Matching, Interpretability, Pipeline Framework\n# 1 Introduction\nWith the development of information technology, more and more traditional industries are benefiting from artificial intelligence. Legal AI has become a trendy area of research and, as such, has received much more attention from legal professionals and AI researchers [1\u20133]. The task of the SCM aims to detect whether the two given cases are similar or not. In a standard legal system, the judgement of a case is influenced by the most similar cases in the past. However, in the traditional administration of justice, legal professionals spend a great deal of time and effort searching for similar cases to provide them with the necessary knowledge and evidential support in court. Therefore, the automatic retrieval of similar cases is of great practical value and relevance as it reduces the heavy workload of legal professionals. Since the release of the Chinese SCM task in CAIL (Chinese AI and Law Challenge) 20191 [4], scholars have started to focus on the performance of SCM on Chinese, and many valuable studies have emerged. However, these efforts focus only on whether the two cases are similar but do not explain for the result. The lack of explainability in previous studies can lead to a risky society of algorithmic discrimination, algorithmic killing, and \u201dinformation cocoon\u201d, which need to be solved urgently. Due to the fact that the current legal system preserves the neutral value of technological instruments while ignoring technological legal requirements, it is impossible for unjustified algorithms to control and prevent social problems. As the artificial intelligence become \u201dsmarter\u201d, the explainable AI is an emerging field targeting at solving the potential social risks. The field promotes use to reconsider the usage of AI application in many fields including in the legal system. So the interpretability of Legal AI needs to be fully valued and considered [5\u20137]. This paper addresses the issue of interpretability in SCM tasks and presents an interpretable pipeline framework. The framework consists of four modules: a judicial feature sentence identification module, a case matching module, a feature sentence alignment module, and a conflict resolution module. In contrast to existing SCM methods, our framework focuses on identifying feature sentences in a case that contain crucial information, conducting similar case matching based on the extracted feature sentence results, and aligning\nAn interpretable similar case matching framework\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a9b8/a9b87d26-db2a-4ef4-b165-464bd56f0d52.png\" style=\"width: 50%;\"></div>\nFig. 1 Task Definition.\nthe feature sentences in the two cases to provide evidence for case similarity. As similar case matching results might conflict with feature sentence alignment results, our framework includes a mechanism for resolving inconsistent outcomes. Experimental results demonstrate the effectiveness of our proposed framework, and its modular design allows for easy integration of new components and techniques to enhance model performance. In summary, the contributions of this paper are: (1) The paper proposes a framework oriented towards SCM, which can effectively retrieve similar cases with explanation. (2) The framework proposed in this paper contains several modules, each of which is complementary in function. The framework is flexible. Adjustments to each module will not affect other modules. Each module can be replaced independently, making it easy to improve. (3) On the Chinese interpretable similarity case matching task, the framework proposed in this paper outperforms the baseline method by 33.04%, providing a new benchmark for this task.\n# 2 Related Work\nIn judicial decisions, legal professionals often make decisions based on past cases. Therefore, identifying similar cases is the primary concern in the judgment. Similar Case Matching (SCM) has emerged as a crucial area of study for LegalAI [8]. It focuses on identifying pairs of similar cases, and there are many ways to define the similarity. SCM calls for modeling the link between cases using data at various granularity levels, such as the fact, event, and element levels. In other words, SCM is a specific type of semantic matching that can help in retrieving legal knowledge [9].\nSpringer Nature 2021 LATEX template\nAn interpretable similar case matching framework\nWith the emergence of LegalIR datasets such as COLIEE [10], CaseLaw [11], and CM [4], SCM has gradually attracted the attention of scholars. Benchmarks for the studies of LegalIR are provided by these datasets. The issues of semantic text matching are addressed using a variety of deep learning models. In order to attain the best results on COLIEE, Tran, Nguyen and Satoh [12] suggested a CNN-based model with document and sentence level pooling. Other researchers are investigating the use of better embedding techniques for LegalIR [13]. In order to improve the model\u2019s performance in the primary task of similar case matching, Peng, Yang and Lu [14] proposed a multitask learning framework with \u201cde- and re-construction\u201d, which makes use of the extraction of sub-tasks based on sentence-level knowledge components to improve the document level representation. The semantic text matching model\u2019s legal feature vector is added by Hong, Zhou, Zhang, Li and Mo [15], and BERT is used as the encoding layer to capture distant dependencies in the case documents. Li, Lu, Le and He [16] developed a brand-new interactive attention capsule network model. It attempts to mimic the method of expert legal judgment, which captures the similarity of minute details to produce an understandable verdict. Additionally, they developed an interactive dynamic routing technique that outperforms the standard dynamic routing in learning the interaction representation of legal aspects among cases. Although scholars have researched similar case matching, there is still a lack of explanation for the case matching results. To better support the case matching result, we propose a pipeline framework for interpretable SCM.\n# 3 Task Definition\nFigure 1 shows the task flow of the interpretable similar case matching task. This task is given two cases and asks the model to judge how similar the two cases are (not match, partial match, and match). At the same time, the model needs to identify alignable feature sentences in the cases as evidence support for the two cases that the model considers similar. It is worth noting that the feature sentences contained in a case are not necessarily all alignable. There are three feature sentences: (1) The critical issues about the evidential facts and the application of law disputes, that is, the focus of the dispute, summarized by the judge. (2) Essential facts, such sentences contain abstract words or phrases of legal concepts. (3) Case descriptions, that is, a description of the circumstances of the case. Since the length of the case text is too long, directly matching the text and extracting the evidence will generate many calculations and reduce the model\u2019s efficiency. Therefore, this paper attempts to decompose the matching task of similar cases with interpretability. First, we identify all the feature sentences of each case. Then, based on the identified feature sentences, the similarity degree is judged and aligned with the feature sentences.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/24be/24be11ae-4020-424e-a0da-45b788aa910f.png\" style=\"width: 50%;\"></div>\n# 4 A pipeline framework for interpretable similarity case matching\nThis paper introduces an interpretability framework for similar case matching. In contrast to existing methods, our framework is designed to identify the feature sentence that contains crucial information within a case (detailed in subsection 4.1). Leveraging the extracted feature sentence results, we then proceed to match similar cases (detailed in subsection 4.2) and align the feature sentences from the two cases (detailed in subsection 4.3) to provide evidence supporting the similarity of the cases. To address potential conflicts between the results of the case matching module and the feature sentence alignment module, our framework includes a mechanism to resolve these inconsistencies (detailed in subsection 4.4). The overall proposed framework is visually depicted in Figure 2.\n# 4.1 Feature sentence identification module\nGiven a case as the input of the module: X = [(s1, y1), (s2, y2), . . . (sn, yn)], n is the number of sentences in the case X, si(i \u2208[1, n]) represents the i-th sentence in the case and yi is the associated label of it. The label is a binary variable y \u2208{0, 1} that indicates whether a sentence is a feature sentence of the case or not. Given a sentence si, the feature sentence identification module first represents the sentence into a semantic vector using the RoBERTa [17] pre-trained model:\nThen the vector is fed to a feed-forward network followed by a softma unction to output a label probability distribution:\npi = softmax(Wfsi \u00b7 hi + bfsi)\nwhere Wfsi and bfsi are learnable parameters. Notice that the RoBERTa model can be replaced by any pre-trained language models for sentence representation, and the feed-forward network can also be substituted with other complex classifiers. Since the project aims to prove our framework\u2019s\n(1)\n(2)\nAn interpretable similar case matching framework\neffectiveness, we keep the components simple and offer flexibility for other possibilities.\n# 4.2 Case matching module\nThe case matching module can classify whether or not two input cases are matched. Given two cases Xa and Xb, each contains all the sentences of a case and a label Y \u2208{0, 1, 2} indicating not match, partial match, and match, respectively. The two cases are first fed to the feature sentence identification module described in the last subsection. The module will identify feature sentences in a case and form a new set of sentences representing the case. Thus, cases Xa and Xb will be transformed into a set of m feature sentences representing X \u2032 a = [sa1, sa2, . . . sam] and a set of l feature sentences representing X \u2032 b = [sb1, sb2, . . . sbl]. With X \u2032 a and X \u2032 b as input, the module first encodes sentences in each case using RoBERTa model and then performs matching in two different modes, as follows.\n# 4.2.1 Concat Mode\n# Under this mode, sentence pairs (sai, sbj) from the two cases are concatenated and are fed into the RoBERTa model:\ninputai,bj = [CLS]sai[SEP]sbj[SEP]\nThen the vector is fed to a feedforward network followed by a softmax function to output a label probability distribution\uff1a\npai,bj = softmax(Wcm \u00b7 hai,bj + bcm)\nwhere Wcm and bcm are learnable parameters.\n4.2.2 Siamese Mode\n# 4.2.2 Siamese Mode\nUnlike in the Concat mode, we represent each sentence in the sentence pairs (sai, sbj) using RoBERTa model:\n  We construct a hidden vector by concatenating the two text representations and an absolute difference of the representations. Then it is fed to a feedforward network followed by a softmax function to output a label probability distribution: hfe = [ha; hb; |ha \u2212hb|] (8)\n(3)\n(4)\n(5)\n(6)\n(7)\n(8)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7feb/7feba7bd-5045-4bf3-b3f0-823d59153594.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 3 The label distribution of case matching.</div>\n<div style=\"text-align: center;\">pfe = softmax(Wfe \u00b7 hfe + bfe) where Wfe and bfe are learnable parameters.</div>\npfe = softmax(Wfe \u00b7 hfe + bfe) where Wfe and bfe are learnable parameters.\n# 4.3 Feature sentence alignment module\nFor the two cases X \u2032 a = [sa1, sa2, . . . sam] and X \u2032 b = [sb1, sb2, . . . sbl] after feature identification and filtering, we can form sentence-pairs set P = [(sa1, sb1, c11), (sa1, sb2, c12), . . . , (sam, sbl, cml)] for alignment, and P \u2208Rm\u2217l. For each sentence pair (sai, sbj), i \u2208[1, m], j \u2208[1, l] there is an associated label cij \u2208{0, 1} indicating whether the two sentences can be aligned or not . The sentence alignment module uses the same two matching modes as in the case matching modules to calculate the alignment probability of a sentence pair. In the testing stage, we first calculate alignment probabilities for each sentence pair in P and get a set of alignment probabilities p = [p00, p01, . . . pml]. Then we only preserve sentence pairs with corresponding alignment probabilities larger than 0.5 to form an aligned feature sentence pair set Palign. The set can explain the case-matching prediction.\n# 4.4 Conflict Resolution Module\nAmbiguation between the case matching module and the feature sentence alignment module may happen. Two cases might be predicted as \u201dmatch\u201d or \u201dpartially match\u201d in the case matching module but cannot find aligned sentence pairs in the feature alignment module. To resolve the ambiguity, in this case, we modify the matching label of the two cases to \u201dnot match\u201d.\n(9)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5e91/5e9124d0-4569-4ef1-aeb6-ba030e3d8343.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 4 The distribution of the number of feature sentences.</div>\n# 5 Experimental data\nThe experimental data used in this paper comes from the CAIL 2022 Interpretable Similar Case Matching dataset2, which provides a total of 1000 labeled samples for the competition. For each given pair of cases, the matching degree, all feature sentences of the cases, and the aligned feature sentences have been annotated. The matching labels statistics are shown in Figure 3. It can be observed that the weight of the three categories in the dataset is relatively close, and there is no category imbalance. In addition, we further analyzed the distribution of the number of feature sentences for the cases, and the results are presented in Figure 4. The first line in the x-axis indicates the number of feature sentences contained in one case, and the second line indicates the total number of cases with the specific number of feature sentences (2 to 14+). It can be seen that the number of feature sentences in most cases is 3 to 7 sentences. We performed five-fold cross-validation on the dataset. Each fold\u2019s samples were divided in equal proportions according to the proportion of labels to construct the training and test sets. Based on the above five-fold dataset, we further construct the data for feature sentence identification and feature sentence alignment. Taking the first fold data as an example, we split all the cases in the first fold (each sample has two cases) into new samples in sentences to construct the training set for feature sentence identification of the first fold. Also, we treat a sample with two cases of standard feature sentence matches that exist in the actual set of sentence pairs supporting the match as a positive sample and vice versa as a negative sample. The distribution of categories in the five-fold training set for feature sentence identification and feature sentence alignment is shown in figure 5 with figure 6. In Figure 5, the tag \u201dNum. of feature sentences\u201d\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/db40/db40012a-17c0-452b-bff5-2be22405d184.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b231/b231e0c8-72b2-4b99-a615-b16485f516ef.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\nrepresents the number of feature sentences, and the tag \u201dNum. of non feature sentences\u201d represents the data of non feature sentences. In Figure 6, the tag \u201daligned\u201d represents that the sentence pair is an aligned feature sentence pair, while the tag \u201dunaligned\u201d represents that the sentence pair is an unaligned sentence pair.\nSpringer Nature 2021 LATEX template\n10\nAn interpretable similar case matching framework\n# 6 Evaluation Metrics\nFor the entire interpretable SCM task, the mean of the matching result score and the interpretation result score is used as the final score. We used MacroF1 in the classification task as the evaluation metric when calculating the matching result score:\n \u2208{} For the interpretation results, we first evaluate the accuracy of feature sentence extraction for individual cases, i.e., we assess how well the judicial feature sentences extracted by the model match the annotated feature sentences. We use Macro-F1 as the evaluation metric, where Sp i is the set of judicial feature sentences of a single case output by the model, and Sg i is the set of true feature sentences:\n|  | Meanwhile, for the case pairs with matching or partial matching labels, the accuracy of feature sentence identification and alignment in the case pairs supporting matching results is evaluated, again using Macro-F1 as the evaluation metric. Sp i is the set of sentence pairs supporting matching output by the model, and Sg i is the set of true sentence pairs supporting matching.\n|  | For the entire interpretable SCM task, the final score is:\n|  | For the entire interpretable SCM task, the final score is:\n(10)\n(11)\n(12)\n(13)\n(14)\n(15)\n(16)\n(17)\n(18)\nSpringer Nature 2021 LATEX template\nAn interpretable similar case matching framework\nIn evaluating the performance of the judicial feature sentence recognition module, the case matching module, and the feature sentence alignment module respectively, Macro-F1 was used as the evaluation metric.\n# 7 Experiments\n# 7.1 Experimental setup\n7.1 Experimental setup\nAll experiments were carried out using PyTorch3 and an RTX 8000 with 48 GB of memory. We build our framework based on Transformers4. Furthermore, we choose the RoBERTa-large5 [17] model as the pre-trained model adopted by our framework. As can be seen from section 4, the data distribution of the feature sentence alignment module is extremely unbalanced, so we use the label weight strategy [18] in this module, where the loss weights of negative samples and positive samples are set to 0.1 and 1, respectively. In order to verify the ease of modification of our framework, we tried to add FGM strategies to each module. A brand-new regularization technique called FGM [19\u201321] enhances the robustness of misclassifying minor perturbed inputs. We also compare our framework with the baseline model6 provided by the competition for both accuracy and interpretability. We aim to propose a stronger benchmark than the existing baseline method. In this way, our framework provides a more appropriate comparison method for the follow-up research on the interpretable cases matching. Table 2 summarises the hyper-parameters used in our experiments.\n<div style=\"text-align: center;\">Table 1 Hyper-parameter values.</div>\nParameter\nValue\nFeature dimension\n1024\nBatch size\n4\nDropout\n0.5\nNumber of epochs\n10\nLearning rate\n5e-6\nOptimizer\nAdam\nMax length in feature sentence identification module\n128\nMax length in case matching module\n512\nMax length in feature sentence alignment module\n128\n# 7.2 Experimental results\n# 7.2 Experimental results 7.2.1 Main results\nWe employ four combinations for the interpretable similar case matching task under our proposed framework. The results are shown in Table 2. It can be seen that, based on different combinations, our framework can exceed the\n11\n<div style=\"text-align: center;\">An interpretable similar case matching framework 2 Experimental results of our framework.</div>\n<div style=\"text-align: center;\">An interpretable similar case matching framework</div>\n<div style=\"text-align: center;\">An interpretable similar case matching framework</div>\n<div style=\"text-align: center;\">Table 2 Experimental results of our framework.</div>\n<div style=\"text-align: center;\">Table 2 Experimental results of our framework.</div>\nMethod\nMatching\nresult score\nInterpretation\nresult score\nFinal score\nBaseline\n65.38\n22.37\n43.87\nOur Framework (Concat)\n67.85\n81.55\n74.70\nOur Framework (Siamese)\n68.72\n79.04\n73.88\nOur Framework (Concat and FGM)\n71.74\n82.07\n76.91\nOur Framework (Siamese and FGM))\n69.21\n79.09\n74.15\nperformance of the existing baseline model by 30%. Among them, when the case matching module and the case matching module use the \u201dconcat\u201d mode, and all modules use the FGM strategy, our framework achieves the optimal performance, and the final score reaches 76.91%. We can easily apply different models in different modules, showing that our framework is straightforward to operate and modify.\nMethod\nMacro-F1\nRoBERTa\n91.80\nRoBERTa with FGM\n92.08\n# 7.2.2 Each modules\u2019 results\nWe further explore the application of different models under different modules, and the experimental results are shown in Table 3, Table 4, and Table 5. As can be seen from Table 2, the feature sentence identification is an easy-to-learn task. Even without adding other strategies, feature sentence identification module can achieve good performance, and the Macro-F1 value reaches 91.80%. Existing strategies, such as FGM, have improved the module, and the Macro-F1 value has only increased by 0.28%. Therefore, we suggest that follow-up research should focus on improving the performance of other modules.\n<div style=\"text-align: center;\">Table 4 Experimental results of case matching module.</div>\nMethod\nUsed data\nMacro-F1\nMatching\nFull text\n63.17\nMatching with FGM\nFull text\n63.61\nMatching\nFeature sentences\n63.76\nConcat\nFeature sentences\n67.97\nConcat with FGM\nFeature sentences\n70.26\nSiamese\nFeature sentences\n68.15\nSiamese with FGM\nFeature sentences\n69.17\nTable 4 shows the performance of different strategies on the case matching module. In addition to the two matching modes mentioned in subsection 3.2, we also use a similar version of the \u201dsiamese\u201d mode, the \u201dmatching\u201d mode;\n<div style=\"text-align: center;\">An interpretable similar case matching framework</div>\n<div style=\"text-align: center;\">Table 5 Experimental results of feature sentence alignment module.</div>\nMethod\nMacro-F1\nMatching\n68.04\nConcat\n86.07\nConcat and FGM\n86.55\nSiamese\n83.39\nSiamese and FGM\n83.50\nMethod\nMacro-F1\nMatching\n68.04\nConcat\n86.07\nConcat and FGM\n86.55\nSiamese\n83.39\nSiamese and FGM\n83.50\nthat is, the text representations of the two texts are directly added without additional feature extraction. In the case matching module, we can see that using the feature sentence identification module to extract the feature sentences for constructing the input text performs better than directly using all the case information as the input text. This shows the effectiveness and structural soundness of our pipeline framework. Among them, the case matching module combining FGM strategy and \u201dconcat\u201d mode achieved the best performance, and the Macro-F1 value reached 70.26%. Similarly, the combination also achieved the best performance in the feature sentence alignment module, and the experimental results are shown in Table 5.\n<div style=\"text-align: center;\">Table 6 Ablation study.</div>\nMethod\nMatching\nresult score\nInterpretation\nresult score\nFinal score\nOur Framework (Concat)\n67.85\n81.55\n74.70\n- Conflict Resolution Module\n67.10\n81.55\n74.32\nOur Framework (Siamese)\n68.72\n79.04\n73.88\n- Conflict Resolution Module\n67.18\n79.04\n73.11\nOur Framework (Concat and FGM)\n71.74\n82.07\n76.91\n- Conflict Resolution Module\n70.60\n82.07\n76.33\nOur Framework (Siamese and FGM))\n69.21\n79.09\n74.15\n- Conflict Resolution Module\n68.53\n79.09\n73.81\n# 7.3 Ablation study\nSince the conflict resolution module is not necessary for our framework, we conducted an ablation study on it, and the experimental results are shown in Table 6. It can be seen that under different models, the conflict resolution module can bring specific improvements. Through a simple resolution strategy, the framework\u2019s performance can be improved by 0.34% to 0.77%, indicating that the design of the conflict resolution module is meaningful for our pipeline framework.\n# 7.4 Case study\nWe further conduct a case study to demonstrate the superior performance of our method over existing baseline models. The results of the case study are shown in Table 7. For the given example, both our method and the baseline model obtain correct predictions for the matching results of the identified cases.\nSpringer Nature 2021 LATEX template\nAn interpretable similar case matching framework\nIn terms of providing interpretability evidence, we show our superior performance. We not only correctly identify all the feature sentences in the two cases but also correctly align the feature sentences. However, the baseline method only correctly recognizes some feature sentences, and the wrong recognition results further affect the performance of subsequent alignment methods. It can be seen that our method can not only accurately complete the case-matching task but also provide high-quality supporting evidence.\nAn interpretable similar case matching framework\nTable 7 Case study.\nCase 1\n\u2460\u7ecf\u5ba1\u7406\u67e5\u660e:2019\u5e747\u670812\u65e5,\u88ab\u544a\u4ebaXXX\u901a\u8fc7\u5fae\u4fe1\u670b\u53cb\u5708\u53d1\u5e03\n\u62db\u52df\u5356\u8840\u4eba\u5458\u4fe1\u606f,\u540e\u4e8e7\u670815\u65e57\u65f6\u5728\u5317\u4eac\u5e02\u901a\u5dde\u533a\u5317\u8fd0\u6cb3\u897f\u5730\u94c1\n\u7ad9\u7ec4\u7ec75\u4eba\u524d\u5f80\u901a\u5dde\u533a\u67d0\u8857\u9053\u653f\u52a1\u670d\u52a1\u4e2d\u5fc3\u4e8c\u5c42\u8fdb\u884c\u6709\u507f\u732e\u8840;\u540c\n\u5e747\u670815\u65e512\u65f6\u8bb8,\u88ab\u544a\u4ebaXXX\u5728\u5317\u4eac\u5e02\u660c\u5e73\u533a\u67d0\u5927\u5b66\u9644\u8fd1\u88ab\u6c11\u8b66\u6293\n\u83b7;\u88ab\u544a\u4ebaXXX\u4f5c\u6848\u65f6\u6240\u7528\u624b\u673a\u5df2\u6263\u62bc\u3002\n\u2461\n\u4e0a\n\u8ff0\n\u4e8b\n\u5b9e,\u6709\n\u8bc1\n\u4ebaXXX1\u3001\n\u9ad8\n\u67d0\n\u3001\n\u4efb\n\u67d0\u3001XXX\u3001XXX\u3001XXX\u3001XXX2\u7684\u8bc1\u8a00,\u88ab\u544a\u4ebaXXX\u7684\u4f9b\u8ff0,\u6263\u62bc\n\u7b14\u5f55\u3001\u8fa8\u8ba4\u7b14\u5f55,\u89c6\u542c\u8d44\u6599,\u5fae\u4fe1\u804a\u5929\u8bb0\u5f55\u622a\u56fe,\u53f8\u6cd5\u9274\u5b9a\u610f\u89c1\u4e66,\u63a5\u62a5\n\u6848\u7ecf\u8fc7\u3001\u5230\u6848\u7ecf\u8fc7\u3001\u7834\u6848\u62a5\u544a\u3001\u5317\u4eac\u5e02\u65e0\u507f\u732e\u8840\u767b\u8bb0\u8868\u3001\u6263\u62bc\u51b3\u5b9a\n\u4e66\u3001\u6263\u62bc\u6e05\u5355\u3001\u6237\u7c4d\u4fe1\u606f\u67e5\u8be2\u5355\u3001\u7535\u8bdd\u67e5\u8be2\u8bb0\u5f55\u7b49\u8bc1\u636e\u8bc1\u5b9e,\u8db3\u4ee5\u8ba4\n\u5b9a\u3002\n\u2462\u672c\u9662\u8ba4\u4e3a,\u88ab\u544a\u4ebaXXX\u65e0\u89c6\u6cd5\u5f8b,\u975e\u6cd5\u7ec4\u7ec7\u4ed6\u4eba\u5356\u8840,\u5176\u884c\u4e3a\u5df2\u6784\u6210\n\u975e\u6cd5\u7ec4\u7ec7\u5356\u8840\u7f6a,\u4f9d\u6cd5\u5e94\u4e88\u60e9\u5904\u3002\n\u2463\u516c\u8bc9\u673a\u5173\u6307\u63a7\u7684\u7f6a\u540d\u6210\u7acb\u3002\n\u2464\u88ab\u544a\u4ebaXXX\u5230\u6848\u540e\u5982\u5b9e\u4f9b\u8ff0\u81ea\u5df1\u7684\u72af\u7f6a\u4e8b\u5b9e,\u81ea\u613f\u8ba4\u7f6a\u8ba4\u7f5a,\u4f9d\u6cd5\n\u53ef\u4ee5\u4ece\u8f7b\u5904\u7f5a\u3002\n\u2465\u8fa9\u62a4\u4ebaXXX\u7684\u8fa9\u62a4\u610f\u89c1\u7ecf\u67e5\u5c5e\u5b9e\u4e14\u4e0e\u6cd5\u6709\u636e,\u672c\u9662\u4e88\u4ee5\u91c7\u7eb3\nCase 2\n\u2460\u7ecf\u5ba1\u7406\u67e5\u660e:\u88ab\u544a\u4eba\u6587\u5efa\u4e8e2019\u5e7410\u670818\u65e5,\u5728\u5317\u4eac\u5e02\u671d\u9633\u533a\u56fd\n\u8d38\u7b49\u5730\u975e\u6cd5\u7ec4\u7ec7XXX\u3001XXX\u3001XXX\u3001XXX\u3001XXX\u67d0\u7b49\u4eba\u8fdb\u884c\u5356\n\u8840,\u4e8e10\u670821\u65e5\u5728\u5317\u4eac\u5e02\u987a\u4e49\u533a\u7b2c\u4e8c\u533b\u9662\u975e\u6cd5\u7ec4\u7ec7XXX\u8fdb\u884c\u5356\u8840,\u83b7\n\u5229\u5171\u8ba1\u4eba\u6c11\u5e01700\u5143\u3002\n\u2461\u540eXXX\u88ab***\u67e5\u83b7\u5f52\u6848\u3002\n\u2462\n***\u8d77\u83b7\u4e86XXX\u7684vivo\u724c\u624b\u673a1\u90e8,\u53e6\u8d77\u83b7\u4e86\u624b\u673a3\u90e8\u3001\u7b14\u8bb0\n\u672c1\u672c\u3001\u94f6\u884c\u53618\u5f20,\u73b0\u6263\u62bc\u5728\u6848\u3002\n\u2463\u4e0a\u8ff0\u4e8b\u5b9e,\u88ab\u544a\u4eba\u6587\u5efa\u53ca\u8fa9\u62a4\u4eba\u5728\u5ead\u5ba1\u8fc7\u7a0b\u4e2d\u672a\u63d0\u51fa\u5f02\u8bae,\u4e14\u6709\u8bc1\n\u4ebaXXX\u7b49\u4eba\u7684\u8bc1\u8a00\u3001\u8fa8\u8ba4\u7b14\u5f55\u3001\u732e\u8840\u4eba\u540d\u5355\u7b49\u8bc1\u4ee5\u8bc1\u5b9e,\u8db3\u4ee5\u8ba4\u5b9a\u3002\n\u672c\u9662\u8ba4\u4e3a,\u88ab\u544a\u4eba\u6587\u5efa\u65e0\u89c6\u56fd\u6cd5,\u975e\u6cd5\u7ec4\u7ec7\u4ed6\u4eba\u51fa\u5356\u8840\u6db2,\u5176\u884c\u4e3a\u89e6\u72af\u4e86\n\u5211\u6cd5,\u5df2\u6784\u6210\u975e\u6cd5\u7ec4\u7ec7\u5356\u8840\u7f6a,\u4f9d\u6cd5\u5e94\u4e88\u60e9\u5904\u3002\n\u2464\u5317\u4eac\u5e02\u671d\u9633\u533a\u4eba\u6c11\u68c0\u5bdf\u9662\u6307\u63a7\u88ab\u544a\u4eba\u6587\u5efa\u72af\u975e\u6cd5\u7ec4\u7ec7\u5356\u8840\u7f6a\u7684\u4e8b\n\u5b9e\u6e05\u695a,\u8bc1\u636e\u786e\u5b9e\u3001\u5145\u5206,\u6307\u63a7\u7f6a\u540d\u6210\u7acb\u3002\n\u2465\u88ab\u544a\u4eba\u6587\u5efa\u5f52\u6848\u540e\u5982\u5b9e\u4f9b\u8ff0\u81ea\u5df1\u7684\u7f6a\u884c,\u5f53\u5ead\u8ba4\u7f6a\u8ba4\u7f5a,\u6545\u672c\u9662\u5bf9\u5176\n\u6240\u72af\u7f6a\u884c\u4f9d\u6cd5\u4e88\u4ee5\u4ece\u8f7b\u5904\u7f5a\u3002\n\u2466\u8fa9\u62a4\u4eba\u5173\u4e8e\u6587\u5efa\u83b7\u5229\u4e0d\u591a\u3001\u8ba4\u7f6a\u8ba4\u7f5a\u53ca\u5efa\u8bae\u6cd5\u5ead\u5bf9\u5176\u4ece\u8f7b\u5904\u7f5a\u7684\n\u8fa9\u62a4\u610f\u89c1,\u672c\u9662\u4e88\u4ee5\u91c7\u7eb3;\u5176\u4ed6\u8fa9\u62a4\u610f\u89c1,\u7f3a\u5c11\u4e8b\u5b9e\u6216\u8005\u6cd5\u5f8b\u4f9d\u636e,\u672c\u9662\n\u4e0d\u4e88\u91c7\u7eb3\u3002\n\u2467\u8fa9\u62a4\u4eba\u6587\u5efa\u7684\u72af\u7f6a\u6240\u5f97,\u4f9d\u6cd5\u5e94\u4e88\u6ca1\u6536\u3002\n\u2468\u5728\u6848\u4e4bvivo\u724c\u624b\u673a,\u7cfb\u6587\u5efa\u7684\u72af\u7f6a\u5de5\u5177,\u4f9d\u6cd5\u5e94\u4e88\u6ca1\u6536;\u5728\u6848\u4e4b\u5176\u4ed6\n\u7269\u54c1,\u548c\u6307\u63a7\u4e8b\u5b9e\u65e0\u5173,\u4f9d\u6cd5\u9000\u56de\u516c\u8bc9\u673a\u5173\u3002\n\u2469\u7efc\u4e0a,\u6839\u636e\u88ab\u544a\u4eba\u6587\u5efa\u72af\u7f6a\u7684\u4e8b\u5b9e\u3001\u72af\u7f6a\u7684\u6027\u8d28\u3001\u60c5\u8282\u4ee5\u53ca\u5bf9\u4e8e\u793e\n\u4f1a\u7684\u5371\u5bb3\u7a0b\u5ea6,\u672c\u9662\u4f9d\u7167\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u5211\u6cd5\u300b\u7b2c\u4e09\u767e\u4e09\u5341\u4e09\u6761\u7b2c\n\u4e00\u6b3e\u3001\u7b2c\u516d\u5341\u4e00\u6761\u3001\u7b2c\u516d\u5341\u4e03\u6761\u7b2c\u4e09\u6b3e\u3001\u7b2c\u56db\u5341\u4e94\u6761\u3001\u7b2c\u56db\u5341\u4e03\u6761\u3001\n\u7b2c\u4e94\u5341\u4e8c\u6761\u3001\u7b2c\u4e94\u5341\u4e09\u6761\u3001\u7b2c\u516d\u5341\u56db\u6761\u53ca\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u5211\u4e8b\u8bc9\u8bbc\n\u6cd5\u300b\u7b2c\u5341\u4e94\u6761\u4e4b\u89c4\u5b9a,\u5224\u51b3\u5982\u4e0b:\nGold match label\nmatching\nGold feature sentences of case 1\n\u2460, \u2462, \u2464\nGold feature sentences of case 2\n\u2460, \u2464, \u2466, \u2467\nGold aligned feature sentences\n \u2460-\u2460\uff0c\u2462-\u2464\uff0c\u2464-\u2466\nPredicted match label by our\nframework\nmatching\nPredicted feature sentences of\ncase 1 by our framework\n\u2460, \u2462, \u2464\nPredicted feature sentences of\ncase 2 by our framework\n\u2460, \u2464, \u2466, \u2467\nPredicted aligned feature sen-\ntences by our framework\n \u2460-\u2460\uff0c\u2462-\u2464\uff0c\u2464-\u2466\nPredicted match label by base-\nline method\nmatching\nPredicted feature sentences of\ncase 1 by baseline method\n\u2460, \u2461, \u2462\nPredicted feature sentences of\ncase 2 by baseline method\n\u2460, \u2461, \u2462\nPredicted aligned feature sen-\ntences by baseline method\n \u2460-\u2460\uff0c\u2461-\u2461\uff0c\u2462-\u2462\nSpringer Nature 2021 LATEX template\n16\nAn interpretable similar case matching framework\n# 8 Conclusion\nExisting SCM research has focused on improving the model\u2019s performance but not on its interpretability. Therefore, this paper proposes a pipeline framework for interpretable SCM. The experimental results show the effectiveness of our framework, and our work provides a new benchmark for interpretable SCM. In addition, we suggest that follow-up research should focus on improving the performance of the case matching and feature sentence alignment modules.\n# 9 Acknowledgement\nThis work was supported by the Guangdong Basic and Applied Basic Research Foundation of China (No. 2023A1515012718) and the Philosophy and Social Sciences 14th Five-Year Plan Project of Guangdong Province (No. GD23CTS03).\n# 10 Declarations\n# 10.1 Conflicts of interests\nThe authors declare that we do not have any commercial or associative interest that represents a conflict of interest in connection with the work submitted and that the research do not involve human participants and/or animals.\nData will be made available on request.\n# References\nAn interpretable similar case matching framework\n17\nAn interpretable similar case matching framework\n[14] Peng, D., Yang, J., Lu, J.: Similar case matching with explicit knowledgeenhanced text representation. Applied Soft Computing 95, 106514 (2020). https://doi.org/10.1016/j.asoc.2020.106514\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of interpretability in Similar Case Matching (SCM) tasks, highlighting the lack of explainability in previous studies and the need for a new framework that integrates interpretability with case matching.",
        "problem": {
            "definition": "The problem is the inability of existing SCM methods to provide explanations for case matching results, which can lead to algorithmic discrimination and other social risks.",
            "key obstacle": "The core obstacle is the lack of interpretability in current SCM models, making it difficult for legal professionals to trust and understand the results."
        },
        "idea": {
            "intuition": "The idea is inspired by the need for legal professionals to not only find similar cases but also understand the reasoning behind the matches.",
            "opinion": "The proposed idea is an interpretable pipeline framework for SCM that includes modules for feature sentence identification, case matching, feature sentence alignment, and conflict resolution.",
            "innovation": "The primary innovation lies in the framework's ability to provide explanations for case matches through the identification and alignment of feature sentences, something previous methods did not address."
        },
        "method": {
            "method name": "Interpretable Similar Case Matching Framework",
            "method abbreviation": "ISCMF",
            "method definition": "A framework designed to enhance the interpretability of SCM by extracting feature sentences, matching cases based on these features, and resolving any conflicts in the results.",
            "method description": "The method involves identifying critical feature sentences in legal cases, matching them, and providing aligned evidence of similarity.",
            "method steps": [
                "Identify feature sentences in each case.",
                "Match the cases based on the identified feature sentences.",
                "Align the feature sentences from the matched cases.",
                "Resolve any conflicts between matching and alignment results."
            ],
            "principle": "The method is effective because it focuses on crucial information within cases, allowing for a clearer understanding of why cases are considered similar."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted using the CAIL 2022 Interpretable Similar Case Matching dataset, which includes 1000 labeled samples for evaluation.",
            "evaluation method": "Performance was assessed using Macro-F1 scores for both matching results and feature sentence extraction accuracy."
        },
        "conclusion": "The experimental results demonstrate the effectiveness of the proposed framework, establishing a new benchmark for interpretable SCM and highlighting the need for future research to focus on improving specific modules.",
        "discussion": {
            "advantage": "The key advantage of the proposed approach is its ability to provide explanations for case matches, enhancing trust and understanding for legal professionals.",
            "limitation": "A limitation of the method is that it may still struggle with complex cases where feature sentences are not easily identifiable or alignable.",
            "future work": "Future work should explore enhancements to the case matching and feature sentence alignment modules to further improve their performance."
        },
        "other info": {
            "acknowledgement": "This work was supported by the Guangdong Basic and Applied Basic Research Foundation of China and the Philosophy and Social Sciences 14th Five-Year Plan Project of Guangdong Province.",
            "conflicts of interest": "The authors declare no conflicts of interest in connection with the work submitted."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "Natural Language Processing (NLP) has evolved to address complex tasks, including interpretability in Similar Case Matching (SCM), highlighting its significance in artificial intelligence."
        },
        {
            "section number": "1.2",
            "key information": "The focus of the paper is on the integration of interpretability within SCM tasks, emphasizing the need for explainable case matching frameworks."
        },
        {
            "section number": "2.1",
            "key information": "Key concepts include interpretability in NLP and the importance of explainable models in legal applications to prevent algorithmic discrimination."
        },
        {
            "section number": "3.1",
            "key information": "The proposed interpretable framework for SCM addresses the importance of understanding the reasoning behind case matches, which is essential for improving search accuracy."
        },
        {
            "section number": "3.3",
            "key information": "A limitation noted in current SCM methods is the lack of interpretability, which can lead to distrust among legal professionals."
        },
        {
            "section number": "4.1",
            "key information": "The Interpretable Similar Case Matching Framework (ISCMF) enhances the interpretability of SCM by extracting and aligning feature sentences from legal cases."
        },
        {
            "section number": "5.1",
            "key information": "The ISCMF method involves identifying critical feature sentences in legal cases, which can be considered a neural network architecture approach to information retrieval."
        },
        {
            "section number": "6.1",
            "key information": "The framework's ability to provide explanations for case matches creates synergies between semantic search techniques and neural networks by enhancing understanding."
        },
        {
            "section number": "7.1",
            "key information": "Challenges related to the interpretability of SCM models include scalability and the identification of feature sentences in complex legal cases."
        },
        {
            "section number": "8",
            "key information": "The conclusions drawn emphasize the need for future research to improve specific modules of the ISCMF, highlighting its significance in advancing NLP applications."
        }
    ],
    "similarity_score": 0.5694858869767502,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-12-1934_natur/papers/An interpretability framework for Similar case matching.json"
}