{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2402.13840",
    "title": "LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation",
    "abstract": "Traditional session-based recommendation (SBR) utilizes session behavior sequences from anonymous users for recommendation. Although this strategy is highly efficient, it sacrifices the inherent semantic information of the items, making it difficult for the model to understand the true intent of the session and resulting in a lack of interpretability in the recommended results. Recently, large language models (LLMs) have flourished across various domains, offering a glimpse of hope in addressing the aforementioned challenges. Inspired by the impact of LLMs, research exploring the integration of LLMs with the Recommender system (RS) has surged like mushrooms after rain. However, constrained by high time and space costs, as well as the brief and anonymous nature of session data, the first LLM recommendation framework suitable for industrial deployment has yet to emerge in the field of SBR. To address the aforementioned challenges, we have proposed the LLM Integration Framework for SBR (LLM4SBR). Serving as a lightweight and plug-and-play framework, LLM4SBR adopts a two-step strategy. Firstly, we transform session data into a bimodal form of text and behavior. In the first step, leveraging the inferential capabilities of LLMs, we conduct inference on session text data from different perspectives and design the component for auxiliary enhancement. In the second step, the SBR model is trained on behavior data, aligning and averaging two modal session representations from different perspectives. Finally, we fuse session representations from different perspectives and modalities as the ultimate session",
    "bib_name": "qiao2024llm4sbrlightweighteffectiveframework",
    "md_text": "# LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4b4c/4b4c6bab-dd36-41d3-af77-2f74495955e3.png\" style=\"width: 50%;\"></div>\n21 Feb 2024\n# ABSTRACT\nTraditional session-based recommendation (SBR) utilizes session behavior sequences from anonymous users for recommendation. Although this strategy is highly efficient, it sacrifices the inherent semantic information of the items, making it difficult for the model to understand the true intent of the session and resulting in a lack of interpretability in the recommended results. Recently, large language models (LLMs) have flourished across various domains, offering a glimpse of hope in addressing the aforementioned challenges. Inspired by the impact of LLMs, research exploring the integration of LLMs with the Recommender system (RS) has surged like mushrooms after rain. However, constrained by high time and space costs, as well as the brief and anonymous nature of session data, the first LLM recommendation framework suitable for industrial deployment has yet to emerge in the field of SBR. To address the aforementioned challenges, we have proposed the LLM Integration Framework for SBR (LLM4SBR). Serving as a lightweight and plug-and-play framework, LLM4SBR adopts a two-step strategy. Firstly, we transform session data into a bimodal form of text and behavior. In the first step, leveraging the inferential capabilities of LLMs, we conduct inference on session text data from different perspectives and design the component for auxiliary enhancement. In the second step, the SBR model is trained on behavior data, aligning and averaging two modal session representations from different perspectives. Finally, we fuse session representations from different perspectives and modalities as the ultimate session\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY \u00a9 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/18/06...$15.00 https://doi.org/XXXXXXX.XXXXXXX\nrepresentation for recommendation. We conducted experiments on two real-world datasets, and the results demonstrate that LLM4SBR significantly improves the performance of traditional SBR models and is highly lightweight and efficient, making it suitable for industrial deployment.\n# CCS CONCEPTS\n# \u2022 Information systems \u2192Recommender systems.\nKEYWORDS\nRecommender System; Session-based Recommendation; Large Language Models; Data Augmentation\nACM Reference Format: Shutong Qiao, Chen Gao, Junhao Wen, Wei Zhou, Qun Luo, Peixuan Chen, and Yong Li. 2018. LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation. In Woodstock \u201918: ACM Symposium on Neural Gaze Detection, June 03\u201305, 2018, Woodstock, NY. ACM, New York, NY, USA, 11 pages. https://doi.org/ XXXXXXX.XXXXXXX\n# 1 INTRODUCTION\nThe 21st century is an era of information explosion. Recently, Recommender systems (RS) [14, 27] have received widespread attention from industry and academia as a crucial tool to solve information overload. To achieve personalized and accurate recommendations, RS usually uses the user\u2019s personal information and historical behavior records to model user portraits. As both user privacy concerns and businesses\u2019 demands for accurately capturing user dynamic intent continue to escalate, research on Session-based Recommendation (SBR) [15, 41] has become a crucial aspect of RS, which only relies on the behavior sequence generated by the user within the session time to model, and does not require user profiles. Traditional SBR research [2, 15, 31, 37, 41] is based on the ID-based (behaviorbased) recommendation paradigm. After encoding the items into one-hot features, methods such as Markov chains [29], recurrent\nneural networks (RNN) [28], graph neural networks (GNN) [32], etc., are employed to model anonymous session sequences. While traditional recommendation methods can efficiently and accurately model collaborative information, they often overlook semantic information in interaction behavior, such as item name, price, etc. Particularly in SBR, where sequence lengths are typically short and data sparsity is high, and the SBR model uses one-hot encoding of the item ID to represent the item, which results in a serious lack of correlation between items. Consequently, solely modeling sparse behavioral information is insufficient for understanding users\u2019 true intent. Semantic information, unlike interaction information, inherently possesses similarities and correlations between items. For example, if a user clicks on \"iPhone 15,\" \"running shoes,\" \"iPhone 14,\" \"milk,\" and \"skirt,\" solely modeling behavior might mistakenly prioritize the last few clicks, such as \"milk\" and \"skirt,\" in determining session intent. However, leveraging semantic information, we can analyze that the user in the current session is likely more interested in the Apple product series. Therefore, if we can appropriately infer semantic information within the session, we can better understand the true intent behind the session sequence. With the strong debut of large language models (LLMs) [1, 3, 35, 46], it has not only shaken the entire field of natural language processing (NLP) [5], but also caused turmoil in various fields, and the RS is no exception. LLMs trained on large-scale corpora exhibit robust language comprehension abilities as well as a certain degree of logical reasoning capability. LLMs like GPT-4 are capable of handling complex tasks and engaging in dialogues, inspiring researchers in RS to envision new directions for the future development of RS. But how should RS be combined with LLM? This is the issue that RS researchers are most concerned about. Recently, there has been a proliferation of work exploring the combination of RS and LLM. Some works [6, 11] take advantage of LLM by converting tasks in RS into language understanding or language generation tasks in NLP, through pre-training, fine-tuning, etc. Some researchers [7, 13, 17] have applied LLM to different recommendation system processes to explore LLM\u2019s ability to encode features, sort, and score. The above attempts to combine RS with LLM have achieved many encouraging results, but they are not suitable for SBR. SBR combined with LLM has the following difficulties:\n\u2022 LLM hallucinations are more likely to occur. The sequence length in SBR is typically short, and access to users\u2019 personal information is unavailable. When the information available to the LLM is very limited, the LLM may not be able to generate valid answers or may generate false items that exceed the item set returned. \u2022 A \"repeater\" problem occurred when fine-tuning LLM. Session data is typically augmented through sequence splitting, resulting in datasets containing numerous similar sessions. Consequently, fine-tuning LLMs may lead to instances where the model excessively duplicates input text or repetitively repeats the same sentences when generating responses. \u2022 Training and inferring consume a lot of resources. LLM is complex in calculation takes up a lot of GPU memory, and takes a long time to infer. The recommendation task pursues real-time performance, so LLM-based RS models are difficult to implement in industrial practice.\nTo address these difficulties, we propose a lightweight and effective LLM-enhanced framework framework (LLM4SBR) for SBR. The framework comprises two distinct stages, intent inference and representation enhancement. In the intent inference stage, our framework employs LLM as the inference engine. We guide LLM in inferring through carefully crafted prompts from different perspectives. The intent localization module is crafted to eliminate hallucinations and semantically enhance the reasoning results. Subsequently, these refined outcomes are encoded into an embedded form and stored in external files. Moving on to the representation enhancement stage, the traditional SBR model simultaneously loads interaction data in ID format and intention inference data in text format. On one hand, the SBR model models conversation representations from different perspectives based on interaction data, while on the other hand, it parses text data into embedded forms. Subsequently, alignment and uniformity of session embeddings and inference embeddings are performed separately for each perspective. Finally, all embeddings from all perspectives are fused as the ultimate session representation for prediction. We summarize significant contributions as follows: \u2022 We are the first to propose an LLM enhancement framework for SBR. We divide the LLM inference and SBR model training into two stages. The LLM inference results are saved in an external file in advance, ensuring that GPU usage and training time during training depend only on the SBR model. \u2022 We proposed an intent localization module, which addresses hallucinations and enhances semantic aspects in the preliminary results of LLM inference. In addition, We achieve a finer-grained modal alignment by performing alignment and uniformity between embeddings from different perspectives, facilitating the effective integration of interaction ID information and textual information. \u2022 Experiments on two real-world datasets show that our proposed framework LLM4SBR can be applied to most current SBR models and achieve substantial performance improvements.\n# 2 RELATED WORK\n# 2 RELATED WORK 2.1 Session-based Recommendation\nIn the field of SBR, the available information is very limited, consisting only of interaction data within the session. Therefore, the focus of SBR research lies in how to effectively model interaction behavior and learn session preferences. Based on different modeling emphases, we can broadly categorize SBR methods into two types: traditional SBR methods and methods focusing on modeling item transition relationships. In traditional SBR methods, S-POP [2] recommends based on the most popular items, and Item-KNN [8] calculates item similarity based on historical behavior to recommend similar items. As Markov chains exhibit advantages in modeling sequential data, FPMC [31] captures data sequence information and user preferences by combining first-order Markov chains with matrix factorization. In the SBR methods based on deep learning, inspired by the field of NLP, GRU4Rec [15] proposed for the first time to use of the recurrent neural network (RNN) to simulate user preference changes in behavioral sequence data. Based on this research, Stamp improved\nLLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation\nperformance by introducing an attention mechanism to make preferences more targeted. NARM [19] uses the attention network to capture users\u2019 short-term interests and long-term dependencies. As GNN shows its prowess in various fields, SBR researchers have found that by constructing session data into the form of graphs, they can better capture the complex transformation relationships between items and greatly improve recommendation performance. SR-GNN[41] is the first model to represent sequences in the form of session graphs, utilizing gated graph neural networks as encoders. GC-SAN [43], an upgraded version of SR-GNN, incorporates attention mechanisms to make session representations more targeted. GCE-GNN [39], HADCG [33], MSGAT [30] and KMVG[4] construct multiple graphs with different structures, simultaneously considering both local item collaborations and global session collaboration relationships. In addition, DHCN [42], HL[38], and HIDE [24] captures the complex high-order miscellaneous information of the items by building the hypergraph. Although the aforementioned SBR methods have achieved good performance, they solely rely on modeling the interaction information of sessions, thus lacking effective utilization of semantic information embedded within the sequences.\n# 2.2 Recommender System with LLM\nGenerative dialogue models represented by ChatGPT have caused a stir in research in various fields. According to how LLM participates in the recommendation system, we simply divide it into LLM as Recommender and LLM-enhanced Recommender.\n2.2.1 LLM as Recommender. The model of LLM as Recommender realizes the transformation from the ID paradigm to the modal paradigm by converting the recommendation task into a task in natural language processing. The M6-Rec [6] model extends the pre-trained language model M6 [25] by transforming recommendation tasks into either language understanding or language generation tasks. It establishes a unified foundational recommendation model to reduce downstream tasks\u2019 dependence on data. Shijie Geng et al. [11] proposed the P5 paradigm, which enables predictions in a zero-shot or few-shot manner by providing adaptive personalized prompts tailored to different users. This approach reduces the need for fine-tuning. Wang-cheng Kang et al. [17] evaluated the performance of LLMs of different sizes (250M - 540B parameters) in zero-shot, few-shot, and fine-tuning scenarios to explore the extent to which LLM understands user preferences based on the user\u2019s previous behavior. Sunhao Dai et al. [7] enhance the recommendation capabilities of ChatGPT by combining ChatGPT with traditional information retrieval (IR) ranking functions. GPT4Rec [20] first generates queries based on a language model, and then optimizes product retrieval separately through a search engine, addressing optimization from two aspects. VIP5 [12] explores a multi-modal base model of the P5 recommendation paradigm that considers both visual and textual modalities. Zhu Sun et al. [34] proposed the PO4ISR model of SBR, which promotes LLM to continuously reflect and update the results from the perspective of real-time optimization prompts to improve the accuracy of recommendations. Agent4Rec [47] utilizes a generative agent empowered by LLM to simulate and infer personalized user preferences and behavioral patterns. The core of\nthe above method is to enhance recommendation performance by improving LLM\u2019s adaptability to recommended data and reasoning capabilities. Although these methods have made breakthrough progress in zero-shot, few-shot, and interpretability aspects, they suffer from drawbacks such as high fine-tuning costs and difficulty in capturing specific fine-grained behavioral patterns. Consequently, they face challenges in being deployed in industrial applications.\n2.2.2 LLM-enhanced Recommender. LLM-enhanced RS treats LLM as a tool to enhance the performance of recommendation models. The large-model recommendation framework proposed by Weiwei et al. [40] leverages graph-enhanced strategies based on LLM to enhance RS, addressing challenges posed by data sparsity and low-quality side information in RS. Chat-Rec [10] integrates traditional RS with conversational AI like ChatGPT, eliminating the need for training to gain a deep understanding of user preferences through LLM\u2019s comprehension of dialogue context. CTRL [22] regards the original table data and the corresponding text data as two different modalities, and uses the collaborative CTR model and the pre-trained language model respectively for feature extraction, and adjusts the knowledge of the two modalities through comparative learning. LlamaRec retrieves candidates based on user interaction history through a sequence recommendation model. Candidates and historical records are designed as textual prompts, with the output of LLM transformed into a ranked probability distribution. E4SRec [23] is a solution that combines sequence recommendation with LLMs. It takes only ID sequences as input and ensures efficient controllable generation by predicting all candidate sequences at each forward pass. The above method has made us realize the potential of integrating LLM with RS and how a two-stage framework can better balance efficiency and performance compared to an endto-end framework. Jesse Harte et al. [13] devised three strategies for leveraging LLM, and found that using embeddings initialized with LLM significantly enhances the performance of sequence recommendation models. This inspires us about the importance of textual semantics. The above methods explore the effectiveness of LLM in RS from different perspectives. Compared to the \"LLM as Recommender\" approach, they have greatly improved performance and efficiency. However, these methods do not fully leverage and integrate textual and interaction information, and they are not applicable to SBR scenarios with short sequences and no user information. Considering aspects such as performance, efficiency, and hallucinations of LLMs, effectively integrating LLM with traditional RS models remains a challenging issue. In comparison, our framework is the first plug-and-play LLM framework designed for SBR. It effectively addresses several aspects mentioned above and better meets real-world industrial demands.\n# 3 METHODOLOGY\nThe overall architecture of LLM4SBR is depicted in Figure 1. This section will introduce the problem definition and the specific implementation details of each module in turn.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0bb7/0bb70722-c129-4ffb-bf40-19e1c6307eda.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\nFigure 1: LLM4SBR framework diagram. LLM4SBR is a two-stage framework. In the first stage\u2014the Intent Inference Stage, LLM makes initial inferences based on prompts from different perspectives (long-term and short-term). Subsequently, the intent localization module is utilized to eliminate hallucinations and enhance semantics in the inference results, with the embeddings of the results stored in an external file as text data. Then, in the second stage\u2014Representation Enhancement Stage\u2014interaction data and text data are synchronously loaded into the model. Traditional SBR models are used to model the interaction data to obtain local and global session representations. Meanwhile, we parse the inference embeddings stored in text format for each perspective and restore them to tensor form for subsequent computations. After aligning and uniforming session representations and inference representations of the same perspective, all representations are fused into the final session representation for prediction.\n# 3.1 Problem Formulation\nThe objective of SBR is to predict the next interaction item expected to occur in the current session history of an anonymous user. Here, we provide the problem definition in mathematical terms. Each data entry in the dataset represents a session sequence. Let the collection of all sessions be denoted as S = {\ud835\udc601,\ud835\udc602, \u00b7 \u00b7 \u00b7 ,\ud835\udc60\ud835\udc5a}, where \ud835\udc5ais the total number of sessions. The item set is the summary of items that have appeared in all sessions, which we define as I = {\ud835\udc561,\ud835\udc562, \u00b7 \u00b7 \u00b7 ,\ud835\udc56\ud835\udc5b}, where \ud835\udc5bis the total number of items in the set. We represent the t-th session \ud835\udc60\ud835\udc61in the dataset as \ud835\udc60\ud835\udc61= {\ud835\udc56\ud835\udc61,1,\ud835\udc56\ud835\udc61,2, \u00b7 \u00b7 \u00b7 ,\ud835\udc56\ud835\udc61,\ud835\udc58, \u00b7 \u00b7 \u00b7 ,\ud835\udc56\ud835\udc61,|\ud835\udc60\ud835\udc61|}, where |\ud835\udc60\ud835\udc61| is the length of the current session, and \ud835\udc56\ud835\udc61,\ud835\udc58\u2208I represents the \ud835\udc58-th clicked item in the current session \ud835\udc60\ud835\udc61. Based on the above symbols and descriptions, we define the modeling goal of session\ud835\udc60\ud835\udc61as predicting the click of the |\ud835\udc60\ud835\udc61|+1th item based on the historical behavior records of \ud835\udc60\ud835\udc61.\n# 3.2 Intent Inference Stage\n3.2.1 Prompt Design. At the current stage, the logical reasoning ability of LLM is limited. To achieve more accurate inference, we introduce perspective-limiting qualifiers as auxiliary, enabling LLM\n<div style=\"text-align: center;\"></div>\nto speculate on existing items in a sequence from a specific perspective rather than directly predicting using LLM. Specifically, in our prompt design, we utilize the perspectivelimiting qualifiers based on commonly used behavioral modeling perspectives in SBR (long-term and short-term). By artificially setting them, we decompose the text inference task into finer-grained perspective inference subtasks, thereby maximizing the utilization of LLM\u2019s reasoning capabilities. It is worth noting that the perspective settings are not fixed and can be freely added or removed, endowing the framework with scalability. The specific prompt design is illustrated in Figure 2, where we denote perspective-limiting qualifiers with blue color. A prompt consists of three parts: [background prompt, item name sequence, and task prompt ]. Some studies [16, 21] suggest that ID information helps LLM distinguish between different items more accurately. Inspired by this, we incorporate corresponding ID information after the item names in the prompt design. Therefore, we present the prompt template as follows: \"The order in which users click on items is as follows: 1. ItemName_ItemID\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a662/a662531c-4784-4eed-83d1-8dfb6c40718e.png\" style=\"width: 50%;\"></div>\nLLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation\n<div style=\"text-align: center;\">Figure 2: Illustration of the design of prompts.</div>\n\u00b7 \u00b7 \u00b7 N. ItemName_ItemID Please guess an item that the user is interested in in the (perspectivelimiting qualifiers). (Only output the item name without any explanation.)\"\n3.2.2 LLM Inference. To enhance the effective utilization of semantic information and understand the genuine intent of sessions, we leverage the contextual understanding and logical reasoning capabilities of LLMs to achieve intent inference from different perspectives. In the aspect of selecting large models, we have chosen the Qwen7B 1 model as the inference model after comprehensive consideration of LLM\u2019s inference capability, adaptability to both Chinese and English languages, and model parameter count. It is worth noting that here, the LLM is interchangeable. LLMs with more parameters and stronger reasoning capabilities can produce more accurate inference results. We adopt the form of question and answer, input different perspective prompts as questions to the LLM, and then the LLM returns its inferring results according to the prompts. In addition, to standardize the answers of the LLM, we specially mark \"(Only output the item name without any explanation.)\" in the prompts. 3.2.3 Intent Localization. To assist LLM in eliminating hallucinations and achieving and achieving semantic enhancement, we designed the intent localization module. Although in most cases, the LLM inference result is an accurate item name, sometimes it may be just a vague item category or key project term. In rare cases, a reasonable inference result may not be obtained. The red portion in Figure 3 illustrates the initial inference results of LLM. Inspired by the RAG retrieval model [18], addressing hallucinations in LLM requires providing relevant external knowledge to LLM. The text retrieval scheme of the RAG model is usually based\n3.2.2 LLM Inference. To enhance the effective utilization of semantic information and understand the genuine intent of sessions, we leverage the contextual understanding and logical reasoning capabilities of LLMs to achieve intent inference from different perspectives. In the aspect of selecting large models, we have chosen the Qwen7B 1 model as the inference model after comprehensive consideration of LLM\u2019s inference capability, adaptability to both Chinese and English languages, and model parameter count. It is worth noting that here, the LLM is interchangeable. LLMs with more parameters and stronger reasoning capabilities can produce more accurate inference results. We adopt the form of question and answer, input different perspective prompts as questions to the LLM, and then the LLM returns its inferring results according to the prompts. In addition, to standardize the answers of the LLM, we specially mark \"(Only output the item name without any explanation.)\" in the prompts.\n3.2.3 Intent Localization. To assist LLM in eliminating hallucinations and achieving and achieving semantic enhancement, we designed the intent localization module. Although in most cases, the LLM inference result is an accurate item name, sometimes it may be just a vague item category or key project term. In rare cases, a reasonable inference result may not be obtained. The red portion in Figure 3 illustrates the initial inference results of LLM. Inspired by the RAG retrieval model [18], addressing hallucinations in LLM requires providing relevant external knowledge to LLM. The text retrieval scheme of the RAG model is usually based\n1https://github.com/QwenLM/Qwen\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5fac/5fac37e2-45c0-4734-8c31-59b2e39b1a53.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3: The result of intent localization module.</div>\non the similarity of text embeddings, so we first encode all inference results and the text of the item set into embedding forms using a pre-trained BERT model [9]2.\n(1) (2)\n(1)\n(2)\nwhere \ud835\udc52infer,\ud835\udc52item \u2208R\ud835\udc51\ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61. Then, we compute the cosine similarity scores between each inference result and all item embeddings. Utilizing text embedding similarity, we select the Top-\ud835\udc53most similar actual items from the item set, where \ud835\udc53is a hyperparameter that controls the number of semantically similar items to be filtered. We multiply the embeddings of selected items by their corresponding similarity scores and then sum them up to obtain the inference result of the LLM. Figure 3 illustrates the comparison of inference results before and after using the intent localization module. Finally, the inference results from each perspective undergo hallucinations removal and semantic enhancement through this module. To reduce unnecessary\n2https://huggingface.co/bert-base-uncased\ncomputation time in the next stage, we store the adjusted results\u2019 embeddings in an external file.\n(4)\n\ufffd where \ud835\udc52\ud835\udc56 infer \u2208\ud835\udc38infer is the text embedding of the inference result and \ud835\udc52\ud835\udc56 item \u2208\ud835\udc38item is the text embedding of the item name.\n# 3.3 Representation Enhancement Stage\nAfter the intent inference stage, we move into the representation enhancement phase. In this stage, the SBR model processes behavioral modeling data and parsed inference data. Subsequently, the alignment and uniformity of session embeddings and inference embeddings are conducted separately for each perspective. Ultimately, all perspective inference embeddings are fused with session embeddings to form the final session representation used for prediction. Most of the state-of-the-art (SOTA) models in RS are currently based on the item-ID paradigm. Although this paradigm may sacrifice semantic information, its performance and efficiency are undeniably superior. There is still a long way to go to subvert the ID paradigm. [45] Therefore, we opt to model user behavior based on the item-ID paradigm while simultaneously injecting multimodal information for supplementary enhancement. The SBR model in the framework is interchangeable. In the subsequent experimental section, we also test the performance after replacing SR-GNN with other SBR models.\n3.3.1 SBR Modeling. In this section, we use the SBR model to model interactive information in conversation sequences and learn user behavior preferences. The SBR model here can be replaced arbitrarily. Given that SR-GNN [41] stands as one of the classic models in SBR, and the state-of-the-art (STOA) models in SBR predominantly rely on GNN, this model holds significant importance. Therefore, we primarily select it as the prototype SBR model within the framework for the experimental segment. Specifically, SR-GNN constructs session data into a session graph, where each node in the graph represents a unique item in the session. It utilizes GGNN to learn node features, then takes the last clicked item in the session as the local embedding of the session. It aggregates all node information and utilizes a soft attention mechanism to represent global preferences.\n(5)\nwhere I\ud835\udc61\u2286I represents the set of items interacted with in session at time \ud835\udc61. \ud835\udc3b\ud835\udc59 \ud835\udc61, and \ud835\udc3b\ud835\udc54 \ud835\udc61represent the local embedding and global embedding of session \ud835\udc61respectively.\n3.3.2 Text Embeddings Parsing. In the intent inference stage, we save the inference results\u2019 embeddings in an external file. Therefore, we need to read out the embeddings of the inference, then parse and restore them into tensor form, followed by performing dimension alignment. str\n(6)\nHere, \ud835\udc641 \u2208R\ud835\udc51\u00d7\ud835\udc51\ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61is the weight matrix, and \ud835\udc4f1 \u2208R\ud835\udc51is the bias term. \ud835\udc3bstr infer represents the inference embeddings stored as strings, and Parse denotes the conversion between strings and embeddings using the \"\ud835\udc4e\ud835\udc60\ud835\udc61.\ud835\udc59\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc59_\ud835\udc52\ud835\udc63\ud835\udc4e\ud835\udc59\" function.\n3.3.3 Representation Alignment and Fusion. The SBR model models interaction information within sessions, while LLM employs its knowledge to infer the textual content corresponding to sessions. Although both have the same goal, they are not in a unified embedding space. To better integrate embeddings and enhance session representation quality, we incorporate DirectAU [36] for alignment and uniformity of representation.\n(8)\nL / + / where L\ud835\udc4edenotes alignment loss function and L\ud835\udc62denotes uniformity loss function. For each perspective (long-term, short-term), we separately compute the alignment loss between the inference representation and session representation under that perspective, as well as the uniform loss within each inference representation and each session representation. \u210e\ud835\udc5d infer and \u210e\ud835\udc5d \ud835\udc61represent the inference representation and session representation, respectively, corresponding to the session \ud835\udc61under the same perspective. Then, we fuse the session representations from different perspectives and modalities into the final session representation.\n(9)\nwhere \ud835\udc4a2 \u2208R\ud835\udc51\u00d74\ud835\udc51is a weight matrix. \ud835\udc3b\ud835\udc59 \ud835\udc61is the local preference representation obtained in the SBR model, where the local preference embedding is simply defined as the last clicked item. \ud835\udc3b\ud835\udc54 \ud835\udc61is the global embedding obtained by the SBR model, which is obtained by the soft attention mechanism. For details, please see SR-GNN [41]. Additionally, \ud835\udc3bst infer and \ud835\udc3blt infer represent the short-term and long-term perspective text embeddings of LLM inference, respectively. From this, the four embeddings are compressed into the same embedding space through a linear layer.\n3.3.4 Prediction and Optimization. By taking the item of the session representation and the item representation, scores for each candidate item are obtained. Then, the softmax function is applied to obtain the model\u2019s predicted values \ud835\udc4c.\n(10)\nwhere \u02c6\ud835\udc66\ud835\udc56represents the probability that each item in the itemset becomes the next item in the current session. The loss function for SBR tasks is defined as the cross-entropy between the predicted values and the ground truth, as shown below:\n(11)\n\u2211\ufe01 where \ud835\udc66is the one-hot encoding vector of the ground truth item. Ultimately, the joint learning loss function is composed of both the recommendation loss function and the auxiliary task (alignment and uniformity) loss function.\n(12)\nLLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation\n<div style=\"text-align: center;\">Table 1: Statistics of the utilized datasets.</div>\nDatasets\nTrain\nTest\nClicks\nItems\nAvg.len.\nBeauty\n158,139\n18,000\n198,502\n12,101\n8.66\nML-1M\n47,808\n5,313\n987,610\n3,416\n17.59\nwhere \ud835\udf0fcontrols the proportion of auxiliary tasks.\n# 4 EXPERIMENTS\n# 4.1 Experimental Settings\n4.1.1 Datasets. We initially hoped to validate the performance using commonly used datasets in SBR, as they are more representative. Unfortunately, we couldn\u2019t find any session datasets that provide both interaction ID sequences and item name information. Taking this into consideration, we opted for Beauty3 and MovieLens-1M (ML-1M)4 datasets, which are the closest in format. The details of these two datasets are shown in Table 1. For both datasets, we adhere [19, 41] to removing sessions with a length of 1 and items that appear fewer than 5 times across all sessions. \u2022 Beauty dataset comprises evaluations and ratings from users on various beauty products. We treat all ratings sequences from a single user as a session sequence. We enhance the dataset using the commonly employed sequence segmentation method [19, 26, 41] in SBR. For instance, consider an original session \ud835\udc60= [\ud835\udc56\ud835\udc61,1,\ud835\udc56\ud835\udc61,2, \u00b7 \u00b7 \u00b7 ,\ud835\udc56\ud835\udc61,\ud835\udc5b]. After segmentation by sequence, we obtain ([\ud835\udc56\ud835\udc61,1],\ud835\udc56\ud835\udc61,2), ([\ud835\udc56\ud835\udc61,1,\ud835\udc56\ud835\udc61,2],\ud835\udc56\ud835\udc61,3), \u00b7 \u00b7 \u00b7 ,([\ud835\udc56\ud835\udc61,1,\ud835\udc56\ud835\udc61,2, \u00b7 \u00b7 \u00b7 ,\ud835\udc56\ud835\udc61,\ud835\udc5b\u22121],\ud835\udc56\ud835\udc61,\ud835\udc5b). \u2022 ML-1M dataset consists of over 1 million ratings from more than 6, 000 users on over 4, 000 movies. Considering our research question, we partition the movie rating data of the same user in this dataset into multiple session sequences using a 10-minute interval as the splitting point.\n4.1.2 Evaluation metrics. In terms of the evaluation indicators used in the experiment, We chose the most commonly used ones in SBR tasks: Precision (P) @\ud835\udc3eand Mean reciprocal rank (MRR) @\ud835\udc3e. After referring to the classic work [39, 42] in recent years, we set the length of the candidate set @\ud835\udc3eto 5, 10, and 20, which is the most meaningful for comparison.\n4.1.3 Parameter Settings. All experiments were conducted on NVIDI A100 GPUs. For fairness in performance comparison, the optimizer used throughout the experiments was unified as Adam with a learning rate of 0.001, decayed by 0.1 every three epochs, and an \ud835\udc3f2 penalty set to 10\u22125. For the SBR model involved in the experiments, the batch size is 100 and the dimension size is 100. \ud835\udf0fis set to 0.1. We initially set the hyperparameter \ud835\udc53in the intent localization module to 5, and subsequent hyperparameter experiments 4.4 will discuss the optimal value. We followed the optimal parameter settings as published in their paper for the remaining parameters.\n# 4.2 Performance Experiment and Analysis\nIn this section, we mainly compare the performance of the SBR model and the corresponding SBR model applying the LLM framework under different Top-\ud835\udc3e.\n3https://jmcauley.ucsd.edu/data/amazon/links.html 4https://grouplens.org/datasets/movielens/\n4.2.1 Backbone. To validate the effectiveness of the framework, we selected four classic models from SBR to replace the SBR model in the framework and compared the performance between each pair. The introduction of the SBR models is as follows: \u2022 SR-GNN [41] is the first model to construct data into session graphs, utilizing GGNN to capture complex transition relationships among items. \u2022 TAGNN [44] adds a target-sensitive attention mechanism based on SR-GNN. \u2022 GCE-GNN [39] constructs session graphs and global graphs respectively, and learns relevant information from the item level and session level. \u2022 \ud835\udc462-DHCN [42] uses hypergraph convolution to learn high-order relationships in item sequences, and uses self-supervised learning to alleviate the data sparse problem of hypergraphs. The comparison results of the overall performance experiments are shown in Table 2. We record the performance with K set to 5, 10, 20. It is worth noting that in the evaluation system of RS, smaller \ud835\udc3evalues are more significant. From the results displayed in Table 2, we draw the following observations: \u2022 LLM4SBR significantly improves backbone performance. In the models enhanced through the LLM framework, all demonstrate performance improvement. This confirms that the text representations derived from LLM inference contain rich and valuable information, which can greatly help the SBR model understand the potential intention of the conversation data. \u2022 LLM4SBR has a greater improvement for smaller \ud835\udc3evalues. For example, LLM4SBR (TAGNN) improved the P@5 index of the two data sets by 27.28% and 107.5% respectively. We believe this is due to the semantic enhancement achieved by LLM4SBR during the intent localization stage, where it utilizes \ud835\udc53similar semantic items. Consequently, it results in more accurate predictions for the top few items in the predicted candidate set. We also observe slight decreases in performance for \ud835\udc462-DHCN and GCE-GNN on a few metrics (\ud835\udc43@20 and \ud835\udc40\ud835\udc45\ud835\udc45@20) after integrating with the framework. We posit that when the original SBR model already effectively models the data, enhancing the inference information through the intent localization module may introduce noise. Compared to the improvement magnitude, the decrease is very slight. Moreover, since noise issues can be effectively controlled by adjusting the hyperparameter \ud835\udc53in the intent localization module, the negative impact can be almost negligible. \u2022 LLM4SBR can compensate for poor modeling caused by a lack of interactive information. GCE-GNN captures effective information at both the item and session levels by constructing global graphs and session graphs simultaneously, due to the model\u2019s complex computations, in scenarios with limited data volume, it becomes challenging for this model to learn effective session representations. LLM4SBR (GCE-GNN) showed the greatest improvement, especially on the ML-1M dataset, P@5, P@10, and P@20 increased by 37.59%, 96.2%, and 128.54% respectively. We attribute this to the effective text information obtained from LLM inference, which compensates for the information scarcity in GCE-GNN\u2019s session modeling, allowing it to achieve better performance. In addition, The architectures of SR-GNN\nThe comparison results of the overall performance experiments are shown in Table 2. We record the performance with K set to 5, 10, 20. It is worth noting that in the evaluation system of RS, smaller \ud835\udc3evalues are more significant. From the results displayed in Table 2, we draw the following observations:\n# \u2022 LLM4SBR significantly improves backbone performan In the models enhanced through the LLM framework, all demo\nlack of interactive information. GCE-GNN captures effective information at both the item and session levels by constructing global graphs and session graphs simultaneously, due to the model\u2019s complex computations, in scenarios with limited data volume, it becomes challenging for this model to learn effective session representations. LLM4SBR (GCE-GNN) showed the greatest improvement, especially on the ML-1M dataset, P@5, P@10, and P@20 increased by 37.59%, 96.2%, and 128.54% respectively. We attribute this to the effective text information obtained from LLM inference, which compensates for the information scarcity in GCE-GNN\u2019s session modeling, allowing it to achieve better performance. In addition, The architectures of SR-GNN\n<div style=\"text-align: center;\">Table 2: Performance comparison experimental results (%).</div>\nDataset\nBeauty\nML-1M\nModel\n\ud835\udc43@5\n\ud835\udc43@10\n\ud835\udc43@20\n\ud835\udc40\ud835\udc45\ud835\udc45@5\n\ud835\udc40\ud835\udc45\ud835\udc45@10\n\ud835\udc40\ud835\udc45\ud835\udc45@20\n\ud835\udc43@5\n\ud835\udc43@10\n\ud835\udc43@20\n\ud835\udc40\ud835\udc45\ud835\udc45@5\n\ud835\udc40\ud835\udc45\ud835\udc45@10\n\ud835\udc40\ud835\udc45\ud835\udc45@20\nSR-GNN\n6.30\n10.02\n14.86\n3.18\n3.70\n3.99\n4.29\n8.64\n13.01\n2.16\n3.09\n3.19\nLLM4SBR(SR-GNN)\n7.58\n11.29\n16.30\n4.34\n4.62\n5.00\n7.38\n11.52\n17.54\n4.06\n4.55\n5.26\nSR-GNN Improv.\n20.31%\n12.67%\n9.69%\n36.47%\n24.86%\n25.31%\n72.02%\n33.33%\n34.82%\n87.96%\n47.25%\n64.89%\nTAGNN\n6.12\n10.06\n15.23\n3.10\n3.63\n3.97\n3.60\n6.19\n10.28\n1.77\n2.15\n2.23\nLLM4SBR(TAGNN)\n7.79\n11.79\n16.76\n4.39\n4.78\n5.05\n7.47\n12.33\n18.60\n4.03\n4.79\n4.87\nTAGNN Improv.\n27.28%\n17.19%\n10.04%\n41.61%\n31.68%\n27.20%\n107.5%\n99.19%\n80.93%\n127.68%\n122.79%\n118.38%\nGCE-GNN\n6.39\n8.93\n12.38\n3.97\n4.30\n4.54\n5.16\n6.85\n9.67\n3.18\n3.41\n3.60\nLLM4SBR(GCE-GNN)\n7.75\n12.48\n18.08\n3.91\n4.41\n4.80\n7.10\n13.44\n22.10\n3.14\n3.63\n4.21\nGCE-GNN Improv.\n21.28%\n39.75%\n46.04%\n-1.51%\n2.56%\n5.73%\n37.59%\n96.20%\n128.54%\n-1.25%\n6.45%\n16.94%\n\ud835\udc462-DHCN\n7.14\n11.97\n17.54\n2.97\n3.61\n3.99\n8.35\n14.55\n23.38\n3.66\n4.51\n5.09\nLLM4SBR(\ud835\udc462-DHCN)\n7.77\n11.85\n17.48\n4.26\n4.79\n5.15\n9.54\n15.31\n22.67\n5.13\n5.91\n6.40\n\ud835\udc462-DHCN Improv.\n8.82%\n-1.00%\n-0.34%\n43.43%\n32.68%\n29.07%\n14.25%\n5.22%\n-3.03%\n40.16%\n31.04%\n25.73%\n* We highlight the best performance values for each metric in bold and underscore the best values within the backbones\nand TAGNN are based on directed session graphs, utilizing GNN to capture complex transition relationships between items. However, limited by the number of layers in GNNs, both of these models struggle to effectively capture useful information from long-term items. After adding LLM4SBR, both of the above two models have achieved substantial performance improvements. Inference information from a long-term perspective solves the problem of insufficient capture of long-term dependencies in the model. In conclusion, the effectiveness of the LLM4SBR framework is ndeniable. As a plug-and-play framework, it significantly enhances he prediction accuracy of traditional SBR models.\n# 4.3 Ablation Experiment and Analysis\nTo examine the necessity and relative importance of the long-term and short-term inference perspectives, we designed two variants: LLM4SBR w/o Long and LLM4SBR w/o Short. LLM4SBR w/o Long indicates inference without considering the long-term perspective, retaining only the short-term perspective. Conversely, LLM4SBR w/o Short retains only the long-term perspective and removes the short-term perspective during inference. We compared the performance of these two variants with the whole performance and visualized the comparison as a bar chart to clearly illustrate the differences between them. Through observation and analysis of Figure 4, we summarized the following conclusions:\n# \u2022 Both long-term and short-term perspectives\n# \u2022 Both long-term and\n<div style=\"text-align: center;\">ML-1M</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1a7e/1a7e8417-0e86-4b29-944f-916e4bbaaae8.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Inference perspective ablation experiment results</div>\ndiscussion and analysis, we attribute this performance difference to the length of the dataset sessions. Session intent in short sequences is usually relatively stable, and the intent is mainly reflected in the last few clicks. This underscores the increased importance of accurately modeling short-term interests in shortsession scenarios. However, as the session length increases, the session intent is influenced by various factors, thereby increasing the importance of long-term dependency relationships within the session. Finally, we believe that considering the inference results of multiple perspectives simultaneously can enhance the stability of the framework\u2019s performance, making it adaptable to datasets with varying session lengths.\nLLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation\n<div style=\"text-align: center;\">Table 3: The result of space occupation experiment</div>\nModel\nOccupies video memory (M)\nDataset\nBeauty\nML-1M\nSR-GNN\n1,314\n1,224\nLLM4SBR(SR-GNN)\n1,330\n1,304\n# 4.4 Hyperparameter Experiment and Analysis\nIn this section, we discuss the hyperparameter \ud835\udc53set within the intent localization module. This hyperparameter is designed to eliminate hallucination and enhance semantics in the preliminary inference results of LLM, using a candidate set of items with similar semantics. The hyperparameter \ud835\udc53is configured to control the range of selecting items with similar semantics. The value of \ud835\udc53is set to 0, 1, 3, and 5, and we discuss four scenarios accordingly: (1) directly utilizing the inference results of LLM, (2) eliminating hallucination using the most similar item, (3) eliminating hallucination and enhancing semantics using the Top-3 most similar items, and (4) eliminating hallucination and enhancing semantics using the Top-5 most similar items. The experimental results are shown in Figure 5. Firstly, across all three plots, although the optimal hyperparameter values differ for each plot, we can see that the performance is consistently the worst when \ud835\udc53= 0. We believe this is logical and demonstrates the necessity of the intent localization module in the framework. If the results of LLM inference are not processed, hallucinations occurring in some session data may lead to a decrease in the overall framework performance. Taking a closer look at the local details, in Figures 5a and 5b, the performance peaks when \ud835\udc53= 1, with \ud835\udc43@5 and \ud835\udc43@10 being 7.69 and 11.48 respectively. However, in Figure 5c, a notable peak is observed when \ud835\udc53= 3, achieving the best performance with \ud835\udc43@20 is 18.56. When the value of \ud835\udc3eis relatively small (\ud835\udc3e= 5, \ud835\udc3e= 10), the performance is best when \ud835\udc53= 1. We believe this is because utilizing multiple similar items for semantic enhancement of intent may introduce noise, thereby leading to a slight performance decrease. As the value of \ud835\udc3eincreases, the performance of the \ud835\udc53= 3 and \ud835\udc53= 5 becomes similar, both surpass \ud835\udc53= 1. This suggests that introducing multiple similarly named items appropriately can increase the diversity of candidate items while enhancing performance. In summary, values of \ud835\udc53ranging from 1 to 5 are all effective. Depending on the requirements for different values of \ud835\udc3e, selecting different values of \ud835\udc53can better leverage the module\u2019s effectiveness.\n# 4.5 Space Occupation Experiment and Analysis\nRecommendation models based on LLM often require a large amount of video memory. To explore the spatial effectiveness of the LLM4SBR framework, we recorded the memory usage of SR-GNN and LLM4SBR (SR-GNN). The results are shown in Table 3, the memory usage rates of the two are very close. Through the two-stage strategy, LLM inference is performed only once in the first stage, and then the inference results are stored in an external file. During the second stage of SBR model training, the memory consumption is limited to the original SBR model, the ID sequence data, and the pre-stored inference\nRecommendation models based on LLM often require a large amount of video memory. To explore the spatial effectiveness of the LLM4SBR framework, we recorded the memory usage of SR-GNN and LLM4SBR (SR-GNN).\nThe results are shown in Table 3, the memory usage rates of the two are very close. Through the two-stage strategy, LLM inference is performed only once in the first stage, and then the inference results are stored in an external file. During the second stage of SBR model training, the memory consumption is limited to the original SBR model, the ID sequence data, and the pre-stored inference\nembeddings, significantly reducing memory usage. Additionally, since the second stage only requires parsing the stored inference embeddings into tensors, its increased time complexity is \ud835\udc42(1), the model\u2019s time complexity mainly depends on the original SBR model. Taking into account time and space factors, the LLM4SBR framework we proposed can be implemented in industrial environments.\n# 5 CONCLUSIONS AND FUTURE WORK\nIn this paper, we explore the feasibility of combining LLM with SBR models while considering both effectiveness and efficiency. In short sequence data, LLM can infer preferences directly leveraging its language understanding capability without fine-tuning. This approach is more efficient in utilizing information compared to encoding text data into embeddings for training, and it allows us to place LLM and SBR in separate stages, greatly reducing training costs. Regarding the LLM hallucination, we found that it can be corrected through the similarity of text embeddings, and enhancement with similar samples can improve the diversity of inference results to a certain extent. In addition, we propose a scalable two-stage LLM enhancement framework (LLM4SBR) tailored for SBR. Specifically, in the semantic reasoning phase, we utilize LLM as the inference engine, designing prompt-guided inference processes from different perspectives and leveraging an intent localization module to eliminate LLM hallucinations and achieve semantic enhancement. In the representation enhancement stage, we perform fine-grained alignment and uniformity of text embeddings and session embeddings from different perspectives. This effectively facilitates the fusion of representations from different modalities, thereby enhancing the final session representation. Extensive experiments have demonstrated the effectiveness of the LLM4SBR framework, which significantly enhances most SBR models while also improving model interpretability and enhancing the diversity of candidate selection. For future work, we will continue exploring whether adding additional LLM inference perspectives can yield greater benefits, as well as assessing the effectiveness of utilizing LLM Agent for logical reasoning. In addition, we also want to explore the application of other downstream tasks combined with LLM. Finally, we hope for this work to open up new avenues in SBR research, accelerating deeper exploration into the integration of LLM with RS.\n# REFERENCES\n[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023). [2] Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE transactions on knowledge and data engineering 17, 6 (2005), 734\u2013749. [3] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023. Qwen Technical Report. arXiv preprint arXiv:2309.16609 (2023). [4] Qian Chen, Zhiqiang Guo, Jianjun Li, and Guohui Li. 2023. Knowledge-enhanced multi-view graph neural networks for session-based recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a97a/a97a557a-6423-41fb-999c-6224e900753f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Hyperparameter experimental results of different f settings of the Intent positioning module on ML-1M</div>\nin Information Retrieval. 352\u2013361. [5] KR1442 Chowdhary and KR Chowdhary. 2020. Natural language processing. Fundamentals of artificial intelligence (2020), 603\u2013649. [6] Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou, and Hongxia Yang. 2022. M6-rec: Generative pretrained language models are open-ended recommender systems. arXiv preprint arXiv:2205.08084 (2022). [7] Sunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao Zhang, and Jun Xu. 2023. Uncovering ChatGPT\u2019s Capabilities in Recommender Systems. arXiv preprint arXiv:2305.02182 (2023). [8] James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al. 2010. The YouTube video recommendation system. In Proceedings of the fourth ACM conference on Recommender systems. 293\u2013296. [9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018). [10] Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei Zhang. 2023. Chat-rec: Towards interactive and explainable llms-augmented recommender system. arXiv preprint arXiv:2303.14524 (2023). [11] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5). In Proceedings of the 16th ACM Conference on Recommender Systems. 299\u2013315. [12] Shijie Geng, Juntao Tan, Shuchang Liu, Zuohui Fu, and Yongfeng Zhang. 2023. VIP5: Towards Multimodal Foundation Models for Recommendation. arXiv preprint arXiv:2305.14302 (2023). [13] Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos, Dietmar Jannach, and Marios Fragkoulis. 2023. Leveraging large language models for sequential recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems. 1096\u20131102. [14] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web. 173\u2013182. [15] Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015). [16] Wenyue Hua, Shuyuan Xu, Yingqiang Ge, and Yongfeng Zhang. 2023. How to Index Item IDs for Recommendation Foundation Models. arXiv preprint arXiv:2305.06569 (2023). [17] Wang-Cheng Kang, Jianmo Ni, Nikhil Mehta, Maheswaran Sathiamoorthy, Lichan Hong, Ed Chi, and Derek Zhiyuan Cheng. 2023. Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction. arXiv preprint arXiv:2305.06474 (2023). [18] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33 (2020), 9459\u20139474. [19] Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural attentive session-based recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. 1419\u20131428. [20] Jinming Li, Wentao Zhang, Tian Wang, Guanglei Xiong, Alan Lu, and Gerard Medioni. 2023. GPT4Rec: A generative framework for personalized recommendation and user interests interpretation. arXiv preprint arXiv:2304.03879 (2023). [21] Lei Li, Yongfeng Zhang, and Li Chen. 2023. Prompt distillation for efficient llmbased recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management. 1348\u20131357.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2076/2076ebb0-2ec9-499f-a824-31ee36db6d0f.png\" style=\"width: 50%;\"></div>\n[22] Xiangyang Li, Bo Chen, Lu Hou, and Ruiming Tang. 2023. CTRL: Connect Tabular and Language Model for CTR Prediction. arXiv preprint arXiv:2306.02841 (2023). [23] Xinhang Li, Chong Chen, Xiangyu Zhao, Yong Zhang, and Chunxiao Xing. 2023. E4SRec: An Elegant Effective Efficient Extensible Solution of Large Language Models for Sequential Recommendation. arXiv preprint arXiv:2312.02443 (2023). [24] Yinfeng Li, Chen Gao, Hengliang Luo, Depeng Jin, and Yong Li. 2022. Enhancing Hypergraph Neural Networks with Intent Disentanglement for Session-based Recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval. 1997\u20132002. [25] Junyang Lin, Rui Men, An Yang, Chang Zhou, Yichang Zhang, Peng Wang, Jingren Zhou, Jie Tang, and Hongxia Yang. 2021. M6: Multi-modality-to-multi-modality multitask mega-transformer for unified pretraining. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 3251\u20133261. [26] Qiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018. STAMP: shortterm attention/memory priority model for session-based recommendation. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining. 1831\u20131839. [27] Jie Lu, Dianshuang Wu, Mingsong Mao, Wei Wang, and Guangquan Zhang. 2015. Recommender system application developments: a survey. Decision support systems 74 (2015), 12\u201332. [28] Danilo Mandic and Jonathon Chambers. 2001. Recurrent neural networks for prediction: learning algorithms, architectures and stability. Wiley. [29] James R Norris. 1998. Markov chains. Number 2. Cambridge university press. [30] Shutong Qiao, Wei Zhou, Junhao Wen, Hongyu Zhang, and Min Gao. 2023. Bichannel Multiple Sparse Graph Attention Networks for Session-based Recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management. 2075\u20132084. [31] Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing personalized markov chains for next-basket recommendation. In Proceedings of the 19th international conference on World wide web. 811\u2013820. [32] Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2008. The graph neural network model. IEEE transactions on neural networks 20, 1 (2008), 61\u201380. [33] Jiajie Su, Chaochao Chen, Weiming Liu, Fei Wu, Xiaolin Zheng, and Haoming Lyu. 2023. Enhancing Hierarchy-Aware Graph Networks with Deep Dual Clustering for Session-based Recommendation. In Proceedings of the ACM Web Conference 2023. 165\u2013176. [34] Zhu Sun, Hongyang Liu, Xinghua Qu, Kaidong Feng, Yan Wang, and Yew-Soon Ong. 2023. Large Language Models for Intent-Driven Session Recommendations. arXiv preprint arXiv:2312.07552 (2023). [35] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023). [36] Chenyang Wang, Yuanqing Yu, Weizhi Ma, Min Zhang, Chong Chen, Yiqun Liu, and Shaoping Ma. 2022. Towards representation alignment and uniformity in collaborative filtering. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 1816\u20131825. [37] Meirui Wang, Pengjie Ren, Lei Mei, Zhumin Chen, Jun Ma, and Maarten de Rijke. 2019. A collaborative session-based recommendation approach with parallel memory modules. In Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval. 345\u2013354. [38] Nan Wang, Shoujin Wang, Yan Wang, Quan Z Sheng, and Mehmet A Orgun. 2022. Exploiting intra-and inter-session dependencies for session-based recommendations. World Wide Web 25, 1 (2022), 425\u2013443. [39] Ziyang Wang, Wei Wei, Gao Cong, Xiao-Li Li, Xian-Ling Mao, and Minghui Qiu. 2020. Global context enhanced graph neural networks for session-based\nLLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation\nrecommendation. In Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval. 169\u2013178. [40] Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2023. Llmrec: Large language models with graph augmentation for recommendation. arXiv preprint arXiv:2311.00423 (2023). [41] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In Proceedings of the AAAI conference on artificial intelligence, Vol. 33. 346\u2013353. [42] Xin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Lizhen Cui, and Xiangliang Zhang. 2021. Self-supervised hypergraph convolutional networks for sessionbased recommendation. In Proceedings of the AAAI conference on artificial intelligence, Vol. 35. 4503\u20134511. [43] Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. 2019. Graph contextualized selfattention network for session-based recommendation.. In IJCAI, Vol. 19. 3940\u2013 3946.\n[44] Feng Yu, Yanqiao Zhu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2020. TAGNN: target attentive graph neural networks for session-based recommendation. In Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval. 1921\u20131924. [45] Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023. Where to go next for recommender systems? id-vs. modality-based recommender models revisited. arXiv preprint arXiv:2303.13835 (2023). [46] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414 (2022). [47] An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng Chua. 2023. On generative agents in recommendation. arXiv preprint arXiv:2310.10108 (2023).\n",
    "paper_type": "method",
    "attri": {
        "background": "Traditional session-based recommendation (SBR) utilizes session behavior sequences from anonymous users for recommendation. Although this strategy is highly efficient, it sacrifices the inherent semantic information of the items, making it difficult for the model to understand the true intent of the session and resulting in a lack of interpretability in the recommended results.",
        "problem": {
            "definition": "The problem addressed in this paper is the inability of traditional SBR methods to effectively incorporate semantic information from session data, which limits their interpretability and understanding of user intent.",
            "key obstacle": "The main difficulty is that existing methods rely solely on behavioral data, leading to a lack of correlation between items and insufficient understanding of the user's true intent."
        },
        "idea": {
            "intuition": "The idea is inspired by the capabilities of large language models (LLMs) to incorporate semantic understanding into the recommendation process, thus enhancing the interpretability and effectiveness of SBR.",
            "opinion": "The proposed idea, LLM4SBR, involves integrating LLMs into a two-step framework for session-based recommendation, allowing for better semantic inference and user intent understanding.",
            "innovation": "The key innovation of LLM4SBR lies in its two-stage approach that separates the LLM inference from the SBR model training, allowing for efficient resource usage while enhancing the recommendation process."
        },
        "method": {
            "method name": "LLM Integration Framework for SBR",
            "method abbreviation": "LLM4SBR",
            "method definition": "LLM4SBR is a lightweight framework that enhances session-based recommendation by integrating large language models to infer user intent and improve recommendation quality.",
            "method description": "The core of LLM4SBR involves transforming session data into a bimodal form of text and behavior, conducting inference on session text data, and training the SBR model on behavior data.",
            "method steps": [
                "Transform session data into bimodal text and behavior forms.",
                "Conduct inference on session text data using LLMs.",
                "Train the SBR model on behavior data while aligning and averaging session representations.",
                "Fuse session representations from different perspectives for final predictions."
            ],
            "principle": "This method is effective because it leverages the semantic understanding capabilities of LLMs, allowing for a more nuanced interpretation of user behavior and intent in session-based recommendations."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted on two real-world datasets: Beauty and ML-1M, comparing the performance of traditional SBR models with the LLM4SBR framework.",
            "evaluation method": "Performance was assessed using Precision and Mean Reciprocal Rank (MRR) metrics at various candidate set sizes (K=5, 10, 20)."
        },
        "conclusion": "The experiments demonstrated that LLM4SBR significantly enhances the performance of traditional SBR models, improving their interpretability and efficiency in real-world applications.",
        "discussion": {
            "advantage": "The main advantages of LLM4SBR include its ability to effectively integrate semantic information, enhance interpretability, and improve the overall performance of SBR models.",
            "limitation": "One limitation is the potential for noise introduced by the intent localization module, which may affect performance if not properly managed.",
            "future work": "Future research will explore additional LLM inference perspectives and the application of LLMs in other downstream tasks to further enhance recommendation systems."
        },
        "other info": [
            {
                "info1": "The framework is designed as a plug-and-play solution for SBR models.",
                "info2": {
                    "info2.1": "LLM4SBR can be adapted for various traditional SBR models.",
                    "info2.2": "The framework is scalable and can accommodate different session lengths and user behaviors."
                }
            }
        ]
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "Recommendation algorithms are significant as they enhance user experience by providing personalized suggestions based on user behavior and preferences."
        },
        {
            "section number": "1.2",
            "key information": "The integration of large language models (LLMs) into session-based recommendation systems allows for better semantic inference and understanding of user intent."
        },
        {
            "section number": "2.1",
            "key information": "Traditional session-based recommendation (SBR) utilizes session behavior sequences from anonymous users for recommendation, but lacks the incorporation of semantic information."
        },
        {
            "section number": "2.2",
            "key information": "The evolution of recommendation systems includes the transition from traditional methods that rely solely on behavioral data to approaches that integrate semantic understanding."
        },
        {
            "section number": "3.1",
            "key information": "Traditional SBR methods focus on user behavior but often sacrifice interpretability due to the lack of semantic information."
        },
        {
            "section number": "4.1",
            "key information": "LLM4SBR leverages the capabilities of LLMs to enhance session-based recommendations by incorporating semantic understanding."
        },
        {
            "section number": "4.2",
            "key information": "The LLM Integration Framework for SBR (LLM4SBR) is designed to improve recommendation quality by inferring user intent through LLMs."
        },
        {
            "section number": "5.1",
            "key information": "NLP techniques can be utilized to interpret user preferences more effectively by integrating semantic information into the recommendation process."
        },
        {
            "section number": "6.1",
            "key information": "LLM4SBR can be seen as an innovative approach to enhancing collaborative filtering methods by incorporating semantic understanding into user behavior analysis."
        },
        {
            "section number": "10.1",
            "key information": "Current challenges in conventional recommendation systems include the inability to effectively incorporate semantic information, limiting interpretability and user intent understanding."
        },
        {
            "section number": "11",
            "key information": "The findings indicate that LLM4SBR significantly enhances the performance of traditional SBR models, improving interpretability and efficiency in real-world applications."
        }
    ],
    "similarity_score": 0.7441932462173598,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/LLM4SBR_ A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation.json"
}