{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1911.10003",
    "title": "Locality Constraint Dictionary Learning with Support Vector for Pattern Classification",
    "abstract": "Discriminative dictionary learning (DDL) has recently gained significant attention due to its impressive performance in various pattern classification tasks. However, the locality of atoms is not fully explored in conventional DDL approaches which hampers their classification performance. In this paper, we propose a locality constraint dictionary learning with support vector discriminative term (LCDL-SV), in which the locality information is preserved by employing the graph Laplacian matrix of the learned dictionary. To jointly learn a classifier during the training phase, a support vector discriminative term is incorporated into the proposed objective function. Moreover, in the classification stage, the identity of test data is jointly determined by the regularized residual and the learned multi-class support vector machine. Finally, the resulting optimization problem is solved by utilizing the alternative strategy. Experimental results on benchmark databases demonstrate the superiority of our proposed method over previous dictionary learning approaches on both hand-crafted and deep features. The source code of our proposed LCDL-SV is accessible at https://github.com/yinhefeng/LCDL-SV",
    "bib_name": "yin2019localityconstraintdictionarylearning",
    "md_text": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000. Digital Object Identifier 10.1109/ACCESS.2017.DOI\n# Locality Constraint Dictionary Learning with Support Vector for Pattern Classification\nHE-FENG YIN1,2, XIAO-JUN WU1,2, AND SU-GEN CHEN3\n1School of Internet of Things Engineering, Jiangnan University, Wuxi 214122, China 2Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi 214122, China 3School of Mathematics and Computational Science, Anqing Normal University, Anqing 246133, China Corresponding author: Xiao-Jun Wu (e-mail: wu_xiaojun@jiangnan.edu.cn)  2019\nThis work was supported by the National Natural Science Foundation of China (Grant No. 61672265, U1836218, 61702012), the 111 Project of Ministry of Education of China (Grant No. B12018), the Postgraduate Research & Practice Innovation Program of Jiangsu Province under Grant No. KYLX_1123, the Overseas Studies Program for Postgraduates of Jiangnan University and the China Scholarshi Council (CSC, No.201706790096). 2 Nov\nABSTRACT Discriminative dictionary learning (DDL) has recently gained significant attention due to its impressive performance in various pattern classification tasks. However, the locality of atoms is not fully explored in conventional DDL approaches which hampers their classification performance. In this paper, we propose a locality constraint dictionary learning with support vector discriminative term (LCDLSV), in which the locality information is preserved by employing the graph Laplacian matrix of the learned dictionary. To jointly learn a classifier during the training phase, a support vector discriminative term is incorporated into the proposed objective function. Moreover, in the classification stage, the identity of test data is jointly determined by the regularized residual and the learned multi-class support vector machine. Finally, the resulting optimization problem is solved by utilizing the alternative strategy. Experimental results on benchmark databases demonstrate the superiority of our proposed method over previous dictionary learning approaches on both hand-crafted and deep features. The source code of our proposed LCDL-SV is accessible at https://github.com/yinhefeng/LCDL-SV.\nINDEX TERMS Dictionary learning, support vector discriminative term, locality constraint, pattern classification\nNDEX TERMS Dictionary learning, support vector discriminative term, locality constraint, pattern lassification\n#  INTRODUCTION\nDictionary learning (DL) has aroused considerable interest during the past decade and has been adopted in a wide rang of applications, such as face recognition [1], image fusion [2] and person re-identification [3], [4]. According to the characteristic of the learned dictionary, existing DL approaches for pattern classification can be divided into three categories: synthesis dictionary learning (SDL), analysis dictionary learning (ADL) and dictionary pair learning (DPL). In SDL, the dictionary is employed to represent the input data as a linear superposition of atoms. ADL aims to yield the sparse representation by exploiting the dictionary as a transformation matrix. DPL, also referred to as analysis-synthesis dictionary learning (ASDL), can jointly learn synthesis dictionary and analysis dictionary. According to whether the dictionary is class-shared or not, SDL can be further divided into three different types, i.e., shared SDL, class-specific ar\nSDL and hybrid SDL. Similarly, ADL can be classified into two categories, i.e., shared ADL and class-specific ADL. Fig. 1 presents a taxonomy of dictionary learning approaches for pattern classification. In class-specific SDL, sub-dictionary for each class is independently learned, then all the sub-dictionaries are concatenated to form the final dictionary. Ramirez et al. [5] presented a dictionary learning with structured incoherence (DLSI) method by imposing incoherence constraint on subdictionaries so as to encourage dictionaries correspond to different classes to be as independent as possible. Yang et al. [6] proposed a metaface learning (MFL) algorithm which learns a set of metafaces for each class. Yang et al. [7] developed a Fisher discrimination dictionary learning (FDDL) method which imposes the Fisher discrimination criterion on the coding coefficients to learn class-specific sub-dictionaries. By considering the fact that different training samples con-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5b48/5b48b85d-bc16-4d84-a04c-7078963b1169.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 1. A taxonomy of dictionary learning approaches for pattern classification.</div>\ntribute unequally to the dictionary, Liu et al. [8] proposed a class specific dictionary learning (CSDL) approach. Akhtar et al. [9] developed a joint discriminative Bayesian dictionary and classifier learning (JBDC) approach which associates the dictionary atoms with the class labels using Bernoulli distributions. By employing the directions of coefficients to promote the discriminative capability of representation, Wang et al. [10] presented a unidirectional representation dictionary learning (URDL) algorithm. Ling et al. [11] proposed a class-oriented discriminative DL (CODDL) method, in which the class-specific sub-dictionaries are learned in a classwise fashion.\nIn shared SDL, a universal dictionary shared by all classes is learned. The most classic SDL approach is the K-SVD algorithm [12] which has been successfully applied to image compression and denoising. However, KSVD mainly focuses on the representational ability of the dictionary without considering its capability for classification. To address this problem, Zhang et al. [13] proposed a discriminative KSVD (D-KSVD) method by introducing the classification error into the framework of K-SVD. Jiang et al. [14] further incorporated a label consistency constraint into K-SVD and presented a label consistent K-SVD (LC-KSVD) algorithm. The \u21130-norm sparse regularization term is used in LC-KSVD, which is difficult to find the optimum sparse solution. To overcome this limitation, Shao et al. [15] explored a label embedded dictionary learning (LEDL) method which utilizes the \u21131-norm as the sparse regularization term. By jointly learning a multi-class support vector machine (SVM) classifier, Cai et al. [16] developed a support vector guided dictionary learning (SVGDL) model. Zhang et al. [17] designed class relatedness oriented discriminative DL (CRODDL) method which utilizes the \u21131,\u221enorm constraint [18] on the coding coefficient matrix. By integrating multiple classifiers training into dictionary learning process, Quan et al. [19] presented a multiple classifiers based dictionary learning (MCDL) method. Dong et al. [20] proposed an orthonormal DL method by exerting an orthonormal constraint on the learned dictionary to enforce the dictionary atoms to\nbe as dissimilar as possible. Min et al. [21] constructed a Laplacian regularized locality-constrained coding (LapLLC) algorithm for image classification, in which the similarity matrix is defined on the training data. To fully exploit the locality and label information of the learned dictionary, Li et al. [22] constructed a locality-constrained and label embedding dictionary learning (LCLE-DL) algorithm. Song et al. [23] presented a class-wise discriminative DL (CW-DDL) method which introduces a label-aware constraint and graph regularization into the framework of SDL. By employing the profiles (row vectors of coding coefficient matrix) to construct discriminative terms in SDL, Li et al. [24] proposed an interactively constrained discriminative DL (IC-DDL) algorithm for image classification.\nIn hybrid SDL, a dictionary that contains several classspecific sub-dictionaries and a shared dictionary is learned. Kong et al. [25] proposed a DL approach dubbed DLCOPAR which explicitly learns the shared patterns (the commonality) and the class-specific dictionaries (the particularity). Gao et al. [26] developed a category-specific and shared dictionary learning (CSDL) method for fine-grained image categorization. Sun et al. [27] presented a discriminative group sparse dictionary learning (DGSDL) model which learns a class-specific sub-dictionary for each class as well as a common sub-dictionary shared by all classes. By introducing a cross-label suppression constraint and group regularization term into the framework of SDL, Wang et al. [28] designed a cross-label suppression discriminative DL (CLS-DDL) approach. Lin et al. [29] proposed a robust, discriminative and comprehensive dictionary learning (RDCDL) model which learns a class-shared dictionary, classspecific dictionaries and a disturbance dictionary to represent the commonality, particularity and disturbance components in the data. In order to tackle corrupted samples, Vu et al. [30] developed a low-rank shared dictionary learning (LRSDL) framework which simultaneously learns a set of common patterns and class-specific features for classification. By integrating the low-rank matrix recovery technique with the class-specific and class-shared dictionary learning, Rong\net al. [31] explored a low-rank double dictionary learning (LRD2L) approach. Du et al. [32] proposed a low-rank graph preserving discriminative dictionary learning (LRGPDDL) method which incorporates the low-rank constraint on the class-specific dictionaries, graph preserving criterion and the dictionary incoherence term into the framework of SDL. Readers can refer to [33] for a survey of SDL approaches. Recently, ADL has received increasing attention due to its efficacy and efficiency, and shared ADL has been widely studied. Rubinstein et al. [34] presented analysis K-SVD which is parallel to the synthesis K-SVD [12]. Afterwards, Shekhar et al. [35] applied ADL to image classification tasks and obtained comparable or better recognition performance than conventional SDL models. To enhance the classification performance of ADL, Guo et al. [36] proposed discriminative ADL (DADL) method. By introducing a synthesislinear-classifier-based error term into the basic ADL model, Wang et al. [37] presented a synthesis linear classifier based ADL (SLC-ADL) algorithm. By solving a joint learning of ADL and a linear classifier through K-SVD based technique, Wang et al. [38] designed a synthesis K-SVD based ADL (SK-SVDADL) method. Similar to LC-KSVD [14], Tang et al. [39] incorporated the label consistency term and classification error term into the framework of ADL and developed a structured ADL (SADL) approach. Maggu et al. [40] proposed label consistent transform learning (LCTL) for hyperspectral image classification. In essence, transform learning and ADL have similar formulation. For class-specific ADL, Wang et al. [41] proposed a class-aware ADL model which learns a discriminative analysis sub-dictionary for each class. In DPL, a pair of synthesis dictionary and analysis dictionary is learned from the input data. Gu et al. [42] presented a projective dictionary pair learning (PDPL) framework which jointly learns a synthesis dictionary and an analysis dictionary. To further enhance the discriminative ability of DPL, Chen et al. [43] developed a discriminative DL approach called DPL-SV which introduces a differentiable support vector discriminative term into the DPL model. DPL does not impose sparse constraint on the representation matrix, which may lose discriminative power of sparse property. To alleviate this problem, Zhang et al. [44] designed a joint label consistent embedding and dictionary learning (JEDL) model which explicitly exploit a sparse constraint on the representation matrix. To preserve the locality property of learned atoms in the synthesis dictionary, Zhang et al. [45] proposed a locality constrained projective dictionary learning (LC-PDL) method. By jointly learning a classifier with the dictionary pair, Yang et al. [46] explored a discriminative analysis-synthesis dictionary learning (DASDL) model. To preserve the local geometry structure of input data, Chang et al. [47] presented a graph-regularized discriminative analysis-synthesis dictionary pair learning (GDASDL) model to enhance the classification performance of DASDL. To integrate structured dictionary learning, analysis representation and analysis classifier training into a unified framework, Zhang et al. [48] proposed an analysis discriminative dictio-\nnary learning (ADDL) algorithm. Inspired by the superiority of \u21131,\u221enorm [18], Wei et al. [49] developed a fast DDL (FaDDL) method for synthetic aperture radar (SAR) image classification. The ordinal locality of analysis dictionary is not fully exploited in the above DPL and its variant, to tackle this problem, Li et al. [50] proposed a discriminative low-rank analysis-synthesis dictionary learning (LR-ASDL) algorithm with the adaptively ordinal locality. In addition to the above DL approaches, to deal with multiview data, some multi-view DL methods have been presented recently. Wu et al. [51] offered a multi-view low-rank dictionary learning (MLDL) method for image classification. Wu et al. [52] proposed a multi-view discriminant dictionary learning via learning view-specific and shared structured dictionaries (MDVSD) for image classification, in which a structured dictionary shared by all views and multiple viewspecific structured dictionaries are simultaneously learned. Ma et al. [53] developed a multi-view coupled dictionary pair learning (MVCDL) framework for person re-identification. Wu et al. [54] presented a multi-view synthesis and analysis dictionaries learning (MSADL) approach for pattern classification. However, ADL often requires enormous atoms to achieve satisfactory results when applied to pattern classification. For hybrid SDL, how to choose the optimal number of shared atoms remains unresolved. Moreover, the optimization process of class-specific SDL is time-consuming, especially when the number of classes is large. In this paper, we propose a locality constraint dictionary learning with support vector discriminative term (LCDL-SV) for pattern classification, which belongs to the shared SDL category. A support vector discriminative term is introduced to promote the discrimination of coding coefficients. Since the original training data may contain noise or outliers, graph Laplacian matrix constructed on the original training samples cannot faithfully describe the manifold structure. To alleviate this problem, we employ a locality constraint on atoms. The atoms are updated in the dictionary learning procedure, thus the graph Laplacian matrix defined on the atoms is also updated. More importantly, to further enhance the classification performance of our proposed method, the regularized residual and the learned multi-class SVM classifier are jointly exploited to classify the test data. The flowchart of our proposed method for classification is illustrated in Fig. 2. Firstly, features are extracted from the original training and test samples, respectively. Then the training data is fed into our proposed dictionary learning algorithm, when the dictionary learning process is completed, a compact dictionary and multi-class SVM are obtained. Finally, the test data is classified based on the learned multi-class SVM and the regularized residual. Our main contributions are summarized as follows, \u2022 A locality constraint of atoms is introduced in our approach, and this term can intrinsically inherit the manifold structure of training data. \u2022 In addition to the learned SVM classifier, we take the regularized residual into account to further promote the\nclassification performance. \u2022 The resulting problem is solved elegantly by employing an alternative optimization technique. The remainder of this paper is structured as follows. Section II reviews related work on SDL. In Section III, we present our proposed approach, and detailed optimization procedures are given in Section IV. Section V reports experimental results on five benchmark datasets. Finally, conclusions are drawn in Section VI.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d576/d5763eae-f5b9-4825-87b1-48de3ece5444.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 2. Flowchart of our proposed method for classification. In our LCDL-SV, a locality constraint on atoms and a support vector discriminative term are introduced in the formulation of LCDL-SV (red dashed rectangles in the middle part). Moreover, a fused decision strategy (red dashed rectangle at the bottom) which employs both the regularized residual and the learned multi-class SVM is designed to classify the input test sample.</div>\n# II. RELATED WORK\nIn this section, we will briefly review some related work, including the basic K-SVD [12] and its two discriminative variants, i.e., D-KSVD [13] and LC-KSVD [14]. Additionally, support vector guided dictionary learning (SVGDL) method [16] is also introduced. To begin with, we first give an introduction to the notations used throughout this paper. Let X = [X1, X2, . . . , XC] = [x1, x2, . . . , xn] \u2208Rm\u00d7n be the data matrix of n training samples belonging to C classes, where m is the dimension of vectorized data and n is the total number of training samples, D = [d1, d2, . . . , dK] \u2208\nRm\u00d7K is the learned dictionary which has K atoms, Z = [z1, z2, . . . , zn] \u2208RK\u00d7n is the coding coefficients matrix of X on the dictionary D.\n# A. K-SVD AND ITS DISCRIMINATIVE VARIANTS\nA. K-SVD AND ITS DISCRIMINATIVE VARIANTS By generalizing the K-means clustering process, Aharon et al. [12] developed K-SVD to learn an overcomplete dictionary that best suits given data. The objective function of KSVD is formulated as follows,\n# min D,Z \u2225X \u2212DZ\u22252 F , s.t. \u2225zi\u22250 \u2264T0\n(1)\nwhere D \u2208Rm\u00d7K is the dictionary that is to be learned, Z \u2208RK\u00d7n is the coding coefficient matrix, and T0 is a given sparsity level. (1) can be solved by alternatively updating D and Z. Although K-SVD yields impressive results in image compression and denoising, it is not tailored for classification. To make K-SVD suitable for classification problems, Zhang et al. [13] proposed D-KSVD algorithm by introducing the classification error term into the framework of K-SVD,\nmin D,W,Z \u2225X \u2212DZ\u22252 F + \u03b2 \u2225H \u2212WZ\u22252 F + \u03bb \u2225W\u22252 F , s.t. \u2225zi\u22250 \u2264T0\n(2)\nwhere H = [h1, h2, . . . , hn] \u2208RC\u00d7n is the label matrix of training data, hi = [0, 0, . . . , 1, . . . , 0, 0]T \u2208RC\u00d71 is the label vector of xi, and W is the parameters for a linear classifier. As can be seen from (2), dictionary and a linear classifier are jointly learned in D-KSVD. Afterwards, Jiang et al. [14] presented LC-KSVD by solving the following optimization problem,\n(3)\nwhere Q = [q1, q2, . . . , qn] \u2208RK\u00d7n is an ideal representation matrix and A is a linear transformation matrix.\n# B. SVGDL\nB. SVGDL\nTo promote the discriminative ability of coding vectors, Cai et al. [16] introduced a multi-class SVM regularization term into the framework of SDL. The regularization term is defined as follows,\n(4)\nwhere uc is the normal vector associated with the c-th class hyperplane of SVM, bc is the corresponding bias, and yc = [yc 1, yc 2, . . . , yc n] is defined as yc i = 1 if class labels yi = c and otherwise yc i = \u22121. Concretely, the discrimination term is f(Z, y, u, b) = \u2225u\u22252 2 + \u03b8 \ufffdn i=1 l(zi, yi, u, b), where l(zi, yi, u, b) is the hinge loss function, and \u03b8 is a penalty parameter.\nThe objective function of SVGDL is formulated as follows,\n  + \u03bb1 \u2225Z\u22252 F , s.t. \u2225dk\u22252 \u22641\nwhere U = [u1, u2, . . . , uC] and b = [b1, b2, . . . , bC].\n# III. PROPOSED METHOD\nIn this section, our proposed LCDL-SV is presented. First we will introduce a locality constraint on the atoms of the learned dictionary. Then by incorporating the locality constraint and the support vector discriminative term into the framework of SDL, we will present the formulations of our proposed LCDL-SV.\n# A. LOCALITY CONSTRAINT ON ATOMS\nAs mentioned earlier, Z is the coding coefficient matrix of training data X over the dictionary D, and zi = [z1,i, z2,i, . . . , zK,i]T , (i = 1, 2, . . . , n) is the coding vector of xi on D. The input training data can be represented as a linear combination of atoms in the dictionary, and the formulation is illustrated in Fig. 3.\nFIGURE 3. Linear representation of training data by atoms in the dictionary\n<div style=\"text-align: center;\">FIGURE 3. Linear representation of training data by atoms in the dictionary.</div>\nIn [55] and [22], the j-th row vector of Z is coined the profile of atom dj. Thus, \u02c6zj = [zj,1, zj,2, . . . , zj,n]T (j = 1, 2, . . . , K) is the profile of atom dj, and the red rectangle in Fig. 3 depicts profile \u02c6zj. So the profile matrix can be constructed as ZT = [\u02c6z1, \u02c6z2, . . . , \u02c6zK] \u2208Rn\u00d7K, which is the transpose matrix of Z. Based on the definition of profile, the linear representations in Fig. 3 can be reformulated as follows,\n(6)\nFrom (6), one can see that the profile \u02c6zj and atom dj have a one-to-one correspondence. In this paper, instead of preserving locality information of the original training data, we introduce a locality constraint on the atoms of the learned dictionary, which has proven to be more effective and robust [22]. A viable way to encourage similar atoms to have similar profiles is to minimize the following problem,\n(7)\nwhere M is a similarity matrix which can be defined as,\n(8)\n\uf8f3 where kNN(di) represents the k-nearest neighbors of atom di and \u03b4 is a parameter. After some deductions, we can obtain the following equivalent formulation of (7),\n\ufffd \ufffd where L = T \u2212M is a graph Laplacian matrix, T = diag(t1, . . . , tK) and ti = \ufffdK j=1 Mij. We can observe that the graph Laplacian matrix L is defined on the learned dictionary D. As a result, the graph Laplacian matrix L is updated due to the fact that D is updated in the dictionary learning process. Therefore, the graph Laplacian matrix L can inherit the manifold structure of the training samples.\nB. LCDL-SV MODEL Apart from the locality constraint on the atoms, to facilitate the subsequent classification stage, a support vector discriminative term is incorporated into our proposed method. The purpose of this term is to enforce the coefficients of different classes to be separated by a max-margin. Intuitively, when the coefficients are separated by a hyperplane, the large margin of different classes can promote the confidence of classification. Moreover, the parameters of SVM (i.e., U and b) can be learned in our dictionary learning process. The support vector discriminative term has the same formulation in (4). Thus, the objective function of our proposed LCDLSV is formulated as follows,\n(10)\n\ufffd + \u03bb1tr(ZT LZ), s.t. \u2225dk\u22252 = 1, k = 1, . . . , K where \u03bb1 and \u03bb2 are two balancing parameters.\n# IV. OPTIMIZATION\nIn this section, we adopt an alternative strategy to solve the LCDL-SV model. The alternative minimization scheme can be partitioned into the following three sub-problems, Update Z: Fix the other variables and update Z by solving the following problem:\n(11)\nThe optimization of Z in (11) can be performed by columns, which is formulated as,\n(12)\nTo facilitate the optimization process, we employ the quadratic hinge loss function to approximate the original one. The quadratic hinge loss function is defined as,\n(13)\n\ufffd \ufffd where t denotes the iteration number. When t=1, (12) is degenerated into the following problem,\n(14)\n(15)\nWhen t \u22652, (12) can be rewritten as,\n(16)\n\ufffd \ufffd where \u03c6 = \ufffd c|1 \u2264c \u2264C, yc i (uT c zi + bc) \u22121 > 0 \ufffd , (16) also has closed-form solution which is given by,\n(16)\n(17)\nwhere D1 = DT D + \u03bb1L + 2\u03bb2\u03b8 \ufffd c\u2208\u03c6 ucuT c and D2 = DT xi + 2\u03bb2\u03b8 \ufffd c\u2208\u03c6 uc(yc i \u2212bc) Update D and L: To update D, we fix variables other than D and minimize (10), which leads to\n(18)\nWe can see that (18) becomes a least squares problem with quadratic constraints. Here we employ the Lagrange dual function [56] to solve (18), and the Lagrange dual function of (18) is formulated as,\n\ufffd where \u03b4 = [\u03b41, \u03b42, . . . , \u03b4K] and \u03b4k is the Lagrange multiplier corresponds to the k-th equality constraint (\u2225dk\u22252 \u22121 = 0). We can define a diagonal matrix \u2206whose diagonal element \u2206kk = \u03b4k, then (19) can be reformulated as, L(D, \u03b4) = \u2225X \u2212DZ\u22252 F + tr(DT D\u2206) \u2212tr(\u2206) (20) By setting the first-order derivative of (20) to zero, we can obtain the following solution to D,\n(20)\n(21)\nTo speed up the optimization process, we discard \u2206in the final formulation, which is given by,\n(22)\nWhen D is updated, we update the graph Laplacian matrix L by using (8).\nUpdate U and b: When the other variables are fixed, (10) with respect to U and b is boiled down to the following problem,\n(23)\n(23) is a multi-class linear SVM problem which can be solved by the SVM solver presented in [57]. Due to the fact that the objective function proposed in (10) is non-convex, the algorithm cannot converge to the global minimum. However, satisfactory solutions can be obtained with the decreasing of the objective function. The convergence curve of LCDL-SV on the Extended Yale B database is plotted in Fig. 4. Algorithm 1 outlines the optimization process of our proposed LCDL-SV.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c3af/c3affdc5-5b3d-4ea4-9155-3472287bd09b.png\" style=\"width: 50%;\"></div>\nAlgorithm 1 Optimization procedure of LCDL-SV\nInput: Training data matrix X, parameters \u03bb1, \u03bb2 and \u03b8\n1: Initialize D, Z, U and b\n2: while not converged do\n3:\nConstruct the graph Laplacian matrix L by using (8)\n4:\nfor i=1 to n do\n5:\nUpdate zi by using (15) and (17)\n6:\nend for\n7:\nUpdate the dictionary by using (22)\n8:\nfor c=1 to C do\n9:\nUpdate Uc and bc by solving (23)\n10:\nend for\n11: end while\nOutput: D, U and b\nWhen the dictionary learning process is completed, we perform classification as follows. For a test sample xnew, first we obtain its coding vector by z = Pxnew, where\nWhen the dictionary learning process is completed, we perform classification as follows. For a test sample xnew, first we obtain its coding vector by z = Pxnew, where\n<div style=\"text-align: center;\">TABLE 1. Optimal parameters of LCDL-SV on each dataset.</div>\nEYaleB\nAR\nScene\n15\nCaltech\n101\nLFW\n(VGG16)\nLFW\n(VGG19)\n\u03bb1\n1e-3\n1e-3\n1e-5\n1e-1\n1e-2\n1e-2\n\u03bb2\n1e-6\n1e-6\n1e-4\n1e-6\n1e-6\n1e-6\n\u03b71\n1e-2\n1e-3\n1e-5\n1\n1e-2\n1e-2\n\u03b72\n5\n50\n10\n600\n600\n80\nP = (DT D + \u03b71I)\u22121DT . Then the regularized residual for the c-th class can be obtained by,\n(24)\nwhere Dc and zc are the sub-dictionary and coding vector associated with the c-th class, respectively. Moreover, the result produced by the learned SVM classifier is formulated as,\n(25)\nFinally, the identity of xnew is given by,\n(26)\nwhere \u03b72 is a weighting parameter.\n# V. EXPERIMENTAL RESULTS\nIn this section, we conduct experiments on five publicly available databases, i.e., the Extended Yale B database [58], AR database [59], Scene 15 dataset [60], Caltech 101 dataset [61] and LFW database [62]. We compare LCDL-SV with SRC [63], D-KSVD [13], LC-KSVD [14], FDDL [7], SVGDL [16] and two recently proposed ADL approaches, i.e., CADL [41] and SADL [39]. To validate the effectiveness of employing both the regularized residual and SVM, we also report the results of LCDL-SV only using regularized residual for classification and LCDL-SV only employing the learned multiclass SVM for classification, which are denoted by LCDLSV (Res) and LCDL-SV (SVM), respectively. Besides the classification accuracy, we also record the training time and testing time of these competing methods in our experiments. SRC directly employs all the training data as the dictionary, thus we do not report its training time. The difference between LCDL-SV (Res), LCDL-SV (SVM) and LCDL-SV lies in the classification rule, thus they have the same training time but different testing time. All experiments are conducted with MATLAB R2019b under Windows 10 on a PC equipped with Intel i9-8950HK 2.90 GHz CPU and 32 GB RAM. There are five parameters in our proposed method, i.e., \u03b8, \u03bb1, \u03bb2, \u03b71 and \u03b72. In all experiments, \u03b8 is set to be 0.2, the other four parameters are determined by cross-validation, and \u03bb1 and \u03bb2 are selected from 10\u22126, 10\u22125, . . . , 10\u22121. The optimal values on each dataset are recorded in Table 1. For fair comparison, we tune the parameters of competing approaches to achieve their best performance.\n<div style=\"text-align: center;\">TABLE 2. Recognition accuracy (%) and computing time on the Extended Yale B database.</div>\nMethods\nAccuracy\nTraining time(s)\nTesting time(s)\nSRC [63]\n90.0\nNo Need\n3.2\nD-KSVD [13]\n75.3\n7.8\n0.2\nLC-KSVD [14]\n90.6\n11.5\n0.2\nFDDL [7]\n91.9\n592.6\n3.4\nSVGDL [16]\n96.1\n57.8\n0.01\nCADL [41]\n96.3\n23.8\n0.01\nSADL [39]\n95.2\n27.2\n0.01\nLCDL-SV (Res)\n91.5\n57.2\n0.8\nLCDL-SV (SVM)\n97.1\n57.2\n0.06\nLCDL-SV\n97.8\n57.2\n0.9\nA. EXTENDED YALE B The Extended Yale B database contains 2414 frontal face images of 38 subjects, each person has about 64 images, and some example images are shown in Fig. 5. Following the experimental setting in [16], in our experiments, all images are cropped to 54\u00d748, then they are reduced to a dimension of 300 by PCA. We randomly select 20 images per person as training set and the remaining as testing set. The dictionary has 380 atoms, which corresponds to an average of 10 atoms per subject. Experimental results are summarized in Table 2. We can observe that the proposed LCDL-SV achieves the highest recognition accuracy. Moreover, LCDL-SV is much faster than FDDL in the training phase, and the training time of LCDL-SV is comparable to that of SVGDL. Thanks to the framework of ADL, CADL and SADL are efficient on this dataset. Due to the jointly learning dictionary and multi-class SVM, the testing time of SVGDL and LCDLSV (SVM) is less than our proposed LCDL-SV. Nevertheless, by fusing the regularized residual and the learned multi-class SVM, LCDL-SV outperforms all the competing approaches in recognition accuracy, and it is more efficient than SRC and FDDL in terms of testing time. It should be noted that, in [39], the reported accuracy of SADL and SRC is 96.35% and 96.51%, respectively. The differences lie in the following two aspects. On the one hand, in [39], each image of 192\u00d7168 pixels is projected onto a 504-dimensional vector by random projection, while we use the cropped image of 54\u00d748 pixels and employ PCA to reduce the image to a dimension of 300. On the other hand, half of the images (i.e., 32 images) per subject are used for training in [39], while 20 images per person are employed for training in our experiments.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7954/79542e91-d847-4433-b271-e94bebc1f14e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 5. Example images from the Extended Yale B database.</div>\n<div style=\"text-align: center;\">TABLE 3. Recognition accuracy (%) and computing time on the AR database.</div>\nMethods\nAccuracy\nTraining time(s)\nTesting time(s)\nSRC [63]\n66.5\nNo Need\n2.3\nD-KSVD [13]\n88.8\n25.3\n0.08\nLC-KSVD [14]\n93.7\n38.2\n0.1\nFDDL [7]\n97.4\n822.4\n2.9\nSVGDL [16]\n98.8\n358.9\n0.01\nCADL [41]\n98.5\n288.3\n0.01\nSADL [39]\n97.2\n183.1\n0.01\nLCDL-SV (Res)\n94.7\n360.3\n0.6\nLCDL-SV (SVM)\n99.0\n360.3\n0.01\nLCDL-SV\n99.2\n360.3\n0.62\n# B. AR\nThe AR database has more than 4000 face images of 126 subjects with variations in facial expression, illumination conditions and occlusions. Fig. 6 shows example images from the database. In our experiments, we use a subset of 2600 images of 50 male and 50 female subjects from the database. As in [14], each 165\u00d7120 face image is projected onto a 540-dimensional vector by random projection. For each person, 20 images are randomly selected for training and the remaining for testing. The learned dictionary has 500 atoms, namely five atoms per person. Table 3 lists the recognition accuracy and computing time of all compared methods. Notice that 20 atoms per class are exploited in [41], while only five atoms per class are used in our experiments. One can see that LCDL-SV has the best performance in recognition accuracy and is more efficient than FDDL in both training and testing phases. Moreover, on this database and the Extended Yale B database, LCDL-SV (SVM) achieves better results than SVGDL, which demonstrates that locality constraint of atoms does promote the classification performance of SDL approaches on these two face databases.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/269a/269a4ef1-199e-4246-a2c1-317e9523f05f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 6. Example images from the AR database.</div>\n# C. SCENE 15\nScene 15 dataset contains 15 natural scene categories, which comprises a wide range of indoor and outdoor scenes, such as bedroom, office and mountain, example images from this dataset are shown in Figure 7. For fair comparison, we employ the 3000-dimensional SIFT-based features used in LCKSVD [14]. Following the common experimental settings, we randomly select 100 images per category as training data\nTABLE 4. Recognition accuracy (%) and computing time on the Scene 15 dataset.\n<div style=\"text-align: center;\">TABLE 4. Recognition accuracy (%) and computing time on the Scene 15 dataset.</div>\nMethods\nAccuracy\nTraining time(s)\nTesting time(s)\nSRC [63]\n91.8\nNo Need\n3.5\nD-KSVD [13]\n89.1\n54.1\n0.4\nLC-KSVD [14]\n92.9\n72.2\n0.4\nFDDL [7]\n97.5\n2470.5\n208.2\nSVGDL [16]\n98.4\n159.0\n0.1\nCADL [41]\n98.6\n5365.8\n0.67\nSADL [39]\n98.5\n314.7\n0.2\nLCDL-SV (Res)\n97.8\n159.2\n6.5\nLCDL-SV (SVM)\n98.4\n159.2\n0.4\nLCDL-SV\n99.0\n159.2\n6.7\nand use the remaining for testing. The learned dictionary has 450 atoms. Experimental results are shown in Table 4. The recognition accuracy of LCDL-SV is 99.0%, which outperforms all the compared methods. CADL performs the second best on this dataset, followed by SADL and SVGDL. Moreover, LCDL-SV is 15 times faster than FDDL in the training stage. The confusion matrix for LCDL-SV is depicted in Fig. 8, in which diagonal elements are well-marked. It can be seen that LCDL-SV attains 100% recognition accuracy for the categories of suburb, forest and inside-city.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d8fc/d8fca488-e83f-4d1f-b732-914c0085a5bc.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 7. Example images from the Scene 15 dataset.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a3cd/a3cdf1ad-f044-435c-a233-6d637b06cddb.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 8. Confusion matrix on the Scene 15 dataset.</div>\nD. CALTECH 101 Caltech101 dataset is a widely used dataset for object classification with 102 classes (i.e., 101 object classes and one background class). The number of images in each category is\n# D. CALTECH 101\nCaltech101 dataset is a widely used dataset for object classification with 102 classes (i.e., 101 object classes and one background class). The number of images in each category is\n<div style=\"text-align: center;\">TABLE 5. Recognition accuracy (%) on the Caltech 101 dataset.</div>\nnumber of train. samp.\n5\n10\n15\n20\n25\n30\nSRC [63]\n48.8\n60.1\n64.9\n67.7\n69.2\n70.7\nD-KSVD [13]\n49.6\n59.5\n65.1\n68.6\n71.1\n73.0\nLC-KSVD [14]\n54.0\n63.1\n67.7\n70.5\n72.3\n73.6\nFDDL [7]\n53.6\n63.6\n66.8\n69.8\n71.7\n73.1\nSVGDL [16]\n55.3\n64.3\n69.6\n72.3\n75.1\n76.7\nCADL [41]\n55.6\n63.9\n65.7\n68.1\n70.1\n75.0\nSADL [39]\n46.6\n59.4\n62.4\n68.4\n70.3\n74.4\nLCDL-SV (Res)\n52.6\n61.1\n62.2\n63.9\n62.2\n60.7\nLCDL-SV (SVM)\n56.9\n65.6\n69.2\n72.6\n74.5\n76.5\nLCDL-SV\n57.0\n65.9\n69.7\n73.1\n75.1\n76.8\nunbalanced, varying from 31 to 800, and in total this dataset contains 9144 images. For fair comparison, we also employ the 3000-dimensional SIFT-based features used in LC-KSVD [14]. Following the common experimental protocol, we randomly choose 5, 10, 15, 20, 25, and 30 samples per category for training and test on the remaining images. We repeat this process 10 times with different splits of training and test images and record the averaged classification accuracy. Table 5 summarizes the classification results and Table 6 lists the training time and testing time when 5 samples per category are used for training. As can be seen from Table 5, LCDL-SV consistently outperforms the other competing approaches in all cases. Compared with SVGDL, LCDL-SV (SVM) does not always achieve better accuracy (e.g., when the number of training samples per category is 25). This indicates that using only the locality constraint cannot guarantee the best performance. Combining with the proposed classification scheme, LCDL-SV exhibits its advantage over other dictionary learning approaches. From Table 6, we can observe that the training time of LCDL-SV is only one-sixteenth of that of FDDL and LCDL-SV is faster than SRC in the testing phase.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9086/9086fede-dd07-40c1-a568-e512f474cabb.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 9. Example images from the Caltech 101 dataset.</div>\n# E. DEEP FEATURES\nIn this subsection, a subset of LFW database is used to evaluate our proposed LCDL-SV and other competing approaches on deep features. This subset contains 1251 images of 86 subjects, each person has 11-20 images. All images are converted to grayscale images and cropped and resized to 32\u00d732, some example images are shown in Fig. 10. Five images per subject are randomly selected as training samples and the remaining as test samples. The pre-trained VGG16 and VGG19 [64] models are employed to extract deep features, and FC6 in\nTABLE 6. Computing time on the Caltech 101 dataset when 5 samples per category are used for training.\nMethods\nTraining time(s)\nTesting time(s)\nSRC [63]\nNo Need\n33.9\nD-KSVD [13]\n35.3\n1.3\nLC-KSVD [14]\n43.3\n1.6\nFDDL [7]\n2112.7\n177.2\nSVGDL [16]\n162.3\n0.3\nCADL [41]\n183.6\n1.2\nSADL [39]\n176.2\n0.2\nLCDL-SV (Res)\n139.4\n23.2\nLCDL-SV (SVM)\n139.4\n2.1\nLCDL-SV\n139.4\n24.2\nboth VGG16 and VGG19 is used for feature extraction. The dimension of deep features extracted by VGG16 and VGG19 is 4096. In order to obtain more compact representations, we apply principal component analysis (PCA) to the 4096dimensional features (keeping 98% of the variance) and the dimensions of reduced features for VGG16 and VGG19 are 270 and 264, respectively. Finally, the reduced features are fed into the compared approaches. Experimental results are shown in Table 7, and the training time and testing time are recorded for the VGG19 feature. From Table 7, we can see that LCDL-SV delivers the best result on both the VGG16 and VGG19 features. This demonstrates that LCDL-SV is not only superior to its competing methods on hand-crafted features, but on the deep features as well. Similar to the observations on the other datasets used in our experiments, LCDL-SV is more efficient than FDDL in terms of training and testing time.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0eb2/0eb2a7ea-c7f3-4aaf-899e-4886d35e7b8e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 10. Example images from the LFW database.</div>\nF. PARAMETER SENSITIVITY ANALYSIS As mentioned earlier, five parameters should be determined in our proposed method, i.e., \u03b8, \u03bb1, \u03bb2, \u03b71 and \u03b72. For the two parameters \u03bb1 and \u03bb2, we find that relatively small values (e.g., 1e-5) can guarantee our proposed method to achieve satisfactory results for pattern classification tasks. \u03b71 is used to obtain the coding coefficients of test samples and it is usually set to 1e-3. For diverse datasets, \u03b72 has a relatively wide range in fusing the regularized residual and the results of multi-class SVM. Therefore, the above\n<div style=\"text-align: center;\">TABLE 7. Recognition accuracy (%) and computing time on the LFW database.</div>\nMethods\nVGG16\nVGG19\nTraining time(s)\nTesting time(s)\nSRC [63]\n42.4\n36.4\nNo Need\n2.3\nD-KSVD [13]\n35.7\n35.8\n5.9\n0.2\nLC-KSVD [14]\n41.5\n36.9\n8.7\n0.1\nFDDL [7]\n45.4\n39.4\n203.7\n2.3\nSVGDL [16]\n46.9\n42.8\n85.5\n0.01\nCADL [41]\n46.5\n41.2\n26.8\n0.01\nSADL [39]\n41.0\n35.1\n7.1\n0.01\nLCDL-SV (Res)\n25.6\n22.9\n66.0\n0.5\nLCDL-SV (SVM)\n47.6\n45.3\n66.0\n0.03\nLCDL-SV\n48.0\n46.5\n66.0\n0.6\nobservations can be treated as a rule of thumb for selecting parameters of the proposed LCDL-SV. To investigate the sensitivity of parameters, we carry out experiments on the Extended Yale B database, and the experimental settings are the same as that in Section V-A. When analyzing one parameter, we fix the other two parameters. Firstly, we fix the parameters \u03bb2 and \u03b72, and examine how the performance changes with varying \u03bb1. Fig. 11 (a) plots the recognition accuracy with varying \u03bb1. Similarly, Figs. 11 (b) and 11 (c) plot the results of varying \u03bb2 and \u03b72. As can be seen from Fig. 11 (a), when the value of \u03bb1 increases from 10\u22125 to 10\u22123, the accuracy of LCDL-SV is gradually increasing. However, the performance of LCDL-SV will degrade when the value of \u03bb1 is larger than 0.01. From Fig. 11 (b), we can see that LCDL-SV achieves stable performance when the value of \u03bb2 is in the range of [10\u22127,10\u22124]. With the increasing of \u03bb2, the performance drops to some extent. A larger \u03bb2 will reduce the discriminative ability of the support vector term, leading to degenerated performance. From Fig. 11 (c), one can see that accuracy of LCDL-SV has an increase with \u03b72 from 1 to 5, and then has a decline when \u03b72 continues increasing. On the Extended Yale B database, LCDL-SV has the best performance when \u03b72 is set to be 5.\n# VI. CONCLUSION\nIn this paper, we propose a locality constraint dictionary learning with support vector discriminative term (LCDL-SV) for pattern classification. In contrast with traditional methods in which the graph Laplacian matrix is derived from the original training data, we preserve the locality of atoms on the basis of the learned dictionary. By introducing a support vector discriminative term into the formulation of LCDL-SV, a classifier can be jointly learned in our dictionary learning procedures. More importantly, the regularized residual and multi-class SVM are simultaneously employed to classify the test samples. Experimental results on face databases, scene dataset and object dataset validate the effectiveness of LCDLSV, and it outperforms some state-of-the-art dictionary learning approaches, e.g., FDDL, SVGDL, CADL, and SADL. Discriminative analysis dictionary learning methods have aroused considerable interest due to their efficiency and efficacy. In future work, we will develop new discriminative ADL approach and apply it to other classification scenarios,\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ef36/ef361086-d158-4861-b048-d29c867812f2.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5305/53051194-9c36-4dd6-871e-1041aee24a03.png\" style=\"width: 50%;\"></div>\nFIGURE 11. Classification accuracy (%) of LCDL-SV with varying parameters on the Extended Yale B database. (a) \u03bb1 changes when \u03bb2 and \u03b72 are fixed to 1e-6 and 5, respectively. (b) \u03bb2 changes by fixing \u03bb1=1e-3 and \u03b72=5 and (c) \u03b72 varies when \u03bb1 and \u03bb2 are fixed to 1e-3 and 1e-6, respectively.\nsuch as action recognition and texture classification.\n# REFERENCES\n[1] X. Song, Y. Chen, Z. Feng, G. Hu, T. Zhang, and X. Wu, \"Collaborative representation based face classification exploiting block weighted LBP and analysis dictionary learning,\" Pattern Recognition, vol. 88, pp. 127-138, Apr. 2019 [2] H. Li and X. Wu, \"Multi-focus image fusion using dictionary learning and low-rank representation,\" 2017 International Conference on Image and Graphics, Shanghai, China, 2017, pp. 675-686. [3] S. Li, M. Shao, and Y. Fu, \"Person re-identification by cross-view multiLevel dictionary learning,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 40, no. 12, pp. 2963-2977, Dec. 2018. [4] X. Jing, X. Zhu, F. Wu, X. You, Q. Liu, D. Yue, R. Hu, and B. Xu, \"Superresolution person re-identification with semi-coupled low-rank discriminant dictionary learning,\" 2015 IEEE Conference on Computer Vision and Pattern Recognition, Boston, Massachusetts, 2015, pp. 695-704. [5] I. Ramirez, P. Sprechmann, and G. Sapiro, \"Classification and clustering via dictionary learning with structured incoherence and shared features,\" 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, San Francisco, CA, 2010, pp. 3501-3508. [6] M. Yang, L. Zhang, J. Yang, and D. Zhang, \"Metaface learning for sparse representation based face recognition,\" 2010 IEEE International Conference on Image Processing, Hong Kong, 2010, pp. 1601-1604. [7] M. Yang, L. Zhang, X. Feng, and D. Zhang, \"Fisher discrimination dictionary dearning for sparse representation,\" 2011 International Conference on Computer Vision, Barcelona, 2011, pp. 543-550. [8] B. Liu, B. Shen, L. Gui, Y. Wang, X. Li, F. Yan, and Y. Wang, \"Face recognition using class specific dictionary learning for sparse representation and collaborative representation,\" Neurocomputing, vol. 204, pp. 198-210, Sep. 2016. [9] N. Akhtar, A. Mian, and F. Porikli, \"Joint discriminative Bayesian dictionary and classifier learning,\" 2017 IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, 2017, pp. 3919-3928. [10] X. Wang, Y. Lid, S. You, H. Li, and S. Wang, \"Unidirectional representation based efficient dictionary learning,\" IEEE Transactions on Circuits and Systems for Video Technology, DOI: 10.1109/TCSVT.2018.2886600 [11] J. Ling, Z. Chen, and F. Wu, \"Class-oriented discriminative dictionary learning for image classification,\" IEEE Transactions on Circuits and Systems for Video Technology, DOI: 10.1109/TCSVT.2019.2918852 [12] M. Aharon, M. Elad, and A. Bruckstein, \"K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation,\" in IEEE Transactions on Signal Processing, vol. 54, no. 11, pp. 4311-4322, Nov. 2006. [13] Q. Zhang and B. Li, \"Discriminative K-SVD for dictionary learning in face recognition,\" 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, San Francisco, CA, 2010, pp. 2691-2698. [14] Z. Jiang, Z. Lin, and L. S. Davis, \"Learning a discriminative dictionary for sparse coding via label consistent K-SVD,\" 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Colorado Springs, CO, USA, 2011, pp. 1697-1704. [15] S. Shao, Y. Wang, B. Liu, W. Liu, and R. Xu, \"Label Embedded Dictionary Learning for Image Classification. arXiv preprint arXiv:1903.03087, 2019. [16] S. Cai, W. Zuo, L. Zhang, X. Feng, and P. Wang, \"Support vector guided dictionary learning,\" 2014 European Conference on Computer Vision, Zurich, Switzerland 2014, pp. 624-639. [17] D. Zhang, P. Liu, K. Zhang, H. Zhang, Q. Wang, and X. Jing, \"Class relatedness oriented-discriminative dictionary learning for multiclass image classification,\" Pattern Recognition, vol. 59, pp. 168-175, Nov. 2016. [18] A. Quattoni, X. Carreras, M. Collins, and T. Darrell, \"An efficient projection for \u21131,\u221eregularization,\" 2009 International Conference on Machine Learning, Montreal, Canada, 2009, pp. 857-864. [19] Y. Quan, Y. Xu, Y. Sun, and Y. Huang, \"Supervised dictionary learning with multiple classifier integration,\" Pattern Recognition, vol. 55, pp. 247260, Jul. 2016. [20] Z. Dong, M. Pei, and Y. Jia, \"Orthonormal dictionary learning and its application to face recognition,\" Image and Vision Computing, vol. 51, pp. 13-21, Jul. 2016. [21] H. Min, M. Liang, R. Luo, and J. Zhu, \"Laplacian regularized localityconstrained coding for image classification,\" Neurocomputing, vol. 171, pp. 1486-1495, Jan. 2016. [22] Z. Li, Z. Lai, Y. Xu, J. Yang, and D. Zhang, \"A locality-constrained and label embedding dictionary learning algorithm for image classification,\" IEEE Transactions on Neural Networks and Learning Systems, vol. 28, no. 2, pp. 278-293, Feb. 2017.\n[23] J. Song, X. Xie, G. Shi, and W. Dong, \"Exploiting class-wise coding coefficients: Learning a discriminative dictionary for pattern classification,\" Neurocomputing, vol. 321, pp. 114-125, Dec. 2018. [24] Z. Li, Z. Zhang, Z. Fan, and J. Wen, \"An interactively constrained discriminative dictionary learning algorithm for image classification,\" Engineering Applications of Artificial Intelligence, vol. 72, pp. 241-252, Jun. 2018. [25] S. Kong and D. Wang, \"A dictionary learning approach for classification: separating the particularity and the commonality,\" 2012 European conference on computer vision, Florence, Italy, 2012, pp. 186-199. [26] S. Gao, I. W. Tsang, and Y. Ma, \"Learning category-specific dictionary and shared dictionary for fine-grained image categorization,\" IEEE Transactions on Image Processing, vol. 23, no. 2, pp. 623-634, Feb. 2014. [27] Y. Sun, Q. Liu, J. Tang, and D. Tao, \"Learning discriminative dictionary for group sparse representation,\" IEEE Transactions on Image Processing, vol. 23, no. 9, pp. 3816-3828, Sept. 2014. [28] X. Wang and Y. Gu, \"Cross-label suppression: A discriminative and fast dictionary learning with group regularization,\" IEEE Transactions on Image Processing, vol. 26, no. 8, pp. 3859-3873, Aug. 2017. [29] G. Lin, M. Yang, J. Yang, L. Shen, and W. Xie, \"Robust, discriminative and comprehensive dictionary learning for face recognition,\" Pattern Recognition, vol. 81, pp. 341-356, Sep. 2018. [30] T. H. Vu and V. Monga, \"Fast low-rank shared dictionary learning for image classification,\" IEEE Transactions on Image Processing, vol. 26, no. 11, pp. 5160-5175, Nov. 2017. [31] Y. Rong, S. Xiong, and Y. Gao, \"Low-rank double dictionary learning from corrupted data for robust image classification,\" Pattern Recognition, vol. 72, pp. 419-432, Dec. 2017. [32] H. Du, L. Ma, G. Li, and S. Wang, \"Low-rank graph preserving discriminative dictionary learning for image recognition,\" Knowledge-Based Systems, DOI: 10.1016/j.knosys.2019.06.031. [33] Y. Xu, Z. Li, J. Yang, and D. Zhang, \"A survey of dictionary learning algorithms for face recognition,\" IEEE Access, vol. 5, pp. 8502-8514, Apr. 2017. [34] R. Rubinstein, T. Peleg, and M. Elad, \"Analysis K-SVD: A dictionarylearning algorithm for the analysis sparse model,\" IEEE Transactions on Signal Processing, vol. 61, no. 3, pp. 661-677, Feb. 2013. [35] S. Shekhar, V. M. Patel, and R. Chellappa, \"Analysis sparse coding models for image-based classification,\" 2014 IEEE International Conference on Image Processing, Paris, 2014, pp. 5207-5211. [36] J. Guo, Y. Guo, X. Kong, M. Zhang, and R. He, \"Discriminative analysis dictionary learning,\" 2016 AAAI Conference on Artificial Intelligence, Phoenix, USA, 2016, pp. 1617-1623. [37] J. Wang, Y. Guo, J. Guo, M. Li, and X. Kong, \"Synthesis linear classifier based analysis dictionary learning for pattern classification,\" Neurocomputing, vol. 238, pp. 103-113, May 2017. [38] Q. Wang, Y. Guo, J. Guo, and X. Kong, \"Synthesis K-SVD based analysis dictionary learning for pattern classification,\" Multimedia Tools and Applications, vol. 77, no. 13, pp.17023-17041, Jul. 2018. [39] W. Tang, A. Panahi, H. Krim, and L. Dai, \"Analysis dictionary learning based classification: Structure for robustness,\" IEEE Transactions on Image Processing, vol. 28, no. 12, pp. 6035-6046, Dec. 2019. [40] J. Maggu, H. K. Aggarwal, and A. Majumdar, \"Label-consistent transform learning for hyperspectral image classification,\" IEEE Geoscience and Remote Sensing Letters, vol. 16, no. 9, pp. 1502-1506, Sept. 2019. [41] J. Wang, Y. Guo, J. Guo, X. Luo, and X. Kong, \"Class-aware analysis dictionary learning for pattern classification,\" IEEE Signal Processing Letters, vol. 24, no. 12, pp. 1822-1826, Dec. 2017. [42] S. Gu, L. Zhang, W. Zuo, and X. Feng, \"Projective dictionary pair learning for pattern classification,\" 2014 Advances in neural information processing systems, Montreal, Canada, 2014, pp. 793-801. [43] B. Chen, J. Li, B. Ma, and G. Wei, \"Discriminative dictionary pair learning based on differentiable support vector function for visual recognition,\" Neurocomputing, vol. 272, pp. 306-313, Jan. 2018. [44] Z. Zhang, F. Li, T. W. S. Chow, L. Zhang, and S. Yan, \"Sparse codes auto-extractor for classification: A joint embedding and dictionary learning framework for representation,\" IEEE Transactions on Signal Processing, vol. 64, no. 14, pp. 3790-3805, Jul. 2016. [45] Z. Zhang, W. Jiang, Z. Zhang, S. Li, G. Liu, and J. Qin, \"Scalable block-diagonal locality-constrained projective dictionary learning,\" arXiv preprint arXiv:1905.10568, 2019. [46] M. Yang, H. Chang, and W. Luo, \"Discriminative analysis-synthesis dictionary learning for image classification,\" Neurocomputing, vol. 219, pp. 404-411, Jan. 2017.\n[47] H. Chang, H. Tang, F. Zhang, Y. Chen, and H. Zheng, \"Graph-regularized discriminative analysis-synthesis dictionary pair learning for image classification,\" IEEE Access, vol. 7, pp. 55398-55406, Apr. 2019. [48] Z. Zhang, W. Jiang, J. Qin, L. Zhang, F. Li, M. Zhang, and S. Yan , \"Jointly learning structured analysis discriminative dictionary and analysis multiclass classifier,\" IEEE Transactions on Neural Networks and Learning Systems, vol. 29, no. 8, pp. 3798-3814, Aug. 2018. [49] Y. Wei, L. Jiao, F. Liu, S. Yang, Q. Wu, and G. Sanga, \"Fast DDL classification for SAR images with l1,\u221econstraint,\" IEEE Access, vol. 7, pp. 68991-69006, May 2019. [50] Z. Li, Z. Zhang, J. Qin, S. Li, and H. Cai, \"Low-rank analysis-synthesis dictionary learning with adaptively ordinal locality,\" Neural Networks, vol. 119, pp. 93-112, Nov. 2019. [51] F. Wu, X. Jing, X. You, D. Yue, R. Hu, and J. Yang, \"Multi-view low-rank dictionary learning for image classification,\" Pattern Recognition, vol. 50, pp. 143-154, Feb. 2016. [52] F. Wu, X. Jing, and D. Yue, \"Multi-view discriminant dictionary learning via learning view-specific and shared structured dictionaries for image classification,\" Neural Processing Letters, vol. 45, no. 2, pp. 649-666, Apr. 2017. [53] F. Ma, X. Zhu, Q. Liu, C. Song, X. Jing, and D. Ye, \"Multi-view coupled dictionary learning for person re-identification,\" Neurocomputing, vol. 348, pp. 16-26, Jul. 2019. [54] F. Wu, X. Dong, L. Han, X. Jiang, and Y. Ji, \"Multi-View Synthesis and Analysis Dictionaries Learning for Classification,\". IEICE TRANSACTIONS on Information and Systems, vol. 102, no. 3, pp. 659-662, Mar. 2019. [55] M. Sadeghi, M. Babaie-Zadeh, and C. Jutten, \"Learning overcomplete dictionaries based on atom-by-atom updating,\" IEEE Transactions on Signal Processing, vol. 62, no. 4, pp. 883-891, Feb.15, 2014. [56] M. Zheng, J. Bu, C. Chen, C. Wang, L. Zhang, G. Qiu, and D. Cai. \"Graph regularized sparse coding for image representation,\" IEEE Transactions on Image Processing, vol. 20, no. 5, pp. 1327-1336, May 2011. [57] J. Yang, K. Yu, Y. Gong, and T. Huang, \"Linear spatial pyramid matching using sparse coding for image classification,\" 2009 IEEE Conference on Computer Vision and Pattern Recognition, Miami, FL, 2009, pp. 17941801. [58] K. Lee, J. Ho, and D. J. Kriegman, \"Acquiring linear subspaces for face recognition under variable lighting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 27, no. 5, pp. 684-698, May 2005. [59] A. M. Martinez and R. Benavente, \"The AR face database.\" CVC Tech. Rep. #24, Jun. 1998. [Online]. Available: http://www2.ece.ohiostate.edu/\u223caleix/ARdatabase.html [60] S. Lazebnik, C. Schmid, and J. Ponce, \"Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories,\" 2006 IEEE Conference on Computer Vision and Pattern Recognition, New York, USA, 2006, pp. 2169-2178. [61] Li Fei-Fei, R. Fergus, and P. Perona, \"Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories,\" 2004 Conference on Computer Vision and Pattern Recognition Workshop, Washington, DC, USA, 2004, pp. 178-178. [62] G. Huang, M. Mattar, T. Berg, and E. Learned-Miller, \"Labeled faces in the wild: A database for studying face recognition in unconstrained environments,\" 2008 Workshop on Faces in Real-Life Images: Detection, Alignment, and Recognition, Marseille, France, 2008. [63] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma, \"Robust face recognition via sparse representation,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 31, no. 2, pp. 210-227, Feb. 2009. [64] Simonyan K and Zisserman A, \"Very deep convolutional networks for large-scale image recognition,\" arXiv preprint arXiv:1409.1556, 2014.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3c14/3c14a89c-35fe-4797-9a94-a0f5577578bd.png\" style=\"width: 50%;\"></div>\nHE-FENG YIN received his B.S. degree in School of Computer Science and Technology from Xuchang University, Xuchang, China, in 2011. Currently, he is a PhD candidate in School of IoT Engineering, Jiangnan University, Wuxi, China. He was a visiting PhD student at centre for vision, speech and signal processing (CVSSP), University of Surrey, under the supervision of Prof. Josef Kittler. His research interests include representation based classification methods, dictionary learning\nand low rank representation\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ea18/ea181f23-e6b3-4f94-905e-1912feb889f8.png\" style=\"width: 50%;\"></div>\nXIAO-JUN WU received the B.S. degree in mathematics from Nanjing Normal University, Nanjing, China, in 1991, and the M.S. and Ph.D. degrees in pattern recognition and intelligent system, from the Nanjing University of Science and Technology, Nanjing, in 1996 and 2002, respectively. From 1996 to 2006, he was with the School of Electronics and Information, Jiangsu University of Science and Technology, where he was involved in teaching and promoted to a Professor. From\n1999 to 2000, he was a fellow of the International Institute for Software Technology, United Nations University. From 2003 to 2004, he was a Visiting Researcher with the Centre for Vision, Speech, and Signal Processing, University of Surrey, U.K. Since 2006, he has been with the School of Information Engineering, Jiangnan University, where he is currently a Professor of computer science and technology. He has published over 200 papers. His current research interests include pattern recognition, computer vision, and computational intelligence. He received the Most Outstanding Postgraduate Award from the Nanjing University of Science and Technology.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/442a/442a098e-761f-4da0-8ce3-29a3d29b30d5.png\" style=\"width: 50%;\"></div>\nSU-GEN CHEN received the B.S. degree in mathematics and applied mathematics from Anqing Normal University, Anqing, Anhui, in 2004, the M.S. degree in computational mathematics from the Hefei University of Technology, Hefei, Anhui, in 2009, and the Ph.D. degree in control science and engineering from Jiangnan University, Wuxi, Jiangsu, in 2016. Since 2015, he has been an Associate Professor with the School of Mathematics and Computational Science, Anqing Normal\nUniversity. His research interests include pattern recognition and intelli systems, and machine learning.\nUniversity. His research interests include pattern recognition and intelligent systems, and machine learning.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of locality in dictionary learning for pattern classification, highlighting the limitations of conventional discriminative dictionary learning (DDL) methods that do not fully exploit the locality of atoms, necessitating a new approach to enhance classification performance.",
        "problem": {
            "definition": "The problem defined in this paper is the ineffective utilization of locality information in traditional DDL methods, which hampers their ability to accurately classify patterns.",
            "key obstacle": "The main challenge is that existing methods fail to preserve the locality of atoms in the learned dictionary, leading to suboptimal classification results."
        },
        "idea": {
            "intuition": "The proposed idea stems from the observation that preserving the locality of atoms can significantly improve classification performance, as it aligns better with the inherent structure of the data.",
            "opinion": "The proposed method, termed Locality Constraint Dictionary Learning with Support Vector Discriminative Term (LCDL-SV), integrates locality constraints into dictionary learning while simultaneously learning a classifier.",
            "innovation": "The primary innovation of this method lies in the incorporation of a locality constraint on the atoms of the dictionary and a support vector discriminative term, which collectively enhance the discriminative ability of the learned representations."
        },
        "method": {
            "method name": "Locality Constraint Dictionary Learning with Support Vector Discriminative Term",
            "method abbreviation": "LCDL-SV",
            "method definition": "LCDL-SV is defined as a method that incorporates locality constraints into dictionary learning while jointly optimizing a support vector classifier.",
            "method description": "The method focuses on preserving the locality of dictionary atoms and learning a multi-class support vector machine classifier during the dictionary learning process.",
            "method steps": [
                "Extract features from training and test samples.",
                "Perform dictionary learning incorporating locality constraints.",
                "Learn a multi-class support vector machine classifier.",
                "Classify test samples using the learned classifier and regularized residual."
            ],
            "principle": "The effectiveness of LCDL-SV arises from its ability to maintain the manifold structure of the training data through locality constraints, which leads to improved classification accuracy."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted on five publicly available databases: Extended Yale B, AR, Scene 15, Caltech 101, and LFW, comparing LCDL-SV against several baseline methods.",
            "evaluation method": "The performance was assessed based on classification accuracy, training time, and testing time, with results reported for different configurations of the proposed method."
        },
        "conclusion": "The experimental results demonstrate that LCDL-SV outperforms several state-of-the-art dictionary learning methods in terms of classification accuracy and efficiency, validating its effectiveness for pattern classification tasks.",
        "discussion": {
            "advantage": "The key advantages of LCDL-SV include improved classification accuracy due to the preservation of locality and the integration of a support vector classifier, making it more robust than traditional methods.",
            "limitation": "A limitation of the method is the potential increase in computational complexity due to the additional optimization required for the support vector discriminative term.",
            "future work": "Future research will focus on developing new discriminative analysis dictionary learning approaches and applying them to various classification scenarios, such as action recognition and texture classification."
        },
        "other info": {
            "source code": "The source code for LCDL-SV is accessible at https://github.com/yinhefeng/LCDL-SV.",
            "funding": "This work was supported by the National Natural Science Foundation of China and other academic grants."
        }
    },
    "mount_outline": [
        {
            "section number": "1.2",
            "key information": "The motivation behind the proposed method, Locality Constraint Dictionary Learning with Support Vector Discriminative Term (LCDL-SV), is to address the limitations of conventional discriminative dictionary learning methods that do not fully exploit the locality of atoms."
        },
        {
            "section number": "1.3",
            "key information": "The main goals and objectives of the paper include enhancing classification performance by preserving the locality of dictionary atoms and integrating a support vector classifier."
        },
        {
            "section number": "2.1",
            "key information": "Key terms defined in the paper include 'locality information' in dictionary learning and 'discriminative dictionary learning (DDL)' methods."
        },
        {
            "section number": "3.1",
            "key information": "The proposed method, LCDL-SV, is categorized under generative and probabilistic models, focusing on the integration of locality constraints into dictionary learning."
        },
        {
            "section number": "4.1",
            "key information": "The paper discusses the critical role of preserving locality in dictionary learning for improving classification accuracy, emphasizing its importance in the semi-supervised learning context."
        },
        {
            "section number": "5.2",
            "key information": "The advantages of using LCDL-SV include improved classification accuracy due to the preservation of locality and the integration of a support vector classifier."
        },
        {
            "section number": "7.1",
            "key information": "A challenge identified in the paper is the potential increase in computational complexity due to the additional optimization required for the support vector discriminative term in LCDL-SV."
        },
        {
            "section number": "7.4",
            "key information": "Future research directions mentioned in the paper include developing new discriminative analysis dictionary learning approaches and applying them to various classification scenarios."
        }
    ],
    "similarity_score": 0.5798445213048236,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-2055_semi-/papers/Locality Constraint Dictionary Learning with Support Vector for Pattern Classification.json"
}