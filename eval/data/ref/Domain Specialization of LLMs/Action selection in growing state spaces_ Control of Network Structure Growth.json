{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1606.07777",
    "title": "Action selection in growing state spaces: Control of Network Structure Growth",
    "abstract": "The dynamical processes taking place on a network depend on its topology. Influencing the growth process of a network therefore has important implications on such dynamical processes. We formulate the problem of influencing the growth of a network as a stochastic optimal control problem in which a structural cost function penalizes undesired topologies. We approximate this control problem with a restricted class of control problems that can be solved using probabilistic inference methods. To deal with the increasing problem dimensionality, we introduce an adaptive importance sampling method for approximating the optimal control. We illustrate this methodology in the context of formation of information cascades, considering the task of influencing the structure of a growing conversation thread, as in Internet forums. Using a realistic model of growing trees, we show that our approach can yield conversation threads with better structural properties than the ones observed without control.",
    "bib_name": "thalmeier2016actionselectiongrowingstate",
    "md_text": "# Action selection in growing state spaces: Control of Network Structure Growth\nDominik Thalmeier1, Vicenc\u00b8 G\u00b4omez 2, and Hilbert J. Kappen 1\n1Donders Institute for Brain, Cognition and Behaviour Radboud University Nijmegen, the Netherlands 2Department of Information and Communication Technologies Universitat Pompeu Fabra. Barcelona, Spain\n# Abstract\nThe dynamical processes taking place on a network depend on its topology. Influencing the growth process of a network therefore has important implications on such dynamical processes. We formulate the problem of influencing the growth of a network as a stochastic optimal control problem in which a structural cost function penalizes undesired topologies. We approximate this control problem with a restricted class of control problems that can be solved using probabilistic inference methods. To deal with the increasing problem dimensionality, we introduce an adaptive importance sampling method for approximating the optimal control. We illustrate this methodology in the context of formation of information cascades, considering the task of influencing the structure of a growing conversation thread, as in Internet forums. Using a realistic model of growing trees, we show that our approach can yield conversation threads with better structural properties than the ones observed without control.\narXiv:1606.07777v2\nords: control, complex Networks, sampling, conversation threads\n# 1 Introduction\nMany complex systems can be described as dynamic processes which are characterized by the topology of an underlying network. Examples of such systems are human interaction networks, where the links may represent transmitting opinions Olfati-Saber et al. [2007], Dai and Mesbahi [2011], Centola and Baronchelli [2015], habits Centola [2010], Farajtabar et al. [2014], money Gai and Kapadia [2010], Amini et al. [2016], Giudici and Spelta [2016] or viruses Pastor-Satorras and Vespignani [2001], Egu\u00b4\u0131luz and Klemm [2002]. Being able to control, or just influence in some way, the dynamics of such complex networks may lead to important progress, for example, avoiding financial crises, preventing epidemic outbreaks or maximizing information spread in marketing campaigns. The control of the dynamics on networks is a very challenging problem that has attracted significant interest recently Liu et al. [2011], Cornelius et al. [2013], Gao et al. [2014], Yan et al. [2015]. Existing approaches typically consider network controllability as the controllability of\nthe dynamical system induced by the underlying network structure. While it is agreed that network controllability critically depends on the network structure, the problem of how to control the network structure itself while it is evolving remains open. The network structure is determined by the dynamics of addition and deletion of nodes and links over time. In this paper, we address the problem of influencing this dynamics in the framework of stochastic optimal control. The standard way to address these problems is through the Bellman equation and dynamic programming. Dynamic programming is only feasible in small problems and requires approximations when the state and action spaces are large. In the setting of network growth, this problem is more severe, since the state space increases (super-)exponentially with the number of nodes. In order to deal with this curse of dimensionality, we propose to approximate the network growth control problem by a special class of stochastic optimal control problems, known as Kullback-Leibler (KL) control or Linearly-Solvable Markov Decision Problems (LMDPs) Todorov [2009], Kappen et al. [2012]. For this class of problems, one can use efficient adaptive importance sampling methods that scale well in high dimensions. The optimal solution for the KL-control problem tends to be sparse, so that only a few next states become relevant, effectively reducing the branching factor of the original problem. The obtained solution of the KL-control problem is then used to compute the optimal action in the original problem that does not belong to the KL-control class. In the next section we present our proposed general methodology. We then apply it to a realistic problem: influencing the growth process of cascades in online forums, in order to maximize structural network measures that are connected to the quality of an online conversation thread. We conclude the paper with a discussion.\n# 2 Optimal Network Growth as a Control Problem\nWe now formulate the network growth control problem as a stochastic optimal control problem. Let xt \u2208X, with X being the set of all possible network structures, denote the growing structure (state) of the network at time t and let P(x\u2032|x, u) describe the network dynamics, where the control variable u \u2208U denotes possible actions we can perform in order to manipulate the network. Let us label the default action, which means not interacting with the system, with u = 0. We denote the corresponding dynamics without control as the uncontrolled process p(x\u2032|x) := P(x\u2032|x, u = 0). At each time-step t, we incur an arbitrary cost function on the network state r(x, t) which is assigned when the state is reached. The state cost r(x, t) penalizes network structures that are not convenient in the particular context under consideration. For example, if one wants to favour networks with large average clustering coefficient C(x), then r(x, t) = \u2212C(x). Alternatively, one can consider more complex functions, such as the structural virality or Wiener index Mohar and Pisanski [1988], as proposed recently Goel et al. [2015], to maximize the influence in a social network. In general, any measure that can be (efficiently) computed from x fits the presented framework. Our objective is to find the control function u(x, t) : X \u00d7 N \ufffd\u2192U which minimizes the total cost over a time horizon T, starting at state x at initial time t = 0\n(1)\nwhere the expectation is taken with respect to the probability P(x1:T|x, u(\u00b7), t = 0) over paths x1:T in the state space, given state x at time t = 0 using the control-function u(\u00b7). The probability of a path is given by P(xt+1:T|x, u(\u00b7), t = 0) = \ufffdT\u22121 s=t P(xs+1|xs, u(xs, s), s). Computing the optimal control can be done by dynamic programming Bertsekas [1995]. We introduce the optimal cost-to-go\nwhich is an expectation of the cumulative cost starting at state x and time t and acting optimally thereafter. This can be computed using the Bellman equation\nJ(x, t) = min u \ufffd r(x, t) + \ufffd J(x\u2032, t + 1) \ufffd P(x\u2032|x,u,t) \ufffd .\n\ufffd \ufffd \ufffd \ufffd From J(x, t), the optimal control is obtained by a greedy local optimization:\nu\u2217(x, t) = argminu \ufffd r(x, t) + \ufffd J(x\u2032, t + 1) \ufffd P(x\u2032|x,u,t) \ufffd\n\ufffd \ufffd \ufffd \ufffd In general, the solution to equation (3) can be computed recursively using dynamic programming Bertsekas [1995] for all possible states. This is however infeasible for controlling network growth, as the computation is of polynomial order in the number of states and the state space of networks increases super-exponentially on the number of nodes. E.g. for directed unweighed networks, there are 2N2 possible networks with N labelled nodes.\n# Approximating the network growth problem by a Kullback-Leibler\n# 3 Approximating the network growth problem by a Kullback-Leibler control problem\nIn this section we present our main approach, which first computes the optimal cost-to-go on a relaxed problem and then uses it as a proxy for the original optimal cost-to-go. In the next subsection, we introduce the class of KL-control problems that we use as a relaxation. We then illustrate KL-control using a tractable example of tree growth. In subsection 3.3, we explain how can we approximate the KL-control solution using the cross-entropy method. Finally, in subsection 3.4 we show how can we use that result to compute the action selection in the original problem.\n# 3.1 Kullback-Leibler control\nIn order to efficiently compute the optimal cost-to-go, we make the assumption that our controls directly specify the transition probabilities between two subsequent network structures, e.g. P(x\u2032|x, u(t)) \u2248 u(x\u2032|x, t). Further, we define the natural growth process of the network (the uncontrolled dynamics) as a Markov chain with transition probabilities p(x\u2032|x). Because our influence on the network dynamics is limited, we add a regularization term to the total cost defined in equation (1) that penalizes deviations from p(x\u2032|x). The approximated control cost becomes\nC\u03bb KL (x, t, u(\u00b7)) =\u03bbKL [u (xt+1:T|x, t) \u2225p (xt+1:T|x, t)] + r (x, t) + \ufffd T \ufffd t\u2032=t+1 r \ufffd xt\u2032, t\u2032\ufffd \ufffd u(xt+1:T|x,t) , (5)\n (x, t, u(\u00b7)) =\u03bbKL [u (xt+1:T|x, t) \u2225p (xt+1:T|x, t)] + r (x, t) +\n(2)\n(3)\n(4)\n, (5)\nwhich measures the closeness of the two path distributions, p (xt+1:T|x, t) and u (xt+1:T|x, t). The parameter \u03bb thereby regulates the strength of this penalization. With this assumption, the control problem consisting in minimizing C\u03bb KL w.r.t. the control u(x\u2032|x, t) belongs to the KL-control class and has a closed form solution Todorov [2009], Kappen et al. [2012]. The probability distribution of an optimal path u\u2217 KL (xt+1:T|x, t) that minimizes equation (5) is\nwith\n\ufffd Plugging this into equation (5) and minimizing gives the optimal cost-to-go J\u03bb KL(x, t) = r(x, t) \u2212\u03bb log \u27e8\u03c6(xt+1:T)\u27e9p(xt+1:T|x,t) ,\n\ufffd Plugging this into equation (5) and minimizing gives the optimal cost-to-go\n\ufffd Plugging this into equation (5) and minimizing gives the optimal cost-to-go \u03bb x t rx tx\nwhich can be numerically approximated using paths sampled from the uncontrolled dynamics p(xt+1:T|x, t The optimal control corresponding to equation (4) corresponds to a state transition probability distribution that is obtained by marginalization in equation (6). It is expressed in terms of the uncontrolled transition probability p(x\u2032|x) and the (exponentiated) optimal cost-to-go:\nu\u2217 KL(x\u2032|x, t) = \ufffd xtT u\u2217 KL \ufffd xt+1 = x\u2032, xt+2:T|x, t \ufffd \u221dp(x\u2032|x) exp \ufffd \u2212J\u03bb KL(x\u2032, t + 1) \u03bb \ufffd .\nu\u2217 KL(x\u2032|x, t) = \ufffd xt+2:T u\u2217 KL \ufffd xt+1 = x\u2032, xt+2:T|x, t \ufffd \u221dp(x\u2032|x) exp \ufffd \u2212J\u03bb KL(x\u2032, t + 1) \u03bb \ufffd . (9)\nThis resembles a Boltzmann distribution with temperature \u03bb where the optimal cost-to-go takes the role of an energy. The effect of the temperature becomes clear: for high values of \u03bb, u\u2217 KL(x\u2032|x, t) deviates only a little from the uncontrolled dynamics p(x\u2032|x), thus the optimal control has a weak influence on the system. In contrast, for low values of \u03bb, the exponential in equation (9) becomes very pronounced for the state(s) x\u2032 with the smallest cost-to-go J\u03bb KL(x\u2032, t + 1), suppressing the transition probabilities to suboptimal states x\u2032. Thus the control has a very strong effect on the process. In the limit of \u03bb going to zero, the controlled process becomes deterministic, if J\u03bb KL(x\u2032, t + 1) is not degenerate (meaning there is a unique state x\u2032 which minimizes the optimal cost-to-go). In this case the control is so strong that it overpowers the noise completely. We thus approximate our original (possibly difficult) control problem as a KL-control problem, parametrized by the temperature \u03bb. The approximated optimal cost-to-go J(x\u2032, t + 1) of equation (4) is replaced by the corresponding optimal cost-to-go of the KL-control problem J\u03bb KL(x\u2032, t + 1) of equation (9) and used to compute the action selection in the original problem.\n# 3.2 A Tractable Example\nWe now present a tractable example amenable for exact optimal control computation. This example already belongs to the KL-control class, so no approximation is made. The purpose of this analysis it\n(6)\n(7)\n(8)\n(9)\nto show how different values of the temperature \u03bb may lead to qualitatively different optimal solutions and other interesting phenomena. Let\u2019s consider a tree that grows at discrete time-steps, starting with the root node at time t = 0. We represent the tree at time t as a vector xt = (x0, x1, ..., xt), where xt indicates the label of the parent of the node attached at time t. At every time-step, either the tree remains the same or a new node is attached to it. The root node has label 1 and the label 0 is specially used to indicate that no node was added at a given time-step (it is also the label of the parent of the root node). The nodes are labelled in increasing order as they arrive to the tree, so that at time-step t, for a tree with k nodes, k \u2264t, xt = 0, 1, . . . , k corresponds to the parent of node k + 1 if a node is added or zero otherwise. Thus, the parent vector at time t = 1 is always x1 = (0, 1). Our example is a finite horizon task of T = 10 time-steps and end-cost only. The end-cost implements two control objectives: it prefers trees of large Wiener index while penalising trees with many nodes (more than five, in this case). The Wiener index is the sum of the lengths of the shortest paths between all nodes in a graph. It is maximal for a chain and minimal for a star. The uncontrolled process is biased to the root: new nodes choose to link the root with probability 3/5 and uniformly otherwise. More precisely\nwhere \u2225x\u22250 denotes the number of non-zero elements in x and Wiener the (normalized) Wiener index. In this setting, the uncontrolled process p tends to grow trees with more than five nodes with many of them attached to the root node, i.e. with low Wiener index. We want to influence this dynamics so that the target configuration, a chain of five nodes (maximal Wiener index) is more likely to be obtained. Figure 1 (top) shows the state cost r of the final tree that results from choosing the most probable control (MAP solution) as a function of the temperature \u03bb. The exact solution is calculated using dynamic programming Kappen et al. [2012]. We can differentiate three types of solutions, denoted as A, B and C in the figure. For low temperatures (region A) the control aims to fulfil both control objectives: to find a small network with maximal Wiener index. The optimal strategy does not add nodes initially and then builds a tree of maximal Wiener index (see inset of initial controls in left column of the figure). This type of control (to wait while the target is far in the future) is reminiscent of the delayed choice mechanism described previously Kappen [2005]. This initial waiting period makes sense because if the chain of length 5 would be grown immediately, then at time 6 the size of 5 is already reached. If now an additional node attaches, then the final cost would be zero. However if one first waits and then grows the chain, an accidental node insertion before time 6 would not be so disastrous (actually it may help), as one can then just wait until time 7 to start growing the rest of the tree. So delaying the decision when to start growing the tree helps compensating accidental events. For intermediate temperatures (region B), the initial control becomes less extreme, as we observe if we compare the left plots between regions A and B. For \u03bb \u22480.07, the solution that builds the tree with maximal Wiener index is no longer optimal, since it deviates too much from the uncontrolled\n(10)\n(11)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ac42/ac42dd47-029c-4ee3-a3dc-7f43c5ca7c37.png\" style=\"width: 50%;\"></div>\nFigure 1: Example of optimal control of tree growth. (Top): the state cost of the most probable solutions as a function of the temperature \u03bb. In region A, the optimal strategy waits until the last time-steps and then grows a tree with maximal Wiener index. In region B, it builds a star of five nodes. Finally, in region C, it follows the uncontrolled dynamics and builds a star of ten nodes. (Left): for each region, the optimal probabilities u\u2217(xt+1|xt) at t = 1 for the two actions which are initially available: no node addition (0) and adding a node to the root (1). In regions A, B the optimal control favours not adding a new node initially. The sequences on the right show how the tree grows. When a new node is added to the tree, it is coloured in red.\ndynamics. In region B, the control aims to build a network of five nodes or less, but no longer aims to maximize the Wiener index. The control is characterized by an initial waiting period and the subsequent growth of a tree of five nodes, which are in this case all attached to the root node. Finally, for high temperatures (region C, \u03bb > 0.4), the control essentially ignores the cost r and the optimal strategy is to add one node to the root at every time-step, following the uncontrolled process. From these results we conclude that KL-control as a mechanism for controlling network growth can capture complex phenomena such as transitions between qualitatively different optimal solutions and delayed choice effects.\n# 3.3 Sampling from the KL-optimally controlled dynamics\nIn this subsection, we explain how we can sample from the optimally controlled dynamics and thereby obtain an estimate of the optimal cost-to-go J\u03bb KL(x, t) of equation (8). The probability of an optimally controlled path, equation (6), corresponds to the product of the uncontrolled dynamics by the exponentiated state costs. Hence a naive way to obtain samples from the optimal dynamics, would consist in sampling paths from the uncontrolled dynamics p(x\u2032|x) and\nweight them by their exponentiated state costs. Using these samples we can then compute expecta tions from the optimally controlled dynamics. We use that for any function f(xt+1:T) we have:\nMore precisely, provided a learned model or a simulator of the uncontrolled dynamics p(x\u2032|x), we generate M sample paths x(i) t+1:T, i = 1, . . . , M from p(x\u2032|x) and compute the weights \u03c6(x(i) t+1:T) \u02c6\u03c6 . The denominator thereby gives with equation (8) an estimate of the optimal cost-to-go as\nThis method can be combined with resampling techniques Douc and Capp\u00b4e [2005], Hol et al. [2006] to obtain unweighted samples xopt,(i) t+1:T from the optimal dynamics (for the numerical methods in this article, we have used structural resampling Douc and Capp\u00b4e [2005], Hol et al. [2006]). Using such a naive sampling method, however, can be inefficient, specially for low temperatures. While for high temperatures \u03bb basically all weights \u03c6(x(i) t+1:T) \u02c6\u03c6 are more or less equal, for low temperatures only a few samples with very large weights contribute to the approximation, resulting in very poor estimates. This is a standard problem in Monte Carlo sampling and can be addressed using the Cross-Entropy (CE) method De Boer et al. [2005], Kappen and Ruiz [2016], which is an adaptive importance sampling algorithm that incrementally updates a baseline sampling policy or sequence of controls. Here we propose to use the CE method in the discrete formulation and use a parametrized Markov process \ufffdu\u03c9(x\u2032|x, t), with parameters \u03c9, to approximate u\u2217 KL. The CE method in our setting alternates the following steps: 1. In the first step, the optimal control is estimated using M sample paths drawn from a parametrized proposal distribution \ufffdu\u03c9(x\u2032|x, t). 2. In the second step, the parameters \u03c9 are updated so that the proposal distribution becomes closer to the optimal probability distribution. As a proposal distribution \ufffdu\u03c9(x\u2032|x, t), we use \ufffd \ufffd\nAs a proposal distribution \ufffdu\u03c9(x\u2032|x, t), we use\n\ufffd \ufffd which has the same functional form as the optimally controlled transition probabilities in equation (9). The KL-optimal cost-to-go is thereby approximated by a linear sum of time-dependent feature t\n\ufffd \ufffd The probability distribution of an optimally controlled path, equation (6), can be written as \ufffd \ufffd\n(12)\n(13)\n(14)\nThis shows that we can draw samples from the proposal distribution and reweight them with the combined weights\nThis shows that we can draw samples from the proposal distribution and reweight them with t combined weights\n\ufffd | The parameters \u03c9k(t) of the importance sampler are initialized with zeros, which makes the initial proposal distribution equivalent to the uncontrolled dynamics. The procedure requires the gradients of \ufffdu\u03c9(x\u2032|x, t) at each iteration. We describe the details of the CE method in A. We measure the efficiency of an obtained proposal control using the effective sample size (EffSS), which estimates how many effective samples can be drawn from the optimal distribution. Given M samples with weights w(i), the EffSS is given by\n\ufffd \ufffd \ufffd If the weights w(i) are all about the same value, the EffSS is high, indicating that many samples contribute to statistical estimates using the weighted samples. If all weights are equal, the EffSS is equal to the number of samples M. Conversely if the weights w(i) have a large spread, the EffSS is low, indicating that only few independent samples contribute to statistical estimates. In the extreme case, when one weight is much larger then all others, the EffSS approaches 1.\n# 3.4 Action selection using the KL-approximation\nOnce we have an estimate of the cost-to-go J\u03bb KL, we need to select an action u \u2208U in the original control problem, which is not of the KL-control type. We select the optimal action according to\nwhich requires the computation of J\u03bb KL(xt+1, t + 1) for every reachable state xt+1. In growing networks, the number of possible next states (the branching factor) increases quickly, and visiting all of them soon becomes infeasible. In this subsection we highlight an important benefit of using the KL-approximation as a relaxation of the original problem: the optimally controlled process tends to discard many irrelevant states, specially for small values of \u03bb. This means that u\u2217 KL(x\u2032|x, t) is sparse on x\u2032 (only a few next states are relevant for the task), since the cost J\u03bb KL(x\u2032, t) is very large for the corresponding x\u2032 where u\u2217 KL(x\u2032|x, t) \u22480. Let xopt t+1:T denote a trajectory sampled from the optimally controlled process, as described in the previous section. We compute u\u2217 KL(x\u2032|x, t) using:\n\ufffd \ufffd where xopt(t + 1) is the first element of the trajectory and \u03b4xopt(t+1),x\u2032 is the Kronecker delta which is equal one if xopt(t + 1) is equal to x\u2032, and zero otherwise. We then compute the optimal cost using equation (9):\n(15)\n(16)\n(17)\n(18)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0cf4/0cf4ef61-52dd-498d-87d4-8775d28cb306.png\" style=\"width: 50%;\"></div>\nFigure 2: Task illustration: example of an Internet news forum. News are posted periodically and users can write comments either to the original post or to other user\u2019s comments, forming a cascade of messages. The figure shows an example of conversation thread taken from Slashdot about Google\u2019s AlphaGo. The control task is to influence the structure of the conversation thread (shown as a growing tree in the top-right). where we dropped a term which does not depend on x\u2032 and therefore plays no role in the minimization of equation (16). The KL-approximation can help reducing the branching factor because it needs only a few samples to calculate J\u03bb KL(x\u2032, t + 1) only for the x\u2032 where u\u2217 KL(x\u2032|x, t) > 0 and thus J\u03bb KL(x\u2032, t) has a finite value. As mentioned earlier, u\u2217 KL(x\u2032|x, t) tends to be more sparse for small values of \u03bb, when the KLcontrol problem is less noisy. In B we provide analytical details of the two extreme conditions, when \u03bb is zero or infinite, respectively.\nFigure 2: Task illustration: example of an Internet news forum. News are posted periodically and users can write comments either to the original post or to other user\u2019s comments, forming a cascade of messages. The figure shows an example of conversation thread taken from Slashdot about Google\u2019s AlphaGo. The control task is to influence the structure of the conversation thread (shown as a growing tree in the top-right).\nwhere we dropped a term which does not depend on x\u2032 and therefore plays no role in the minimization of equation (16). The KL-approximation can help reducing the branching factor because it needs only a few samples to calculate J\u03bb KL(x\u2032, t + 1) only for the x\u2032 where u\u2217 KL(x\u2032|x, t) > 0 and thus J\u03bb KL(x\u2032, t) has a finite value. As mentioned earlier, u\u2217 KL(x\u2032|x, t) tends to be more sparse for small values of \u03bb, when the KLcontrol problem is less noisy. In B we provide analytical details of the two extreme conditions, when \u03bb is zero or infinite, respectively.\n# 4 Application to Conversation Threads\nWe have described a framework for controlling growing graphs. We now illustrate this framework in the context of growing information cascades. In particular, we focus on the task of controlling the growth of online conversation threads. These are information cascades that occur, for example, in online forums such as weblogs Leskovec et al. [2007], news aggregators G\u00b4omez et al. [2008] or the synthesis of articles of Wikipedia Laniado et al. [2011]. In conversation threads, after an initial post appears, different users react writing comments either to the original post or to comments from other users.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7cd7/7cd75dfb-b28f-41f0-91b5-b8474fc7099f.png\" style=\"width: 50%;\"></div>\nFigure 3: Our proposed control mechanism: in addition to the the threaded conversation, we highlight a comment (red node in the growing tree), suggested to be replied by the user. The choice of suggested comment, shown at the bottom of the page, is calculated using the method described in section 3.3.\nFigure 2 shows an example of a conversation thread, taken from Slashdot (www.slashdot.org) Users see a conversation thread using a similar hierarchical interface. The task we consider is to optimize the structure of the generated conversation thread while it grows. The state is thus defined as a growing tree. We assume an underlying (not observed) population of users that keep adding nodes to this tree. Since we can not control directly what is the node that will receive the next comment, we propose the user interface as a control mechanism to influence indirectly the growth process. This can be done in different ways, for example, manipulating the layout of the comments. In our case, the control signal will be to recommend a comment (by highlighting it) to which the next user can reply. Figure 3 illustrates such a mechanism. The action selection strategy introduced in section 3.4 is used to select the comment to highlight. Our goal is thus to modify the structure of a cascade in certain way while it evolves, by influencing its growth indirectly. It is known that the structure of online threads is strongly related with the complexity of the underlying conversation G\u00b4omez et al. [2008], Gonzalez-Bailon et al. [2010]. To fully define our control problem, we need to specify the structural cost function, the uncontrolled dynamics, i.e. the equivalent of equations (10) and (11) for this task, and a model of how an action (highlighting a node) changes the dynamics. Globally, this application differs from the toy example of subsection 3.2 in some important ways: 1. The state-space is larger (threads typically receive more than 10 comments).\n1. The state-space is larger (threads typically receive more than 10 comments). 2. We choose as state-cost function the Hirsch index (h-index), which makes the control\n1. The state-space is larger (threads typically receive more than 10 comments). 2. We choose as state-cost function the Hirsch index (h-index), which makes the control task\nhighly non-trivial.\n# 3. The original problem is not a KL-control problem. We use the action selection method de scribed in section 3.4 to control the growth of the conversation thread.\n3. The original problem is not a KL-control problem. We use the action selection method described in section 3.4 to control the growth of the conversation thread.\n# 4.1 Structural Cost Function\nWe propose to optimize the Hirsch index (h-index) as structural measure. In our context, a cascade with h-index h has h comments each of which have received at least h replies. It is a sensible quantity to optimize, since it measures how distributed the comments of users on previous comments are. A high h-index prevents two extreme cases that occur in a rather poor conversation: the case where a small number of posts attract most of the replies, thus there is no interaction, and the case with deep chains, characteristic of a flame war of little interest for the community. Both cases have a low h-index, while a high h-index spreads the conversation over multiple levels of the cascade. The h-index is a function of the degree sequence of all nodes in the tree, where the degree of a node is this case is the number of replies plus one, as there is also a link to the parent (replied comment or post). Therefore we use the degree histogram as features \u03c8t k(x) for the parametrized form of the optimal cost-to-go, equation (13). That is, feature \u03c8t k(x) is the number of nodes with degree k in the tree x at time-step t. We model the problem as a finite horizon task with end-cost. Thus, the state cost is defined as r(x, t) = \u2212\u03b4t,T \u00b7 h(x), where h(x) is the h-index of the tree x.\n# 4.2 Uncontrolled Dynamics for Online Conversation Threads\nAs uncontrolled dynamics, we use a realistic model that determines the probability of a comment to attract the replies of other users at any time, by means of an interplay between the following features: \u2022 Popularity \u03b1: number of replies that a comment has already received. \u2022 Novelty \u03c4: the elapsed time since the comment appeared in the thread. \u2022 Root node bias \u03b2: characterizes the level of trendiness of the main post. Such a model has proven to be successful in capturing the structural properties and the temporal evolution of discussion threads present in very diverse platforms G\u00b4omez et al. [2013]. Notice that these features \u03b8 = (\u03b1, \u03c4, \u03b2) should not be confused with the features \u03c8t k(x) used to encode the costto-go. We represent the conversation thread as a vector of parents xt = (x0, x1, ..., xt). Given the current state of the thread xt, the uncontrolled dynamics attaches a new node t + 1 to an existing node j with probability\n\ufffd \ufffd with Zt+1 a normalization constant, degj,t the degree of node j at time t and \u03b4j,1 the Kronecker del function, so parameter \u03b2 is only nonzero for the root. Given a dataset composed of S threads D := {x(1), . . . , x(S)} with respective sizes |x(k)|, k  {1, . . . S}, the parameter vector \u03b8 can be learned by minimizing\n\u2212log L(D; \u03b8) = \u2212 S \ufffd k=1 |x(k)| \ufffd t=2 log p\u03b8(x(k) t+1|x(k) t ).\n(19)\nWe learn the parameters using the Slashdot dataset, which consists of S = 9, 820 threads, containing more than 2 \u00b7 106 comments among 93, 638 users. In Slashdot, the most relevant feature is the preferential attachment, as detailed in G\u00b4omez et al. [2013]. This will have implications in the optimal control solution, as we show later.\n# 4.3 Control interaction\nThe control interaction is done by highlighting a single comment of the conversation. We assume a behavioural model for the user inspired by Craswell et al. [2008], where the user looks at the highlighted comment and decides to reply or not. For simplicity, we assume that the user chooses the highlighted comment with a fixed probability p\u2032 = \u03b1/(1 + \u03b1) and with probability 1 \u2212p\u2032 she chooses to ignore it. If the highlighting of the comment is ignored, the thread grows according to the uncontrolled process. Therefore, \u03b1 parametrizes the strength of the influence the controller has on the user. For \u03b1 \u2192\u221e, we can fully control the behaviour and for \u03b1 = 0, the thread evolves according to the uncontrolled process. A typical control would have a small \u03b1 as usually the influence of an controlling agent on a social systems is weak.\n# 4.4 Experimental Setup\nTo evaluate the proposed framework we use a simulated environment, without real users. We consider a finite horizon task with T = 50 with the goal to maximize the h-index at end-time, starting from a thread with a single node as initial condition. The state-space consists of 50! \u2248364 states. The thread grows in discrete time-steps. At each time-step, a new node is added to the thread by a (simulated) user. For that, we first choose which node to highlight (optimal action) as described in section 3.4 using equation (16). We then simulate the user as described in section 4.3, so the highlighted node is selected with probability p\u2032 = \u03b1/(1 + \u03b1) as the parent of the new node. Otherwise, with probability 1 \u2212p\u2032, the user ignores the highlighted node and the parent of the new node is chosen according to the Slashdot model, equation (19). This is repeated until the end time.\n# 4.5 Experimental Results\nWe first analyse the performance of the adaptive importance sampling algorithm described in section 3.3 for different fixed values of \u03bb. Figure 4 shows the effective sample size (EffSS), equation (15) as a function of the number of iterations of the CE method. We observe that the EffSS increases to reach a stable value. As expected, large temperature (easier) problems result in higher values of EffSS. We can also see that, even for hard problems with low temperature, the obtained EffSS is significantly larger than zero, which allows us to compute the KL-optimal control. In general, the curves are less smooth for smaller values of \u03bb, because a few qualitatively better samples dominate the EffSS, resulting in higher variance. On the other hand we also observe that the EffSS never reaches 100%. This is expected, as this would mean that our parametrized importance sampler perfectly resembles the optimal control, and this is not possible due to the approximation error introduced by the use of features. We can better understand the learned control by analysing the linear coefficients of the parametrized optimal cost-to-go, equation (13), for this problem. Figure 5 shows the feature weights \u03c9k(t), at different times t = 1, . . . , T, after convergence of the CE method. Feature k corresponds to the number of nodes with degree k in the tree, after a new node arrives. The parent node to which the new node\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0a55/0a555f30-d277-444b-b343-8ee91433555b.png\" style=\"width: 50%;\"></div>\nFigure 4: Evaluation of the inference step: The Effective sampling size (EffSS) increases after several iterations of the cross-entropy method. As expected, large values of the temperature \u03bb result in higher values of EffSS. We use M = 105 samples to compute the EffSS. The EffSS is measured here in percent of the maximum number of samples M.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4c5d/4c5df5e4-c335-4d21-914b-adaa7464c270.png\" style=\"width: 50%;\"></div>\nFigure 5: The learned importance sampler: The figure shows the time-dependent parameters of the learned expected cost-to-go for \u03bb = 0.2. Each pixel is the parameter of a feature at a certain time. The features are the degrees of the parent node after the new child attaches. The colour represents the weight of the parameter. Large negative weights (pixels in blue colour) stand for a low cost and thus a desirable state, while large positive weights (red pixels) stand for high cost and thus undesirable states. At all times there is a desirable degree which the parent should have and higher as well as lower degrees are inhibited. This desirable degree is small at early times and becomes larger at later times.\nhas attached is thereby the only node whose degree changes (the degree increases by 1). Thus a high weight for a feature which measures the number of nodes with a certain degree k results in a low probability of attaching to a node with degree k \u22121. Conversely low, or large negative weights thus correspond to nodes which have a high probability of becoming the parent of the next node which is added. We observe that there is an intermediate preferred degree (large negative weight, in blue). This is the preferred degree of the parent of the new node, and this preferred degree increases with time, reaching a value of 5 at t = 50. Does this strategy make sense? The maximum h-index of a tree of 50 nodes is 7, and it is achieved if 6 nodes have exactly 7 children and one node has 8. However, achieving such a configuration requires a very precise control. For example, increasing too much the degree of a node, say up to 9, prevents the maximum h-index to be reached, as there are not enough links left, due to the finite horizon. Thus, in this setting, steering for the maximal possible h-index is not optimal. The controller prefers all parents to have a degree of 5 and not less, but also not much more. As having more than five parents with degree at least five will result in an h-index of 5 we conclude that the control seems to aim for a target h-index of 5, while preventing wasting links to higher or lower degree nodes, which would not contribute to achieve that target. The interpretation of why the preferred degree increases with time involves the uncontrolled dynamics. Remember that the most relevant term in equation (19) for the considered dataset corresponds to the preferential attachment, parametrized by \u03b1. This term boosts high-degree nodes to get more links. If this happens, most of the links end up attached to a few parents, and this effect can only be suppressed by a strong control. The controller prevents that self-amplifying effect by aiming initially for an overall low degree, preventing a high impact of the preferential attachment. This keeps the process controllable and allows for a more equal distribution of the links. After having evaluated the sampling algorithm, we evaluate the proposed mechanism for actual control of the conversation thread. As described in section 3.4, in our simulated scenario, we highlight the node as the parent which minimizes the computed expected cost-to-go. Figure 6 shows the evolution of the h-index using different control mechanisms. The blue curve shows how the h-index changes under the uncontrolled dynamics. On average, it reaches a maximum of about 3.7 after 50 time steps. In green, we show the evolution of the h-index under a KL-optimal controlled case, for temperature \u03bb = 0.2. As expected, we observe a faster increase, on average, than using the uncontrolled dynamics. The maximum is about 4.7. The red and black curves show the evolution of the h-index using the control mechanism described in subsections 3.4 and 4.3, where we select actions using the expected cost-to-go J\u03bb KL of the KLoptimal control with \u03bb = 0.2, for \u03b1 = 1 and \u03b1 = 0.5, respectively. In both cases the obtained h-index is even higher than the one obtained with the KL-control relaxation. Therefore, the objective for this task, to increase the h-index, can be achieved through our action selection strategy. As expected, a stronger interaction strength \u03b1 = 1 leads to higher h-indices than a lower strength \u03b1 = 0.5. Finally, in Figure 7 we show examples of a real discussion thread from the dataset (Slashdot), a thread generated from the learned model (uncontrolled process) and one resulting from applying our action selection strategy. The latter has higher h-index.\n# 5 Discussion\nWe have addressed the problem of controlling the growth process of a network using stochastic optimal control with the objective to optimize a structural cost that depends on the topology of the\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8e6f/8e6faa04-8ea1-4fc5-8aa2-7ece54fa8411.png\" style=\"width: 50%;\"></div>\nFigure 6: Evaluation of the actual control: uncontrolled dynamics (blue), KL-optimally controlled dynamics (green) action selection based control for \u03b1 = 1 (red) and \u03b1 = 0.5 (black). The KLoptimally controlled dynamics, which optimize the sum of the \u03bb-weighted KL-term and the end cost, shifts the final mean value from about 3.7 to about 4.7. The action selection based control, which is aiming to optimize the end cost only, is able to shift the h-index to even higher values then the KL-optimal control. For the controlled dynamics, \u03bb = 0.2 for all three cases. To compute the control in each time-step we sample 1000 trajectories. The statistics where computed using 1000 samples for each of the three cases.\ngrowing network. The main difficulty of such a problem is the exploding size of the state space, which grows (super-)exponentially with the number of nodes in the network and renders exact dynamic programming infeasible. We have shown that a convenient way to address this problem is using KL-control, where a regularizer is introduced which penalizes deviations from the natural network growth process. One advantage of this approach is that the optimal control can be solved by sampling. The difficulty of the sampling is controlled by the strength of the regularization, which is parametrized by a temperature parameter \u03bb: for high temperatures the sampling is easy, while for low temperatures, it becomes hard. This is in contrast to standard dynamic programming, whose complexity is directly determined by the number of states and independent of \u03bb. In order to tackle the more challenging low temperature case, we have introduced a featurebased parametrized importance sampler and used adaptive importance sampling for optimizing its parameters. This allows us to sample efficiently in the low temperature regime. For control problems which cannot directly be formulated as KL-control problems, we have proposed to use the solution of a related KL-control problem as a proxy to estimate the effective values of possible next network states. These expected effective values are subsequently used in a greedy strategy for action selection in the original control problem. This action selection mechanism benefits from the sparsity induced by the optimal KL-control solution. We have illustrated the effectiveness of our method on the task of influencing the growth of\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/663e/663e6e44-fe60-4f4c-9ef5-c22a1210566b.png\" style=\"width: 50%;\"></div>\nFigure 7: Examples of threads. A thread from the data (Slashdot), an uncontrolled thread generated from the model and a controlled thread. The nodes that contribute to the h-index are coloured in yellow. The h-index for the data and the uncontrolled thread is 4 and 6 for the controlled one.\nconversation cascades. Our control seeks to optimize the structure of the cascade, as it evolves in time, to maximize the h-index at a final time. This task is non-trivial and characterized by a sparse, delayed reward, since the h-index remains constant during most of the time, and therefore a greedy strategy is not possible. Our approach for controlling network growth is inspired in recent approaches to optimal decisionmaking with information-processing constraints Todorov [2009], Tishby and Polani [2011], Kappen et al. [2012], Theodorou and Todorov [2012], Rawlik et al. [2012]. The Cross-Entropy method has been explored previously in the continuous case Kappen and Ruiz [2016]. The continuous formulation of this class of problems has been used in robotics, using parametrized policies Theodorou et al. [2010], Levine and Koltun [2013], G\u00b4omez et al. [2014]. In economics, the question of altering social network structure in order to optimize utility has been addressed mainly from a game theoretical point of view, under the name of strategic network formation Jackson and Watts [2002], Bloch and Jackson [2007]. To the best of our knowledge, the problem of network formation has not yet been addressed from a stochastic optimal control perspective. The standard approach to address the problem of controlling a complex, networked system is to directly try to control the dynamics on the network Liu et al. [2011], Cornelius et al. [2013]. This approach considers the classical notion of structural controllability as the capability of being driven from any initial state to any desired final state within finite time. Optimal control in thus referred to the situation where a network can be fully controlled using only one driving signal. This idea is also prevalent in the influence maximization problem in social networks Kempe et al. [2003], Farajtabar et al. [2014, 2015], which consists in finding the subset of driver (most influential) nodes in a network. Since the controllability of the dynamics on the network depends crucially on the topology, several works have considered the idea of changing the network structure is some way that favours structural controllability. For example, the perturbation approach introduced in Wang et al. [2012] looks for the minimum\nnumber of links that needs to be added so that the perturbed network can be fully controlled using a single input signal. In Hou et al. [2015], a method to enhance structural controllability of a directed network by changing the direction of a small fraction of links is proposed. More recently, Wang et al. [2016] analyzed node augmentation of directed networks while insisting that the minimum number of drivers remains unchanged. The main difference between our approach and these approaches is that, rather than considering the controllability of the dynamical system on the underlying network, our optimal control task is defined on the structure of the network itself, regardless of the dynamical system defined on it. In some sense, our results complement these approaches. For example, one could use our optimal control approach to shape the growth of the network in a way that the structural controllability, understood as the state cost function, is optimized.\n# Acknowledgements\nThis project is co-financed by the Marie Curie FP7-PEOPLE-2012-COFUND Action, Grant agreement no: 600387, the Marie Curie Initial Training Network NETT, project N. 289146 and the Spanish Ministry of Economy and Competitiveness under the Mar\u00b4\u0131a de Maeztu Units of Excellence Programme (MDM-2015-0502).\n# A Adaptive Importance Sampling for KL-Optimal Control Computation using the Cross-Entropy method\nHere we show how the time-dependent weights \u03c9k(t) of the importance sampler are updated such that \ufffdu\u03c9(x\u2032|x, t) becomes closer to the optimal sampling distribution. This corresponds to the second step of the Cross-Entropy method described in subsection 3.3. For clarity in the derivations, we will replace p(x1:T|x, 0) and u\u2217 KL(x1:T|x, 0) by p and u\u2217 KL, respectively, in the expectations. The closeness of the two distributions \ufffdu\u03c9(x\u2032|x, t) and u\u2217 KL(x\u2032|x, t) can be measured as the cross entropy between the path x1:T probabilities under these two Markov processes:\n \ufffd where the constant term \u27e8log u\u2217 KL(x1:T|x, 0)\u27e9u\u2217 KL is dropped. We minimize equation (20) by gradient descent. At iteration l, the gradient D(\u03c9(l)) with respec to \u03c9k(t) is given by\n(20)\nwith the normalization constant Z. This leads to\nwhere we can drop the first term as it is independent of \u03c9(t). The second term can be evaluated usin the definition of \ufffdJKL, equation (13). Further, plugging in Z we get\nwhere we have used the estimates from the importance sampling step and equation The update rule for the parameters becomes\n<div style=\"text-align: center;\">where we have used the estimates from the importance sampling step and equation (9). The update rule for the parameters becomes</div>\n(21)\n(22)\n(23)\nAlgorithm 1 Cross-Entropy Method for KL-control\nRequire: importance sampler \ufffdu\u03c9,\nfeature space \u03c8(\u00b7),\nnumber of samples M,\nlearning rate \u03b7\nl \u21900\n\u03c9(l)\nk (t) \u21900, Initialize weights for all k, t, l\nx(i)\nt+1:T \u2190draw M sample trajectories \u223c\ufffdu\u03c9(l), i = 1, . . . , M\nrepeat\ncompute gradient \u2202D(\u03c9(l))\n\u2202\u03c9k(t) using equation (21)\n\u03c9(l+1)\nk\n(t) \u2190\u03c9(l)\nk (t) + \u03b7 \u2202D(\u03c9(l))\n\u2202\u03c9k(t) for all k, t, l\nx(i)\nt+1:T \u2190draw M samples \u223c\ufffdu\u03c9(l+1)\nl \u2190l + 1\nuntil convergence\n# B Analyzing the KL-optimal cost-to-go based action selection\nWe have introduced an action selection framework which is based on an approximation of the optimal cost-to-go J(x\u2032, t) by the optimal cost-to-go J\u03bb KL(x\u2032, t + 1) of a parametrized family of KL-control problems which share the same state cost r(x, t). Why is this a good idea? Consider the two extreme cases where the temperature \u03bb, which parametrizes the family of equivalent KL-control problems, is zero or infinite, respectively.\nWe have introduced an action selection framework which is based on an approximation of the optimal cost-to-go J(x\u2032, t) by the optimal cost-to-go J\u03bb KL(x\u2032, t + 1) of a parametrized family of KL-control problems which share the same state cost r(x, t). Why is this a good idea? Consider the two extreme cases where the temperature \u03bb, which parametrizes the family of equivalent KL-control problems, is zero or infinite, respectively. Extreme case \u03bb \u21920 (zero temperature): The total cost in the KL-control problem becomes equal to the total cost in the original control problem, equation (1), as the KL term vanishes. The KL-optimal control becomes deterministic: \ufffd \ufffd\nExtreme case \u03bb \u21920 (zero temperature): The total cost in the KL-control problem becomes equal to the total cost in the original control problem, equation (1), as the KL term vanishes. The KL-optimal control becomes deterministic:\nwhere Z is a normalization constant. Thus, for \u03bb \u21920, the KL-control problem becomes identical to the original problem if the syst is fully controllable, i.e. for every t, x and \u02dcx there is a u\u02dcx \u2208U such that p(x\u2032|x, t, u\u02dcx) = \u03b4\u02dcx,x\u2032.\nJ\u221e KL(x, t) = lim \u03bb\u2192\u221eJ\u03bb KL(x, t)\n(24)\nThus, for \u03bb \u2192\u221e, the KL-optimal cost-to-go becomes equal to the total cost in the original contro problem under the uncontrolled dynamics (using u = 0). Having this equation (16) can be written as\nu\u2217(x, t) \u2248argminu \ufffd r(x, t) + \ufffd C \ufffd x\u2032, t + 1, 0 \ufffd\ufffd P(x\u2032|x,u,t) \ufffd .\n\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd In this case, the action selection is equivalent to optimize an expected total cost assuming the system will evolve according to the free dynamics in the future. Thus the infinite temperature control can be used if one wants to guarantee that the obtained solution will not be worse than the solution obtained with zero control. Choosing a lower \u03bb, however, might in practice work better (as we also have shown in section 4) but has no theoretical guarantee. We can conclude that our action selection strategy is meaningful in the two extreme cases, \u03bb \u2192\u221e and \u03bb \u21920. Also this analysis suggests that, if the available set of actions u \u2208U offers a strong control over the system dynamics, it is more convenient to use a J\u03bb KL with a low temperature \u03bb.\n# References\nH. Amini, R. Cont, and A. Minca. Resilience to contagion in financial networks. Mathematical finance, 26(2):329\u2013365, 2016. D. P. Bertsekas. Dynamic programming and optimal control, volume 1. Athena Scientific Belmont, MA, 1995. F. Bloch and M. O. Jackson. The formation of networks with transfers among players. Journal of Economic Theory, 133(1):83\u2013110, 2007. D. Centola. The spread of behavior in an online social network experiment. Science, 329(5996): 1194\u20131197, 2010. D. Centola and A. Baronchelli. The spontaneous emergence of conventions: An experimental study of cultural evolution. Proceedings of the National Academy of Sciences, 112(7):1989\u20131994, 2015. doi: 10.1073/pnas.1418838112. S. P. Cornelius, W. L. Kath, and A. E. Motter. Realistic control of network dynamics. Nature Communications, 4(1942), Jun 2013. doi: 10.1038/ncomms2939. N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An experimental comparison of click position-bias models. In Proceedings of the 2008 International Conference on Web Search and Data Mining, pages 87\u201394. ACM, 2008. R. Dai and M. Mesbahi. Optimal topology design for dynamic networks. In Decision and Control and European Control Conference, 2011 50th IEEE Conference on, pages 1280\u20131285, 2011. P.-T. De Boer, D. P. Kroese, S. Mannor, and R. Y. Rubinstein. A tutorial on the cross-entropy method. Annals of operations research, 134(1):19\u201367, 2005.\n(26)\nR. Douc and O. Capp\u00b4e. Comparison of resampling schemes for particle filtering. In Image and Signal Processing and Analysis, 2005. ISPA 2005. Proceedings of the 4th International Symposium on, pages 64\u201369. IEEE, 2005. V. M. Egu\u00b4\u0131luz and K. Klemm. Epidemic threshold in structured scale-free networks. Physical Review Letters, 89(10):108701, Aug 2002. M. Farajtabar, N. Du, M. Gomez-Rodriguez, I. Valera, H. Zha, and L. Song. Shaping social activity by incentivizing users. In Advances in neural information processing systems, pages 2474\u20132482, 2014. M. Farajtabar, Y. Wang, M. Rodriguez, S. Li, H. Zha, and L. Song. COEVOLVE: A joint point process model for information diffusion and network co-evolution. In Advances in Neural Information Processing Systems, pages 1945\u20131953, 2015. P. Gai and S. Kapadia. Contagion in financial networks. Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, 2010. ISSN 1364-5021. doi:10.1098/rspa.2009.0410. J. Gao, Y.-Y. Liu, R. M. D\u2019Souza, and A.-L. Barab\u00b4asi. Target control of complex networks. Nature communications, 5(5415), 2014. P. Giudici and A. Spelta. Graphical network models for international financial flows. Journal of Business & Economic Statistics, 34(1):128\u2013138, 2016. S. Goel, A. Anderson, J. Hofman, and D. J. Watts. The structural virality of online diffusion. Management Science, 62(1):180\u2013196, 2015. V. G\u00b4omez, A. Kaltenbrunner, and V. L\u00b4opez. Statistical analysis of the social network and discussion threads in Slashdot. In Proceedings of the 17th international conference on World Wide Web, pages 645\u2013654. ACM, 2008. V. G\u00b4omez, H. J. Kappen, N. Litvak, and A. Kaltenbrunner. A likelihood-based framework for the analysis of discussion threads. World Wide Web, 16(5-6):645\u2013675, 2013. ISSN 1386-145X. doi: 10.1007/s11280-012-0162-8. V. G\u00b4omez, H. J. Kappen, J. Peters, and G. Neumann. Policy search for Path-Integral control. In Machine Learning and Knowledge Discovery in Databases, pages 482\u2013497. Springer, 2014. S. Gonzalez-Bailon, A. Kaltenbrunner, and R. E. Banchs. The structure of political discussion networks: a model for the analysis of online deliberation. Journal of Information Technology, 25(2): 230\u2013243, 2010. J. D. Hol, T. B. Schon, and F. Gustafsson. On resampling algorithms for particle filters. In Nonlinear Statistical Signal Processing Workshop, pages 79\u201382. IEEE, 2006. L. Hou, S. Lao, M. Small, and Y. Xiao. Enhancing complex network controllability by minimum link direction reversal. Physics Letters A, 379(20):1321\u20131325, 2015. M. O. Jackson and A. Watts. The evolution of social and economic networks. Journal of Economic Theory, 106(2):265\u2013295, 2002.\nH. J. Kappen. Linear theory for control of nonlinear stochastic systems. Physical Review Letters, 95 (20):200201, 2005. doi: 10.1103/PhysRevLett.95.200201. H. J. Kappen and H. C. Ruiz. Adaptive importance sampling for control and inference. Journal of Statistical Physics, 162(5):1244\u20131266, 2016. ISSN 1572-9613. doi: 10.1007/s10955-016-1446-7. H. J. Kappen, V. G\u00b4omez, and M. Opper. Optimal control as a graphical model inference problem. Machine Learning, 87(2):159\u2013182, 2012. D. Kempe, J. Kleinberg, and \u00b4E. Tardos. Maximizing the spread of influence through a social network. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 137\u2013146. ACM, 2003. D. Laniado, R. Tasso, Y. Volkovich, and A. Kaltenbrunner. When the wikipedians talk: network and tree structure of wikipedia discussion pages. In Proceedings of the Fifth International Conference on Weblogs and Social Media, pages 177\u2013184, 2011. J. Leskovec, M. McGlohon, C. Faloutsos, N. S. Glance, and M. Hurst. Patterns of cascading behavior in large blog graphs. In SIAM International Conference on Data Mining, volume 7, pages 551\u2013556, 2007. S. Levine and V. Koltun. Guided policy search. Proceedings of The 30th International Conference on Machine Learning, 3:1\u20139, 2013. Y.-Y. Liu, J.-J. Slotine, and A.-L. Barab\u00b4asi. Controllability of complex networks. Nature, 473(7346): 167\u2013173, 2011. B. Mohar and T. Pisanski. How to compute the Wiener index of a graph. Journal of Mathematical Chemistry, 2(3):267\u2013277, 1988. ISSN 0259-9791. doi: 10.1007/BF01167206. R. Olfati-Saber, A. Fax, and R. M. Murray. Consensus and cooperation in networked multi-agent systems. Proceedings of the IEEE, 95(1):215\u2013233, 2007. R. Pastor-Satorras and A. Vespignani. Epidemic spreading in scale-free networks. Physical Review Letters, 86(14):3200\u20133203, Apr 2001. doi: 10.1103/PhysRevLett.86.3200. K. Rawlik, M. Toussaint, and S. Vijayakumar. On stochastic optimal control and reinforcement learning by approximate inference. In Int. Conf. on Robotics Science and Systems (R:SS 2012), 2012. E. Theodorou and E. Todorov. Relative entropy and free energy dualities: Connections to path integral and KL control. In Decision and Control, 2012 IEEE 51st Annual Conference on, pages 1466\u2013 1473. IEEE, 2012. E. Theodorou, J. Buchli, and S. Schaal. A generalized path integral control approach to reinforcement learning. Journal of Machine Learning Research, 11(Nov):3137\u20133181, 2010. N. Tishby and D. Polani. Information theory of decisions and actions. In Perception-action cycle, pages 601\u2013636. Springer, 2011.\nE. Todorov. Efficient computation of optimal actions. Proceedings of the National Academy of Sciences, 106(28):11478\u201311483, 2009. J. Wang, X. Yu, and L. Stone. Effective augmentation of complex networks. Scientific Reports, 6: 25627, 2016. W.-X. Wang, X. Ni, Y.-C. Lai, and C. Grebogi. Optimizing controllability of complex networks by minimum structural perturbations. Physical Review E, 85(2):026115, Feb 2012. doi: 10.1103/ PhysRevE.85.026115. G. Yan, G. Tsekenis, B. Barzel, J. J. Slotine, Y. Y. Liu, and A. L. Barabasi. Spectrum of controlling and observing complex networks. Nature Physics, 11(9):779\u2013786, 2015.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of controlling the growth dynamics of complex networks, particularly focusing on the topology of networks that influences their dynamical processes. Previous methods primarily dealt with network controllability without considering how to influence the evolving structure of the network itself. This gap necessitates a new approach that can effectively manage the growth of network structures to optimize their performance.",
        "problem": {
            "definition": "The problem is defined as influencing the growth of a network in a way that optimizes its structural properties over time, specifically focusing on how to control the addition and deletion of nodes and links as the network evolves.",
            "key obstacle": "The main challenge is the curse of dimensionality, as the state space of the network grows super-exponentially with the number of nodes, making conventional dynamic programming approaches infeasible."
        },
        "idea": {
            "intuition": "The idea is inspired by the need to optimize network growth processes through a control mechanism that can adapt to the dynamics of the network as it evolves.",
            "opinion": "The proposed method involves framing the problem as a stochastic optimal control issue, utilizing a Kullback-Leibler control approach to approximate optimal actions in the context of network growth.",
            "innovation": "The key innovation lies in the introduction of adaptive importance sampling methods that efficiently approximate optimal control solutions in high-dimensional state spaces, which significantly differ from traditional methods that struggle with computational feasibility."
        },
        "method": {
            "method name": "Kullback-Leibler Control for Network Growth",
            "method abbreviation": "KL-Control",
            "method definition": "KL-Control is a stochastic optimal control method that aims to influence the growth of network structures by minimizing a cost function that penalizes undesired topologies while approximating the control problem using probabilistic inference.",
            "method description": "The method employs a Kullback-Leibler divergence-based approach to optimize control actions that influence network growth.",
            "method steps": [
                "Formulate the network growth problem as a stochastic optimal control problem.",
                "Define the cost function that penalizes undesirable network structures.",
                "Use KL-control to approximate the optimal cost-to-go.",
                "Implement adaptive importance sampling to efficiently estimate control actions."
            ],
            "principle": "This method is effective because it leverages the sparsity of the optimal solution in the KL-control framework, allowing for a focused selection of relevant states and actions, thereby reducing computational complexity."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted in a simulated environment modeling online conversation threads, using a dataset from Slashdot with 9,820 threads. The goal was to maximize the h-index of the conversation threads over a finite horizon of 50 time steps.",
            "evaluation method": "The performance of the KL-control method was assessed by comparing the h-index of controlled and uncontrolled dynamics, measuring how effectively the proposed method could influence the structure of the conversation threads."
        },
        "conclusion": "The experiments demonstrated that the KL-control approach successfully optimized the h-index of growing conversation threads, achieving better structural properties compared to uncontrolled dynamics, thus validating the effectiveness of the proposed control mechanism.",
        "discussion": {
            "advantage": "The primary advantage of the proposed approach is its ability to efficiently manage high-dimensional control problems through adaptive sampling, which allows for effective action selection in complex networks.",
            "limitation": "One limitation is that the method relies on the assumptions of the KL-control framework, which may not apply universally to all types of network growth scenarios.",
            "future work": "Future research could explore the application of this control framework to other types of complex networks and investigate ways to further enhance the adaptability and efficiency of the control mechanisms."
        },
        "other info": {
            "acknowledgements": "This project is co-financed by the Marie Curie FP7-PEOPLE-2012-COFUND Action, Grant agreement no: 600387, and the Spanish Ministry of Economy and Competitiveness under the Mar\u00eda de Maeztu Units of Excellence Programme (MDM-2015-0502)."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "This paper addresses the issue of controlling the growth dynamics of complex networks, particularly focusing on the topology of networks that influences their dynamical processes."
        },
        {
            "section number": "2.1",
            "key information": "The problem is defined as influencing the growth of a network in a way that optimizes its structural properties over time, specifically focusing on how to control the addition and deletion of nodes and links as the network evolves."
        },
        {
            "section number": "2.2",
            "key information": "The key innovation lies in the introduction of adaptive importance sampling methods that efficiently approximate optimal control solutions in high-dimensional state spaces."
        },
        {
            "section number": "3.1",
            "key information": "The method employs a Kullback-Leibler divergence-based approach to optimize control actions that influence network growth."
        },
        {
            "section number": "6.1",
            "key information": "One limitation is that the method relies on the assumptions of the KL-control framework, which may not apply universally to all types of network growth scenarios."
        },
        {
            "section number": "6.3",
            "key information": "The main challenge is the curse of dimensionality, as the state space of the network grows super-exponentially with the number of nodes, making conventional dynamic programming approaches infeasible."
        },
        {
            "section number": "6.4",
            "key information": "Future research could explore the application of this control framework to other types of complex networks and investigate ways to further enhance the adaptability and efficiency of the control mechanisms."
        }
    ],
    "similarity_score": 0.5335438945124352,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-15-0239_large/papers/Action selection in growing state spaces_ Control of Network Structure Growth.json"
}