{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2305.06572",
    "title": "Scheduling Multi-Server Jobs with Sublinear Regrets via Online Learning",
    "abstract": "Multi-server jobs that request multiple computing resources and hold onto them during their execution dominate modern computing clusters. When allocating the multi-type resources to several co-located multi-server jobs simultaneously in online settings, it is difficult to make the tradeoff between the parallel computation gain and the internal communication overhead, apart from the resource contention between jobs. To study the computation-communication tradeoff, we model the computation gain as the speedup on the job completion time when it is executed in parallelism on multiple computing instances, and fit it with utilities of different concavities. Meanwhile, we take the dominant communication overhead as the penalty to be subtracted. To achieve a better gain-overhead tradeoff, we formulate an cumulative reward maximization program and design an online algorithm, named OGASched, to schedule multi-server jobs. OGASched allocates the multi-type resources to each arrived job in the ascending direction of the reward gradients. It has several parallel sub-procedures to accelerate its computation, which greatly reduces the complexity. We proved that it has a sublinear regret with general concave rewards. We also conduct extensive trace-driven simulations to validate the performance of OGASched. The results demonstrate that OGASched outperforms widely used heuristics by $11.33\\%$, $7.75\\%$, $13.89\\%$, and $13.44\\%$, respectively.",
    "bib_name": "zhao2023schedulingmultiserverjobssublinear",
    "md_text": "# Scheduling Multi-Server Jobs with Sublinear Regrets via Online Learning\nHailiang Zhao, Shuiguang Deng, Senior Member, IEEE, Zhengzhe Xiang, Xueqiang Yan, Jianwei Yi Schahram Dustdar, Fellow, IEEE, and Albert Y. Zomaya, Fellow, IEEE\nAbstract\u2014Multi-server jobs that request multiple computing resources and hold onto them during their execution dominate modern computing clusters. When allocating the multi-type resources to several co-located multi-server jobs simultaneously in online settings, it is difficult to make the tradeoff between the parallel computation gain and the internal communication overhead, apart from the resource contention between jobs. To study the computation-communication tradeoff, we model the computation gain as the speedup on the job completion time when it is executed in parallelism on multiple computing instances, and fit it with utilities of different concavities. Meanwhile, we take the dominant communication overhead as the penalty to be subtracted. To achieve a better gain-overhead tradeoff, we formulate an cumulative reward maximization program and design an online algorithm, named OGASCHED, to schedule multi-server jobs. OGASCHED allocates the multi-type resources to each arrived job in the ascending direction of the reward gradients. It has several parallel sub-procedures to accelerate its computation, which greatly reduces the complexity. We proved that it has a sublinear regret with general concave rewards. We also conduct extensive trace-driven simulations to validate the performance of OGASCHED. The results demonstrate that OGASCHED outperforms widely used heuristics by 11.33%, 7.75%, 13.89%, and 13.44%, respectively.\n5\nIndex Terms\u2014Multi-server job, online gradient ascent, online scheduling, regret analysis.\n# 1 INTRODUCTION\nIn today\u2019s computing clusters, whether in the cloud data centers or at the network edge, many jobs request multiple resources (CPUs, GPUs, etc.) simultaneously and hold onto them during their executions. For example, graph computations [1], federated learning [2], distributed DNN model trainings [3], etc. In this paper, we refer to these jobs as multi-server jobs [4], [5]. Multi-server jobs of diverse resource requirements arrive at the cluster online, which puts great pressure to current resource allocation policies to achieve a high computation efficiency. When allocating the multi-type resources to several colocated multi-server jobs simultaneously in online settings, it is difficult to make the tradeoff between the parallel computation gain and the internal communication overhead, apart from the resource contention between jobs. Here the parallel computation gain refers to the speedup on the job completion time when it is executed in parallelism on multiple comput-\ning instances, which could be modeled with a function of the allocated multi-type resources [6]. Correspondingly, the internal communication overhead refers to the cost caused by non-computation operations such as data synchronization, averaging, message passing, etc., between the distributed workers. To achieve better computation efficiency, we need to consider the following key challenges.\n\u2022 Resource contention with service locality. With service locality, a multi-server job can only be processed by a subset of computing instances where the resource requirements, session affinity [7], and other obligatory constraints are satisfied. When several multiserver jobs arrive simultaneously, how to allocate the limited resources to them without degenerating the computation efficiency is challenging. \u2022 Unknown arrival patterns of jobs. In real-life scenarios, the resource allocation should be made online without the knowledge of future job arrivals. The lack of information on the problem space could lead to a solution far from the global optimum. \u2022 The parallel computation gain does not increase in a linear rate with the quantity of allocated resources. For instance, in distributed DNN model training or federated learning, adding workers (that request more resources) does not improve the training speed linearly [3], [6]. This is because the overhead of all-reduce operation between workers or the averaging of local gradients increase with the number of participated workers, especially when the workers are distributed in different machines and communicate with each other through network [8], [9], [10]. Compared with high-speed intra-node communication channels such\nas NVLink, the inter-node bandwidth through NIC is relatively much slower. Another example is graph computation. Without a well-designed graph partition policy, the speedup of message-passing between graph nodes can be significantly slowed down [1], [11]. The type of resource which dominates the communication overhead varies to different job types. For example, in graph computation jobs, the dominant communication overhead lies in the internal input-output data transferring between the interdependent CPU- and memory-intensive tasks [12]. However, the dominant overhead of the distributed training of DNNs lies in the data averaging and synchronizing between the GPU-intensive workers through network [13]. This variety greatly complicates the theoretical analysis for the gain-overhead tradeoff.\nDespite the vast literature on the online resource allocation algorithms [3], [6], [13], [14], [15], [16], [17], [18], their model formulation and theoretical analysis which places emphasis on the gain-overhead tradeoff is limited. To fill the theoretical gap, in this paper, we propose an online scheduling algorithm, termed as OGASCHED, to learn to allocate multi-type resources to co-located multi-server jobs online to maximize the overall computation efficiency. We try to analyze the tradeoff in a generic way. The generality is embodied in the following points. First of all, different from the specific works on deep learning jobs [6], [13], [3] or query jobs [12], we allow different types of multi-server jobs to co-locate in the cluster which consists of heterogeneous computing resources. Different job types can have different resource requirements while different computing instances can be equipped with diverse quantities and types of resources. Secondly, we adopt general zero-startup nondecreasing utility functions to model the parallel computation gain in terms of the job completion time. Compared to existing literature, we allow the utilities to be diverse in their level of concavity. Specifically, we provide both analysis and experiments on linear, polynomial, logarithmic, and reciprocal utilities. Thirdly, we makes no assumptions on the arrival patterns of multi-server jobs. OGASCHED requests no knowledge on the job arrival distributions but tries to learn them to make better scheduling decisions. In our model formulation, the computation efficiency is modeled in the way of cumulative reward. Time is slotted, and the cumulative reward is obtained by summing up the reward in each time slot, where a single-time reward is a linear aggregation of each job\u2019s reward. Further, a job\u2019s reward at each time is designed as the achieved parallel computation gain aggregated over the allocated resources minus the penalty introduced by the dominant communication overhead. At each time, OGASCHED allocates resources to each arrived job in the direction that makes the gradient of the reward increase. OGASCHED is capable of handling high dimensional inputs in stochastic scenarios with unpredictable behaviors. We adopt regret, i.e., the gap on the cumulative reward between the proposed online algorithm and the offline optimum achieved by an oracle [19], to analyze the performance lower bound of OGASCHED. We prove that, OGASCHED has a State-of-the-Art (SOTA) regret,\nwhich is sublinear with the time slot length and the number of job types. This work fulfills one of the key deficiencies of the past works in the modeling and analysis of the gainoverhead tradeoff for multi-server jobs. The contributions are summarized as follows.\n\u2022 We systematically study the resource allocation of co-located multi-server jobs in terms of the tradeoff between the parallel computation gains and the internal communication overheads. Our study is general in scenario settings and it sufficiently takes the characters of the diminishing marginal effect of gains into consideration. \u2022 We propose an algorithm, i.e., OGASCHED, to learn to strike a balanced computation-communication tradeoff. OGASCHED has no assumptions on the job arrival patterns. With a nice setup (defined in Sec. 3.1), OGASCHED achieves a SOTA regret O \ufffdHG \u00b7 \u221a T \ufffd for general concave non-linear rewards, where T is the time slot length, and HG (formally defined in (49)) is parameter that characterizes the bipartite graph model. OGASCHED is accelerated by well-designed parallel sub-procedures. The parallelism helps yield a complexity of O \ufffdlog(K) \ufffd , where K is the number of resource types. \u2022 We conduct extensive trace-driven simulations to validate the performance of OGASCHED. The simulation results show that OGASCHED outperforms widely used heuristics including DRF [20], FAIRNESS, BINPACKING, and SPREADING by 11.33%, 7.75%, 13.89%, and 13.44%, respectively. We also provide large-scale validations.\nThe rest of this paper is organized as follows. We formulate the online scheduling problem for multi-server jobs in Sec. 2. We then present the design details of OGASCHED with regret analysis and discuss its extensions in Sec. 3. We demonstrate the experimental results in Sec. 4, and discuss related works in Sec. 5. Finally, we conclude this paper in Sec. 6.\n# 2 BIPARTITE SCHEDULING WITH REGRETS\nWe consider a cluster of heterogenous computing instances serving several types of multi-server jobs. Here the computing instances can be VMs in clouds, or local servers at the network edge. The computing instances work collaboratively to provide resources to serve the considered jobs. Different computing instances are equipped with different types and quantities/specifications of resources, including CPU cores, memory, bandwidth, GPUs, etc. Jobs of different types can have different demands on them. Key notations used in this paper are summarized in Tab. 1.\n# 2.1 Online Bipartite Scheduling\nWe use a bipartite graph G = (L, R, E) to model the jobserver constraints, as shown in Fig. 1. In graph G, L is the set of job types and indexed by l while R is the set of computing instances and indexed by r. The connections between the job types and the computing instances are recorded in E.\n<div style=\"text-align: center;\">TABLE 1 Summary of key notations.</div>\nNOTATION\nDESCRIPTION\nT\nTime horizon of length T\nG = (L, R, E)\nThe bipartite graph\nl \u2208L\nA job type (port)\nr \u2208R\nA computing instance\n(l, r) \u2208E\nThe edge (channel) between l and r\n\u2200r : Lr\nThe set of job types connect to r\n\u2200l : Rl\nThe set of computing instances connect to l\nx(t)\nThe job arrival status at time t\ny(t)\nThe scheduling decision at time t\nK\nThe set of different types of resources\n\u2200l : al\nResource requirements of type-l job\n\u2200r, k : ck\nr\nThe number of type-k resources equipped by r\nq\n\ufffd\nx(t), y(t)\n\ufffd\nThe reward of time t\n\u2200k : fk(\u00b7)\nComputation gain of type-k devices\n\u2200k : \u03b2k \u2208[0, 1]\nCoefficient of type-k communication overhead\nBecause of the job-server constraints, type-l job may only be served by a subset of R. We denote the subset by \ufffd \ufffd\n(1)\nSimilarly, we use\n(2)\n\ufffd \ufffd to represent the set of job types that connect to computing instance r. We designate each job type l \u2208L as port and each connection (l, r) \u2208E as channel. G is called right d-regular iff the indegree of each right vertex is d, i.e., \u2200r \u2208R, |Lr| = d.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4eb0/4eb0c017-8ff4-44aa-8b59-ef6dc2c524d5.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 1. The bipartite graph model for online job scheduling.</div>\nFig. 1. The bipartite graph model for online job scheduling.\nTime is discretized, and at each time t \u2208T \u225c{1, ..., T} rom each port, at most one job yields. Let us denote by \ufffd \ufffd\n\ufffd \ufffd \u2208L  \ufffd \ufffd the job arrival status at time t. We do not make any assumption on the job arrival patterns or distributions. The cluster has K types of resources, and computing instance r has ck r type-k resources, where k \u2208K \u225c{1, 2, .., K}. For each typel job, we denote its maximum requests on each resource by al = [ak l ]k\u2208K \u2208N|K|. At time t, we use \ufffd \ufffd\n(4)\n\ufffd \ufffd \u2208L\u2208R\u2208K  to denote the scheduling decision. Here we allow yk (l,r)(t) to be fractional. Taking GPU as example, Machine-Learning-\nas-a-Service (MLaaS) platforms support GPU sharing in a space- and time-multiplexed manner by intercepting CUDA APIs [21], [22], [23]. The first constraint is that, through each channel, a job should not be allocated with resources more than it requires. Formally, we have\n(5)\n \u2264  \u2264  \u2200 The second constraint y(t) should satisfy is that, the resources allocated out from any computing instance r should not more than it has: \ufffd\n(6)\n\ufffd \u2208L We denote by Y \u225c \ufffdy \u2208R \ufffd l\u2208L |Rl|\u00d7K | (5) and (6) hold \ufffd to represent the solution space from here on.\n# 2.2 Computation-Communication Tradeoff\nThe performance metric we use for online bipartite scheduling is designed as the gain obtained by the parallel computation through multi-type resources minus the penalty introduced by the dominant communication overheads. Specifically, we denote by ql \ufffdx(t), y(t) \ufffd the reward of port l at time t , and it is formulated as\n(7)\n\ufffd In this formulation, the first part, \ufffd k\u2208K fk(\ufffd r\u2208Rl yk (l,r)(t)), is the parallel computation gain, which is linearly aggregated over each type of resource, in proportional to each resource\u2019s weight. Jobs of different types can have different combinations of weights. fk(\u00b7) is the gain achieved by \ufffd r\u2208Rl yk (l,r)(t) type-k resources collaboratively, where fk(\u00b7) is a zero-startup concave utility defined in R\u22650. Note that \ufffd r\u2208Rl yk (l,r)(t) is the quota of the type-k resources allocated to the type-l job at t. As we have analyzed before, {fk(\u00b7)}k\u2208K are non-decreasing concave functions because the marginal effect of parallel computation decreases successively when increasing participated resources [24], [25]. We expect {fk(\u00b7)}k\u2208K to be continuously differentiable because it helps design a policy that yields a nice lower bound of the reward. The details will be demonstrated in Sec. 3.3. If {fk(\u00b7)}k\u2208K are not differentiable everywhere, we can apply subgradient ascent-related techniques in the policy design. The second part in (7) is maxk\u2208K \ufffd\u03b2k \ufffd r\u2208Rl yk (l,r)(t) \ufffd , which reflects the dominant weighted communication overheads over different types of resources. For example, in federated learning at the edge, the dominant communication overhead lies in the averaging and synchronizing of data between each edge server over the network [26]. Another example is graph computation, in which the job is organized into a direct acyclic graph (DAG), and the dominant communication overhead falls into the data & message passing between CPU- and memory-intensive tasks [12]. {\u03b2k}k\u2208K are the coefficients to balance the gain and the overhead. W.L.O.G., we set each \u03b2k \u2208[0, 1]. Theoretically, the second part of (7) is a penalty, the minimization of which guides the\nscheduling decisions to balance the communication overheads of different device types. Our reward design encourages each job to be served with the balance between the computation gain and the communication overhead being achieved.\n# 2.3 Regret Minimizing\nBased on the above, we define the overall reward at time t as the linear aggregation over each port: \ufffd\n(8)\n\ufffd \ufffd \ufffd \u2208L \ufffd \ufffd The cumulative reward of scheduling policy \u03c0 over the time horizon T is obtained by summing up the rewards obtained at each time until T: \ufffd \ufffd \ufffd \ufffd \ufffd\n(9)\n\ufffd \u2208T \ufffd \ufffd where the scheduling decisions {y(t)}T 1 are made under the guidance of policy \u03c0. In the following, we just use Q and drop the superscript \u03c0 for simplification. We do not make any assumption on the distribution of the job arrival trajectory {x(t)}T 1 . To obtain a non-trivial performance measure, we cast the multi-server bipartite scheduling problem into the framework of online learning, which prompts us to compare the performance of the online policy \u03c0 with the best offline stationary policy \u03c0\u2217[27], [28]. Let us denote by y\u2217the optimal offline stationary resource allocation decision guided by policy \u03c0\u2217, i.e., \ufffd \ufffd\n(10)\n\u2208Y \ufffd \ufffd Physically, y\u2217is the optimal stationary resource reservation decisions for each port whatever the actual job arrival status x(t) is. Formally, we define the regret R\u03c0 T \ufffd{x(t)}T 1 \ufffd for the job arrival trajectory {x(t)}T 1 as \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\n\ufffd \ufffd \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd \ufffd \ufffd \ufffd The regret of policy \u03c0 is further defined as the maximum regret achieved over every possible job arrival trajectory: \ufffd \ufffd\n(11)\n\ufffd\ufffd \ufffd \ufffd Our goal is to find a policy \u03c0, under which a sequence of bipartite scheduling decisions {y(t)}T 1 is yielded, to minimize R\u03c0 T .\n# 3 ONLINE GRADIENT ASCENT\nTo minimize the regret R\u03c0 T , we resort to an online variant of the gradient-based methods, online gradient ascent (OGA) [29]. A series of recent works have demonstrated that OGA achieves the best possible regret for online caching problems in different network settings when the rewards are linear [28], [30], [31], [32]. In this paper, we extend OGA to the online bipartite scheduling problem for multi-server jobs with non-linear rewards. Before presenting the design details, we first give some preliminary definitions and analysis.\n# 3.1 Preliminaries\nDefinition 1. NICE SETUP. If all the utilities {fk}k\u2208K are (i) linearly separable over computing instances, i.e., \ufffd\ufffd \ufffd \ufffd \ufffd \ufffd\n(12)\n\ufffd \ufffd and each concave utility f k r (\u00b7) is (ii) continuously differentiable in R+, and (iii) there exist \u03d6k r > 0 such that\n(13)\n \u2264  \u2200 we say this is a nice setup. The following proposition demonstrates the property of the regret minimization problem, which will be used in the design and analysis of OGASCHED.\nProposition 1. CONVEXITY. (i) The feasible solution space Y is convex. (ii) With a nice setup, at each time t, the single-slot reward function q \ufffdx(t), y(t) \ufffd is a concave function of y(t).\nProof. In the following proof, we just drop (t) from x(t) and y(t) for simplification. Besides, we only prove the case that G is right d-regular and d = |L|. The left cases can be easily proved with the same techniques used in this proof. We firstly prove (i). To do this, let us arrange the vector y as \ufffd \ufffd\n(14)\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd where yk \u2208R(|L|\u00d7|R|) is arranged as \ufffd\n(15)\n\ufffd \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd With this arrangement, the vector representation of (5) is 0 \u2264y \u2264a, (1 \ufffd\ufffd\n(16)\n(17)\n\ufffd \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd Similarly, we want to construct a matrix B and a vector c for the vector representation of (6). \u2200k \u2208K, we design B\u2032 \u2208R|R|\u00d7(|L|\u00d7|R|) as \ufffd\n(18)\n\ufffd\ufffd \ufffd and ck = \ufffdck 1; ...; ck |R| \ufffd . Then, we have\n(19)\nWe can transform (19) into \ufffd\n(20)\n\ufffd where O is a zero matrix. As a result, (6) is equivalent to\n(21)\n\ufffd\ufffd\u2208 The above analysis leads to Y = \ufffdy | 0 \u2264y \u2264a, By \u2264c \ufffd being a polyhedron, which is well known to be a convex set.\nWe now prove (ii). Similarly, we try to find the vectorized representation of q \ufffdx, y \ufffd . To do this, we define the operator f : R|L|\u00d7|R|\u00d7K \u2192R|L|\u00d7|R|\u00d7K as \ufffd\ufffd\nwhere\n\ufffd \ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd Then, the first part of (7) can be transformed into \ufffd \ufffd \ufffd\n(24)\nwhere\n(25)\n\ufffd \ufffd\ufffd \ufffd For the second part of (7), we have \ufffd \ufffd\n(26)\n(27)\n(28)\n\ufffd \ufffd\ufffd The above analysis leads to \ufffd \ufffd\n(29)\n(30)\nwhere k\u2217is defined by (27).\n# 3.2 Online Gradient Ascent\nIn this section, we give the design details of the OGA-based bipartite scheduling policy.\nDefinition 2. THE OGA POLICY. For any feasible initial bipartite scheduling decision y(1) \u2208Y, at each time t \u2208T , the OGA policy gets y(t + 1) in the direction of ascending the gradient of q \ufffdx(t), y(t) \ufffd : \ufffd \ufffd\n(31)\n(32)\n\ufffd\ufffd \ufffd\ufffd is the Euclidean projection of z onto Y. To implement the projection (32) with low complexity, we propose OGASCHED, which is a combination of the OGA\nTo implement the projection (32) with low complexity, we propose OGASCHED, which is a combination of the OGA\npolicy and the following fast projection technique. Firstly, we introduce the Lagrangian of the projection (32) as\n(33)\n\ufffd \u2208L \ufffd \u2208R \ufffd \u2208K where \u03c1 is the dual variable for (6), \u00b5 is the dual variable for y(t) \u2264a, and \u03bb is the dual variable for y(t) \u22650. Then, we can write the KKT conditions of the projection as \uf8f1 \ufffd \ufffd\n(34)\n\uf8f4 \uf8f4 \uf8f4 \uf8f3 for every l, r, k. Our fast projection is implemented for each pair of (r, k) in parallel. Specifically, for each r \u2208R and each k \u2208K, we divide the ports l \u2208L into three disjoint sets: \uf8f1 \ufffd \ufffd\n(35)\nThe fast projection works by solving the equation system (34) iteratively. Specifically, for each pair of (r, k), we sort the elements of zk (:,r) in descending order (step 7), and initialize B1 rk and B2 rk as \u2205while initializing B3 rk as Lr (step 10 and 12). Then, we repeat a loop, in which we calculate \u03c1k r with (35), and update the value of \u02c6yk (l,r) for each port l in B3 rk (step 25). Since the elements of zk (:,r) are sorted from largest to smallest, if some \u02c6yk (l,r) < 0, we can derive that for all the l\u2032 \u2208 Srk := \ufffdl, ..., |Lr| \ufffd , we have \u02c6yk (l\u2032,r) < 0. Thus, the resource allocation for all the ports in Srk is illegal, since \u02c6yk (l,r) \u22650 must hold. As a result, we update the sets B2 rk and B3 rk, and repeat the calculate loop again (step 29). The calculation loop stops when there are no illegal resource allocations, i.e., \u2200l \u2208Lr, we have \u02c6yk (l,r) \u22650. In other words, Srk = \u2205. We call the calculation loop in step 18 \u223cstep 30 the innner loop. The outer loop is the while loop defined in step 9. To exit the while loop, we need to guarantee that \u02c6yk (1,r) \u2264ak 1. Otherwise, the resource allocation is also illegal. Note that here we only need to check for l = 1 since the elements in zk (:,r) are sorted. The number of projections is linearly proportional to the size of the solution\u2019s dimensions, i.e., \ufffd l\u2208L |Rl|\u00d7K. Nevertheless, as we have mentioned, we can do the projections for different combinations of r and k in parallel because they are not interwoven. Thus, the time complexity of the fast projection is of O \ufffd|L|\u00d7log(K \ufffd l\u2208L |Rl|) \ufffd in each time slot, where the log(\u00b7) operator comes from the sorting operation (step 7). The multiplier |L| outside log(\u00b7) comes from the inner loop (step 19). In our experiments, the repeat loop\u2019s\nexecution count is significantly less than the number of job types |L|.\n# 3.3 Regret Analysis\nIn this section, we discuss the regret of OGASCHED. The main result is summarized in Theorem 1.\nTheorem 1. REGRET UPPER BOUND. With a nice setup, the regret of OGASCHED is upper bounded by \ufffd\n(36)\nwhere \u00afak := maxl\u2208L ak l , \u03b2\u2217:= maxk\u2208K \u03b2k, and \u03d6\u2217 r := maxk\u2208K \u03d6k r .\nmaxk\u2208K \u03d6 r . Proof. The result is based on the non-expansiveness property of Euclidean projection and the concavity of {f k r (\u00b7)}r,k. Our proof has two parts. The first part gives the general form of the upper bound, which is similar to Theorem 2.13 in [33] and Theorem 3 in [30]. Meanwhile, the second part gives the specific upper bounds of involved variables. At each time t > 1, for the y(t) yielded by OGASCHED, we have \u2225y(t) \u2212y\u2217\u22252 = \ufffd\ufffd\u03a0Y \ufffdy(t \u22121) + \u03b7t\u2207q(t \u22121) \ufffd\u2212y\u2217\ufffd\ufffd2\n(37)\n\u2207 \ufffd \u2212 \ufffd\ufffd \u2212 \u2212\ufffd where \u2207q \ufffdy(t \u22121) \ufffd is a shorthand for \u2207q \ufffdx(t \u22121), y(t \u2212 1) \ufffd . (i) is because the non-expansiveness property of the Euclidean projection. By moving \u2225y(t \u22121) \u2212y\u2217\u22252 to the LHS of (37) and summing the inequality telescopically over T , we have\n(38)\nInequality (i) is because \u2200t \u2208T we set \u03b7t \u2261\u03b7. In (ii), we use the fact that \u2225y(T) \u2212y\u2217\u2225\u22650. In (37), max \u2225\u2207q\u2225is the maximum Euclidean norm of the gradient of q(x(t), y(t)) over every possible y(t), and diam(Y) is the largest Euclidean distance between any two elements of Y. Because q(\u00b7) is a concave function of y(t), we have\n(39)\nIn the following, we give the upper bound of max \u2225\u2207q\u2225 and diam(Y), respectively.\n(40)\n\ufffd \ufffd \ufffd \u2208L \ufffd \u2208R where k\u2217is defined in (27). The second part of (40) can be\nupper bounded by \ufffd \ufffd\n(41)\n\ufffd \u2208L \ufffd \u2208R \ufffd \u2208L \ufffd \u2208R where \u03b2\u2217= maxk\u2208K \u03b2k. If G is right d-regular, the bound reduces to d|R|(\u03b2\u2217)2. For the first part of (40), we use (f k\u2217 r )\u2032 to replace (f k\u2217 r )\u2032\ufffdyk\u2217 (l,r)(t) \ufffd for simplification. Then we have \ufffd \ufffd\n\ufffd \ufffd\ufffd For PART-A we have\n(42)\nwhere \u03d6\u2217 r = maxk\u2208K \u03d6k r . If G is right d-regular, the bound reduces to d|R|(K\u22121)(\u03d6\u2217 r)2. To analyze the upper bound of PART-B, we need to partition the computing instances into two disjoint sets: \ufffd \ufffd\n\ufffd \ufffd For each r \u2208R1, the maximum of (f k\u2217 r )\u2032\ufffd(f k\u2217 r )\u2032 \u22122\u03b2k\u2217\ufffd is 0 since (f k\u2217 r )\u2032 \u22650 holds. For each r \u2208R2, the maximum is (\u03d6k\u2217 r )2 \u22122\u03b2k\u2217\u03d6k\u2217 r . Thus, \ufffd \ufffd\n(43)\n\ufffd \u2208L \ufffd \u2208R\u2229R Recall that in (43) Rl is the set of computing instances that connects to port l. Because \u03b2k \u2208[0, 1] holds for each k \u2208K, \u2200l \u2208L, r \u2208Rl \u2229R2, we have\n(44)\n \u2212 Finally, we can get\n\ufffd \u2208L \ufffd \u2208R \ufffd \ufffd For the upper bound in (45), all the computing instances r \u2208Rl fall into the set R2. 2) The upper bound of diam(Y). By definition we have\n(46)\n(47)\n\ufffd  \ufffd where \u00afak = maxl\u2208L ak l . In (47), (i) is because the constraint (5). In (ii), we use the capacity constraint (6). As a result, we\n(48)\nThe theorem shows that the suboptimality gap between OGASCHED and the offline optimal is of \u0398(HG\u00d7 \u221a T), where \ufffd \ufffd\n\ufffd (49)\nis a factor characterized the scale of the bipartite graph G. In addition, we can find that the regret grows sublinearly with the number of job types |L|. To the best of our knowledge, this is the best regret for the online bipartite scheduling problem with non-linear rewards. The proof also indicates that, to achieve a not-too-bad cumulative reward, at each time t, the learning rate \u03b7t should be set as\n(50)\n# 3.4 Extending to Multiple Job Arrivals\nOGASCHED can be applied to the scenarios where multiple jobs are yielded from each port in each time slot. In this case, the job arrival status x(t) is re-formulated as x(t) = \ufffdxl(t) \ufffd l\u2208L \u2208N|L|, where xl(t) indicates the number of jobs arrive at port l at time t. Further, the scheduling decisions at time t is re-formulated as \ufffd \ufffd\n\ufffd \ufffd   where Jl is the maximum number of the type-l jobs arrive during each time slot, i.e. Jl = maxt\u2208T xl(t). Correspondingly, the port-l reward is re-formulated as\n\ufffd \u2208R where 1{p} is the indicator function: 1{p} is 1 if the predicate p is true, otherwise 0. The new formulated problem can be solved by native OGASCHED after transformations.\n# 3.5 Extending to Gang Scheduling\nOGASCHED can be extended to the Gang Scheduling scenarios, where the scheduling decisions for the task instances of a job follows the ALL-OR-NOTHING property. In other words, only when all tasks1 of a job are successfully scheduled, the job could be launched. In the following, we show briefly how Gang Scheduling can be modeled. To start with, for each job type l \u2208L, we denote the corresponding set of task components by Ql\n1. In practice, not all tasks of a job need to be scheduled. In Kubernetes, the job submitter can specify the minimum number of tasks that must be scheduled successfully. In the following, we use ml(t) to represent the minimum number of tasks that should be scheduled at time t of the type-l job.\nand indexed by q. Correspondingly, the job requests al is redefined as \ufffd\nand indexed by q. Correspondingly, the job requests al is redefined as\n\ufffd \ufffd   Similarly, we redefine the scheduling decisions at time t as \ufffd \ufffd\n\ufffd \ufffd   As a result, the solution space Y turns to \ufffd \ufffd \ufffd \ufffd\n\ufffd \ufffd where in the first inequality, ml(t) is the minimum number of task components that should be scheduled at time t of type-l job. The port-l reward at time t is re-formulated as\n\ufffd \ufffd The new formulated problem is more difficult because Y is no longer a convex set and ql \ufffdx(t), y(t) \ufffd is not differentiable everywhere. Nevertheless, we can still develop a similar online scheduling algorithm with the subgradient ascent and mirror ascent related techniques which retains a sublinear regret. The design detail is omitted due to space limits.\n# 4 EXPERIMENTAL RESULTS\nIn this section, we conduct extensive experiments to validate the performance of OGASCHED. Based on the Alibaba cluster trace datasets [34], we first examine the theoretically guaranteed superiority of OGASCHED against several baselines on the cumulative and average rewards. Then, we analyze the generality and robustness of it under different cluster settings. At last, we validate the efficacy of OGASCHED in large-scale scenarios. The trace-driven simulation is conducted on a server with 48 Intel Xeon Silver 4214 CPUs, 256 GB memory, and 2 Tesla P100 GPUs. Traces. We hybrid the traces from cluster-trace-v2018 and cluster-trace-gpu-v2020 of the Alibaba Cluster Trace Program. Specifically, we leverage the specifications of the machines, the arrival patterns, and the resource requirements of different kinds of jobs to generate our simulation environment. Baselines. The following widely used baselines are implemented to make comparisons with OGASCHED. \u2022 DRF [20]. It is adopted by YARN [35] and Mesos [36]. In our scenario, DRF allocates resources to ports that yield jobs in the ascending order of their dominant resource shares. The dominant share sl of port l is calculated as sl = maxk\u2208K{ak l / \ufffd r\u2208Rl ck r}. \u2022 FAIRNESS. We implement FAIRNESS in this way: at each time t, we allocate the type-k resource of each node r to each port l that yield a job according to the job\u2019s share ak l / \ufffd l\u2208Lr ak l .\nDefault Settings. In default settings, our simulation environment has 128 computing instances, each equipped with 6 types of resources (CPUs, MEM, GPUs, NPUs, TPUs, and FPGAs), and 10 job types of different resource requirements. Large-scale validations will be demonstrated in Sec. 4.3. The computing instances and jobs are carefully selected from the trace to reflect heterogenity. We support 4 types of utilities: \uf8f1\n(51)\n\uf8f4 \uf8f4 \uf8f3  \u2212 The default settings of main parameters are listed in Tab. 2. In this table, the initial learning rate and the decay are used to tune the learning rate at each time t around the value (50). Job arrival probability \u03c1 is adopted to adjust the job arrival status with Bernoulli Distributions. This parameter is applied based on the actual arrival patterns from the trace to increase stochasticity. The contention level, located at the last cell of this table, is designed to tune the level of resource contention. The larger this value, the more fierce the contention. It is a multiplier to the resource requirements of jobs. The effect of it will be analyzed in detail in Sec. 4.2.\n<div style=\"text-align: center;\">TABLE 2 Default parameter settings</div>\nPARAMETER\nVALUE\nPARAMETER\nVALUE\njob types num. |L|\n10\nnode num. |R|\n128\ndevice type num. K\n6\ntime slot num. T\n2000\nrange of \u03b1\n[1.0, 1.5]\nrange of \u03b2\n[0.3, 0.5]\ninitial learning rate \u03b70\n25\ndecay \u03bb\n0.9999\njob arrival prob. \u03c1\n0.7\ncontention level\n10\nNote that in Sec. 4.1, the time slot length T is set as 8000. For the left experiments, the time slot length is 2000, unless otherwise stated.\n# 4.1 Performance Verification\nIn this section, we compare the performance of OGASCHED with the baselines in terms of the achieved cumulative and average rewards. In Fig. 2(a), the y-axis is the average reward unitl time t, i.e., 1 t \ufffdt \u03c4=1 q \ufffdx(\u03c4), y(\u03c4) \ufffd . Compared with the baselines, OGASCHED has a clear advantage on the performance (with the increases of 11.33%, 7.75%, 13.89%, and 13.44% compared with DRF, FARINESS, BINPACKING, and SPREADING, respectively). Besides, it shows that the performance of OGASCHED tends to increase as the length of the time horizon increases. The curve of OGASCHED starts steep and later flattens. The reason is that, as a learning-powered algorithm, OGASCHED learns the underlying distribution\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/afac/afac0a28-9a97-4a36-903d-68ddb0d7905f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) Accumulative rewards.</div>\n<div style=\"text-align: center;\">(a) Average rewards.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b01a/b01a1ebe-8702-4381-b10b-18003d42dd59.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">TABLE 3 Generality and Robustness validation under different scenario settings.</div>\nTime Horizon Length T\nJob Arrival Probability \u03c1\nGraph Dense\nAvg. Reward\n1000\n2000\n5000\n10000\n0.3\n0.5\n0.7\n0.9\n\u22482\n\u22482.5\n\u22483\nOGASCHED\n2578.53\n2886.33\n2911.37\n3104.98\n1904.87\n2154.18\n3117.29\n2938.22\n2816.18\n2904.51\n3127.47\nDRF\n2422.47\n2493.02\n2449.23\n2497.85\n1364.53\n2086.59\n2503.01\n2755.41\n2417.08\n2786.94\n2795.42\nFAIRNESS\n2532.24\n2582.80\n2552.41\n2436.22\n1295.53\n1997.19\n2628.02\n2873.84\n2501.54\n2857.60\n2918.98\nBINPACKING\n2386.01\n2449.15\n2444.32\n2365.13\n1246.39\n1897.79\n2518.98\n2740.19\n2374.31\n2757.71\n2829.19\nSPREADING\n2382.01\n2466.71\n2436.60\n2362.88\n1250.67\n1888.06\n2519.37\n2737.93\n2382.87\n2766.07\n2836.37\nof job arrival patterns and it can make better decisions by adjusting the step directions. It is interesting to find that the rewards oscillate at the beginning time slots. One of the leading factors is that OGASCHED is not boosted with a welldesigned initial solution. In our experiments, a 8000-time slot training only takes one hour. Thus, not surprisingly, the rewards achieved in the beginning can be easily surpassed when the time slot is sufficiently large. It is not a surprise that FAIRNESS achieves the best among the baselines. FAIRNESS adopts a proportional allocation strategy and allocates resources to each non-empty port without bias, which increases the computation gains adequately. When the contention is not fierce while the communication overhead is low, the advantages of FAIRNESS will be more steady. By contrast, the advantages of BINPACKING and SPREADING are respectively high resource utilization and job isolation, which do not contribute to the reward directly. Fig. 2(b) shows that the cumulative rewards achieved by all the five algorithms. In the beginning, FAIRNESS and DRF have the slight edge, benefiting by the propotional allocation idea. Nevertheless, as the time slot increases,\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/43ac/43ac0fd8-e549-413d-84e1-97764d3d66a8.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(c) Accumulative rewards vs. contention.</div>\nOGASCHED is able to surpass them without difficulty. Fig. 2(c) demonstrates the ratio on the achieved average rewards between OGASCHED and the baselines. Similarly, the ratios oscillate at the beginning. After that, they increase steeply and later flattens.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/df75/df756d89-a922-4407-9a7b-b03012c34c18.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) Impact of decay.</div>\n<div style=\"text-align: center;\">(a) Impact of \u03b70.</div>\n<div style=\"text-align: center;\">Fig. 4. The performance of OGASCHED with different hyper-parameters.</div>\nThe hyper-parameters of OGASCHED, especially the initial learning rate \u03b70 and the decay, have a remarkable impact on its performance. From Fig. 4 we can find that, a wrong setting of these hyper-parameters could lead to a poor performance, even the decrease of the cumulative reward\n(which means, the reward is negative in many time slots). At the last of Sec. 3.3, we claim that, to achieve an cumulative reward with a lower bound guarantee, at each time t, the learning rate should be set around (50). Note that in (50), the learning rate is encouraged to be larger and larger as time moves, which is counterintuitive and it goes against the convergence to a local optimum. The curves in Fig. 4(b) also verify that, setting decay as 0.9999 is better than 1.0001. The best decay in practice does not follow the guidance of theory because the regret analysis only gives the worst case guarantee on the cumulative rewards. In our experiments, the best range for decay is [0.995, 0.9999].\n# 4.2 Scalability, Generality and Robustness Evaluations\nIn this section, we evaluate the performance of OGASCHED under different scales of scenario settings. Fig. 3(a) and Fig. 3(b) demonstrate the impact of the scale of the bipartite graph G. In these two figures, the left y-axis is the cumulative reward while the right y-axis is the ratio ra/rb, where ra is the cumulative reward achieved by OGASCHED, and rb is the baselines\u2019. Firstly, we observe that, whatever the number of the computing instances is, OGASCHED takes the leading position. Besides, as |R| increases, all the algorithms obtain a larger cumulative reward. The result is evident because a large cluster can provide sufficient resources, which leads to jobs being fully served. It is also worth noting that, when |R| increases, the superiority of OGASCHED over the baselines firstly increases then decreases. It demonstrates that the resource contention is fierce when |R| \u2208[128, 256]. In this case, it is necessary for OGASCHED to be trained with a larger time slot. Fig. 3(b) shows that the number of job types, i.e., |L|, has a weaker impact than |R| to the performance of OGASCHED. The phenomenon verifies the conclusion we have concluded, i.e., the regret grows linearly with |R|, but it is sublinear with |L|. Fig. 3(c) shows the impact of contention level. This parameter works as a multiplier to the resource requirements of jobs. We can observe that, when moving contention level from 0.1 to 1, all the achieved cumulative rewards increase. This is obvious because a larger resource requirement leads to a larger computation gain on the premise of low contention. However, increasing the multiplier further leads to the downgrade of performances and the reduction of the superiority of OGASCHED. Even so, OGASCHED always performs the best. Fig. 6 shows the average computation gain and communication overhead penalty of each time slot under different contention levels. We can find that the penalty increases with the contention level slowly. Fig. 7 demonstrates the cumulative rewards with different utilities. Because of the diminishing marginal effect, the rewards with ploy, log, and reciprocal utilities are significantly less than the rewards with linear utilities. Nevertheless, the diminishing marginal effect does not change the superiority of OGASCHED against the baselines. Even in the all reciprocal utility settings, for FAIRNESS, OGASCHED has its advantages. In addition to the above evaluations, we also test the generality and robustness of OGASCHED under different settings of the following parameters: the time horizon length T, the job arrival probability \u03c1, and the dense of the bipartite\ngraph. The graph dense is calculated as \ufffd r\u2208R |Lr|/|R|. The results are shown in Tab. 3. The two largest values in each column of the table are made bold. Besides, for each parameter and each algorithm, the setting which leads to the largest reward is marked with a light-grey background. We summarize the key findings as follows.\n\u2022 Firstly, whatever the parameter settings, OGASCHED always performs the best, and its performance has a positive correlation with the time horizon length T. As we have analyzed, a large time horizon provides more chances for OGASCHED to learn the underlying distributions, thereby increasing the reward in the gradient ascent directions. \u2022 Increasing the job arrival probability can lead to a high resource utilization, thereby increasing the rewards. However, a large job arrival probability also brings in a fierce resource contention. A direct consequence of it is that, for OGASCHED, many elements in the vector y(t) fall into the interior of Y, rather than the boundaries, thereby leading to a reward reduction. The phenomenon can be observed when moving \u03c1 from 0.7 to 0.9. \u2022 Graph dense has a similar effect on the reward to the job arrival probability. Nevertheless, the reasons behind are distinct. A larger graph dense increases the opportunities for a job to be served with a large possible parallelism, thereby increasing the computation gain. By contrast, the communication overhead has a slow rate of growth.\n# 4.3 Large-Scale Validations\nTo test the efficacy of OGASCHED in large-scale scenarios, we conduct the following experiments. In these experiments, the number of the job types is set as 100 while the quantity of the computing instances is 1024 in default. The results in Fig. 5 show that the superiority of OGASCHED is preserved even in large-scale scenarios.\n# 5 RELATED WORKS\nThe design of online job scheduling algorithms that yield a nice theoretical bound is always the focus of attention from the research community. Existing online job scheduling algorithms can be organized into two categories. In the first category, the online algorithms are elaborately designed for specific job types, such as DNN model training [38], [39], [25], [6], [18], [13], [40], big-data query & analytics [12], [41], multi-stage workflows [42], [17], [43], [44], etc. A typical work on DNN model training is [18], where the authors fully take the layered structure of DNNs into consideration and develop an efficient resource scheduling algorithm based on the sum-of-ratios multi-type-knapsack decomposition method. The authors further prove that the proposed algorithm has a SOTA approximation ratio within a polynomial running time. [13] is another work that fully explores the Bulk Synchronous Parallel (BSP) property of the DNN training jobs. The authors develop an algorithm which is O(ln |M|)-approximate with high probability, where M is the set of resources. These works are designed for specific job types, and they do not provide a general analysis of\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/98ed/98ed64ca-817c-44dd-9b58-48d3dcd5750c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 5. Large-scale validations. It takes 15 hours for OGASCHED to complete when T = 10000, \u03b2 \u2208[0.01, 0.015], and contention level is 5.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8a44/8a442541-2f4b-4889-8040-2f1e789d3745.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 6. Average computation gain and communication overhead of each time slot under different contention levels.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3c4f/3c4fb38e-e048-43fb-8116-6c2be279094d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 7. Accumulative rewards with different utilities.</div>\nthe gain-overhead tradeoff for multi-server jobs. This paper intends to fill the gap. In the second category, the types of job are not specified, while the theoretical superiority is highlighted. The algorithms are designed with different theoretical basis, including online approximate algorithms [45], [15], [46], Online Convex Optimization (OCO) techniques [14], gametheoretical approaches [16], online learning and DRL-based algorithms [47], [48], etc. In these works, the performance of the proposed algorithms is usually analyzed with approximate ratio, competitive ratio, Price of Anarchy (PoA), and regret. A typical recent work is [14]. The authors develop an algorithm whose dynamic regret is upper bounded by O(OPT1\u2212\u03b2), where \u03b2 \u2208[0, 1). None of the existing works analyze the gain-overhead tradeoff and provide a regret of O( \ufffd |L|T) as this paper demonstrates.\n# 6 CONCLUSIONS\nIn this paper, we study the online scheduling of multi-server jobs in terms of the gain-overhead tradeoff. The problem is formulated as an cumulative reward maximization program. The reward of scheduling a job is designed as the difference between the computation gain and the penalty on the dominant communication overhead. We propose an al-\ngorithm, i.e. OGASCHED, to learn the best possible scheduling decision in the ascending direction of the reward gradients. OGASCHED is the first algorithm that has a sublinear regret w.r.t. the number of job types and time slot length, which is a SOTA result for concave rewards. OGASCHED is well designed to be parallelized, which makes large-scale applications possible. The superiority of OGASCHED is also validated with extensive trace-driven simulations. Future extensions may include, i.e., more elaborate modeling and analysis of the intra-node and inter-node communication overheads.\n# ACKNOWLEDGMENTS\nThis work was supported in part by the National Key Research and Development Program of China under Grant 2022YFB4500100, the National Science Foundation of China under Grants 62125206 and U20A20173, and the Key Research Project of Zhejiang Province under Grant 2022C01145.\n# REFERENCES\nsystem,\u201d in IEEE INFOCOM 2021 - IEEE Conference on Computer Communications, 2021, pp. 1\u201310.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f8ad/f8ad008d-be75-4ade-b83f-ef0f6923f2ed.png\" style=\"width: 50%;\"></div>\nHailiang Zhao received the B.S. degree in 2019 from the school of computer science and technology, Wuhan University of Technology, Wuhan, China. He is currently pursuing the Ph.D. degree with the College of Computer Science and Technology, Zhejiang University, Hangzhou, China. His research interests include cloud & edge computing, distributed systems and optimization algorithms. He has published several papers in flagship conferences and journals including IEEE ICWS 2019, IEEE TPDS, IEEE TMC, etc.\nHe has been a recipient of the Best Student Paper Award of IEEE ICWS 2019. He is a reviewer for IEEE TSC and Internet of Things Journal.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bf83/bf83d191-7b0a-468a-87bd-6025228a2a1b.png\" style=\"width: 50%;\"></div>\nShuiguang Deng is currently a full professor at the College of Computer Science and Technology in Zhejiang University, China, where he received a BS and PhD degree both in Computer Science in 2002 and 2007, respectively. He previously worked at the Massachusetts Institute of Technology in 2014 and Stanford University in 2015 as a visiting scholar. His research interests include Edge Computing, Service Computing, Cloud Computing, and Business Process Management. He serves for the journal IEEE\nTrans. on Services Computing, Knowledge and Information Systems, Computing, and IET Cyber-Physical Systems: Theory & Applications as an Associate Editor. Up to now, he has published more than 100 papers in journals and refereed conferences. In 2018, he was granted the Rising Star Award by IEEE TCSVC. He is a fellow of IET and a senior member of IEEE.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3168/31680c50-52cd-4faa-ae65-83181938bf9b.png\" style=\"width: 50%;\"></div>\nZhengzhe Xiang received the B.S. and Ph.D. degree of Computer Science and Technology in Zhejiang University, Hangzhou, China. He was previously a visiting student worked at the Karlstad University, Sweden in 2018. He is currently a Lecturer with Zhejiang University City College, Hangzhou, China. His research interests lie in the fields of Service Computing, Cloud Computing, and Edge Computing.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9bad/9bad7ed8-1820-4fb2-adeb-7aeefb144326.png\" style=\"width: 50%;\"></div>\nXueqiang Yan is currently a technology expert with the Wireless Technology Lab, Huawei Technologies. He was a member of technical staff at Bell Labs from 2000 to 2004. From 2004 to 2016, he was the director of the Strategy Department, Alcatel-Lucent Shanghai Bell. His current research interests include wireless networking, the Internet of Things, edge AI, future mobile network architecture, network convergence, and evolution.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ae7a/ae7a21fb-b1aa-4278-93f2-ec912ebfe458.png\" style=\"width: 50%;\"></div>\nJianwei Yin received the Ph.D. degree in computer science from Zhejiang University (ZJU) in 2001. He was a Visiting Scholar with the Georgia Institute of Technology. He is currently a Full Professor with the College of Computer Science, ZJU. Up to now, he has published more than 100 papers in top international journals and conferences. His current research interests include service computing and business process management. He is an Associate Editor of the IEEE Transactions on Services Computing.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/188e/188eb86a-2d6f-4911-aeeb-74b96e21a866.png\" style=\"width: 50%;\"></div>\nSchahram Dustdar is a Full Professor of Computer Science (Informatics) with a focus on Internet Technologies heading the Distributed Systems Group at the TU Wien. He is founding coEditor-in-Chief of ACM Transactions on Internet of Things (ACM TIoT) as well as Editor-in-Chief of Computing (Springer). He is an Associate Editor of IEEE Transactions on Services Computing, IEEE Transactions on Cloud Computing, ACM Computing Surveys, ACM Transactions on the Web, and ACM Transactions on Internet Tech-\nnology, as well as on the editorial board of IEEE Internet Computing and IEEE Computer. Dustdar is recipient of multiple awards: TCI Distinguished Service Award (2021), IEEE TCSVC Outstanding Leadership Award (2018), IEEE TCSC Award for Excellence in Scalable Computing (2019), ACM Distinguished Scientist (2009), ACM Distinguished Speaker (2021), IBM Faculty Award (2012). He is an elected member of the Academia Europaea: The Academy of Europe, where he is chairman of the Informatics Section, as well as an IEEE Fellow (2016), an AsiaPacific Artificial Intelligence Association (AAIA) President (2021) and Fellow (2021). He is an EAI Fellow (2021) and an I2CICC Fellow (2021). He is a Member of the 2022 IEEE Computer Society Fellow Evaluating Committee (2022).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5626/56264c08-e4ef-43d2-b550-bd82574031ee.png\" style=\"width: 50%;\"></div>\nAlbert Y. Zomaya is the Peter Nicol Russell Chair Professor of Computer Science and Director of the Centre for Distributed and HighPerformance Computing at the University of Sydney. To date, he has published > 600 scientific papers and articles and is (co-)author/editor of > 30 books. A sought-after speaker, he has delivered > 250 keynote addresses, invited seminars, and media briefings. His research interests span several areas in parallel and distributed computing and complex systems. He is currently\nthe Editor in Chief of the ACM Computing Surveys and processed in the past as Editor in Chief of the IEEE Transactions on Computers (20102014) and the IEEE Transactions on Sustainable Computing (20162020). Professor Zomaya is a decorated scholar with numerous accolades including Fellowship of the IEEE, the American Association for the Advancement of Science, and the Institution of Engineering and Technology (UK). Also, he is an Elected Fellow of the Royal Society of New South Wales and an Elected Foreign Member of Academia Europaea. He is the recipient of the 1997 Edgeworth David Medal from the Royal Society of New South Wales for outstanding contributions to Australian Science, the IEEE Technical Committee on Parallel Processing Outstanding Service Award (2011), IEEE Technical Committee on Scalable Computing Medal for Excellence in Scalable Computing (2011), IEEE Computer Society Technical Achievement Award (2014), ACM MSWIM Reginald A. Fessenden Award (2017), the New South Wales Premier\u2019s Prize of Excellence in Engineering and Information and Communications Technology (2019), and the Research Innovation Award, IEEE Technical Committee on Cloud Computing (2021).\n",
    "paper_type": "method",
    "attri": {
        "background": "In modern computing clusters, multi-server jobs that request multiple resources simultaneously pose challenges for resource allocation policies. The difficulty lies in balancing the parallel computation gain against the internal communication overhead while managing resource contention among jobs.",
        "problem": {
            "definition": "The paper addresses the challenge of scheduling multi-server jobs in online settings, where jobs arrive without prior knowledge of future requests, leading to difficulties in resource allocation.",
            "key obstacle": "The main challenge is the non-linear relationship between the number of allocated resources and the resulting parallel computation gain, complicating the gain-overhead tradeoff."
        },
        "idea": {
            "intuition": "The idea stems from the need to optimize resource allocation in a way that accounts for both computation gains and communication overheads, which has not been adequately addressed in existing literature.",
            "opinion": "The proposed solution is an online scheduling algorithm called OGASCHED, which learns to allocate resources to multi-server jobs to maximize cumulative rewards.",
            "innovation": "OGASCHED differentiates itself by allowing diverse job types to co-locate and by modeling the computation gain with general concave utility functions, providing a more flexible approach to resource allocation."
        },
        "method": {
            "method name": "OGASCHED",
            "method abbreviation": "OGA",
            "method definition": "OGASCHED is an online scheduling algorithm designed to allocate multi-type resources to multi-server jobs, maximizing the overall computation efficiency by balancing gains and overheads.",
            "method description": "The method utilizes online gradient ascent to determine resource allocation based on the reward gradients.",
            "method steps": [
                "Model the job-server constraints using a bipartite graph.",
                "Define the reward function based on computation gain and communication overhead.",
                "Implement the online gradient ascent policy to update resource allocations.",
                "Use fast projection techniques to maintain feasibility in allocations."
            ],
            "principle": "The effectiveness of OGASCHED lies in its ability to learn from past scheduling decisions and adaptively allocate resources to maximize cumulative rewards, thereby minimizing regret."
        },
        "experiments": {
            "evaluation setting": "The experimental setup involved trace-driven simulations using datasets from Alibaba, comparing OGASCHED against baseline methods like DRF, FAIRNESS, BINPACKING, and SPREADING under various conditions.",
            "evaluation method": "Performance was measured based on cumulative and average rewards achieved during the scheduling process, with extensive simulations to validate the effectiveness of OGASCHED."
        },
        "conclusion": "The experiments demonstrated that OGASCHED significantly outperforms existing heuristics in terms of resource allocation efficiency, achieving a sublinear regret with respect to the number of job types and time slots.",
        "discussion": {
            "advantage": "OGASCHED provides a robust framework for scheduling multi-server jobs, effectively balancing computation gains and communication overheads, which is a significant improvement over existing methods.",
            "limitation": "The method may face challenges in scenarios with highly unpredictable job arrival patterns or extreme resource contention, potentially affecting performance.",
            "future work": "Future research could explore more detailed modeling of intra-node and inter-node communication overheads and further optimizations for large-scale applications."
        },
        "other info": {
            "acknowledgments": "Supported by the National Key Research and Development Program of China and the National Science Foundation of China.",
            "key terms": [
                "Multi-server job",
                "Online gradient ascent",
                "Online scheduling",
                "Regret analysis"
            ]
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper addresses the challenge of scheduling multi-server jobs in online settings, where jobs arrive without prior knowledge of future requests, leading to difficulties in resource allocation."
        },
        {
            "section number": "1.2",
            "key information": "The idea stems from the need to optimize resource allocation in a way that accounts for both computation gains and communication overheads, which has not been adequately addressed in existing literature."
        },
        {
            "section number": "1.3",
            "key information": "The proposed solution is an online scheduling algorithm called OGASCHED, which learns to allocate resources to multi-server jobs to maximize cumulative rewards."
        },
        {
            "section number": "2.1",
            "key information": "OGASCHED is an online scheduling algorithm designed to allocate multi-type resources to multi-server jobs, maximizing the overall computation efficiency by balancing gains and overheads."
        },
        {
            "section number": "2.2",
            "key information": "The main challenge is the non-linear relationship between the number of allocated resources and the resulting parallel computation gain, complicating the gain-overhead tradeoff."
        },
        {
            "section number": "3.1",
            "key information": "The experimental setup involved trace-driven simulations using datasets from Alibaba, comparing OGASCHED against baseline methods like DRF, FAIRNESS, BINPACKING, and SPREADING under various conditions."
        },
        {
            "section number": "6.3",
            "key information": "The method may face challenges in scenarios with highly unpredictable job arrival patterns or extreme resource contention, potentially affecting performance."
        },
        {
            "section number": "6.4",
            "key information": "Future research could explore more detailed modeling of intra-node and inter-node communication overheads and further optimizations for large-scale applications."
        }
    ],
    "similarity_score": 0.5486813922516369,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-15-0239_large/papers/Scheduling Multi-Server Jobs with Sublinear Regrets via Online Learning.json"
}