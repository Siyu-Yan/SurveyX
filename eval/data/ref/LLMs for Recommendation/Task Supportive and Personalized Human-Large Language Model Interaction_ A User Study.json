{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2402.06170",
    "title": "Task Supportive and Personalized Human-Large Language Model Interaction: A User Study",
    "abstract": "Large language model (LLM) applications, such as ChatGPT, are a powerful tool for online information-seeking (IS) and problem-solving tasks. However, users still face challenges initializing and refining prompts, and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive information retrieval (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through prompt engineering. We developed a ChatGPT-like platform integrated with supportive functions, including perception articulation, prompt suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine prompts, and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with LLMs. It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users.",
    "bib_name": "wang2024tasksupportivepersonalizedhumanlarge",
    "md_text": "# Task Supportive and Personalized Human-Large Language Model Interaction: A User Study\n# Task Supportive and Personalized Human-Large Language Model Interaction: A\nBEN WANG, JIQUN LIU, JAMSHED KARIMNAZAROV, and NICOLAS THOMPSON, The University of Oklahoma, USA\nLarge language model (LLM) applications, such as ChatGPT, are a powerful tool for online information-seeking (IS) and problem-solving tasks. However, users still face challenges initializing and refining prompts, and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive information retrieval (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through prompt engineering. We developed a ChatGPT-like platform integrated with supportive functions, including perception articulation, prompt suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine prompts, and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with LLMs. It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users. CCS Concepts: \u2022 Information systems \u2192Retrieval tasks and goals; Personalization; \u2022 Human-centered computing \u2192 Natural language interfaces. Additional Key Words and Phrases: Human-LLM Interaction, ChatGPT, Prompt Engineering, Information Seeking, Proactive System\nLarge language model (LLM) applications, such as ChatGPT, are a powerful tool for online information-seeking (IS) and problem-solving tasks. However, users still face challenges initializing and refining prompts, and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive information retrieval (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through prompt engineering. We developed a ChatGPT-like platform integrated with supportive functions, including perception articulation, prompt suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine prompts, and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with LLMs. It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users. CCS Concepts: \u2022 Information systems \u2192Retrieval tasks and goals; Personalization; \u2022 Human-centered computing \u2192 Natural language interfaces. Additional Key Words and Phrases: Human-LLM Interaction, ChatGPT, Prompt Engineering, Information Seeking, Proactive System ACM Reference Format: Ben Wang, Jiqun Liu, Jamshed Karimnazarov, and Nicolas Thompson. 2024. Task Supportive and Personalized Human-Large Language Model Interaction: A User Study. In Proceedings of the 2024 ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR \u201924), March 10\u201314, 2024, Sheffield, United Kingdom. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3627508.3638344 \u00a9 Wang et al., 2024. This is the author\u2019s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in ACM CHIIR 2024, https://doi.org/10.1145/3627508.3638344.\nAdditional Key Words and Phrases: Human-LLM Interaction, ChatGPT, Prompt Engineering, Information Seeking, Proactive System ACM Reference Format: Ben Wang, Jiqun Liu, Jamshed Karimnazarov, and Nicolas Thompson. 2024. Task Supportive and Personalized Human-Large Language Model Interaction: A User Study. In Proceedings of the 2024 ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR \u201924), March 10\u201314, 2024, Sheffield, United Kingdom. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3627508.3638344\narXiv:2402.06170v1\n\u00a9 Wang et al., 2024. This is the author\u2019s version of the work. It is posted here for your personal use. Not for redistribution The definitive Version of Record was published in ACM CHIIR 2024, https://doi.org/10.1145/3627508.3638344.\n# 1 INTRODUCTION\nThe release of ChatGPT has sparked considerable interest in the interaction between humans and AI. This interest has led to a rising number of individuals employing large language models (LLMs) for various purposes such as task assistance, entertainment, education, and even as an alternative to traditional search engines [3, 5]. Despite the prevalence of ChatGPT, users still face challenges formulating prompts, and cognitive barriers and biased perceptions further impede task completion [26, 34]. These issues reflect broader challenges identified within the fields of information seeking (IS) and interactive information retrieval (IIR), particularly concerning task context and user perceptions, such as task topic and type, user intent, topic familiarity, and task expectations [2, 14, 16, 23, 30]. Previous IIR studies have underscored the complexity of integrating these fluctuating user perceptions into a predominantly static search system. Fortunately, the evolution of LLMs marks a transformative phase in information access (IA) paradigms, introducing a promising avenue for incorporating more nuanced interaction data through\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are n made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-pa components of this work must be honored. For all other uses, contact the owner/author(s). \u00a9 2024 Copyright held by the owner/author(s). Manuscript submitted to ACM\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). \u00a9 2024 Copyright held by the owner/author(s). Manuscript submitted to ACM\nconversational context between the user and generative IA (GIA) system [24]. Therefore, it becomes crucial to explore methodologies for embedding task context and user perceptions into ChatGPT interactions, subsequently evaluating their impact on user experience and task completion, which are essential criteria for evaluation IIR and Human-AI Interaction [1, 17, 19, 26]. To achieve this, we have developed a task platform that emulates the official ChatGPT interface, incorporating the GPT-3.5-turbo model. Aiming to support users with the challenges mentioned above, we designed and implemented three supportive functions: 1. Perception Articulation: allows users to clarify their perceptions, including topic familiarity, and expected task complexity. This perception articulation will be then input to ChatGPT through prompt engineering to enrich the context information; 2. Prompt Suggestions: generates prompt revisions and follow-up questions, aiding users who struggle with prompt formulation; 3. Conversation Explanation: generates explanations for the ongoing conversation (i.e., the user\u2019s prompt and ChatGPT\u2019s response pair) for users to better comprehend ChatGPT\u2019s interpretation of the conversation. To validate our approach, we conducted a naturalistic user study, involving 16 participant of college students and crowdsourced workers with self-defined tasks. These tasks spanned various lengths and cover diverse topics including creative writing, professional development, and specific programming questions. Our analysis underscores the effectiveness of the supportive functions, illuminating their role in facilitating user experience and task completion. The findings reveal that these functions proved instrumental in managing user expectations, reducing cognitive load, guiding prompt refinement, and increasing user engagement. This research further enhances our understanding of designing proactive and user-centric systems with LLMs, offering insights into evaluating human-LLM interactions from both the system and user ends, and underscoring potential challenges for under served users in this new era of AI.\n# 2 RELATED WORK\n# 2.1 Capability of ChatGPT\nLLMs have emerged as a groundbreaking development in the realm of artificial intelligence, leveraging sophisticated architectures trained on extensive data to understand and emulate human-like text generation [20]. One such application is ChatGPT, which has seen the most significant growth in its userbase. One key access to the versatility of LLMs is prompt engineering, a method that uses specific information and instruction in the input to optimize ChatGPT\u2019s output content and format [18]. Previous studies have examined using ChatGPT and other LLMs in educational settings where they can personalize content delivery and foster enhanced learning experiences [4, 8, 29, 35]. In addition, ChatGPT has demonstrated potential in providing emotional support, by playing therapeutic roles based on user sentiment and need [29].\n# 2.2 LLMs as Information Access Systems\nIncorporating LLMs in information access systems introduces transformative prospects from GIA, particularly through multi-turn interactions that resemble traditional IIR processes [24, 26]. However, harnessing LLMs in information access systems presents pronounced challenges. Users encounter difficulties in query formulation or interpreting search results often due to cognitive barriers, which are common when initializing and refining prompts during interactions with LLMs [23, 34]. These barriers often stem from task context and user perceptions, such as lack of prior knowledge, low\nfamiliarity level with the topic, high complexity, and inappropriate expectations, leading to potential misconceptions about how LLMs interpret and respond [6, 7, 19, 23, 30, 31].\n# 2.3 Evaluating Human-LLM-Interaction\nIn recent literature, the evaluation of human-LLM interaction has garnered significant attention, especially as these models become increasingly used in human tasks. A comprehensive approach to this evaluation has been proposed, encompassing aspects such as task performance, user experience, and general \"Human-AI eXperience\" (HAX) [1, 10]. With similar interaction process and challenges, there are also notable parallels between the evaluation of human-LLM interaction and the assessment of IIR. Both areas highlight the significance of user experience and perception. Another critical facet enhancing user trust and comprehension is explainability in AI, which merits more profound exploration [9, 33].\n# 3 RESEARCH QUESTIONS\nIn respect to the challenges and opportunities in human-LLM interaction and the roles of task context and user perceptions in IS and IIR research, our study aims to investigate the research question RQ: How can we provide support with task context and user perception information to mitigate user challenges in tasks when interacting with ChatGPT? To answer this question, we explore our methodology for collecting and integrating features related to task context and user perception, importing these features into the system through prompt engineering, and developing supportive functions to enhance user assistance in the task.\n# 4 METHODOLOGY\n# 4.1 System design and supportive functions\nWe developed an interface similar to the official ChatGPT, with GPT-3.5-turbo as the model, and integrated questionnaires and supportive functions. The interface and the prompt templates for the supprortive functions are shown in Figure 1. To interact with the system, users need to enter the pre-task questionnaire highlighted in upper left of the interface. The pre-task questionnaire collects features of task context and user perceptions, including task topic and type, familiarity level, and expectations (e.g., expected task complexity, spending time, and outcome). The detailed descriptions of these features are in Table 1. Within the pre-task questionnaire, perceptions articulation is implemented as the generative features: familiarity level and expected complexity. Unlike traditional surveys that use Likert scales to measure these two features, our approach utilizes ChatGPT to generate five degrees of familiarity or task complexity with descriptions and examples. This function aims to assist participants in better comprehending and selecting the option that most closely aligns with their perceptions. The chosen degree, along with its description and example, are then formatted in the prompt template to enrich the context of the main prompt template, which is demonstrated in the left dashed box in Figure 1. We developed this main prompt template with several components, including role, description, narrative, aspect, and format according to a prior study for designing effective prompts [28]. This template aims to provide ChatGPT with comprehensive background information about task context and user perceptions. After this pre-task questionnaire, we implement the second supportive function, prompt suggestions, by using the main prompt template involved ongoing conversations. The suggestions are displayed in separate tabs at the bottom of the interface. Furthermore, for each conversation, we implement the conversation explanation function in the rating questionnaire. This function generates five explanation options, allowing users to select the one that best\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f5dd/f5dd55b7-aca5-491d-be4a-cc7c9c23dabf.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 1. User study platform and prompt templates for supportive functions. Yellow boxes highlight the components for the questionnaires and supportive functions. Grey boxes contain features (including generative features) collected through the questionnaires Solid arrows indicate the features collected in the pre-task questionnaire, subsequently utilized in prompt suggestions and conversation explanations through prompt engineering. Dashed and dotted boxes contain prompt templates, with {variable features}. Dotted arrows indicate the application of prompt templates in implementing the supportive functions.</div>\n<div style=\"text-align: center;\">Table 1. Features in the pre-task questionnaire and the conversation rating questionnair</div>\nFeature\nDescription\nPre-task questionnaire\nTask topic\nUser input text of task topic\nTask type\nGeneral task type options, such as Learning a\nnew topic, generating text, casual conversation,\nreplacing search engine, etc.\nFamiliarity\nlevel\nFive-degree choices with descriptions and examples\ngenerated by a prompt involving {task topic}\nExpected\ncomplexity\nFive-degree choices with descriptions and examples\ngenerated by a prompt involving {Task topic}\nand {Familiarity level}\nExpected\nspending time\nThree options: less than 30 minutes, 1 to 2 hours,\nmore than 3 hours\nExpected\noutcome\nFour options: get a broad idea of the task,\npartially complete the task,\nfully complete the task, other(text input)\nConversation rating questionnaire\nExplanation\nFive potential explanations for corresponding\n{user prompt} and {ChatGPT response}\nExplanation\nutility\nFive-degree options with descriptions from\n\u201cvery poor\u201d to \u201cexcellent\u201d\nConversation\nusefulness\nFive-degree options from not useful to\nextremely useful.\nConversation\nsatisfaction\nFive-degree options from very unsatisfied to\nvery satisfied.\naligns with their intent. We also include an explanation utility question, which allows users to rate the utility of the chosen explanation on a five-point scale. The purpose of the conversation explanation function is to present ChatGPT\u2019 interpretation of each prompt or response for users and investigate the potential of these explanations in enhancing user engagement and experience.\n# 4.2 Participant recruitment\nWe targeted two distinct user groups for our research: college students at a research university and crowdsourced workers from Amazon mTurk. The recruitment process contains two steps: Step 1: participants were asked to complete a registration survey. This survey collected background information, including demographics and prior experience with ChatGPT. Step 2: We then inquired participants if they wished to proceed to the remote user study. Those who\nopted in then reported the tasks they planned to perform with ChatGPT. We required participants to report task plans with three anticipated task lengths: short (less than 30 minutes), medium (1 to 2 hours), and long (3 hours or more). According to the naturalistic study setting, participants were allowed to edit the task plan when they had new task ideas and complete planned tasks in five days. Before their own tasks, they would perform a warm-up task to get familiar with the platform interface and the study process. After the user study, participants could opt for an interview where we sought their feedback and insights on their experiences. In these interviews, we specifically explored their views on the task experience using our platform, the effectiveness of the supportive functions, and any suggestions or opinions they might have. Compensation for participants includes $5 for the step 1 registration survey and $50 for the step 2 user study. This compensation exceeds the minimum wage threshold, and our research has received approval from the Institutional Review Board (IRB). The decision to choose two distinct participant groups aimed at broadening user diversity. While past studies focused on college students as early adopters of ChatGPT, they still highlighted the need for a more heterogeneous user group. Consequently, our participant pool includes college students from diverse fields such as Computer Science, Library and Information Science, and Public Health. Additionally, we incorporated crowd workers to ensure an even broader user spectrum. However, we set a qualification with an age range of 18-25 for crowd workers to facilitate a comparative analysis between the two groups.\n# 4.3 Analysis\nFor this small-scale user study, we utilized a descriptive analysis by presenting the tasks users performed on our platform and explaining how the platform influenced user experience and assisted them in task completion. In addition, we delved into the interview data as case studies to illuminate users\u2019 experiences and insights.\n# 5 RESULTS\n# 5.1 Participants and tasks\nAs a result, 16 participants enrolled in the user study, comprising 8 college students and 8 crowd workers. The college students came from various academic backgrounds, including computer science, library/information science, and public health, ranging from sophomores to graduates. The crowd workers specialized in fields such as information technology and business, and were either pursuing or had already obtained their bachelor\u2019s degrees. Out of the 16 participants, six completed the tasks according to their task plans and participated in the interview (3 college students and 3 crowd workers), while the remainder finished at least the warm-up task. Table 2 presents the average results of the tasks. Excluding the warm-up task, there were 29 tasks in total, comprising 10 short tasks, 13 medium tasks, and 6 long tasks. There were notable differences between the college student group and the crowd worker group, especially concerning the numbers of prompts and used prompt suggestions, and task duration. College students submitted approximately 5 to 6 prompts in short or medium tasks, though the duration for medium tasks was about double that of short tasks. They submitted over 20 prompts in the long task, completing the task in almost two days. In all task lengths, they adopted about one prompt from the suggestions in average. Conversely, crowd workers spent more time and prompts on short tasks than college students did, but they spent less time on medium and long tasks. This discrepancy could stem from their reliance on prompt suggestions, as nearly all their prompts were derived from these suggestions. Regarding the conversation ratings, college students had a positive experience (high\n<div style=\"text-align: center;\">Table 2. Average results of the tasks and user experience</div>\nParticipant group\nCollege student\nCrowd worker\nExpected length\nShort\nMedian\nLong\nShort\nMedian\nLong\nTask count\n7\n6\n3\n3\n7\n3\n# Prompt\n5.9\n5.2\n22.7\n12.5\n12.5\n25.3\n# Suggestion\n1.2\n0.8\n1\n12.5\n12\n23\nDuration (min)*\n223.5\n445.2\n2488.6\n558.3\n31.5\n32.9\nUsefulness\n3.8\n4.2\n3.2\n4.3\n4.2\n4\nExplanation utility\n4\n4.1\n3.2\n4.2\n3.8\n2.8\nSatisfaction\n4\n4.2\n3.3\n4.3\n4.5\n4.2\nen the start and end of the task, not the exact amount of time spent on the task.\n<div style=\"text-align: center;\">Table 3. Summary and examples of task topics and types grouped by expected length and participant group.</div>\nExpected length\nShort\nMedian\nLong\nParticipant group\nCollege student\nTopic\nLearning a language,\nGrammar Checking,\nBasic programming\nSpecific programming problems\nSpecific programming problems\nType\nLearning a new topic,\nWriting or generating text\nLearning a new topic,\nDeveloping or programming\nDeveloping or programming\nParticipant group\nCrowd worker\nTopic\n(writing techniques)\nJK (Rowling),\nCompany market\nLearning (online learning platform),\nDeveloping (learning programming languages)\nType\nCasual conversation,\n(Learning anew topic)\nCasual conversation,\n(Learning a new topic)\nCasual conversation,\nLearning a new topic\nsk topics and types in \"()\" provide clarifications for ambiguous topics or types that users entered in the pre-task questionnaire, as further inferred from actual conversations\nusefulness, explanation utility, and satisfaction) in short and medium tasks but a moderate experience in long tasks. Crowd workers generally had a positive experience, except for the moderate explanation utility in long tasks. To gain deeper insight into the participants\u2019 experiences, table 3 provides a summary and examples of tasks topics and types, grouped by users and expected task length. College students (especially computer science students) engaged in tasks that included learning new topics (in short and medium tasks) and solving specific programming problems (in medium and long tasks). In contrast, crowd workers did not specify clear task topics in the pre-task questionnaire. They used vague terms like \"JK,\" \"learning,\" and \"developing,\" primarily intending to engage in casual conversations with ChatGPT. Consequently, based on their input and heavy reliance on the prompt suggestion function, those suggestions led the conversations towards topics such as \"J.K. Rowling\", \"online learning platforms\", and \"learning programming languages\".\n# 5.2 Interview case study on task experience\nWe further present insights from the interview as case studies, examining the impact of supportive functions on user experience and task completion. Table 3 outlines participants\u2019 backgrounds, prior experiences with ChatGPT, task experiences during this study, and insights. We interviewed three computer science college students, P1, P2, and P3, all of whom showed considerable enthusiasm and engagement in both the tasks and subsequent interviews. Additionally, we interviewed crowd workers P4, P5, and P6. We delve into detailed feedback from P1, P2, and P3 and summarize the concerns raised by P4, P5, and P6. P1, a self-identified expert of ChatGPT, considering ChatGPT as useful but not compatible with human experts. In this study, P1 recognized the value of perception articulation in \"guiding expectations\". In addition, the conversation explanations helped P1 \"balance expectations\" and satisfaction. For instance, P1 previously experienced ChatGPT\u2019s\nPartici-\npant\nP1\nP2\nP3\nP4 P5 P6\nBack-\nground\nComputer science senior\nComputer science sophomore\nComputer science sophomore\nCrowd workers in infor-\nmation technology fields\nPrevious\nexperience\nChatGPT not compatible with\nhuman experts\nChatGPT with unexpected perfor-\nmance\nMiscommunication between\nthe user and ChatGPT\nUsing ChatGPT for text\ngeneration work\nTask\nin\nthis study\nGenerating Haikus,\nInternship specific question,\nSpecific Coding problem\nLearning a game dev tool,\nUsing a game dev package,\nSpecific coding problem\nResume revision\nCasual conversation,\nlearning a topic\nExperi-\nence\nin\nthis study\n\u2022 Detailed pre-task perceptions\nfor guiding expectations;\n\u2022 Prompt explanations for bal-\nancing expectations;\n\u2022 Prompt suggestions for cu-\nriosity or unfamiliarity;\n\u2022 Task-level conversation\n\u2022 Overestimated familiarity recogni-\ntion through retrospection;\n\u2022 Prompt suggestions for initializing\nthe conversation;\n\u2022 Prompt suggestion not applicable for\ncomplex tasks;\n\u2022 Explanations for prompt refining;\n\u2022 Final prompt development or final\nsolution guidance\n\u2022 Paraphrasing issues in expla-\nnations;\n\u2022 Distracting issues in prompt\nsuggestions;\n\u2022 Prompt suggestions for new\nand diverse information;\n\u2022 Efforts in refining desired out-\nput\n\u2022 Prompt suggestion re-\nliance;\n\u2022 Satisfaction\nInsight\n\u2022 Expectation management\n\u2022 Task reliability\n\u2022 Prompt refining willingness\n\u2022 Diverse prompt suggestions\n\u2022 Task-focused interface\n\u2022 Dynamic perceptions\n\u2022 Expectation management\n\u2022 Task reliability\n\u2022 Explainability for prompt refining\n\u2022 Interactive prompt refining process\n\u2022 Diverse explanation,\n\u2022 Diverse prompt suggestions\n\u2022 Interactive prompt refining\nprocess\n\u2022 Misuse of prompt sug-\ngestions\nshortcomings in understand the specific rules of haikus, and they (a gender-neutral alternative to he/she) had a low expectation and started with some simple rules of haikus in this study. Surprisingly, P1 found the generated haikus followed the correct rules. However, inconsistencies arose when P1 increased the rule complexity. After reviewing the conversation explanations, P1 adjusted their expectations, acknowledging ChatGPT\u2019s limitations but remaining satisfied. P1 also noticed that explanations were more detailed for tasks with low familiarity but more concise and \u201cstraight to the point\u201d for more familiar topics. However, P1 found the prompt suggestion function sometimes misaligned with their intended task direction, particularly in specific programming problems. Nonetheless, P1 appreciated the guidance from suggested prompts when exploring unfamiliar content, especially in the internship related question. They also highlighted the study platform\u2019s effectiveness in maintaining focus on specific tasks, thereby enhancing engagement and efficiency. P2 previously found ChatGPT unexpectedly efficient in suggesting coding solutions. However, they did not anticipate fully completing tasks from ChatGPT\u2019s responses but expected to \"get a broad idea\" to guide their own solution development. In this study, P2 recognized how the platform interpreted task context and user perceptions in the pre-task questionnaire. For example, when encountering challenges that ChatGPT\u2019s response exceeded P2\u2019s knowledge, they realized overestimated familiarity of a topic and reassessed it. The conversation explanation function allowed P2 to understand where any miscommunication began and to refine prompts. For example, in the complex C++ coding task, P2 gained confidence and refined prompts through iterative interactions and could use ChatGPT to \"build all remembered functions in one prompt\", attributing this improvement to learning from the explanations. However, P2 became dissatisfied when the code generated by ChatGPT was incompatible with an updated game development package. They then realized that ChatGPT had limited knowledge on this development package and discontinued the conversation for alternative resources. Regarding the prompt suggestions, P2 found them useful in initializing short tasks, but overly broad and generalized in the longer or more complex tasks. P3 self-identified as proficient with ChatGPT, but they experienced miscommunication with ChatGPT\u2019s interpretations. In this study, P3 provided unique insights when revising their resume. P3 observed redundancy and paraphrasing\nissues among the explanation options. For the prompt suggestions, P3 felt that those suggestions could sometimes distract from their initial intents. Nevertheless, P3 acknowledged the suggestions\u2019 potential to unveil new perspectives, such as unconsidered resume layouts. P3 also emphasized the effort required to modify ChatGPT\u2019s output to their preferred style and content. Regarding the crowd workers (P4, P5, and P6) involved in IT-related fields, their previous interaction with ChatGPT was primarily work-related. In this study, as per the tasks summarized in Tables 1 and 2, they appeared hurried in their completion, heavily relying on prompt suggestions, possibly due to their focus on Human Intelligence Tasks (HITs). Their feedback during interviews remained nonspecific, centered more around task completion for compensation rather than the study\u2019s investigative purpose. It seems they misunderstood the task purpose of this study, or they were outliers of target users, which raised concerns discussed in the next section.\n# 6 DISCUSSION AND CONCLUSION\nIn closing discussion, we incorporate insights derived from our study, focusing on enhancing human-LLM interaction and identifying prevalent challenges during these interactions. Insights and Implications for System Evaluation: The interview insights suggest distinct evaluation metrics at both the system and user ends. For the system, we can propose task reliability, which reflects the LLM\u2019s deep understanding and capability of task-specific knowledge beyond the text completion. This reliability could be evaluated through the LLM\u2019s ability to describe different levels of task familiarity and complexity for better recognizing the user\u2019s task states given the task familiarity and complexity levels. Another evaluation aspect could be conversation explainability, reflecting the LLM\u2019s ability to interpret the conversation from a task-aware perspective. Enhancements of both task reliability and explainability might include graph-based methods to represent the task in a knowledge structure with contextual information that enhances situational awareness [22, 32]. On the user end, metrics on task engagement could be measured by users\u2019 willingness to refine prompts and be influenced by the expectation of LLM\u2019s capability [17, 34]. Proactive User Interface and System Design: Our study offers insights for proactive user interface and system design, which extends previous work on proactive IR [15]. Our approach involved utilizing questionnaires and specific interface tabs, yet the need for more seamless integration emerged. Following established AI interaction guidelines, a separate interface, such as a sidebar or secondary tab, could be deployed to facilitate supportive functions without interruptions on the ongoing conversation with ChatGPT. This proactive interface could also adopt a conversation-based mechanism for capturing user perceptions and provide suggestions, assisting the main ChatGPT interaction. This system holds the potential to leverage a fine-tuned LLM, for analyzing ongoing conversations and offering task-aware recommendations [11\u201313, 25]. This insight represents a step towards more intuitive, assistive AI, catering to diverse user needs without over-complicating the interaction. Recognizing the Unique Position of Crowd Workers: This study revealed unexpected findings concerning crowd workers\u2019 interactions with ChatGPT. These anomalies may not solely be attributed to users\u2019 misunderstanding of the study\u2019s purpose but also possibly to the inherent challenges these users faced in formulating their own tasks. HITs for crowd workers are usually straightforward and repetitive tasks, like data labelling, even though they still require instructions and a gold standard to ensure accurate labeling [28]. Although they can produce text resembling task plans to meet the HIT criteria, this text does not necessarily mirror their real information needs [21, 27]. Formulating their \"own\" tasks or even identifying their information needs may be internally complex tasks. Additionally, the emphasis on task-centric LLM in this study might overshadow challenges with exploratory or open-ended user intentions. Therefore, it is crucial to comprehend the diverse information needs and usage contexts among more diverse user categories, so that the\nproactive system should be intuitively informative and inclusive, rather than restrictively functional for certain user groups [24]. Limitations and Future Directions: Acknowledging our study\u2019s constraints in its limited scale, we advocate for expansive user studies with participants from diverse communities, populations, and backgrounds. Beginning for the prototype system in this study, future work could involve improving the interface and system design, conducting prompt template ablation studies, and exploring LLM fine-turning for developing task support affordances. Further discussions might explore task automation and copilot, with the challenge of balancing user engagement in information seeking and learning, while providing efficient, single-prompt task resolution. In conclusion, our user study delved into supportive functions for ChatGPT, bolstering user experiences and task completion. The results indicated that these functions effectively guided users in managing expectations, reducing cognitive load, better refining prompts, and increasing user engagement. This investigation markedly advances our understanding of how to leverage LLMs for proactive IS systems. Moreover, it sheds light on the evaluation of humanLLM interactions and highlights the potential oversight of certain user groups\u2019 unique challenges in the era of Generative AI.\n# 7 ACKNOWLEDGMENT\nThis work is supported by the National Science Foundation (NSF) Award IIS-2106152, a grant from the Seed Funding Program of the Data Institute for Societal Challenges, the University of Oklahoma, and a fund from Microsoft for Startups Founders Hub. Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsors.\n[1] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen, et al. 2019. Guidelines for human-AI interaction. In Proceedings of the 2019 chi conference on human factors in computing systems. 1\u201313. [2] Leif Azzopardi. 2021. Cognitive biases in search: a review and reflection of cognitive biases in Information Retrieval. In Proceedings of the 2021 conference on human information interaction and retrieval. 27\u201337. [3] Aram Bahrini, Mohammadsadra Khamoshifar, Hossein Abbasimehr, Robert J Riggs, Maryam Esmaeili, Rastin Mastali Majdabadkohne, and Morteza Pasehvar. 2023. ChatGPT: Applications, opportunities, and threats. In 2023 Systems and Information Engineering Design Symposium (SIEDS). IEEE, 274\u2013279. [4] David Baidoo-Anu and Leticia Owusu Ansah. 2023. Education in the era of generative artificial intelligence (AI): Understanding the potential benefits of ChatGPT in promoting teaching and learning. Journal of AI 7, 1 (2023), 52\u201362. [5] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877\u20131901. [6] Barbara J Ford. 1995. Information literacy as a barrier. IFLA journal 21, 2 (1995), 99\u2013101. [7] Ahmed Hassan, Ryen W White, Susan T Dumais, and Yi-Min Wang. 2014. Struggling or exploring? Disambiguating long search sessions. In Proceedings of the 7th ACM international conference on Web search and data mining. 53\u201362. [8] Enkelejda Kasneci, Kathrin Se\u00dfler, Stefan K\u00fcchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan G\u00fcnnemann, Eyke H\u00fcllermeier, et al. 2023. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and individual differences 103 (2023), 102274. [9] Sunnie SY Kim, Elizabeth Anne Watkins, Olga Russakovsky, Ruth Fong, and Andr\u00e9s Monroy-Hern\u00e1ndez. 2023. \" Help Me Help the AI\": Understanding How Explainability Can Support Human-AI Interaction. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 1\u201317. [10] Mina Lee, Megha Srivastava, Amelia Hardy, John Thickstun, Esin Durmus, Ashwin Paranjape, Ines Gerard-Ursin, Xiang Lisa Li, Faisal Ladhak, Frieda Rong, et al. 2022. Evaluating human-language model interaction. arXiv preprint arXiv:2212.09746 (2022). [11] Lizi Liao, Grace Hui Yang, and Chirag Shah. 2023. Proactive conversational agents. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining. 1244\u20131247. [12] Lizi Liao, Grace Hui Yang, and Chirag Shah. 2023. Proactive Conversational Agents in the Post-ChatGPT World. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. 3452\u20133455.\n[13] Jiqun Liu, Matthew Mitsui, Nicholas J Belkin, and Chirag Shah. 2019. Task, information seeking intentions, and user behavior: Toward a multi-level understanding of Web search. In Proceedings of the 2019 conference on human information interaction and retrieval. 123\u2013132. [14] Jiqun Liu, Shawon Sarkar, and Chirag Shah. 2020. Identifying and predicting the states of complex search tasks. In Proceedings of the 2020 conference on human information interaction and retrieval. 193\u2013202. [15] Jiqun Liu and Chirag Shah. 2019. Proactive identification of query failure. Proceedings of the Association for Information Science and Technology 56, 1 (2019), 176\u2013185. [16] Jiqun Liu and Chirag Shah. 2022. Leveraging user interaction signals and task state information in adaptively optimizing usefulness-oriented search sessions. In Proceedings of the 22nd ACM/IEEE joint conference on digital libraries. 1\u201311. [17] Mengyang Liu, Yiqun Liu, Jiaxin Mao, Cheng Luo, Min Zhang, and Shaoping Ma. 2018. \" Satisfaction with Failure\" or\" Unsatisfied Success\" Investigating the Relationship between Search Success and User Satisfaction. In Proceedings of the 2018 world wide web conference. 1533\u20131542. [18] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. Comput. Surveys 55, 9 (2023), 1\u201335. [19] Daan Odijk, Ryen W White, Ahmed Hassan Awadallah, and Susan T Dumais. 2015. Struggling and success in web search. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. 1551\u20131560. [20] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730\u201327744. [21] Joel Ross, Lilly Irani, M Six Silberman, Andrew Zaldivar, and Bill Tomlinson. 2010. Who are the crowdworkers? Shifting demographics in Mechanical Turk. In CHI\u201910 extended abstracts on Human factors in computing systems. 2863\u20132872. [22] Shawon Sarkar, Maryam Amirizaniani, and Chirag Shah. 2023. Representing Tasks with a Graph-Based Method for Supporting Users in Complex Search Tasks. In Proceedings of the 2023 Conference on Human Information Interaction and Retrieval. 378\u2013382. [23] Reijo Savolainen. 2015. Cognitive barriers to information seeking: A conceptual analysis. Journal of Information Science 41, 5 (2015), 613\u2013623. [24] CHIRAG SHAH and EMILY M BENDER. 2023. Envisioning Information Access Systems: What Makes for Good Tools and a Healthy Web? (2023). [25] Chirag Shah, Ryen White, Paul Thomas, Bhaskar Mitra, Shawon Sarkar, and Nicholas Belkin. 2023. Taking search to task. In Proceedings of the 2023 Conference on Human Information Interaction and Retrieval. 1\u201313. [26] Marita Skjuve, Asbj\u00f8rn F\u00f8lstad, and Petter Bae Brandtzaeg. 2023. The user experience of ChatGPT: Findings from a questionnaire study of early users. In Proceedings of the 5th International Conference on Conversational User Interfaces. 1\u201310. [27] Manuel Steiner, Damiano Spina, Falk Scholer, and Lawrence Cavedon. 2021. Crowdsourcing Backstories for Complex Task-Based Search. In Proceedings of the 25th Australasian Document Computing Symposium. 1\u20136. [28] Paul Thomas, Seth Spielman, Nick Craswell, and Bhaskar Mitra. 2023. Large language models can accurately predict searcher preferences. arXiv preprint arXiv:2309.10621 (2023). [29] Ahmed Tlili, Boulus Shehata, Michael Agyemang Adarkwah, Aras Bozkurt, Daniel T Hickey, Ronghuai Huang, and Brighter Agyemang. 2023. What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education. Smart Learning Environments 10, 1 (2023), 15. [30] Ben Wang and Jiqun Liu. 2022. Investigating the Relationship between In-Situ User Expectations and Web Search Behavior. Proceedings of the Association for Information Science and Technology 59, 1 (2022), 827\u2013829. [31] Ben Wang and Jiqun Liu. 2023. Investigating the role of in-situ user expectations in Web search. Information Processing & Management 60, 3 (2023), 103300. [32] Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, and Tat-Seng Chua. 2019. Explainable reasoning over knowledge graphs for recommendation. In Proceedings of the AAAI conference on artificial intelligence, Vol. 33. 5329\u20135336. [33] Feiyu Xu, Hans Uszkoreit, Yangzhou Du, Wei Fan, Dongyan Zhao, and Jun Zhu. 2019. Explainable AI: A brief survey on history, research areas, approaches and challenges. In Natural Language Processing and Chinese Computing: 8th CCF International Conference, NLPCC 2019, Dunhuang, China, October 9\u201314, 2019, Proceedings, Part II 8. Springer, 563\u2013574. [34] JD Zamfirescu-Pereira, Richmond Y Wong, Bjoern Hartmann, and Qian Yang. 2023. Why Johnny can\u2019t prompt: how non-AI experts try (and fail) to design LLM prompts. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 1\u201321. [35] Xiaoming Zhai. 2022. ChatGPT user experience: Implications for education. Available at SSRN 4312418 (2022).\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of challenges users face when interacting with large language models (LLMs) like ChatGPT, particularly in initializing and refining prompts, which are further complicated by cognitive barriers and biased perceptions. Previous methods have not effectively integrated task context and user perceptions into these interactions, necessitating a new approach.",
        "problem": {
            "definition": "The problem focuses on the difficulties users encounter in formulating effective prompts when using LLMs, which are exacerbated by cognitive barriers and biased perceptions that hinder task completion.",
            "key obstacle": "The main challenge lies in the static nature of existing search systems that fail to adapt to the dynamic user perceptions regarding task context, familiarity, and expectations."
        },
        "idea": {
            "intuition": "The idea was inspired by the need to enhance user interactions with LLMs by integrating task context and user perceptions into the interaction process.",
            "opinion": "The proposed idea involves developing a ChatGPT-like platform that incorporates supportive functions such as perception articulation, prompt suggestions, and conversation explanations to aid users in effectively utilizing LLMs.",
            "innovation": "The primary innovation of this method is the integration of supportive functions that dynamically adapt to user input, thereby enhancing user engagement and reducing cognitive load compared to traditional methods."
        },
        "method": {
            "method name": "Task Supportive and Personalized Human-Large Language Model Interaction",
            "method abbreviation": "TSP-LLM",
            "method definition": "This method involves a user-centric platform that utilizes prompt engineering to incorporate task context and user perceptions into interactions with LLMs.",
            "method description": "The core of the method is a ChatGPT-like interface that supports users through tailored functions designed to improve user experience and task completion.",
            "method steps": [
                "User completes a pre-task questionnaire to articulate perceptions and expectations.",
                "The system utilizes responses to generate enriched prompts for ChatGPT.",
                "Users receive prompt suggestions and explanations during interactions to facilitate understanding and engagement."
            ],
            "principle": "The method is effective due to its ability to adapt to users' cognitive states and task contexts, providing tailored support that enhances comprehension and task management."
        },
        "experiments": {
            "evaluation setting": "The experimental setup involved a user study with 16 participants, including college students and crowdsourced workers, who engaged in various tasks using the developed platform.",
            "evaluation method": "Participants' experiences were assessed through descriptive analysis of task completion, prompt usage, and qualitative feedback from interviews."
        },
        "conclusion": "The study concluded that the supportive functions significantly enhance user experiences by managing expectations, reducing cognitive load, and facilitating prompt refinement, ultimately leading to improved task completion and engagement.",
        "discussion": {
            "advantage": "The key advantage of the proposed approach is its proactive support for users, which helps manage expectations and improve interaction quality compared to traditional LLM usage.",
            "limitation": "A limitation identified is the potential misalignment of prompt suggestions with user intents, particularly in complex tasks.",
            "future work": "Future research should focus on expanding user studies to diverse populations and improving the interface and system design for better integration of supportive functions."
        },
        "other info": {
            "funding": "This work is supported by the National Science Foundation (NSF) Award IIS-2106152 and other grants.",
            "participant demographics": {
                "college_students": "Participants included college students from various fields such as Computer Science and Public Health.",
                "crowd_workers": "Crowdsourced workers were recruited from Amazon mTurk, focusing on individuals aged 18-25."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper addresses the challenges users face when interacting with large language models (LLMs), highlighting the significance of improving user experience in technology."
        },
        {
            "section number": "1.2",
            "key information": "The proposed idea involves developing a ChatGPT-like platform that incorporates supportive functions to aid users in effectively utilizing LLMs."
        },
        {
            "section number": "4.1",
            "key information": "The method, named Task Supportive and Personalized Human-Large Language Model Interaction (TSP-LLM), utilizes prompt engineering to enhance user interactions with LLMs."
        },
        {
            "section number": "4.2",
            "key information": "The study concluded that supportive functions significantly enhance user experiences by managing expectations and facilitating prompt refinement."
        },
        {
            "section number": "5.1",
            "key information": "The method includes a pre-task questionnaire that helps articulate user perceptions and expectations, which is crucial for understanding user preferences."
        },
        {
            "section number": "10.1",
            "key information": "A limitation identified in the paper is the potential misalignment of prompt suggestions with user intents, particularly in complex tasks."
        },
        {
            "section number": "10.2",
            "key information": "Future research should focus on expanding user studies to diverse populations and improving the interface and system design for better integration of supportive functions."
        }
    ],
    "similarity_score": 0.7347102618566448,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Task Supportive and Personalized Human-Large Language Model Interaction_ A User Study.json"
}