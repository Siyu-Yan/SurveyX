{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1704.08719",
    "title": "When memory pays: Discord in hidden Markov models",
    "abstract": "When is keeping a memory of observations worthwhile? We use hidden Markov models to look at phase transitions that emerge when comparing state estimates in systems with discrete states and noisy observations. We infer the underlying state of the hidden Markov models from the observations in two ways: through naive observations, which take into account only the current observation, and through Bayesian filtering, which takes the history of observations into account. Defining a discord order parameter to distinguish between the different state estimates, we explore hidden Markov models with various numbers of states and symbols and varying transition-matrix symmetry. All behave similarly. We calculate analytically the critical point where keeping a memory of observations starts to pay off. A mapping between hidden Markov models and Ising models gives added insight into the associated phase transitions.",
    "bib_name": "lathouwers2017memorypaysdiscordhidden",
    "md_text": "# When memory pays: Discord in hidden Markov models\nEmma Lathouwers\u2217 Department of Physics, Simon Fraser University, Burnaby, British Columbia, V5A 1S6, Canada and Department of Physics, Utrecht University, Princetonplein 5, 3584 CC Utrecht, The Netherlands\nJohn Bechhoefer\u2020 Department of Physics, Simon Fraser University, Burnaby, British Columbia, V5A 1S6, Canada (Dated: September 17, 2018)\nWhen is keeping a memory of observations worthwhile? We use hidden Markov models to look at phase transitions that emerge when comparing state estimates in systems with discrete states and noisy observations. We infer the underlying state of the hidden Markov models from the observations in two ways: through naive observations, which take into account only the current observation, and through Bayesian filtering, which takes the history of observations into account. Defining a discord order parameter to distinguish between the different state estimates, we explore hidden Markov models with various numbers of states and symbols and varying transition-matrix symmetry. All behave similarly. We calculate analytically the critical point where keeping a memory of observations starts to pay off. A mapping between hidden Markov models and Ising models gives added insight into the associated phase transitions.\n# I. INTRODUCTION\nProblems requiring statistical inference [1, 2] are all around us, in fields as varied as neuroscience [3, 4], signal processing [5], and artificial intelligence (machine learning) [6, 7]. A common problem is state estimation, where the goal is to learn the underlying state of a dynamical system from noisy observations [6, Chapt. 10]. In most cases, the ability to infer states improves smoothly as the signal-to-noise ratio of observations is varied. However, there can also be phase transitions in the ability to infer the most likely value of a state, as the signal-to-noise ratio of observations is varied [8]. Formally, phase transitions in inference can occur because problems of inference and statistical physics share common features such as the existence of a free-energy-like function and the requirement or desire that this function be minimized. Yet the extent to which these elements lead to common outcomes such as phase transitions is not yet clear. In this paper, we investigate the generality of these links in the context of a specific setting: the comparison of state estimates based on current observations with those based on both current and past observations. A simple setting for exploring such problems is given by hidden Markov models (HMMs). They are widely used, from speech recognition [9, 10], to economics [11, 12], and biology [13, 14]. HMMs describe the evolution of a Markovian variable and the emission of correlated, noisy symbols. Taking the current emitted symbol at face value gives us a naive state estimate. However, in these correlated systems there is additional information in the history of emitted symbols, which we can use to find a more\nrefined state estimate. Comparing the state estimates then reveals in which cases the additional information from keeping a memory of observations makes a difference. When the observed symbols as a function of time are Markovian, such as HMMs with no noise, there is no advantage to retaining past information. However, for more general systems, the situation is not clear. Intuitively, if the noise is low (and the entire state vector is observed), then there should be no advantage. But if the noise is high, then averaging over many observations may help, as long as the system does not change state in the meantime. The surprise is that the transition from a situation where there is no advantage to keeping a memory to one where there is can have the character of a phase transition. Such transitions have been observed in the specific case of two-state, two-symbol HMMs [8, 15]. In this article, we ask how general this behavior is in HMMs: Do we observe these phase transitions [16] in more complicated models? How sensitive is the behavior of the phase transitions to the details of the model? And can we understand their origin? In Section II, we introduce the theoretical background of the systems we study. Then, in Sections III\u2013V, we introduce and characterize phase transitions in various generalizations of HMMs. In the appendices, we detail the calculation of a phase-transition in n-state, n-symbol HMMs, and in 2-state, 2-symbol models with broken symmetry. In an attempt to gain insight into the origins of the observed phase transitions, we also show how to map a two-state, two-symbol HMM onto an Ising model.\n# II. STATE ESTIMATION IN HMMS\nHMMs can be fully described by two probability matrices and an initial state. The evolution of the hid-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/280e/280e2a8e-dfad-4ed5-b1a1-f56e26ffb94e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIG. 1. Graphical structure of a HMM. At time t, the hidden state xt produces an observation yt. The matrix A defines the state dynamics, while B relates observations to states.</div>\nden state xt is governed by a n-state Markov chain, described by an n \u00d7 n transition matrix A with elements Aij = P(xt+1 = i|xt = j). The observation of an emitted symbol yt is described by an m \u00d7 n observation matrix B, with elements Bij = P(yt = i|xt = j). The matrix dimensions m and n refer to, respectively, the number of symbols and the number of states. A graphical representation of the dependence structure is shown in Fig. 1. The observations depend only on the current state of the system. Note that the observations as a function of time, described by P(yt+1|yt), generally do not have Markovian dynamics. We will refer to an n-state, m-symbol HMM as an n \u00d7 m HMM. We assume that we have perfect knowledge of our model parameters, and we will focus on comparing stateestimation methods that do or do not keep a memory. In particular, we will compare the naive observation yt of the HMM to the state estimate \u02c6xf t found through Bayesian filtering. The Bayesian filtering equations recursively calculate the probability for the system to be in a state xt given the whole history of observations yt [8], where yt = {y1, y2, . . . , yt} is used as a shorthand for all past and current information. The probability is calculated in two steps: the prediction step P(xt+1|yt), and the update step P(xt+1|yt+1). The steps can be worked out using marginalization, the definition of conditional probability, the Markov property, and Bayes\u2019 theorem. The transition matrix and the previous filter estimate are needed to predict the next state, and the observation matrix together with the prediction are needed to update the probability. Together, they give the Bayesian filtering equations [17],\n(1a)\n(1b)\nwith the normalization factor\n(2)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/dd04/dd046bea-6e33-4311-b64b-62b3b8e5e907.png\" style=\"width: 50%;\"></div>\nFIG. 2. Time series of a 2 \u00d7 2 HMM generated from a transition matrix A = \ufffd0.8 0.4 0.2 0.6 \ufffd , and an observation matrix B = \ufffd0.7 0.3 0.3 0.7 \ufffd . The (unknown) Markov chain is shown in light gray, the naive observations as circles, and the filter probability as a black line. The arrow indicates a time step where the naive state estimate differs from the filter estimate.\nThe Bayesian formulation results in a probability density function for the state xt. When the observations yt are noisy, we cannot be completely sure that our observations and state estimates are correct. Long sequences of the same observation increase our belief that system is indeed in the observed state, according to Bayesian filtering. However, even after an infinitely long sequence of the same observation, there is always a chance that the system actually transitioned into another state during the last time step and that we are therefore observing an \u201cincorrect\u201d symbol (the symbol does not match the state): The probability to be in state xt = i given the history of observations yt is bounded by a maximum confidence level p\u2217 i that depends on the model\u2019s parameters and is defined as the probability to be in a given state after a long sequence of the same observation:\n(3)\nwhere by yt = it we mean {y1 = i, y2 = i, . . . , yt = i}. It is important that the sequence of identical observations is long enough that making an additional identical observation does not change the probability. In Fig. 2 a fragment of the evolution of a HMM, the underlying (unknown) state and observed symbols, is shown together with the Bayesian filtering probability calculated over the time series. For long sequences of identical observations, we see that the filtering probability levels off. Generally, each state will have a different maximum confidence level. We will return to the maximum confidence level in later calculations and discussions. Many applications, such as feedback control, depend on single-value estimates \u02c6xt rather than on probability distributions. Although statistics such as the mean and median are reasonable candidates for the \u201ctypical\u201d value of a distribution (minimizing mean-square and absolute errors [18, Sec. 14.2]), it is more convenient here to use the mode, or maximum, which is termed, in this context, the state estimate. For state estimates based on all past and current information, we define the filter estimate\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f1d0/f1d0227c-132c-4c12-b581-2fa7d75b140c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIG. 3. Discrete probability distribution, with continuously varying control parameter going from (a)\u2013(c).</div>\nFor the HMM shown in Fig. 2, Eq. (4) implies that whenever the filter probability is above 0.5, the filter estimates the system to be in state 1; similarly, it is in state \u22121 when the probability < 0.5. Analogously, we define the naive state estimate to be based entirely on the current observation, with no use made of past observations,\n(5)\nIn the special case where there is a one-to-one correspondence between symbols y and elements of the internal state x, the quantity \u02c6xo t reduces to yt, the symbol emitted at time t. More generally, the number of internal state components may be smaller than the number of observations, making the interpretation of the estimates more subtle. As we will see, the combination of defining a probability distribution for the state variable and then selecting its maximum leads to the possibility of phase transitions. When one uses other ways to characterize the state than the mode, e.g. the mean, one may not find the analytical discontinuities that we study. However, the arg max captures an interesting complexity of the probability density function that would be lost in taking the mean. This is illustrated in Fig. 3, where there is a transition in the arg max, at (b). By contrast, taking the mean of the distribution ignores the bimodal nature of the distributions and shows no transition. This argument also applies to observables, such as work, that are functions of filter estimates. To know when keeping a history of observations pays off, we need to determine under what conditions the two state estimates will differ. We quantify how similar two sequences of state estimates by defining a discord order parameter,\n(6)\nwhere the function d depends on the naive and filter state estimates:\n(7)\nThe discord parameter is zero when the state estimates agree at all times. In such a case, there is no value in keeping a memory of observations: the extra information\ncontained in the past observations has not changed the best estimate from that calculated using only the present observation. Similarly, when D = 2 the state estimates disagree at all times, the state estimates are perfectly anti-correlated. At intermediate values of D, keeping a memory can be beneficial. An HMM with a non-zero discord is illustrated in Fig. 2: an arrow indicates a point where the state estimate differs from the estimate based on the current observation. We are interested in the transition from zero to nonzero discord, where the state estimates start to differ, and where keeping a history of observations starts to pay off. The lowest observation probability that leads to a nonzero discord is the critical observation probability. We have just seen that after a long sequence of identical observations the probability to be in some state xt reaches a maximum value. Thus, the first place where state estimates will differ is when a single discordant observation after a long string of identical observations does not change our belief of the state of the system (i.e., where the filter estimate no longer follows the naive estimate exactly). Mathematically, the threshold where the discord goes from zero to being non-zero for an n\u00d7n HMM is given by\nlim t\u2192\u221eP(xt+1 = i|yt+1 = j, yt = it)\n(8)\nfor all states i, j \u2208{1, 2, . . . , n}, and j \u0338= i. From Ref. [8], the transition threshold for a symmetric 2\u00d72 HMM with transition probability a and error rate b is\nbc = 1 2 \ufffd 1 \u2212 \u221a 1 \u22124a \ufffd \ufffd a \u22641 4 \ufffd ,\n(9)\n\ufffd \ufffd \ufffd \ufffd and bc = 1/2 for larger a values. In Sec. III, we generalize this result by dropping the symmetry requirement. As found in [8], the transitions are sometimes discontinuous and sometimes just have a discontinuity in their derivative. As far as we know, the distinction has not been explored. So far, we have only considered the extreme cases of no memory and infinitely long memory. What about a finite memory? In Fig. 2, we see that the filter reacts to new observations with a characteristic timescale. Indeed, since the filter dynamics for a system with n internal states is itself a dynamical system with n\u22121 states (minus one because of probability normalization), we expect filters to have n \u22121 time scales. This statement holds no matter how big or small the memory of the filter. As a numerical exploration confirms, there is geometric (exponential) relaxation with time scales that are easy to evaluate numerically, if difficult algebraically. Thus, an \u201cinfinite\u201d filter memory need only be somewhat longer than the slowest time scale, and \u201cno memory\u201d need only be faster than the fastest time. A brief study of filters with intermediate time scales suggests that their behavior typically interpolates between the two limits.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1767/1767a3ea-a96f-465c-bab3-e37527d50f43.png\" style=\"width: 50%;\"></div>\nFIG. 4. (Color online) Discord parameter as a function of the average observation probability for a 2 \u00d7 2 HMM with symmetric observations (\u2206b = 0) and slightly asymmetric transitions, \u2206a = 0.01. Arrows indicate the primary and two higher-order transitions.\n# III. SYMMETRY BREAKING IN TWO-STATE, TWO-SYMBOL HMMS\nIn 2 \u00d7 2 HMMs where the symmetry in the transition and observation probabilities is broken, the probability matrices each have two independent parameters. We parametrize the transition-matrix probabilities as\n(10)\n\uf8ed \uf8f8 which depends on the mean transition probability \u00afa = 1 2(A21 + A12) and the difference in transition probabilities \u2206a = A21 \u2212A12. When the difference between the transition probabilities is zero (\u2206a = 0), the transition matrix is symmetric. The observation matrix is parameterized similarly, with \u00afa \u2192\u00afb and \u2206a \u2192\u2206b. The matrix B depends on the mean observation probability \u00afb = 1 2(B21 + B12) and the difference in observation probabilities \u2206b = B21 \u2212B12. All matrix elements must be in the range [0, 1] to ensure proper normalization. We restrict the off-diagonal elements (probability to transition to a different state or probability to make a wrong observation) to be < 0.5, to preclude anticorrelations. We use the set {1, \u22121} to label both states and the corresponding symbols for 2 \u00d7 2 HMMs. The discord parameter is calculated by generating a realization of an HMM using the transition and observation matrices, following Eq. (6) and averaging over the entire chain. A plot of the discord for a 2 \u00d7 2 HMM with asymmetric transition probabilities is shown in Fig. 4. All points shown are averaged over 30, 000 time steps. The expression defining the critical observation probability in Eq. (8) simplifies greatly for 2 \u00d7 2 HMMs:\n(11)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/68ad/68adea82-7068-448e-b58e-7a38733379cc.png\" style=\"width: 50%;\"></div>\nFIG. 5. (Color online) Mean critical observation probability of HMMs with asymmetric transition matrices and symmetric observation matrices (\u2206b = 0) a function of \u00afa. Simulated results are shown as circles; solid lines show the analytical solutions.\nWe write this in terms of the model\u2019s parameters and solve for the critical observation probability \u00afb = \u00afbc. This corresponds to the lowest points \u00afb in Fig. 4 that are nonzero for a given \u00afa. The complete analytical calculations for the critical observation probability can be found in App. A. Figure 5 shows the analytical and simulated critical observation probabilities as a function of the mean transition probability \u00afa, for a system with symmetric observation probabilities and several different transition asymmetries. The curve labeled \u2206a = 0.01 corresponds to the transitions in Fig. 4. The solutions agree with simulations, which are shown as circles in the same diagram. The discord becomes non-zero at lower mean transition probabilities for larger asymmetries. The phase transitions differ in location from those of the symmetric 2 \u00d7 2 HMMs, but they still exist. We find similar results in systems with symmetric transition matrices and asymmetric observation matrices, and in systems with both asymmetric transition and observation matrices [19]. Another approach to understanding these results is offered in App. B, where we show that we can map 2 \u00d7 2 HMMs onto one-dimensional Ising models with disordered fields and zero-temperature phase transitions. In Fig. 4, we observe some additional jumps and kinks at error rates \ufffd\u00afb > \u00afbc \ufffd that can be interpreted as \u201chigherorder transitions\u201d in the discord. We have labeled two of such transitions by \u00afb1 and \u00afb2 in Fig. 4. The first of these is due to the asymmetry of this HMM. The threshold \u00afbc results from the observation sequence yt = {1, . . . , 1, \u22121}, whereas the slightly higher \u00afb1 results from the sequence yt = {\u22121, . . . , \u22121, 1}, which gives a condition that is different when \u2206a \u0338= 0. The second of these transitions, \u00afb2, marks the threshold where two discordant observations are needed to change the filter state estimate. That is, the observation sequence is yt = {1, . . . , 1, \u22121, \u22121}. For still higher values of \u00afb, there will be transitions where one needs more than two sequential discordant observations\nto alter the filter value. Further transitions can occur for finite arbitrary sequences, too. Higher-order transitions, however, are increasingly weak and harder to detect numerically.\n# IV. MORE STATES AND SYMBOLS\nWe have seen that phase transitions in the discord order parameter occur in both symmetric and asymmetric time-homogeneous 2 \u00d7 2 HMMs. In this section, we will study systems with more states and more symbols. To keep the number of parameters manageable, we will consider symmetric HMMs, and we will consider only two classes of states: an observation is either correct and the symbol is the \u201csame\u201d as the underlying state, or an observation is incorrect and the system emits an \u201cother\u201d symbol. We consider a straightforward generalization of symmetric 2\u00d72 HMMs to symmetric n\u00d7n HMM, and a model that describes a particle diffusing on a lattice with constant background noise. We investigate whether the transitions that we have encountered so far exist in these systems, too.\nLet us now label the states and symbols 1, 2, . . . , n. We first consider a system with transition matrix\n(12)\nand an observation matrix B, which has the same form except that a \u2192b. This system depends on only two parameters for a given number of states n: the transition probability, a, and the observation error probability, b. This transition matrix describes a system that has a probability 1 \u2212a to stay in the same state and equal probabilities to transition to any other state, a n\u22121. The observation matrix describes a measurement with uniform background noise; there is a certain probability of observing the correct symbol 1\u2212b and equal probabilities of observing any other symbol, b n\u22121. Just as before, we calculate the discord parameter for these systems and study the transition to non-zero discord by finding the critical observation probability. The problem simplifies from the case discussed above, where A is a general transition matrix. In App. C, we write it out explicitly, and find two solutions:\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9cf1/9cf1df06-4ba1-4302-9141-f172815ae437.png\" style=\"width: 50%;\"></div>\nFIG. 6. (Color online) Phase diagram of symmetric n \u00d7 n HMMs for n = 2, 3, 4, 10, and n \u2192\u221e. The lines are analytical solutions; the circles are the results of simulations.\n(13a)\n(13b)\nFor n = 2, Eq. (13a) reduces to Eq. (9). The threshold values of b are plotted in Fig. 6 for various numbers of states and symbols n. The branches of the solutions that are increasing with increasing a are given by b(1) c , and the constant branches are given by b(2) c . The analytical and simulated values agree quite well, especially for smaller n. The n = 10 curve deviates from the simulations slightly at higher a. The area under the curves indicates the parameter regime where D = 0, where the state estimates with and without memory agree. Above the critical error probability, the two state estimates differ. There are no discontinuities as bc \u2192n\u22121 n ; the curves are simply very steep.\n# B. Diffusing particle\nWe now consider an HMM that describes a particle diffusing on a lattice with constant background noise and periodic boundary conditions. The symmetric n\u00d7n transition matrix is given by\n(14)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5581/558150b3-e506-4c99-ab13-872a505e9663.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIG. 7. (Color online) Scaled discord parameter as a function of the scaled observation probability for a diffusing particle on a one-dimensional lattice with four sites (n = 4).</div>\nFIG. 7. (Color online) Scaled discord parameter as a function of the scaled observation probability for a diffusing particle on a one-dimensional lattice with four sites (n = 4).\nThe observation matrix is the same as the one in the previous section. Physically, the particle stays in the same place with probability 1 \u2212a or it diffuses one site to the left or right with probability a/2. The discord parameter as a function of the observation probability is plotted in Fig. 7. For visualization purposes, both the discord and the observation probability are scaled by a factor of n/(2n\u22122), where n is the number of lattice sites. The scaling is such that (n/(2n\u22122))D = 1 at (n/(2n \u22122))b = 0.5 for any integer n > 1. The transition to non-zero discord is smooth in this case; however, at higher b and D, a non-analytic jump is seen.\n# V. MORE SYMBOLS THAN STATES\nFinally, we consider an HMM with more symbols than states. In particular, consider an HMM with only two states, 1 and \u22121, and an even number of symbols n. We will also consider the n \u2192\u221elimit. The transitions and errors are once again taken to be symmetric, with A = \ufffd1\u2212a a a 1\u2212a \ufffd , but the observation errors are now determined by a Gaussian distribution around the states. In particular, the elements of the observation matrix are determined by integrals over the Gaussian distribution of the desired state. For state 1, the observation probability for symbol i is\n(15)\nThe boundaries \u2113i of the integral are determined such that the probability of observing each symbol is equal\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c887/c887f150-749f-467a-a666-5f462027bf09.png\" style=\"width: 50%;\"></div>\nFIG. 8. (Color online) Critical observation probability bc of symmetric 2 \u00d7 n HMMs, for a fixed transition probability a = 0.30, as a function of 1/n. The straight line emphasizes the asymptotic behavior for large n.\nwhen considering the sum of Gaussian distributions around each state.\n(16)\nThe symmetry of the problem reduces the number of equations we need to solve: We know that \u21130 = \u2212\u221e, \u2113n = \u221e, \u2113n/2 = 0, and \u2113(n/2)\u2212j = \u2212\u2113(n/2)+j for integers j between 1 and n/2 \u22121 (all for even n). Also, symmetry dictates that the probability of observing a symbol i given the state is \u22121, bi(\u22121), equals b(n\u2212i+1)1. For n \u2192\u221e(infinitely many symbols), we use the probability density function directly rather than integrating over an interval. In systems with a finite number of symbols, we observe non-analytic behavior as the discord becomes nonzero. These phase transitions move to lower observation probabilities for a larger number of symbols. In systems with an infinite number of symbols, the discontinuities are not present. To confirm this observation, we study the critical error probability as a function of the number of symbols; see Fig. 8. The critical error probability is shown for a transition probability a = 0.30 as a function of 1/n. The behavior is similar for other transition probabilities and suggests that the critical observation probability goes to zero asymptotically. The (discontinuous) transitions disappear only in the limit of infinitely many symbols. In the n\u00d7n symmetric HMMs, we saw similar behavior: The critical error probability decreases as a function of the number of symbols (and states). However, if we look at the limit of n \u2192\u221eof the critical error probability of these HMMs (Fig. 6), the critical error probability does not go to zero.\nIn this paper, we have investigated when keeping a memory of observations pays off in hidden Markov models. We used HMMs to look at a relatively simple system with discrete states and noisy observations. We inferred the underlying state of the HMM from the observations in two ways: through naive observations, and a state estimate found through Bayesian filtering (and decision making). We then compared the state estimates by calculating the discord, D, between the two. We were particularly interested in investigating a phase transition at the point where D becomes non-zero. Such transitions have been observed in symmetric 2 \u00d7 2 HMMs; here, we have seen that such behavior applies to more general models. We looked at asymmetric 2\u00d72 HMMs, some symmetric n \u00d7 n HMMs, and symmetric 2 \u00d7 n HMMs. The general features of the discord stayed the same in all these systems: it starts at D = 0 for b = 0; it becomes non-zero at some critical error probability; and it increases for increasing error probability. In all these systems, we found a non-analytic behavior in the discord as a function of observation error probability (phase transition), except in the 2 \u00d7 n case in the limit of infinitely many symbols, n \u2192\u221e. Throughout this paper, we have defined the usefulness of memory in a rather narrow way: we ask when inferences using a memory are different or better than those that do not. But memory can have many more uses. In thermodynamics, Maxwell\u2019s demon and Szilard\u2019s engine showed that information that is acquired can be converted to work [20]. Bauer et al. analyzed a periodic,\n# Appendix A: Critical error probability of asymmetric 2 \u00d7 2 HM\nIn Eq. (11), we defined the critical error probability \u00afbc as the lowest \u00afb for given \u00afa, \u2206a, and \u2206b that results in  non-zero discord parameter. In this appendix, we calculate this threshold analytically. We start by writing out the left-hand-side of Eq. (11) explicitly:\nlim t\u2192\u221eP(xt+1 = 1|yt+1 = \u22121, yt = 1t) = lim t\u2192\u221e P(yt+1 = \u22121|xt+1 = 1) \ufffd xt P(xt+1 = 1|xt)P(xt|yt = 1t) \ufffd xt+1 P(yt+1 = \u22121|xt+1) \ufffd xt P(xt+1|xt)P(xt|yt = 1t) .\n\ufffd  \ufffd We recognize several terms as part of the transition and observation matrices. The term P(xt|yt = 1t) relates to the maximum confidence level. We need to find the maximum confidence level in terms of the observation and transition probabilities.\n\ufffd  \ufffd We use normalization to write limt\u2192\u221eP(xt\u22121 = \u22121|yt\u22121 = 1t\u22121) = 1 \u2212p\u2217 1, and we have an expression only in term\ntwo-state Maxwell demon with noisy state measurements and showed that there are transitions very much analogous to the ones considered here between phases where measurements are judged reliable, or not [15]. When reliable, there is no advantage to keeping a memory.\nand showed that there are transitions very much analogous to the ones considered here between phases where measurements are judged reliable, or not [15]. When reliable, there is no advantage to keeping a memory. In biology, one can consider cells in noisy environments and ask whether keeping a memory of observations of this environment is worthwhile. For example, Sivak and Thomson showed, in a simple model, that for very low and very high ratios of signal to noise in the environment, memoryless algorithms lead to optimal regulatory strategies [21]. However, for intermediate levels of noise, strategies that retain a memory perform better. In contrast to the situations considered in this paper, they found no evidence of any phase transition. There were smooth crossovers between regimes. In another setting, Rivoire and Leibler have explored how information retention by populations of organisms can improve the ability of the population to adapt to fluctuating environment [22]. Again, in this setting, no phase transitions were encountered. Also, Hartich et al. showed that the performance of a sensor, characterized by its \u201csensory capacity,\u201d increases with the addition of a memory but report no phase transition [26]. Thus, in this paper, we have explored a class of models where phase transitions occur generically as a function of signal-to-noise ratios. Yet, in many other applications, such transitions are not observed. Clearly, a better understanding is needed to clarify which settings will show phase transitions and which ones continuous crossovers between different regimes.\nThus, in this paper, we have explored a class of models where phase transitions occur generically as a function of signal-to-noise ratios. Yet, in many other applications, such transitions are not observed. Clearly, a better understanding is needed to clarify which settings will show phase transitions and which ones continuous crossovers between different regimes.\n(A1)\n(A2)\nof the maximum confidence level, transition probability and the observation probability. We then solve for p\u2217 1:\n# of the maximum confidence level, transition probability and the observation probability. We then solve for p\u2217 1:\n\ufffd \ufffd astly, we solve for \u00afb = \u00afbc. We find three solutions, of which only two lie in our region of interest, 0 \u2264\u00afa,\u00afb \u22640.5. ince the resulting expressions are complicated, we show the full solution only for the special case where \u2206b = 0:\n384 \ufffd \u2212 \u2212 \u2212 \ufffd \ufffd Y \ufffd \ufffd \ufffd Y = \ufffd 18(\u00afa \u22121)\u2206a \u2212\u2206a3 + 3 \u221a 3 \ufffd (11 \u22124\u00afa(\u00afa + 4))\u2206a2 + (4\u00afa \u22121)3 + \u2206a4 \ufffd1/3 .\n18(\u00afa \u22121)\u2206a \u2212\u2206a3 + 3 \u221a 3 \ufffd (11 \u22124\u00afa(\u00afa + 4))\u2206a2 + (4\u00afa \u22121)3 + \u2206a\n\ufffd \ufffd \ufffd These solutions are plotted in Fig. 5. Note that the expression for \u00afb(2) c is real for relevant branches. That is, for some values of \u00afa and \u2206a the expression is complex; however, all the branches we plot have a zero imaginary part. When we set \u2206a = 0, b(1) c reduces to 1 2 \ufffd 1 \u2212\u221a1 \u22124\u00afa \ufffd for \u00afa \u22641/4, and 1 2 for \u00afa \u22651/4. These are the familiar solutions for symmetric 2 \u00d7 2 HMMs as found in [8] and App. C.\n# Appendix B: Mapping to Ising models\nOne can map a symmetric 2 \u00d7 2 HMM onto a one-dimensional random-field Ising model [8, 23, 24]. Here, we generalize this mapping so that it applies to a general (asymmetric) 2 \u00d7 2 HMM. We start by defining a mapping from the transition and observation probabilities to the spin-spin coupling and the spin-field coupling constants,\nP(xt+1|xt) = exp(J(xt)xt+1xt) 2 cosh(J(xt))\n\uf8f4 \uf8f4 \uf8f4 \uf8f3 We define the Hamiltonian H \u2261\u2212log(P(xN, yN)), which, using the product rule of probability and the Marko property of the state dynamics, is\nNext, we rewrite the h(xt) and J(xt) in a convenient way:\nh(xt) = \u00afh + \u2206hxt, with \u00afh = 1 2(h+ + h\u2212) and \u2206h = 1 2(h+ \u2212h\u2212) ,\n(A3)\n(A4)\n(A5)\n(A6)\n(A7)\n(A8)\n(B1)\n(B2)\n(B3)\nand the same for J(xt) with h \u2192J. When \u2206a is zero, we have \u2206J = 0 and \u00afJ = J, where J is the coupling constant found in the case of symmetric 2 \u00d7 2 HMMs [8]. The same happens with the h-terms when \u2206b = 0. The terms consisting of a logarithm with a hyperbolic cosine can also rewritten by taking the mean value of the possible terms and a deviation from that mean value. The constant terms can be neglected since they lead only to a shift in the energy. Similarly, terms that depend only on a single factor yt can also be neglected. Higher-order terms that depend on a product of these factors still contribute. The full Hamiltonian is now given by\nFor large N, we can neglect boundary terms. Then rearranging the Hamiltonian so that one term represents t nearest-neighbor interactions and the others the local external fields, we find,\n\ufffd = \u2212 \ufffd \u00afJxt+1xt \u2212\u00afhytxt + C( \u00afJ, \u2206J, \u00afh, \u2206h)xt .\nThe external field consists of a fluctuating term that depends on yt and a constant term that depends transition and observation parameters.\nThe external field consists of a fluctuating term that depends on yt and a constant term that d observation parameters.\nFrom Eq. (B5), it is clear that this Hamiltonian remains the Hamiltonian of the familiar Ising model. There is a constant spin-spin coupling term, the strength of which is determined by the transition probabilities \u00afa and \u2206a. Then there is the fluctuating term of the local external fields. The magnitude is constant and determined by the observation probabilities, but the direction is assigned randomly through yt. Finally, there is a constant term in the external fields that depends on both the transition and observation probabilities. Above, we have seen that the filtering problem for a HMM can be mapped onto an Ising model. How useful is such a mapping? It does add intuitive language. The observations yt play the role of a local spin at each site. From Eq. (B1), we see that a lower error rate (small \u00afb) corresponds to strong coupling between the local field and the local spin, which corresponds to state xt. When the noise is so strong that an observation says nothing about the underlying state (\u00afb = 1/2), then the coupling h = 0. Likewise, deviations of \u00afa from 1/2 determine the spinspin coupling constant J. These results, however, were previously derived for symmetric 2\u00d72 HMMs [23, 24]. Here, we add the insight that generalizing to asymmetric dynamics (matrix A) or observation errors (matrix B) leads to the same qualitative scenario. The mapping remains a simple Ising model; only the coefficients are modified. It would be interesting to know whether such mappings work for more order parameters, where the corresponding spin problem is presumably a Potts model [25]. Although the Ising mapping gives some qualitative insights, it has limitations. In a closely related problem, estimating the full path xt of states on the basis of ob-\n(B4)\n(B5)\nservations yt, the desired filter estimate corresponds to the ground state of the corresponding Ising model [24]. Here, by contrast, the filter estimate corresponds, in Ising language, to estimating the most likely value of the last (edge) spin of a 1d chain, without caring about the spin of any other site\u2014a strange quantity! Thus, in mapping the filter state estimation problem to an Ising chain, we transform a familiar question concerning a strange system to asking a strange question of a familiar system. Whether such a swap leads to analytical progress beyond its value in forming a qualitative picture is not at present clear.\nAppendix C: Calculation of critical observation probability for n \u00d7 n HMMs\nHere, we compute the critical observation probability for symmetric n \u00d7 n HMMs analytically. We need only consider one state/ symbol i and one j, thanks to the symmetry of the problem. For example, use i = 1 and j = 2 in Eq. (8), which leads to\nlim t\u2192\u221eP(xt+1 = 1|yt+1 = 2, yt = 1t) = lim t\u2192\u221eP(xt+1 = 2|yt+1 = 2, yt = 1t) .\n(C1)\nSimilar to the calculation in App. A, we start with the calculation of the maximum confidence level, p\u2217. Since all states of a symmetric n \u00d7 n HMM are equivalent, the maximum confidence levels are all the same. We calculate\n(C2)\nThe first two terms in the numerator are known from the transition and observation matrix of the HMM. The last term is p\u2217if xt\u22121 = i. For xt\u22121 \u0338= i, we can calculate it\n\ufffd \ufffd e preliminary expressions, we can calculate the critical error probability. From Eq. (C1), the left-hand\nPlugging all these terms into Eq. (C1) and substituting p\u2217from Eq. (C4), we solve for the critical error probability b as a function of a and n and find Eq. (13).\nPlugging all these terms into Eq. (C1) and substituting p\u2217from Eq. (C4), we solve for the critical error probability bc as a function of a and n and find Eq. (13).\n# ACKNOWLEDGMENTS\nWe thank Malcolm Kennett for suggestions concerning the Ising-model map and Rapha\u00a8el Ch\u00b4etrite for comments\n[1] D. J. C. MacKay, Information Theory, Inference, and Learning Algorithms (Cambridge Univ. Press, 2003).\nby demanding a normalized probability,\n\ufffd p\u2217+ (n \u22121) lim t\u2192\u221eP(xt\u22121 = j|yt\u22121 = it\u22121) = 1\nPlugging all of the terms into Eq. (C2) and solving for p\u2217in terms of the model parameters leaves us with two solutions. Restricting interest to the solutions that take on positive values for 0 \u2264a, b \u22641 and integer n > 1, we find,\n(C4)\n(C5)\n(C6a)\n(C6b)\n[2] B. Efron and T. Hastie, Computer Age Statistical Inference: Algorithms, Evidence, and Data Science (Cam-\nbridge University Press, 2016). [3] J. J. Hopfield, \u201cNeural networks and physical systems with emergent collective computational abilities,\u201d Proc. Natl. Acad. Sci. USA 79, 2554\u20132558 (1982). [4] A. C. C. Coolen, R. K\u00a8uhn, and P. Sollich, Theory of Neural Information Processing Systems (Oxford Univ. Press, 2005). [5] H. L. Van Trees and K. L. Bell, Detection Estimation and Modulation Theory, Part I: Detection, Estimation, and Filtering Theory, 2nd ed. (Wiley, 2013). [6] K. P. Murphy, Machine Learning: A Probabilistic Perspective (MIT press, 2012). [7] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning (MIT Press, 2016). [8] J. Bechhoefer, \u201cHidden Markov models for stochastic thermodynamics,\u201d New J. Phys. 17 (2015). [9] L. R. Rabiner, \u201cA tutorial on hidden Markov models and selected applications in speech recognition,\u201d Proceedings of the IEEE 77, 257\u2013286 (1989). [10] X. D. Huang, Y. Ariki, and M. A. Jack, Hidden Markov Models for Speech Recognition, Vol. 2004 (Edinburgh University Press, 1990). [11] J. D. Hamilton, \u201cA new approach to the economic analysis of nonstationary time series and the business cycle,\u201d Econometrica 57, 357\u2013384 (1989). [12] R. S. Mamon and R. J. Elliott, Hidden Markov Models in Finance, Vol. 104 (Springer Science & Business Media, 2007). [13] R. Durbin, S. R. Eddy, A. Krogh, and G. Mitchison, Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids (Cambridge University Press, 1998). [14] A. Krogh, M. Brown, I. S. Mian, K. Sj\u00a8olander, and D. Haussler, \u201cHidden Markov models in computational biology: Applications to protein modeling,\u201d J. Mol. Biol. 235, 1501\u20131531 (1994). [15] M. Bauer, A. C. Barato, and U. Seifert, \u201cOptimized\nfinite-time information machine,\u201d J. Stat. Mech. , P09010 (2014). [16] These transitions have the character of a phase transition in the sense that there is a free-energy-like function that is non-analytic at certain points. It may not have all characteristics of a thermodynamic phase transition. [17] S. S\u00a8arkk\u00a8a, Bayesian Filtering and Smoothing (Cambridge Univ. Press, 2013). [18] W. von der Linden, V. Dose, and U. von Toussaint, Bayesian Probability Theory: Applications in the Physical Sciences (Cambridge Univ. Press, 2014). [19] E. Lathouwers, When memory pays: Discord in hidden Markov models, Master\u2019s thesis, Simon Fraser University and Utrecht University (2016). [20] J. M. R. Parrondo, J. M. Horowitz, and T. Sagawa, \u201cThermodynamics of information,\u201d Nature Phys. 11, 131\u2013139 (2015). [21] D. A. Sivak and M. Thomson, \u201cEnvironmental statistics and optimal regulation,\u201d PLoS Comp. Biol. 10, e1003826 (2014). [22] O. Rivoire and S. Leibler, \u201cThe value of information for populations in varying environments,\u201d J. Stat. Phys. 142, 1124\u20131166 (2011). [23] O. Zuk, I. Kanter, and E. Domany, \u201cThe entropy of a binary hidden Markov process,\u201d J. Stat. Phys 121, 343\u2013 360 (2005). [24] A. Allahverdyan and A. Galstyan, \u201cOn maximum a posteriori estimation of hidden Markov processes,\u201d Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence , 1\u20139 (2009). [25] F. Y. Wu, \u201cThe Potts model,\u201d Rev. Mod. Phys. 54, 235\u2013 268 (1982). [26] D. Hartich, A. C. Barato, and U. Seifert, \u201cSensory capacity: An information theoretical measure of the performance of a sensor,\u201d Phys. Rev. E 93, 022116 (2016).\n",
    "paper_type": "theory",
    "attri": {
        "background": "This paper addresses the issue of state estimation in hidden Markov models (HMMs) and explores the phase transitions that arise when comparing state estimates derived from current observations versus those that incorporate historical data.",
        "problem": {
            "definition": "The problem involves determining when retaining a memory of past observations provides a significant advantage in state estimation within HMMs.",
            "key obstacle": "The main challenge is to identify the conditions under which the incorporation of past observations leads to improved state estimates, particularly in noisy environments."
        },
        "idea": {
            "intuition": "The idea stems from the observation that there can be phase transitions in inference similar to those in statistical physics, where the ability to infer states can change dramatically under varying conditions.",
            "opinion": "The authors propose that keeping a memory of observations can significantly improve state estimation, especially in systems with high noise levels.",
            "innovation": "The main innovation lies in identifying and mathematically characterizing the critical point at which memory retention becomes beneficial, which has not been thoroughly explored in previous models."
        },
        "Theory": {
            "perspective": "The theoretical perspective is grounded in the analogy between HMMs and Ising models, allowing for insights into the phase transitions that occur in state estimation.",
            "opinion": "The authors assume that the dynamics of state estimation can be understood through concepts from statistical physics, particularly the behavior of free-energy-like functions.",
            "proof": "The paper provides analytical calculations to derive the critical observation probabilities that mark the transitions in state estimation efficacy."
        },
        "experiments": {
            "evaluation setting": "The experiments utilize various HMM configurations, including symmetric and asymmetric models with different numbers of states and symbols, to assess the performance of naive versus Bayesian state estimates.",
            "evaluation method": "The evaluation involves calculating the discord order parameter to quantify the difference between state estimates and identifying the critical observation probabilities through simulations and analytical methods."
        },
        "conclusion": "The study concludes that phase transitions in state estimation are a general feature of HMMs, and that memory retention can significantly enhance performance, particularly in noisy environments.",
        "discussion": {
            "advantage": "The advantages of this paper include a novel approach to understanding state estimation through the lens of phase transitions, providing a deeper insight into when memory is beneficial.",
            "limitation": "A limitation is that the analysis primarily focuses on specific types of HMMs, which may not capture the full complexity of more generalized models.",
            "future work": "Future work could explore the implications of these findings in more complex systems and investigate the conditions under which phase transitions might occur in different types of inference problems."
        },
        "other info": [
            {
                "info1": "The paper includes appendices detailing further calculations related to critical observation probabilities and mappings to Ising models.",
                "info2": {
                    "info2.1": "The authors acknowledge contributions from colleagues for insights on the Ising model mapping.",
                    "info2.2": "References to additional literature on related topics are provided throughout the paper."
                }
            }
        ]
    },
    "mount_outline": [
        {
            "section number": "2.1",
            "key information": "The problem involves determining when retaining a memory of past observations provides a significant advantage in state estimation within hidden Markov models (HMMs)."
        },
        {
            "section number": "2.2",
            "key information": "The theoretical perspective is grounded in the analogy between HMMs and Ising models, allowing for insights into the phase transitions that occur in state estimation."
        },
        {
            "section number": "3.4",
            "key information": "The main innovation lies in identifying and mathematically characterizing the critical point at which memory retention becomes beneficial, which has not been thoroughly explored in previous models."
        },
        {
            "section number": "4.3",
            "key information": "The main challenge is to identify the conditions under which the incorporation of past observations leads to improved state estimates, particularly in noisy environments."
        },
        {
            "section number": "6.2",
            "key information": "Future work could explore the implications of these findings in more complex systems and investigate the conditions under which phase transitions might occur in different types of inference problems."
        }
    ],
    "similarity_score": 0.5548098861366496,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-0115_inter/papers/When memory pays_ Discord in hidden Markov models.json"
}