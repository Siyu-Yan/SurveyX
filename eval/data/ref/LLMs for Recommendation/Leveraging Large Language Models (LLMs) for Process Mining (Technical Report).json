{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2307.12701",
    "title": "Leveraging Large Language Models (LLMs) for Process Mining (Technical Report)",
    "abstract": "This technical report describes the intersection of process mining and large language models (LLMs), specifically focusing on the abstraction of traditional and object-centric process mining artifacts into textual format. We introduce and explore various prompting strategies: direct answering, where the large language model directly addresses user queries; multi-prompt answering, which allows the model to incrementally build on the knowledge obtained through a series of prompts; and the generation of database queries, facilitating the validation of hypotheses against the original event log.\n  Our assessment considers two large language models, GPT-4 and Google's Bard, under various contextual scenarios across all prompting strategies. Results indicate that these models exhibit a robust understanding of key process mining abstractions, with notable proficiency in interpreting both declarative and procedural process models.\n  In addition, we find that both models demonstrate strong performance in the object-centric setting, which could significantly propel the advancement of the object-centric process mining discipline.\n  Additionally, these models display a noteworthy capacity to evaluate various concepts of fairness in process mining. This opens the door to more rapid and efficient assessments of the fairness of process mining event logs, which has significant implications for the field.\n  The integration of these large language models into process mining applications may open new avenues for exploration, innovation, and insight generation in the field.",
    "bib_name": "berti2023leveraginglargelanguagemodels",
    "md_text": "# Leveraging Large Language Models (LLMs) for Process Mining (Technical Report)\nAlessandro Berti1,2* and Mahnaz Sadat Qafari\n1*Process and Data Science Group, RWTH Aachen University, Ahornstrasse 55, Aachen, 52074, NRW, Germany. 2*Center for Process Intelligence, Fraunhofer FIT, Schloss Birlinghoven, Konrad-Adenauer-Stra\u00dfe, Sankt Augustin, 53757, NRW, Germany.\n# *Corresponding author(s). E-mail(s): a.berti@pads.rwth-aachen.de; Contributing authors: sadatghafari@gmail.com;\nAbstract\nThis technical report describes the intersection of process mining and large language models (LLMs), specifically focusing on the abstraction of traditional and object-centric process mining artifacts into textual format. We introduce and explore various prompting strategies: direct answering, where the large language model directly addresses user queries; multi-prompt answering, which allows the model to incrementally build on the knowledge obtained through a series of prompts; and the generation of database queries, facilitating the validation of hypotheses against the original event log. Our assessment considers two large language models, GPT-4 and Google\u2019s Bard, under various contextual scenarios across all prompting strategies. Results indicate that these models exhibit a robust understanding of key process mining abstractions, with notable proficiency in interpreting both declarative and procedural process models. In addition, we find that both models demonstrate strong performance in the object-centric setting, which could significantly propel the advancement of the object-centric process mining discipline. Additionally, these models display a noteworthy capacity to evaluate various concepts of fairness in process mining. This opens the door to more rapid and efficient assessments of the fairness of process mining event logs, which has significant implications for the field.\nThe integration of these large language models into process mining applications may open new avenues for exploration, innovation, and insight generation in the field. Keywords: Large Language Models, Process Mining, GPT-4, Querying Language\nThe integration of these large language models into process mining applications may open new avenues for exploration, innovation, and insight generation in the field.\nKeywords: Large Language Models, Process Mining, GPT-4, Querying Language\n# 1 Preliminaries\nThe following subsections delve into some key preliminaries to provide the necessary background for our discussion. This encompasses the nature of traditional and object-centric event logs (Section 1.1), the distinctions between procedural and declarative process models (Section 1.2), the techniques for extracting numerical features from event logs (Section 1.4), and the understanding of fairness concepts within the scope of process mining (Section 1.5). These topics form the cornerstone of our exploration into the integration of large language models within process mining.\n# 1.1 Traditional and Object-Centric Event Logs\nCase ID\nActivity\nTimestamp\nCase1\nActivity A\n2023-07-13 09:00:00\nCase1\nActivity B\n2023-07-13 09:15:00\nCase1\nActivity C\n2023-07-13 09:30:00\nCase2\nActivity A\n2023-07-13 10:00:00\nCase2\nActivity B\n2023-07-13 10:30:00\nCase3\nActivity A\n2023-07-13 11:00:00\nCase3\nActivity C\n2023-07-13 11:30:00\nCase3\nActivity D\n2023-07-13 11:45:00\nEvent logs are pivotal to process mining, representing empirical data that drives operations such as process discovery, conformance checking, and model enhancement. Extracted from information systems, these logs comprise collections of events, each characterized by an activity and timestamp and associated with a particular process. As primary artifacts, event logs provide a robust basis for data-driven process analysis. Traditional event logs adhere to a format where each event is tied to a specific case, signifying a unique execution of the process. Every event is defined by its activity\u2014representing the operation performed, and a timestamp\u2014indicating when the operation took place. The Extensible Event Stream (XES) standard Acampora et al (2017) has been established for storing and exchanging these event logs, facilitating systematic documentation and analysis of process events. An example of traditional event logs is reported in\nTable 1. We have three cases. For Case1, we have three events with activities A,B,C. For Case2, we have two events with activities A and B. For Case3, we have three events with activities A,C,D.\nEvent ID\nActivity\nTimestamp\nOrder\nOrderItems\nInvoices\nEvent1\nActivity A\n2023-07-13 09:00:00\nOrder1\nItem1, Item2\nInvoice1\nEvent2\nActivity B\n2023-07-13 09:15:00\nOrder1\nItem1, Item2\nInvoice1\nEvent3\nActivity C\n2023-07-13 09:30:00\nOrder2\nItem3\nInvoice2\nEvent4\nActivity A\n2023-07-13 10:00:00\nOrder2\nItem3\nInvoice2\nEvent5\nActivity B\n2023-07-13 10:30:00\nOrder2\nItem4\nInvoice2\nEvent6\nActivity A\n2023-07-13 11:00:00\nOrder3\nItem5, Item6\nInvoice3\nEvent7\nActivity C\n2023-07-13 11:30:00\nOrder3\nItem5\nInvoice3\nEvent8\nActivity D\n2023-07-13 11:45:00\nOrder3\nItem6\nInvoice3\nEvent9\nActivity A\n2023-07-13 12:00:00\nOrder4\nItem7, Item8\nInvoice4\nEvent10\nActivity B\n2023-07-13 12:15:00\nOrder4\nItem8\nInvoice4\nObject-centric event logs, on the other hand, cater to more complex scenarios by associating each event with multiple objects of different types. Each event still holds information about its activity and timestamp, but instead of relating to a single process execution, it ties into multiple entities. The OCEL standard Ghahfarokhi et al (2021) has been proposed as a standard for the storage of object-centric event logs, capturing detailed interaction patterns between diverse process entities. An example is reported in Table 2. For example, we see that the event with identifier Event1 is related to one object of type order, two objects of type order item, and one object of type invoice. Object-centric event logs allow for the capture of complex, intertwined, multi-object scenarios, opening avenues for more nuanced process mining tasks. However, the complexity of these logs presents unique challenges for process mining, such as how to structure the data for analysis. A significant stride has been made in addressing these challenges with the proposal by Adams et al. in their 2022 study Adams et al (2022b) to partition object-centric event logs into \u201dexecutions\u201d. Their methodology, inspired by traditional case-oriented process mining, breaks down the intricate graph structure of object-centric event logs into manageable \u201dprocess executions\u201d, effectively the equivalent of cases in traditional event logs. By extending the case concept to object-centric data, the authors enable a more refined application of process mining tasks to these logs, enabling practitioners to query specific aspects of a process. Furthermore, through the application of graph isomorphism, they are able to identify equivalent process executions with respect to an attribute, thereby discovering object-centric variants. This approach offers a method for handling the complexities inherent in object-centric event logs without resorting to flattening the data, thereby preserving information and structure. As example, the object-centric event log in Table 2 is split in four distinct connected components ( {Order1, Item1, Item2, Invoice1}, {Order2, Item3, Invoice2}, {Order3, Item5, Item6, Invoice3}, {Order4, Item8, Invoice4} ).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7908/790847e2-c948-4680-b31a-197b83010fa0.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Frequency Annotation</div>\n# Fig. 1: Example directly-follows graph (DFG) computed on the event log described in Table 1.\nFig. 1: Example directly-follows graph (DFG) computed on the event log described in Table 1.\n# 1.2 Procedural Process Models\nProcedural process models, as a fundamental tool in process mining, systematically depict the order of activities and their interrelations within a process. These models capture the idea that some activities must precede others, clearly indicating the sequence or procedure that needs to be followed to attain a particular outcome. They represent a step-by-step visualization of a process, guiding us from the beginning to the end, hence the name \u2019procedural.\u2019 In such models, each step is contingent on the output of the preceding one, reinforcing a precise flow of tasks in a process. Now, let\u2019s delve into some common types of procedural process models.\nFig. 2: Example Petri net obtained from the event log described in Table  using the Inductive miner process discovery algorithm Leemans et al (2013).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3f9f/3f9ffc02-dc9c-46ef-a802-feaf612b1bb7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Performance Annotation</div>\nSpringer Nature 2021 LATEX template\nA primary example of a procedural process model is the directly-follows graph (DFG) van der Aalst (2016). This model encapsulates the succession relationship between activities, where an edge from activity A to activity B signifies that B has directly followed A in the process. DFGs provide an intuitive, visual way to comprehend the sequence of activities in a process and can be an effective starting point for process discovery. An example of a directly-follows graph, annotated with frequency and performance information, is reported in Figure 1.\nFig. 3: Example BPMN model obtained from the event log described in Table 1 using the Inductive miner process discovery algorithm Leemans et al (2013).\n<div style=\"text-align: center;\">Fig. 3: Example BPMN model obtained from the event log described in Table 1 using the Inductive miner process discovery algorithm Leemans et al (2013).</div>\nIn the realm of formal procedural process models, Petri nets have gained wide acceptance in process mining van der Aalst (1998). They offer a graphical and mathematical modelling tool well suited to capture concurrency, synchronization and shared resources. In a Petri net, places (represented as circles) can contain tokens, and transitions (represented as rectangles) can consume and produce these tokens, in line with predefined rules. Different process discovery algorithms have Petri nets as eventual output, including the Alpha van der Aalst et al (2004), the Inductive Leemans et al (2013) and the Heuristics Weijters and Ribeiro (2011) miners. An example of Petri net model, discovered from Table 1 using the Inductive miner, is presented in Figure 2. Another common procedural modelling notation used in business process management is the Business Process Model and Notation (BPMN 2.0 Aagesen and Krogstie (2015)). It is a rich, graphical representation for specifying business processes in a business process model, offering a more extensive set of symbols compared to Petri nets, thereby allowing more precise business communication Kalenkova et al (2017, 2019). However, the expressiveness of BPMN can lead to ambiguity due to the potential for different interpretations of its constructs Dijkman et al (2008); Ouyang et al (2006). An example of BPMN model is represented in Figure 3. We also provide an example of BPMN 2.0 XML1. In the realm of object-centric process mining, procedural process models extend their scope to encapsulate the multiple object types involved in a process. This leads to the creation of two key variants: object-centric directlyfollows graphs and object-centric Petri nets. An object-centric directly-follows\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/064d/064d0e06-4300-4a2f-bacf-63803f74fc3e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Frequency Annotation</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/0983/09839f6e-64d3-4df1-a753-60938243a6f9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Performance Annotation</div>\ngraph Berti and van der Aalst (2023) represents a direct evolution from the traditional directly-follows graph, with each object type having its own graph portraying the succession of activities involving that particular object. This collation of graphs offers a nuanced view of the process, maintaining the simplicity of the traditional format. On the other hand, the object-centric Petri net van der Aalst and Berti (2020) extends traditional Petri nets to capture the lifecycle of each individual object type within the process. Each object type is represented by its own Petri net, and their integration forms the objectcentric Petri net. This detailed representation provides a comprehensive view of the process, accounting for the interactions between the multiple object\nSpringer Nature 2021 LATEX template\ntypes. These models provide a powerful means for analyzing complex, objectcentric processes, enabling an in-depth understanding of the process from the perspective of individual object types and their interaction.\n# 1.3 Declarative Process Models\nDeclarative process models provide a different perspective compared to the traditional procedural process models. While procedural models specify the explicit sequence of activities in a process, declarative models describe the process through a set of constraints or rules that prescribe what cannot happen, leaving a degree of flexibility for what can happen. A common notation used for declarative modeling in the process mining field is the DECLARE framework Maggi et al (2011). It targets the controlflow perspective of a process by specifying constraints on the sequence, choice, and parallelism of activities. For instance, a DECLARE model can express that if activity \u2019A\u2019 happens, then activity \u2019B\u2019 must eventually follow, capturing the interdependence between activities.\nSource Activity\nTarget Activity\nAverage Time\nStandard Deviation\nActivity A\nActivity B\n1350.0\n636.40\nActivity A\nActivity C\n1800.0\n0.00\nActivity B\nActivity C\n900.0\n0.00\nActivity A\nActivity D\n2700.0\n0.00\nActivity C\nActivity D\n900.0\n0.00\nTable 3: Temporal profile model Stertz et al (2020) for the traditional event\nTable 3: Temporal profile model Stertz et al (2020) for the traditional even log presented in Table 1.\nFurthermore, declarative process models extend beyond control-flow constraints to capture other aspects of the process. Temporal declarative models incorporate temporal constraints into the process Stertz et al (2020); Barrientos et al (2023), providing further refinement on when activities should occur. Data-driven declarative models integrate data conditions to determine the valid sequence of activities, thus introducing a context-sensitive dimension to the process model. An example temporal model is presented in Table 3. Overall, declarative process models offer a flexible and holistic approach to process modeling, allowing for a wide range of scenarios and conditions to be incorporated, thereby addressing the complex, dynamic nature of many real-world processes.\n# 1.4 Extraction of Numerical Featu\nFeature extraction is a fundamental process in transforming raw event log data into a format that machine learning algorithms can interpret and learn from. In the context of process mining, feature extraction plays a significant role in various tasks, including predictive process monitoring, anomaly detection, and process enhancement, among others de Leoni et al (2016).\nSpringer Nature 2021 LATEX template\n# 8\nThe primary strategy to convert an event log into numeric features is through the use of encoding techniques such as one-hot encoding. In this strategy, each unique activity in the event log is assigned a distinct binary (0 or 1) feature, thus creating a binary vector representation for each case in the log. This enables machine learning algorithms to effectively capture and learn the presence or absence of specific activities within each case. This transformation is crucial since machine learning algorithms primarily work with numeric data. A numeric feature table computed on the traditional event log in Table 1 is presented in Table 4. Apart from the straightforward one-hot encoding, more advanced feature extraction methods can be considered. For instance, there are aggregate features that summarize specific characteristics of a case, like the total number of events, the mean time between events, or the standard deviation of the time between events. Another advanced technique is sequence encoding, where the order of activities is preserved. This is particularly beneficial when the sequence of activities is of paramount importance to the process. Other techniques include using n-grams Zandkarimi et al (2020), which capture sequences of \u2019n\u2019 consecutive activities, or using methods from natural language processing, such as word embeddings Junior et al (2020), to encode activities and their context within the case.\nCase ID\nActivity A\nActivity B\nActivity C\nActivity D\nCount\nTotal Duration\nCase1\n1\n1\n1\n0\n3\n30\nCase2\n1\n1\n0\n0\n2\n30\nCase3\n1\n0\n1\n1\n3\n45\nIn the realm of object-centric event logs, numeric feature extraction expands to accommodate the complexity and multidimensionality of these logs. Features are designed to represent the intricate dynamics involving multiple object types, their interactions, and temporal associations Berti et al (2023a); Adams et al (2022a). A numeric feature table computed on the object-centric event log in Table 2 is presented in Table 5. Activity features from object-centric event logs encapsulate the actions occurring on specific objects or types of objects. For each unique activity, a binary indicator or count variable can be created to signify whether a particular activity has occurred or how often it has taken place on each object. This not only helps encapsulate the inherent processes but also provides a granular understanding of different object types\u2019 behaviors. Inter-object features delve into the relationships between different objects in an object-centric log. When objects of different types consistently appear together, a feature is devised to symbolize this co-occurrence. This might be a binary flag signaling the presence of such a relationship or a count of\nthe frequency of these interactions, offering insight into patterns of object interdependencies and interplay. Temporal features are instrumental in encapsulating the timing aspects associated with events. For each object type, these can include the timestamp of the first or last event, the mean time between events, or the overall duration of processes involving the object. The temporal features help shed light on the pace and sequence of events across different objects, an essential aspect of understanding the overall process flow.\nOrder\nActivity A\nActivity B\nActivity C\nActivity D\nRelated Items\nRelated Invoices\nOrder1\n1\n1\n0\n0\n2\n1\nOrder2\n1\n1\n1\n0\n2\n1\nOrder3\n1\n0\n1\n1\n2\n1\nOrder4\n1\n1\n0\n0\n2\n1\nTable 5: Numeric feature table (for the object type Order) derived from the object-centric event log presented in Table 2.\nFinally, data attribute features cater to any additional attributes tied to the events or objects themselves. If an event or object comes with associated data attributes such as cost or resource allocation, these attributes can be incorporated as features. This inclusion ensures any vital context-specific or process-related information is not overlooked during the feature extraction process Qafari and van der Aalst (2021), thereby enhancing the explanatory power of the derived features. By generating suitable features from event logs, we can create informative inputs for machine learning algorithms, enhancing their ability to model and predict complex process behaviors.\n# .5 Fairness Concepts in Process Mi\nFairness in process mining is a central theme of increasing importance Qafari and van der Aalst (2019). In essence, it aims to ensure that the algorithms and models developed based on event data do not unfairly favor or disadvantage certain instances or groups. This is crucial because process mining techniques are often used to inform operational decisions and business strategies that can significantly impact people and resources. For example, they may be used to optimize workflows, allocate resources, or make predictive decisions. If these models or algorithms are biased or unfair, the resulting decisions can be unjust, leading to significant negative consequences. Therefore, maintaining fairness in process mining is not just an ethical imperative, but also a necessary condition for building trust and ensuring the overall sustainability of business processes. Fairness in process mining can be thought of as a continuum that spans from the individual to the group level, incorporating notions of procedural and counterfactual fairness along the way Pohl et al (2022).\nSpringer Nature 2021 LATEX template\nAt the individual level, fairness centers on ensuring that every case in a process is treated equitably. This could involve examining each instance independently to determine whether the same rules and decisions were applied consistently. For example, in a loan application process, individual fairness would imply that each application is evaluated based on the same set of criteria and not influenced by irrelevant attributes such as the applicant\u2019s race or gender. Progressing towards the group level, fairness becomes about ensuring equitable outcomes across different groups within a process. This could mean analyzing whether certain groups are systematically disadvantaged compared to others. For example, in an employee onboarding process, group fairness would imply that new hires from all backgrounds receive equal access to resources and opportunities for training and development. The notion of procedural fairness emphasizes the importance of the process itself being fair, beyond merely the outcomes it produces. Procedural fairness is concerned with the transparency, consistency, and unbiased nature of the processes. For instance, in a complaint handling process, procedural fairness would mean that all complaints are handled following the same, predefined steps and procedures without any bias. Counterfactual fairness Qafari and van der Aalst (2021) introduces a more complex, hypothetical element into the fairness equation. It considers whether the outcome of a process would have been the same had an irrelevant attribute been different. For example, in an employee promotion process, counterfactual fairness would mean that an employee\u2019s promotion decision would have been the same, irrespective of their gender. One of the key challenges in the development of fairness-oriented techniques in process mining is the scarcity of publicly available event logs that feature fairness concerns. Such data sets are crucial for testing and refining techniques. They not only provide a ground truth against which the effectiveness of methods can be evaluated, but also highlight the real-world complexities and nuances that such techniques need to handle. Currently, the only public collection of simulated event logs that are designed to exhibit fairness issues is provided in Pohl and Berti (2023). These logs and their characteristics are described in detail in the paper Pohl et al (2023). This availability gap underlines the need for greater openness and collaboration in the field, and the importance of creating and sharing more such resources, so as to advance the development and validation of fairness-oriented process mining techniques.\n# 2 Approach\nIn the forthcoming section, we unpack our unique approach to leveraging large language models for process mining tasks. Initially, we focus on developing textual abstractions for process mining artifacts Section 2.1, a vital foundation for enabling the language model\u2019s comprehension of processrelated entities. This step includes particular emphasis on process models\nSpringer Nature 2021 LATEX template\nand event logs Section 2.1.1 Section 2.1.2. Subsequently, we delineate various prompting strategies Section 2.2 to guide the model in problem resolution. These strategies span from direct answering to multi-prompt answering, and even generation of database queries Section 2.2.1 Section 2.2.2 Section 2.2.3. Through an effective synergy between these components, we navigate the nuanced landscape of process mining with large language models, ensuring efficient analysis and meaningful insights.\n# 2.1 Textual Abstractions of Process Mining Artifacts\nIn order to leverage the capabilities of Large Language Models (LLMs) for process mining, we need to convert process mining artifacts into a format that these models can understand and interpret effectively. The initial and crucial step in this transformation process is the textual encoding of these artifacts. The goal of this encoding is to convey the essential information embedded in the artifacts while maintaining the constraints imposed by the context window of the LLM.\n<div style=\"text-align: center;\">Listing 1: Textual abstraction of the directly-follows graph presented in Figure 1 (obtained using the method pm4py.llm.abstract dfg).</div>\nIf I have a process with flow:\nActivity A \u2212> Activity B ( frequency = 2 performance = 1350.0 )\nActivity C \u2212> Activity D ( frequency = 1 performance = 900.0 )\nActivity B \u2212> Activity C ( frequency = 1 performance = 900.0 )\nActivity A \u2212> Activity C ( frequency = 1 performance = 1800.0 )\nIn our research, we have developed distinct textual abstractions for different types of event logs and process models. On the one hand, we address traditional and object-centric event logs, which provide a chronological record of events related to a particular process. On the other hand, we also consider procedural and declarative process models. Procedural models focus on the sequence of activities necessary to accomplish a process, while declarative models describe the rules and constraints that govern the execution of the process. Our textual abstractions offer a balanced summary of these artifacts that preserve their critical properties while remaining accessible to LLMs.\n# 2.1.1 Textual Abstractions of Process Models\nOne of the fundamental process mining artifacts is the directly-follows graph (DFG) introduced in Section 1.2. To translate this information into a form digestible by Large Language Models (LLMs), we need to convert the DFG into a textual abstraction. This conversion, as exemplified in Listing 1, is a careful process that aims to maintain the core information contained in the graph while conforming to the text-based input restrictions of the LLMs. Each arc in\nSpringer Nature 2021 LATEX template\nthe DFG is translated into a textual sentence that describes the transition from one activity to another, along with its frequency and performance. Frequency signifies how often a particular sequence of activities occurs in the process, while performance captures the average time it takes to move from one activity to the next. The arcs are listed in order of decreasing frequency to prioritize the most common transitions in the process. If the total length of the textual abstraction threatens to exceed the context window limitation of the LLM, some of the less frequent arcs may be omitted. This ensures that the model is fed with the most representative information about the process within the imposed text length constraint, thus enabling effective query answering and process analysis. In addition to the standard textual encoding of the DFG, it is worth noting that advanced large language models exhibit significant flexibility in understanding various text representations of process flows. They are capable of interpreting and reasoning about different encodings for the same underlying information. For instance, the transition from \u201dActivity A\u201d to \u201dActivity B\u201d could be expressed in several ways, such as \u201dActivity A is followed by Activity B\u201d, \u201dActivity A \u2192Activity B\u201d, or even as a pair \u201d(Activity A, Activity B)\u201d. Despite the stylistic differences, the LLMs can recognize these expressions as conveying the same transition in the process. This flexibility makes LLMs robust and adaptable tools for analyzing process mining artifacts represented in different textual formats.\nListing 2: Textual abstraction of the Petri net presented in Figure 2 (obtained using the method pm4py.llm.abstract petri net).\nIf I have a Petri net:\nplaces: [ p 3, p 4, p 5, sink, source ]\ntransitions: [ (0309dbf9\u221252f9\u221242a5\u2212a73a\u221279da3a2ea20a, \u2019Activity B\u2019), (37ede306\n\u22124d81\u2212499a\u22128dbe\u2212b23b5a31372a, \u2019Activity C\u2019), (5f5a9dd2\u2212b140\u22124e88\u2212\nac73\u2212b05c3ab17b63, \u2019Activity A\u2019), (eba11fc0\u2212143b\u22124765\u2212adb0\u22122\nb736b348f88, \u2019Activity D\u2019), (skip 1, None), (skip 2, None), (skip 3, None) ]\narcs: [ (0309dbf9\u221252f9\u221242a5\u2212a73a\u221279da3a2ea20a, \u2019Activity B\u2019)\u2212>p 4, (37ede306\n\u22124d81\u2212499a\u22128dbe\u2212b23b5a31372a, \u2019Activity C\u2019)\u2212>p 5, (5f5a9dd2\u2212b140\u22124\ne88\u2212ac73\u2212b05c3ab17b63, \u2019Activity A\u2019)\u2212>p 3, (eba11fc0\u2212143b\u22124765\u2212adb0\n\u22122b736b348f88, \u2019Activity D\u2019)\u2212>sink, (skip 1, None)\u2212>p 4, (skip 2, None)\n\u2212>sink, (skip 3, None)\u2212>sink, p 3\u2212>(0309dbf9\u221252f9\u221242a5\u2212a73a\u221279\nda3a2ea20a, \u2019Activity B\u2019), p 3\u2212>(skip 1, None), p 4\u2212>(37ede306\u22124d81\u2212499\na\u22128dbe\u2212b23b5a31372a, \u2019Activity C\u2019), p 4\u2212>(skip 2, None), p 5\u2212>(eba11fc0\n\u2212143b\u22124765\u2212adb0\u22122b736b348f88, \u2019Activity D\u2019), p 5\u2212>(skip 3, None),\nsource\u2212>(5f5a9dd2\u2212b140\u22124e88\u2212ac73\u2212b05c3ab17b63, \u2019Activity A\u2019) ]\ninitial marking: [\u2019source:1\u2019]\nfinal marking: [\u2019sink:1\u2019]\nSpringer Nature 2021 LATEX template\na specific label, while arcs serve as the connectors between places and transitions and are depicted accurately. This approach enables a clear and precise representation of the Petri net\u2019s structure, making it easy for large language models to comprehend and reason about. As with directly-follows graphs, it is important to note that there is not a single \u201dcorrect\u201d way to textually encode Petri nets. Advanced large language models are capable of understanding a wide range of textual encodings, provided the chosen method clearly communicates the structure and components of the Petri net. Different encodings might express the same Petri net, using various terminologies or formatting conventions to depict places, transitions, and arcs. As long as the encoding is clear and unambiguous, the language model will be able to understand and analyze the underlying Petri net effectively. In addition, it is crucial to note that, unlike with directly-follows graphs, we cannot employ the same approach to addressing the context window limitation when dealing with Petri nets. The nature of Petri nets makes it necessary to abstract the entire model textually. The interconnected structure of places, transitions, and arcs in a Petri net forms a unified whole that cannot be easily segmented or reduced without potentially losing critical information or misrepresenting the process logic. Hence, the complete Petri net, regardless of its size, needs to be translated into text for the large language model to process effectively. This characteristic emphasizes the importance of developing efficient, concise and clear abstraction methods to avoid exceeding the context window of the large language model.\n14\nWhen it comes to DECLARE process models (Section 1.3), a declarative process modeling notation, our approach to abstraction changes. These models are expressed as a set of constraints, each representing specific interdependencies and relationships between process activities. Given the non-trivial nature of these constraints, it becomes crucial to adequately explain them to the large language model. A textual representation of a DECLARE model, as shown in Listing 3, translates these constraints into a readable format. However, unlike with procedural models, the form in which the constraints and explanations are presented is not rigid. Advanced large language models are capable of interpreting the constraints, regardless of how they\u2019re expressed, as long as the explanation remains clear and coherent. However, one of the significant challenges when dealing with DECLARE models is the context window limitation. Real-life processes often involve hundreds of constraints, making their textual representations considerably long. To tackle this issue, one possible preprocessing strategy could be to rename the activities using alphabet letters or abbreviations. This approach considerably reduces the length of the textual encoding, ensuring it fits within the context window of the large language model, without losing the integrity of the model\u2019s information.\nListing\n4:\nTextual\nabstraction\nof\ntemporal\nprofile\nprocess\nmodel\npresented\nin\nTable\n3\n(obtained\nusing\nthe\nmethod\npm4py.llm.abstract temporal profile).\nThe temporal profile is a model describing the average and the standard deviation\nof the times between couples of activities eventually (not only directly)\nfollowing each other in at least a process execution (so in a trace <A,B,C,D>\nthe couples (A,B) (A,C) (A,D) (B,C) (B,D) (C,D) shall be considered). Given\na positive value ZETA, a deviation occurs in a process execution when the\ntime between two activities is lower than AVG \u2212ZETA \u2217STDEV or greater\nthan AVG + ZETA \u2217STDEV. For this process, the model is:\nActivity A \u2212> Activity B : AVG: 1350.00 s STD: 636.40 s\nActivity A \u2212> Activity C : AVG: 1800.00 s STD: 0.00 s\nActivity B \u2212> Activity C : AVG: 900.00 s STD: 0.00 s\nActivity A \u2212> Activity D : AVG: 2700.00 s STD: 0.00 s\nActivity C \u2212> Activity D : AVG: 900.00 s STD: 0.00 s\nIn addition to the abstractions we\u2019ve discussed, there are also temporal profile models to consider. A temporal profile model, another type of declarative process model (Section 1.3), is primarily concerned with the timing aspects of a process. The abstraction for such a model, as shown in Listing 4, encapsulates the temporal dependencies between various pairs of activities. Specifically, for each pair of activities that can potentially follow one another in the process, the abstraction provides the average and standard deviation of the time elapsed between them. Just as with other models, advanced large language models are flexible in terms of the representation used for these constraints. As long as the pairs of activities and their corresponding time intervals are clearly stated, the large language model can interpret them, regardless of how they are presented in the abstraction. This versatility makes advanced large language models a potent tool for generating meaningful insights from abstracted temporal profile models.\n<div style=\"text-align: center;\">Listing 5: Textual abstraction of the OC-DFG presented in Figure 4 (obtain using the method pm4py.llm.abstract ocel ocdfg).</div>\nusing the method pm4py.llm.abstract ocel ocdfg).\nIf I have an object\u2212centric event log with the following directly follows graph (\nsplit between the different object types):\nObject type: Order\n\u201dActivity A\u201d \u2212> \u201dActivity B\u201d (frequency (number of events) = 3, frequency (\nnumber of objects) = 3, duration = 1200.00)\n\u201dActivity C\u201d \u2212> \u201dActivity A\u201d (frequency (number of events) = 1, frequency (\nnumber of objects) = 1, duration = 1800.00)\n\u201dActivity A\u201d \u2212> \u201dActivity C\u201d (frequency (number of events) = 1, frequency (\nnumber of objects) = 1, duration = 1800.00)\n\u201dActivity C\u201d \u2212> \u201dActivity D\u201d (frequency (number of events) = 1, frequency (\nnumber of objects) = 1, duration = 900.00)\nObject type: Invoices\n\u201dActivity A\u201d \u2212> \u201dActivity B\u201d (frequency (number of events) = 3, frequency (\nnumber of objects) = 3, duration = 1200.00)\n\u201dActivity C\u201d \u2212> \u201dActivity A\u201d (frequency (number of events) = 1, frequency (\nnumber of objects) = 1, duration = 1800.00)\n\u201dActivity A\u201d \u2212> \u201dActivity C\u201d (frequency (number of events) = 1, frequency (\nnumber of objects) = 1, duration = 1800.00)\n\u201dActivity C\u201d \u2212> \u201dActivity D\u201d (frequency (number of events) = 1, frequency (\nnumber of objects) = 1, duration = 900.00)\nObject type: OrderItems\n\u201dActivity A\u201d \u2212> \u201dActivity B\u201d (frequency (number of events) = 2, frequency (\nnumber of objects) = 3, duration = 900.00)\n\u201dActivity A\u201d \u2212> \u201dActivity D\u201d (frequency (number of events) = 1, frequency (\nnumber of objects) = 1, duration = 2700.00)\n\u201dActivity C\u201d \u2212> \u201dActivity A\u201d (frequency (number of events) = 1, frequency (\nnumber of objects) = 1, duration = 1800.00)\n\u201dActivity A\u201d \u2212> \u201dActivity C\u201d (frequency (number of events) = 1, frequency (\nnumber of objects) = 1, duration = 1800.00)\nWhen it comes to object-centric event logs, we often utilize object-centric directly-follows graphs (Section 1.2) as part of the abstraction process. An example of such an abstraction is depicted in Listing 5. In this case, each type of object within the log has a corresponding set of arcs in its directly-follows graph. These arcs illustrate the flow and sequence of activities involving that particular object type. However, similar to traditional directly-follows graphs, we must be mindful of the context window limitation. As a result, arcs with fewer occurrences may be omitted from the textual abstraction to maintain a manageable size. Regardless of this omission, the critical insight here is the pattern of activities and interactions concerning each object type. Like the previously discussed abstractions, the way in which these object-specific arcs are represented in the abstraction does not significantly affect how advanced large language models interpret them. As long as the arcs are clearly stated, the large language model can efficiently process and generate useful insights from them. This flexibility underlines the applicability and utility of advanced\nlarge language models in understanding and analyzing complex object-centric artifacts.\n# 1.2 Textual Abstractions of Event Log\nProcess variants provide a crucial view of a traditional event log by giving us a glimpse into the different paths or sequences of activities that cases may follow in a process. They can be textually abstracted and presented to a Large Language Model (LLM), as illustrated in Listing 6. Each variant is represented along with its frequency and average throughput time. This structure enables the LLM to understand both the variant\u2019s prevalence and the time typically required for its completion. Given the frequency-based ordering of the variants, it is possible to handle limitations imposed by the context window. If the number of process variants is large and exceeds the context window size, less frequent variants can be omitted from the textual abstraction. Despite this omission, the abstraction would still retain the most common patterns, which likely capture a substantial portion of the overall process behavior. The ability of advanced LLMs to understand different textual representations is particularly beneficial here. The representation of process variants does not have to adhere to a strict syntax. It could be a sequence of activities separated by symbols or a plain text description.\n<div style=\"text-align: center;\">Listing 6: Textual abstraction of the process variants in Table 1 (obtain using the method pm4py.llm.abstract variants).</div>\nusing the method pm4py.llm.abstract variants).\nIf I have a process with the following process variants:\nActivity A \u2212> Activity C \u2212> Activity D ( frequency = 1 performance = 2700.0\n)\nActivity A \u2212> Activity B \u2212> Activity C ( frequency = 1 performance = 1800.0\n)\nActivity A \u2212> Activity B ( frequency = 1 performance = 1800.0 )\nWhen dealing with traditional event logs (Section 1.1), which are essentially organized collections of events grouped into cases, we can utilize textual abstractions to distill the key features of a specific case, as shown in Listing 7. In this type of abstraction, we highlight the key attributes at the case level and provide a detailed list of all events associated with that case. Each event is principally characterized by an activity and a timestamp, but other event-level attributes can be included as necessary, providing a more detailed snapshot of each event. The crucial aspect of this textual abstraction is that it presents all necessary information to evaluate the progression of a specific case. Consequently, it enables the large language model to answer questions that pertain to a specific case in question, such as identifying any potential issues or irregularities within that case. This makes case-level textual abstraction a powerful tool for detailed, case-specific analysis in process mining.\n17\nListing 7: Textual abstraction of Case 1 in Table 1 (obtained using the metho pm4py.llm.abstract case). If I have a case with the following (case) attributes: concept:name = Case1 the case contains the following events (the activity of the event is reported first): Activity A ( timestamp = 2023\u221207\u221213 09:00:00+00:00 ; @@case index = 0 ; @@index = 0 ; ) Activity B ( timestamp = 2023\u221207\u221213 09:15:00+00:00 ; @@case index = 0 ; @@index = 1 ; ) Activity C ( timestamp = 2023\u221207\u221213 09:30:00+00:00 ; @@case index = 0 ; @@index = 2 ; )\nA traditional event log can also be translated into a matrix of numerical features (Section 1.4), a format often used in machine learning. Each row in this matrix represents a case from the event log, and each column, or feature, provides some quantitative characteristic of that case. The textual abstraction of this type of matrix can be illustrated as in Listing 8. For every feature in the matrix, we provide its support, i.e., the number of cases where this feature is present or significant. Additionally, we supply quantiles of the feature values, giving a more detailed understanding of the distribution of these values. These aspects combined allow us to understand the relevance and descriptive power of each feature. Given the potential breadth of this kind of matrix, it is essential to consider the context window limitation when producing a textual abstraction. As a solution, one could decide to omit features that have a low support. Such a choice would ensure that the most impactful features, those that occur more frequently, are represented in the abstraction, providing a succinct yet representative snapshot of the event log\u2019s numerical features. This strategy makes this type of textual abstraction extremely valuable for a broad understanding of the event log\u2019s characteristics from a numerical perspective.\nListing\n8:\nTextual\nabstraction\nof\nfeatures\nextracted\nfrom\nthe\nevent\nlog\npresented\nin\nTable\n3\n(obtained\nusing\nthe\nmethod\npm4py.llm.abstract log features).\nGiven the following features:\nValue \u2019Activity A\u2019 for Event Attribute \u2019concept:name\u2019: number of non\u2212zero values:\n3 ; quantiles of the non\u2212zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}\nValue \u2019Activity C\u2019 for Event Attribute \u2019concept:name\u2019: number of non\u2212zero values:\n2 ; quantiles of the non\u2212zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}\nValue \u2019Activity B\u2019 for Event Attribute \u2019concept:name\u2019: number of non\u2212zero values:\n2 ; quantiles of the non\u2212zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}\nValue \u2019Activity D\u2019 for Event Attribute \u2019concept:name\u2019: number of non\u2212zero values:\n1 ; quantiles of the non\u2212zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}\nSuccession \u2019Activity A\u2019 \u2212> \u2019Activity B\u2019 for the Values of the Attribute \u2019concept:\nname\u2019: number of non\u2212zero values: 2 ; quantiles of the non\u2212zero: {0.0: 1.0,\n0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}\nSuccession \u2019Activity C\u2019 \u2212> \u2019Activity D\u2019 for the Values of the Attribute \u2019concept:\nname\u2019: number of non\u2212zero values: 1 ; quantiles of the non\u2212zero: {0.0: 1.0,\n0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}\nSuccession \u2019Activity B\u2019 \u2212> \u2019Activity C\u2019 for the Values of the Attribute \u2019concept:\nname\u2019: number of non\u2212zero values: 1 ; quantiles of the non\u2212zero: {0.0: 1.0,\n0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}\nSuccession \u2019Activity A\u2019 \u2212> \u2019Activity C\u2019 for the Values of the Attribute \u2019concept:\nname\u2019: number of non\u2212zero values: 1 ; quantiles of the non\u2212zero: {0.0: 1.0,\n0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}\nSimilar to the abstraction of traditional event logs, object-centric event logs can also be textually abstracted (Section 1.1), as exemplified in Listing 9. In an object-centric event log, each event is characterized not only by an activity and a timestamp, as in traditional event logs, but also by a set of related objects. These objects extend the dimensionality of the event log, providing more nuanced and contextually rich information about each event. The textual abstraction of an object-centric event log essentially reflects this richer structure. Each event is paired with its associated objects, hence providing a thorough picture of the specific process instance that the event belongs to. However, due to the typically large size of object-centric event logs, a direct abstraction of the entire log could easily exceed the context window limitation of the large language model. To address this issue, it is advisable to execute the textual abstraction against a specific process execution (as in Listing 9), which can be a connected component of related objects, rather than the entire log. This approach allows for localized question answering on a given process execution, ensuring that the resulting prompts are meaningful and contextually appropriate while staying within the context window limitation. The ability to abstract and question specific process executions provides an extra level of flexibility when investigating process behaviours. It can help to unveil patterns or anomalies that are localized to specific instances of the process, contributing to a more granular understanding of the process dynamics.\nListing 9: Textual abstraction of the connected component in Table 2 containing {Order1, Item1, Item2, Invoice1} (obtained using the method pm4py.llm.abstract ocel).\nAs with traditional event logs, object-centric event logs can also be transformed into a matrix of numerical features (Section 1.4), each representing a unique aspect of the process. These features often delve deeper, exploring the lifecycles of individual objects or interactions between them within the event log\u2019s graph structure. The textual abstraction of such features is presented in Listing 10, with each feature detailed by its support and quantiles of its values, mirroring the approach used for traditional logs. However, due to the increased complexity and the larger number of features that object-centric event logs can offer, dealing with the context window limitation of Large Language Models can be more challenging. The primary strategy here is to focus on the most relevant features - those with the highest support. This prioritization helps to manage the amount of information fed into the LLM, ensuring that the most significant features are included, while those with less support can be omitted to fit within the context window. This approach allows for an effective trade-of between information detail and the size constraints imposed by the LLMs.\nSpringer Nature 2021 LATEX template\n# 2.2 Prompting Strategies\nThis section introduces three prompting strategies for utilizing large language models (LLMs) in the field of process mining: \u201ddirect answering,\u201d \u201dmultiprompt answering,\u201d and \u201dgeneration of database queries.\u201d These strategies vary in complexity and are chosen based on the problem at hand. They make use of textual abstractions and questions, and leverage the capabilities of LLMs for hypothesis generation, result interpretation, and even SQL query formulation, providing an interactive and adaptive approach to process mining.\n# 2.2.1 Direct Answering\nThe \u201ddirect answering\u201d strategy is the most straightforward prompting approach used with large language models in the context of process mining. This strategy involves formulating a prompt which combines a textual abstraction of a process mining artifact with a direct question related to it. Example questions might be \u201dWhat are the bottlenecks of the process?\u201d (starting from the process variants abstraction) or \u201dWhat are the main anomalies?\u201d (starting from the directly-follows graph abstraction). It is important to note that, in this strategy, the output structure of the response is not predetermined. Rather, the large language model will generate a response in the form of free text. Consequently, this means that the user, while freed from the task of analyzing the event log themselves, must have sufficient background knowledge to interpret the answer correctly. Another key factor for success with the direct answering strategy is the formulation of the question itself. It needs to be concise, clear, and well-structured to enable the large language model to provide a meaningful and relevant response. This strategy, therefore, represents a delicate balance between user expertise, question formulation, and the interpretability of the model\u2019s responses.\n# 2.2.2 Multi-Prompt Answering\nIn certain scenarios, more complex process mining tasks require a series of distinct prompts, each involving different abstractions and questions. This approach, known as multi-prompt answering, leverages the iterative nature of inquiry, where the answer to one question informs the formulation of the next. In this way, the user guides the large language model (LLM) through a sequence of steps to ultimately resolve the overarching process mining problem. A classic example where the multi-prompt answering strategy is useful is in assessing fairness in process mining. Initially, a user might use a feature table abstraction to identify attributes that could potentially lead to discrimination. Once the LLM provides this information, the user formulates a subsequent prompt to investigate if the process execution differs for cases belonging to the protected and non-protected groups. The second prompt is contingent on the results from the first one, as it is necessary to distinguish between cases before delving deeper into potential discrepancies in process execution.\nSpringer Nature 2021 LATEX template\nIn another example, the user might want to analyze process conformance. An initial prompt could be used to compare the process model to a log abstraction to identify non-conforming activities. Subsequent prompts could then be designed to examine why these non-conformities are occurring, perhaps by examining specific cases or focusing on particular process variants. Multi-prompt answering is a powerful strategy, as it allows users to conduct a step-by-step, deep-dive analysis. However, it requires careful formulation of prompts and the ability to interpret and act on the LLM responses to guide the inquiry effectively. Therefore, it demands more user engagement than the direct answering strategy.\n# 2.2.3 Generation of Database Queries\nThe third strategy is \u201dgeneration of database queries\u201d, which is particularly useful for complex process mining problems that are too intricate to be directly abstracted or solved by the large language model (LLM). Questions like \u201dWhat is the average throughput time when activity B occurs more than one day after the start of the case?\u201d or \u201dMeasure the correlation between throughput time and rework in the case\u201d fall into this category. In these situations, the LLM can be leveraged to generate SQL queries based on the user\u2019s initial natural language inquiry. These generated queries can then be executed against the event log, enabling complex data analysis without the user having to manually construct the intricate SQL statements. Yet, this strategy\u2019s potential goes beyond translating natural language questions into SQL queries. It can also be used to generate hypotheses about the event log, derived from certain abstractions like process variants or log features. For instance, the user can present the LLM with such an abstraction and ask it to formulate an hypothesis about the event log expressed as a SQL query. Once the SQL query (representing the hypothesis) is executed and the results are obtained, the LLM can then be employed again to evaluate if the original hypothesis holds true. Should the initial hypothesis be invalidated, the LLM is capable of formulating alternative hypotheses, which can then be transformed into SQL queries and tested against the data. This iterative method, which encompasses generating hypotheses, testing them, and re-assessing based on the outcomes, allows for a more in-depth exploration and understanding of the underlying processes. This approach significantly expands the scope of possible investigations that can be conducted using the LLM. Nevertheless, while this method can streamline complex query generation and hypothesis testing, it does call for a specific set of skills on the part of the user. While the LLM can assist in generating complex queries and hypotheses, the responsibility of result interpretation and subsequent steps of analysis falls on the user. Thus, a certain degree of analytical acumen and domain knowledge is necessary for this approach to be fully effective.\nSpringer Nature 2021 LATEX template\n24\n# 3 Tool Support\nIn this section, we delve into the tool support available for conducting process mining tasks with large language models. pm4py Berti et al (2019), short for Process Mining for Python, is a versatile and comprehensive library that supports the entire spectrum of process mining applications, ranging from data loading and pre-processing, to process discovery, conformance checking, and enhancement. This suite of functionality enables practitioners and researchers to extract valuable insights from event logs and use them for optimizing and monitoring real-world processes. pm4py is developed from the Fraunhofer FIT process mining group and is fully documented at the address https://pm4py. fit.fraunhofer.de.\nMethod\nAbstraction Provided\npm4py.llm.abstract dfg()\nProvides the DFG abstraction of a tradi-\ntional event log\npm4py.llm.abstract variants()\nProvides the variants abstraction of a tra-\nditional event log\npm4py.llm.abstract log attributes()\nProvides\nthe\nabstraction\nof\nthe\nattributes/columns of the event log\npm4py.llm.abstract log features()\nProvides the abstraction of the machine\nlearning features obtained from an event\nlog\npm4py.llm.abstract case()\nProvides the abstraction of a case (collec-\ntion of events)\npm4py.llm.abstract ocel()\nProvides the abstraction of an object-\ncentric\nevent\nlog\n(list\nof\nevents\nand\nobjects)\npm4py.llm.abstract ocel ocdfg()\nProvides the abstraction of an object-\ncentric event log (OC-DFG)\npm4py.llm.abstract ocel features()\nProvides the abstraction of an object-\ncentric event log (features for ML)\npm4py.llm.abstract event stream()\nProvides an abstraction of the (last)\nevents of the stream related to a tradi-\ntional event log\npm4py.llm.abstract petri net()\nProvides the abstraction of a Petri net\npm4py.llm.abstract log skeleton()\nProvides the abstraction of a log skeleton\nmodel\nA significant development in version 2.7.5 of pm4py is the integration with Large Language Models (LLM), bolstering the tool\u2019s capacity for analysis and understanding of process data. This integration enables pm4py to offer a range of abstractions for process data and models, as detailed in Table 6. More features will be introduced in pm4py 2.7.6. Each method in this module provides a different view or representation of the process data, facilitating diverse avenues for exploration and analysis. In addition to these abstractions, pm4py 2.7.5 allows for direct interaction with LLM through specific methods such as pm4py.llm.openai query\nMethod\nFunctionality\npm4py.llm.openai query()\nExecutes\na\nprompt\nagainst\nOpenAI,\nreturning the response as string\nTable 7: Method for interacting directly with the LLM APIs available in\n(Table 7). This function enables users to directly execute prompts agains OpenAI\u2019s language models, obtaining textual responses that can be furthe analyzed or used in subsequent processes.\n<div style=\"text-align: center;\">Listing 11: Example usage of the pm4py\u2019s LLM integration on traditional process mining objects</div>\nprocess mining objects\nimport pm4py\nlog = pm4py.read xes(\u201dtests/input data/roadtraffic100traces.xes\u201d)\nq1 = \u201d\u201d\u201d\\n What are the root causes of the performance issues in the process?\nPlease provide only process and data specific considerations,\nno general considerations.\u201d\u201d\u201d\nprint(pm4py.llm.abstract variants(log) + q1)\nnet, im, fm = pm4py.discover petri net inductive(log)\nq2 = \u201d\u201d\u201d\\n Can you provide suggestions to improve the process model\nbased on your domain knowledge?\u201d\u201d\u201d\nprint(pm4py.llm.abstract petri net(net, im, fm) + q2)\nA sample usage of pm4py\u2019s LLM integration is shown in Listing 11, where the abstract variants method is used to retrieve the variants of an event log. Subsequently, the Petri net discovered from the event log is abstracted using abstract petri net, and both of these abstractions are used to construct prompts for querying an LLM.\nA distinct advantage of the pm4py tool is its support for object-centric process mining, a relatively recent advancement in the process mining field\nthat provides a more detailed view of complex processes. Object-centric process mining expands the traditional case-centric perspective, allowing for the consideration of multiple interacting objects in a process, thus enabling a more nuanced understanding of process dynamics. The LLM integration in pm4py embraces this object-centric perspective, as demonstrated in the example given in Listing 12. The script loads an objectcentric event log (OCEL) and then uses two specific abstraction methods tailored for this type of data. The method abstract ocel ocdfg is used to generate an abstraction of the Object-Centric Directly Follows Graph (OCDFG), a representation that captures the relationships between the different activities and objects in the log. This abstraction is then used to create a query for the LLM, asking for unusual relationships in the process graph. The method abstract ocel features is used to generate an abstraction of the features of a specific type of object (in this example, \u201dorder\u201d) in the OCEL. This abstraction is then used to create another query for the LLM, asking for odd feature values. These examples showcase the potential of using LLM in conjunction with object-centric process mining. The intricate process insights offered by objectcentric logs, coupled with the rich interpretative capabilities of large language models, provide practitioners and researchers with powerful tools to uncover hidden process knowledge and drive informed process decisions.\n# 4 Assessment\nIn this section, we examine the ability of large language models, specifically Bard and GPT-4, to understand, generate, and answer queries related to process mining tasks. The considered models and their unique characteristics are discussed in Section 4.1. We also outline the specific event logs leveraged in this assessment in Section 4.2. We delve into the models\u2019 capabilities in the realm of direct answering to process mining queries in Section 4.3, where we assess their ability to respond directly to various types of prompts. This exploration is then extended in Section 4.4, where we investigate the models\u2019 capacity for providing answers across multiple prompts, encapsulating more complex interactions. Finally, we evaluate the models\u2019 aptitude in generating database queries from user prompts in Section 4.5. This involves assessing the ability of these models to not just understand a prompt, but to translate that understanding into SQL queries, a crucial aspect in the context of data analysis. By comprehensively assessing these aspects, we aim to gauge the practicality and potential of these large language models in process mining tasks, seeking to illuminate areas of strength as well as identify opportunities for further research and improvement.\nEvent Log\nNumber of Events\nNumber of Cases\nNumber of Variants\nNumber of Activities\nRoad Traffic\n561470\n150370\n231\n11\nBPI Challenge 2020\n56437\n10500\n99\n17\nSepsis\n15214\n1050\n846\n16\nConformance Checking Challenge 2019\n1394\n20\n20\n29\n# 4.1 Considered Large Language Models\nThis section provides an examination of the two advanced LLMs currently leveraged in the field of process mining: GPT-4, developed by OpenAI, and Google Bard, brought forward by Google AI. Both models are the product of extensive training on vast datasets comprised of a diverse range of text and code, and exhibit remarkable capabilities in a variety of tasks. GPT-4 is a large language model (LLM) developed by OpenAI. It is a powerful tool that can be used for a variety of tasks, including text generation, translation, and question answering. GPT-4 is trained on a massive dataset of text and code, which allows it to generate text that is both coherent and grammatically correct. Google Bard is a large language model developed by Google AI. It is similar to GPT-4 in terms of its capabilities, but it is trained on a different dataset of text and code. This difference in training data means that Google Bard has different strengths and weaknesses than GPT-4.\n# 4.2 Considered Event Logs\nIn this study, we focus on several real-world process event logs to explore and evaluate the capabilities of large language models in the domain of process mining. These event logs encapsulate diverse fields, such as road traffic fine management, hospital case management, and business travel expenses, offering a breadth of scenarios to test the adaptability and accuracy of the language model. The event logs employed in this research are described in detail below.\nEvent Log\nNumber of Events\nNumber of Cases\nNumber of Variants\nNumber of Activities\nhiring log high-xes.gz\n63869\n10000\n386\n12\nhiring log low-xes.gz\n72094\n10000\n296\n12\nhiring log medium-xes.gz\n69054\n10000\n382\n12\nhospital log high-xes.gz\n69528\n10000\n80\n10\nhospital log low-xes.gz\n70037\n10000\n106\n10\nhospital log medium-xes.gz\n70124\n10000\n77\n10\nlending log high-xes.gz\n58822\n10000\n41\n12\nlending log low-xes.gz\n60746\n10000\n31\n12\nlending log medium-xes.gz\n58668\n10000\n33\n12\nrenting log high-xes.gz\n89972\n10000\n496\n16\nrenting log low-xes.gz\n96440\n10000\n508\n16\nrenting log medium-xes.gz\n105555\n10000\n610\n16\nmain\nAge\nCitizenship\nGerman Proficiency\nGender\nReligion\nYears of Education\nUnderlying Condition\nPrivate Insuran\nng\nX\nX\nX\nX\nX\nX\npital\nX\nX\nX\nX\nX\nX\nding\nX\nX\nX\nX\nX\nting\nX\nX\nX\nX\nX\nX\n\u2022 Road Traffic Fine Management Process2: real-life event log of an information system managing road traffic fines in an Italian municipality. \u2022 BPI Challenge 2020 (Domestic Declarations)3: the travel expense process consists of an employee\u2019s submission, approval by the travel administration, then by the budget owner and supervisor, and possibly a director. The process concludes with a trip or a payment request. There are two types of trips: domestic and international. Domestic trips do not need prior approval, allowing employees to ask for cost reimbursement afterward. \u2022 Sepsis Cases Event Log4: the dataset is an anonymized real-life event log of sepsis cases from a hospital, where sepsis is a life-threatening condition often resulting from an infection. Each case represents a patient\u2019s journey through the hospital, with events captured by the hospital\u2019s Enterprise Resource Planning (ERP) system. The events cover a range of different activities, and a multitude of data attributes are recorded such as the group responsible for the activity, test results, and checklist information. While event timestamps have been randomized, the time interval between events within a case remains unchanged. \u2022 Conformance Checking Challenge 2019 5: This past version of the conformance checking challenge was centered around a process involved in medical training. Specifically, it revolved around how medical students were taught to place a central venous catheter (CVC) using ultrasound guidance. The CVC procedure involves inserting a tube into a large vein, a process critical for administering fluids or medicines to patients, among other applications. For assessment of the multi-prompt answering strategy, we also use the vent logs provided in Pohl and Berti (2023) and described in Pohl et al (2023), ncluding: \u2022 Hiring event logs: these logs chronicle a complex recruitment process with various stages of evaluation and decision-making. The applicant\u2019s journey can be as simple as a straightforward rejection or as elaborate as multi-step screening culminating in a job offer, contingent on a host of influencing factors. \u2022 Hospital event logs: this dataset portrays a patient\u2019s journey through a hospital system, starting from the initial check-in at the Emergency Room or Family Department. It progresses through phases of medical\nexamination, diagnosis, and treatment. It\u2019s worth noting that unsuccessful treatments often necessitate repeat examinations and interventions, illustrating the cyclical nature of healthcare delivery. \u2022 Lending event logs: these logs detail a loan application process starting from the scheduling of an initial appointment. It traverses several steps including validation of provided information and underwriting, leading to either loan approval or denial. Further requirements, such as the involvement of a co-signer or an assessment of collateral, may be needed. Some cases may experience direct appointment refusal, highlighting the process\u2019s variability based on applicants\u2019 individual financial circumstances. \u2022 Renting event logs: these logs present a comprehensive rental process that begins with a property viewing request and can end with a contract termination. Between these endpoints, stages such as preliminary vetting, property viewing, decision-making, and possibly, intensive screening occur. If successful, a rental agreement is initiated, with possible outcomes ranging from eviction due to late payments to voluntary contract termination by tenants. It\u2019s important to note that not all applications advance to the property viewing phase. The degree of discrimination exhibited in the logs varies across different domains, offering researchers an opportunity to explore tangible real-world situations. Table 9 furnishes fundamental statistics for the log collection, and Table 10 elaborates on the sensitive attributes. It\u2019s important to note that the selection of attributes pertaining to fairness can be a subject of debate; hence, we welcome discussions to enhance our grasp of fairness within the realm of process mining. Detailed descriptions of each log\u2019s attributes and process have been provided to facilitate the identification of potential instances of discrimination. The event logs provided also include the ground truth concerning the classification of cases - whether they belong to the protected group or not. This inclusion enables a comparison between actual case classifications, which are based on the sensitive attributes, and the actual ground truth. Therefore, the capacity to evaluate the accuracy of case categorization into protected and non-protected groups is significantly enhanced. In our exploration of object-centric process mining using large language models, we utilized several publicly accessible logs available at https://www. ocel-standard.org. Specifically, two simulated object-centric event logs were chosen for this analysis: \u2022 the \u2019Order Management\u2019 event log, which can be accessed directly at https://www.ocel-standard.org/1.0/running-example.jsonocel.zip. This log contains the object types \u2019orders\u2019, \u2019items\u2019, and \u2019packages\u2019, all of which were retained for our assessment. \u2022 the \u2019Recruiting\u2019 event log, available at https://www.ocel-standard.org/1. 0/recruiting.jsonocel.zip. In this log, we focused on the \u2019applications\u2019 and \u2019offers\u2019 object types.\nBy leveraging these specific logs, we aimed to evaluate how effectively large language models like Bard and GPT-4 could handle complex, object-centric process mining tasks.\n# 4.3 Direct Answering\nIn this section, we conduct an evaluation of the ability of advanced large language models, specifically Bard and GPT-4, to respond effectively to process mining queries, given the required abstraction. Our assessments of Bard and GPT-4 with regards to traditional process mining and event logs are documented in Table 11. In the table, each query is assigned a unique code, and the appropriate acceptance criteria for the responses generated by the large language models are stipulated. Furthermore, each query is examined across four distinct event logs, namely Road Traffic, BPI Challenge 2020, Sepsis, and CCC19. Observably, both Bard and GPT-4 demonstrate commendable performance when dealing with descriptive queries such as TQ1, TQ2, TQ3, and TQ5. Furthermore, these large language models exhibit a fair understanding of procedural and declarative models, demonstrating capabilities in tasks like play-out and conformance checking, albeit with certain constraints. In particular, GPT-4 displayed a satisfactory level of competency across the diverse range of queries, albeit with some restrictions pertaining to medical processes. Therefore, it is suggested that further refinement and training might be beneficial in enhancing the capability of these models in the realm of process mining.\n<div style=\"text-align: center;\"></div>\nT-4\nBard\nGPT-4\nBard\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\nX\n\u221a\nX\n\u221a\n\u221a\n\u221a\nX\n\u221a\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\n<div style=\"text-align: center;\"> ev nt</div>\nties on object-centric\non Used\nOrder Managemen\nGPT-4\nBard\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\nSpringer Nature 2021 LATEX template\nIn Table 12, we evaluate the performance of large language models in tackling object-centric process mining tasks. Considering the relatively uncomplicated nature of the event logs used for this assessment, both models - Bard and GPT-4 - demonstrate notable proficiency across all tasks. To provide a comprehensive understanding of their capabilities, we document a selection of responses generated by these models in Listing 13, Listing 14, Listing 15, and Listing 16. These examples serve as illustrative evidence of the substantial potential these models exhibit in responding effectively to a diverse set of queries within the realm of object-centric process mining.\nFrom the process variants and the frequency and performance statistics provided, there are a few key steps that could be causing performance issues in the\nprocess: \u2212Rejection by ADMINISTRATION or SUPERVISOR: Variants where the declaration is rejected by the Administration or Supervisor tend to have a higher performance number, which indicates more time or resources consumed in the process. This could be due to the time taken to review the declaration, the process to handle rejection, or the time spent to correct and resubmit the declaration. \u2212Re\u2212submission by EMPLOYEE: After a declaration is rejected, it is often re\u2212 submitted by the employee. This step will naturally add to the overall time of the process, as the employee will need to correct the issue that caused the rejection and then re\u2212submit the declaration. \u2212Approval by PRE APPROVER, BUDGET OWNER or SUPERVISOR: Variants that include additional approval steps (by a PRE APPROVER, BUDGET OWNER, or SUPERVISOR) also have higher performance numbers, indicating that these steps are adding to the time taken for the process. This could be due to time\u2212consuming review processes or waiting times for approval. \u2212Missing Approval: There are few cases where declarations are rejected due to missing approvals. This adds an additional step and increases the performance of the process. \u2212Multi\u2212step Processes: Variants with multiple steps, such as those that include rejections, resubmissions, and multiple approvals, show much higher performance numbers. This suggests that processes with multiple stages are taking much longer and consuming more resources. Solutions to these issues might include streamlining the approval process, providing better training or resources to reduce the number of rejections, or implementing a more efficient system for handling re\u2212submissions. Identifying and addressing these root causes could lead to significant improvements in the performance of the process.\n# 4.4 Multi-Prompt Answering\nIn our fairness assessment, we employ the multi-prompt strategy, primarily aiming to discern whether GPT-4 and Bard can accurately identify the protected group. For this purpose, SQL queries were generated through the large language model, utilizing prompts that encapsulate the attributes of the log and their corresponding characterization. An exemplar script that generates such prompts is available at https://github.com/pm4py/pm4py-core/ blob/priv/examples/llm/01 1 protected group identification.py. The aforementioned queries for two event logs are delineated in Figure 5. Upon analysis, we observe that GPT-4\u2019s queries display a more encompassing view of the behavior considered as protected. Conversely, Bard\u2019s queries precisely target a specific subset of cases that are presumably exposed to discrimination.\nListing 17: SQL query provided by\nGPT-4 to identify the protected\ngroup in the hiring log high.xes.gz\nevent log.\nSELECT \u2217FROM dataframe\nWHERE \u201dcase:citizen\u201d = \u2019False\u2019\nOR \u201dcase:gender\u201d = \u2019False\u2019\nOR \u201dcase:german speaking\u201d = \u2019False\u2019\nOR \u201dcase:religious\u201d = \u2019False\u2019;\nListing 18: SQL query provided\nby Bard to identify the protected\ngroup in the hiring log high.xes.gz\nevent log.\nSELECT \u2217\nFROM dataframe\nWHERE \u201dcase:citizen\u201d = \u2019False\u2019\nAND \u201dcase:gender\u201d = \u2019False\u2019\nListing 19: SQL query provided by\nGPT-4 to identify the protected\ngroup in the renting log high.xes.gz\nevent log.\nSELECT \u2217FROM dataframe\nWHERE \u201dcase:citizen\u201d = \u2019False\u2019\nOR \u201dcase:gender\u201d = \u2019False\u2019\nOR \u201dcase:german speaking\u201d = \u2019False\u2019\nOR \u201dcase:married\u201d = \u2019False\u2019;\nListing 20: SQL query provided\nby Bard to identify the protected\ngroup in the renting log high.xes.gz\nevent log.\nSELECT \u2217\nFROM dataframe\nWHERE \u201dcase:gender\u201d = \u2019False\u2019\nAND \u201dcase:german speaking\u201d = \u2019\nFalse\u2019\nListing 17: SQL query provided by GPT-4 to identify the protected group in the hiring log high.xes.gz\nSELECT \u2217FROM dataframe\nWHERE \u201dcase:citizen\u201d = \u2019False\u2019\nOR \u201dcase:gender\u201d = \u2019False\u2019\nOR \u201dcase:german speaking\u201d = \u2019False\u2019\nOR \u201dcase:religious\u201d = \u2019False\u2019;\nFig. 5: SQL queries generated by Bard and GPT-4 to identify the protected groups in the considered event logs.\nSubsequently, our focus shifts towards those event logs that signify a substantial degree of discrimination. To assess the classification performance on these logs, we employ an exemplar script accessible at https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/01 2 protected group query.py. The resulting classification quality of GPT-4 and Bard is presented in Table 13 and Table 14. While Bard demonstrates high precision, it is hindered by a low recall and true negative rate, suggesting that it may fail to identify a considerable number of cases where potential discrimination might have taken place. On the other hand, GPT-4, despite exhibiting lower precision, boasts a high recall and true negative rate. This highlights GPT-4\u2019s capability to label a larger number of cases as potentially discriminated, hence reducing the occurrence of false negatives. Having established a set of cases as \u2019protected\u2019 via GPT-4 and Bard, we now shift our focus towards assessing procedural fairness. The objective here is to uncover any process discrepancies that might hint at discrimination. To achieve this, we craft prompts embodying the process variants abstraction of both \u2019protected\u2019 and \u2019non-protected\u2019 cases. These prompts are then fed into the large language model with a request to discern the differences. To ensure a fair and effective comparison, the \u2019protected\u2019 group, as per the ground truth contained within the simulated event logs, is taken into\nListing 18: SQL query provided by Bard to identify the protected group in the hiring log high.xes.gz event log.\nListing 20: SQL query provided by Bard to identify the protected group in the renting log high.xes.gz event log.\n<div style=\"text-align: center;\">Table 13: Quality of the classification done by GPT-4 between the \u2019protected\u2019 and \u2019non-protected\u2019 groups.</div>\nand \u2019non-protected\u2019 groups.\nEvent Log\nTP\nFP\nFN\nTN\nPrecision\nRecall\nTrue Neg. Rate\nhiring log high\n1507\n606\n1512\n6375\n0.72\n0.50\n0.80\nhospital log high\n1105\n1089\n1417\n6389\n0.50\n0.44\n0.82\nlending log high\n1501\n688\n1500\n6391\n0.69\n0.50\n0.81\nrenting log high\n1068\n1056\n1914\n5962\n0.50\n0.35\n0.75\n<div style=\"text-align: center;\">able 14: Quality of the classification done by GPT-4 between the \u2019protected\u2019 d \u2019non-protected\u2019 groups. The excellent recall and true negative rate should</div>\nbe noticed.\nEvent Log\nTP\nFP\nFN\nTN\nPrecision\nRecall\nTrue Neg. Rate\nhiring log high\n2977\n5768\n42\n1213\n0.34\n0.98\n0.97\nhospital log high\n2922\n6395\n88\n595\n0.31\n0.97\n0.87\nlending log high\n2923\n4555\n78\n2444\n0.39\n0.97\n0.96\nrenting log high\n2716\n6749\n266\n269\n0.29\n0.91\n0.50\nconsideration. This approach is demonstrated in the example script accessible at https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/02 group fairness factors.py.\nListing 21: Procedural differences between the \u2019protected\u2019 and \u2019non-protected\u2019 group identified by GPT-4 in the hiring log high.xes.gz event log.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4689/46891cd3-94dd-46ff-857f-c697c3ef6066.png\" style=\"width: 50%;\"></div>\nListing 22: Procedural differences between the \u2019protected\u2019 and \u2019non-protected\u2019 group identified by Google Bard in the hiring log high.xes.gz event log.\nRefer to Listing 21 and Listing 22 for GPT-4 and Bard\u2019s respective responses pertaining to the hiring event log. Similarly, for the renting event log, GPT-4 and Bard\u2019s responses can be found in Listing 23 and Listing 24 respectively.\nListing 23: Procedural differences between the \u2019protected\u2019 and \u2019non-protected\u2019 group identified by GPT-4 in the renting log high.xes.gz event log.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/21a4/21a4f57d-8a48-49bc-b4a9-c0efc72963f5.png\" style=\"width: 50%;\"></div>\nListing 24: Procedural differences between the \u2019protected\u2019 and \u2019non-protected\u2019 group identified by Google Bard in the renting log high.xes.gz event log.\n# Listing 24: Procedural differences between the \u2019protected\u2019 and \u2019non-protected\u2019 group identified by Google Bard in the renting log high.xes.gz event log.\nBoth large language models perform admirably, pinpointing differences in the control-flow and time perspectives. These variances in control-flow correlate with the outcome of a case, the presence of rework, and the number of events in the case. That said, GPT-4\u2019s response stands out for being more comprehensive compared to Bard\u2019s.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ec69/ec697f27-b2c9-4035-84ce-da96752a9f6f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Prompt executed against both large language mode</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/84b2/84b252af-518e-4f23-95ea-0f9c80d2a890.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Wrong response from Bard.</div>\nFig. 6: SQL query generation comparison between GPT-4 and Bard for the \u201cWhat is the average throughput time when activity \u2019Send Fine\u2019 occurs more than 50 days after the start of the case?\u201d query executed against the Road Traffic event log.\nIn our research, we are investigating how large language models can formulate process queries in mainstream SQL language. Our primary focus lies on two prominent models - Bard and GPT-4 - and their ability to translate user-provided natural language queries into executable SQL statements. Furthermore, we are interested in how adept these models are at spontaneously generating hypotheses based on an event log. The models are given basic abstractions such as the list of attributes and process variants within the log. For our analysis, we utilize DuckDB SQL language, a choice motivated by its seamless compatibility with the event log structure used by pm4py. In the present state of affairs, it is evident that some amount of domain knowledge is indispensable to ensure correct query formulation. This includes:\nSpringer Nature 2021 LATEX template\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a104/a104bab6-b6bf-40ed-9fce-6cf418d08666.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9652/96525b55-734c-4c7c-a01e-c0e92012411d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Correct response from GPT-4.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/78c1/78c145a6-273d-4059-892e-a91d79945b34.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Wrong response from Bard.</div>\n\u2022 Knowledge of SQL, such as the functions needed to calculate timestamps. \u2022 An understanding of process mining concepts, such as how to compute a case\u2019s throughput time or how to derive the process variant from a list of activities. \u2022 Awareness of the event log\u2019s key attributes, such as the column that identifies the case, the activity, and the timestamp.\n\u2022 Knowledge of the variable name that the query should target. While these prerequisites may require specialized knowledge, they are instrumental in ensuring the accuracy and relevance of the SQL queries generated by the large language models. In our study, we endeavored to assess the ability of large language models to convert natural language queries into SQL. Two distinct queries were used for this purpose on the Road Traffic event log.: 1. What is the average throughput time when activity \u2019Send Fine\u2019 occurs more than 50 days after the start of the case? (Refer to Figure 6 for the full query and the corresponding responses from GPT-4 and Bard). 2. I want to check the average rework for cases below and above the average throughput time (Refer to Figure 7 for the full query and the corresponding responses from GPT-4 and Bard). Our analysis reveals that, given sufficient domain knowledge, GPT-4 has an impressive capability to translate natural language queries into accurate SQL statements. Bard, on the other hand, appears to have significant difficulty making sense of the provided information, often failing to generate executable SQL queries. This discrepancy underscores the importance of adequate domain understanding for successful natural language processing tasks in process mining.\nCreate Fine \u2212> Send Fine \u2212> Insert Fine Notification \u2212> Add penalty \u2212> Send for Credit Collection ( frequency = 36 performance = 53746600.0 ) Create Fine \u2212> Payment ( frequency = 22 performance = 809181.8181818182 )\nCan you provide me a DuckDB SQL query. You should use the EPOCH function of DuckDB to get the timestamp from the date. The data is stored in a Pandas dataframe where each row is an event having the provided attributes (so there are no separate table containing the variant). The dataframe is called \u201ddataframe\u201d. Please consider the following information: the case identifier is called \u201dcase:concept :name\u201d, the activity is stored inside the attribute \u201dconcept:name\u201d, the timestamp is stored inside the attribute \u201dtime:timestamp\u201d, the resource is stored inside the attribute \u201dorg:resource\u201d. There is not a variant column but that can be obtained as concatenation of the activities of a case. There is not a duration column but that can be obtained as difference between the timestamp of the first and the last event.\nTo explore the potential of large language models in autonomously formulating hypotheses about event data, we posed a specific prompt to both GPT-4 and Bard (refer to Listing 25). This prompt was formulated such that t encouraged the models to generate hypotheses, starting from the knowledge f the attributes and the process variants present in the data. Here are some hypotheses generated by GPT-4: 1. The majority of cases conclude with the payment of fines after the addition of a penalty. This suggests that the imposition of a penalty may be a decisive factor prompting payment. The corresponding SQL query formulated by GPT-4, along with the results derived from its execution, are depicted in Figure 8. 2. The process of appealing to the prefecture does not appear to be a common practice. This indicates that offenders rarely dispute their fines. The provided SQL query for this hypothesis, along with the subsequent results, can be viewed in Figure 9. 3. There may be a correlation between the amount of fines and the frequency of credit collections, with higher fines potentially leading to an increase in credit collection instances. This could be attributed to the difficulty in paying larger fines. The SQL query and results corresponding to this hypothesis are presented in Figure 10. Bard\u2019s generated hypotheses included the following: 1. The most common process variant is \u201dCreate Fine -\u2192Send Fine -\u2192Insert Fine Notification -\u2192Add penalty -\u2192Send for Credit Collection\u201d. 2. The average payment amount for cases that traverse the complete process appears to be higher compared to cases that are concluded prematurely. 3. The longest durations to complete are typically associated with cases that involve an appeal. Both large language models generated valid hypotheses. However, a critical istinction arises from their ability to translate these hypotheses into exeutable SQL queries. While GPT-4 demonstrated this capability effectively, Bard did not manage to formulate corresponding SQL queries, emphasizing he advantage of incorporating explicit domain knowledge into the language model.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/23d5/23d5504d-1300-4198-87da-e505e3db9b85.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">SQL query generated by GPT-4.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4630/4630d51b-3df8-48c4-ae58-f1c251e316d5.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/05e4/05e47b3c-8466-42da-86a2-b896f032cfca.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">SQL query generated by GPT-4.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d55f/d55f49b2-5319-4abc-9e8c-94c2cc240f5b.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Validity of the hypothesis assessed by GPT-4.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9a8f/9a8fe11a-883c-4faf-8598-02dcac469ca1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">SQL query generated by GPT-4.</div>\n<div style=\"text-align: center;\">Result obtained after executing the SQL query.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fa3b/fa3b85d8-d32c-47a7-8016-7aa53e660976.png\" style=\"width: 50%;\"></div>\nSpringer Nature 2021 LATEX template\n# 5 Related Work\nThe field of process mining is not isolated, but intersects with various domains such as database technologies, natural language processing (NLP), and the use of large language models. Additionally, it relies heavily on domain knowledge for effective task execution. In the subsequent sections, we explore these intersections and dependencies, providing an overview of the state-of-the-art in these domains and their relevance to process mining. We delve into the interaction of database technologies with process mining (Section 5.1), the intersection of process mining and NLP (Section 5.2), and the importance of domain knowledge in process mining tasks (Section 5.3). This is followed by a thorough examination of the current state of large language models (Section 5.4) and their application within the realm of Business Process Management (Section 5.5). This examination helps illuminate the context and motivation behind our study.\n# 5.1 Database Technologies for Process Mining\nDatabase technologies play a crucial role in process mining, helping manage the increasing amounts of process-related data. They provide ways to extract and analyze this data, leading to valuable insights. In this section, we delve into several of these technologies and their contributions to process mining. The book Polyvyanyy (2022) considers the recognition and management of core techniques for retrieving and manipulating process-related artifacts. These core techniques are deemed reusable across various contexts and use cases such as process compliance, standardization, and monitoring, among others. By focusing on these reusable techniques, their aim is to increase efficiency and streamline the application of process querying across various projects and disciplines. Another approach Polyvyanyy et al (2017) proposes a framework to guide the creation of process querying methods. This framework serves as a blueprint for managing repositories of executed and designed processes and their relationships. This approach is instrumental in facilitating strategic decision-making, as well as laying the groundwork for the next generation of Business Intelligence platforms. The paper Sch\u00a8onig et al (2016) delve into a more specific solution, introducing a mining approach that works directly on relational event data through conventional SQL queries. By leveraging the power of database technologies, this approach is able to efficiently mine data without limiting the detection of certain control-flow constraints, thus proving to be fast and effective. In Baader and",
    "paper_type": "benchmark",
    "attri": {
        "background": {
            "problem background": "The intersection of process mining and large language models (LLMs) is a growing area of research. Traditional process mining techniques often struggle with the complexity and variability inherent in real-world processes. This benchmark is necessary to provide a standardized way to evaluate how LLMs can interpret and analyze process mining artifacts, thus fitting into the broader research landscape that seeks to enhance process mining methodologies.",
            "purpose of benchmark": "The benchmark is intended for assessing the capabilities of LLMs in understanding and generating insights from process mining data, thus facilitating comparisons between different models and prompting strategies."
        },
        "problem": {
            "definition": "The benchmark is designed to address the challenge of effectively utilizing LLMs to interpret process mining artifacts and generate meaningful insights from them, including the evaluation of process fairness and efficiency.",
            "key obstacle": "Existing benchmarks in process mining often do not account for the complexities introduced by LLMs, such as their ability to generate natural language responses and SQL queries based on process data."
        },
        "idea": {
            "intuition": "The development of this benchmark was inspired by the need to leverage LLMs for enhanced analysis of process mining artifacts, particularly in generating textual abstractions that simplify complex data.",
            "opinion": "The authors believe that integrating LLMs into process mining can significantly improve the efficiency and effectiveness of process analysis, potentially leading to new insights and methodologies.",
            "innovation": "This benchmark introduces novel prompting strategies specific to process mining tasks, allowing for a more nuanced evaluation of LLM capabilities compared to previous benchmarks.",
            "benchmark abbreviation": "LLM-PM"
        },
        "dataset": {
            "source": "The dataset comprises a collection of real-world event logs from various domains, including road traffic management and healthcare, which have been structured to facilitate analysis by LLMs.",
            "desc": "The dataset includes traditional and object-centric event logs, with a focus on their structural and temporal characteristics, allowing for comprehensive process analysis.",
            "content": "The dataset contains event logs characterized by activities, timestamps, and associated objects, enabling the evaluation of both procedural and declarative process models.",
            "size": "561,470",
            "domain": "Process Mining",
            "task format": "Event Log Analysis"
        },
        "metrics": {
            "metric name": "Accuracy, F1-score",
            "aspect": "Model performance in generating accurate insights and SQL queries from process mining data.",
            "principle": "The metrics were chosen based on their relevance to evaluating the effectiveness of LLMs in interpreting and responding to complex process mining queries.",
            "procedure": "Models were evaluated based on their ability to accurately generate responses to queries derived from event logs, with statistical significance assessed through multiple trials."
        },
        "experiments": {
            "model": "GPT-4, Google Bard",
            "procedure": "The models were tested using a range of process mining queries, with performance tracked across different event logs to assess their understanding and generation capabilities.",
            "result": "Both models demonstrated varying levels of proficiency, with GPT-4 generally outperforming Bard in terms of accuracy and relevance of responses.",
            "variability": "Variability in results was accounted for through multiple trials and the use of diverse event logs to ensure comprehensive evaluation."
        },
        "conclusion": "The experiments indicate that LLMs, particularly GPT-4, can effectively interpret and analyze process mining data, suggesting significant potential for future applications in this field.",
        "discussion": {
            "advantage": "The benchmark provides a structured approach to evaluating LLMs in process mining, highlighting their strengths in generating insights and automating queries.",
            "limitation": "One limitation is that the performance of LLMs may vary significantly based on the complexity of the queries and the quality of the event logs used.",
            "future work": "Future research should explore enhancing the capabilities of LLMs in handling more complex process mining tasks and developing additional benchmarks for comparative analysis."
        },
        "other info": {
            "info1": "The benchmark includes a variety of prompting strategies such as direct answering, multi-prompt answering, and SQL query generation.",
            "info2": {
                "info2.1": "The integration of LLMs into process mining applications opens new avenues for exploration and insight generation.",
                "info2.2": "Further studies are needed to evaluate the scalability of LLMs in processing larger and more complex event logs."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.2",
            "key information": "The intersection of process mining and large language models (LLMs) is a growing area of research, enhancing process mining methodologies."
        },
        {
            "section number": "2.3",
            "key information": "This benchmark is intended for assessing the capabilities of LLMs in understanding and generating insights from process mining data."
        },
        {
            "section number": "4.1",
            "key information": "LLMs, particularly GPT-4, can effectively interpret and analyze process mining data, suggesting significant potential for future applications."
        },
        {
            "section number": "4.2",
            "key information": "The benchmark introduces novel prompting strategies specific to process mining tasks, allowing for a more nuanced evaluation of LLM capabilities."
        },
        {
            "section number": "10.2",
            "key information": "Future research should explore enhancing the capabilities of LLMs in handling more complex process mining tasks and developing additional benchmarks for comparative analysis."
        }
    ],
    "similarity_score": 0.734942873331965,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Leveraging Large Language Models (LLMs) for Process Mining (Technical Report).json"
}