{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2409.14673",
    "title": "Instruction Tuning Vs. In-Context Learning: Revisiting Large Language Models in Few-Shot Computational Social Science",
    "abstract": "Real-world applications of large language models (LLMs) in computational social science (CSS) tasks primarily depend on the effectiveness of instruction tuning (IT) or in-context learning (ICL). While IT has shown highly effective at fine-tuning LLMs for various tasks, ICL offers a rapid alternative for task adaptation by learning from examples without explicit gradient updates. In this paper, we evaluate the classification performance of LLMs using IT versus ICL in few-shot CSS tasks. The experimental results indicate that ICL consistently outperforms IT in most CSS tasks. Additionally, we investigate the relationship between the increasing number of training samples and LLM performance. Our findings show that simply increasing the number of samples without considering their quality does not consistently enhance the performance of LLMs with either ICL or IT and can sometimes even result in a performance decline. Finally, we compare three prompting strategies, demonstrating that ICL is more effective than zero-shot and Chain-of-Thought (CoT). Our research highlights the significant advantages of ICL in handling CSS tasks in few-shot settings and emphasizes the importance of optimizing sample quality and prompting strategies to improve LLM classification performance. The code will be made available.",
    "bib_name": "wang2024instructiontuningvsincontext",
    "md_text": "# Instruction Tuning Vs. In-Context Learning: Revisiting Large Language Models in Few-Shot Computational Social Science\nTaihang Wang\u2663, Xiaoman Xu\u2663, Yimin Wang\u2661and Ye Jiang\u2663* College of Information Science and Technology\u2663 College of Data Science\u2661 Qingdao University of Science and Technology China\nAbstract\nReal-world applications of large language models (LLMs) in computational social science (CSS) tasks primarily depend on the effectiveness of instruction tuning (IT) or in-context learning (ICL). While IT has shown highly effective at fine-tuning LLMs for various tasks, ICL offers a rapid alternative for task adaptation by learning from examples without explicit gradient updates. In this paper, we evaluate the classification performance of LLMs using IT versus ICL in few-shot CSS tasks. The experimental results indicate that ICL consistently outperforms IT in most CSS tasks. Additionally, we investigate the relationship between the increasing number of training samples and LLM performance. Our findings show that simply increasing the number of samples without considering their quality does not consistently enhance the performance of LLMs with either ICL or IT and can sometimes even result in a performance decline. Finally, we compare three prompting strategies, demonstrating that ICL is more effective than zero-shot and Chainof-Thought (CoT). Our research highlights the significant advantages of ICL in handling CSS tasks in few-shot settings and emphasizes the importance of optimizing sample quality and prompting strategies to improve LLM classification performance. The code will be made available.\narXiv:2409.14673v1\n# 1 Introduction\nInstruction tuning (IT) of large language models (LLMs) has shown exceptional capability in understanding language across various tasks (Ouyang et al., 2022). However, the large number parameters of LLMs makes it challenging to transfer the pre-trained knowledge to downstream tasks (Naveed et al., 2023; Xu et al., 2024). Alternatively, in-context learning (ICL) enables LLMs to\n*Corresponding author\nperform downstream tasks by conditioning on taskspecific prompts, thus eliminating the need for explicit gradient updates (Dong et al., 2022; Wang et al., 2024b; Jiang, 2023). Recent successful deployment of LLMs in practical applications largely hinges on the effectiveness of the ICL and the IT. Previous studies have extensively assessed the zero-shot capabilities of LLMs in computational social science (CSS) tasks, including hate speech detection (Roy et al., 2023) and rumour stance detection (Yang et al., 2024b). However, CSS is a dynamic research area that involves detailed linguistic analysis and deep semantic comprehension. Direct zero-shot prompting LLMs to CSS tasks may even underperform compared to fully fine-tuned, task-specific smaller models like BERT (Juan Jos\u00e9 Bucher and Martini, 2024). Meanwhile, studies on ICL and IT typically occur independently, with direct comparisons between these approaches often overlooked. To address the above issues, this paper raises the following research questions (RQ):\n# \u2022 RQ 1: What are the performance differences between LLMs with ICL and IT in few-shot CSS tasks?\n# \u2022 RQ 2: How do varying numbers of sample influence the performance of LLMs with ICL and IT?\n\u2022 RQ 2: How do varying numbers of sample influence the performance of LLMs with ICL and IT?\n\u2022 RQ 3: How different prompting strategies affect the proficiency of LLMs in CSS tasks?\nTo answer the above questions, we extensively investigate six open-source LLMs in a total of five publicly accessible social media datasets within n-shot settings, where n \u2208{1, 8, 16, 32}. Initially, we compare the few-shot classification performance of LLMs with ICL and IT separately. We then assess how performance varies with an increase in the number of samples. Lastly, we\napply three prompting strategies including zeroshot, ICL and chain-of-thought (CoT), and examine their effects on performance. Additionally, except zero-shot setting, all experiments are conducted using five random seeds to account for the potential impact of few-shot sample quality on performance. Our main findings are:\n- (I) In few-shot settings, the performance of LLMs with ICL generally surpasses that of LLMs with IT on five CSS tasks.\n (II) Merely increasing the sample size (from 1-shot to 32-shot in our experiments) does not consistently improve the performance of LLMs either with ICL or IT, and even leads to a performance decline in some cases.\n (III) ICL prompting still outperforms zeroshot and CoT strategies, indicating that excessively complex prompting strategies can potentially hinder performance.\n# 2 Related Work\n# 2.1 Instruction tuning for large language models\nIT (Jiang et al., 2023; Wang et al., 2024a; Parthasarathy et al., 2024) is an effective technique that updates LLM parameters in a supervised fashion by modifying the context of inputs to follow specific instructions. Previous studies have extensively discussed the advancements of IT in LLMs. For example, Zhang et al. (2023); Qin et al. (2024) provide a comprehensive overview of the IT in LLMs, explaining the process of fine-tuning LLMs with instruction pairs and analyzing key factors that impact IT results. Ouyang et al. (2022) thoroughly examines data selection strategies for IT in LLMs, emphasizing the critical role of data quality over quantity and offering methods for selecting the most effective datasets to improve LLMs\u2019 instruction-following abilities. Hu et al. (2024) proposes a Sequential Instruction Tuning (SIT) method that systematically incorporates continuous tasks into the training process to enhance the model\u2019s capability to follow long, multi-step instructions. However, the aforementioned studies primarily assess IT in data-rich or zero-shot settings, leaving the few-shot performance of IT relatively underexplored.\n# 2.2 Comparison between instruction tuning and in-context learning\nICL enables LLMs to quickly adapt to tasks by learning from samples without updating the model\u2019s weights (Yang et al., 2023b; Brown et al., 2020). Dong et al. (2022) comprehensively summarizes the progress and challenges of ICL, discussing related techniques including prompt design and training strategies, and explores effective application scenarios of ICL in enhancing the inferential capabilities of LLMs. Coda-Forno et al. (2023) further explores how LLMs enhance their capabilities through the ICL paradigm by adjusting learning strategies and prior knowledge, through regression and multi-armed bandit tasks. Recent studies have also focused on exploring the connections between IT and ICL. For example, Mosbach et al. (2023) evaluates the generalization capabilities of Pattern-based fine-tuning (PBFT) and ICT for out-of-domain (OOD) tasks under the same experimental settings in a few-shot context. They find that PBFT achieves better generalization. Duan et al. (2023) investigates how ICL and IT modify the hidden layer states of LLMs to achieve task adaptability in LLMs, finding that ICL is implicit IT. Our work differs from previous research in that we directly compare the classification performance between the ICL and IT in various CSS tasks.\n# 2.3 Large language models in computational social science\nLLMs have demonstrated exceptional capabilities in CSS (M\u00f8ller and Aiello, 2024; Jiang, 2023; Xu et al., 2024; Jiang et al., 2023). For example, Ziems et al. (2024) has outlined a roadmap for using LLMs as tools for CSS, recommending best practices for prompting and conducting an extensive evaluation of the zero-shot performance of thirteen language models across twenty-four representative CSS benchmark tasks. Additionally, Mu et al. (2024) has assessed the zero-shot performance of two LLMs under six CSS tasks, while also researching the effects of various prompting strategies. However, the emerging CSS topics demand that LLMs quickly adapt to limited annotated data (Jiang et al., 2024), therefore it is crucial to evaluate their few-shot performance in CSS tasks. Our work aims to explore the performance differences between ICL and IT in CSS tasks within few-shot settings, as well as how to enhance the\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/851b/851b4721-ee61-48e2-a089-98d2185856d2.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: Illustration of the overall workflow in this paper. (a) The instruction prompts including the context of the tasks (Instruction), the constraints for generating the responses from LLMs (Constraints), and the input text of each task (Text). (b) The ICL prompts include a set of input-label pairs (Samples) to guide the LLMs in focusing on task-specific content. (c) A comparison between different prompting strategies in CSS tasks.</div>\ncapabilities of LLMs.\n# 3 Methodology\n# 3.1 Instruction tuning for CSS\nFollowing the IT strategy outlined by (Duan et al., 2023), we first create a task-specific Instruction (e.g., \"Analyze the content and determine if it includes label\", where label represents task-specific labels) to define the objective of each task. We then incorporate a set of Constraints (e.g., \"Respond only with label or not label, without offering additional context or explanation\") to guide the LLMs\u2019 responses. The detailed workflow of the IT process is presented in Figure 1 (a) and Appendix A.2. Considering the computational efficiency and challenges of fine-tuning LLMs, we employ LoRA (Hu et al., 2021) for instruction-tuning across all models. Specifically, we set the dropout probability at 0.1 and the learning rate at 1e-4. As recommended by Duan et al. (2023), the scaling factor is set to 32, with a rank of 8. The models are finetuned over three epochs using Brain Floating Point 16 (bf16) precision.\n# 3.2 In-context learning for CSS\nIn accordance with the in-context learning prompts described by Jiang and Wang (2024), we create input prompts consisting of Instruction, Constraints, Samples (e.g., \"Tweet: How to not miss\nsomeone who doesn\u2019t even know you. Label: not bragging\"), and Text (e.g., \"Tweet: For real, I just want to be prescribed something..., and what I\u2019m all about. Label: \"). The detailed workflow of ICL is depicted in Figure 1 (b). Given the limited fixed context length of LLMs, for the GossipCop dataset, we manually truncate the length of news articles to 256 tokens. Preliminary experiments revealed that higher temperature settings introduced more randomness in the model\u2019s responses. Hence, following the approach of Mu et al. (2024), we apply a reduced temperature of 0.2 to enhance the model\u2019s focus and stability.\n# 3.3 Comparing in different prompting strategies\nIn the zero-shot setting, we compose the prompt by combining Instruction, Constraints, and Text. For ICL, the detailed workflow is presented in Section 3.2. Inspired by Dogan et al. (2024), we utilize the ChatGPT-4 model1 to automatically generate CoT descriptions for each sample. For example, we input the tweet along with prompts in Bragging (e.g., \u201cAnalyze the content and determine if it includes a bragging statement by using the CoT method. Tweet: For a minute I was tired of being the bigger man, until I realized that\u2019s just who I am\u201d). These\n1https://chatgpt.com/\n<div style=\"text-align: center;\">Labels (number of samples)</div>\nDataset\nTotal\nLabels (number of samples)\nBragging\n6,696\nBragging (781)\nNot Bragging (5,915)\nComplaint\n3,449\nComplaint (1,232)\nNot Complaint (2,217)\nSarcasm\n4,868\nSarcasm (1,067)\nNot Sarcasm (3,801)\nRumour Stance\n5,568\nSupport(1,004)\nDeny(415)\nQuery(464)\nComment(3,685)\nGossipCop\n6,805\nReal (4,928)\nFake (1,877)\n<div style=\"text-align: center;\">Table 1: Statistics of the selected datasets.</div>\nCoT descriptions are then combined with Instruction and Text to form input prompts, as illustrated in Figure 1 (c). The examples of CoT description are provided in Appendix A.3.\n# 4 Experimental setups\n# 4.1 Data\nTo assess the classification performance of LLMs, five publicly available datasets are selected, encompassing a broad spectrum of computational social science topics. The statistics of these datasets are presented in Table 1. Bragging (Jin et al., 2022) : This dataset is designed to facilitate a comprehensive semantic analysis of tweets to ascertain whether they contain narratives of bragging, specifically identifying the subject of the author\u2019s boast. Complaint (Preo\u00b8tiuc-Pietro et al., 2019) : This task aims to identify whether tweets from social\n<div style=\"text-align: center;\">1-Shot Setting</div>\n1-Shot Setting\nQwen2\nBaichuan2\nGLM4\nLlama3\nGemma2\nPhi-3\nAvg\nICL\n68.6/67.2\n61.6/48.3\n66.4/60.0\n60.1/54.6\n61.1/55.8\n74.7/62.5\n65.4/58.1\nIT\n65.1/62.2\n60.7/47.9\n56.0/51.3\n53.9/50.1\n71.3/62.8\n65.4/57.8\n62.1/55.3\n8-Shot Setting\nQwen2\nBaichuan2\nGLM4\nLlama3\nGemma2\nPhi-3\nAvg\nICL\n71.7/70.3\n63.4/48.0\n60.8/56.6\n61.6/56.4\n59.6/55.7\n72.5/62.4\n64.9/58.2\nIT\n64.8/62.8\n63.8/49.3\n56.3/51.5\n53.0/50.0\n68.8/60.8\n65.3/58.0\n62.0/55.4\n16-Shot Setting\nQwen2\nBaichuan2\nGLM4\nLlama3\nGemma2\nPhi-3\nAvg\nICL\n71.5/70.1\n62.6/47.0\n60.2/56.7\n60.4/55.5\n60.8/56.7\n70.6/61.5\n64.4/57.9\nIT\n64.4/62.7\n62.3/49.5\n56.3/51.4\n51.2/48.6\n68.0/59.9\n65.1/57.5\n61.2/54.9\n32-Shot Setting\nQwen2\nBaichuan2\nGLM4\nLlama3\nGemma2\nPhi-3\nAvg\nICL\n72.6/71.2\n70.2/50.2\n61.7/57.6\n59.6/55.1\n61.0/56.4\n69.4/59.2\n65.7/58.3\nIT\n65.9/63.4\n61.3/48.5\n56.2/51.4\n52.4/49.4\n71.4/62.2\n64.8/57.1\n62.0/55.3\nTable 2: The LLMs\u2019 performance is compared between ICL and IT in CSS tasks. Scores are first calculated by averaging the accuracy and macro-F1 (Acc/F1) scores (%) across five seeds for each model, followed by computing the mean across five tasks. Bold indicates the highest accuracy, and Underline denotes the best F1 score.\nmedia contain complaints, where the complaint content expresses a mismatch between reality and expectations in a specific context. Sarcasm (Farha et al., 2022) : This task aims to conduct semantic analysis on texts to determine whether they contain sarcasm. Rumour Stance (Derczynski et al., 2017) : This task aims to perform semantic analysis on tweets (rumours) in social media to assess the stance classification of the rumours. GossipCop (Shu et al., 2020) : This task aims to perform semantic analysis on news articles in entertainment media to determine the authenticity of the news articles. For each benchmark task, we utilize stratified random sampling to divide the dataset into 70% for training, 10% for validation, and 20% for testing. The 10% validation set is used for hyperparameter tuning during the instruction tuning, and the\nperformances of LLMs under the ICL and IT are evaluated on the designated 20% test set. We apply the same few-shot settings to both the ICL and IT. First, we randomly sample n \u2208 {1, 8, 16, 32} examples (where n is the number of samples per class) from the training set. Given the high sensitivity of ICL and IT to the choice of examples, we use five random seeds per shot, repeating the process to assess LLM performance in few-shot scenarios.\n# 4.2 Baselines\nTo ensure a fair comparison of LLMs in CSS tasks, we utilize Huggingface2 to select six different open-source LLMs, with model sizes ranging from 7B to 9B, namely Qwen2-7B-Instruct (Qwen2) (Yang et al., 2024a), Baichuan2-7B-Chat (Baichuan2) (Yang et al., 2023a), GLM4-9B-chat (GLM4) (GLM et al., 2024), Meta-llama3-8Binstruct (LLama3) (Meta, 2024), Gemma-2-9B-it (Gemma2) (Team et al., 2024), and Phi-3-Small128K-Instruct (Phi-3) (Abdin et al., 2024).\n# 5 Results\nThe overall experimental results are presented in Table 2 and Table 3. For each n-shot setting, we evaluate the LLMs by computing the average accuracy (Acc) and macro-F1 (F1) scores across five random seeds3. Comparing between IT and ICL: We first calculate the average accuracy and F1 scores across\n2https://huggingface.co/ 3The detailed experimental results for each seed are presented in Appendix A.4\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d978/d9781baf-6232-414c-bbcd-975d7dc04d7b.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: Illustration of different sample sizes affect the performance of LLMs with ICL and IT respectively.</div>\nfive seeds for each model, and then compute the means of these scores across all CSS tasks. The averaged scores are presented in Table 2. We observe that the overall classification performance of LLMs with ICL is significantly better than that of LLMs with IT. For instance, ICL outperforms IT by 3.3% in accuracy in the 1-shot setting. Similarly, LLMs with ICL consistently outperform LLMs with IT in the 8, 16, and 32-shot settings, with accuracy improvements of 2.9%, 3.2%, and 3.7%, respectively. We also examine how different tasks impact the performance of ICL and IT, as presented in Table 3. In the Bragging and Complaint tasks, ICL consistently outperforms IT, achieving higher accuracy across all six models. For instance, ICL attains an average accuracy of 85.2% across six LLMs, which is 5.7% higher than IT in the 32shot setting for the Complaint task. This advantage is also evident in GossipCop, Sarcasm, and Rumour Stance. However, it is noteworthy that LLMs demonstrate relatively lower performance in the latter two benchmark tasks (e.g., Sarcasm and Rumour Stance) compared to others. For example, the average accuracy of ICL in Sarcasm and Rumour Stance is 57.2% and 41.4%, respectively, which is significantly lower than the 85.2% achieved in the Complaint task under the 32-shot setting. Comparing between LLMs: We also assess the ability of six LLMs to address CSS tasks using ICL and IT in few-shot settings, as presented in Table 3. We observe that Phi-3 outperforms the others in most tasks, achieving the highest average accuracy in the Bragging and Complaint tasks, with scores of 88.1% and 89.5%, respectively.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7a46/7a4698cd-9bca-4213-bb91-d4eda1dd8818.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">1-Shot Setting</div>\n1-Shot Setting\nModel\nBragging\nComplaint\nSarcasm\nRumour Stance\nGossipCop\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nQwen2\n86.0 / 86.9\n81.7/84.0\n81.5/81.8\n85.6/85.9\n59.3/62.5\n51.4/54.1\n41.3/44.0\n33.2/27.9\n75.0/60.6\n73.5/59.1\nBaichuan2\n81.7/60.8\n85.7/58.8\n62.6/60.7\n62.0/58.1\n77.7/50.9\n55.4/43.0\n48.4/32.8\n41.2/29.8\n37.6/36.4\n59.2/50.0\nGLM4\n87.1/73.7\n58.6/51.8\n83.4/82.9\n79.8/79.4\n54.8/53.4\n53.5/51.3\n36.1/28.3\n17.9/16.0\n70.5/61.7\n70.4/57.8\nLlama3\n78.7/64.6\n67.7/56.7\n88.4/87.8\n81.8/81.3\n43.4/43.2\n35.1/34.3\n22.5/18.6\n18.6/20.2\n67.6/58.8\n66.2/57.9\nGemma2\n77.4/64.3\n84.9/70.0\n84.0/83.6\n85.5/85.0\n41.4/41.3\n57.2/55.9\n45.5/35.5\n55.7/40.7\n57.1/54.5\n73.2/62.3\nPhi-3\n89.1/71.0\n87.8/72.2\n89.6/88.6\n86.3/85.7\n68.2/63.3\n43.9/43.8\n57.6/41.1\n38.2/35.2\n68.8/48.5\n70.8/52.3\n8-Shot Setting\nModel\nBragging\nComplaint\nSarcasm\nRumour Stance\nGossipCop\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nQwen2\n86.3/87.3\n77.7/81.1\n89.2/89.3\n84.6/84.9\n70.8/72.6\n52.7/55.8\n35.5/39.1\n38.4/30.6\n76.5/63.1\n70.4/61.7\nBaichuan2\n83.1/65.2\n79.0/59.6\n64.1/61.5\n61.0/53.2\n78.2/44.3\n60.7/52.9\n51.7/29.5\n48.6/28.4\n39.8/39.6\n69.4/52.3\nGLM4\n80.2/68.4\n59.0/52.1\n84.4/84.0\n79.9/79.5\n43.2/43.2\n54.1/51.9\n24.0/24.0\n18.0/16.0\n72.1/63.7\n70.3/57.8\nLlama3\n83.3/68.6\n63.4/54.0\n88.1/86.6\n81.3/80.8\n50.8/50.2\n38.8/38.4\n26.3/20.4\n18.7/19.8\n59.6/56.4\n63.0/56.8\nGemma2\n72.3/61.5\n81.8/67.4\n85.1/84.7\n83.9/83.5\n42.5/42.5\n57.0/55.7\n45.9/38.1\n56.8/40.9\n52.4/51.6\n64.7/56.7\nPhi-3\n88.9/73.8\n87.9/72.7\n89.7/88.9\n86.3/85.7\n62.6/59.5\n44.2/44.1\n51.8/38.3\n37.2/34.6\n69.7/51.5\n71.1/52.7\n<div style=\"text-align: center;\">16-Shot Setting</div>\n16-Shot Setting\nModel\nBragging\nComplaint\nSarcasm\nRumour Stance\nGossipCop\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nQwen2\n84.9/86.4\n76.8/80.5\n89.4/89.5\n84.1/84.4\n71.5/73.1\n53.0/56.1\n35.9/39.6\n38.6/30.6\n76.1/61.9\n69.8/61.8\nBaichuan2\n84.5/67.4\n83.8/62.7\n63.6/57.3\n62.0/53.5\n78.2/44.2\n61.5/52.6\n47.0/26.9\n44.6/29.6\n39.8/39.5\n59.6/48.8\nGLM4\n81.1/69.2\n58.8/51.9\n84.1/83.8\n79.8/79.5\n42.1/42.0\n54.1/51.8\n23.1/24.1\n18.1/16.0\n70.8/64.3\n70.4/57.9\nLlama3\n83.9/68.8\n66.4/55.9\n86.6/84.4\n80.7/80.3\n52.9/52.1\n36.6/36.3\n21.9/17.8\n18.6/19.2\n56.5/54.5\n53.8/51.3\nGemma2\n68.6/58.6\n82.7/68.2\n86.6/86.1\n83.8/83.4\n48.2/48.0\n56.5/55.2\n46.3/37.4\n56.6/40.6\n54.6/53.6\n60.5/51.8\nPhi-3\n88.1/73.7\n87.6/72.1\n89.6/88.8\n85.4/84.8\n54.8/53.6\n44.4/44.3\n50.2/40.4\n37.9/35.1\n70.2/50.8\n70.4/51.3\n32-Shot Setting\nModel\nBragging\nComplaint\nSarcasm\nRumour Stance\nGossipCop\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nQwen2\n86.7/87.7\n76.2/80.1\n89.9/90.0\n84.1/84.5\n71.1/72.7\n51.7/54.7\n39.4/43.4\n46.6/36.3\n75.8/62.1\n70.6/61.6\nBaichuan2\n87.1/67.5\n80.8/60.7\n73.7/67.8\n62.4/53.5\n78.2/44.2\n61.0/53.9\n65.7/26.0\n44.4/29.5\n46.2/45.4\n58.0/44.8\nGLM4\n81.4/69.4\n58.8/51.9\n84.4/84.0\n79.8/79.5\n42.1/42.1\n53.9/51.7\n29.2/28.0\n17.9/16.0\n71.2/64.7\n70.4/57.8\nLlama3\n84.5/69.5\n64.5/54.8\n87.1/85.1\n81.6/81.1\n48.9/48.6\n36.4/36.0\n17.3/15.2\n26.1/23.8\n60.3/57.0\n53.6/51.1\nGemma2\n70.3/59.7\n83.1/68.4\n87.0/86.5\n84.0/83.6\n53.8/53.1\n56.0/54.8\n45.9/35.0\n60.3/42.7\n48.0/47.7\n73.8/61.5\nPhi-3\n86.3/72.3\n87.7/72.3\n89.0/88.2\n85.0/84.4\n49.3/48.9\n44.0/43.9\n51.1/36.9\n36.9/34.5\n71.2/49.8\n70.2/50.5\nTable 3: The accuracy and macro-F1 (Acc/F1) scores (%) of various LLMs across five benchmark tasks. For eac shot, experiments are conducted using five random seeds, and the average values across all seeds are recorded. I each task, Bold indicates the highest accuracy, and Underline is the best F1 score.\nQwen2\nBaichuan2\nGLM4\nLlama3\nGemma2\nPhi-3\nAvg\nZero-shot\n61.7/55.9\n55.0/44.0\n58.1/54.6\n58.8/52.5\n64.3/57.1\n64.5/54.7\n60.4/53.1\nICL\n68.6/67.2\n61.6/48.3\n66.4/60.0\n60.1/54.6\n61.1/55.8\n74.7/62.5\n65.4/58.1\nCoT\n66.6/63.8\n56.7/52.0\n65.6/60.0\n59.4/52.6\n53.8/52.8\n67.0/62.1\n61.5/57.2\nTable 4: The accuracy and macro-F1 (Acc/F1) scores(%) across all benchmark tasks for different models represent the average values from five tasks. Bold and Underline indicate the highest accuracy and F1 among the LLMs in each task respectively.\nBaichuan2 and Qwen2 attain the highest average accuracy of 78.1% and 75.9% in the Sarcasm and GossipCop tasks, respectively. However, GLM4 and Llama3 generally underperform compared to the others. Additionally, all LLMs exhibit significant weaknesses in Rumour Stance. Notably, the IT performance of Gemma2 consistently surpasses that of ICL across all tasks. For instance, in the 1-shot setting, the average accuracy of IT exceeds that of ICL by 10.2%.\n# Comparing between different n-shot settings:\nFigure 2 illustrates the overall performance of the LLMs with ICL and IT in different n-shot settings. We compute the average accuracy of the six LLMs across all tasks. The experimental results show that the performance of LLMs with either ICL or IT does not consistently improve as the number of training samples increases, and even declines in some cases. For example, the average accuracy of Phi-3 with ICL is 74.7% in the 1-shot setting, but drops to 69.4% in the 32-shot setting. Similarly, the accuracy of Llama3 with IT decreases from 53.9% in the 1-shot setting to 52.4% in the 32-shot setting.\ngies: To assess the impact of prompting strategies on the inferential capabilities of LLMs, we compare three prompting approaches: zero-shot, ICL, and CoT in the 1-shot setting. Note that this comparison is not conducted in other n-shot settings, as we found no strong correlation between the number of samples and prompting strategies, based on the preliminary findings.\nThe performance of these three prompting strategies is shown in Table 4. We observe that ICL prompting consistently achieves the highest accuracy and F1 scores. Specifically, ICL surpasses CoT in accuracy by 3.9%. CoT, in turn, outperforms zero-shot by 1.1% in accuracy. Lastly, zeroshot exhibits the lowest accuracy and F1 scores.\n# 6 Analysis\nThe experimental results underscore the proficiency of LLMs in CSS tasks that require comprehension of complex real-world contexts. Next, we will contextualize these findings within the framework of our three research questions: (RQ1) What are the performance differences between LLMs with ICL and IT in few-shot CSS tasks? The experimental results reveal that LLMs with ICL generally outperform those with IT in few-shot CSS tasks. ICL exhibits strong adaptability, likely due to the extensive knowledge acquired during the pre-training phase. This allows the model to comprehend and swiftly adapt to complex tasks by leveraging pre-trained knowledge. While IT also enhances LLM capabilities through instructions, its performance is comparatively more sensitive than that of ICL, as illustrated in Figure 2. Additionally, ICL enables the model to directly leverage the input-label pairs provided in the samples to guide inference without requiring gradient updates. For LLMs with IT, insufficient training samples can lead to overfitting, instability, and may even impair the inferential capacity of the models. For example, the average accuracies of GLM4 and Llama3 are 56.0% and 53.9% in the 1-shot setting. However, both models achieve higher average accuracies of 58.1% and 58.8% in the zero-shot settings, respectively.\n# (RQ2) How do varying numbers of sample influence the performance of LLMs with ICL and IT?\nOur experimental results suggest that merely increasing the number of training samples does not consistently improve the performance of LLMs with either ICL or IT, and in some cases, it even leads to a decline. Given the characteristics of few-shot settings, we speculate that the contextual diversity of samples is more crucial than their quantity, regardless of whether LLMs use IT or ICL. If the additional sam-\nples are highly similar in content, LLMs may struggle to learn from the feature diversity in few-shot examples, leading to poor inferential performance. Moreover, when the feature distribution of fewshot samples deviates significantly from that of the pre-trained data, this variation may also negatively affect the classification performance of LLMs.\n# (RQ3) How different prompting strategies affect the proficiency of LLMs in CSS tasks?\nthe proficiency of LLMs in CSS tasks? LLMs with ICL achieve the highest performance among the three prompting strategies: zero-shot, ICL, and CoT. This indicates that incorporating a small number of input-label pairs into the prompt can help LLMs better focus on task-specific content across various CSS tasks. Surprisingly, we find that the CoT strategy slightly underperforms compared to ICL. We hypothesize two potential reasons for this: 1) the CoT examples are automatically generated by GPT-4, which may result in varying content quality depending on the context; 2) incorporating CoT descriptions into the prompt might introduce noise and transform a simple classification problem into a more complex language understanding task, as detailed in the Appendix A.3. Finally, the zero-shot strategy yields the lowest performance. This may be due to insufficient contextual information to guide the model in understanding and performing CSS tasks, which often require deeper semantic comprehension (e.g., Sarcasm and Bragging). Moreover, the zero-shot strategy primarily depends on the pre-trained knowledge of LLMs. The absence of task-specific knowledge during the pre-training phase may cause the model to struggle in identifying appropriate solutions.\n# 7 Conclusion\nIn this paper, we first evaluate the performance of LLMs with IT and ICL in few-shot CSS tasks. We also investigate whether increasing the number of training samples affects LLM performance. Lastly, we compare different prompting strategies and analyze their efficiency in few-shot settings. In our experiments, we evaluate six open-source LLMs on five publicly available CSS datasets. Our results indicate that: 1) LLMs with ICL generally outperform those with IT in tackling complex CSS tasks in few-shot settings; 2) merely increasing the number of samples without considering their quality does not consistently improve the perfor-\nmance of LLMs with either ICL or IT, and may even lead to a decline in some cases; 3) LLMs with ICL are more effective than those using zero-shot and CoT strategies in few-shot settings, suggesting that overly complex prompting may negatively impact LLM performance. Overall, our research underscores the substantial advantages of ICL in handling CSS tasks in few-shot settings, highlighting the critical role of optimizing sample quality and prompting strategies to enhance the classification performance of LLMs.\n# 8 Limitations\nThis study acknowledges several limitations, including: 1) Due to computational resource constraints and the context length limitations of LLMs, larger n-shot settings remain underexplored. 2) Our experiments primarily compare LLMs with parameters ranging between 7B and 9B, due to hardware restrictions. 3) The generation of CoT descriptions relies mainly on GPT-4, without manual assessment, which may result in inconsistencies in CoT quality.\n# 9 Ethic statement\nThis work has received ethical approval from the Ethics Committee of our university and adheres to the research policies of Twitter. All datasets were obtained via links provided in the respective research papers or directly from the authors upon request. Additionally, we confirm that the data was fully anonymized prior to being used for model inference with the LLMs. Due to the time-intensive and challenging nature of generating the CoT strategy, we solely rely on ChatGPT-4 to automatically generate the CoT descriptions, without manually crafting any CoT strategies.\n# Acknowledgments\nThis work is funded by the Natural Science Foundation of Shandong Province under grant ZR2023QF151 and the Natural Science Foundation of China under grant 12303103.\n# References\nMarah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al. 2024. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219.\nTeam GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang, Weng Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du, Zhenyu Hou, and Zihan Wang. 2024. Chatglm: A family of large language models from glm-130b to glm-4 all tools. Preprint, arXiv:2406.12793.\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685.\nFine-tuning large language models with sequential instructions. arXiv preprint arXiv:2403.07794. Ye Jiang. 2023. Team qust at semeval-2023 task 3: A comprehensive study of monolingual and multilingual approaches for detecting online news genre, framing and persuasion techniques. In Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023), pages 300\u2013306. Ye Jiang, Taihang Wang, Xiaoman Xu, Yimin Wang, Xingyi Song, and Diana Maynard. 2024. Crossmodal augmentation for few-shot multimodal fake news detection. arXiv preprint arXiv:2407.12880. Ye Jiang and Yimin Wang. 2024. Large visual-language models are also good classifiers: A study of incontext multimodal fake news detection. arXiv preprint arXiv:2407.12879. Ye Jiang, Xiaomin Yu, Yimin Wang, Xiaoman Xu, Xingyi Song, and Diana Maynard. 2023. Similarityaware multimodal prompt learning for fake news detection. Information Sciences, 647:119446. Mali Jin, Daniel Preo\u00b8tiuc-Pietro, A Seza Do\u02d8gru\u00f6z, and Nikolaos Aletras. 2022. Automatic identification and classification of bragging in social media. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3945\u20133959. Martin Juan Jos\u00e9 Bucher and Marco Martini. 2024. Fine-tuned\u2019small\u2019llms (still) significantly outperform zero-shot generative ai models in text classification. arXiv e-prints, pages arXiv\u20132406. AI Meta. 2024. Introducing meta llama 3: The most capable openly available llm to date, 2024. URL https://ai. meta. com/blog/meta-llama-3/. Accessed on April, 26. Anders Giovanni M\u00f8ller and Luca Maria Aiello. 2024. Prompt refinement or fine-tuning? best practices for using llms in computational social science tasks. arXiv preprint arXiv:2408.01346. Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Dietrich Klakow, and Yanai Elazar. 2023. Few-shot fine-tuning vs. in-context learning: A fair comparison and evaluation. In The 61st Annual Meeting Of The Association For Computational Linguistics. Yida Mu, Ben P Wu, William Thorne, Ambrose Robinson, Nikolaos Aletras, Carolina Scarton, Kalina Bontcheva, and Xingyi Song. 2024. Navigating prompt complexity for zero-shot classification: A study of large language models in computational social science. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LRECCOLING 2024), pages 12074\u201312086.\nMali Jin, Daniel Preo\u00b8tiuc-Pietro, A Seza Do\u02d8gru\u00f6z, and Nikolaos Aletras. 2022. Automatic identification and classification of bragging in social media. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3945\u20133959.\nMartin Juan Jos\u00e9 Bucher and Marco Martini. 2024. Fine-tuned\u2019small\u2019llms (still) significantly outperform zero-shot generative ai models in text classification. arXiv e-prints, pages arXiv\u20132406.\nMarius Mosbach, Tiago Pimentel, Shauli Ravfogel, Dietrich Klakow, and Yanai Elazar. 2023. Few-shot fine-tuning vs. in-context learning: A fair comparison and evaluation. In The 61st Annual Meeting Of The Association For Computational Linguistics.\nYida Mu, Ben P Wu, William Thorne, Ambrose Robinson, Nikolaos Aletras, Carolina Scarton, Kalina Bontcheva, and Xingyi Song. 2024. Navigating prompt complexity for zero-shot classification: A study of large language models in computational social science. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LRECCOLING 2024), pages 12074\u201312086.\nHumza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Naveed Akhtar, Nick Barnes, and Ajmal Mian. 2023. A comprehensive overview of large language models. arXiv preprint arXiv:2307.06435. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in neural information processing systems, 35:27730\u201327744. Venkatesh Balavadhani Parthasarathy, Ahtsham Zafar, Aafaq Khan, and Arsalan Shahid. 2024. The ultimate guide to fine-tuning llms from basics to breakthroughs: An exhaustive review of technologies, research, best practices, applied research challenges and opportunities. arXiv preprint arXiv:2408.13296. Daniel Preo\u00b8tiuc-Pietro, Mihaela Gaman, and Nikolaos Aletras. 2019. Automatically identifying complaints in social media. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5008\u20135019. Yulei Qin, Yuncheng Yang, Pengcheng Guo, Gang Li, Hang Shao, Yuchen Shi, Zihan Xu, Yun Gu, Ke Li, and Xing Sun. 2024. Unleashing the power of data tsunami: A comprehensive survey on data assessment and selection for instruction tuning of language models. arXiv preprint arXiv:2408.02085. Sarthak Roy, Ashish Harshvardhan, Animesh Mukherjee, and Punyajoy Saha. 2023. Probing llms for hate speech detection: strengths and vulnerabilities. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 6116\u20136128. Kai Shu, Deepak Mahudeswaran, Suhang Wang, Dongwon Lee, and Huan Liu. 2020. Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media. Big data, 8(3):171\u2013188. Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, L\u00e9onard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ram\u00e9, et al. 2024. Gemma 2: Improving open language models at a practical size. arXiv preprint arXiv:2408.00118. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2024a. A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):186345. Liang Wang, Nan Yang, and Furu Wei. 2024b. Learning to retrieve in-context examples for large language models. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1752\u20131767.\nXiaoman Xu, Xiangrun Li, Taihang Wang, Jianxiang Tian, and Ye Jiang. 2024. Team QUST at SemEval2024 task 8: A comprehensive study of monolingual and multilingual approaches for detecting AIgenerated text. In Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval2024), pages 463\u2013470, Mexico City, Mexico. Association for Computational Linguistics. Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, et al. 2023a. Baichuan 2: Open large-scale language models. arXiv preprint arXiv:2309.10305. An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al. 2024a. Qwen2 technical report. arXiv preprint arXiv:2407.10671. Ruichao Yang, Wei Gao, Jing Ma, Hongzhan Lin, and Bo Wang. 2024b. Reinforcement tuning for detecting stances and debunking rumors jointly with large language models. arXiv preprint arXiv:2406.02143. Zhe Yang, Damai Dai, Peiyi Wang, and Zhifang Sui. 2023b. Not all demonstration examples are equally beneficial: Reweighting demonstration examples for in-context learning. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 13209\u201313221. Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, et al. 2023. Instruction tuning for large language models: A survey. arXiv preprint arXiv:2308.10792. Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, and Diyi Yang. 2024. Can large language models transform computational social science? Computational Linguistics, 50(1):237\u2013291.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fff8/fff86078-5e23-4e4c-bed1-31b327020386.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure A1: Performance comparison between LLMs on CSS tasks.</div>\n<div style=\"text-align: center;\">A.2 Examples of instruction and constraints in CSS task</div>\nDataset\nInstruction\nConstraint\nBragging\nAnalyze the content and determine if it\nincludes a bragging statement.\nRespond only with bragging or not bragging\n, without providing any additional context or\nexplanation.\nComplaint\nAnalyze the content and determine if it\nincludes a complaint.\nRespond only with complaint or not complaint,\nwithout providing any additional context or ex-\nplanation.\nSarcasm\nAnalyze the content and determine if it\nincludes sarcasm.\nRespond only with sarcasm or not sarcasm, with-\nout providing any additional context or explana-\ntion.\nRumour Stance\nGiven a tweet related to a rumour, clas-\nsify its stance as one of the following cate-\ngories: support, deny, query, or comment.\nEach tweet should only be associated with\none stance category based on its content.\nRespond only with the appropriate stance cate-\ngory, without providing any additional context\nor explanation.\nGossipCop\nGiven a news article, classify its truthful-\nness as either real or fake.\nRespond only with real or fake, without provid-\ning any additional context or explanation.\n information on the instructions and constraints for each benchmark tas\n# A.3 Examples of CoT description\n<div style=\"text-align: center;\">A.3 Examples of CoT description</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1344/13442fae-b1a8-428d-bee0-d9253edd4e52.png\" style=\"width: 50%;\"></div>\nTable A2: The CoT strategy for Bragging samples.\n<div style=\"text-align: center;\">Table A2: The CoT strategy for Bragging samples.</div>\nQwen2\nn-shot\n(seed)\nBragging\nComplaint\nSarcasm\nRumour Stance\nGossipCop\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\n1(42)\n88.7/88.8\n86.5/87.4\n82.9/83.3\n85.7/86.0\n64.0/67.1\n56.9/60.3\n44.3/46.7\n37.3/30.6\n75.7/63.5\n73.3/60.8\n1(43)\n84.0/85.6\n77.2/80.9\n77.4/77.8\n85.2/85.5\n56.8/60.2\n50.5/53.4\n36.2/39.3\n36.4/29.1\n74.1/58.1\n73.3/60.8\n1(44)\n87.2/87.5\n86.3/87.3\n83.6/84.0\n83.8/84.1\n64.9/67.9\n50.9/53.8\n42.6/44.8\n28.5/25.3\n75.2/60.0\n73.3/60.8\n1(45)\n85.2/86.5\n82.0/84.3\n86.7/86.9\n89.0/89.2\n52.5/56.0\n42.9/43.9\n46.9/50.2\n36.8/29.6\n76.5/63.4\n74.0/54.1\n1(46)\n84.7/86.1\n76.5/80.3\n76.8/77.2\n84.5/84.8\n58.2/61.5\n55.9/59.1\n36.4/39.2\n26.9/24.8\n73.7/58.0\n73.6/58.9\nAvg\n86.0/86.9\n81.7/84.0\n81.5/81.8\n85.6/85.9\n59.3/62.5\n51.4/54.1\n41.3/44.0\n33.2/27.9\n75.0/60.6\n73.5/59.1\n8(42)\n86.6/87.5\n76.2/80.1\n89.6/89.7\n84.1/84.4\n74.5/74.6\n51.8/55.1\n30.3/33.1\n40.3/30.8\n76.0/62.2\n66.2/60.4\n8(43)\n86.1/87.3\n71.4/76.4\n89.6/89.7\n85.1/85.4\n71.1/72.8\n51.3/54.3\n40.4/44.4\n36.5/30.1\n75.9/62.6\n68.5/61.6\n8(44)\n86.7/87.5\n78.4/81.7\n89.3/89.4\n85.8/86.1\n70.6/72.6\n52.6/55.7\n36.5/40.6\n35.1/28.6\n76.9/64.5\n70.7/62.9\n8(45)\n85.9/87.0\n82.1/84.3\n89.9/89.9\n85.1/85.4\n69.5/71.8\n55.4/58.9\n32.6/35.9\n37.2/30.4\n76.7/62.0\n74.2/61.2\n8(46)\n86.2/87.2\n80.3/83.1\n87.5/87.8\n82.9/83.3\n68.2/71.0\n52.4/55.3\n37.7/41.7\n43.1/32.9\n77.2/64.1\n72.4/62.3\nAvg\n86.3/87.3\n77.7/81.1\n89.2/89.3\n84.6/84.9\n70.8/72.6\n52.7/55.8\n35.5/39.1\n38.4/30.6\n76.5/63.1\n70.4/61.7\n16(42)\n86.0/87.0\n79.4/82.5\n91.3/91.4\n83.2/83.6\n70.4/72.3\n54.3/57.6\n33.1/36.6\n37.1/29.5\n76.1/61.8\n71.3/62.4\n16(43)\n85.1/86.6\n71.3/76.3\n88.1/88.3\n84.6/85.0\n71.5/73.2\n55.9/59.2\n37.5/41.6\n39.4/31.3\n76.6/64.1\n67.3/61.0\n16(44)\n82.9/84.9\n77.9/81.4\n88.6/88.8\n84.8/85.1\n71.5/73.2\n52.5/55.5\n34.6/38.5\n36.5/29.5\n76.1/62.8\n67.4/61.2\n16(45)\n83.1/85.2\n75.2/79.3\n90.1/90.3\n83.5/83.8\n68.4/70.9\n49.9/52.6\n31.1/34.1\n38.2/30.5\n75.5/60.0\n72.7/62.1\n16(46)\n87.5/88.1\n80.0/82.9\n88.8/89.0\n84.3/84.7\n75.7/75.8\n52.3/55.4\n42.9/47.2\n41.7/32.2\n75.9/60.6\n70.2/62.4\nAvg\n84.9/86.4\n76.8/80.5\n89.4/89.5\n84.1/84.4\n71.5/73.1\n53.0/56.1\n35.8/39.6\n38.6/30.6\n76.1/61.9\n69.8/61.8\n32(42)\n87.2/88.0\n76.3/80.2\n89.9/89.9\n84.6/85.0\n69.9/71.6\n52.2/55.3\n40.2/44.4\n47.1/37.4\n75.4/62.4\n67.3/61.3\n32(43)\n86.0/87.3\n73.9/78.3\n90.1/90.3\n84.1/84.4\n70.3/72.3\n52.7/55.7\n39.6/43.4\n46.0/35.5\n76.3/62.4\n69.7/62.2\n32(44)\n86.2/87.3\n78.4/81.8\n89.9/90.0\n83.2/83.6\n72.6/74.0\n53.6/56.9\n42.5/46.8\n48.7/36.3\n75.7/61.0\n71.3/61.7\n32(45)\n86.7/87.7\n75.9/79.9\n90.1/90.3\n85.9/86.2\n69.5/71.5\n51.5/54.5\n37.4/41.7\n46.3/36.6\n76.4/63.3\n73.3/59.9\n32(46)\n87.3/88.1\n76.6/80.4\n89.6/89.7\n82.9/83.3\n73.0/74.1\n48.6/51.2\n37.0/40.8\n44.9/35.7\n75.3/61.3\n71.4/62.9\nAvg\n86.7/87.7\n76.2/80.1\n89.9/90.0\n84.1/84.5\n71.1/72.7\n51.7/54.7\n39.4/43.4\n46.6/36.3\n75.8/62.1\n70.6/61.6\nTable A3: The detailed experimental results for Qwen2.\n<div style=\"text-align: center;\">Baichuan2</div>\nBaichuan2\nn-shot\n(seed)\nBragging\nComplaint\nSarcasm\nRumour Stance\nGossipCop\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\n1(42)\n83.9/57.8\n87.9/56.7\n71.8/69.0\n69.6/66.8\n78.1/43.9\n62.4/45.6\n52.4/37.6\n39.9/28.3\n34.5/33.3\n54.3/51.0\n1(43)\n87.3/64.1\n88.0/54.2\n71.0/70.7\n37.4/30.0\n78.1/45.2\n43.3/40.7\n44.3/29.8\n42.8/31.4\n50.6/50.0\n54.3/51.0\n1(44)\n83.2/59.8\n88.3/56.7\n47.7/46.2\n70.1/67.0\n76.8/52.9\n69.8/53.6\n51.5/32.7\n41.2/29.8\n34.8/33.8\n54.3/51.0\n1(45)\n88.4/67.3\n85.6/64.7\n51.7/51.0\n69.3/63.5\n77.8/55.7\n73.1/47.2\n42.5/29.4\n40.5/28.1\n32.6/30.7\n72.5/42.6\n1(46)\n65.7/55.1\n78.9/61.5\n70.7/66.7\n63.7/63.3\n77.6/56.6\n28.5/27.8\n51.2/34.5\n41.5/31.4\n35.4/34.3\n60.8/54.4\nAvg\n81.7/60.8\n85.7/58.8\n62.6/60.7\n62.0/58.1\n77.7/50.9\n55.4/43.0\n48.4/32.8\n41.2/29.8\n37.6/36.4\n59.2/50.0\n8(42)\n80.0/62.2\n87.8/63.7\n68.3/66.6\n62.6/59.7\n78.1/43.9\n68.9/56.4\n59.9/29.7\n50.7/30.5\n41.2/41.2\n66.6/53.4\n8(43)\n79.2/65.1\n73.9/57.9\n74.3/73.7\n60.7/57.4\n78.2/44.4\n56.2/51.7\n57.9/34.1\n41.3/29.5\n40.0/40.0\n67.8/54.3\n8(44)\n86.8/65.7\n78.9/59.2\n60.0/56.8\n62.5/51.1\n78.2/44.4\n55.7/51.9\n47.5/28.1\n62.9/24.9\n39.3/39.2\n68.5/53.6\n8(45)\n83.0/65.8\n72.7/55.2\n38.0/31.1\n57.8/53.1\n78.2/44.4\n65.1/54.3\n53.1/29.8\n35.4/27.0\n39.7/39.6\n72.0/47.6\n8(46)\n86.8/67.1\n81.9/61.7\n79.9/79.1\n61.5/44.5\n78.2/44.3\n57.7/50.2\n40.2/25.8\n52.7/30.1\n38.5/38.2\n72.1/52.6\nAvg\n83.1/65.2\n79.0/59.6\n64.1/61.5\n61.0/53.2\n78.2/44.3\n60.7/52.9\n51.7/29.5\n48.6/28.4\n39.8/39.6\n69.4/52.3\n16(42)\n77.4/62.2\n85.9/63.9\n50.1/50.0\n62.3/57.1\n78.2/44.4\n62.954.7\n52.9/29.0\n41.4/29.3\n47.2/46.5\n57.8/52.1\n16(43)\n84.8/69.8\n83.4/61.1\n64.3/55.6\n60.1/50.0\n78.1/43.9\n60.8/53.1\n50.1/29.9\n43.8/28.2\n38.9/38.8\n68.9/55.9\n16(44)\n90.8/70.6\n81.4/61.9\n71.1/67.0\n62.7/54.3\n78.2/44.4\n60.7/51.3\n46.1/24.9\n48.3/31.6\n38.0/37.8\n58.2/52.8\n16(45)\n83.7/66.9\n83.0/63.2\n64.1/59.1\n62.4/54.8\n78.1/43.9\n59.2/50.3\n46.9/26.9\n40.1/30.8\n40.6/40.6\n72.6/42.6\n16(46)\n85.7/67.4\n85.4/63.6\n68.6/55.0\n62.3/51.5\n78.2/44.4\n63.8/53.8\n38.8/23.7\n49.4/28.2\n34.4/33.6\n40.5/40.4\nAvg\n84.5/67.4\n83.8/62.7\n63.6/57.3\n62.0/53.5\n78.2/44.2\n61.5/52.6\n47.0/26.9\n44.6/29.6\n39.8/39.5\n59.6/48.8\n32(42)\n88.8/66.5\n83.8/63.1\n72.2/64.4\n61.8/51.2\n78.0/44.3\n62.9/56.2\n65.7/27.4\n52.9/29.6\n42.6/42.5\n36.8/36.2\n32(43)\n87.2/67.0\n79.5/59.8\n71.6/65.0\n65.3/58.7\n78.2/44.4\n58.1/52.9\n66.2/25.1\n38.6/29.1\n51.0/48.7\n67.7/54.6\n32(44)\n86.0/68.5\n78.5/58.8\n68.2/56.1\n63.5/56.3\n78.2/44.4\n64.4/55.5\n65.2/25.7\n46.1/29.9\n43.3/43.0\n72.3/48.2\n32(45)\n87.1/67.4\n83.9/62.4\n78.1/75.2\n60.4/52.0\n78.2/44.4\n60.8/52.3\n64.6/23.8\n34.1/28.5\n45.0/44.6\n72.7/44.5\n32(46)\n86.6/67.8\n78.0/59.3\n78.7/78.1\n61.2/49.5\n78.1/43.9\n58.8/52.6\n66.7/28.0\n50.1/30.6\n49.2/48.3\n40.5/40.5\nAvg\n87.1/67.4\n80.8/60.7\n73.7/67.8\n62.4/53.5\n78.2/44.2\n61.0/53.9\n65.7/26.0\n44.4/29.5\n46.2/45.4\n58.0/44.8\nTable A4: The detailed experimental results for Baichuan2.\nTable A4: The detailed experimental results for Baichuan2.\nGLM4\nn-shot\n(seed)\nBragging\nComplaint\nSarcasm\nRumour Stance\nGossipCop\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\n1(42)\n84.7/71.6\n58.8/51.8\n83.0/82.4\n79.7/79.3\n56.5/55.0\n53.9/51.6\n35.4/27.8\n17.9/16.1\n72.2/61.5\n70.3/57.8\n1(43)\n86.5/72.6\n58.6/51.7\n85.7/84.8\n79.7/79.3\n49.2/48.7\n53.3/51.1\n41.9/30.6\n17.8/15.9\n68.2/60.4\n70.3/57.8\n1(44)\n90.5/75.6\n58.6/51.8\n82.9/82.5\n80.1/79.7\n54.0/52.8\n53.3/51.1\n37.9/29.6\n17.8/15.9\n69.3/63.0\n70.3/57.8\n1(45)\n85.9/73.0\n58.6/51.7\n83.6/83.2\n79.9/79.6\n51.1/50.5\n53.9/51.6\n31.1/25.8\n17.9/16.1\n73.3/61.7\n70.3/57.8\n1(46)\n87.7/75.3\n58.6/51.8\n81.7/81.5\n79.7/79.3\n63.2/60.1\n53.3/51.1\n34.3/27.6\n17.9/16.1\n69.5/61.9\n70.5/57.8\nAvg\n87.1/73.7\n58.6/51.8\n83.4/82.9\n79.8/79.4\n54.8/53.4\n53.5/51.3\n36.1/28.3\n17.9/16.0\n70.5/61.7\n70.4/57.8\n8(42)\n77.4/66.1\n59.1/52.1\n83.3/83.0\n79.8/79.4\n44.5/44.3\n54.2/52.0\n22.8/22.3\n18.1/16.0\n71.8/63.8\n70.3/57.8\n8(43)\n79.8/68.3\n59.1/52.1\n84.5/84.1\n79.9/79.6\n40.6/40.6\n53.8/51.5\n22.1/22.8\n18.1/16.1\n74.4/62.9\n70.3/57.8\n8(44)\n80.5/68.6\n59.1/52.2\n86.8/86.4\n79.8/79.5\n42.4/42.4\n54.0/51.9\n23.2/23 .0\n18.0/16.1\n71.1/64.8\n70.4/57.9\n8(45)\n81.1/68.7\n58.8/51.9\n85.9/85.5\n80.2/79.9\n45.2/45.0\n54.2/52.0\n26.4/27.0\n18.0/16.1\n71.4/63.1\n70.3/57.8\n8(46)\n82.3/70.1\n59.1/52.1\n81.4/81.2\n79.8/79.4\n43.5/43.4\n54.1/51.9\n25.5/24.7\n17.8/15.9\n71.8/63.8\n70.2/57.7\nAvg\n80.2/68.4\n59.0/52.1\n84.4/84.0\n79.9/79.5\n43.2/43.2\n54.1/51.9\n24.0/24.0\n18.0/16.0\n72.1/63.7\n70.3/57.8\n16(42)\n76.4/65.0\n59.2/52.2\n85.1/84.6\n79.8/79.4\n42.0/42.0\n54.1/51.8\n22.0/23.2\n18.2/16.1\n71.7/64.8\n70.4/57.9\n16(43)\n80.7/69.3\n58.6/51.8\n84.1/83.7\n79.9/79.6\n45.6/45.4\n53.8/51.6\n25.0/25.7\n18.1/16.0\n70.4/63.9\n70.3/57.8\n16(44)\n83.8/70.8\n58.6/51.8\n84.8/84.4\n79.8/79.4\n38.8/38.8\n53.8/51.6\n22.9/23.6\n18.1/16.0\n70.1/64.6\n70.4/57.9\n16(45)\n79.0/67.4\n58.8/51.8\n84.6/84.3\n80.1/79.7\n40.1/40.1\n54.2/52.0\n23.6/24.3\n18.2/16.1\n70.3/63.9\n70.4/57.9\n16(46)\n85.5/73.5\n59.0/52.0\n82.2/81.9\n79.7/79.3\n43.7/43.7\n54.3/52.0\n22.0/23.6\n18.0/15.9\n71.6/64.3\n70.5/57.8\nAvg\n81.1/69.2\n58.8/51.9\n84.1/83.8\n79.8/79.5\n42.1/42.0\n54.1/51.8\n23.1/24.1\n18.1/16.0\n70.8/64.3\n70.4/57.9\n32(42)\n78.4/66.7\n58.251.5\n85.5/85.1\n79.9/79.6\n45.4/45.2\n54.1/51.7\n27.8/28.0\n17.7/15.7\n72.2/64.4\n70.1/57.6\n32(43)\n84.1/72.0\n58.8/51.9\n85.4/85.0\n79.9/79.6\n41.0/41.0\n53.7/51.5\n30.9/30.0\n17.7/15.7\n72.1/65.8\n70.4/57.8\n32(44)\n80.5/68.6\n58.9/51.9\n83.2/82.9\n79.7/79.3\n44.3/44.2\n54.2/52.0\n28.2/25.6\n17.9/16.1\n70.6/64.6\n70.5/57.9\n32(45)\n80.5/68.6\n58.8/51.9\n84.2/83.9\n79.8/79.4\n38.2/38.1\n54.0/51.8\n25.0/25.7\n18.2/16.3\n70.0/64.0\n70.5/57.8\n32(46)\n83.5/70.9\n59.1/52.2\n83.5/83.2\n79.8/79.4\n41.8/41.8\n53.7/51.4\n34.3/30.8\n18.1/16.3\n71.0/64.6\n70.4/58.0\nAvg\n81.4/69.4\n58.8/51.9\n84.4/84.0\n79.8/79.5\n42.1/42.1\n53.9/51.7\n29.2/28.0\n17.9/16.0\n71.2/64.7\n70.4/57.8\nTable A5: The detailed experimental results for GLM4.\nTable A5: The detailed experimental results for GLM4.\nLlama3\nn-shot\n(seed)\nBragging\nComplaint\nSarcasm\nRumour Stance\nGossipCop\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\nICL\nIT\n1(42)\n81.4/66.7\n78.4/62.9\n88.7/88.1\n81.7/81.2\n44.6/44.5\n36.4/36.1\n15.0/14.7\n19.0/19.7\n70.0/59.2\n65.0/58.6\n1(43)\n80.6/65.7\n59.8/51.9\n88.0/87.2\n80.8/80.4\n46.1/46.0\n37.3/37.0\n23.7/19.9\n16.5/17.2\n72.2/59.4\n65.0/58.6\n1(44)\n78.1/63.4\n64.9/55.3\n89.8/89.1\n82.0/81.5\n48.5/48.2\n43.0/43.0\n35.6/25.6\n18.4/20.0\n70.9/58.3\n65.0/58.6\n1(45)\n74.9/62.4\n70.6/58.4\n88.7/88.1\n84.5/83.3\n37.5/37.3\n28.0/26.2\n17.7/16.4\n19.4/21.2\n66.8/62.0\n71.7/56.1\n1(46)\n78.7/64.6\n64.7/55.0\n86.9/86.4\n80.1/79.8\n40.1/40.1\n30.5/29.3\n20.3/16.2\n19.4/22.7\n58.0/55.0\n64.5/57.5\nAvg\n78.7/64.6\n67.7/56.7\n88.4/87.8\n81.8/81.3\n43.4/43.2\n35.1/34.3\n22.5/18.6\n18.6/20.2\n67.6/58.8\n66.2/57.9\n8(42)\n82.6/68.1\n66.1/55.7\n86.1/83.9\n81.9/81.3\n55.4/54.2\n34.9/34.4\n26.0/19.6\n18.5/19.1\n62.6/59.0\n69.2/58.3\n8(43)\n81.6/67.4\n57.5/50.5\n88.2/86.8\n80.3/79.9\n48.0/47.9\n30.5/29.3\n16.8/15.3\n18.2/19.7\n64.5/58.9\n65.8/58.3\n8(44)\n82.6/66.6\n68.8/57.4\n88.7/87.5\n81.9/81.3\n51.8/51.3\n47.7/47.6\n32.5/23.9\n18.5/20.1\n55.5/53.6\n51.7/50.7\n8(45)\n85.2/70.6\n56.9/49.9\n87.1/85.2\n82.7/82.0\n54.6/53.7\n40.0/40.0\n31.3/23.7\n18.8/20.3\n62.5/58.8\n64.3/58.3\n8(46)\n84.8/70.6\n67.5/56.5\n90.4/89.5\n79.8/79.5\n43.9/43.9\n40.6/40.5\n25.0/19.5\n19.3/19.7\n53.0/51.6\n63.9/58.3\nAvg\n83.3/68.6\n63.4/54.0\n88.1/86.6\n81.3/80.8\n50.8/50.2\n38.8/38.4\n26.3/20.4\n18.7/19.8\n59.6/56.4\n63.0/56.8\n16(42)\n83.6/67.9\n64.3/54.8\n85.1/81.9\n79.7/79.4\n59.5/57.7\n39.4/39.4\n15.9/13.6\n18.8/19.9\n58.6/56.2\n61.5/57.0\n16(43)\n80.7/67.1\n65.3/55.4\n86.9/85.0\n81.0/80.5\n49.3/49.0\n33.2/32.5\n20.1/17.3\n19.0/19.2\n56.1/54.4\n60.1/56.5\n16(44)\n83.7/67.5\n71.5/59.0\n86.9/85.0\n81.9/81.4\n53.5/52.7\n37.5/37.3\n26.2/19.9\n18.1/19.0\n52.7/51.6\n41.1/41.1\n16(45)\n85.9/71.6\n59.5/51.6\n87.1/85.0\n80.8/80.4\n54.6/53.7\n35.2/34.8\n27.7/21.2\n18.1/18.5\n60.5/57.4\n60.8/56.6\n16(46)\n85.6/70.0\n71.2/58.9\n87.1/84.9\n80.1/79.8\n47.3/47.2\n37.8/37.6\n19.8/16.9\n19.0/19.4\n54.5/53.1\n45.3/45.3\nAvg\n83.9/68.8\n66.4/55.9\n86.6/84.4\n80.7/80.3\n52.9/52.1\n36.6/36.3\n21.9/17.8\n18.6/19.2\n56.5/54.5\n53.8/51.3\n32(42)\n82.0/67.1\n66.0/55.9\n87.7/85.7\n82.3/81.7\n50.1/49.7\n34.4/33.9\n17.4/14.7\n27.1/23.2\n63.7/58.8\n58.4/55.1\n32(43)\n86.2/71.5\n63.4/54.2\n87.2/85.1\n81.0/80.5\n47.0/46.9\n35.0/34.6\n19.7/16.2\n21.5/20.5\n56.1/54.3\n59.0/56.0\n32(44)\n85.2/68.0\n66.3/55.8\n86.9/84.9\n81.1/80.7\n47.0/46.9\n38.4/38.3\n16.7/14.7\n26.0/23.8\n64.2/59.5\n39.1/38.8\n32(45)\n85.8/71.9\n63.6/54.3\n85.9/83.6\n81.9",
    "paper_type": "benchmark",
    "attri": {
        "background": {
            "problem background": "The paper addresses the challenges faced by large language models (LLMs) in computational social science (CSS) tasks due to the limitations of instruction tuning (IT) and the emerging need for in-context learning (ICL). The necessity for a benchmark arises from the dynamic nature of CSS, which requires effective adaptation of LLMs to limited annotated data.",
            "purpose of benchmark": "The benchmark is intended to evaluate and compare the effectiveness of instruction tuning and in-context learning in few-shot settings for various CSS tasks."
        },
        "problem": {
            "definition": "The benchmark is designed to assess the classification performance of LLMs in few-shot CSS tasks, specifically comparing IT and ICL approaches.",
            "key obstacle": "Existing benchmarks have limitations in evaluating LLMs' performance in few-shot settings, often overlooking the impact of sample quality and prompting strategies."
        },
        "idea": {
            "intuition": "The inspiration for this benchmark stems from the observation that while IT is effective, ICL may provide a more adaptable approach in few-shot scenarios, particularly in CSS tasks.",
            "opinion": "The authors emphasize the importance of ICL in enhancing LLM performance in CSS tasks, suggesting that it can outperform IT under certain conditions.",
            "innovation": "This benchmark introduces a comparative analysis of IT and ICL in few-shot settings, highlighting the significance of sample quality and prompting strategies, which have been less explored in previous research.",
            "benchmark abbreviation": "CSS-IT-ICL"
        },
        "dataset": {
            "source": "The dataset is composed of five publicly accessible social media datasets specifically designed for CSS tasks.",
            "desc": "The dataset includes a variety of tasks and is divided into training, validation, and testing sets, ensuring a comprehensive evaluation of LLM performance.",
            "content": "The dataset includes text data from social media, focusing on tasks such as sarcasm detection, complaint identification, and rumor stance classification.",
            "size": "30,000",
            "domain": "Social Media Analysis",
            "task format": "Text Classification"
        },
        "metrics": {
            "metric name": "Accuracy, F1-score",
            "aspect": "Model performance in terms of classification accuracy and balance between precision and recall.",
            "principle": "The metrics were chosen to provide a comprehensive evaluation of model performance, considering both overall accuracy and the balance of classification outcomes.",
            "procedure": "Model performance is evaluated by computing the average accuracy and macro-F1 scores across multiple trials and datasets."
        },
        "experiments": {
            "model": "The benchmark evaluates six open-source LLMs, including Qwen2, Baichuan2, GLM4, Llama3, Gemma2, and Phi-3, across various CSS tasks.",
            "procedure": "Models are trained and evaluated in few-shot settings with varying sample sizes, and their performance is assessed using multiple random seeds to account for variability.",
            "result": "The results show that ICL generally outperforms IT in most CSS tasks, with statistical significance in several comparisons.",
            "variability": "Variability in results is accounted for by conducting experiments with five random seeds for each sample size."
        },
        "conclusion": "The findings indicate that ICL is more effective than IT in few-shot CSS tasks, emphasizing the need to focus on sample quality rather than quantity for optimal LLM performance.",
        "discussion": {
            "advantage": "The benchmark highlights the strengths of ICL in adapting LLMs to CSS tasks, demonstrating its superiority over IT in few-shot scenarios.",
            "limitation": "The benchmark may not fully account for larger n-shot settings due to computational constraints, and the reliance on automated processes for generating prompts may introduce variability.",
            "future work": "Future research should explore larger n-shot settings and investigate the impact of different prompting strategies on LLM performance."
        },
        "other info": {
            "Funding": "This work is funded by the Natural Science Foundation of Shandong Province and the Natural Science Foundation of China."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper addresses the challenges faced by large language models (LLMs) in computational social science (CSS) tasks due to the limitations of instruction tuning (IT) and the emerging need for in-context learning (ICL)."
        },
        {
            "section number": "1.2",
            "key information": "The authors emphasize the importance of ICL in enhancing LLM performance in CSS tasks, suggesting that it can outperform IT under certain conditions."
        },
        {
            "section number": "1.3",
            "key information": "The benchmark is intended to evaluate and compare the effectiveness of instruction tuning and in-context learning in few-shot settings for various CSS tasks."
        },
        {
            "section number": "2",
            "key information": "The benchmark is designed to assess the classification performance of LLMs in few-shot CSS tasks, specifically comparing IT and ICL approaches."
        },
        {
            "section number": "3.1",
            "key information": "The inspiration for this benchmark stems from the observation that while IT is effective, ICL may provide a more adaptable approach in few-shot scenarios, particularly in CSS tasks."
        },
        {
            "section number": "6.1",
            "key information": "The benchmark may not fully account for larger n-shot settings due to computational constraints, and the reliance on automated processes for generating prompts may introduce variability."
        }
    ],
    "similarity_score": 0.7266324855637172,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2330_in-co/papers/Instruction Tuning Vs. In-Context Learning_ Revisiting Large Language Models in Few-Shot Computational Social Science.json"
}