{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2411.01178",
    "title": "LLM4PR: Improving Post-Ranking in Search Engine with Large Language Models",
    "abstract": "Alongside the rapid development of Large Language Models (LLMs), there has been a notable increase in efforts to integrate LLM techniques in information retrieval (IR) and search engines (SE). Recently, an additional \u201cpost-ranking\u201d stage is suggested in SE to enhance user satisfaction in practical applications. Nevertheless, research dedicated to enhancing the post-ranking stage through LLMs remains largely unexplored. In this study, we introduce a novel paradigm named Large Language Models for Post-Ranking in search engine (LLM4PR), which leverages the capabilities of LLMs to accomplish the post-ranking task in SE. Concretely, a QueryInstructed Adapter (QIA) module is designed to derive the user/item representation vectors by incorporating their heterogeneous features. A feature adaptation step is further introduced to align the semantics of user/item representations with the LLM. Finally, the LLM4PR integrates a learning to post-rank step, leveraging both a main task and an auxiliary task to fine-tune the model to adapt the post-ranking task. Experiment studies demonstrate that the proposed framework leads to significant improvements and exhibits state-of-the-art performance compared with other alternatives.",
    "bib_name": "yan2024llm4primprovingpostrankingsearch",
    "md_text": "# LLM4PR: Improving Post-Ranking in Search Engine with Large Language Models\nYang Yan, Yihao Wang, Chi Zhang, Wenyuan Hou, Kang Pan, Xingkai Ren, Zelun Wu, Zhixin Zhai, Enyun Yu, Wenwu Ou and Yang Song Kuaishou Technology Beijing, China\nABSTRACT\n# ABSTRACT\nAlongside the rapid development of Large Language Models (LLMs), there has been a notable increase in efforts to integrate LLM techniques in information retrieval (IR) and search engines (SE). Recently, an additional \u201cpost-ranking\u201d stage is suggested in SE to enhance user satisfaction in practical applications. Nevertheless, research dedicated to enhancing the post-ranking stage through LLMs remains largely unexplored. In this study, we introduce a novel paradigm named Large Language Models for Post-Ranking in search engine (LLM4PR), which leverages the capabilities of LLMs to accomplish the post-ranking task in SE. Concretely, a QueryInstructed Adapter (QIA) module is designed to derive the user/item representation vectors by incorporating their heterogeneous features. A feature adaptation step is further introduced to align the semantics of user/item representations with the LLM. Finally, the LLM4PR integrates a learning to post-rank step, leveraging both a main task and an auxiliary task to fine-tune the model to adapt the post-ranking task. Experiment studies demonstrate that the proposed framework leads to significant improvements and exhibits state-of-the-art performance compared with other alternatives.\narXiv:2411.01178v1\nKEYWORDS\nLarge Language Model, Search Engine,Generative Post-ranking ACM Reference Format: Yang Yan, Yihao Wang, Chi Zhang, Wenyuan Hou, Kang Pan, Xingkai Ren, Zelun Wu, Zhixin Zhai, Enyun Yu, Wenwu Ou and Yang Song. 2018. LLM4PR: Improving Post-Ranking in Search Engine with Large Language Models. In Proceedings of Make sure to enter the correct conference title from your rights confirmation emai (Conference acronym \u2019XX). ACM, New York, NY, USA, 10 pages. https://doi.org/XXXXXXX.XXXXXXX\n# 1 INTRODUCTION\nConventional search engines (SE) and information retrieval (IR) systems are composed of multiple stages including matching and ranking, in which the relevant items are retrieved in matching\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY \u00a9 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/18/06 https://doi.org/XXXXXXX.XXXXXXX\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY \u00a9 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/18/06 https://doi.org/XXXXXXX.XXXXXXX\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bf5a/bf5a303c-3ed1-41c7-89a4-13656d18a352.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: Illustration of the search process, encompassing matching, ranking and post-ranking stages.</div>\nstages and sorted by relevance in ranking stage. However, in practical applications, the relevance score of a single item is not the sole measure for practical search engines. On e-commerce platforms, the search engine is required not only to provide relevant results but also to maximize users\u2019 purchase rate by presenting the product list. Meanwhile, in the short video search scenario, the search platform also attempts to maximize users\u2019 play time during the entire search session. To this end, a post-ranking stage is suggested in practical applications. As depicted in Figure 1, the post-ranking stage severs as the final stage in search engines. This stage considers multiple attributes (item relevance score, user click/purchase rate, etc.) as well as mutual influences between items, and deliver the final list to optimally enhances user experience in the search session. In IR and SE, the classic Learning-To-Rank (LTR) method formulates a composite objective encompassing item relevance and click/purchase to model the post-ranking stage. Recently, numerous additional efforts have been dedicated to studying this search topic[1, 3, 15, 19, 26, 34, 55]. Concretely, SetRank [34] proposes the self-attention method to model mutual influences between items, and DLCM [2] suggests a RNN-based approach. PRM [35], PRS [13] and PIER [42] suggest permutation-based two-stage processes for list generation and evaluation. Another pioneering stream of studies on post-ranking stages focus on the generative method. Seq2slate[4] and GRN [14] introduce the generative method in post-ranking stage in recommendation scenario1. Regarding the increasing popularity of generative methods, especially its significant success in Large Language Models (LLMs), the generative and LLMbased approaches emerge as a promising avenue for optimizing post-ranking stage in search engine. The advances in Large Language Models (LLMs) have achieved remarkable success in Natural Language Processing (NLP) and IR\n1In recommender system, \u201cre-ranking\u201d refers to \u201cpost-ranking\u201d stage. While in information retrieval, \"re-ranking\" denotes the \"ranking\". In case of confusion, we call the last stage in search engine as \u201cpost-ranking\u201d in this paper.\ntasks [6, 11, 33, 46\u201348], and it has been prompting increasing integration between LLM and practical applications such as search engine (SE). Currently, most existing LLM methods for SE primarily focus on augmenting document retrieval [5, 10, 20, 28, 49], document ranking/re-ranking [36, 43] and modeling relevance between queries and items [7, 36, 41, 54]. However, despite significant efforts being directed towards matching (i.e., item retrieval) and ranking within SE, the post-ranking stage has been overlooked. Consequently, the explorations of LLMs for the post-ranking stage in SE remain scarce. To implement LLMs for the post-ranking process in search engine, several challenges have yet to be overcome. Issue 1: Heterogeneous Features Input. The input of postranking model commonly encompasses heterogeneous features including item descriptions, category ID features, item-level statistical features, and the output (i.e., numerical embedding) from the upstream (i.e., ranking) stage. However, current LLMs are specifically designed to process semantic textual input only. Directly inputting these feature embeddings into the LLM could potentially lead to confusion, as these embeddings lack semantic context. Therefore, developing a mechanism to seamlessly incorporate these diverse features into the LLM input and align the feature representation with the LLM remains a significant challenge. Issue 2: Task Specification for Post-Ranking. Existing LLMs are designed for general purposes (i.e.conversation, question and answering), exhibiting limited capacities for the post-ranking task in practical applications. Thus, it is essential to explore appropriate adjustments to enhance the LLM\u2019s ability for optimizing the postranking task. To address these issues, we propose an LLM-based framework for Post-Ranking in search engine, named LLM4PR, comprising a Query-Instructed Adapter (QIA) component and a backbone LLM. To handle the challenge of heterogeneous features (Issue 1), we propose a feature adaptation step to integrate diverse features. The QIAs take user/item side features as input, and combine various features in a query-instructed manner. Specifically, within the QIAs, the search query assigns distinct weights to diverse feature domains via the attention mechanism and derive the representation vectors for the user/item. Moreover, a template-based generation task is designed to achieve the semantic alignment between the user/item representations and the LLM. Particularly, we freeze the LLM and train the QIAs to generate semantic user/item representations that can be decoded by the LLM. To tackle the post-ranking task challenge (Issue 2), we design a main task and an auxiliary task to fine-tune the LLM4PR to learn to post-rank, named learning to post-rank step. The main task involves taking candidate item list as input and instructing LLM4PR to predict the target post-ranking order in a generative manner. To produce satisfying post-ranking lists, the model is required to assess the quality of various candidate item lists. To this end, we propose an auxiliary task that compares a pair of candidate lists and predicts the superior one. The auxiliary task serves as a supplement to the main task, supporting the model in developing an insight for judging the quality of candidate lists. In the training stage, both the main task and the auxiliary task are trained simultaneously. During the inference stage, we utilize the main task to generate the final post-ranking results. Overall, the contributions of this paper can be summarized as follows:\n\u2022 Firstly, to the best of our knowledge, our LLM4PR is the first LLM-based framework that optimizing the post-ranking stage for search engines. This framework leverages the robust capabilities of LLM and generates the final results straightforwardly. \u2022 Secondly, the proposed LLM4PR suggests a novel QIA component and feature adaptation step to align heterogeneous features. Additionally, it introduces an efficient template-based learning to post-rank step for model tuning. \u2022 Last but not least, the effectiveness of the proposed LLM4PR is fully validated through comprehensive experiment studies.\n# 2 RELATED WORKS\nPost-Raking in Search Engine. In the context of the post-ranking stage, where not only document relevance but also user satisfaction are taken into consideration in practical applications, [26] categorizes the methods from the perspectives of modeling objectives and learning signals. Early methods [2, 13, 34, 35, 42, 55] consider the single objective and learn from supervised signals. [1] proposes location diversity ranker loss to optimize the diversity issue in Airbnb Search. Among generative post-ranking models, ListCVAE [21] selects the Conditional Variational AutoEncoder (CVAE) to generate the slate straightforwardly, while Seq2slate [4] and GRN [14] predict the next item sequentially via pointer network and policy gradient, respectively. [19] further introduces a discriminator to ensure the generated results are close to real lists. LLM for Information Retrieval. In recent years, research on Large Language Models (LLMs) has gained considerable attention. Various pre-trained models (BERT[11], T5[38, 48], BART[22]) and LLMs (LLaMA series [46, 47], GPT series [6, 33], Baichuan [51], GLM [12]) are proposed, and [52] provides a comprehensive survey reviewing the development of LLMs. In light of the remarkable successes achieved by LLMs for natural language problems, considerable efforts have been dedicated to integrating LLMs with information retrieval. [53] offers an insightful overview of potential applications of LLMs in information retrieval, including query rewriter, retriever, text ranking and so on. The text ranking capabilities of LLMs have been comprehensively explored through various methodologies, including the pointwise approach [7, 41, 54], the pairwise approach [36], and the listwise approach [29, 43]. [28] proposes a LLaMA-based retriever and ranker simultaneously. [43] investigates ChatGPT for passage ranking straightforwardly and suggests model distillation. Further works on LLMs for document ranking could be found in [17, 23, 24, 37, 50]. However, the aforementioned methods do not pay attention to the post-ranking stage, and LLM-based methods for post-ranking in search engine are urgently needed.\n# 3 PRELIMINARY\nIn search engines, post-ranking refines the results list by accounting for both item quality and the mutual influences between items, and determines the ultimate outcomes to maximize users experience. Particularly, given a request R and its output list I = {\ud835\udc561,\ud835\udc562, \u00b7 \u00b7 \u00b7 ,\ud835\udc56\ud835\udc5b} from previous stage (i.e., ranking stage), the postranking algorithm aims to refine the order and produce a new ranking list I\u2217= {\ud835\udc56\u2217 1,\ud835\udc56\u2217 2, \u00b7 \u00b7 \u00b7 ,\ud835\udc56\u2217\ud835\udc5b} that better matches the users preferences. Therefore, the post-ranking stage can be formulated as\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e749/e749b645-27ac-448e-a73d-6329e73c6962.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: Overview of the proposed LLM4PR framework.</div>\na function \ud835\udc53: R \u00d7 I \u21a6\u2192I\u2217, where the request R = {\ud835\udc5e, X\ud835\udc62, H\ud835\udc62} comprises the raw search query \ud835\udc5e, user profile features X\ud835\udc62, and information about user history behavior items H\ud835\udc62.\n# 4 METHODOLOGY\n# 4 METHODOLOGY 4.1 Overview of LLM4PR\n# 4.1 Overview of LLM4PR\n# 4.1 Overview of LLM4PR\nThe overview structure of the proposed LLM4PR is illustrated in Figure 2. Specifically, QIA\ud835\udc62takes query embedding \ud835\udc65\ud835\udc5eand user feature embeddings X\ud835\udc62(e.g., id embedding, gender embedding, etc.) as input, and produces a single embedding \ud835\udc52\ud835\udc62to represent the user. Similarly, QIA\ud835\udc56takes query embedding \ud835\udc65\ud835\udc5eand candidate/history item feature embeddings X\ud835\udc56/X\u210eas input, and generates a hidden vector for each item in I/H\ud835\udc62. Note that, the query embedding and feature embeddings of the user/item fed into the QIA are fetched from previous stage (i.e., the ranking stage), instead of training from scratch. Subsequently, the user embedding \ud835\udc52\ud835\udc62, candidate item embeddings \ud835\udc52\ud835\udc56, behavior item embeddings \ud835\udc52\u210e, and the raw query \ud835\udc5eare combined using a post-ranking template T\ud835\udc5a\ud835\udc4e\ud835\udc56\ud835\udc5b \ud835\udc5d\ud835\udc5f . The template provides a hybrid input instruction, containing both texts and embeddings, and the LLM directly predicts the final list in a generative manner according to the given input instruction. Next, we will introduce the designed QIA and training tasks for LLM4PR.\n# 4.2 Query-Instructed Adapter\nTraditional post-ranking methods utilize diverse features to represent a specific user or item. A straightforward way to utilize these features in LLMs is to combine all texts into one sentence as the input for LLM (serving as one baseline method in Section 5). However, considering current ranking methods include hundreds or even thousands of different features, the combined sentence may become excessively long, causing significant increase in inference time. To this end, we propose the QIA component, which utilizes the attention mechanism to merge various features of the user/item and delivers a single embedding vector to represent the specific user/item. Specifically, the QIA takes search query embedding \ud835\udc65\ud835\udc5e\u2208R1\u00d7\ud835\udc51\ud835\udc5e and multiple user/item features X = {\ud835\udc651,\ud835\udc652, \u00b7 \u00b7 \u00b7 ,\ud835\udc65\ud835\udc58} as input, where \ud835\udc65\ud835\udc57\u2208R1\u00d7\ud835\udc51\ud835\udc57is the \ud835\udc57-th feature vector with dimension \ud835\udc51\ud835\udc57. We concatenate all the numerical features (e.g., category embeddings, predicted scores from the up-stream stage, etc.) and treat it as an embedding vector. It is noted that the query embedding\n\ud835\udc65\ud835\udc5eand feature vectors X are fetched from the ranking stage and fixed during the training phase. The search query \ud835\udc5ereflects user demand and may align with specific characteristics of the items. For example, when a user searches for a romance film, the model should focus on the genre of the movies. Thus, we implement a feature field attention technique to automatically align various features based on the query. Concretely, the projection heads are first applied on the query and feature embeddings to produce the Query \ud835\udc44, Key \ud835\udc3eand Value \ud835\udc49, which can be formulated as\n(1) (2) (3)\nwhere \ud835\udc44\u2208R1\u00d7\ud835\udc51\u210e, \ud835\udc3e,\ud835\udc49\u2208R\ud835\udc58\u00d7\ud835\udc51\u210e, \ud835\udc4a\ud835\udc44\u2208R\ud835\udc51\ud835\udc5e\u00d7\ud835\udc51\u210e, \ud835\udc4a\ud835\udc3e\ud835\udc57,\ud835\udc4a\ud835\udc49\ud835\udc57\u2208 R\ud835\udc51\ud835\udc57\u00d7\ud835\udc51\u210e,\ud835\udc51\u210erepresents the attention hidden size, and\ud835\udc58is the number of feature fields. Then, a standard target attention is employed to derive the hidden vector \u210e\ud835\udc64= Softmax( \ud835\udc44\ud835\udc3eT \u221a \ud835\udc51\u210e)\ud835\udc49, where \u210e\ud835\udc64\u2208 R1\u00d7\ud835\udc51\u210e. Note that, the QIA attention mechanism provides a finegrained interaction approach at the feature level, which enriches the expression of the user/item embedding. Finally, an additional linear projection maps the size of the hidden feature vector to the LLM hidden size: \ud835\udc52= Linear(\u210e\ud835\udc64), where \ud835\udc52\u2208R1\u00d7\ud835\udc51\ud835\udc59\ud835\udc59\ud835\udc5ais the final embedding to represent the specific user/item. \ud835\udc51\ud835\udc59\ud835\udc59\ud835\udc5ais the hidden size for the LLM.\n# 4.3 Feature Adaptation Step\nLLMs are initially proposed to handle the NLP tasks, which take semantic texts as input. However, the user/item representations provided by the QIAs lack semantic information and cannot be understood by the LLM. Thus, we introduce a feature adaptation step to align the user/item representation embeddings with the LLM, serving as the preparatory phase for subsequent learning to post-rank. In this step, we freeze the LLM and fine-tune the QIAs to produce user/item representations that are most concordant with their semantic information. The process of feature adaptation step is illustrated in Figure 3. The QIA takes query \ud835\udc5eand user/item feature vectors (X\ud835\udc62/X\ud835\udc56) as input and produces the representation vector for the user/item (\ud835\udc52\ud835\udc62/\ud835\udc52\ud835\udc56). A template T\ud835\udc53\ud835\udc4eis introduced to integrate the query, user representation and item representation into a prompt sentence.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/109b/109b0c2e-3af5-426c-b2f7-4477cc29039c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(i) Illustration of the feature adaptation step.   is the template for feature adaptation step.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b292/b29221f2-456d-4bab-a320-d42294c223fb.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(ii) Take MovieLens dataset as example to illustrate the template for the feature adaptation step.</div>\nT\ud835\udc53\ud835\udc4e, demonstrated in Figure 3(ii), is a hybrid template including both texts and numerical embeddings. There are two parts in the template, the input part is the input sentence for LLM and the output part is the target response that LLM is expected to produce. In template T\ud835\udc53\ud835\udc4e, \ud835\udc52\ud835\udc62and \ud835\udc52\ud835\udc56are the user and item representations provided by QIA\ud835\udc62and QIA\ud835\udc56, respectively. Besides the user and item information, T\ud835\udc53\ud835\udc4ealso contains the instructions for LLM. Take MovieLens[16] dataset as an example, T\ud835\udc53\ud835\udc4erequires the LLM to predict the user rating for the movie by providing descriptions for the input user and movie. The description generation aims to align the user/movie representation vector to its corresponding textual semantic. In this sense, the output of this instruction is constructed by organizing the various features of user/movie into a coherent sentence. Particularly, for categorical features such as gender, age group and occupation, we assemble the original meaning of the features as the description (e.g., this user is a male adult who is currently technician or engineer). For numerical features, which typically are the predicted values from the previous stage or statistics features like average rating scores, we directly articulate these features by combining their semantic interpretations and numerical values (e.g., the user has rated a range of movies with an average rating of 3.6). The user rating prediction instruction is designed to transfer the preference information from user/movie feature embeddings to its representation vector. In the output part of T\ud835\udc53\ud835\udc4e, the response for predicting user ratings is straightforwardly given as the rating score like he will rate this film 5 score. When constructing the input and output sentences for the LLM, we can train LLM4PR with such sentence pairs. Specifically, we freeze the LLM and train the parameters of the QIAs with the target of generating corresponding output sentence. We achieve this by maximizing the log likelihood for predicting target responses, and\nthe loss function can be formulated as \u2211\ufe01\n(4)\n\u2211\ufe01 where X\ud835\udc62and X\ud835\udc56represent the user and item feature embeddings, respectively. \ud835\udc66<\ud835\udc61indicates the tokens predicted in the previous \ud835\udc61\u22121 steps.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fef2/fef2cf15-68c5-46d0-b835-0c4b59eedb58.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(i) Illustration of the learning to post-rank step.   and  are the templates for the main task and auxiliary task, respectively.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/73fd/73fdb72a-dedb-4169-aece-af729f832128.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(ii) Take MovieLens dataset as example to illustrate the two task templates for the learning to post-rank step.</div>\n# 4.4 Learning to Post-rank Step\nLLMs are originally designed for general purposes and necessitate proper modifications to effectively address the post-ranking task. Therefore, we introduce a learning to post-rank step that trains the generative LLM4PR framework. We construct the input for the LLM and instruct it to generate a suitable order for candidate items, which serves as the main task. In addition, we further incorporate an auxiliary task that evaluates the qualities of two candidate lists via pairwise comparisons. The auxiliary task determines the superior list, and this auxiliary task serves as a simplified version for generating final post-ranking outcomes. The procedure of learning to post-rank step is described in Figure 4, QIA\ud835\udc62and QIA\ud835\udc56produce the user representation \ud835\udc52\ud835\udc62and item representation vector \ud835\udc52\ud835\udc56\ud835\udc57for item \ud835\udc57in candidates I, respectively. The representation vector for the \ud835\udc58-th item in user\u2019s history behaviors is denoted as \ud835\udc52\u210e\ud835\udc58. Two hybrid templates T\ud835\udc5a\ud835\udc4e\ud835\udc56\ud835\udc5b \ud835\udc5d\ud835\udc5f and T\ud835\udc4e\ud835\udc62\ud835\udc65 \ud835\udc5d\ud835\udc5f are proposed to implement the learning to post-rank step. According to Figure 4(ii), the input parts of both templates are comprised of query \ud835\udc5e, user \ud835\udc52\ud835\udc62,\nAlgorithm 1 LLM4PR Input: Parameters of QIA\ud835\udc62: \ud835\udf03\ud835\udc44\ud835\udc3c\ud835\udc34\ud835\udc62; Parameters of QIA\ud835\udc56: \ud835\udf03\ud835\udc44\ud835\udc3c\ud835\udc34\ud835\udc56; LoRA parameters: \ud835\udf03\ud835\udc3f\ud835\udc5c\ud835\udc45\ud835\udc34; Post-ranking dataset: D; Maximum iteration step: \ud835\udc471, \ud835\udc472 Output: Optimized learnable parameters // feature adaptation step 1: for \ud835\udc61= 0 to \ud835\udc471 \u22121 do 2: for sampled minibatch D\ud835\udc4f\ud835\udc4e\ud835\udc61\ud835\udc50\u210efrom D do 3: construct training data using T\ud835\udc53\ud835\udc4e 4: update \ud835\udf03\ud835\udc44\ud835\udc3c\ud835\udc34\ud835\udc62and \ud835\udf03\ud835\udc44\ud835\udc3c\ud835\udc34\ud835\udc56using Equation 4 5: end for 6: end for // learning to post-rank step 7: for \ud835\udc61= 0 to \ud835\udc472 \u22121 do 8: for sampled minibatch D\ud835\udc4f\ud835\udc4e\ud835\udc61\ud835\udc50\u210efrom D do 9: construct training data using T\ud835\udc4e\ud835\udc62\ud835\udc65 \ud835\udc5d\ud835\udc5f and T\ud835\udc5a\ud835\udc4e\ud835\udc56\ud835\udc5b \ud835\udc5d\ud835\udc5f 10: update \ud835\udf03\ud835\udc44\ud835\udc3c\ud835\udc34\ud835\udc62, \ud835\udf03\ud835\udc44\ud835\udc3c\ud835\udc34\ud835\udc56, and \ud835\udf03\ud835\udc3f\ud835\udc5c\ud835\udc45\ud835\udc34using Equation 5 11: end for 12: end for 13: return \ud835\udf03\ud835\udc44\ud835\udc3c\ud835\udc34\ud835\udc62, \ud835\udf03\ud835\udc44\ud835\udc3c\ud835\udc34\ud835\udc56, \ud835\udf03\ud835\udc3f\ud835\udc5c\ud835\udc45\ud835\udc34\ncandidates \ud835\udc52\ud835\udc56and history behaviors \ud835\udc52\u210e. In the auxiliary task template T\ud835\udc4e\ud835\udc62\ud835\udc65 \ud835\udc5d\ud835\udc5f , two randomly generated candidate lists, denoted by the letters I and II, are provided for each training sample, prompting the LLM to identify the superior option. The quality of the generated ranking list is assessed by Normalized Discounted Cumulative Gain (NDCG). As a result, the target response indicates the list that achieves a higher NDCG value. Regarding the main task template T\ud835\udc5a\ud835\udc4e\ud835\udc56\ud835\udc5b \ud835\udc5d\ud835\udc5f , it requires the LLM to post-rank all candidates. In this sense, the response to this instruction should be as plain as possible to simplify the generation process. Therefore, the output is formatted as a sequence of capital letters, with each letter symbolizing a specific item among the candidates. The final post-ranking list is determined by mapping letter A to \ud835\udc561 , letter B to \ud835\udc562 , and so forth. When training the LLM4PR, the main task and auxiliary task are combined to concurrently fine-tune the QIAs and LLM. However, fine-tuning all the parameters of the LLM is time-consuming and requires massive computational resources. To this end, we utilize LoRA[18], which brings a separate set of trainable parameters and keeps the pre-trained parameters of LLM frozen, to reduce the costs of fine-tuning. In our implementation, LoRA parameters are exclusively integrated into the projection parts within the selfattention modules of the LLM. We train the LLM4PR to predict the corresponding response using next-token prediction, which maximizes the log likelihood of the subsequent token. The loss function of this stage is represented as\n(5)\nwhere I and H\ud835\udc62represent the set of candidate items and history behavior items, respectively. \ud835\udc66<\ud835\udc61indicates the tokens predicted in the previous \ud835\udc61\u22121 steps.\n# 4.5 Training and Inference\nIn the training stage, the feature adaptation step and learning to post-rank step are performed sequentially, and the entire process for training LLM4PR is illustrated in Algo 1. In the inference stage, only T\ud835\udc5a\ud835\udc4e\ud835\udc56\ud835\udc5b \ud835\udc5d\ud835\udc5f is utilized to construct the inputs for the LLM, which instructs the LLM to generate the post-ranking list. The final postranking results are obtained by decoding the generated sequence produced by the LLM4PR.\n# 5 EXPERIMENTS\n<div style=\"text-align: center;\">Table 1: Statistics of the datasets.</div>\nDataset\n#Users\n#Items\n#Queries\n#Actions\nCovid\n-\n171,000\n50\n-\nNFCorpus\n-\n3,600\n323\n-\nTouche\n-\n382,000\n49\n-\nDBPedia\n-\n4,630,000\n400\n-\nSciFact\n-\n5,000\n300\n-\nSignal\n-\n2,860,000\n97\n-\nNews\n-\n595,000\n57\n-\nRobust04\n-\n528,000\n249\n-\nMovieLens-1M\n6,040\n3,883\n-\n1,000,209\nKuaiSAR(Search Part)\n25,877\n3,026,189\n453,667\n5,059,169\n# 5.1 Experiment Settings\n5.1.1 Datasets. To validate the post-ranking performance of the proposed LLM4PR, we conduct experiments on two kinds of datasets information retrieval dataset and search dataset. For the information retrieval dataset, we select several sub-datasets from the BEIR dataset[45], which contain only pure text feature. Moreover, we select MovieLens-1M[16] and KuaiSAR[44] as the search datasets. Both datasets contain heterogeneous features and are modified to adapt the search post-ranking scenario. It is also noted that the KuaiSAR dataset is an industrial dataset collected from the Kuaishou App, the second largest short-video platform in China. The statistics of the datasets are shown in Table 1. To adapt MovieLens-1M for the post-ranking scenario, following [13], we sort movies in ascending order based on the timestamp for each user, and split the rating sequence into segments with a size of 5. The target post-ranking list is the movies arranged in descending order based on their rating scores. Considering LLM4PR is designed the search scenario, we allocate a pseudo search query, such as what to watch or movie recommendations, for each segment. For KuaiSAR dataset, we conduct experiments on the search part of KuaiSAR, treating the items in each search session as candidates for postranking. To leverage the textual information, which is encrypted in this dataset, we have contacted the authors and acquired the raw data.\n5.1.2 Baselines. For the information retrieval dataset, we compare LLM4PR with several state-of-the-art (SOTA) passage ranking methods. The baselines include monoBERT[32], monoT5[31], and Cohere Rerank[40]. For the search dataset, we compare LLM4PR with LTR methods, conventional post-ranking methods, and LLM-based approaches. Specifically, we choose the LTR-DNN and LTR-DCN as the LTR baselines. For conventional post-ranking methods, we\n<div style=\"text-align: center;\">Table 2: Evaluation results (NDCG@10) on the information retrieval task. Bold indicates the best results.  table are presented as percentages (%).</div>\n<div style=\"text-align: center;\">Table 2: Evaluation results (NDCG@10) on the information retrieval task. Bold indicates the best results. The values in th</div>\n<div style=\"text-align: center;\">Table 2: Evaluation results (NDCG@10) on the information retrieval task. Bold indicates the best results. The values in th table are presented as percentages (%).</div>\nable are presented as percentages (%).\nMethod\nCovid\nNFCorpus\nTouche\nDBPedia\nSciFact\nSignal\nNews\nRobust04\nBEIR(Avg)\nBM25\n59.47\n30.75\n44.22\n31.80\n67.89\n33.05\n39.52\n40.70\n43.42\nmonoBERT(340M)\n70.01\n36.88\n31.75\n41.87\n71.36\n31.44\n44.62\n49.35\n47.16\nmonoT5(220M)\n78.34\n37.38\n30.82\n42.42\n73.40\n31.67\n46.83\n51.72\n49.01\nmonoT5(3B)\n80.71\n38.97\n32.41\n44.45\n76.57\n32.55\n48.49\n56.71\n51.36\nCohere Rerank-v2\n81.81\n36.36\n32.51\n42.51\n74.44\n29.60\n47.59\n50.78\n49.45\nLLM4PR(7B)\n83.75\n38.18\n36.83\n46.35\n74.77\n33.86\n49.85\n57.28\n52.61\n<div style=\"text-align: center;\">Table 3: Evaluation results on the search post-ranking task. Bold indicates the best r as percentages (%).</div>\nn results on the search post-ranking task. Bold indicates the best results. The values in the table are presented\ns percentages (%).\nDataset\u2192\nMovieLens-1M\nKuaiSAR\nModel\u2193\nNDCG@3\nNDCG@5\nMRR@3\nMRR@5\nNDCG@3\nNDCG@5\nNDCG@10\nMRR@3\nMRR@5\nMRR@10\nLTR-DNN\n63.30\n77.59\n42.71\n50.14\n63.52\n68.80\n83.06\n43.33\n47.32\n50.05\nLTR-DCN\n70.21\n80.91\n50.92\n56.18\n64.33\n69.37\n83.84\n45.35\n49.37\n51.75\nDLCM\n71.21\n81.33\n52.17\n57.15\n64.93\n69.73\n84.06\n47.29\n50.99\n53.31\nSeq2Slate\n73.47\n82.18\n55.15\n59.14\n65.17\n70.19\n84.22\n47.40\n51.02\n53.46\nSetRank\n73.49\n82.39\n55.89\n60.03\n65.39\n70.23\n84.34\n47.54\n51.38\n53.55\nPRS\n75.71\n83.61\n57.06\n60.90\n65.68\n70.74\n84.96\n47.86\n51.61\n53.72\nChatGPT4RS\n65.07\n77.50\n48.16\n54.11\n55.55\n61.08\n79.79\n17.88\n23.35\n29.46\nLLaRA\n72.64\n81.98\n55.32\n60.17\n64.86\n69.94\n84.37\n47.13\n50.89\n53.22\nPTPR\n71.63\n81.43\n57.60\n61.63\n65.27\n70.05\n84.58\n47.35\n50.57\n53.08\nLLM4PR(Ours)\n76.94\n84.35\n61.77\n65.15\n66.81\n71.96\n84.91\n48.31\n52.75\n54.92\nDataset\u2192\nMovieLens-1M\nKuaiSAR\nModel\u2193\nNDCG@3\nNDCG@5\nMRR@3\nMRR@5\nNDCG@3\nNDCG@5\nNDCG@10\nMRR@3\nMRR@5\nMRR@10\nLLM4PR\n76.94\n84.35\n61.77\n65.15\n66.81\n71.96\n84.91\n48.31\n52.75\n54.92\nw/o QIA\n76.81\n84.28\n61.66\n64.88\n65.54\n70.47\n84.24\n47.97\n51.45\n53.58\nw/o FA\n75.45\n83.68\n60.85\n64.06\n64.90\n69.26\n83.31\n45.56\n48.03\n49.70\nw/o AT\n75.98\n84.07\n61.31\n64.28\n65.05\n69.67\n83.78\n47.20\n50.48\n52.84\nselect DLCM[2], Seq2Slate[4], SetRank[34], and PRS[13] for comparisons. For LLM-based benchmark, we select ChatGPT4RS[9] and LLaRA[25] as alternatives. For ChatGPT4RS, we select the list-wise template to implement the post-ranking task. For LLaRA, we input all the candidate items into model, and the model chooses one item each time. Subsequently, the selected item is eliminated from candidates and the procedure is repeated for the remaining items until the ultimate list is acquired. Furthermore, as discussed in Section 4.2, we combine all features into a single sentence as input for the LLM and train it using post-ranking targets. This alternative is referred to as \u2018Pure Text Post-Ranking model\u2019 (PTPR).\n5.1.3 Evaluation Metrics. For the information retrieval task, following [43], we utilize NDCG@10 to evaluate the retrieval performance. For the search post-ranking task, we use NDCG@k and MRR@k as the evaluation metrics.\n5.1.4 Implementation Details. For the information retrieval dataset, following [43], BM25 is used to retrieve the top 100 candidate\npassages. To simulate the post-ranking scenario, a pre-trained Sentence-BERT[39] is used as the ranking model and obtain the passage embeddings. In the post-ranking stage, we utilize LLaMA27B[47] as the backbone for LLM4PR. Following [43], our LLM4PR model is trained on the MS MARCO dataset[30] and evaluated on the sub-datasets of BEIR[45]. For the search dataset, the initial ranking lists and feature embeddings are produced by a DNN model[8], which serves as the ranking stage. The DNN leverages pre-trained BERT[11] to process the textual features. We utilize LLaMA2-7B[47] as the backbone for LLM4PR on the MovieLens dataset and Baichuan2-7B[51] on the KuaiSAR dataset. For both tasks, The hidden size\ud835\udc51\u210efor QIA is set to 512. We employ AdamW[27] with learning rate annealing from 1e-3 to 1e-6 to optimize the trainable parameters for both the feature adaptation step and the learning to post-rank step. Furthermore, we implement a linear warm-up strategy during the initial 10% of all iterations. LoRA[18] is integrated into [q_proj,k_proj] and [W_pack] modules for LLaMA2 and Baichuan2, respectively. The parameters for LoRA, including\nrank, alpha, and dropout, are configured as 32, 32, and 0.1, respectively. All experiments are conducted on machines equipped with 8\u00d7 NVIDIA A100 GPUs, with a batch size set to 5 for each GPU. All experiments are repeated 10 times, and the average values are reported below.\nFor the information retrieval dataset, the evaluation results are reported in Table 2. As shown in the table, the proposed LLM4PR achieves the best average results (Best performances in 5 out of 8 sub-datasets, and ranking second in the remaining 3 sub-datasets), which fully demonstrate the superiority of the proposed method. Moreover, the model is trained with the MS MARCO dataset and evaluated on the BEIR dataset, verifying its remarkable transferability and generalization capability. For the search dataset, the evaluation results are reported in Table 3. We can see that, the proposed LLM4PR outperforms the baselines in most metrics in both datasets. For the NDCG@10 metric in the KuaiSAR dataset, the performance of LLM4PR is also close to the best results of PRS. Moreover, the ChatGPT4RS merely feeds query and item texts into LLM without specific adaptation to the post-ranking task, leading to an inferior performance, indicating that generically pre-trained LLMs have limited capabilities for postranking. Additionally, the proposed LLM4PR achieves better results than other fine-tuned LLM-based methods, such as LLaRA and PTPR, demonstrating the superiority of our method.\n# 5.3 Ablation Studies\nIn LLM4PR, we propose the QIA component and various tasks to address the post-ranking challenge. To explore the influence of these components in LLM4PR, we conduct ablation studies on the datasets and report the results in Table 4. QIA. QIA utilizes the attention mechanism to combine the multiple feature embeddings. We substitute it with DNN and report the results as w/o QIA in Table 4. For the MovieLens-1M dataset, all metrics show a slight average decrease of 0.14% in both NDCG and MRR. Since the search queries in MovieLens-1M dataset are synthetic and may convey limited information on user requirements, it is reasonable that replacing the QIA does not significantly affect the overall performance. In contrast, the KuaiSAR dataset is a real-world dataset in the search scenario, encompassing authentic search queries for diverse requests. In this context, the decline extended to an average of 1.14% for NDCG and 0.99% for MRR, which verifies the importance of QIA and usefulness of integrating feature embeddings guided by the search query. Feature Adaptation (FA). The FA step is designed to align the user/item representation embeddings with the LLM. To evaluate the impact of this step, we exclude the FA step and train the LLM4PR directly on the post-ranking task. The results are presented as w/o FA in Table 4. As shown in the table, the performance of our model degrades significantly after removing the FA step. Specifically, in the MovieLens-1M dataset, the average NDCG decreases by 1.08%, and the MRR decreases by 1.00%. Similarly, the KuaiSAR dataset exhibits a notable average decrease of 2.07% in NDCG and 4.23% in MRR. Therefore, removing the feature adaptation step notably affects the post-ranking performance, underscoring the indispensableness\nof FA step and confirming the significance of injecting semantic meanings into the representation embeddings through alignment with the LLM. Auxiliary Task (AT). The AT aims to equip the model with the ability to identify the superior list order. We assess its effectiveness by removing the auxiliary task from the training stage and report the results as w/o AT in Table 4. Particularly, the NDCG and MRR decrease for both datasets, which indicates that the auxiliary task positively contributes to enhancing the post-ranking performance.\n# 5.4 Further Analysis\n5.4.1 Feature Embeddings with Different Qualities. The LLM4PR utilizes the feature embeddings obtained from the previous stage (i.e., ranking stage). We explore how feature embeddings with different qualities influence the post-ranking performance. We extract embeddings from various stages of the training phase of the ranking model (i.e., the DNN model), denoted as Poor Quality (PQ, validation ranking AUC score of 0.5), Medium Quality (MQ, validation ranking AUC score of 0.7), and High Quality (HQ, validation ranking AUC score exceeding 0.85). We utilize these embeddings to train the LLM4PR and present the results in Table 5. As shown in the table, the post-ranking performance consistently declines from high-quality to poor-quality embeddings, indicating that highquality embeddings facilitate the learning to post-rank process for LLM4PR. We also find that even with poor-quality or mediumquality embeddings, LLM4PR is capable of delivering competitive results. In this context, the QIA component functions akin to an \u201cembedding layer\u201d. The low-quality embeddings serve as the initialization, and during the training process, the QIA learns to map these low-quality vectors to meaningful embeddings for the LLM. Therefore, our model exhibits favorable compatibility for the input embeddings.\n5.4.2 Inference Time Cost. As we mentioned in Section 4.2, directly concatenating all features into a single sentence as input for LLM would significantly increase the inference time cost. To verify this statement, we compare the inference time costs of PTPR and LLM4PR, with the results presented in Table 6. As shown in the table, the input tokens for PTPR, which simply concatenates all features into a single sentence, are 9 and 23 times greater than those for LLM4PR in MovieLens and KuaiSAR datasets, respectively. Consequently, the inference time cost for PTPR is 1.7 and 3.0 times higher than that of LLM4PR, respectively. The increase in token length primarily comes from the numerical features. For instance, one movie item in the MovieLens dataset has a feature named \u2018history average rating\u2019 with a value of 0.5. In LLM4PR, the rating value is converted into an embedding and serves as only one input token for the LLM. However, for PTPR, the same feature is input as plain text, \u2018history average rating is 0.5\u2019, which will be tokenized into 8 tokens (\u2019_history\u2019, \u2018_average\u2019, \u2018_rating\u2019, \u2018_is\u2019, \u2018_\u2019, \u20180\u2019, \u2018.\u2019, \u20185\u2019). Thus, the proposed LLM4PR can efficiently processes diverse input features.\n5.4.3 Backbone LLM with Different Sizes. To evaluate the impact of the backbone LLM size, we substitute the 7B LLM with different language models and provide the post-ranking performance in Figure 5. As shown in this Figure, the post-ranking performances\n<div style=\"text-align: center;\">Table 5: Evaluation results of LLM4PR with feature embeddings of varying qualities. Bold indicates the best results. HQ, MQ, and PQ represent feature embeddings of High Quality, Medium Quality, and Poor Quality, respectively.</div>\nDataset\u2192\nMovieLens-1M\nKuaiSAR\nModel\u2193\nNDCG@3\nNDCG@5\nMRR@3\nMRR@5\nNDCG@3\nNDCG@5\nNDCG@10\nMRR@3\nMRR@5\nMRR@10\nLLM4PR-HQ\n76.94\n84.35\n61.77\n65.15\n66.81\n71.96\n84.91\n48.31\n52.75\n54.92\nLLM4PR-MQ\n76.84\n84.19\n61.60\n64.83\n65.89\n71.22\n84.88\n47.83\n51.81\n54.26\nLLM4PR-PQ\n76.43\n83.96\n61.23\n64.53\n65.27\n70.05\n84.58\n47.35\n50.57\n53.08\nTable 6: Inference Time Cost. The Token column indicates the input token length and the Cost column represents the\nTable 6: Inference Time Cost. The Token column indicates the input token length and the Cost column represents the inference time.\nDataset\u2192\nMovieLens-1M\nKuaiSAR\nModel\u2193\nTokens\nCost(ms)\nTokens\nCost(ms)\nPTPR\n772\n556\n2135\n1525\nLLM4PR\n80\n318\n92\n501\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e481/e4819c96-cc42-4fd8-bb9b-4a8e309550b7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 5: Post-ranking performance comparison w.r.t. different sizes of backbone language models.</div>\nconsistently improve with the increasing size of backbone models. This is consistent with the intuition that larger LLMs are inherently more powerful than smaller ones. However, when the model size reaches a sufficiently large scale, such as 7B, further enlarging the model size yields only marginal improvements. Therefore, to strike a balance between the training burden and overall performance, selecting a 7B version LLM as the backbone is a practical choice.\n<div style=\"text-align: center;\">Table 7: Feature embedding alignment performance of the feature adaptation step for the MovieLens-1M dataset. Acc represents the accuracy.</div>\nFeatures\nAcc (%)\nAuc (%)\nCategorical Features\n100\n-\nNumerical Features\n99.89\n-\nScore Predictions\n48.70\n64.78\n5.4.4 Feature Adaptation Analysis. In this subsection, we validate the feature adaptation step and analyze its prediction results. We\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e94b/e94b0a7f-c64d-40bc-be7f-097304a32e70.png\" style=\"width: 50%;\"></div>\nFigure 6: Example of the input and output from the feature adaptation step. Yellow, blue, and green indicate the predicted categorical features (e.g., gender, age, and occupation, etc), numerical features (e.g., average rating scores, etc), and rating score, respectively.\nutilize the template T\ud835\udc53\ud835\udc4e(shown in Figure 6) to generate the outputs, which include predicting categorical feature, numerical feature and rating scores. The generation results are evaluated accuracy and AUC values for the predicted features and rating scores, and the results are reported in Table 7. We observe that the LLM achieves exceptionally high accuracy scores for both categorical and numerical features, illustrating that the feature adaptation step successfully incorporates semantic meanings into the user/item representation vectors. Moreover, the LLM achieves 48.70% accuracy score and 64.78% AUC score for the rating score prediction, which is a 5-class classification task in MoiveLen-1M dataset. This demonstrates that the generated user/item representation vectors also encapsulate the user preference information, which is beneficial for learning to post-rank.\n# 6 CONCLUSION\nIn this paper, we introduce LLM4PR, the first LLM-based postranking framework designed for search engines. We introduce a QIA component to fuse heterogeneous features of users and items, and a feature adaptation step to align the user/item embeddings with the LLM. Furthermore, we leverage both the main and auxiliary tasks to fine-tune the model for learning post-ranking. The extensive experiments on multiple datasets fully demonstrate the effectiveness and superiority of our proposed LLM4PR.\n# REFERENCES\n[1] Mustafa Abdool, Malay Haldar, Prashant Ramanathan, Tyler Sax, Lanbo Zhang, Aamir Manaswala, Lynn Yang, Bradley C. Turnbull, Qing Zhang, and Thomas Legrand. 2020. Managing Diversity in Airbnb Search. In KDD \u201920: The 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event, CA, USA, August 23-27, 2020, Rajesh Gupta, Yan Liu, Jiliang Tang, and B. Aditya\n1] Mustafa Abdool, Malay Haldar, Prashant Ramanathan, Tyler Sax, Lanbo Zhang, Aamir Manaswala, Lynn Yang, Bradley C. Turnbull, Qing Zhang, and Thomas Legrand. 2020. Managing Diversity in Airbnb Search. In KDD \u201920: The 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event, CA, USA, August 23-27, 2020, Rajesh Gupta, Yan Liu, Jiliang Tang, and B. Aditya\nPrakash (Eds.). ACM, 2952\u20132960. [2] Qingyao Ai, Keping Bi, Jiafeng Guo, and W. Bruce Croft. 2018. Learning a Deep Listwise Context Model for Ranking Refinement. In Proceedings of the 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. 135\u2013144. [3] Qingyao Ai, Xuanhui Wang, Sebastian Bruch, Nadav Golbandi, Michael Bendersky, and Marc Najork. 2019. Learning Groupwise Multivariate Scoring Functions Using Deep Neural Networks. In Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval. 85\u201392. [4] Irwan Bello, Sayali Kulkarni, Sagar Jain, Craig Boutilier, Ed Huai-hsin Chi, Elad Eban, Xiyang Luo, Alan Mackey, and Ofer Meshi. 2018. Seq2Slate: Re-ranking and Slate Optimization with RNNs. CoRR abs/1810.02019. arXiv:1810.02019 [5] Luiz Henrique Bonifacio, Hugo Queiroz Abonizio, Marzieh Fadaee, and Rodrigo Frassetto Nogueira. 2022. InPars: Data Augmentation for Information Retrieval using Large Language Models. CoRR abs/2202.05144 (2022). arXiv:2202.05144 [6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual. [7] Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, and Jong C. Park. 2023. Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker. In Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023. Association for Computational Linguistics, 960\u2013971. [8] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems, Boston, MA, USA, September 15-19, 2016. ACM, 191\u2013198. [9] Sunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao Zhang, and Jun Xu. 2023. Uncovering ChatGPT\u2019s Capabilities in Recommender Systems. In Proceedings of the 17th ACM Conference on Recommender Systems, RecSys 2023, Singapore, Singapore, September 18-22, 2023. ACM, 1126\u20131132. [10] Zhuyun Dai, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall, and Ming-Wei Chang. 2023. Promptagator: Few-shot Dense Retrieval From 8 Examples. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net. [11] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers). Association for Computational Linguistics, 4171\u20134186. [12] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. GLM: General Language Model Pretraining with Autoregressive Blank Infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022. Association for Computational Linguistics, 320\u2013335. [13] Yufei Feng, Yu Gong, Fei Sun, Qingwen Liu, and Wenwu Ou. 2021. Revisit Recommender System in the Permutation Prospective. CoRR abs/2102.12057 (2021). arXiv:2102.12057 [14] Yufei Feng, Binbin Hu, Yu Gong, Fei Sun, Qingwen Liu, and Wenwu Ou. 2021. GRN: Generative Rerank Network for Context-wise Recommendation. In arXiv preprint arXiv:2104.00860. [15] Yu Gong, Ziwen Jiang, Yufei Feng, Binbin Hu, Kaiqi Zhao, Qingwen Liu, and Wenwu Ou. 2020. EdgeRec: Recommender System on Edge in Mobile Taobao. In CIKM \u201920: The 29th ACM International Conference on Information and Knowledge Management, Virtual Event, Ireland, October 19-23, 2020. ACM, 2477\u20132484. [16] F. Maxwell Harper and Joseph A. Konstan. 2016. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst. 5, 4 (2016), 19:1\u201319:19. [17] Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos, Dietmar Jannach, and Marios Fragkoulis. 2023. Leveraging Large Language Models for Sequential Recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems, RecSys 2023, Singapore, Singapore, September 18-22, 2023. ACM, 1096\u20131102. [18] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-Rank Adaptation of Large Language Models. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net. [19] Guangda Huzhang, Zhen-Jia Pang, Yongqing Gao, Yawen Liu, Weijie Shen, Wen-Ji Zhou, Qianying Lin, Qing Da, Anxiang Zeng, Han Yu, Yang Yu, and Zhi-Hua Zhou. 2023. AliExpress Learning-to-Rank: Maximizing Online Model Performance\nWithout Going Online. IEEE Trans. Knowl. Data Eng. 35, 2 (2023), 1214\u20131226. [20] Vitor Jeronymo, Luiz Henrique Bonifacio, Hugo Queiroz Abonizio, Marzieh Fadaee, Roberto de Alencar Lotufo, Jakub Zavrel, and Rodrigo Frassetto Nogueira. 2023. InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval. CoRR abs/2301.01820 (2023). https://doi.org/10.48550/ ARXIV.2301.01820 arXiv:2301.01820 [21] Ray Jiang, Sven Gowal, Yuqiu Qian, Timothy A. Mann, and Danilo J. Rezende. 2019. Beyond Greedy Ranking: Slate Optimization via List-CVAE. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net. [22] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020. Association for Computational Linguistics, 7871\u20137880. [23] Xinhang Li, Chong Chen, Xiangyu Zhao, Yong Zhang, and Chunxiao Xing. 2023. E4SRec: An Elegant Effective Efficient Extensible Solution of Large Language Models for Sequential Recommendation. CoRR abs/2312.02443 (2023). https: //doi.org/10.48550/ARXIV.2312.02443 arXiv:2312.02443 [24] Jiayi Liao, Sihang Li, Zhengyi Yang, Jiancan Wu, Yancheng Yuan, and Xiang Wang. 2023. LLaRA: Aligning Large Language Models with Sequential Recommenders. CoRR abs/2312.02445 (2023). https://doi.org/10.48550/ARXIV.2312. 02445 arXiv:2312.02445 [25] Jiayi Liao, Sihang Li, Zhengyi Yang, Jiancan Wu, Yancheng Yuan, Xiang Wang, and Xiangnan He. 2024. Llara: Large language-recommendation assistant. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. 1785\u20131795. [26] Weiwen Liu, Yunjia Xi, Jiarui Qin, Fei Sun, Bo Chen, Weinan Zhang, Rui Zhang, and Ruiming Tang. 2022. Neural Re-ranking in Multi-stage Recommender Systems: A Review. In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence (IJCAI-22) Survey Track. [27] Ilya Loshchilov and Frank Hutter. 2019. Decoupled Weight Decay Regularization. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net. [28] Xueguang Ma, Liang Wang, Nan Yang, Furu Wei, and Jimmy Lin. 2023. FineTuning LLaMA for Multi-Stage Text Retrieval. CoRR abs/2310.08319 (2023). https://doi.org/10.48550/ARXIV.2310.08319 arXiv:2310.08319 [29] Xueguang Ma, Xinyu Zhang, Ronak Pradeep, and Jimmy Lin. 2023. Zero-Shot Listwise Document Reranking with a Large Language Model. CoRR abs/2305.02156 (2023). https://doi.org/10.48550/ARXIV.2305.02156 arXiv:2305.02156 [30] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. 2016. MS MARCO: A Human Generated MAchine Reading COmprehension Dataset. In CoCo@NIPS (CEUR Workshop Proceedings, Vol. 1773). CEUR-WS.org. [31] Rodrigo Nogueira, Zhiying Jiang, Ronak Pradeep, and Jimmy Lin. 2020. Document Ranking with a Pretrained Sequence-to-Sequence Model. In Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, 708\u2013718. [32] Rodrigo Frassetto Nogueira and Kyunghyun Cho. 2019. Passage Re-ranking with BERT. CoRR abs/1901.04085 (2019). [33] OpenAI. 2023. GPT-4 Technical Report. CoRR abs/2303.08774 (2023). https: //doi.org/10.48550/ARXIV.2303.08774 arXiv:2303.08774 [34] Liang Pang, Jun Xu, Qingyao Ai, Yanyan Lan, Xueqi Cheng, and Jirong Wen. 2020. SetRank: Learning a Permutation-Invariant Ranking Model for Information Retrieval. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020. ACM, 499\u2013508. [35] Changhua Pei, Yi Zhang, Yongfeng Zhang, Fei Sun, Xiao Lin, Hanxiao Sun, Jian Wu, Peng Jiang, and Wenwu Ou. 2019. Personalized re-ranking for recommendation. In Proceedings of the 13th ACM Conference on Recommender Systems. 3\u201311. [36] Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, Xuanhui Wang, and Michael Bendersky. 2023. Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting. CoRR abs/2306.17563 (2023). https://doi.org/10.48550/ARXIV.2306. 17563 arXiv:2306.17563 [37] Junyan Qiu, Haitao Wang, Zhaolin Hong, Yiping Yang, Qiang Liu, and Xingxing Wang. 2023. ControlRec: Bridging the Semantic Gap between Language Model and Personalized Recommendation. CoRR abs/2311.16441 (2023). https://doi.org/ 10.48550/ARXIV.2311.16441 arXiv:2311.16441 [38] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. J. Mach. Learn. Res. 21 (2020), 140:1\u2013140:67. [39] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In EMNLP/IJCNLP (1). Association for Computational Linguistics, 3980\u20133990.\n[40] Nils Reimers, Sylvie Shi, Lucas Fayoux, and Elliott Choi. 2023. Say Goodbye to Irrelevant Search Results: Cohere Rerank Is Here. https://cohere.com/blog/ rerank. [41] Devendra Singh Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. 2022. Improving Passage Retrieval with Zero-Shot Question Generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022. Association for Computational Linguistics, 3781\u2013 3797. [42] Xiaowen Shi, Fan Yang, Ze Wang, Xiaoxu Wu, Muzhi Guan, Guogang Liao, Yongkang Wang, Xingxing Wang, and Dong Wang. 2023. PIER: Permutation-Level Interest-Based End-to-End Re-ranking Framework in E-commerce. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023. ACM, 4823\u20134831. [43] Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, and Zhaochun Ren. 2023. Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023. Association for Computational Linguistics, 14918\u201314937. [44] Zhongxiang Sun, Zihua Si, Xiaoxue Zang, Dewei Leng, Yanan Niu, Yang Song, Xiao Zhang, and Jun Xu. 2023. KuaiSAR: A Unified Search And Recommendation Dataset. In CIKM. ACM, 5407\u20135411. [45] Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Abhishek Srivastava, and Iryna Gurevych. 2021. BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks, J. Vanschoren and S. Yeung (Eds.), Vol. 1. https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/ 2021/file/65b9eea6e1cc6bb9f0cd2a47751a186f-Paper-round2.pdf [46] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aur\u00e9lien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models. CoRR abs/2302.13971 (2023). https://doi.org/10.48550/ARXIV.2302.13971 arXiv:2302.13971 [47] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aur\u00e9lien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. CoRR abs/2307.09288 (2023). https://doi.org/10.48550/ARXIV.2307.09288 arXiv:2307.09288 [48] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA. 5998\u20136008. [49] Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei. 2024. Improving Text Embeddings with Large Language Models. CoRR abs/2401.00368 (2024). https://doi.org/10.48550/ARXIV.2401.00368 arXiv:2401.00368 [50] Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, Hui Xiong, and Enhong Chen. 2023. A Survey on Large Language Models for Recommendation. CoRR abs/2305.19860 (2023). https://doi.org/10.48550/ARXIV.2305.19860 arXiv:2305.19860 [51] Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, and Zhiying Wu. 2023. Baichuan 2: Open Large-scale Language Models. CoRR abs/2309.10305 (2023). https: //doi.org/10.48550/ARXIV.2309.10305 arXiv:2309.10305 [52] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang,\n[40] Nils Reimers, Sylvie Shi, Lucas Fayoux, and Elliott Choi. 2023. Say Goodbye to Irrelevant Search Results: Cohere Rerank Is Here. https://cohere.com/blog/ rerank. [41] Devendra Singh Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. 2022. Improving Passage Retrieval with Zero-Shot Question Generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022. Association for Computational Linguistics, 3781\u2013 3797. [42] Xiaowen Shi, Fan Yang, Ze Wang, Xiaoxu Wu, Muzhi Guan, Guogang Liao, Yongkang Wang, Xingxing Wang, and Dong Wang. 2023. PIER: Permutation-Level Interest-Based End-to-End Re-ranking Framework in E-commerce. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023. ACM, 4823\u20134831. [43] Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, and Zhaochun Ren. 2023. Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023. Association for Computational Linguistics, 14918\u201314937. [44] Zhongxiang Sun, Zihua Si, Xiaoxue Zang, Dewei Leng, Yanan Niu, Yang Song, Xiao Zhang, and Jun Xu. 2023. KuaiSAR: A Unified Search And Recommendation Dataset. In CIKM. ACM, 5407\u20135411. [45] Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Abhishek Srivastava, and Iryna Gurevych. 2021. BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks, J. Vanschoren and S. Yeung (Eds.), Vol. 1. https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/ 2021/file/65b9eea6e1cc6bb9f0cd2a47751a186f-Paper-round2.pdf [46] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aur\u00e9lien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models. CoRR abs/2302.13971 (2023). https://doi.org/10.48550/ARXIV.2302.13971 arXiv:2302.13971 [47] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aur\u00e9lien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. CoRR abs/2307.09288 (2023). https://doi.org/10.48550/ARXIV.2307.09288 arXiv:2307.09288 [48] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA. 5998\u20136008. [49] Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei. 2024. Improving Text Embeddings with Large Language Models. CoRR abs/2401.00368 (2024). https://doi.org/10.48550/ARXIV.2401.00368 arXiv:2401.00368 [50] Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, Hui Xiong, and Enhong Chen. 2023. A Survey on Large Language Models for Recommendation. CoRR abs/2305.19860 (2023). https://doi.org/10.48550/ARXIV.2305.19860 arXiv:2305.19860 [51] Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, and Zhiying Wu. 2023. Baichuan 2: Open Large-scale Language Models. CoRR abs/2309.10305 (2023). https: //doi.org/10.48550/ARXIV.2309.10305 arXiv:2309.10305 [52] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang,\nZikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A Survey of Large Language Models. CoRR abs/2303.18223 (2023). https://doi.org/10.48550/ARXIV. 2303.18223 arXiv:2303.18223 [53] Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen. 2023. Large Language Models for Information Retrieval: A Survey. CoRR abs/2308.07107 (2023). https: //doi.org/10.48550/ARXIV.2308.07107 arXiv:2308.07107 [54] Honglei Zhuang, Zhen Qin, Kai Hui, Junru Wu, Le Yan, Xuanhui Wang, and Michael Bendersky. 2023. Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels. CoRR abs/2310.14122 (2023). https: //doi.org/10.48550/ARXIV.2310.14122 arXiv:2310.14122 [55] Tao Zhuang, Wenwu Ou, and Zhirong Wang. 2018. Globally Optimized Mutual Influence Aware Ranking in E-Commerce Search. In Proceedings of the TwentySeventh International Joint Conference on Artificial Intelligence, IJCAI 2018, July 13-19, 2018, Stockholm, Sweden. ijcai.org, 3725\u20133731.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of enhancing the post-ranking stage in search engines using large language models (LLMs). Previous methods primarily focused on matching and ranking stages, neglecting the post-ranking process, which is crucial for maximizing user satisfaction and engagement.",
        "problem": {
            "definition": "The problem is the lack of effective methods for optimizing the post-ranking stage in search engines, which is essential for improving user experience by considering various user and item attributes beyond simple relevance.",
            "key obstacle": "The main difficulty lies in the heterogeneous nature of input features for post-ranking, which current LLMs struggle to process effectively due to their design for semantic text input only."
        },
        "idea": {
            "intuition": "The idea is inspired by the successful integration of LLMs in various applications and the recognition that the post-ranking stage can significantly benefit from these advanced models.",
            "opinion": "The proposed method, LLM4PR, aims to leverage LLMs to refine the ranking of search results by incorporating user and item representations more effectively.",
            "innovation": "LLM4PR introduces a Query-Instructed Adapter (QIA) to align heterogeneous features and a learning to post-rank step that combines both main and auxiliary tasks, marking a significant advancement over existing methods."
        },
        "method": {
            "method name": "Large Language Models for Post-Ranking (LLM4PR)",
            "method abbreviation": "LLM4PR",
            "method definition": "LLM4PR is a framework that utilizes LLMs to enhance the post-ranking process in search engines by integrating diverse user and item features and optimizing the ranking order based on user preferences.",
            "method description": "The method integrates heterogeneous feature representations into LLMs to improve the accuracy and relevance of post-ranking results.",
            "method steps": [
                "Input query and user/item features into the Query-Instructed Adapter (QIA).",
                "Generate user/item representation vectors.",
                "Align the representations with LLM semantics through a feature adaptation step.",
                "Train the model using both main and auxiliary tasks to refine the post-ranking order."
            ],
            "principle": "The method is effective due to its ability to integrate diverse feature types and leverage the generative capabilities of LLMs to produce optimized ranking results that enhance user satisfaction."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted on multiple datasets, including information retrieval and search datasets, with comparisons against state-of-the-art methods and baseline models.",
            "evaluation method": "Performance was assessed using metrics like NDCG@k and MRR@k, with detailed analysis provided through ablation studies to evaluate the impact of various components of the LLM4PR framework."
        },
        "conclusion": "The experiments demonstrated that LLM4PR significantly improves post-ranking performance, achieving state-of-the-art results across various datasets and confirming its effectiveness in enhancing user experience in search engines.",
        "discussion": {
            "advantage": "The key advantages of LLM4PR include its ability to effectively combine heterogeneous features and its innovative use of LLMs for generating optimized search results.",
            "limitation": "One limitation of the method is its reliance on high-quality input features; poor-quality embeddings can negatively impact performance.",
            "future work": "Future research could focus on improving feature quality and exploring additional tasks or architectures that further enhance the post-ranking process."
        },
        "other info": {
            "info1": "The framework is the first of its kind to apply LLMs specifically to the post-ranking stage of search engines.",
            "info2": {
                "info2.1": "The QIA component utilizes attention mechanisms to merge user/item features.",
                "info2.2": "The feature adaptation step aligns representations with LLM input requirements."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.2",
            "key information": "The paper highlights the contribution of large language models (LLMs) in enhancing the post-ranking stage of search engines, which is crucial for maximizing user satisfaction and engagement."
        },
        {
            "section number": "4.1",
            "key information": "LLM4PR is a framework that utilizes LLMs to enhance the post-ranking process in search engines by integrating diverse user and item features and optimizing the ranking order based on user preferences."
        },
        {
            "section number": "4.2",
            "key information": "The method integrates heterogeneous feature representations into LLMs to improve the accuracy and relevance of post-ranking results."
        },
        {
            "section number": "8",
            "key information": "The framework is the first of its kind to apply LLMs specifically to the post-ranking stage of search engines, marking a significant advancement over existing methods."
        },
        {
            "section number": "10.1",
            "key information": "One limitation of the LLM4PR method is its reliance on high-quality input features; poor-quality embeddings can negatively impact performance."
        },
        {
            "section number": "10.2",
            "key information": "Future research could focus on improving feature quality and exploring additional tasks or architectures that further enhance the post-ranking process."
        }
    ],
    "similarity_score": 0.7620758175883083,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/LLM4PR_ Improving Post-Ranking in Search Engine with Large Language Models.json"
}