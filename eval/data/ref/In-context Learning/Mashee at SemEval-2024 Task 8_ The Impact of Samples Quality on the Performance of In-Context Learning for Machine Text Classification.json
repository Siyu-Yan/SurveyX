{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2406.17790",
    "title": "Mashee at SemEval-2024 Task 8: The Impact of Samples Quality on the Performance of In-Context Learning for Machine Text Classification",
    "abstract": "Within few-shot learning, in-context learning (ICL) has become a potential method for leveraging contextual information to improve model performance on small amounts of data or in resource-constrained environments where training models on large datasets is prohibitive. However, the quality of the selected sample in a few shots severely limits the usefulness of ICL. The primary goal of this paper is to enhance the performance of evaluation metrics for in-context learning by selecting high-quality samples in few-shot learning scenarios. We employ the chi-square test to identify high-quality samples and compare the results with those obtained using low-quality samples. Our findings demonstrate that utilizing high-quality samples leads to improved performance with respect to all evaluated metrics.",
    "bib_name": "rasheed2024masheesemeval2024task8",
    "md_text": "# Mashee at SemEval-2024 Task 8: The Impact of Samples Quality on the Performance of In-Context Learning for Machine Text Classification\nAreeg Fahad Rasheed College of Information Engineering Al-Nahrain University Baghdad, Iraq areeg.fahad@coie-nahrain.edu.iq M. Zarkoosh Software Engineering Baghdad, Iraq m94zarkoosh@gmail.com\nareeg.fahad@coie-nahrain.edu.iq\nAbstract\nWithin few-shot learning, in-context learning (ICL) has become a potential method for leveraging contextual information to improve model performance on small amounts of data or in resource-constrained environments where training models on large datasets is prohibitive. However, the quality of the selected sample in a few shots severely limits the usefulness of ICL. The primary goal of this paper is to enhance the performance of evaluation metrics for in-context learning by selecting high-quality samples in few-shot learning scenarios. We employ the chi-square test to identify high-quality samples and compare the results with those obtained using low-quality samples. Our findings demonstrate that utilizing high-quality samples leads to improved performance with respect to all evaluated metrics.\n# 1 Introduction\nThe advent of large language models (LLMs) like GPT-3.5 has brought about transformative capabilities, seamlessly handling tasks like question answering, essay writing, and problem-solving (Aljanabi et al., 2023; Wu et al., 2023; Rasheed et al., 2023a). However, this technological advancement necessitates careful consideration of its associated challenges. Concerns regarding the potential impact on creativity and ethical implications, particularly concerning the generation of deepfakes (Tang et al., 2023), warrant careful attention (RAYMOND, 2023). Additionally, the limitations of LLMs, including the possibility of producing erroneous information, require rigorous evaluation and verification. The substantial energy consumption required for training LLMs on massive datasets raises environmental concerns, contributing to their carbon footprint. Moreover, plagiarism issues emerge as users may misuse the generated content, either inadvertently or intentionally (Hadi et al., 2023).\nM. Zarkoosh Software Engineering Baghdad, Iraq m94zarkoosh@gmail.com\nVarious models have been introduced in recent years designed to distinguish text generated by humans from that created by machines(Mitchell et al., 2023). Examples include GPTZero(gpt), AI Content Detector(cop), and AI Content Detector by Writer (wri) among others. Some of these models are trained on specific datasets, while others are commercially available. Designing and implementing LLMs for classification tasks requires substantial resources and computational power, which are often only accessible to institutions and governments. Therefore, various optimization models, such as LoRA (Hu et al., 2021), distillation(Hsieh et al., 2023), quantization(Dettmers et al., 2022), and in-context learning (Liu et al., 2022), have been developed to reduce the resource requirements for LLM implementation. This paper focuses on In Context Learning (ICL) (Liu et al., 2022), which utilizes the capabilities of other models to enhance their ability to classify AI-generated text. In Context Learning (ICL) is a Natural Language Processing (NLP) technique utilized to enable Large Language Models (LLMs) to learn new tasks based on minimal examples. This technique proves powerful in scenarios where training models on extensive datasets is impractical or when there are constraints on dataset availability for a specific task. ICL operates on the premise that humans can often acquire new tasks through analogy or by observing a few examples of task performance. It can be employed without any examples and is referred to as zero-shot learning. Alternatively, if the input includes one example, it is termed one-shot learning, and if it contains more than one, it is known as few-shot learning. This paper focuses on the application of few-shot learning within the context of ICL(Ahmed and Devanbu, 2022; Kang et al., 2023). In this study, our focus lies exclusively on fewshot learning. We present a methodology that leverages the chi-square statistic (Rasheed et al., 2023b;\nLancaster and Seneta, 2005) to select samples for few-shot learning and evaluate its impact on the performance of a machine-generated text classification model. We work on task A English language only (Wang et al., 2024).\n# 2 Dataset\nThe dataset employed for Task A comprises two main components. The first part, derived from human writing, was collected from diverse sources including WikiBidia, WikiHow, Reddit, ArXiv, and PeerRead. The second part consists of a machine-generated text produced by ChatGPT, Cohere, Dolly-v2, and BLOOMz(Muennighoff et al., 2023). For further details, please refer to the associated paper (Wang et al., 2023).\n# 3 Chi-square\nChi-square is a statistical test used to assess the independence of two categorical variables. It calculates the difference between observed and expected frequencies of outcomes, and a larger chisquare value indicates a stronger rejection of independence. In text analysis, chi-square can be used to identify keywords that are more likely to occur in one category than another, making it useful for feature selection and text classification. We computed the chi-square values for each training sample and recorded the sample index with the highest and lowest chi-square values for both human-generated and machine-generated samples. Table I displays the index and corresponding chi-square values for each of these instances. We will use X2 to refer to chi-square (Lancaster and Seneta, 2005).\n<div style=\"text-align: center;\">Table 1: Indices and chi-square values for highest/lowest in human-generated and machine-generated text</div>\nName\nIndex #\nX2 Value\nHighest X2 (Human)\n70873\n1351.59\nLowest X2 (Human)\n85726\n1.21\nHighest X2 (Machine)\n2426\n1154.27\nLowest X2 (Machine)\n29111\n0.8243\n# 4 System overview\nThe system architecture is illustrated in Figure 1. The process starts with feeding the entire training dataset to a chi-square computation, where the chisquare value for each sample is calculated. Subsequently, the indices of the samples with the highest\nand lowest chi-square values are selected for both human-generated and machine-generated datasets using information from Table I. Next, context learning is prepared. Initially, multiple templates were tested, and the one presented in Figure 1 yielded the best results. This template is then fed with two samples: the first being the machine-generated sample with the highest chi-square value, and the second being the human-generated sample with the highest chi-square value. Due to context window size limitations, only the first 5000 characters of each sample are incorporated. This is applied to training samples exceeding 5000 characters to ensure the context learning size is not exceeded. Finally, the test sample is fed into the context-learning process. The Flan-T5 model large version is used. The results are then recorded and evaluated. The dev/test sample size was truncated to 3000. We also evaluated the system using samples with the lowest chi-square values and doing the same process.\n# 5 Findings and Analysis\nWe employed the Flan-T5 Large model for both the development and testing datasets. We selected samples from both human-generated and machinegenerated sources, with each sample limited to 5000 characters to avoid exceeding the token size limit. A total of four experiments were conducted. The first experiment utilized samples with high chi-square values from the development set. The second experiment focused on samples with the smallest chi-square values from the development set. The third experiment involved samples with high chi-square values from the test set. Finally, the fourth experiment utilized samples with low chisquare values from the test set. Table II presents all achieved results. Based on the results presented in Table II, we can discuss several key points.\n The results highlight the crucial role of sample quality in the performance of in-context learning. By leveraging the chi-squared metric and prioritizing samples with high values, we essentially provide the Flan-T5 model with examples rich in diverse features. This choice enables the Flan-T5 model to learn more effectively, drawing substantial insights from the samples. Consequently, the model becomes more familiar with the provided data, ultimately enhancing its performance. In\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e183/e1834a30-719c-429d-bfb4-f02b517b6898.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: Proposed System Components</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8053/8053e830-9252-40eb-9805-6c8d9df6cba3.png\" style=\"width: 50%;\"></div>\nDataset\nChi Type\nRecall\nPrecision\nF1-Score\nAccuracy\nDev set\nLowest\n46.92\n46.90\n46.84\n46.92\nHighest\n53.76\n53.76\n53.74\n53.76\nTest set\nLowest\n55.04\n55.07\n55.03\n55.27\nHighest\n58.68\n58.81\n58.81\n55.99\n<div style=\"text-align: center;\">Table 2: Experiments results</div>\ncontrast, selecting samples with lower quality leads to less optimal performance. This can be noticed for both the dev and test set. The main reason behind this is that words in the sample with high chi-square values contain the most distinctive features. This is because the chi-square test assigns high values to words that are frequent within a particular class but appear less frequently in other classes.Conversely, samples with lower chi-square values likely contain more random words that appear with similar frequency across all classes. In chi-square analysis, words that appear equally or approximately equally in each class receive lower scores.\n The classification of machine-generated text represents a novel frontier in machine learning, and the availability of datasets for this task is currently limited. The dataset used in this study was generated in 2023, marking it as a recent development and underscoring the lack of established benchmarks. Models that support in-context learning have not been trained extensively on such tasks, resulting in lower accuracy when applied. While examples with high-quality data can enhance\nmodel performance, it remain below the desired threshold. Hence, it is advisable to train the model directly on the dataset rather than relying on in-context learning.\n\u2022 We have utilized the Flan-T5 model; however, other models can be employed to evaluate the performance of text classification machinery. We suggest considering alternatives such as bard, Jurassic-1 Jumbo, and ChatGPT.\n# 6 Conclusion\nThis work presents a system for classifying humangenerated and machine-generated text. The system leverages the combined strengths of in-context learning and Chi-square analysis. Chi-square is employed to select high-quality samples from the trainin dataset for few-shot learning in the incontext learning. We implement Flan-T5 model large version for in-context learning. Evaluation using accuracy, recall, precision, and F1-score demonstrates that selecting high-quality samples improves system performance for both dev and test. Furthermore, the results indicate that relying solely on in-context learning for new tasks like machine-generated text detection yields relatively low performance.\nAi content detector. Accessed on June 27, 2024. Ai content detector by writer. Accessed on June 27, 2024. Gptzero. Accessed on June 27, 2024. Toufique Ahmed and Premkumar Devanbu. 2022. Few-shot training llms for project-specific codesummarization. In Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering, pages 1\u20135. Mohammad Aljanabi, Mohanad Ghazi, Ahmed Hussein Ali, Saad Abas Abed, et al. 2023. Chatgpt: open possibilities. Iraqi Journal For Computer Science and Mathematics, 4(1):62\u201364. Tim Dettmers, Mike Lewis, Younes Belkada, and Luke Zettlemoyer. 2022. Llm. int8 (): 8-bit matrix multiplication for transformers at scale. arXiv preprint arXiv:2208.07339. Muhammad Usman Hadi, R Qureshi, A Shah, M Irfan, A Zafar, MB Shaikh, N Akhtar, J Wu, and S Mirjalili. 2023. A survey on large language models: Applications, challenges, limitations, and practical usage. TechRxiv. Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023. Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes. arXiv preprint arXiv:2305.02301. Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. Sungmin Kang, Juyeon Yoon, and Shin Yoo. 2023. Large language models are few-shot testers: Exploring llm-based general bug reproduction. In 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE), pages 2312\u20132323. IEEE. Henry Oliver Lancaster and Eugene Seneta. 2005. Chisquare distribution. Encyclopedia of biostatistics, 2. Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin A Raffel. 2022. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. Advances in Neural Information Processing Systems, 35:1950\u20131965. Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning, and Chelsea Finn. 2023. Detectgpt: Zero-shot machine-generated text detection using probability curvature. arXiv preprint arXiv:2301.11305.\nAi content detector. Accessed on June 27, 2024. Ai content detector by writer. Accessed on June 27, 2024.\nHaokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin A Raffel. 2022. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. Advances in Neural Information Processing Systems, 35:1950\u20131965.\nNiklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin Raffel. 2023. Crosslingual generalization through multitask finetuning. Areeg Fahad Rasheed, M Zarkoosh, Safa F Abbas, and Sana Sabah Al-Azzawi. 2023a. Arabic offensive language classification: Leveraging transformer, lstm, and svm. In 2023 IEEE International Conference on Machine Learning and Applied Network Technologies (ICMLANT), pages 1\u20136. IEEE. Areeg Fahad Rasheed, M Zarkoosh, and Sana Sabah Al-Azzawi. 2023b. The impact of feature selection on malware classification using chi-square and machine learning. In 2023 9th International Conference on Computer and Communication Engineering (ICCCE), pages 211\u2013216. IEEE.\n# DANIEL RAYMOND. 2023. Disadvantages of large language models. Accessed on June 27, 2024.\nRuixiang Tang, Yu-Neng Chuang, and Xia Hu. 2023. The science of detecting llm-generated texts. arXiv preprint arXiv:2303.07205.\nYuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Chenxi Whitehouse, Osama Mohammed Afzal, Tarek Mahmoud, Alham Fikri Aji, and Preslav Nakov. 2023. M4: Multi-generator, multi-domain, and multi-lingual black-box machine-generated text detection.\nuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Chenxi Whitehouse, Osama Mohammed Afzal, Tarek Mahmoud, Giovanni Puccetti, Thomas Arnold, Alham Fikri Aji, Nizar Habash, Iryna Gurevych, and Preslav Nakov. 2024. SemEval-2024 task 8: Multigenerator, multidomain, and multilingual black-box machinegenerated text detection. In Proceedings of the 18th International Workshop on Semantic Evaluation, SemEval 2024, Mexico City, Mexico.\nTianyu Wu, Shizhu He, Jingping Liu, Siqi Sun, Kang Liu, Qing-Long Han, and Yang Tang. 2023. A brief overview of chatgpt: The history, status quo and potential future development. IEEE/CAA Journal of Automatica Sinica, 10(5):1122\u20131136.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of enhancing the performance of in-context learning (ICL) for machine text classification by selecting high-quality samples in few-shot learning scenarios, highlighting that the quality of selected samples severely limits the effectiveness of ICL.",
        "problem": {
            "definition": "The problem defined in this paper revolves around the challenge of utilizing in-context learning effectively in scenarios where only a few samples are available, particularly focusing on the quality of these samples.",
            "key obstacle": "The core obstacle is that existing methods do not adequately account for the quality of samples, leading to suboptimal performance in distinguishing between human-generated and machine-generated text."
        },
        "idea": {
            "intuition": "The intuition behind this work stems from the observation that high-quality samples can significantly enhance the learning capabilities of models, particularly in few-shot learning scenarios.",
            "opinion": "The proposed idea involves employing the chi-square test to identify and select high-quality samples that can improve the performance of in-context learning in machine text classification.",
            "innovation": "The key innovation lies in the application of the chi-square statistic to sample selection, which differentiates this method from existing approaches that do not prioritize sample quality."
        },
        "method": {
            "method name": "Chi-square based sample selection for in-context learning",
            "method abbreviation": "ICL-Chi",
            "method definition": "This method utilizes the chi-square test to evaluate and select high-quality samples for few-shot learning, aiming to improve the performance of in-context learning in machine text classification.",
            "method description": "The core of the method involves calculating chi-square values for samples to identify the highest quality inputs for training the model.",
            "method steps": [
                "Feed the entire training dataset to compute chi-square values for each sample.",
                "Select indices of samples with the highest and lowest chi-square values for both human and machine-generated datasets.",
                "Prepare context learning by using the best-performing template.",
                "Incorporate the selected samples into the training process of the Flan-T5 model."
            ],
            "principle": "The effectiveness of this method is grounded in the chi-square test's ability to identify distinctive features in high-quality samples, which enhances the model's learning from the provided data."
        },
        "experiments": {
            "evaluation setting": "The evaluation involved using a dataset consisting of both human-generated and machine-generated text, with experiments conducted on samples categorized by their chi-square values.",
            "evaluation method": "Performance was assessed through accuracy, recall, precision, and F1-score across four experiments, comparing results from high and low-quality samples."
        },
        "conclusion": "The findings demonstrate that selecting high-quality samples significantly improves the performance of the in-context learning system for classifying human and machine-generated text, although reliance solely on in-context learning yields lower performance.",
        "discussion": {
            "advantage": "The proposed approach effectively enhances model performance by prioritizing high-quality samples, which contain more distinctive features relevant for classification.",
            "limitation": "Despite improvements, the method's performance remains below desired thresholds, indicating that further training directly on datasets may be necessary.",
            "future work": "Future research should explore alternative models for text classification and investigate methods to improve performance beyond in-context learning."
        },
        "other info": {
            "info1": "The study was conducted using the Flan-T5 model, but other models like Bard and ChatGPT could also be evaluated.",
            "info2": {
                "info2.1": "The dataset used was generated in 2023, highlighting the lack of established benchmarks in this area.",
                "info2.2": "The experiments confirmed the critical role of sample quality in the performance of in-context learning."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The foundational concept of in-context learning (ICL) is to enhance performance in machine text classification by selecting high-quality samples in few-shot learning scenarios."
        },
        {
            "section number": "1.2",
            "key information": "The quality of selected samples severely limits the effectiveness of in-context learning, highlighting its impact and relevance within the broader field of natural language processing."
        },
        {
            "section number": "3.1",
            "key information": "The proposed method, Chi-square based sample selection for in-context learning (ICL-Chi), enhances adaptation by selecting high-quality samples that improve model performance in few-shot learning scenarios."
        },
        {
            "section number": "3.2",
            "key information": "The chi-square test is utilized to evaluate and select samples, providing a theoretical framework for understanding how sample quality affects in-context learning performance."
        },
        {
            "section number": "4.1",
            "key information": "The design of prompts can be significantly influenced by the selection of high-quality samples, which are essential for enhancing in-context learning outcomes."
        },
        {
            "section number": "6.1",
            "key information": "The core obstacle in in-context learning identified is that existing methods do not adequately account for the quality of samples, leading to suboptimal performance in distinguishing between human-generated and machine-generated text."
        },
        {
            "section number": "6.2",
            "key information": "Despite improvements in performance through high-quality sample selection, the method's efficiency remains a concern, indicating a need for further optimization."
        },
        {
            "section number": "7",
            "key information": "The findings demonstrate that selecting high-quality samples significantly improves the performance of in-context learning systems, although reliance solely on in-context learning yields lower performance."
        }
    ],
    "similarity_score": 0.707423272022295,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2330_in-co/papers/Mashee at SemEval-2024 Task 8_ The Impact of Samples Quality on the Performance of In-Context Learning for Machine Text Classification.json"
}