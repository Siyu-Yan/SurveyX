{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2312.00794",
    "title": "Informative Priors Improve the Reliability of Multimodal Clinical Data Classification",
    "abstract": "Machine learning-aided clinical decision support has the potential to significantly improve patient care. However, existing efforts in this domain for principled quantification of uncertainty have largely been limited to applications of ad-hoc solutions that do not consistently improve reliability. In this work, we consider stochastic neural networks and design a tailor-made multimodal data-driven (m2d2) prior distribution over network parameters. We use simple and scalable Gaussian mean-field variational inference to train a Bayesian neural network using the m2d2 prior. We train and evaluate the proposed approach using clinical time-series data in MIMIC-IV and corresponding chest X-ray images in MIMIC-CXR for the classification of acute care conditions. Our empirical results show that the proposed method produces a more reliable predictive model compared to deterministic and Bayesian neural network baselines. Keywords: Uncertainty quantification, multimodal healthcare data, Bayesian inference",
    "bib_name": "lopez2023informativepriorsimprovereliability",
    "md_text": "# Informative Priors Improve the Reliability of Multimodal Clinical Data Classification\nL. Julian Lechuga Lopez1,2 Tim G. J. Rudner2 Farah E. Shamout1,2 1NYU Abu Dhabi, AD, UAE 2New York University, NY, USA\nAbstract\n# Abstract\nMachine learning-aided clinical decision support has the potential to significantly improve patient care. However, existing efforts in this domain for principled quantification of uncertainty have largely been limited to applications of ad-hoc solutions that do not consistently improve reliability. In this work, we consider stochastic neural networks and design a tailor-made multimodal data-driven (m2d2) prior distribution over network parameters. We use simple and scalable Gaussian mean-field variational inference to train a Bayesian neural network using the m2d2 prior. We train and evaluate the proposed approach using clinical time-series data in MIMIC-IV and corresponding chest X-ray images in MIMIC-CXR for the classification of acute care conditions. Our empirical results show that the proposed method produces a more reliable predictive model compared to deterministic and Bayesian neural network baselines. Keywords: Uncertainty quantification, multimodal healthcare data, Bayesian inference\narXiv:2312.00794v1\n# 1. Introduction\nTrustworthy machine learning in healthcare requires robust uncertainty quantification (Begoli et al., 2019; Gruber et al., 2023), considering the safety-critical nature of clinical practice. Sources of uncertainty can be due to model parameters, noise and bias of the calibration data, or deployment of the model in an out-of-distribution scenario (Miller et al., 2014). Unfortunately, the literature in machine learning for healthcare has largely neglected developing tailored solutions for improved uncertainty quantification (Kompa et al., 2021), perhaps due to the limited underlying theory on how to best adapt predictive un-\n\u00a9 2023 L.J.L. Lopez, T.G.J. Rudner & F.E. Shamout.\nMachine Learning for Health (ML4H) 2023\nleopoldo.lechuga@nyu.edu tim.rudner@nyu.edu farah.shamout@nyu.edu\ncertainty in clinical tasks (Begoli et al., 2019). Other challenges include the complexity of scaling uncertainty quantification in real-time clinical systems, limited empirical evaluation of different methods due to the lack of well-constructed priors by medical experts (Zou et al., 2023), and the high prevalence of data shifts in real-world clinical applications that can negatively affect predictive performance (Ovadia et al., 2019b; Xia et al., 2022), further emphasizing the need for better uncertainty in predictive models. Additionally, despite the recent proliferation of multimodal learning, existing work on uncertainty quantification in healthcare has mainly been studied in the unimodal setting, with a particular focus on medical imaging applications (Gawlikowski et al., 2021). This includes brain tumor segmentation (Jungo et al., 2018), skin lesion segmentation (DeVries and Taylor, 2018), and diabetic retinopathy detection tasks (Filos et al., 2019; Band et al., 2021; Nado et al., 2022), among others. Hence, effective quantification of predictive uncertainty in the context of multimodal clinical problems remains a challenging and unsolved task (Tran et al., 2022). We propose a multimodal data-driven (m2d2) prior distribution over neural network parameters to improve uncertainty quantification in multimodal fusion of chest X-ray images and clinical time series data. We evaluate the use of effective priors on the two unimodal components of the multimodal fusion network: an image-based convolutional neural network and a recurrent neural network for clinical time series. In summary, we make the following contributions:\n1. We design a multimodal data-driven (m2d2) prior distribution over neural network parameters that places high probability density on desired predictive functions.\n1. We design a multimodal data-driven (m2d2) prior distribution over neural network parameters that places high probability density on desired predictive functions.\nInformative Priors Improve the Reliability of Multimodal Clinical Data Classification\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/12ee/12ee52a3-e3d9-4c2b-8e69-c42fb5abfb73.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\n<div style=\"text-align: center;\">Figure 1: Overview of model training. Left: We construct a multimodal context dataset by applying modalityspecific transformations to clinical time series data and chest X-ray images, resulting in a tailored distribution shift. Right: We train the multimodal neural network end-to-end with the training set and the constructed context dataset.</div>\n2. We evaluate the method on large publicly-available multimodal datasets: MIMIC-IV and MIMICCXR (Johnson et al., 2019, 2021), for the classification of acute care conditions assigned to patient stays in the intensive care unit. 3. Our findings illustrate an increase in predictive performance and improved reliability in uncertaintyaware selective prediction.\n# 2. Related Work\n# 2.1. Multimodal Learning in Healthcare\nMultimodal learning in healthcare seeks to exploit complementary information from different data modalities to enhance the predictive capabilities of learning models. There are different approaches for leveraging information across different data modalities, with the most popular paradigm being multimodal fusion (Huang et al., 2020). For example, Zhang et al. (2020) and Calhoun and Sui (2016) investigated different methods for fusion segmentation and quantification in neuroimaging by leveraging different imaging modalities in the same data pipeline. Another recent study focused on the development of smart healthcare applications by merging multimodal signals collected from different types of medical sensors (Muhammad et al., 2021). Other studies also show improved predictive performance when using multiple modalities in prognostic tasks in patients with COVID-19 (Shamout et al., 2021; Jiao et al., 2021). Despite the promise of multimodal learning in healthcare, research in reliable uncertainty quantifica-\n\ntion applications in the multimodal setting is currently limited. There is no generalized use of uncertainty quantification methods that address increased data distribution shifts and deal with multiple modalities simultaneously (Liang et al., 2023).\n# 2.2. Variational Inference in Neural Networks\nWe consider a stochastic neural network f(\u00b7 ; \u0398), defined in terms of stochastic parameters \u0398 \u2208RP . For an observation model pY |X,\u0398 and a prior distribution over parameters p\u0398, Bayesian inference provides a mathematical formalism for finding the posterior distribution over parameters given the observed data, p\u0398|D (MacKay, 1992; Neal, 1996). However, since neural networks are non-linear in their parameters, exact inference over the stochastic network parameters is analytically intractable. Variational inference is an approach that seeks to avoid this intractability by framing posterior inference as finding an approximation q\u0398 to the posterior p\u0398|D via the variational optimization problem: minq\u0398\u2208Q\u0398 DKL(q\u0398 \u2225p\u0398|D) \u21d0\u21d2maxq\u0398\u2208Q\u0398 F(q\u0398), where F(q\u0398) is the variational objective F(q\u0398) \u02d9=Eq\u0398[log p(yD | xD, \u0398)]\u2212DKL(q\u0398 \u2225p\u0398), (1)\nF |\u2212 \u2225 Q\u0398 is a variational family of distributions (Wainwright and Jordan, 2008), and (xD, yD) are the training data. One particularly simple type of variational inference is Gaussian mean-field variational inference (Blundell et al., 2015; Graves, 2011), where the posterior distribution over network parameters is approximated by a Gaussian distribution with a diagonal covariance matrix. This method enables stochastic optimization and\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/99db/99dba721-fd9d-4eb2-98a6-e9f5610d12c2.png\" style=\"width: 50%;\"></div>\nFigure 2: Selective prediction algorithm. For each input sample, we obtain a prediction and an estimate of t model\u2019s uncertainty for that specific data point. If the uncertainty estimate is higher than the selected r tolerance, then the sample will be sent to an expert for further review and classification. Otherwise, t sample is processed by the learning model for automated prediction.\n<div style=\"text-align: center;\">Figure 2: Selective prediction algorithm. For each input sample, we obtain a prediction and an estimate of th model\u2019s uncertainty for that specific data point. If the uncertainty estimate is higher than the selected ris tolerance, then the sample will be sent to an expert for further review and classification. Otherwise, th sample is processed by the learning model for automated prediction.</div>\ncan be scaled to large neural networks (Hoffman et al., 2013). However, Gaussian mean-field variational inference has been shown to underperform with deterministic neural networks when uninformative, standard Gaussian priors are used (Ovadia et al., 2019a; Rudner et al., 2022a). To improve the performance, we extend the approach presented in Rudner et al. (2023a) to stochastic neural networks, construct a data-driven prior distribution from multimodal input data, and use this prior for Gaussian mean-field variational inference to improve the performance of neural networks for multimodal clinical prediction tasks.\n# 3. Constructing Data-Driven Priors for Models with Multimodal Input Data\nWe consider a supervised multimodal fusion task on data D .= {(x1 n, x2 n, yfusion n )}N n=1 = (X1 D, X2 D, YD). As shown in Figure 1, we consider the first modality to be clinical time series data extracted from electronic health records, denoted by Xehr, and the second to be chest X-ray images, denoted by Xcxr. For a given sample (xehr, xcxr), the two modalities are processed by encoders \u03a6ehr and \u03a6cxr respectively, and their concatenated feature representations are further processed by a classifier g(\u00b7) and activation function to compute the fusion prediction \u02c6yfusion. The loss is computed based on the predictions and ground truth labels yfusion \u2208Y, where Y \u2286{0, 1}Q, with Q > 1 for multi-label classification.\n# 3.1. Informative Priors for Multimodal Data\nOne of the key components in defining the probabilistic model for our uncertainty quantification method is the definition of a sensible and explainable prior distribution. In this work, we construct a prior distribution over parameters that places high probability density\non parameter values that induce predictive functions that have high uncertainty on input points that are meaningfully different from the training data. To do this, we build on the approach proposed in Rudner et al. (2023a) and use information about the two input modalities to construct a data-driven prior that can help find an approximate posterior distribution with desirable properties (e.g., an induced predictive distribution with reliable uncertainty estimation). More specifically, we construct a data-driven prior over some set of model parameters \u03a8 and condition it on a set of context points \u02dcX, that is p(\u03c8|\u02dcx). In Appendix A, we show that we can derive a tractable variational objective using this prior. The objective is given by Equation (A.16). To construct a meaningful prior, we need to specify a distribution over the set of context points, p \u02dc X. We design a multimodal prior by letting \u02dcX be a set of randomly generated multimodal input points ( \u02dcXehr, \u02dcXcxr) designed to be distinct from the training data. For the clinical time series data, we construct \u02dcXehr by applying three transformations to the original time series: drop start, Gaussian noise, and inversion (i.e, for each xi in 1, ..., n, x1 = xn, x2 = xn\u22121, x3 = xn\u22122, etc). For the chest X-ray images, we construct \u02dcXcxr by applying seven transformations representative of perturbations that exist in real-world medical settings to the imaging data: random crop, random horizontal and vertical flip, Gaussian blur, random solarize, random invert and color jitter. Hence, this context set encompasses distributionally shifted points, where we want the model\u2019s uncertainty to be higher.\n# 4. Empirical Evaluation\nTo evaluate the proposed approach, we combine clinical time series data from MIMIC-IV (Johnson et al., 2021) and chest X-ray images from MIMIC-CXR\n<div style=\"text-align: center;\">Table 1: Performance results. We summarize the results on the test set for the baselines and our stochastic model, including 95% confidence intervals computed via bootstrapping. Higher values are better for all metrics.</div>\nModel (MedFuse)\nAUROC\nAUPRC\nSelective AUROC\nSelective AUPRC\nDeterministic (Hayat et al., 2022)\n0.726 (0.718, 0.733)\n0.503 (0.493, 0.517)\n0.724 (0.715, 0.735)\n0.439 (0.429, 0.455)\nBayesian (standard prior)\n0.729 (0.722, 0.736)\n0.507 (0.497, 0.521)\n0.748 (0.739, 0.758)\n0.448 (0.437, 0.467)\nBayesian (m2d2 prior) (Ours)\n0.735 (0.728, 0.742)\n0.514 (0.504, 0.528)\n0.748 (0.738, 0.760)\n0.452 (0.441, 0.472)\n(Johnson et al., 2019) collected during the same patient stay in the intensive care unit for multi-label classification of acute care conditions.\n# 4.1. Experimental Setup\nWe follow the pre-processing steps and use the same neural network architecture (MedFuse) as Hayat et al. (2022). \u03a6ehr is a two-layer LSTM network (Hochreiter and Schmidhuber, 1997), \u03a6cxr is a ResNet-34 (He et al., 2015), g(\u00b7) is a fully connected layer, and \u02c6yfusion are the class probabilities obtained by applying a sigmoid function to g. We use the paired dataset, such that each sample contains both modalities (i.e., there are no missing modalities). Hence, the training, validation, and test sets consisted of 7756, 877, and 2161 samples, respectively. We construct the context dataset using the training set. We train the multimodal network for 400 epochs using the loss presented in Equation (B.17), with the Adam optimizer, a batch size of 16, and a learning rate of 2 \u00d7 10\u22124. Further details on the experimental setup and grid-based hyperparameter tuning can be found in Appendix B.\n# 4.2. Evaluation Metrics\nWe evaluate the overall performance of the models on the test set using the AUROC and Area Under the Precision-Recall curve (AUPRC) (Hayat et al., 2022). In addition, we compute selective prediction evaluation metrics to better assess models\u2019 predictive uncertainty. As shown in Figure 2, selective prediction modifies the standard prediction pipeline by introducing a \u201creject option\u201d, \u22a5, via a gating mechanism defined by selection function s : X \u2192R that determines whether a prediction should be made for a given input point x \u2208X (El-Yaniv et al., 2010). For rejection threshold \u03c4, with s representing the entropy of x, the prediction model is given by \ufffd\n(2)\nTo evaluate the predictive performance of a prediction model (p(y | \u00b7, \u03b8; f), s)(x) with a single label,\nwe compute the AUROC and AUPRC over rejection thresholds \u03c4 = 0%, ..., 99%. We then average the metrics across all thresholds, yielding selective prediction AUROC and AUPRC scores that explicitly incorporate both a model\u2019s predictive performance and its predictive uncertainty. For our multi-label classification task, we report the average selective prediction scores across all 25 labels.\n# 4.3. Results\nTable 1 summarizes the performance results on the test set. Additional per-label results are shown in Appendix C. The Bayesian neural network with an m2d2 prior achieves a better AUROC and AUPRC of 0.735 and 0.514, respectively, compared with 0.726 and 0.503 by the deterministic model. It also achieves a higher selective AUROC and AUPRC of 0.748 and 0.452, respectively, compared with 0.724 and 0.439 by the deterministic model. Our proposed approach achieves a comparable selective AUROC to when using a standard prior. We also observe a decrease in selective AUPRC compared to the 0%-rejection AUPRC. This can occur when a model is poorly calibrated: When the AUPRC for any rejection threshold is below the 0%-rejection score, the selective AUPRC can be lower than the 0%-rejection score. Overall, the selective prediction scores reflect the model\u2019s ability to identify samples that are more likely to be misclassified and should be reviewed by a clinician, and as such, are valuable in assessing model reliability in clinical settings.\n# 5. Conclusion\nWe designed a multimodal data-driven (m2d2) prior to improve the reliability of multimodal fusion of clinical time series data and chest X-ray images. We demonstrated that Bayesian neural networks with such a prior achieve better performance, in terms of AUROC, AUPRC, and selective prediction scores, than deterministic models. For future work, we aim to evaluate the proposed approach in settings of missing modalities, on additional tasks, such as in-hospital mortality prediction, and other multi-modal datasets.\n# 6. Acknowledgements\nThis research was carried out on the High Performance Computing resources at New York University Abu Dhabi. We would also like to thank postdoctoral associate Dr. Alejandro Guerra Manzanares for the helpful discussions and support in refactoring code from Pytorch to JAX.\n# References\nNeil Band, Tim G. J. Rudner, Qixuan Feng, Angelos Filos, Zachary Nado, Michael W. Dusenberry, Ghassen Jerfel, Dustin Tran, and Yarin Gal. Benchmarking Bayesian deep learning on diabetic retinopathy detection tasks. 2021. Edmon Begoli, Tanmoy Bhattacharya, and Dimitri Kusnezov. The need for uncertainty quantification in machine-assisted medical decision making. Nature Machine Intelligence, 1(1):20\u201323, 2019. Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural networks. volume 37 of Proceedings of Machine Learning Research, pages 1613\u20131622, Lille, France, 07\u201309 Jul 2015. PMLR. James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python+NumPy programs, 2018. Vince D Calhoun and Jing Sui. Multimodal fusion of brain imaging data: a key to finding the missing link (s) in complex mental illness. Biological psychiatry: cognitive neuroscience and neuroimaging, 1(3):230\u2013 244, 2016. Terrance DeVries and Graham W Taylor. Leveraging uncertainty estimates for predicting segmentation quality. arXiv preprint arXiv:1807.00502, 2018. Ran El-Yaniv et al. On the foundations of noise-free selective classification. Journal of Machine Learning Research, 11(5), 2010. Angelos Filos, Sebastian Farquhar, Aidan N Gomez, Tim GJ Rudner, Zachary Kenton, Lewis Smith, Milad Alizadeh, Arnoud De Kroon, and Yarin Gal. A systematic comparison of Bayesian deep learning\nNeil Band, Tim G. J. Rudner, Qixuan Feng, Angelos Filos, Zachary Nado, Michael W. Dusenberry, Ghassen Jerfel, Dustin Tran, and Yarin Gal. Benchmarking Bayesian deep learning on diabetic retinopathy detection tasks. 2021.\nEdmon Begoli, Tanmoy Bhattacharya, and Dimitri Kusnezov. The need for uncertainty quantification in machine-assisted medical decision making. Nature Machine Intelligence, 1(1):20\u201323, 2019.\nRan El-Yaniv et al. On the foundations of noise-free selective classification. Journal of Machine Learning Research, 11(5), 2010.\nAngelos Filos, Sebastian Farquhar, Aidan N Gomez, Tim GJ Rudner, Zachary Kenton, Lewis Smith, Milad Alizadeh, Arnoud De Kroon, and Yarin Gal. A systematic comparison of Bayesian deep learning\nrobustness in diabetic retinopathy tasks. arXiv preprint arXiv:1912.10481, 2019.\nJakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, et al. A survey of uncertainty in deep neural networks. arXiv preprint arXiv:2107.03342, 2021.\nAlex Graves. Practical variational inference for neural networks. Advances in neural information processing systems, 24, 2011.\nCornelia Gruber, Patrick Oliver Schenk, Malte Schierholz, Frauke Kreuter, and G\u00a8oran Kauermann. Sources of uncertainty in machine learning \u2013 a statisticians\u2019 view, 2023.\nNasir Hayat, Krzysztof J. Geras, and Farah E. Shamout. Medfuse: Multi-modal fusion with clinical time-series data and chest x-ray images. In Proceedings of the 7th Machine Learning for Healthcare Conference, volume 182 of Proceedings of Machine Learning Research, pages 479\u2013503. PMLR, 05\u201306 Aug 2022. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition, 2015. Sepp Hochreiter and J\u00a8urgen Schmidhuber. Long shortterm memory. Neural computation, 9(8):1735\u20131780, 1997. Matthew D. Hoffman, David M. Blei, Chong Wang, and John Paisley. Stochastic variational inference. Journal of Machine Learning Research, 14(1):1303\u2013 1347, May 2013. ISSN 1532-4435. Shih-Cheng Huang, Anuj Pareek, Saeed Seyyedi, Imon Banerjee, and Matthew P Lungren. Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines. NPJ digital medicine, 3(1):136, 2020. Zhicheng Jiao, Ji Whae Choi, Kasey Halsey, Thi\nShih-Cheng Huang, Anuj Pareek, Saeed Seyyedi, Imon Banerjee, and Matthew P Lungren. Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines. NPJ digital medicine, 3(1):136, 2020.\nZhicheng Jiao, Ji Whae Choi, Kasey Halsey, Thi My Linh Tran, Ben Hsieh, Dongcui Wang, Feyisope Eweje, Robin Wang, Ken Chang, Jing Wu, et al. Prognostication of patients with covid-19 using artificial intelligence based on chest x-rays\nand clinical data: a retrospective study. The Lancet Digital Health, 3(5):e286\u2013e294, 2021.\nand clinical data: a retrospective study. The Lancet Digital Health, 3(5):e286\u2013e294, 2021. Alistair Johnson, Lucas Bulgarelli, Tom Pollard, Leo Anthony Celi, Roger Mark, and S Horng IV. Mimic-iv-ed. PhysioNet, 2021. Alistair EW Johnson, Tom J Pollard, Seth J Berkowitz, Nathaniel R Greenbaum, Matthew P Lungren, Chih-ying Deng, Roger G Mark, and Steven Horng. Mimic-cxr, a de-identified publicly available database of chest radiographs with freetext reports. Scientific data, 6(1):317, 2019. Alain Jungo, Richard McKinley, Raphael Meier, Urspeter Knecht, Luis Vera, Juli\u00b4an P\u00b4erez-Beteta, David Molina-Garc\u00b4\u0131a, V\u00b4\u0131ctor M P\u00b4erez-Garc\u00b4\u0131a, Roland Wiest, and Mauricio Reyes. Towards uncertainty-assisted brain tumor segmentation and survival prediction. In Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: Third International Workshop, BrainLes 2017, Held in Conjunction with MICCAI 2017, Quebec City, QC, Canada, September 14, 2017, Revised Selected Papers 3, pages 474\u2013485. Springer, 2018. Leo Klarner, Tim G. J. Rudner, Michael Reutlinger, Torsten Schindler, Garrett M. Morris, Charlotte Deane, and Yee Whye Teh. Drug discovery under covariate shift with domain-informed prior distributions over functions. In Proceedings of the 40th International Conference on Machine Learning, 2023. Benjamin Kompa, Jasper Snoek, and Andrew L Beam. Second opinion needed: communicating uncertainty in medical machine learning. NPJ Digital Medicine, 4(1):4, 2021. Paul Pu Liang, Amir Zadeh, and Louis-Philippe Morency. Foundations and trends in multimodal machine learning: Principles, challenges, and open questions, 2023. David J. C. MacKay. A practical Bayesian framework for backpropagation networks. Neural Comput., 4(3):448\u2013472, May 1992. ISSN 0899-7667. doi: 10.1162/neco.1992.4.3.448. David C Miller, Brenda Ng, John Eslick, Charles Tong, and Yang Chen. Advanced computational tools for optimization and uncertainty quantification of carbon capture processes. In Computer Aided Chemical Engineering, volume 34, pages 202\u2013211. Elsevier, 2014.\nAlistair Johnson, Lucas Bulgarelli, Tom Pollard, Leo Anthony Celi, Roger Mark, and S Horng IV. Mimic-iv-ed. PhysioNet, 2021.\nAlistair Johnson, Lucas Bulgarelli, Tom Pollard, Leo Anthony Celi, Roger Mark, and S Horng IV. Mimic-iv-ed. PhysioNet, 2021. Alistair EW Johnson, Tom J Pollard, Seth J Berkowitz, Nathaniel R Greenbaum, Matthew P Lungren, Chih-ying Deng, Roger G Mark, and Steven Horng. Mimic-cxr, a de-identified publicly available database of chest radiographs with freetext reports. Scientific data, 6(1):317, 2019. Alain Jungo, Richard McKinley, Raphael Meier, Urspeter Knecht, Luis Vera, Juli\u00b4an P\u00b4erez-Beteta, David Molina-Garc\u00b4\u0131a, V\u00b4\u0131ctor M P\u00b4erez-Garc\u00b4\u0131a, Roland Wiest, and Mauricio Reyes. Towards uncertainty-assisted brain tumor segmentation and survival prediction. In Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: Third International Workshop, BrainLes 2017, Held in Conjunction with MICCAI 2017, Quebec City, QC, Canada, September 14, 2017, Revised Selected Papers 3, pages 474\u2013485. Springer, 2018. Leo Klarner, Tim G. J. Rudner, Michael Reutlinger, Torsten Schindler, Garrett M. Morris, Charlotte Deane, and Yee Whye Teh. Drug discovery under covariate shift with domain-informed prior distributions over functions. In Proceedings of the 40th International Conference on Machine Learning, 2023. Benjamin Kompa, Jasper Snoek, and Andrew L Beam. Second opinion needed: communicating uncertainty in medical machine learning. NPJ Digital Medicine, 4(1):4, 2021. Paul Pu Liang, Amir Zadeh, and Louis-Philippe Morency. Foundations and trends in multimodal machine learning: Principles, challenges, and open questions, 2023. David J. C. MacKay. A practical Bayesian framework for backpropagation networks. Neural Comput., 4(3):448\u2013472, May 1992. ISSN 0899-7667. doi: 10.1162/neco.1992.4.3.448. David C Miller, Brenda Ng, John Eslick, Charles Tong, and Yang Chen. Advanced computational tools for optimization and uncertainty quantification of carbon capture processes. In Computer Aided Chemical Engineering, volume 34, pages 202\u2013211. Elsevier, 2014.\nAlistair EW Johnson, Tom J Pollard, Seth J Berkowitz, Nathaniel R Greenbaum, Matthew P Lungren, Chih-ying Deng, Roger G Mark, and Steven Horng. Mimic-cxr, a de-identified publicly available database of chest radiographs with freetext reports. Scientific data, 6(1):317, 2019.\nDavid C Miller, Brenda Ng, John Eslick, Charles Tong, and Yang Chen. Advanced computational tools for optimization and uncertainty quantification of carbon capture processes. In Computer Aided Chemical Engineering, volume 34, pages 202\u2013211. Elsevier, 2014.\nGhulam Muhammad, Fatima Alshehri, Fakhri Karray, Abdulmotaleb El Saddik, Mansour Alsulaiman, and Tiago H Falk. A comprehensive survey on multimodal medical signals fusion for smart healthcare systems. Information Fusion, 76:355\u2013375, 2021.\nachary Nado, Neil Band, Mark Collier, Josip Djolonga, Michael W. Dusenberry, Sebastian Farquhar, Qixuan Feng, Angelos Filos, Marton Havasi, Rodolphe Jenatton, Ghassen Jerfel, Jeremiah Liu, Zelda Mariet, Jeremy Nixon, Shreyas Padhy, Jie Ren, Tim G. J. Rudner, Faris Sbahi, Yeming Wen, Florian Wenzel, Kevin Murphy, D. Sculley, Balaji Lakshminarayanan, Jasper Snoek, Yarin Gal, and Dustin Tran. Uncertainty baselines: Benchmarks for uncertainty & robustness in deep learning, 2022.\n# Radford M Neal. Bayesian Learning for Neural Networks. 1996.\nYaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, D. Sculley, Sebastian Nowozin, Joshua Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model\u2019s uncertainty? Evaluating predictive uncertainty under dataset shift. In Advances in Neural Information Processing Systems 32. 2019a.\nInformative Priors Improve the Reliability of Multimodal Clinical Data Classification\nIn Proceedings of the 40th International Conference on Machine Learning, Proceedings of Machine Learning Research. PMLR, 2023a.\nence on Machine Learning, Proceedings of Machine Learning Research. PMLR, 2023a. Tim G. J. Rudner, Sanyam Kapoor, Shikai Qiu, and Andrew Gordon Wilson. Should we learn most likely functions or parameters? In Advances in Neural Information Processing Systems 36, 2023b. Farah E Shamout, Yiqiu Shen, Nan Wu, Aakash Kaku, Jungkyu Park, Taro Makino, Stanislaw Jastrzkeski, Jan Witowski, Duo Wang, Ben Zhang, et al. An artificial intelligence system for predicting the deterioration of covid-19 patients in the emergency department. NPJ digital medicine, 4(1):80, 2021. Dustin Tran, Jeremiah Liu, Michael W. Dusenberry, Du Phan, Mark Collier, Jie Ren, Kehang Han, Zi Wang, Zelda Mariet, Huiyi Hu, Neil Band, Tim G. J. Rudner, Karan Singhal, Zachary Nado, Joost van Amersfoort, Andreas Kirsch, Rodolphe Jenatton, Nithum Thain, Honglin Yuan, Kelly Buchanan, Kevin Murphy, D. Sculley, Yarin Gal, Zoubin Ghahramani, Jasper Snoek, and Balaji Lakshminarayanan. Plex: Towards reliability using pretrained large model extensions, 2022. Martin J Wainwright and Michael I Jordan. Graphical Models, Exponential Families, and Variational Inference. Now Publishers Inc., Hanover, MA, USA, 2008. ISBN 1601981848. Tong Xia, Jing Han, and Cecilia Mascolo. Benchmarking uncertainty quantification on biosignal classification tasks under dataset shift. In Multimodal AI in healthcare: A paradigm shift in health intelligence, pages 347\u2013359. Springer, 2022. Yu-Dong Zhang, Zhengchao Dong, Shui-Hua Wang, Xiang Yu, Xujing Yao, Qinghua Zhou, Hua Hu, Min Li, Carmen Jim\u00b4enez-Mesa, Javier Ramirez, et al. Advances in multimodal data fusion in neuroimaging: overview, challenges, and novel orientation. Information Fusion, 64:149\u2013187, 2020. Ke Zou, Zhihao Chen, Xuedong Yuan, Xiaojing Shen, Meng Wang, and Huazhu Fu. A review of uncertainty estimation and its application in medical\nTim G. J. Rudner, Sanyam Kapoor, Shikai Qiu, and Andrew Gordon Wilson. Should we learn most likely functions or parameters? In Advances in Neural Information Processing Systems 36, 2023b.\nYu-Dong Zhang, Zhengchao Dong, Shui-Hua Wang, Xiang Yu, Xujing Yao, Qinghua Zhou, Hua Hu, Min Li, Carmen Jim\u00b4enez-Mesa, Javier Ramirez, et al. Advances in multimodal data fusion in neuroimaging: overview, challenges, and novel orientation. Information Fusion, 64:149\u2013187, 2020.\nKe Zou, Zhihao Chen, Xuedong Yuan, Xiaojing Shen, Meng Wang, and Huazhu Fu. A review of uncertainty estimation and its application in medical imaging. arXiv preprint arXiv:2302.08119, 2023.\n# Supplementary Material\n# Appendix A. Variational Objective\nLet the mapping f in the parametric observation model pY |X,\u0398(y | x, \u03b8; f) be defined by f(\u00b7 ; \u03b8) \u02d9= h(\u00b7 ; \u03b8h)\u03b8L. For a neural network model, h(\u00b7 ; \u03b8h) is the post-activation output of the penultimate layer, \u0398L is the set of stochastic final-layer parameters, \u0398h is the set of stochastic non-final-layer parameters, and \u0398 \u02d9= {\u0398h, \u0398L} is the full set of stochastic parameters. To derive an uncertainty-aware prior distribution over the set of random parameters \u0398, we start by specifying an auxiliary inference problem. Let \u02dcx = {x1, ..., xM} be a set of context points with corresponding labels \u02dcy, and define a corresponding likelihood function \u02dcpY |X,\u0398(\u02dcy | \u02dcx, \u03b8) and a prior over the model parameters, p\u0398(\u03b8). For notational simplicity, we will drop the subscripts as we advance except when needed for clarity. By Bayes\u2019 Theorem, we can write the posterior under the context points and labels as\n\u02dcp(\u03b8 | \u02dcx, \u02dcy) \u221d\u02dcp(\u02dcy | \u02dcx, \u03b8h)p(\u03b8h)p(\u03b8L).\nTo define a likelihood function that induces a posterior with desirable properties, we start from the step as Rudner et al. (2023a) and consider the following stochastic linear model for an arbitrary set of  x \u02d9= {x1, ..., xM \u2032},\nTo define a likelihood function that induces a posterior with desirable properties, we start from the same tep as Rudner et al. (2023a) and consider the following stochastic linear model for an arbitrary set of points  {}\n\u02dcYk(x) \u02d9= h(x; \u03b8h)\u0398k + \u03b5 with \u0398k \u223cN(\u03b8L; mk, \u03c4 \u22121 f sk) and \u03b5 \u223cN(0, \u03c4 \u22121 f \u03b2I)\nfor output dimensions k = 1, ..., K, where h(\u00b7 ; \u03b8h) is the feature mapping used to define f evaluated at a set of fixed feature parameters \u03b8h, \u03c4f and \u03b2 are variance parameters, and m \u2208RPL and s \u2208RPL are\u2014for now\u2014fixed parameters for a PL-dimensional final layer. This stochastic linear model induces a distribution over functions (Rudner et al., 2022a,b; Klarner et al., 2023; Rudner et al., 2023b), which\u2014when evaluated at \u02dcx\u2014is given by N(\u02dcyk(\u02dcx); h(\u02dcx; \u03b8h)mk, \u03c4 \u22121 f K(\u02dcx, \u02dcx; \u03b8h, s)k), (A.2)\nwhere\nK(\u02dcx, \u02dcx; \u03b8h, s)k \u02d9= h(\u02dcx; \u03b8h)(skI)h(\u02dcx; \u03b8h)\u22a4+ \u03b2I\nis an M-by-M covariance matrix. Viewing this probability density over function evaluations as a likelihoo function parameterized by \u03b8, we diverge from Rudner et al. (2023a) and define \u02dcp(\u02dcyk | \u02dcx, \u03b8h) \u02d9=N(\u02dcyk; h(\u02dcx; \u03b8h)mk, \u03c4 \u22121 f K(\u02dcx, \u02dcx; \u03b8h, s)k), (A.\n an M-by-M covariance matrix. Viewing this probability density over function evaluations as a likelihood nction parameterized by \u03b8, we diverge from Rudner et al. (2023a) and define\n\u02dcp(\u02dcyk | \u02dcx, \u03b8h) \u02d9=N(\u02dcyk; h(\u02dcx; \u03b8h)mk, \u03c4 \u22121 f K(\u02dcx, \u02dcx; \u03b8h, s)k),\nwhere\u2014unlike in Rudner et al. (2023a)\u2014we do not assume that m = 0 and s = I. If we define the auxiliary label distribution as p \u02dcY | \u02dc X(\u02dcy | \u02dcx) \u02d9= \u03b4({0, ..., 0} \u2212\u02dcy), the likelihood \u02dcp(\u02dcyk | \u02dcx, \u03b8h) favors learnable parameters \u03b8h for which the induced distribution over functions has a high likelihood of predicting 0. Letting \u02dcp(\u02dcy | \u02dcx, \u03b8) \u02d9= \ufffdK k=1 \u02dcp(\u02dcyk | \u02dcx, \u03b8, mk, sk), and taking the log of the analytically tractable density \u02dcp(\u02dcy | \u02dcx, \u03b8; f), we obtain log \u02dcp(\u02dcy | \u02dcx, \u03b8h) \u221d\u2212 \ufffdK k=1 \u03c4f 2 (h(\u02dcx; \u03b8h)mk)\u22a4K(\u02dcx, \u02dcx; \u03b8h, s)\u22121 k h(\u02dcx; \u03b8h)mk,\nwhere\u2014unlike in Rudner et al. (2023a)\u2014we do not assume that m = 0 and s = I. If we define the auxiliary label distribution as p \u02dcY | \u02dc X(\u02dcy | \u02dcx) \u02d9= \u03b4({0, ..., 0} \u2212\u02dcy), the likelihood \u02dcp(\u02dcyk | \u02dcx, \u03b8h) favors learnable parameters \u03b8h for which the induced distribution over functions has a high likelihood of predicting 0. Letting \u02dcp(\u02dcy | \u02dcx, \u03b8) \u02d9= \ufffdK k=1 \u02dcp(\u02dcyk | \u02dcx, \u03b8, mk, sk),\n\ufffd and taking the log of the analytically tractable density \u02dcp(\u02dcy | \u02dcx, \u03b8; f), we obtain log \u02dcp(\u02dcy | \u02dcx, \u03b8h) \u221d\u2212 \ufffdK k=1 \u03c4f 2 (h(\u02dcx; \u03b8h)mk)\u22a4K(\u02dcx, \u02dcx; \u03b8h, s)\u22121 k h(\u02dcx\n(A.1)\n(A.2)\n(A.3)\n(A.4)\nInformative Priors Improve the Reliability of Multimodal Clinical Data Classification\n# with proportionality up to an additive constant independent of \u03b8. We define\nJ (\u03b8, m, s, \u02dcx, \u02dcy) \u02d9= \u2212 \ufffdK k=1 \u03c4f 2 d2 M(h(\u02dcx; \u03b8h)mk \u2212\u02dcy, K(\u02dcx, \u02dcx; \u03b8h, s)k)\nwhere d2 M(\u2206, K) \u02d9= \u2206\u22a4K\u22121\u2206is the squared Mahalanobis distance for \u2206= v \u2212w. We therefore obta arg max\u03b8 \u02dcp(\u03b8 | \u02dcx, \u02dcy)=arg max\u03b8 J (\u03b8, m, s, \u02dcx, \u02dcy)+log p(\u03b8)\nand hence, maximizing J (\u03b8, m, s, \u02dcx, \u02dcy)+log p(\u03b8) with respect to \u03b8 is mathematically equivalent to maximizing the posterior \u02dcp(\u03b8 | \u02dcx, \u02dcy) and leads to functions that are likely under the distribution over functions induced by the neural network mapping while being consistent with the prior over the network parameters. However, since the parameters m and s are fixed and appear in the auxiliary likelihood function but not in the predictive function f(\u00b7 ; \u03b8), the objective above is not a good choice if the goal is to find parameters \u03b8 that induce functions that have high predictive uncertainty on the set of context points. To address this shortcoming, we include these parameters in the observation model as the mean and variance parameters of the final-layer parameters in f(\u00b7 ; \u03b8), treat them as random variables M and S, place a prior over them, and ultimately infer an approximate posterior distribution for both. In particular, we define a prior over the final-layer parameters \u0398L as\n# p\u0398L(\u03b8L | m, s) = N(\u03b8L; m, sI)\nand corresponding hyperpriors\npM(m) = N(m; \u00b50, \u03c4 \u22121 0 I) pS(s) = Lognormal(s; 0, 2\u03c4 \u22121 s I).\nAs before, we will drop subscripts for brevity unless needed for clarity. The full probabilistic model then ecomes p(y | x, \u03b8h, \u03b8L; f) p(\u03b8, m, s | \u02dcx, \u02dcy). (A.9)\nwith the prior factorizing and simplifying as\np(\u03b8, m, s | \u02dcx, \u02dcy) = \u02dcp(\u03b8h | m, s, \u02dcx, \u02dcy) p(\u03b8L | m, s) p(m) p(s) \u221dp(\u03b8L | m, s) \u02dcp(\u02dcy | \u02dcx, \u03b8; f) p(\u03b8h) p(m) p(s),\nall of which we can compute analytically. With this prior, we can now derive a variational objective and perform approximate inference. We begin by defining a variational distribution, q(\u03b8, m, s, \u02dcx, \u02dcy) \u02d9= q(\u03b8h) q(\u03b8L | m, s) q(m) q(s) q(\u02dcx, \u02dcy),\nall of which we can compute analytically. With this prior, we can now derive a variational objective an perform approximate inference. We begin by defining a variational distribution,\nand frame the inference problem of finding the posterior p(\u03b8, m, s, \u02dcx, \u02dcy | xD, yD) as a problem of optimization, min q\u0398,M,S, \u02dc X, \u02dc Y \u2208Q DKL(q\u0398,M,S, \u02dc X, \u02dcY \u2225p\u0398,M,S, \u02dc X, \u02dcY | XD,YD),\nwhere Q is a variational family. If the posterior p\u0398,M,S, \u02dc X, \u02dcY |XD,YD is in the variational family Q, then the solution to the variational minimization problem is equal to the exact posterior. Modifying the inference problem by defining q(\u02dcx, \u02dcy) \u02d9= p(\u02dcx, \u02dcy) = p(\u02dcy | \u02dcx)p(\u02dcx), which further constrains the variational family, the optimization problem simplifies to min q\u0398,M,S\u2208Q Ep \u02dc X, \u02dc Y \ufffd DKL(q\u0398,M,S \u2225p\u0398,M,S | \u02dc X, \u02dcY ,XD,YD) \ufffd ,\nwhere Q is a variational family. If the posterior p\u0398,M,S, \u02dc X, \u02dcY |XD,YD is in the variational family Q, then the solution to the variational minimization problem is equal to the exact posterior. Modifying the inference problem by defining q(\u02dcx, \u02dcy) \u02d9= p(\u02dcx, \u02dcy) = p(\u02dcy | \u02dcx)p(\u02dcx), which further constrains the variational family, the optimization problem simplifies to\n(A.5)\n(A.6)\n(A.7) (A.8)\n(A.9)\n(A.10)\nwhich can equivalently be expressed as maximizing the variational objective \u00afF(q\u0398, qM, qS) \u02d9= Eq\u0398,M,S[log p(yD | xD, \u0398; f)] \u2212Ep \u02dc X, \u02dc Y [DKL(q\u0398,M,S \u2225p\u0398,M,S | \u02dc X, \u02dcY )]. To obtain a tractable expression of the regularization term, we first note that we can write Ep \u02dc X, \u02dc Y [DKL(q\u0398,M,S \u2225p\u0398,M,S | \u02dc X, \u02dcY )]] = Ep \u02dc X, \u02dc Y \ufffd Eq\u0398qMqS[log q(\u0398)q(M)q(S)] \u2212Eq\u0398qMqS[log p(\u0398, M, S | \u02dcX, \u02dcY )] \ufffd , (A.11) where the first term is the negative entropy and the second term is the negative cross-entropy. Using the same insights as above, we can write Ep \u02dc X, \u02dc Y [Eq\u0398qMqS[log p(\u0398, M, S | \u02dcX, \u02dcY )]] \u221dEp \u02dc X, \u02dc Y \ufffd Eq\u0398hqMqS [log \u02dcp( \u02dcY | \u02dcX, \u0398h, M, S)] + Eq\u0398 [log p(\u0398h) p(\u0398L | M, S) p(M) p(S)] \ufffd , (A.12) up to an additive constant independent of \u03b8, and use it to express the KL divergence in Equation (A.11) up to an additive constant independent of \u03b8 as DKL(q\u0398,M,S \u2225p\u0398,M,S | \u02dc X, \u02dcY ) \u221d\u2212EqMqS[Eq\u0398[log \u02dcp( \u02dcY | \u02dcX, \u0398h, M, S)] + DKL(q\u0398L | M,S \u2225p\u0398L | M,S)] + DKL(q\u0398h \u2225p\u0398h) + DKL(qM \u2225pM) + DKL(qS \u2225pS).\nwith learnable variational parameters \u00b5 \u02d9= {\u00b5h, \u00b5m} and \u03a3 \u02d9= {\u03a3L, \u03a3L} and fixed parameters {\u03c32 m, \u03c32 s},  DKL(q\u0398L | M,S \u2225p\u0398L | M,S) = 0, and the KL divergence simplifies to\nDKL(q\u0398,M,S \u2225p\u0398,M,S | \u02dc X, \u02dcY ) \u221d\u2212Eq\u0398hqMqS[log \u02dcp( \u02dcY | \u02dcX, \u0398h, M, S)] + DKL(q\u0398h \u2225p\u0398h) + DKL(qM \u2225pM) + DKL(qS \u2225pS),\n   where each of the KL divergences can be computed analytically, and we can obtain an unbiased estimator the negative log-likelihood using simple Monte Carlo estimation. Since \u0398h and qM are both mean-field Gaussian distributions, we can equivalently express the full variation objective in a simplified form as\n\ufffd (A.11)\n(A.12)\n(A.13)\n(A.14)\n\ufffd (A.15)\nInformative Priors Improve the Reliability of Multimodal Clinical Data Classification\n# Appendix B. Experimental details\nB.1. Training details\nFor model training, we use the joint fusion protocol defined by Hayat et al. (2022) in which the network is trained end-to-end including the modality specific encoders \u03a6cxr and \u03a6ehr using the fully connected layer g(\u00b7) to obtain the multi-label probabilities \u02c6yfusion. Table A1 shows the details of the dataset splits used as input for our network.\n<div style=\"text-align: center;\">Table A1: Summary of dataset sizes for the unimodal dataset and the combined multimodal dataset. We note that the size of the multimodal dataset decreases when the two modalities are paired.</div>\nDataset\nTraining\nValidation\nTesting\nContext\nClinical time series data\n124,671\n8,813\n20,747\n124,671\nChest X-rays\n42,628\n4,802\n11,914\n42,628\nMultimodal\n7,756\n877\n2,161\n7,756\nWe use the binary cross-entropy loss (Good, 1952), adapted to the multi-label classification task:\n# We use the binary cross-entropy loss (Good, 1952), adapted to the multi-label classification task:\nlog p(y|x, \u03b8; f) = \u2212 n \ufffd i=1 (yi log(\u02c6yi) + (1 \u2212yi)(log(1 \u2212\u02c6yi))),\nwhere \u02c6yi \u02d9= sigmoid(f(xi; \u03b8)). The overall variational objective in our method is given by an expected loglikelihood term, KL regularization, and uncertainty regularization. In the stochastic setting, as described in Figure 1, we combine the training and context datasets as the input for the computation of this loss.\n# B.2. Hyperparameter tuning\nInitially, we used the deterministic baseline model to randomly sample a learning rate between 10\u22125 and 10\u22123 and selected the model and learning rate that achieved the model checkpoint with the best AUROC on the respective validation set. The best learning rate obtained was 2 \u00d7 10\u22124, validated over 10 random seeds of training the deterministic model. For the stochastic model, we performed a standard grid-based search to obtain the best hyper parameters for the regularization function. Table A2 shows the value ranges for each hyperparameter of our grid, which consists of 324 different model combinations. We note that this procedure requires more resources due to the higher number of hyperparameters as compared to the deterministic model. In addition, stochastic models also have more learnable parameters. In our case two times as many parameters, since the model has mean and variance parameters, and the regularization term requires performing a forward pass on the number of context points sampled from the context distribution (which we choose to be fewer points than are contained in each minibatch). In total, as is the case with every mean-field variational distribution, we have more learnable parameters than in a deterministic neural network and require more forward passes for every gradient step.\n<div style=\"text-align: center;\">Table A2: Hyperparameter grid search values for the stochastic model</div>\nTable A2: Hyperparameter grid search values for the stochastic model\nHyperparameter\nValues\nBest\nprior variance\n[1, 0.1, 0.01]\n0.1\nprior likelihood scale\n[1, 0.1, 10]\n1\nprior likelihood f-scale\n[0, 1, 10]\n10\nprior likelihood covariance scale\n[0.1, 0.01, 0.001, 0.0001]\n0.1\nprior likelihood covariance diagonal\n[1, 5, 0.5]\n5\n(B.17)\n# B.3. Model selection\nWe trained our stochastic model for 400 epochs. Since we have four metrics of interest (i.e., AUROC, AUPRC, Selective AUROC and Selective AUPRC), we computed the hypervolume using the volume formula of a 4-dimensional sphere as the main aggregated metric to select the best model checkpoint during training.\nwhere R is the Euclidian magnitude of a 4-dimensional vector. The hypervolume approach ensures that w do not overfit to a single metric in the process of finding the best model.\n# B.4. Technical implementation\nOur data loading and pre-processing pipeline was implemented using PyTorch (Paszke et al., 2019) following the same structure of the code used by Hayat et al. (2022). However, we refactored the original unimodal and multimodal models, training, and evaluation loops using JAX (Bradbury et al., 2018). This framework simplifies the implementation of Bayesian neural networks and stochastic training, which are the basis of the uncertainty quantification methods used in this work. In addition, we obtained a significant reduction in total training time for the unimodal and multimodal models using JAX, compared to PyTorch. We note that due to specific caching procedures of the JAX framework, we had to standardize each xehr instance into 300 time steps for the LSTM encoder to avoid out-of-memory issues. The JAX framework requires that an LSTM encoder defines a static length of the sequences it is going to process, and then it caches this model in order to increase the training speed. This means that if different sequence lengths are used, then JAX would cache an instance of the LSTM encoder for each specific length to be used during each training cycle. The problem arises when dealing with a dataset that contains sequences of dynamic lengths that present high variance, i.e many different sequence lengths for every datapoint in the dataset, just as is the case with MIMIC-IV (Johnson et al., 2021). In comparison, PyTorch does not use this approach and is able to process sequences of dynamic length with one single instance of the LSTM encoder, however this is done at the cost of training speed when you compare both frameworks. All of the experiments were executed using NVIDIA A100 and V100 80Gb Tensor Core GPUs.\n(B.18)\nInformative Priors Improve the Reliability of Multimodal Clinical Data Classification\n# Appendix C. Additional Experimental Results\nIn this section, we provide additional results on the test set. Table A3 presents the results of the stochastic model for different context batch size values.\nsize.\nContext\nbatch size\nAUROC\nAUPRC\nSelective\nAUROC\nSelective\nAUPRC\n16\n0.732 (0.725, 0.739)\n0.511 (0.502, 0.525)\n0.740 (0.728, 0.753)\n0.447 (0.432, 0.469)\n32\n0.733 (0.725, 0.739)\n0.510 (0.500, 0.524)\n0.743 (0.733, 0.756)\n0.448 (0.435, 0.466)\n64\n0.735 (0.728, 0.742)\n0.514 (0.504, 0.528)\n0.748 (0.738, 0.760)\n0.452 (0.441, 0.472)\n128\n0.733 (0.726, 0.739)\n0.512 (0.502, 0.525)\n0.728 (0.718, 0.739)\n0.401 (0.391, 0.418)\nTable A4, Table A5 and Table A6 present the extended results of our experiments for each label for the deterministic baseline, the Bayesian model with standard prior and the Bayesian model with m2d2 prior respectively.\nTable A4, Table A5 and Table A6 present the extended results of our experiments for each label for the deterministic baseline, the Bayesian model with standard prior and the Bayesian model with m2d2 prior, respectively.\nable A4: Performance results across the different labels on the test set for the deterministic baseline (Hayat et al., 2022).\nLabel\nPrevalence\nAUROC\nAUPRC\nSelective\nAUROC\nSelective\nAUPRC\n1 Acute and unspecified renal failure\n0.321\n0.753 (0.732, 0.774)\n0.574 (0.537, 0.613)\n0.775 (0.750, 0.802)\n0.655 (0.600, 0.717)\n2 Acute cerebrovascular disease\n0.078\n0.854 (0.819, 0.888)\n0.427 (0.353, 0.512)\n0.595 (0.526, 0.687)\n0.072 (0.066, 0.098)\n3 Acute myocardial infarction\n0.093\n0.692 (0.654, 0.727)\n0.189 (0.153, 0.234)\n0.634 (0.585, 0.675)\n0.089 (0.080, 0.107)\n4 Cardiac dysrhythmias\n0.379\n0.690 (0.668, 0.713)\n0.563 (0.530, 0.599)\n0.678 (0.649, 0.705)\n0.621 (0.573, 0.682)\n5 Chronic kidney disease\n0.240\n0.755 (0.732, 0.779)\n0.495 (0.454, 0.541)\n0.855 (0.830, 0.878)\n0.600 (0.529, 0.689)\n6 Chronic obstructive pulmonary disease\n0.148\n0.735 (0.706, 0.765)\n0.338 (0.293, 0.390)\n0.814 (0.776, 0.850)\n0.431 (0.334, 0.536)\n7 Complications of surgical/medical care\n0.226\n0.677 (0.650, 0.704)\n0.382 (0.339, 0.428)\n0.583 (0.552, 0.621)\n0.212 (0.202, 0.243)\n8 Conduction disorders\n0.115\n0.787 (0.750, 0.822)\n0.575 (0.515, 0.636)\n0.849 (0.814, 0.882)\n0.746 (0.691, 0.800)\n9 Congestive heart failure; nonhypertensive\n0.295\n0.772 (0.750, 0.794)\n0.593 (0.554, 0.632)\n0.829 (0.808, 0.853)\n0.705 (0.652, 0.758)\n10 Coronary atherosclerosis and related\n0.337\n0.764 (0.744, 0.784)\n0.624 (0.583, 0.663)\n0.842 (0.814, 0.866)\n0.700 (0.640, 0.762)\n11 Diabetes mellitus with complications\n0.120\n0.848 (0.823, 0.872)\n0.485 (0.417, 0.552)\n0.757 (0.704, 0.831)\n0.250 (0.205, 0.305)\n12 Diabetes mellitus without complication\n0.211\n0.710 (0.684, 0.737)\n0.359 (0.324, 0.402)\n0.680 (0.645, 0.731)\n0.251 (0.219, 0.306)\n13 Disorders of lipid metabolism\n0.406\n0.694 (0.671, 0.715)\n0.593 (0.556, 0.630)\n0.749 (0.721, 0.776)\n0.671 (0.617, 0.720)\n14 Essential hypertension\n0.433\n0.653 (0.630, 0.676)\n0.561 (0.525, 0.595)\n0.624 (0.598, 0.653)\n0.599 (0.549, 0.653)\n15 Fluid and electrolyte disorders\n0.454\n0.711 (0.689, 0.731)\n0.681 (0.649, 0.713)\n0.688 (0.664, 0.713)\n0.779 (0.746, 0.811)\n16 Gastrointestinal hemorrhage\n0.071\n0.629 (0.583, 0.677)\n0.135 (0.100, 0.183)\n0.590 (0.542, 0.646)\n0.078 (0.066, 0.091)\n17 Hypertension with complications\n0.222\n0.746 (0.720, 0.768)\n0.452 (0.407, 0.499)\n0.842 (0.810, 0.868)\n0.549 (0.451, 0.644)\n18 Other liver diseases\n0.169\n0.684 (0.654, 0.715)\n0.336 (0.291, 0.385)\n0.701 (0.642, 0.754)\n0.375 (0.286, 0.476)\n19 Other lower respiratory disease\n0.126\n0.615 (0.580, 0.651)\n0.209 (0.172, 0.256)\n0.577 (0.539, 0.612)\n0.118 (0.109, 0.141)\n20 Other upper respiratory disease\n0.054\n0.638 (0.585, 0.686)\n0.092 (0.068, 0.127)\n0.551 (0.489, 0.640)\n0.055 (0.049, 0.074)\n21 Pleurisy; pneumothorax; pulmonary\n0.095\n0.665 (0.629, 0.698)\n0.182 (0.146, 0.230)\n0.607 (0.558, 0.658)\n0.088 (0.084, 0.111)\n22 Pneumonia\n0.185\n0.733 (0.707, 0.758)\n0.373 (0.327, 0.427)\n0.739 (0.698, 0.787)\n0.316 (0.261, 0.407)\n23 Respiratory failure; insufficiency;\n0.282\n0.786 (0.766, 0.807)\n0.603 (0.566, 0.642)\n0.841 (0.817, 0.864)\n0.719 (0.671, 0.769)\n24 Septicemia (except in labor)\n0.227\n0.755 (0.731, 0.778)\n0.504 (0.460, 0.550)\n0.841 (0.809, 0.869)\n0.626 (0.558, 0.696)\n25 Shock\n0.174\n0.816 (0.791, 0.840)\n0.554 (0.507, 0.604)\n0.867 (0.821, 0.903)\n0.663 (0.580, 0.728)\nmodel.\nLabel\nPrevalence\nAUROC\nAUPRC\nSelective\nAUROC\nSelective\nAUPRC\n1 Acute and unspecified renal failure\n0.321\n0.747 (0.726, 0.768)\n0.573 (0.537, 0.611)\n0.817 (0.790, 0.845)\n0.672 (0.618, 0.732)\n2 Acute cerebrovascular disease\n0.078\n0.861 (0.828, 0.893)\n0.418 (0.350, 0.498)\n0.590 (0.520, 0.678)\n0.074 (0.067, 0.101)\n3 Acute myocardial infarction\n0.093\n0.705 (0.670, 0.741)\n0.208 (0.166, 0.266)\n0.694 (0.656, 0.729)\n0.087 (0.078, 0.104)\n4 Cardiac dysrhythmias\n0.379\n0.698 (0.676, 0.721)\n0.577 (0.544, 0.615)\n0.744 (0.707, 0.776)\n0.626 (0.570, 0.688)\n5 Chronic kidney disease\n0.240\n0.739 (0.716, 0.762)\n0.476 (0.432, 0.520)\n0.808 (0.772, 0.841)\n0.574 (0.499, 0.648)\n6 Chronic obstructive pulmonary disease\n0.148\n0.729 (0.700, 0.761)\n0.338 (0.290, 0.393)\n0.802 (0.762, 0.842)\n0.428 (0.334, 0.535)\n7 Complications of surgical/medical care\n0.226\n0.657 (0.627, 0.685)\n0.383 (0.338, 0.429)\n0.672 (0.627, 0.716)\n0.394 (0.321, 0.473)\n8 Conduction disorders\n0.115\n0.817 (0.781, 0.848)\n0.596 (0.537, 0.657)\n0.871 (0.832, 0.906)\n0.734 (0.650, 0.810)\n9 Congestive heart failure; nonhypertensive\n0.295\n0.783 (0.762, 0.805)\n0.618 (0.579, 0.656)\n0.867 (0.840, 0.892)\n0.739 (0.688, 0.787)\n10 Coronary atherosclerosis and related\n0.337\n0.766 (0.745, 0.787)\n0.645 (0.605, 0.680)\n0.836 (0.802, 0.862)\n0.735 (0.686, 0.781)\n11 Diabetes mellitus with complications\n0.120\n0.811 (0.783, 0.837)\n0.429 (0.368, 0.495)\n0.844 (0.804, 0.874)\n0.359 (0.240, 0.444)\n12 Diabetes mellitus without complication\n0.211\n0.691 (0.664, 0.717)\n0.354 (0.319, 0.399)\n0.642 (0.607, 0.682)\n0.222 (0.201, 0.265)\n13 Disorders of lipid metabolism\n0.406\n0.685 (0.662, 0.708)\n0.579 (0.545, 0.614)\n0.759 (0.730, 0.785)\n0.617 (0.564, 0.674)\n14 Essential hypertension\n0.433\n0.660 (0.637, 0.681)\n0.576 (0.543, 0.611)\n0.716 (0.684, 0.746)\n0.632 (0.582, 0.680)\n15 Fluid and electrolyte disorders\n0.454\n0.714 (0.693, 0.734)\n0.668 (0.635, 0.700)\n0.708 (0.685, 0.736)\n0.756 (0.718, 0.796)\n16 Gastrointestinal hemorrhage\n0.071\n0.638 (0.593, 0.682)\n0.131 (0.097, 0.177)\n0.606 (0.561, 0.676)\n0.071 (0.066, 0.092)\n17 Hypertension with complications\n0.222\n0.733 (0.710, 0.757)\n0.431 (0.388, 0.479)\n0.779 (0.735, 0.818)\n0.486 (0.397, 0.579)\n18 Other liver diseases\n0.169\n0.696 (0.664, 0.727)\n0.354 (0.305, 0.403)\n0.731 (0.680, 0.780)\n0.429 (0.345, 0.526)\n19 Other lower respiratory disease\n0.126\n0.604 (0.567, 0.642)\n0.181 (0.153, 0.219)\n0.582 (0.547, 0.617)\n0.123 (0.113, 0.145)\n20 Other upper respiratory disease\n0.054\n0.685 (0.632, 0.739)\n0.165 (0.109, 0.236)\n0.618 (0.552, 0.685)\n0.101 (0.052, 0.205)\n21 Pleurisy; pneumothorax; pulmonary\n0.095\n0.666 (0.629, 0.701)\n0.166 (0.135, 0.208)\n0.593 (0.543, 0.657)\n0.090 (0.082, 0.120)\n22 Pneumonia\n0.185\n0.758 (0.732, 0.781)\n0.400 (0.355, 0.455)\n0.783 (0.743, 0.829)\n0.341 (0.270, 0.436)\n23 Respiratory failure; insufficiency;\n0.282\n0.824 (0.804, 0.843)\n0.631 (0.592, 0.675)\n0.890 (0.868, 0.909)\n0.703 (0.637, 0.771)\n24 Septicemia (except in labor)\n0.227\n0.783 (0.761, 0.805)\n0.522 (0.476, 0.572)\n0.866 (0.834, 0.892)\n0.629 (0.530, 0.703)\n25 Shock\n0.174\n0.826 (0.804, 0.847)\n0.552 (0.502, 0.606)\n0.888 (0.858, 0.918)\n0.582 (0.507, 0.658)\n<div style=\"text-align: center;\">Table A6: Performance results across the different labels on the test set for the Bayesian (m2d2 prior) model.</div>\nLabel\nPrevalence\nAUROC\nAUPRC\nSelective\nAUROC\nSelective\nAUPRC\n1 Acute and unspecified renal failure\n0.321\n0.756 (0.735, 0.779)\n0.587 (0.551, 0.627)\n0.830 (0.800, 0.857)\n0.680 (0.617, 0.740)\n2 Acute cerebrovascular disease\n0.078\n0.870 (0.840, 0.901)\n0.459 (0.385, 0.545)\n0.664 (0.598, 0.745)\n0.088 (0.076, 0.115)\n3 Acute myocardial infarction\n0.093\n0.716 (0.681, 0.754)\n0.220 (0.174, 0.277)\n0.656 (0.611, 0.698)\n0.083 (0.077, 0.104)\n4 Cardiac dysrhythmias\n0.379\n0.687 (0.663, 0.710)\n0.570 (0.536, 0.606)\n0.737 (0.706, 0.768)\n0.654 (0.603, 0.709)\n5 Chronic kidney disease\n0.240\n0.767 (0.744, 0.789)\n0.507 (0.464, 0.553)\n0.853 (0.825, 0.879)\n0.612 (0.534, 0.690)\n6 Chronic obstructive pulmonary disease\n0.148\n0.727 (0.700, 0.757)\n0.326 (0.280, 0.377)\n0.773 (0.725, 0.814)\n0.413 (0.293, 0.503)\n7 Complications of surgical/medical care\n0.226\n0.659 (0.631, 0.686)\n0.396 (0.351, 0.444)\n0.666 (0.620, 0.708)\n0.375 (0.310, 0.462)\n8 Conduction disorders\n0.115\n0.798 (0.763, 0.832)\n0.593 (0.532, 0.656)\n0.850 (0.814, 0.889)\n0.754 (0.689, 0.812)\n9 Congestive heart failure; nonhypertensive\n0.295\n0.788 (0.768, 0.808)\n0.600 (0.562, 0.637)\n0.874 (0.853, 0.892)\n0.722 (0.663, 0.773)\n10 Coronary atherosclerosis and related\n0.337\n0.767 (0.746, 0.787)\n0.626 (0.588, 0.665)\n0.846 (0.820, 0.869)\n0.716 (0.654, 0.769)\n11 Diabetes mellitus with complications\n0.120\n0.842 (0.817, 0.866)\n0.461 (0.398, 0.528)\n0.821 (0.765, 0.906)\n0.344 (0.256, 0.472)\n12 Diabetes mellitus without complication\n0.211\n0.716 (0.690, 0.742)\n0.386 (0.345, 0.432)\n0.673 (0.634, 0.727)\n0.256 (0.223, 0.313)\n13 Disorders of lipid metabolism\n0.406\n0.698 (0.675, 0.720)\n0.591 (0.558, 0.628)\n0.773 (0.746, 0.798)\n0.624 (0.572, 0.685)\n14 Essential hypertension\n0.433\n0.669 (0.646, 0.694)\n0.588 (0.555, 0.621)\n0.709 (0.677, 0.740)\n0.643 (0.588, 0.695)\n15 Fluid and electrolyte disorders\n0.454\n0.717 (0.695, 0.737)\n0.679 (0.647, 0.709)\n0.739 (0.712, 0.767)\n0.771 (0.732, 0.811)\n16 Gastrointestinal hemorrhage\n0.071\n0.667 (0.627, 0.708)\n0.134 (0.104, 0.185)\n0.596 (0.537, 0.720)\n0.068 (0.064, 0.089)\n17 Hypertension with complications\n0.222\n0.760 (0.736, 0.781)\n0.475 (0.430, 0.522)\n0.843 (0.810, 0.872)\n0.574 (0.483, 0.666)\n18 Other liver diseases\n0.169\n0.723 (0.693, 0.750)\n0.378 (0.330, 0.428)\n0.673 (0.614, 0.743)\n0.313 (0.228, 0.423)\n19 Other lower respiratory disease\n0.126\n0.594 (0.560, 0.629)\n0.181 (0.154, 0.222)\n0.568 (0.533, 0.612)\n0.120 (0.114, 0.144)\n20 Other upper respiratory disease\n0.054\n0.670 (0.614, 0.722)\n0.133 (0.094, 0.193)\n0.540 (0.483, 0.603)\n0.052 (0.048, 0.071)\n21 Pleurisy; pneumothorax; pulmonary\n0.095\n0.692 (0.658, 0.726)\n0.167 (0.139, 0.207)\n0.630 (0.576, 0.707)\n0.086 (0.081, 0.109)\n22 Pneumonia\n0.185\n0.756 (0.732, 0.781)\n0.411 (0.362, 0.468)\n0.808 (0.769, 0.851)\n0.395 (0.328, 0.499)\n23 Respiratory failure; insufficiency;\n0.282\n0.811 (0.790, 0.831)\n0.633 (0.594, 0.673)\n0.876 (0.848, 0.899)\n0.733 (0.675, 0.791)\n24 Septicemia (except in labor)\n0.227\n0.774 (0.751, 0.797)\n0.513 (0.467, 0.559)\n0.818 (0.772, 0.865)\n0.582 (0.504, 0.664)\n25 Shock\n0.174\n0.809 (0.786, 0.833)\n0.536 (0.486, 0.586)\n0.876 (0.838, 0.902)\n0.637 (0.546, 0.702)\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of uncertainty quantification in machine learning for healthcare, which has been largely neglected, especially in multimodal settings. Previous methods have been limited and often do not improve reliability, necessitating a new approach to enhance predictive performance.",
        "problem": {
            "definition": "The paper aims to solve the problem of unreliable predictive models in healthcare due to inadequate uncertainty quantification, particularly when dealing with multimodal data such as clinical time-series and imaging data.",
            "key obstacle": "The main difficulty is the lack of effective uncertainty quantification methods that can handle distribution shifts in real-world clinical applications, leading to poor predictive performance."
        },
        "idea": {
            "intuition": "The idea is inspired by the need for better uncertainty quantification in clinical predictions, particularly when integrating different data modalities.",
            "opinion": "The proposed idea involves creating a multimodal data-driven (m2d2) prior distribution over neural network parameters to enhance uncertainty quantification in predictive models.",
            "innovation": "The key innovation lies in using a data-driven prior that effectively captures the complexities of multimodal data, improving upon existing standard Gaussian priors that have shown to be ineffective."
        },
        "method": {
            "method name": "Multimodal Data-Driven Prior (m2d2)",
            "method abbreviation": "m2d2",
            "method definition": "The m2d2 method defines a prior distribution over neural network parameters that is informed by the characteristics of multimodal clinical data.",
            "method description": "This method integrates clinical time-series data and chest X-ray images to enhance predictive modeling in healthcare.",
            "method steps": [
                "Define the multimodal fusion task with clinical time-series data and imaging data.",
                "Construct a multimodal data-driven prior by applying transformations to create context points.",
                "Train a Bayesian neural network using the constructed prior.",
                "Evaluate the model's predictive performance and reliability."
            ],
            "principle": "This method is effective because it leverages contextually relevant data to inform the prior, leading to better uncertainty estimation and improved reliability in predictions."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted using the MIMIC-IV clinical time-series dataset and MIMIC-CXR chest X-ray dataset, focusing on acute care condition classification.",
            "evaluation method": "Performance was assessed using metrics such as AUROC and AUPRC, and selective prediction metrics were computed over various rejection thresholds."
        },
        "conclusion": "The proposed m2d2 prior enhances the reliability of multimodal predictive models, demonstrating improved performance metrics compared to deterministic models and standard Bayesian methods.",
        "discussion": {
            "advantage": "The primary advantage of the m2d2 method is its ability to improve predictive performance and uncertainty quantification in multimodal settings, making it more reliable for clinical applications.",
            "limitation": "A limitation noted is the potential for decreased selective AUPRC compared to 0%-rejection AUPRC, indicating challenges in model calibration.",
            "future work": "Future research will explore the application of the m2d2 prior in scenarios with missing modalities and other clinical prediction tasks."
        },
        "other info": {
            "acknowledgements": "The research was supported by high-performance computing resources at New York University Abu Dhabi. Special thanks to Dr. Alejandro Guerra Manzanares for discussions and code refactoring support."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "Uncertainty quantification is critical for developing reliable and secure AI systems, particularly in healthcare applications where predictive models often lack reliability."
        },
        {
            "section number": "2.5",
            "key information": "The m2d2 method enhances uncertainty quantification in predictive models by creating a multimodal data-driven prior distribution that captures the complexities of multimodal data."
        },
        {
            "section number": "3.5",
            "key information": "The m2d2 method represents an innovative framework for uncertainty quantification in machine learning, particularly for healthcare applications involving multimodal data."
        },
        {
            "section number": "6",
            "key information": "The proposed m2d2 prior improves uncertainty estimation by leveraging contextually relevant data, leading to better reliability in predictions."
        },
        {
            "section number": "7.1",
            "key information": "A key challenge in current OOD detection methods is the lack of effective uncertainty quantification techniques that can handle distribution shifts in real-world clinical applications."
        },
        {
            "section number": "7.2",
            "key information": "Future research directions include exploring the application of the m2d2 prior in scenarios with missing modalities and other clinical prediction tasks, indicating potential advancements in uncertainty estimation."
        }
    ],
    "similarity_score": 0.6156459246803203,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Informative Priors Improve the Reliability of Multimodal Clinical Data Classification.json"
}