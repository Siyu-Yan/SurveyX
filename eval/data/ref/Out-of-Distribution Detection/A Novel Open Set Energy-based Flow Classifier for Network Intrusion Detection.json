{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2109.11224",
    "title": "A Novel Open Set Energy-based Flow Classifier for Network Intrusion Detection",
    "abstract": "Network intrusion detection systems (NIDS) are one of many solutions that make up a computer security system. Several machine learning-based NIDS have been proposed in recent years, but most of them were developed and evaluated under the assumption that the training context is similar to the test context. In real networks, this assumption is false, given the emergence of new attacks and variants of known attacks. To deal with this reality, the open set recognition field, which is the most general task of recognizing classes not seen during training in any domain, began to gain importance in NIDS research. Yet, existing solutions are often bounded to high temporal complexities and performance bottlenecks. In this work, we propose an algorithm to be used in NIDS that performs open set recognition. Our proposal is an adaptation of the single-class Energy-based Flow Classifier (EFC), which proved to be an algorithm with strong generalization capability and low computational cost. The new version of EFC correctly classifies not only known attacks, but also unknown ones, and differs from other proposals from the literature by presenting a single layer with low temporal complexity. Our proposal was evaluated against well-established multi-class algorithms and as an open set classifier. It proved to be an accurate classifier in both evaluations, similar to the state of the art. As a conclusion of our work, we consider EFC a promising algorithm to be used in NIDS for its high performance and applicability in real networks.",
    "bib_name": "souza2022novelopensetenergybased",
    "md_text": "# A Novel Open Set Energy-based Flow Classifier for Network Intrusion Detection\nManuela M. C. Souza, Camila Pontes, Jo\u00e3o J. C. Gondim, Lu\u00eds P. F. Garcia, Luiz DaSilva, Fellow, IEEE, and Marcelo A. Marotta, Member, IEEE\nAbstract\u2014Network intrusion detection systems (NIDS) are one of many solutions that make up a computer security system. Several machine learning-based NIDS have been proposed in recent years, but most of them were developed and evaluated under the assumption that the training context is similar to the test context. In real networks, this assumption is false, given the emergence of new attacks and variants of known attacks. To deal with this reality, the open set recognition field, which is the most general task of recognizing classes not seen during training in any domain, began to gain importance in NIDS research. Yet, existing solutions are often bounded to high temporal complexities and performance bottlenecks. In this work, we propose an algorithm to be used in NIDS that performs open set recognition. Our proposal is an adaptation of the single-class Energy-based Flow Classifier (EFC), which proved to be an algorithm with strong generalization capability and low computational cost. The new version of EFC correctly classifies not only known attacks, but also unknown ones, and differs from other proposals from the literature by presenting a single layer with low temporal complexity. Our proposal was evaluated against well-established multi-class algorithms and as an open set classifier. It proved to be an accurate classifier in both evaluations, similar to the state of the art. As a conclusion of our work, we consider EFC a promising algorithm to be used in NIDS for its high performance and applicability in real networks. Index Terms\u2014Network Intrusion Detection Systems, Energybased Flow Classifier, Multi-class classification, Open Set classification.\n# I. INTRODUCTION\nAs organizations and individuals become increasingly connected, network attacks become more dangerous for victims and more attractive to cybercriminals. Security reports such as ENISA Threat Landscape [1], DCMS\u2019s Cyber Security Breaches Survey [2], and ACSC Annual Cyber Threat Report [3] have shown, year after year, the devastating impact of cyber attacks, ranging from the exposure of personal identifiable information to extortion of millions of dollars in ransom payments. With the sophistication of threat capabilities increasing\nas we move deeper into the digital age, developing better security systems is critical. Currently, an important component of security systems are Network Intrusion Detection System (NIDS). A NIDS is a software used in conjunction with firewalls and antivirus to protect networked devices from several threats [4]. They can be implemented for different purposes, such as simply detecting network anomalies or detecting and classifying anomalies. This latter descriptive approach is particularly interesting because categorizing intrusions enables the formulation of effective incident response actions, increasing the overall system performance [5]. Although NIDS research has advanced a lot in recent years, there are still some issues with state-of-the-art systems present in the literature. As argue Zhang et al. [6] and Apruzzese et al. [7], the majority of papers in NIDS evaluate their proposals under closed-set experiments, i.e., using the same network context in both train and test. This type of assessment does not reflect real networks, as it ignores the presence of new types of attacks or variations of known attacks. To develop an effective NIDS, this problem must be taken into account. Some descriptive NIDS capable of identifying unknown traffic have been proposed lately. These systems are able to recognize samples of classes that were not seen in the training stage, which is called open set recognition. In special, Zhang et al. [6] have show great results using neural networks to perform open set classification in the intrusion detection domain. However, these proposals are often bounded to high temporal complexities and performance bottlenecks duo to the techniques they employ, like deep learning algorithms or cascading supervised classifiers. Naturally, this is not desirable since fast traffic analysis is a key requirement for NIDS [8]. Considering these limitations, an NIDS capable of detecting unknown attacks and classifying intrusions with a low computational complexity is needed. In this work, we propose a novel classifier to detect unknown attacks and to classify known intrusions. Our model consists of an adaptation of the single-class Energy-based Flow Classifier (EFC) [9], which proved to be a method with good generalization capacity and low computational cost. The algorithm we present inherits the advantages of the original method, while extends its functionality to the identification and categorization of several attacks types. We evaluated our proposed classifier using an up-to-date flow-based network intrusion dataset, CICIDS2017 [10]. We performed experiments comparing the EFC with classical\nmachine learning multi-classifiers and with other similar proposals from the literature, both in closed-set and open set experiments. The main contributions of our work are: \u2022 The proposal and development of the multi-class Energybased Flow Classifier; \u2022 A performance comparison between EFC and other multiclassifiers in closed-set experiments; \u2022 An assessment of different multi-class classifiers\u2019 ability to correctly identify unknown attacks in open set experiments The remainder of this paper is organized as follows: section II briefly summarizes some recent work on open set NIDS. Section III presents the fundamentals of the statistical framework employed by EFC and the implementation of the multiclass EFC. Section IV describes the methodology adopted in this work, including experiments, evaluation metrics and dataset. Section V present and discusses the results of the experiments. Finally, section VI closes the paper with conclusions and suggestions for future research.\n# II. RELATED WORK\nIn this section, we present an overview of the literature related to our work. In recent years, a wide variety of NIDS were developed using Machine Learning (ML) classifiers. We review some of these works focusing on descriptive classifiers, i.e., which perform multi-classification, and on open set classifiers, that can detect unknown attacks. To coordinate the discussion and to position our work, we review the literature about NIDS considering the proposed taxonomy presented in Figure 1.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8d31/8d313b43-acd4-40ae-a72d-48d4acc2eee4.png\" style=\"width: 50%;\"></div>\nBinary NIDSs classify traffic into two classes: benign or malicious. They are useful to identify and block intrusions, but they do not provide information about identified attacks. We highlight EFC as it was first presented by Pontes et al. [9], as a binary classifier. EFC performance was evaluated in the CICIDS2017, CIDDS-001 and CICDDoS2019 datasets and it was compared with several other ML classifiers. From these experiments, it was concluded that EFC is capable of detecting\nanomalies in the three datasets with low computational cost and is also a robust algorithm to distribution changes. Due to these characteristics, we propose to modify the original single-class EFC method to perform multi-class classification by using the Potts model to model not only benign flows, but also several attacks classes. In addition to the feature of multi-classification, we also implemented a mechanism to identify unknown attacks. The ability to detect unknown classes is critical for modern network intrusion detection systems and is a particular case of a problem called open set recognition, which is the more general task of recognizing classes unseen in training in any domain [11]. The open set field was initially developed for computer vision applications where it has been an important research topic with several notable works. Hendrycks et al. [12] proposed the Baseline method that utilizes probabilities from softmax distributions to identify unknown samples. They assessed the Baseline performance in tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all these domains. Later, the ODIN [13] method was proposed by Liang et al. establishing a new stateof-the-art performance on the open set image recognition task. ODIN reduces the false positive rate compared to the Baseline from 34.7% to 4.3% on the DenseNet when the true positive rate is 95%. Meanwhile, in the field of intrusion detection, open set recognition hasn\u2019t been widely explored. On the contrary, most experimental evaluations of machine learning-based NIDS are done in closed-set experiments [7] and, under this assumption, traditional ML classifiers like Support Vector Machine (SVM) [14], Decision Tree (DT) [15] [16] and Artificial Neural Network (ANN) [17] [18] [19] have already achieved almost perfect rates. Despite of this, in recent years, some works on NIDS have tried to develop more realistic models with more robust assessments. Al-Yaseen et al. (2017) [20] proposed a multi-level Intrusion Detection System (IDS) composed of five cascading layers, each identifying an attack class using SVM or Extreme Learning Machine (ELM) classifiers. After filtering all classes, the final layer classifies the remaining samples as Normal or Unknown with a SVM classifier. The model overall detection rate in NSL-KDD dataset was 95.17%. In our work, we also classify intrusions into known classes and a Suspicious class, but the complexity of our algorithm is considerably lower than their, especially in the classification phase. Cruz et al. (2017) [21] applied the Weibull-calibrated SVM (W-SVM) classifier on the KDDCUP\u201999 dataset in an open set experiment. They performed a comparison between a multiclass closed set Gaussian RBF kernel Platt-calibrated SVM, and a multi-class open set Gaussian RBF kernel W-SVM. They concluded that the accuracy of the two models is similar, but by weighting the accuracy to give more importance to unknown samples, the W-SVM exhibits better results. On the basis of [21], Henrydoss et al. (2017) [22] investigated the EVM classifier in the intrusion detection domain. EVM is a generic multi-class classifier theoretically derived\nfrom the statistical Extreme Value Theory and developed in the context of computer vision [23]. Henrydoss et al. applied EVM to the KDDCUP\u201999 dataset, testing it on different degrees of openness i.e., on sets with different proportions of unknown data. They compared its accuracy with the W-SVM [21] and concluded that they have similar performances in every degree of openness. More recently, Yao et al. (2019) [24] developed a novel IDS framework based on Hybrid Multi-Level Data Mining (HMLD), evaluated on the KDDCUP\u201999 dataset. Their model classification phase consists of filtering each attack with a specific classifier trained to detect this attack. The chosen classifiers were SVM and ANN. Samples not classified as belonging to any of the known classes are called Impurity Data. A small subset of the Impurity Data is provided to a specialist to be labeled in new attack classes. Afterwards, this labeled set is used to train a DT to classify the Impurity Data. The overall model accuracy in the KDDCUP\u201999 dataset was 96.70%. In our work, we also create a separate class for unknown intrusions, but our process is completely automatic, not requiring the labelling by a specialist. In addition, we also achieve a lower temporal complexity than ANN and SVM. Finally, Zhang et al. [6] proposed what we considered to be the state-of-art in open set intrusion detection. The open set Classification Network (OCD) is an ANN based on the convolutional neural network that adopts the nearest class mean (NCM) classifier and uses both fisher loss and MMD loss to jointly optimize the CNN model. In addition, they proposed a method to discover new attacks among the unknown attack instances detected by OCN and to incrementaly learn the classification of the discovered attack. They conducted several experiments in the KDDCUP\u201999 dataset and CICIDS2017 dataset, showing that their classifier outcomes the state-of-art detectors. In our work, we compared the performance of the EFC with the OCN in terms of detecting unknown attacks in the CICIDS2017 dataset. Although in its early days, there have been some development in open set classifiers in the area of intrusion detection. However, to the best of our knowledge, all of these proposals are complex algorithms, such as cascade systems with several classifiers, like the Multi-level Hybrid model from [20] and the HMLD framework from [24]; or deep neural network methods, like Baseline [12], ODIN [13] and OCN [6]; or SVM-based methods, like W-SVM [21] and EVM [22]. All these proposals are bounded to performance problems and may not be useful outside the research field, as part of real-time NIDS. We propose a new classifier that stands out from other open set proposals for having a simple and effective classification mechanism for both known and unknown classes with low temporal complexity. In the following section, we present the conceptual foundations of EFC [9] and the modifications made for the multi-class version.\n# III. ENERGY-BASED FLOW CLASSIFICATION\nIn this section, we present the energy-based classification technique. First, in subsection A, we briefly explain the EFC method as it was originally developed in [9]. Although\nsubsection A n is not a complete explanation of the EFC, it gives the reader a reasonable understanding of it as well as some key definitions to the method, which will be necessary to understand the proposal of this work. Afterwards, in subsection B, we present the adaptation of the former method to perform multi-class classification and open-set detection.\n# A. Model inference\nThe main idea of EFC\u2019s training phase is to perform a mean field variational (Bayesian) inference to find the posterior probability distribution underlying the flow class to be detected. Once the posterior distribution is defined, it is used to classify new flows. This is done by calculating a quantity called flow energy, which is a measure of how unlikely a flow is to belong to a given probability distribution. The definition of energy was kept unchanged as a quantity coming from the original inference problem from statistical physics (the Potts model), which was concerned with atomic spins in a lattice and served as inspiration for the development of the EFC. To train EFC\u2019s model, a set of latent variables must be inferred. This set of latent variables define a posterior distribution, which is a probability distribution conditioned to the observed (training) data. There are basically two sets of variables that need to be inferred for each flow class: 1storder variables, or local fields \u210e\ud835\udc56, and 2nd order variables, or coupling values \ud835\udc52\ud835\udc56\ud835\udc57. Then, in classification phase, it is possible to calculate the energy of a new flow using the previously inferred latent variables for a given flow class. The energy of a flow \ud835\udc58is a linear combination of local fields and coupling values for all features and features pairs of flow \ud835\udc58, and it reflects how likely it is that this exact configuration of features values occurs in the flow set S. If the flow energy is high, it means that it has a low probability of belonging to that class \u2013 in other words, that it does not resemble the flows that generated the posterior distribution for that class. Likewise, if the energy is low, the flow is more likely to belong to the set of flows that generated the posterior distribution for that class. To decide whether the energy is high or low, we use a threshold defined by the 95th percentile of the energies of the samples used to infer the model. In single-class EFC, the training is done with benign samples only. Therefore, the classification is performed with respect to the normal distribution: if the flow has lowest energy than the 95th percentile of the benign samples, i.e., below the threshold, it is considered to be normal. Otherwise, it is labeled as abnormal traffic. For more details on the development of single-class EFC, as well as a complete explanation of the model inference, please refer to [9]. Next, we will present our proposed multi-class version of EFC and an algorithm for its implementation.\n# B. Multi-class EFC\nThe multi-class EFC uses the same techniques as the singleclass version, i.e., the algorithm decides whether a flow belongs to a class by looking at its energy value. However,\nin the single-class version the flow energy is calculated only with respect to the normal distribution, resulting in a binary classification. In the multi-class case, several distributions are inferred, one for each flow class. Afterwards, flow energies are calculated in each distribution and their values are compared to return the classification result. Figure 2 shows the multi-class EFC training process. This phase consists of a replication of the single-class training process to more than one class. While in the single-class version we infer a model only for the benign traffic class, here we need to infer a model for each flow class. So, initially, training samples are grouped by class. Then, the models are inferred and the thresholds are computed for each class, in the same way as the single-class version, i.e., calculating the local fields, coupling values and assuming an statistical threshold, namely the 95th percentile of training samples energies. Lastly, the models induced for each class are stored to be used in the classification phase.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4af4/4af4f526-5851-4fda-b59d-0fb039a3aca9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: Multi-class EFC training phase</div>\nFigure 3 shows the classification process of the multiclass EFC. To classify an instance from the test set, its energy is computed in each model induced in the training phase, generating an energy vector for each instance. As explained in the previous subsection, the energy of a flow in a distribution is a measure of dissimilarity of that flow to the set used to infer the distribution. So, the energy vector of a flow actually contains values inversely proportional to the probabilities of the flow belonging to each class. Therefore, after computing the energies, EFC takes the lowest generated value and compares it with the threshold of that class (since the lowest energy corresponds to the higher similarity). If the energy is below the threshold, the flow is considered to be from the class that generated the energy, otherwise it is classified as suspicious. This second situation means that even the class that most closely resembles the flow isn\u2019t similar enough to it. Therefore, the flow is considered to be suspicious, possibly corresponding to an unknown type of attack. In more formal terms, let F\ud835\udc60\u2282S be the set of all flows labeled \ud835\udc60\u2208{1,...,\ud835\udc59} in the training set S. For all \ud835\udc60\u2208{1,...,\ud835\udc59}, we infer the coupling values \ud835\udc52\ud835\udc60\ud835\udc56\ud835\udc57and local fields \u210e\ud835\udc60\ud835\udc56from F\ud835\udc60, and define the threshold \ud835\udc61\ud835\udc60as the 95th percentile of the energies of samples in F\ud835\udc60, calculated using \ud835\udc52\ud835\udc60\ud835\udc56\ud835\udc57and \u210e\ud835\udc60\ud835\udc56. To classify a new flow, we compute the energies vector H1,...,H\ud835\udc59, where H\ud835\udc60is the Hamiltonian for class \ud835\udc60, and take the minimum value H\ud835\udc5fof that vector. If H\ud835\udc5f\u2264\ud835\udc61\ud835\udc5fwe label the flow with class \ud835\udc5f. Otherwise, we label it as suspicious.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2de2/2de2f7fe-8b4b-4af7-8641-42a58ef1f17e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3: Multi-class EFC testing phase</div>\nTest  samples Energy in  normal  model Energy in  class 1  model Energy in  class K  model . . . Models Lower  Algorithm 1 shows the pseudo-code of the procedures described above. Lines 2 to 11 represent the EFC\u2019s training phase, in which the F\ud835\udc60sets are separated, the statistical models \ud835\udc52\ud835\udc60\ud835\udc56\ud835\udc57and \u210e\ud835\udc60\ud835\udc56are induced and the threshold \ud835\udc61\ud835\udc60is defined, for each class \ud835\udc60\u2208{1,...,\ud835\udc59}. When a network flow is captured, lines 16 to 38 perform its classification. First, the energy vector H1,...,H\ud835\udc59is computed, using each model inferred in the training phase. Then, lines 28-32 select the lowest energy H\ud835\udc5fand check if it is below the threshold \ud835\udc61\ud835\udc5f. If so, the flow is labeled as \ud835\udc5f. Otherwise, it is labeled as suspicious. The classifier training complexity (lines 2-11) is\nReturn  classification Apply class  threshold  where \ud835\udc41is the number of instances in the training set, \ud835\udc3f is the number of classes, \ud835\udc40is the number of features and \ud835\udc44is the size of the alphabet used for discretization, i.e., the maximum number of bins obtained in the discretization. Considering that \ud835\udc41is expected to be much bigger than the number of classes, the number of features and the size of the discretization alphabet, the term \ud835\udc3f\ud835\udc41\ud835\udc402\ud835\udc442 is dominant over \ud835\udc3f\ud835\udc403\ud835\udc443 and we can simplify EFC trainig complexity to\nMeanwhile, the complexity for classification phase (lines 1638) is 2\nMeanwhile, the complexity for classification phase (lines 16-\nTherefore, both training and testing complexities are linear in the number of samples and can scale up well. In the next section, we will discuss the datasets, metrics and the experimental setup used to evaluate the classifier presented in this section.\n# IV. METHODOLOGY\nThis section describes in detail the methodology adopted in this work to evaluate the multi-class EFC. Subsection IV-A discusses the experiments carried out with the classifier and\nAlgorithm 1 Multi-class Energy-based Flow Classifier Input: \ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc60(\ud835\udc3e\u00d7\ud835\udc41), \ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc52\ud835\udc59\ud835\udc60(\ud835\udc3f), \ud835\udc44, \ud835\udefc 1: import all model inference functions 2: for \ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc60in \ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc52\ud835\udc59\ud835\udc60do 3: \ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64_\ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc60\u2190flows labeled with \ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc60 4: \ud835\udc53_\ud835\udc56\u2190\ud835\udc46\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc39\ud835\udc5f\ud835\udc52\ud835\udc5e( \ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64_\ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc60,\ud835\udc44,\ud835\udefc) 5: \ud835\udc53_\ud835\udc56\ud835\udc57\u2190\ud835\udc43\ud835\udc4e\ud835\udc56\ud835\udc5f\ud835\udc39\ud835\udc5f\ud835\udc52\ud835\udc5e( \ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64_\ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc60, \ud835\udc53_\ud835\udc56,\ud835\udc44,\ud835\udefc) 6: \ud835\udc52_\ud835\udc56\ud835\udc57\u2190\ud835\udc36\ud835\udc5c\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc60( \ud835\udc53_\ud835\udc56, \ud835\udc53_\ud835\udc56\ud835\udc57,\ud835\udc44) 7: \u210e_\ud835\udc56\u2190\ud835\udc3f\ud835\udc5c\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc39\ud835\udc56\ud835\udc52\ud835\udc59\ud835\udc51\ud835\udc60(\ud835\udc52_\ud835\udc56\ud835\udc57, \ud835\udc53_\ud835\udc56,\ud835\udc44) 8: \ud835\udc50\ud835\udc62\ud835\udc61\ud835\udc5c\ud835\udc53\ud835\udc53\u2190\ud835\udc37\ud835\udc52\ud835\udc53\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc36\ud835\udc62\ud835\udc61\ud835\udc5c\ud835\udc53\ud835\udc53( \ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64_\ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc60,\ud835\udc52_\ud835\udc56\ud835\udc57, \u210e_\ud835\udc56,\ud835\udc44 9: \ud835\udc36\ud835\udc5c\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc60.\ud835\udc34\ud835\udc51\ud835\udc51(\ud835\udc52_\ud835\udc56\ud835\udc57) 10: \ud835\udc3f\ud835\udc5c\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc39\ud835\udc56\ud835\udc52\ud835\udc59\ud835\udc51\ud835\udc60.\ud835\udc34\ud835\udc51\ud835\udc51(\u210e_\ud835\udc56) 11: \ud835\udc36\ud835\udc62\ud835\udc61\ud835\udc5c\ud835\udc53\ud835\udc53\ud835\udc60.\ud835\udc34\ud835\udc51\ud835\udc51(\ud835\udc50\ud835\udc62\ud835\udc61\ud835\udc5c\ud835\udc53\ud835\udc53) 12: end for 13: while Scanning the Network do 14: \ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64\u2190wait_for_incoming_flow() 15: \ud835\udc52\ud835\udc5b\ud835\udc52\ud835\udc5f\ud835\udc54\ud835\udc56\ud835\udc52\ud835\udc60\u2190[] 16: for \ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc60in \ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc52\ud835\udc59\ud835\udc60do 17: e \u21900 18: for \ud835\udc56\u21901 to \ud835\udc41\u22121 do 19: \ud835\udc4e_\ud835\udc56\u2190\ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64[\ud835\udc56] 20: for \ud835\udc57\u2190\ud835\udc56+1 to \ud835\udc41do 21: \ud835\udc4e_\ud835\udc57\u2190\ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc64[ \ud835\udc57] 22: if \ud835\udc4e_\ud835\udc56\u2260\ud835\udc44and \ud835\udc4e_\ud835\udc57\u2260\ud835\udc44then 23: \ud835\udc52 \u2190 \ud835\udc52 \u2212 \ud835\udc36\ud835\udc5c\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc60[\ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc60][\ud835\udc56,\ud835\udc4e_\ud835\udc56, \ud835\udc57,\ud835\udc4e_\ud835\udc57] 24: end if 25: end for 26: if \ud835\udc4e_\ud835\udc56\u2260\ud835\udc44then 27: \ud835\udc52\u2190\ud835\udc52\u2212\ud835\udc3f\ud835\udc5c\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc39\ud835\udc56\ud835\udc52\ud835\udc59\ud835\udc51\ud835\udc60[\ud835\udc50\ud835\udc59\ud835\udc4e\ud835\udc60\ud835\udc60][\ud835\udc56,\ud835\udc4e_\ud835\udc56] 28: end if 29: end for 30: \ud835\udc52\ud835\udc5b\ud835\udc52\ud835\udc5f\ud835\udc54\ud835\udc56\ud835\udc52\ud835\udc60.\ud835\udc34\ud835\udc51\ud835\udc51(\ud835\udc52) 31: end for 32: \ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61\u2190\ud835\udc5a\ud835\udc56\ud835\udc5b(\ud835\udc52\ud835\udc5b\ud835\udc52\ud835\udc5f\ud835\udc54\ud835\udc56\ud835\udc52\ud835\udc60) 33: \ud835\udc50\ud835\udc62\ud835\udc61\ud835\udc5c\ud835\udc53\ud835\udc53\u2190\ud835\udc36\ud835\udc62\ud835\udc61\ud835\udc5c\ud835\udc53\ud835\udc53\ud835\udc60[\ud835\udc52\ud835\udc5b\ud835\udc52\ud835\udc5f\ud835\udc54\ud835\udc56\ud835\udc52\ud835\udc60.\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc65(\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61)] 34: if \ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61\u2264\ud835\udc50\ud835\udc62\ud835\udc61\ud835\udc5c\ud835\udc53\ud835\udc53then 35: \ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc52\ud835\udc59\u2190\ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc52\ud835\udc59\ud835\udc60[\ud835\udc52\ud835\udc5b\ud835\udc52\ud835\udc5f\ud835\udc54\ud835\udc56\ud835\udc52\ud835\udc60.\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc65(\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc52\ud835\udc60\ud835\udc61)] 36: else 37: \ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc52\ud835\udc59\u2190\ud835\udc62\ud835\udc5b\ud835\udc58\ud835\udc5b\ud835\udc5c\ud835\udc64\ud835\udc5b\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc5f\ud835\udc62\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b 38: end if 39: end while\nsubsection IV-B present the dataset in which the experiments were conducted.\n# A. Experiments\nWe divided the evaluation of our solution into two parts. The first is a performance comparison of EFC against classical multi-class algorithms such as DT, MLP and SVM, in both closed-set and open set experiments. The second is a reproduction of an open set experiment by Zhang et al. [6] to compare EFC with the Baseline, ODIN and OCN algorithms, all specially designed to detect unknown attacks. To compare EFC with DT, SVM and MLP, we performed a 5-fold cross-validation in CICIDS2017 using their scikit-\nlearn implementations with default hyperparameters. We also used EFC with its default hyperparameters: 30 for number of discretization bins and 0.5 for pseudocount weights. In the closed-set version of the experiment, we performed a traditional 5-fold cross validation, with the aim to evaluate EFC\u2019s ability to distinguish between classes of attacks as a simple multi-class classifier. The results of this assessments are shown in terms of F1 score, defined as the harmonic mean of Precision and Recall measures. In the open set version of the experiment, we used the same sets from the previous experiment, but we systematically removed an attack class from the training sets, while keeping this class in the test sets. For example, for the DoS class, we performed the 5-fold cross-validation having removed the DoS samples from the training sets. In this way, the DoS samples present in the test set became unknown attacks, as the classifier did not train with this attack. This procedure was executed for all classes of attacks present in the dataset, one at time. Although the other algorithms does not have mechanisms to identify unknown attacks, they serve as baselines for what would be the behavior of most techniques encountered today. More details about data pre-processing for this experiment will be presented in the next subsection. The second part of our evaluation consisted of reproducing the experiment by Zhang et al. [6]. As in our open set experiment, they removed one attack class at a time from training, keeping that attack in the test set. However, only the attacks DoS slowloris, Bot, Infiltration, Web Attack, DoS Slowhttptest and Heartbleed were considered in their experiment. The benign class and the other attacks were used as known data for all unknown attacks. They performed a simple train test split with 80% of the known data for training and 20% for testing, which was added with one unknown attack at a time. Despite their algorithm being multi-class, they binarized the labels making the known data as positive and the unknown attack as negative. They used the following threshold independent metrics to evaluate their results: the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUPRC). In the next subsection, we present the datasets used in these experiments and more details about the data preparation.\n# B. Datasets\nCICIDS2017 [10] is a dataset created by the University of New Brunswick in 2017. It contains simulated traffic in packet-based and bidirectional flow-based format. CICIDS2017 contains the most up-to-date attacks as well as benign traffic, providing an environment that resembles real networks. The dataset was made available in two formats: the original PCAP files and CSV files resulting from the extraction of 80 features from these pcaps by CICFlowMeter. These features consist of flow header information, such as Source IP, Destination IP, Source port, Destination port and Protocol; and empirical attributes such as Duration, Number\nof transmitted packets, Number of transmitted bytes, Flags, and Date first seen. In the first experiment, comparing EFC with DT, MLP and SVM, we used the dataset with its original attributes and performed the following pre-processing steps. The features Flow ID, Source IP, Destination IP and Time stamp were removed, because they only make sense in the emulated environment and are not informative regarding the traffic nature. We also combined the classes Web Attack-Brute Force, Web Attack-XSS and Web Attack-Sql Injection into one class called Web Attack, as did [6], because the behavior of flows of these classes is practically the same at the network level. After that, we encoded the labels and the symbolic features using ordinal enconding and normalized the continuous features by their maximum absolute value so that they fit in the range [\u22121,1]. For EFC only, we added a final discretization step. The partitioning of the train and test sets was done to perform a 5-fold cross validation in the whole dataset. Lastly, we undersampled the training sets to avoid data imbalance problems, restricting to 5.000 instances the classes that had more than this. In the experiment from Zhang et al. [6] work, we used their version of CICIDS2017, created by extracting 256dimensional header features from the PCAP files based on the original feature extraction method. As to the data preprocessing, we used the dataset exactly as it was released, just adding a discretization step since EFC needs discrete data. We partitioned the train and test sets exactly as described in [6], with 80% of the samples for training and 20% for testing, and undersampling the DDos, Dos Hulk and PortScan classes to remain with 50.000 flows. All the scripts used to preprocess data and execute the experiments were made available in our project repository. Table I shows the composition of CICIDS2017 in both experiments. In the following section, we will present and discuss our results.\n# V. RESULTS\nOur assessments are two-fold: (i) a performance comparison with SVM, DT and Multi-Layer Perceptron (MLP) in both closed-set and open set experiments and (ii) a performance comparison with Baseline, ODIN and OCN in open set experiment. In the following subsections, we present and discuss the results of both assessments.\n# A. Closed-set comparative analysis\nThis experiment aims to characterize the EFC as a multiclass method, comparing it with other consolidated multi-class classifiers. Table II shows the results of EFC, DT, MLP and SVM in 5-fold cross-validation on CICIDS2017 datasets. In this table, we show the F1 scores obtained in each class and the macro and weighted average of these scores. In comparison with the other classifiers, EFC had the best results in eight of the thirteen classes. In addition, it ranked second best in the classes DDoS, PortScan and SSH-Patator. In overall metrics,\n<div style=\"text-align: center;\">Table I: CICIDS2017 dataset composition in its original version and in the version used in [6]</div>\nFlow class\nNumber of instances\nOriginal CICIDS2017\nZhang et al. CICIDS2017\nBENIGN\n2,272,688\n62,639\nDDoS\n128,027\n261,226\nPortScan\n158,930\n319,636\nFTP-Patator\n7,938\n19,941\nDoS Hulk\n23,0124\n474,656\nDoS GoldenEye\n10,293\n20,543\nDoS slowloris\n5,796\n10,537\nBot\n1,966\n2,075\nInfiltration\n36\n5,330\nWeb Attack\n2,180\n10,537\nSSH-Patator\n5,897\n27,545\nDoS Slowhttptest\n5,499\n6,786\nHeartbleed\n11\n9,859\nEFC achieved 0.752\u00b10.013 of F1 macro average and 0.940\u00b1 0.001 of F1 weighted average, which represent the best and third best results, respectively. In other words, EFC is the best classifier if we consider all classes with the same importance and the third best if we consider the majority classes as most important.\n<div style=\"text-align: center;\">Table II: CICIDS2017 - Average classification performance and standard error (95% CI)</div>\nClass\nEFC\nDT\nSVM\nMLP\nBENIGN\n0.949 \u00b1 0.001\n0.994 \u00b1 0.000\n0.902 \u00b1 0.003\n0.978 \u00b1 0.003\nBot\n0.585 \u00b1 0.019\n0.544 \u00b1 0.065\n0.031 \u00b1 0.003\n0.501 \u00b1 0.046\nDDoS\n0.966 \u00b1 0.002\n0.992 \u00b1 0.002\n0.749 \u00b1 0.002\n0.964 \u00b1 0.012\nDoS GoldenEye\n0.967 \u00b1 0.002\n0.895 \u00b1 0.030\n0.437 \u00b1 0.024\n0.874 \u00b1 0.010\nDoS Hulk\n0.823 \u00b1 0.005\n0.991 \u00b1 0.001\n0.897 \u00b1 0.009\n0.952 \u00b1 0.011\nDoS Slowhttptest\n0.917 \u00b1 0.008\n0.832 \u00b1 0.029\n0.752 \u00b1 0.012\n0.799 \u00b1 0.029\nDoS slowloris\n0.963 \u00b1 0.003\n0.786 \u00b1 0.037\n0.505 \u00b1 0.053\n0.818 \u00b1 0.040\nFTP-Patator\n0.974 \u00b1 0.004\n0.932 \u00b1 0.023\n0.454 \u00b1 0.041\n0.843 \u00b1 0.033\nHeartbleed\n0.800 \u00b1 0.160\n0.055 \u00b1 0.029\n0.302 \u00b1 0.345\n0.336 \u00b1 0.191\nInfiltration\n0.347 \u00b1 0.171\n0.018 \u00b1 0.007\n0.069 \u00b1 0.019\n0.067 \u00b1 0.038\nPortScan\n0.969 \u00b1 0.002\n0.987 \u00b1 0.002\n0.863 \u00b1 0.028\n0.901 \u00b1 0.002\nSSH-Patator\n0.701 \u00b1 0.041\n0.961 \u00b1 0.039\n0.191 \u00b1 0.004\n0.664 \u00b1 0.076\nWeb Attack\n0.574 \u00b1 0.097\n0.520 \u00b1 0.048\n0.216 \u00b1 0.004\n0.307 \u00b1 0.015\nMacro average\n0.752 \u00b1 0.013\n0.731 \u00b1 0.006\n0.490 \u00b1 0.026\n0.693 \u00b1 0.017\nWeighted average\n0.940 \u00b1 0.001\n0.991 \u00b1 0.001\n0.886 \u00b1 0.003\n0.968 \u00b1 0.004\nDespite being significantly better than all other classifiers, EFC performance in Bot, Infiltration and Web Attack was far from good: 0.585, 0.347 and 0.574 of F1 in average, respectively. These results can be explained by with the information that it is the Precision that pulls down the F1 scores and not the Recall (which is actually around 0.90 for the three classes). Since these classes correspond to less than 0.002%, 0.07% and 0.08%, respectively, of the test set, their Precision is expected to be heavily impacted by small portions of misclassifications of majority classes. In other words, we interpret these results as a consequence of class imbalance in the test set and not as clear indication of EFC\u2019s ability to\ncharacterize these attacks. Furthermore, we emphasize that the EFC has a low temporal complexity, significantly smaller than that of SVM and MLP, being comparable to the complexity of a Decision Tree. Figure 4 shows the runtimes of these algorithms for different input sizes in a Ubuntu 20.04.2 LTS OS with a 9th Generation Intel Core i5 processor. The empirical results show expected behavior, with the Decision Tree and EFC growing linearly with the number of samples. However, empirical times should be interpreted with caution, as they depend heavily on the skills of the algorithm implementer. As Buczak et al. [8] noted, SVM, MLP and DT have well-maintained open-source implementations, which allows them to achieve their best possible times. Meanwhile, EFC is a method still under research whose implementation may not yet be the most efficient. Nevertheless, we consider that EFC is a fast algorithm with a high potential of applicability in real-time NIDS.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f209/f20958fa-aa95-430d-8b13-55d86951a7ba.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Training times of SVM, MLP, DT and EFC algorithms for different training set sizes</div>\n# B. Open set comparative analysis\nThe second evaluation carried out in our work investigates the ability of classifiers to detect unknown attacks. To perform such an evaluation, we designed an open set experiment where we turn a known attack into an unknown by removing it from the training set. Afterward, we assess the performance of our solution against the other algorithms considering a normal test set, which remains unchanged with samples of the original attack, evaluating the capability of both techniques to identify these samples as a threat to the network. Further details of this experiment can be found in Subsection IV-A. Next, we present its results. Figure 5 shows the result of the classification of unknown samples by each algorithms. For example, the bar labeled Bot, in Figure 5, shows the classification of Bot samples in the experiment where Bot were omitted from training (making it an unknown attack). The colors in the bars represent the\npredicted classes of these samples, which can be Benign, if it was labeled as Benign, or Other classes, if it was labeled as any other attack class. In addition, for the multi-class EFC, we also have the Suspicious class, which is the label provided by the classifier when samples do not fit into any known class, being classified as a possible threat to the network. The ideal results for SVM, DT and MLP would be full gray bars, which would mean that no unknown attack samples were classified as Benign, even if they were misclassified. Meanwhile, for the EFC, the ideal results would be full orange bars, which would mean that every attack was correctly recognized as an unknown attack. From Figure 5, we can see that EFC classified the vast majority of unknown samples as suspicious in almost all classes. The exceptions were the classes Bot, PortScan and Web Attack, which were almost totally misclassfied, but were also challenging for most classifiers as they belong to the application layer and require deep packet inspection to be properly identified. In this experiment, the Decision Tree illustrates well the problem of unknown attack detection: although it has good classification metrics as a multi-classifier and an excellent runtime speed, it does not identify well new classes of attacks and mistake them as benign samples. From a network security point of view, the best algorithm in this experiment would have been SVM, as it is the least likely to miss attack samples. However, as the goal here is not just to flag attacks, like a binary classifier, but to distinguish and correctly classify them, SVM is not a suitable algorithm. Not only does it not isolate unknown samples, it also performs poorly as a multi-classifier and has a high computational cost. For this reason, we consider EFC a promising classifier to be used in NIDS, as it combines high performance with temporal efficiency and the ability to detect unknown samples.\n# C. Open set literature comparison\nThe third and last experiment we performed was a reproduction of Zhang et al. assessment of open set classifiers. They compared their proposal OCN with Baseline and ODIN open set techniques. The design of the evaluation is similar to the experiment in section V-A, where one type of attack at a time was dropped from the training set. Table III shows the results of this comparison for each algorithm in terms of the AUROC and AUPRC metrics. The EFC recognized virtually all unknown samples of Heartbleed, Infiltration and Botnet, with both AUROC and AUPRC above 0.99. It outperformed all other algorithms in these last two classes and matched the OCN in the first. In DoS slowloris, Web Attack and DoS Slowhttp, OCN obtained the best AUROC values, showing that they can identify both known and unknown samples with greater recall than the EFC. However, in the same classes EFC obtained the best AUPRC, suggesting that it is the least likely to classify unknown samples as known. These results shows that EFC, although not always superior, is at least similar to the state of the art in detecting unknown attacks.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f61c/f61c1120-6001-4a23-ad56-ae19624f7f93.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 5: CICIDS2017 - Classification of unknown attacks by EFC, DT, MLP and SVM - Misclassification represented in blue, desirable results are bars either orange for EFC or gray for other classifiers.</div>\nIt is important to note that in this experiment we use the features extracted by the authors of [6], which are ideal for their method, but may negatively affect the performance of EFC. An evidence of this is that when using the original dataset, around 80% of DoS slowloris and DoS Slowhttp samples were correctly recognized by EFC V-B, while in this experiment they were not well recognized.\n<div style=\"text-align: center;\">Table III: Classification of unknown attacks using Zhang et al CICIDS2017 dataset</div>\nUnknown attack\nAUROC\nAUPRC\nEFC\nBaseline\nODIN\nOCN\nEFC\nBaseline\nODIN\nOCN\nDoS slowloris\n0.693\n0.172\n0.718\n0.926\n0.983\n0.541\n0.668\n0.924\nWeb Attack\n0.830\n0.467\n0.847\n0.924\n0.991\n0.960\n0.832\n0.923\nHeartbleed\n0.990\n0.96\n0.881\n1.000\n1.000\n0.762\n0.885\n1.000\nDoS Slowhttp\n0.658\n0.093\n0.473\n0.836\n0.987\n0.517\n0.498\n0.806\nInfiltration\n0.993\n0.499\n0.778\n0.967\n1.000\n0.660\n0.814\n0.976\nBotnet\n0.992\n0.447\n0.869\n0.974\n1.000\n0.638\n0.887\n0.980\nAverage\n0.859\n0.397\n0.761\n0.938\n0.993\n0.628\n0.764\n0.935\nIn this work, we proposed a new open set multi-class classifier to be used in NIDS: the multi-class EFC. Our method\nis an adaptation of the single-class EFC, first introduced in [9], that performs classification with respect to a benign class, several attack classes and a suspicious class (intended for unknown attacks). We evaluated our proposal using the CICIDS2017 dataset, an up to date dataset containing attacks that are present in modern networks. In our first experiment, we performed a cross-validation and compared EFC with well-established machine learning classifiers such as SVM, DT and MLP. From this evaluation, we conclude that the EFC is better than the others in eight of the thirteen classes of attacks, reaching the best value of F1 macro average. In addition, we highlight the low temporal complexity of our proposal and empirically show that it is a fast algorithm. In the second part of our evaluation, we investigated EFC\u2019 mechanism to identify unknown attacks by comparing it with the classical algorithms from the previous experiment and with other open set algorithms from the literature in open set experiments. These results showed that the mechanism works and that EFC has an unknown detection performance similar to the state of the art. In the future, we intend to investigate a dynamic threshold to replace the static 95th percentile used in the current implementation. Also, we are already working on an online version\n# REFERENCES\n# BIOGRAPHIES\nBIOGRAPHIES\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2419/24197eef-7541-4939-85fd-ce5a98fee30e.png\" style=\"width: 50%;\"></div>\nManuela M. C. de Souza is an undergrad Computer Science student at University of Brasilia (UnB), Brasilia, DF, Brazil. Her research interests are Network Security and Machine Learning.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e053/e053e09d-35cf-4719-baba-496f3a051ecf.png\" style=\"width: 50%;\"></div>\nCamila F. T. Pontes is a researcher at the Barcelona Supercomputing Center (BSC) in Spain. She has two undergrad degrees in Biology and Computer Science from the University of Brasilia (2014, 2020), and also a M.Sc. and a Ph.D. in Computational Biology from the same university (2016, 2021). Her research interests are Computational and Theoretical Biology and Network Security.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bd93/bd930368-0702-43d7-87f2-47285be5f344.png\" style=\"width: 50%;\"></div>\nJo\u00e3o J. C. Gondim was awarded an M.Sc. in Computing Science at Imperial College, University of London, in 1987 and a Ph.D. in Electrical Engineering at UnB (University of Brasilia, 2017). He is an adjunct professor at Department of Computing Science (CIC) at UnB where he is a tenured member of faculty. His research interests are network, information and cyber security.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5b58/5b585caf-c312-4d4c-a862-dbbb1b74c98f.png\" style=\"width: 50%;\"></div>\nLu\u00eds Paulo Faina Garcia Graduated in Computer Engineering (2010) and PhD in Computer Science (2016) from the University of S\u00e3o Paulo. In 2017, his thesis was ranked among the best by the Brazilian Computer Society and received the CAPES award for the best thesis in Computer Science in the country. He is currently Adjunct Professor A in the Department of Computer Science at the University of Bras\u00edlia. He has experience in subjects related to noise detection, meta-learning and data streams.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e7f1/e7f16531-e821-4ab7-9956-0f5b41d28924.png\" style=\"width: 50%;\"></div>\nLuiz A. DaSilva [F] (ldasilva@vt.edu) is the Executive Director of the Commonwealth Cyber Initiative and the Bradley Professor of Cybersecurity at Virginia Tech. He was previously at Trinity College Dublin, where he was the director of CONNECT, the Science Foundation Ireland Research Centre for Future Networks. He is an IEEE Fellow, and an IEEE Communications Society Distinguished Lecturer.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a810/a8107e64-35f7-45d9-a1a8-ea83d7ace50e.png\" style=\"width: 50%;\"></div>\nMarcelo Antonio Marotta is an adjunct professor at the University of Brasilia, Brasilia, DF, Brazil. He received his Ph.D. degree in Computer Science in 2019 from the Institute of Informatics (INF) of the Federal University of Rio Grande do Sul (UFRGS), Brazil. His research involves Heterogeneous Cloud Radio Access Networks, Internet of Things, Software Defined Radio, Cognitive Radio Networks, and Network Security.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of network intrusion detection systems (NIDS) that struggle to identify new and variant attacks due to their reliance on closed-set training and testing. Existing methods often face high temporal complexities and performance bottlenecks, necessitating a new approach to effectively recognize unknown attacks.",
        "problem": {
            "definition": "The problem is the inability of current NIDS to accurately detect and classify unknown attacks due to their training on closed sets of known attack classes, which does not reflect the dynamic nature of real-world network traffic.",
            "key obstacle": "The main challenge is the high temporal complexity and performance limitations of existing methods, which often rely on deep learning or cascading classifiers that are not suitable for real-time analysis."
        },
        "idea": {
            "intuition": "The intuition behind the proposed method stems from the need for a classifier that can efficiently recognize both known and unknown attacks without the high computational costs typically associated with existing models.",
            "opinion": "The proposed idea is an adaptation of the single-class Energy-based Flow Classifier (EFC) to perform multi-class classification and open set recognition, allowing it to identify unknown attacks effectively.",
            "innovation": "The innovation lies in the EFC's ability to maintain low temporal complexity while accurately classifying both known and unknown attacks, differing from existing methods that often compromise on speed."
        },
        "method": {
            "method name": "Multi-class Energy-based Flow Classifier",
            "method abbreviation": "EFC",
            "method definition": "EFC is a statistical method that uses variational inference to classify network flows based on their energy, determining their likelihood of belonging to known attack classes or being classified as suspicious.",
            "method description": "EFC classifies network flows by calculating their energy relative to multiple inferred distributions for different attack classes, allowing for effective detection of known and unknown attacks.",
            "method steps": [
                "Group training samples by class and infer models for each class.",
                "Calculate local fields and coupling values for each flow class.",
                "Define thresholds for classification based on the 95th percentile of training sample energies.",
                "For each incoming flow, compute its energy in relation to all class models and classify it based on the lowest energy value."
            ],
            "principle": "The effectiveness of EFC is based on the statistical properties of energy calculations, which reflect how likely a flow is to belong to a specific class, enabling the identification of flows that are significantly different from known classes."
        },
        "experiments": {
            "evaluation setting": "The evaluation was conducted using the CICIDS2017 dataset, comparing EFC against classical classifiers like Decision Trees, Multi-Layer Perceptron, and SVM in both closed-set and open set experiments.",
            "evaluation method": "The performance was assessed using 5-fold cross-validation, measuring F1 scores for closed-set experiments and AUROC and AUPRC metrics for open set experiments."
        },
        "conclusion": "The experiments demonstrated that EFC outperforms classical classifiers in several attack classes and effectively identifies unknown attacks, making it a promising candidate for implementation in real-time NIDS.",
        "discussion": {
            "advantage": "EFC provides significant advantages in terms of speed and accuracy, particularly in identifying unknown attacks, while maintaining low temporal complexity compared to other classifiers.",
            "limitation": "The method's performance may be impacted by class imbalance in the dataset, particularly for less frequent attack classes, which can lead to lower precision scores.",
            "future work": "Future research will focus on developing a dynamic threshold mechanism to enhance the classifier's adaptability and performance in varying network conditions."
        },
        "other info": {
            "info1": "The dataset used for evaluation contains simulated traffic with both benign and malicious flows.",
            "info2": {
                "info2.1": "EFC's training complexity is linear with respect to the number of samples and features.",
                "info2.2": "The proposed method is designed to be applicable in real-time network environments."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The inability of current network intrusion detection systems (NIDS) to accurately detect and classify unknown attacks is critical for developing reliable and secure AI systems."
        },
        {
            "section number": "2.1",
            "key information": "Out-of-distribution detection is defined as the ability to recognize unknown attacks that are not represented in the training data, which reflects the dynamic nature of real-world network traffic."
        },
        {
            "section number": "3.1",
            "key information": "The Multi-class Energy-based Flow Classifier (EFC) is proposed as a method for open set recognition, allowing it to identify unknown attacks effectively."
        },
        {
            "section number": "3.4",
            "key information": "EFC classifies network flows by calculating their energy relative to multiple inferred distributions for different attack classes, enabling effective detection of both known and unknown attacks."
        },
        {
            "section number": "5.1",
            "key information": "The overlap between anomaly detection and OOD detection is evident in the ability of EFC to identify flows that are significantly different from known classes, which is crucial for recognizing unusual patterns."
        },
        {
            "section number": "7.1",
            "key information": "Current limitations in NIDS include high temporal complexity and performance bottlenecks, which challenge the effectiveness of existing methods in real-time analysis."
        },
        {
            "section number": "7.2",
            "key information": "Future directions include developing a dynamic threshold mechanism to enhance the classifier's adaptability and performance in varying network conditions."
        }
    ],
    "similarity_score": 0.611151124251423,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/A Novel Open Set Energy-based Flow Classifier for Network Intrusion Detection.json"
}