{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2411.02830",
    "title": "Mixtures of In-Context Learners",
    "abstract": "In-context learning (ICL) adapts LLMs by providing demonstrations without fine-tuning the model parameters; however, it does not differentiate between demonstrations and quadratically increases the complexity of Transformer LLMs, exhausting the memory. As a solution, we propose Mixtures of In-Context Learners (MoICL), a novel approach to treat subsets of demonstrations as experts and learn a weighting function to merge their output distributions based on a training set. In our experiments, we show performance improvements on 5 out of 7 classification datasets compared to a set of strong baselines (up to +13\\% compared to ICL and LENS). Moreover, we enhance the Pareto frontier of ICL by reducing the inference time needed to achieve the same performance with fewer demonstrations. Finally, MoICL is more robust to out-of-domain (up to +11\\%), imbalanced (up to +49\\%), or noisy demonstrations (up to +38\\%) or can filter these out from datasets. Overall, MoICL is a more expressive approach to learning from demonstrations without exhausting the context window or memory.",
    "bib_name": "hong2024mixturesincontextlearners",
    "md_text": "Giwon Hong 1 Emile van Krieken 1 Edoardo M. Ponti 1 Nikolay Malkin 1 Pasquale Minervini 1, 2\n1 University of Edinburgh, United Kingdom 2 Miniml.AI, United Kingdom {giwon.hong, p.minervini}@ed.ac.uk\n\n# Abstract\n\nIn-context learning (ICL) adapts LLMs by providing demonstrations without fine-tuning the model parameters; however, it does not differentiate between demonstrations and quadratically increases the complexity of Transformer LLMs, exhausting the memory. As a solution, we propose Mixtures of In-Context Learners (M O ICL), a novel approach to treat subsets of demonstrations as experts and learn a weighting function to merge their output distributions based on a training set. In our experiments, we show performance improvements on 5 out of 7 classification datasets compared to a set of strong baselines (up to +13% compared to ICL and LENS). Moreover, we enhance the Pareto frontier of ICL by reducing the inference time needed to achieve the same performance with fewer demonstrations. Finally, M O ICL is more robust to out-of-domain (up to +11%), imbalanced (up to +49%), or noisy demonstrations (up to +38%) or can filter these out from datasets. Overall, M O ICL is a more expressive approach to learning from demonstrations without exhausting the context window or memory.\n\n# Introduction\n\nIn-context learning (ICL), where we condition a large language model (LLM) on a set of input\u2013 output examples (demonstrations) to perform a wide range of tasks (Brown et al., 2020; Wei et al., 2022), is a transformative technique in NLP. However, in ICL, the context length of the model severely limits the maximum number of in-context demonstrations (Wei et al., 2022), and its effectiveness can vary significantly depending on what demonstrations are selected (Lu et al., 2022; Chen et al., 2023). Current methods for selecting demonstrations are largely heuristic and do not adequately quantify the influence of individual examples on the generalisation properties of the model (Lu et al., 2024). In general settings, demonstrations are often selected randomly over different seeds or based on\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2419/24196ca6-d2d6-4b62-b375-229328419c65.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: A Mixture of In-Context Learners (M O ICL) first partitions a set of demonstrations D in k partitions to create k experts trained via in-context learning, and then combines their next-token predictions via a trainable weighting function.\n</div>\nsimple criteria (Xu et al., 2024), which can lead to suboptimal performance. But is each demonstration high quality and useful, or merely noise? And can we automate this distinction? We propose Mixtures of In-Context Learners (M O ICL), a method for dynamically learning how different sets of examples contribute to the prediction task. M O ICL prompts an LLM with multiple subsets of examples, and combines their next-token distributions via a weighting function that can be trained via gradient-based optimisation methods; Fig. 1 shows a high-level outline of the method. We analyse the generalisation properties of M O ICL in the following settings: (1) presence of out-of-distribution (OOD) demonstrations, where some in-context demonstrations are sourced from a different dataset; and (2) label imbalance, where the training label distribution is significantly skewed towards a subset of labels. (3) noised demonstrations, where the labels of some demonstrations are perturbed to be completely incorrect. In all three cases, we find that M O ICL produces significantly more accurate results than ICL. Furthermore, M O ICL does not require access to the internal parameters of the LLM, making it applicable to black-box LLMs, and it significantly reduces the complexity issues arising from the quadratic time and memory complexity in sequence length of self-attention since it allows the distribution of the training samples among multiple\n\nexperts. We also show that the method can be made more efficient by sparsifying the mixing weights. We summarise our contributions as follows:\n\u2022 We introduce the Mixture of In-Context Learners (M O ICL), which assigns weights to each demonstration subset and learns from them, dynamically identifying the optimal experts and  antiexperts via gradient-based optimisation.\n\u2022 We demonstrate that M O ICL is competitive with standard ICL while being significantly more data, memory, and computationally efficient.\n\u2022 We show that M O ICL is resilient to noisy demonstrations and label imbalance.\n\n# 2 Mixtures of In-Context Learners\n2.1 In-context Learning\n\n# 2 Mixtures of In-Context Learners\n\n# 2.1 In-context Learning\n\nGiven a large language model (LLM) with nexttoken distribution p (\u00b7), a set of n demonstrations D = {(x 1, y 1)... (x n, y n)} and an input text x, the model generates a response y when prompted with the concatenation of the examples in D and the input text x:\n\ny \u223c p (y | x 1, y 1, . . . , x n, y n, x)\n= p (y | D, x),\n\n(1)\n\nwe refer to the model in Eq. (1) as concat-based ICL (Min et al., 2022a). With concat-based ICL, given a demonstration set D, the model can generate a response y for the input text x  without needing task-specific fine-tuning or access to the model parameters. However, concat-based ICL is still problematic: recent works show that it is very sensitive to the choice of the prompts and in-context demonstrations (Voronov et al., 2024); the number of demonstrations is bounded by the maximum context size (Brown et al., 2020); and, in Transformerbased LLMs, the cost of self-attention operations grows quadratically with the number of in-context samples (Liu et al., 2022).\n\n# 2.2 Mixtures of In-Context Learners\n\nWe propose Mixtures of In-Context Learners (M O ICL), a method for addressing the limitations of concat-based ICL (Section 2.1). We first partition (Appendix B.1) the set of demonstrations D into k disjoint subsets D 1, . . . , D k:\n\nD = D 1 \u2294 D 2 \u2294. . . \u2294 D k.\n\n(2)\n\nThen, each demonstration subset D i \u2286 D is passed to the LLM along with the input text x, and we\n\ndenote these as experts. The next-token distributions of the experts are combined using a vector of mixing weights w \u2208 R k:\n\ntions of the experts are combined using a vector of mixing weights w \u2208 R k:\n(3)\np (y | D, x) \u221d exp\n\ufffd\ni =1 w i log p (y | D i, x)\n\ufffd k \ufffd\nwhere each w i \u2208 R represents the contribution of the expert denoted by p (y | D i, x) to the final next-token distribution p (y | D, x), and each expert p (y | D i, x) is trained via concat-based ICL, as in Eq. (1). 1\nWeighting Functions. We consider the following weighting functions for calculating the weight w i \u2208 R of the i-th expert in M O ICL: Scalar weights.  Use a vector of trainable parameters w \u2208 R k, where w i  denotes the weight associated to the i-th expert. The weights w are initialised as \u2200 i: w i = 1 /k. Hyper-network. Use a hyper-network (Ha et al., 2017) h \u03d5 (\u00b7) with parameters \u03d5 to generate the weights of each expert w i, given all in-context demonstration subsets concatenated: w 1, . . . , w k = h \u03d5 (D 1, . . . , D k). We learn the parameters of the weighting function w by maximising the conditional log-likelihood of a training set D T. One advantage of using a hyper-network h \u03d5 for dynamically computing the weights w over having w as a set of parameters is that the model can provide weights for sets of demonstrations not seen during training.\nSparsifying the Mixture Weights One limitation of M O ICL is that, for each token, it requires invoking the base LLM k  times, one for each expert with a different set of in-context examples. To solve this issue, we propose to sparsify  the weighting coefficients w \u2208 R k so that only k \u2032 < k of them have non-zero values. To achieve this, we define the output of the weighting function as:\n\n(3)\n\n(4)\n\nwhere w \u2032 \u2208 R k are scalar weights for the k  experts, m \u2208 R k is a set of masking coefficients, topk \u2032: R k \ufffd\u2192{0, 1} k is a function that produces a mask that selects the highest k \u2032 elements of a k-dimensional input vector, and \u2299 is the elementwise product. To back-propagate through the rationale extraction process, we use Implicit Maximum Likelihood Estimation (IMLE; Niepert et al.,\n\n1 The formulation in Eq. (3) uses a product of experts; it is also possible to use a regular mixture of experts \u2014 we experimentally compare them in Fig. 2 and Appendix B.2.\n\n2021; Minervini et al., 2023), a gradient estimation method for back-propagating through continuousdiscrete functions like  topk \u2032 into neural architectures. More specifically, let \ufffd m =  topk \u2032 (m) \u2208 {0, 1} k denote the  topk \u2032 mask. In our experiments using IMLE, we estimate the gradient of the loss w.r.t. the masking coefficients \u2207 m L as \u2207 m L \u2248 topk \u2032 (m) \u2212 topk \u2032 (m + \u03bb \u2207 \ufffd m L), where \u03bb \u2208 R + is a hyperparameter selected by the user.\n\n# 3 Experimental Setup\n\nModels For our experiments, we primarily used Llama-3-8B and its instruction-tuned models, Llama-3-8B-Instruct (AI@Meta, 2024) as our base LLMs. We use Llama-3-8B-Instruct for classification tasks, and Llama-3-8B was used for an openended generation task; we use greedy decoding for generating from M O ICL. Furthermore, we use Llama-2-7b-chat, 13b-chat, and 70b-chat (Touvron et al., 2023) for analysing the influence of model scale in Section 4.9. For the hyper-network, in our experiments, we used the T5 models (efficienttiny, efficient-mini, t5-small, t5-base) (Raffel et al., 2020).\n\nDatasets To study how well M O ICL performs on classification tasks, we use the TweetEval (Barbieri et al., 2020) offensive/hate, SST2 (Socher et al., 2013), RTE (Bentivogli et al., 2009), FEVER (Thorne et al., 2018), PAWS (Zhang et al., 2019), and QNLI (Wang et al., 2018) datasets. For SST2, RTE, FEVER, and QNLI, we report the performance on the development set. For a generation task, we use Natural Questions (NQ; Kwiatkowski et al., 2019) with an open-book setting (Lee et al., 2019).\n\nBaselines We compare M O ICL with the following baselines. Concat-based ICL refers to the standard ICL introduced in Section 2.1 where all demonstrations are concatenated into a single sequence and passed as input to the LLM along with the input text. Random Search samples random subsets from the demonstration pool, concatenates them, and utilizes them in the same manner as Concat-based ICL. Specifically, we sample k  random subsets and select the one that performs best on the training set. Here, k is the maximum number of subsets used in M O ICL, and the size of each subset is a random number between 1 and the number of demonstrations n. After finding the best subset, we evaluate it on the test set. Ensemble-based\n\nICL (Min et al., 2022a) and LENS (Li and Qiu, 2023) were adjusted in terms of tasks and models to fit our experimental setup. We also report the results of fine-tuning the target model using a parameter-efficient fine-tuning method, namely LoRA (Hu et al., 2022); this is a strong baseline that requires access to the model weights. Finally, we study M O ICL Uniform, an ablation that simply weights all experts equally, i.e. \u2200 i: w i = 1 /k.\nEvaluation Metrics For classification tasks, we use accuracy as the evaluation metric. For generation tasks, we use EM (Exact Match) for NQ-open. More detailed settings, including dataset statistics, hyperparameters, and implementation details, are provided in Appendix A. Furthermore, in Appendix B.1, we show that our method is not significantly affected by the choice of partitioning methods. Therefore, we applied static partitioning in all experiments.\n\n# 4 Results\n\nIn our experiments, we aim to answer the following research questions: (1) Does M O ICL demonstrate general performance improvements over concatbased ICL and other baselines? (Section 4.1 and Section 4.2) (2) Is MoICL resilient to problem settings involving label imbalance and noise? (Section 4.4, Section 4.5 and Section 4.6) (3) Can we select demonstrations (experts) based on the tuned weights? (Section 4.7) (4) Can M O ICL handle demonstrations that were not seen during finetuning? (Section 4.8) (5) Is M O ICL more efficient in terms of data, time, and memory compared to traditional concat-based ICL? (Section 5)\n\n# 4.1 M O ICL in Classification Tasks\n\nTo determine the effectiveness of M O ICL across various datasets, we compare it with baseline methods in Table 1. In this experiment, we set the total number of demonstrations (n) as 30, and the number of subsets (k) as 5, 10, and 30. M O ICL outperformed the Baseline ICL on the Offensive, Hate, FEVER, PAWS, and QNLI datasets. The exceptions are SST2 and RTE, where M O ICL performs similarly to concat-based ICL in SST2 and shows lower performance in RTE. Surprisingly, M O ICL scalar achieved the highest performance with k =10 (e.g. in Hate M O ICL achieves 66.52, which is about 10 points increase compared to the concat-based ICl) or k =30 (e.g. in Offensive M O ICL achieves 81.33), rather than k =5, in all\n\nMethod \u2193Dataset \u2192\nOffensive\nHate\nSST2\nRTE\nFEVER\nPAWS\nQNLI\nConcat-based ICL\n76.44\u00b12.48\n53.54\u00b14.29\n95.46\u00b10.14\n86.43\u00b11.26\n80.63\u00b10.49\n78.12\u00b10.77\n89.08\u00b10.44\nRandom Search\n77.88\u00b11.14\n58.09\u00b11.93\n95.76\u00b10.18\n86.57\u00b11.43\n82.13\u00b10.10\n78.88\u00b10.57\n89.99\u00b10.26\nEnsemble-based ICL (Min et al., 2022a)\n73.35\u00b10.44\n53.68\u00b14.27\n95.48\u00b10.12\n86.43\u00b11.34\n80.63\u00b10.46\n65.27\u00b10.48\n88.57\u00b10.21\nLENS (Li and Qiu, 2023)\n78.70\u00b10.67\n53.20\u00b13.11\n93.81\u00b10.16\n84.98\u00b10.74\n80.07\u00b10.29\n75.60\u00b10.72\n89.04\u00b10.40\nPEFT (LoRA, Hu et al., 2022)\n79.79\u00b14.07\n53.76\u00b14.98\n85.89\u00b16.32\n88.88\u00b12.78\n59.78\u00b10.62\n54.82\u00b13.08\n57.24\u00b14.77\nMixture of ICL (uniform)\nk = 5\n73.77\u00b11.60\n59.29\u00b11.23\n95.39\u00b10.30\n83.10\u00b11.28\n80.12\u00b10.64\n75.37\u00b10.53\n89.65\u00b10.22\nk = 10\n74.00\u00b10.87\n61.70\u00b11.61\n94.91\u00b10.19\n79.93\u00b10.81\n77.47\u00b10.89\n73.49\u00b10.46\n89.65\u00b10.14\nk = 30\n73.37\u00b10.34\n59.12\u00b10.47\n94.17\u00b10.21\n77.26\u00b11.02\n79.46\u00b10.36\n65.29\u00b10.51\n88.66\u00b10.25\nMixture of ICL (scalar)\nk = 5\n78.35\u00b11.49\n66.03\u00b13.31\n95.46\u00b10.35\n84.12\u00b11.07\n81.43\u00b10.90\n77.56\u00b10.53\n89.99\u00b10.44\nk = 10\n79.42\u00b11.48\n66.52\u00b12.62\n95.32\u00b10.27\n83.32\u00b11.60\n82.04\u00b10.98\n79.42\u00b10.79\n90.44\u00b10.27\nk = 30\n81.33\u00b10.69\n63.45\u00b11.69\n94.79\u00b10.34\n79.93\u00b10.93\n82.66\u00b10.38\n79.50\u00b10.33\n90.11\u00b10.20\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d428/d428bc4a-72d7-4a01-911f-1b6d5086c457.png\" style=\"width: 50%;\"></div>\nFigure 2: Accuracy according to the number of demonstrations per subset on TweetEval offensive dataset. The shaded area represents the standard deviation. We also compare mixing logits to mixing probabilities; see Appendix B.2.\n\n<div style=\"text-align: center;\">Figure 2: Accuracy according to the number of demonstrations per subset on TweetEval offensive dataset. The shaded area represents the standard deviation. We also compare mixing logits to mixing probabilities; see Appendix B.2.\n</div>\ntasks except for SST2 and RTE. Considering that a larger k reduces the context length (which will be further discussed in Section 5), M O ICL manages to capture both efficiency and effectiveness.\n\n# 4.2 Impact of Partitioning Size\n\nIn Fig. 2, we present the performance changes on the test set of TweetEval offensive when varying the number of subsets, k. Since the total number of demonstrations is fixed at 30, each subset contains 30 /k demonstrations, which corresponds to the x-axis of the Figure. Note that when the number of demonstrations per subset is 30 (k = 1), it corresponds to the standard Concat-based ICL. We observe that Uniform Weights and scalar  exhibit distinctly different patterns. With Uniform Weights, as the number of demonstrations per subset decreases, performance tends to decline, which is an expected outcome for ICL. However, with\n\nMOICL Method (n, k=30)\nOffensive\nuniform\n76.44\u00b12.48\nscalar\n81.33\u00b10.69\n- Positive Weights Only\n76.05\u00b10.55\nTable 2: How important is it to be able to detect anti-experts? Results on the TweetEval Offensive Test set using Llama-38B-Instruct. \u201cPositive Weights Only\u201d limits the weights of subsets to positive values, preventing subsets from acting as anti-experts. The number of subsets k and the total number of demonstrations n is 30.\n\nscalar, performance surprisingly increases. This seems to be because the decrease in the number of demonstrations per subset is outweighed by the increased flexibility afforded by having more subsets, each assigned tuned weights by scalar.\n\n# 4.3 Impact of Non-Negative Weights\n\nInspired by Liu et al. (2024), we made an assumption that each expert could also serve as an antiexpert, by allowing the expert weights to be negative. If the weight becomes negative during the training process, this indicates that the expert is not only unhelpful, but is actively being used as an anti-expert in generating the response. To verify this, in Table 2, we compare the performance when we restrict the weights to be positive. We observe that restricting the weights to be positive, thereby eliminating the possibility for anti-experts, significantly degrades performance. This is because certain demonstrations or their subsets can be useful when utilised as anti-experts. This also greatly aids in interpreting the usefulness of experts, as seen in the experiments from Section 4.4 and Section 4.6.\n\nMethod (n, k = 30)\np=0.0\np=0.5\np=0.7\nConcat-based ICL\n76.44\u00b12.48\n70.67\u00b15.06\n68.49\u00b14.34\nMixture of ICL\n- uniform\n73.37\u00b10.34\n72.07\u00b10.38\n70.79\u00b10.56\n- scalar\n81.33\u00b10.69\n80.95\u00b10.65\n80.19\u00b10.37\nTable 3: Analysis of out-of-domain (OOD) demonstrations on TweetEval offensive test set using Llama-3-8B-Instruct. Here, p represents the proportion of OOD demonstrations sampled from the SST2 dataset. The number of subsets k and the total number of demonstrations n was set to 30. Bold text signifies the highest accuracy for each p.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/44c3/44c372ef-4f55-44eb-b9ad-d4f496f26b52.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f6b2/f6b2c554-8777-4c96-9511-167e91b6bdb5.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3313/3313a56e-686f-451d-8d71-75a4da68d461.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) 50% OOD\n</div>\n<div style=\"text-align: center;\">(b) 70% OOD\n</div>\nFigure 3: Visualisation of the tuned weights when (a) 50% and (b) 70% of demonstrations are OOD. The y-axis indicates the weights, whereas the x-axis represents the index of demonstrations sorted in ascending order (across five different seeds). Blue bars correspond to in-domain (ID) demonstrations, and red bars correspond to out-of-domain (OOD) demonstrations.\n\n# 4.4 Handling Out-of-domain Demonstrations\n\nBy learning to associate a weight to each expert, M O ICL can be used to identify whether demonstrations are relevant to the task. To analyse this, in Table 3, we present the accuracy of M O ICL on the TweetEval offensive test set, using a mix of demonstrations sampled from the SST dataset and those from the TweetEval offensive dataset. We observe that as p (the proportion of OOD demonstrations) increases, the performance of standard ICL methods decreases. However, M O ICL (with scalar) effectively mitigates this by reducing the influence of these OOD demonstrations, resulting in the smallest performance drop. This becomes even more apparent when analysing the weights of actual OOD demonstrations. When p = 0. 5 (i.e. the number of OOD and in-domain demonstrations is equal), the average weight of in-domain demonstrations is 0.0108 \u00b1 0.0025, while the average weight for OOD demonstrations is-0.0059 \u00b1 0.0027. For p = 0. 7, the average weight of in-domain demonstrations is 0.0127 \u00b1 0.0052, while the average weight for OOD demonstrations is-0.0019 \u00b1 0.0016. In Fig. 3, we visualise how the weights of in-domain demonstrations (blue bars) and OOD demonstrations (red bars) are distributed. We observed a general trend where in-domain demonstrations typically receive posi\n\nMethod (n, k = 30)\nOriginal\nImbalanced\nConcat-based ICL\n76.44\u00b12.48\n28.49\u00b10.86\nMixture of ICL\n- uniform\n73.37\u00b10.34\n40.19\u00b12.32\n- scalar\n81.33\u00b10.69\n77.77\u00b11.20\nTable 4: Analysis of imbalanced demonstrations on the TweetEval Offensive Test set using Llama-3-8B-Instruct. \u201cImbalanced\u201d refers to a condition where only one out of 30 demonstrations has a \u201cneutral\u201d label, while the rest are \u201coffensive\u201d.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/107e/107e8f43-826f-4306-b38b-c8b035fa9a44.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Resilience of ICL to adding noisy demonstration. We report the EM based on the number of noised demonstrations out of the total 12 demonstrations in NQ. For the case of scalar, we also present the average weights of standard and noisy demonstrations as (standard, noisy).\n</div>\nFigure 4: Resilience of ICL to adding noisy demonstration. We report the EM based on the number of noised demonstrations out of the total 12 demonstrations in NQ. For the case of scalar, we also present the average weights of standard and noisy demonstrations as (standard, noisy).\n\ntive weights, while OOD demonstrations tend to receive negative weights. This provides evidence that our proposed method successfully mitigates the OOD demonstrations.\n\n# 4.5 Mitigating Label Imbalance\n\nTo determine whether our proposed method can handle label imbalance, on the TweetEval Offensive dataset, we set up 29 \u201coffensive\u201d label demonstrations and one \u2018non-offensive\u2019 label demonstration out of 30 demonstrations. Since the TweetEval Offensive dataset has a \u201cnon-offensive\u201d to \u201coffensive\u201d label ratio of about 7:3, such imbalanced demonstrations would be detrimental to performance. As seen in Table 4, such imbalanced demonstrations caused a significant performance drop in standard ICL methods. However, our proposed method (scalar) showed the least performance drop, successfully mitigating the effects of label imbalance.\n\n# 4.6 Filtering Noisy Demonstrations\n\nOne of the benefits of assigning weights to each demonstration or its subsets is the ability to handle low-quality, or more specifically, noisy demonstrations. To verify this, in NQ-Open, we created noisy\n\nMethod \u2193Subset \u2192\nk\u2032 = 5\nk\u2032 = 10\nk\u2032 = 20\nk\u2032 = 30\nk\u2032 = 90\nConcat-based ICL (n = k\u2032)\n72.19\u00b12.63\n74.12\u00b12.24\n74.84\u00b11.88\n76.44\u00b12.48\n75.67\u00b12.33\nMOICL (n, k = k\u2032)\nuniform\n73.05\u00b10.52\n73.42\u00b10.76\n73.42\u00b10.49\n73.37\u00b10.34\n73.26\u00b10.16\nscalar\n76.26\u00b11.11\n78.16\u00b10.91\n80.16\u00b11.23\n81.33\u00b10.69\n83.35\u00b10.41\nw/ scalar (n, k = 90)\nHighest k\u2032 Weights\n75.58\u00b10.81\n75.56\u00b10.46\n74.42\u00b10.61\n74.33\u00b10.38\n-\nHighest k\u2032 Weights (abs)\n69.79\u00b114.84\n60.53\u00b121.84\n71.58\u00b114.67\n72.93\u00b113.14\n-\nIMLE Top-k\u2032 mask\n76.07\u00b10.64\n75.93\u00b10.69\n76.35\u00b10.35\n76.44\u00b10.64\n-\nble 5: Analysis of selecting useful demonstrations with the proposed M O ICL on the TweetEval Offensive test set on Lla-Instruct. \u2018Highest k \u2032 Weights\u2019 refers to selecting the k \u2032 subsets with the largest weights out of 90 weights of M O ICL s hile \u2018Highest k \u2032 Weights (abs)\u2019 uses absolute weights instead.\n\ndemonstrations (see Appendix B.3 for the result of NQ-open without noised demonstrations) by randomly changing the answers to one of (yes, no, foo, bar), where the total number of demonstration is 12, and each subset has one demonstration (n, k = 12). The results in Fig. 4  show that our proposed method effectively handles noisy demonstrations. While the performance of the concat-based ICL significantly decreases as the number of noisy demonstrations increases, the M O ICL methods can maintain performance. Additionally, without tuning the weights (Uniform Weights), performance gradually declines as the number of noisy demonstrations increases, but with tuning (scalar), the performance remains stable (more than +35% with 10 noised demonstrations). This is clearly evident when analysing the learned weights. In the figure, the average weights of normal and noisy demonstrations are displayed in the form (normal weights, noise weights) for scalar, showing a noticeable difference.\n\n# 4.7 Selecting Demonstration Subsets\n\nWe now analyse the impact of sparsifying the mixture weights w \u2208 R k in M O ICL. Results are available in Table 5\u2014 \u201cHighest n  Weights\u201d refers to selecting the subsets with the n largest w weights (or | w |  in the case of \u201cabs\u201d), while IMLE Topk \u2032 mask refers to the method introduced in Section 2.2, using \u03bb = 1 following the default hyper-parameters proposed by Niepert et al. (2021). While M O ICL scalar achieved the highest accuracy, the need to learn them for each m and k  makes selection methods that tune weights for a large n and then select m of them more practical. Notably, \u201cHighest n Weights (abs)\u201d is high-variance, indicating the difficulty in effectively leveraging anti-experts (Section 4.3). In contrast, IMLE, which uses a mask, demonstrated stable performance, achieving the\n\nMethod \u2193Dataset \u2192\nOffensive\nHate\nConcat-based ICL (n = 30)\n76.44\u00b12.48\n53.54\u00b14.29\nMixture of ICL (n, k=30)\n- uniform\n73.37\u00b10.34\n59.12\u00b10.47\n- Hyper-network\n76.65\u00b11.31\n65.07\u00b15.22\nTable 6: Comparison of M O ICL methods, including scalar and Hyper-network, on the TweetEval Offensive and Hate, using Llama-3-8b-Instruct.\n\nbest results, particularly with a few demonstrations (when k \u2032 = 5).\n\n4.8 Generalization to Unseen Demonstrations\n\nWhile Mixture of ICL with scalar is simpler and less costly, it has the disadvantage of requiring a fixed set of demonstration subsets. This is an inherent limitation of the method itself, which assigns weights to each subset and learns from them. A solution to overcome this limitation is to utilise a smaller, fine-tuned hyper-network (Hyper-network) that calculates the weights for arbitrary demonstration subsets. Table 6 compares the performance of M O ICL methods, where the demonstration set D was not available during the training process. In this situation, scalar, which assumes that the experts and their corresponding demonstrations are fixed, cannot be tuned. However, the  Hypernetwork fine-tuned on the available demonstrations, can generalize well when presented with unseen demonstration D.\n\n# 4.9 Impact of Model Size\n\nConsidering the ongoing trend of scaling up LLMs, it is essential to analyse how the proposed method is affected by model size. In Table 7, we compare the accuracy of our proposed method on the TweetEval Offensive task when using Llama-2-chat models in various sizes (7B, 13B, 70B) as the target LLM. Although the performance of the Llama-2\n\nMethod \u2193Model \u2192\nll2-chat-7b\nll2-chat-13b\nll2-chat-70b\nConcat-based ICL\n73.09\u00b13.21\n63.09\u00b13.85\n69.42\u00b11.78\nMOICL\n- uniform\n79.35\u00b10.22\n63.60\u00b11.84\n67.88\u00b11.03\n- scalar\n79.16\u00b10.60\n80.49\u00b11.01\n82.26\u00b10.65\nTable 7: Comparison on the TweetEval Offensive Test set across different sizes of the Llama-2 models.\n\nHyper-network Model\nOffensive\nHate\nt5-efficient-tiny (16M)\n69.32\u00b12.07 | 74.60\u00b12.03\n67.32\u00b10.66 | 60.48\u00b14.56\nt5-efficient-mini (31M)\n68.50\u00b12.01 | 73.74\u00b11.43\n66.00\u00b11.51 | 56.61\u00b10.90\nt5-small (60M)\n71.01\u00b11.09 | 76.65\u00b11.31\n70.20\u00b11.53 | 65.07\u00b15.22\nt5-base (220M)\n69.14\u00b11.01 | 74.40\u00b12.39\n68.24\u00b10.75 | 63.23\u00b14.51\nTable 8: Comparison on the TweetEval Offensive/hate Dev|Test set using Llama-3-8b-Instruct as a target LLM across different sizes of the hyper-network. The numbers in parentheses indicate the number of parameters.\n\n7B-chat model is somewhat unusual compared to the other two models, we observed that M O ICL consistently outperforms concat-based ICL across all three model sizes. We also analysed the impact of hyper-network model size. Table 8  compares the dev/test set accuracy on the TweetEval hate/offensive task based on the size of the T5 model used as the hyper-network. From analysing the dev set results, we found that even with a very small model size (16M\u201360M), the hyper-network performed relatively well, leading us to decide on using T5-small as our hypernetwork.\n\n# 5 Data and Compute Efficiency\n\nOne potential limitation of M O ICL is that it requires training instances for weight tuning, which can be problematic when such training data is unavailable. To analyse the data efficiency of M O ICL, we present the accuracy on TweetEval Offensive and Hate test set in Fig. 5 under scenarios where the number of training instances (Number of Annotated Demonstrations) is limited. In this experiment, we set n = k, so each expert is assigned one demonstration and weight tuning is performed using the number of training instances minus k (e.g., when the x-axis is at 40, M O ICL with k = 10 is tuned with 30 training instances). We observed that M O ICL is highly data-efficient, achieving better performance than concat-based ICL with only around 20 annotated demonstrations. In contrast, concat-based ICL showed lower performance when given the same number of annotated demonstrations and particularly struggled when the number of demonstrations exceeded 160, as this surpassed\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fe2a/fe2a1727-9fb8-4dc7-a9ee-724ebfa1731e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Number of Annotated Demonstrations\n(a) TweetEval Offensive\n</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c9cf/c9cff03c-3c2a-4088-9014-099fe41c2520.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Number of Annotated Demonstrations\n(b) TweetEval Hate\n</div>\nFigure 5: An analysis of M O ICL\u2019s data efficiency on the TweetEval offensive/hate test set using Llama-3-8B-Instruct. Concat-based ICL concatenated all available demonstrations (x-axis), though more than 160 exceeded the context length. M O ICL Scalar Weights (k = n) assigned the designated demonstrations to the experts while using the remaining available demonstrations for fine-tuning.\n\nthe context length limit. Furthermore, we also analysed whether M O ICL could be more time-efficient compared to concatbased ICL under the same settings. Fig. 6  compares the performance in terms of the average inference time (in seconds) per instance when up to 160 annotated demonstrations (which is the context length limit for concat-based ICL) are provided. We observed that M O ICL consistently showed higher accuracy compared to concat-based ICL relative to inference time, demonstrating that M O ICL is not only data-efficient but also time-efficient.\n\nthe context length limit. Furthermore, we also analysed whether M O ICL could be more time-efficient compared to concatbased ICL under the same settings. Fig. 6  compares the performance in terms of the average inference time (in seconds) per instance when up to 160 annotated demonstrations (which is the context length limit for concat-based ICL) are provided. We observed that M O ICL consistently showed higher accuracy compared to concat-based ICL relative to inference time, demonstrating that M O ICL is not only data-efficient but also time-efficient.\nComplexity The proposed M O ICL method partitions demonstrations into subsets rather than concatenating them, thereby reducing the input context length for LLMs. This reduction is beneficial in Transformer-based architectures, where computational load increases quadratically with the context length. In Table 9, we analyse the computation cost based on the unit computation cost (one forward\n\nComplexity The proposed M O ICL method partitions demonstrations into subsets rather than concatenating them, thereby reducing the input context length for LLMs. This reduction is beneficial in Transformer-based architectures, where computational load increases quadratically with the context length. In Table 9, we analyse the computation cost based on the unit computation cost (one forward\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3245/324502e6-db83-4ade-93ce-d3a3efd60625.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) TweetEval Offensive\n</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a959/a959ecfc-6220-4f83-b6e1-f15c165725b0.png\" style=\"width: 50%;\"></div>\nFigure 6: An analysis of the inference time efficiency of M O ICL on the TweetEval offensive/hate test set using Llama3-8B-Instruct. The total number of demonstrations available to M O ICL scalar is 160, the same as the maximum number of demonstrations that concat-based ICL can use within the context length limit.\n\npass for one example) of LLM and Hyper-network, namely C LLM and C Hyper. Concat-based ICL exhibits the highest cost by concatenating all demonstrations and the test input (n + 1), whereas Ensemble-based ICL shows the lowest cost by concatenating each demonstration with the test input (1+1). M O ICL lies in-between, with the cost determined by the number of subsets, k. Hyper-network takes all subsets as input and outputs the weight for each subset, thereby adding a cost of (n + 1) 2 \u00b7 C Hyper. Since C LLM  is usually much larger than C Hyper, this approach still offers a computational advantage. Furthermore, the weights of the subsets only need to be computed once and can be reused for future inputs, which means n 2 \u00b7 C Hyper is a one-time process.\n\n# 6 Related Work\n\nIn-Context Learning In-context learning (ICL) is an approach to few-shot learning by concatenating the training examples and providing them as input to the model before the actual test example.\n\n<div style=\"text-align: center;\">Complexity\n</div>\nMethod\nComplexity\nConcat-based ICL\n(n + 1)2 \u00b7 CLLM\nEnsemble-based ICL\nn \u00b7 (1 + 1)2 \u00b7 CLLM\nMixture of ICL\n- uniform\nk \u00b7 ( n\nk + 1)2 \u00b7 CLLM\n- scalar\nk \u00b7 ( n\nk + 1)2 \u00b7 CLLM\n- Hyper-network\nk \u00b7 ( n\nk + 1)2 \u00b7 CLLM + n2 \u00b7 CHyper\nTable 9: Comparison of the computational complexity at inference time between M O ICL Methods and Baseline ICL Methods. C LLM and C Hyper  refer to the unit computation complexity for one demonstration and one forward pass for an LLM and Hyper-network, respectively. n and k refer to the number of demonstrations and the number of subsets.\n\nBeing able to perform ICL is an emerging ability of very large models, such as GPT-3 (Brown et al., 2020) and PaLM (Chowdhery et al., 2023). One characteristic of ICL is that increasing the number of demonstrations tends to increase the downstream task accuracy (Brown et al., 2020; Lu et al., 2022). However, Agarwal et al. (2024) show that, after a given number of demonstrations, performance saturates and additional examples might even decrease the downstream task accuracy. Furthermore, in Transformer-based LLMs, increasing the number of ICL demonstrations can be too computationally demanding due to the complexity of self-attention operations growing quadratically with the context size (Liu et al., 2022). Finally, ICL is sensitive to out-of-domain demonstrations (Min et al., 2022b) or label imbalance, underscoring the importance of the selection of the in-context demonstrations to use (Zhao et al., 2021; Fei et al., 2023).\n\n# Ensembles of Demonstrations Min et al\n\n# Ensembles of Demonstrations\n\n(2022a) introduce ensemble-based demonstrations as an alternative to concat-based ICL (Section 2.1), where each demonstration (x i, y i) is provided to a language model along with the input x to obtain a next-token distribution p (y | x i, y i, x); such nexttoken distributions are then combined in a productof-experts to produce the final next-token distribution: p (y | x 1, y 1, . . . , x) = \ufffd i p (y | x i, y i, x).\nLe et al. (2022) propose Mixtures of In-Context Experts for anaphora resolution, where the weights for each expert were calculated based on the cosine similarity between the embeddings of the test input and the demonstrations. Ye et al. (2023) extend the models by Le et al. (2022) and analyse the impact of merging the expert activations at different stages, both in terms of efficiency and downstream task performance.\n\nOur proposed Mixture of In-Context Learners (M O ICL) extends such approaches by learning a weighting function assigning specific weights to each expert. Our experiments show that this approach allows us to tackle various challenges in ICL (such as label imbalance, out-of-distribution demonstrations, and sample selection) without requiring access to the model weights.\n\n# 7 Conclusions\n\nWe proposed Mixture of In-Context Learners (M O ICL), a method for dynamically learning to combine multiple models, each trained via ICL, via gradient-based optimisation methods. We show that M O ICL significantly improves accuracy compared to a set of strong baselines. Furthermore, we show that M O ICL is robust to out-of-domain and noisy demonstrations, can help mitigate label imbalance, and can be used for selecting sets of demonstrations.\n\n# Limitations\n\nAlthough M O ICL does not require direct access to the model parameters, it requires access to the logits of the distribution over the vocabulary or answers produced by the model, both to train the experts and to calculate the final prediction at inference time, which prevents its use with blackbox models like GPT-4. Future work can consider black-box optimisation methods to address this limitation. An important direction for future work, though not explored in this study, is extending the learned weights to the demonstrations across the entire training set. Currently, we sample n  demonstrations from the training set and assign them to experts, tuning their weights. Extending this to all demonstrations in the training set would require progressively expanding the experts and their tuned weights. One possible approach for future work is to incorporate the search and relevance heuristics proposed by Li and Qiu (2023) as inductive biases in our proposed hyper-network. Additionally, due to computational resource limitations, we conducted our experiments on the Llama-2 models (Llama-2-7B-chat, Llama-213B-chat, Llama-2-70B-chat) and Llama-3 models (Llama-3-8B, Llama-3-8B-Instruct) as target LLMs, and T5-models (T5-efficient-tiny, T5-efficient-mini, T5-small, T5-base) as  hypernetworks. However, our method is not limited to\n\nspecific LMs and can be applied across various models.\n\nAcknowledgments Giwon Hong was supported by the ILCC PhD program (School of Informatics Funding Package) at the University of Edinburgh, School of Informatics. Pasquale Minervini and Emile van Krieken were partially funded by ELIAI (The Edinburgh Laboratory for Integrated Artificial Intelligence), EPSRC (grant no. EP/W002876/1). Additionally, Pasquale Minervini was partially funded by an industry grant from Cisco, and a donation from Accenture LLP. This work was supported by the Edinburgh International Data Facility (EIDF) and the Data-Driven Innovation Programme at the University of Edinburgh.\n\n# References\n\nRishabh Agarwal, Avi Singh, Lei M Zhang, Bernd Bohnet, Luis Rosias, Stephanie CY Chan, Biao Zhang, Aleksandra Faust, and Hugo Larochelle. 2024. Many-shot in-context learning. In  ICML 2024 Workshop on In-Context Learning.\n\nAI@Meta. 2024. Llama 3 model card.\n\n# AI@Meta. 2024. Llama 3 model card.\n\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In  Advances in Neural Information Processing Systems,\n\nYanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown, and He He. 2023. On the relation between sensitivity and accuracy in in-context learning. In 2023 Findings of the Association for Computational Linguistics: EMNLP 2023, pages 155\u2013167. Association for Computational Linguistics (ACL).\n\nNghia T. Le, Fan Bai, and Alan Ritter. 2022.  Fewshot anaphora resolution in scientific protocols via mixtures of in-context experts. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 2693\u20132706, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\n\nKenton Lee, Ming-Wei Chang, and Kristina Toutanova. 2019. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6086\u20136096, Florence, Italy. Association for Computational Linguistics.\nXiaonan Li and Xipeng Qiu. 2023. Finding support examples for in-context learning. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 6219\u20136235.\nAlisa Liu, Xiaochuang Han, Yizhong Wang, Yulia Tsvetkov, Yejin Choi, and Noah A. Smith. 2024.  Tuning language models by proxy. In First Conference on Language Modeling.\nHaokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin Raffel. 2022. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning.\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2022. Fantastically ordered prompts and where to find them: Overcoming fewshot prompt order sensitivity. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8086\u20138098, Dublin, Ireland. Association for Computational Linguistics.\nYao Lu, Jiayi Wang, Raphael Tang, Sebastian Riedel, and Pontus Stenetorp. 2024. Strings from the library of babel: Random sampling as a strong baseline for prompt optimisation. In NAACL-HLT, pages 2221\u2013 2231. Association for Computational Linguistics.\nSourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and Benjamin Bossan. 2022. Peft: State-of-the-art parameterefficient fine-tuning methods. https://github. com/huggingface/peft.\nSewon Min, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022a. Noisy channel language model prompting for few-shot text classification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5316\u20135330, Dublin, Ireland. Association for Computational Linguistics.\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022b. Rethinking the role of demonstrations: What makes in-context learning work? In  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 11048\u201311064, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\nPasquale Minervini, Luca Franceschi, and Mathias Niepert. 2023. Adaptive perturbation-based gradient estimation for discrete latent variable models. In AAAI, pages 9200\u20139208. AAAI Press.\n\nMathias Niepert, Pasquale Minervini, and Luca Franceschi. 2021. Implicit mle: backpropagating through discrete exponential family distributions.  Advances in Neural Information Processing Systems, 34:14567\u201314579.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1\u201367.\nStephen Robertson, Hugo Zaragoza, et al. 2009. The probabilistic relevance framework: Bm25 and beyond.  Foundations and Trends\u00ae in Information Retrieval, 3(4):333\u2013389.\nRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In  Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631\u20131642, Seattle, Washington, USA. Association for Computational Linguistics.\nJames Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. 2018. Fever: a large-scale dataset for fact extraction and verification. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 809\u2013819.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.\nAnton Voronov, Lena Wolf, and Max Ryabinin. 2024. Mind your format: Towards consistent evaluation of in-context learning improvements. In  ACL (Findings), pages 6287\u20136310. Association for Computational Linguistics.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2018. Glue: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353\u2013355.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. Transactions on Machine Learning Research.\nXin Xu, Yue Liu, Panupong Pasupat, Mehran Kazemi, et al. 2024. In-context learning with retrieved demonstrations for language models: A survey. arXiv preprint arXiv:2401.11624.\n\nMathias Niepert, Pasquale Minervini, and Luca Franceschi. 2021. Implicit mle: backpropagating through discrete exponential family distributions.  Advances in Neural Information Processing Systems, 34:14567\u201314579.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1\u201367.\nStephen Robertson, Hugo Zaragoza, et al. 2009. The probabilistic relevance framework: Bm25 and beyond.  Foundations and Trends\u00ae in Information Retrieval, 3(4):333\u2013389.\nRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In  Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631\u20131642, Seattle, Washington, USA. Association for Computational Linguistics.\nJames Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. 2018. Fever: a large-scale dataset for fact extraction and verification. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 809\u2013819.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.\nAnton Voronov, Lena Wolf, and Max Ryabinin. 2024. Mind your format: Towards consistent evaluation of in-context learning improvements. In  ACL (Findings), pages 6287\u20136310. Association for Computational Linguistics.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2018. Glue: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353\u2013355.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. Transactions on Machine Learning Research.\nXin Xu, Yue Liu, Panupong Pasupat, Mehran Kazemi, et al. 2024. In-context learning with retrieved demonstrations for language models: A survey. arXiv preprint arXiv:2401.11624.\n\nQinyuan Ye, Iz Beltagy, Matthew Peters, Xiang Ren, and Hannaneh Hajishirzi. 2023.  FiD-ICL: A fusionin-decoder approach for efficient in-context learning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8158\u20138185, Toronto, Canada. Association for Computational Linguistics.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, and Ritesh Kumar. 2019. Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval). In Proceedings of the 13th International Workshop on Semantic Evaluation, pages 75\u201386.\nYuan Zhang, Jason Baldridge, and Luheng He. 2019.\nPAWS: Paraphrase adversaries from word scrambling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1298\u20131308, Minneapolis, Minnesota. Association for Computational Linguistics.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language models. In International conference on machine learning, pages 12697\u201312706. PMLR.\n\nQinyuan Ye, Iz Beltagy, Matthew Peters, Xiang Ren, and Hannaneh Hajishirzi. 2023.  FiD-ICL: A fusionin-decoder approach for efficient in-context learning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8158\u20138185, Toronto, Canada. Association for Computational Linguistics.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, and Ritesh Kumar. 2019. Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval). In Proceedings of the 13th International Workshop on Semantic Evaluation, pages 75\u201386.\nYuan Zhang, Jason Baldridge, and Luheng He. 2019.\nPAWS: Paraphrase adversaries from word scrambling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1298\u20131308, Minneapolis, Minnesota. Association for Computational Linguistics.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language models. In International conference on machine learning, pages 12697\u201312706. PMLR.\n\nSplit\nOffensive\nHate\nSST2\nRTE\nFEVER\nPAWS\nQNLI\nTrain set\n11,916\n9,000\n66,349\n2,190\n54,550\n49,401\n99,743\nDev set\n1,324\n1,000\n1,000\n300\n5,000\n8,000\n5,000\nTest set\n860\n2,970\n872\n277\n13,332\n8,000\n5463\nTable 10: Statistics of the classification datasets used in our experiments.\n\n# A Detailed Experiment Settings\n\n# A.1 Datasets\n\nTweetEval (Barbieri et al., 2020) offensive/hate datasets are originally from Zampieri et al. (2019) and Basile et al. (2019), respectively. PAWS (Zhang et al., 2019) is released under a custom license 2 from Google LLC. For SST-2 (Socher et al., 2013) 3, RTE (Bentivogli et al., 2009), FEVER (Thorne et al., 2018) 4, and QNLI (Wang et al., 2018) 5, we used the original validation/development set as the test set and sampled a portion of the training set to construct a new validation set. Table 10 presents the dataset split statistics for all classification datasets used in our experiments. For NQ-open (Lee et al., 2019) 6, we used the top 1 retrieved documents as a context. The dataset contains 79,168 train instances, 8,757 validation instances, and 3,610 test instances.\n\n# A.2 Hyperparameters\n\nWe used five seeds [31, 42, 65, 438, 991]  in all experiments except for NQ-open, which were applied to every possible aspect, including dataset shuffle, demonstration pooling and partition, and Hyper-network fine-tuning, and baseline results. For NQ-open, we only use seed 42. Also, we set the batch size to 1, the gradient accumulation steps to 12 and the learning rate to 0.0001, without performing a hyperparameter search for these settings. For the PEFT (LoRA, Hu et al., 2022) baseline, we set r =16 (rank), alpha=32 (scale factor), and dropout=0.1. We did not perform a search for these LoRA hyperparameters as we utilised the default settings provided by Mangrulkar et al. (2022). Unless otherwise specified, a total of 30 demonstrations were used along with Static partitioning. Both scalar and Hyper-network were tuned for 5 epochs.\n\n2 The dataset is provided \"AS IS\" without any warranty, express or implied. Google disclaims all liability for any damages, direct or indirect, resulting from the use of the dataset. 3 The dataset is released under The MIT License license. 4 The dataset is released under CC BY-SA 3.0 license. 5 The dataset is released under CC BY-SA 4.0 license. 6 The dataset is released under CC BY-SA 3.0 license.\n\nFor the data efficiency analysis on Fig. 5  in Section 5, we applied the same training step (10,240) to all different M O ICL settings.\n\n# A.3 Implementation Details\n\nM O ICL For all datasets used in the experiments, we fine-tuned all the M O ICL weights and  hypernetwork on the training set and evaluated them on the validation/development set at each epoch, selecting the ones with the highest performance. The results reported in all experiments were measured on the test set. For scalar, we first sampled D from the training set based on the different seeds and used the remaining training instances as D T  (Section 2.2). For hyper-network, D is not available during training and is used only during evaluation. We further separate D T into D pool and D pair  randomly at each epoch, where demonstrations are sampled from D pool and (x, y) \u2208 D pair. While any model that produces weights can be used for the hyper-network, we attach a linear layer on top of a pre-trained encoder-decoder T5-small (Raffel et al., 2020) model.\n\nM O ICL For all datasets used in the experiments, we fine-tuned all the M O ICL weights and  hypernetwork on the training set and evaluated them on the validation/development set at each epoch, selecting the ones with the highest performance. The results reported in all experiments were measured on the test set. For scalar, we first sampled D from the training set based on the different seeds and used the remaining training instances as D T  (Section 2.2). For hyper-network, D is not available during training and is used only during evaluation. We further separate D T into D pool and D pair  randomly at each epoch, where demonstrations are sampled from D pool and (x, y) \u2208 D pair. While any model that produces weights can be used for the hyper-network, we attach a linear layer on top of a pre-trained encoder-decoder T5-small (Raffel et al., 2020) model.\nBaselines For PEFT fine-tuned on RTE, we applied early stopping based on the dev set accuracy, as we observed that the training process was highly unstable. Both Ensemble-based ICL (Min et al., 2022a) and LENS (Li and Qiu, 2023) used the Direct method instead of the Channel method, which also applied for M O ICL as well. For LENS, We first apply Progressive Example Filtering to select 30 demonstrations, then perform Diversity-Guided Search to obtain 5 permutations of the examples, and report the average and standard deviation based on these 5 permutations.\n\nBaselines For PEFT fine-tuned on RTE, we applied early stopping based on the dev set accuracy, as we observed that the training process was highly unstable. Both Ensemble-based ICL (Min et al., 2022a) and LENS (Li and Qiu, 2023) used the Direct method instead of the Channel method, which also applied for M O ICL as well. For LENS, We first apply Progressive Example Filtering to select 30 demonstrations, then perform Diversity-Guided Search to obtain 5 permutations of the examples, and report the average and standard deviation based on these 5 permutations.\n\n# B Additional Analyses\n\nIn this work, we analyse the following partitioning strategies: Static, Random Size, and BM25. Static means partitioning n demonstrations into k subsets, with each subset containing n/k  demonstrations. Random Size refers to partitioning into k subsets, each containing a random number of elements. BM25 apply k-NN clustering based on BM25 scores on demonstrations (Robertson et al., 2009) to partition into them k subsets. Table 11 compares the performance of M O ICL methods and different partitioning methods (Static, Random, BM25) for the same k  (number of subsets). In uniform, there is little difference between\n\nMOICL Method\nStatic\nRandom Size\nBM25\nuniform\nk = 3\n74.86\u00b11.84\n74.74\u00b11.90\n74.79\u00b11.79\nk = 5\n73.77\u00b11.60\n74.09\u00b11.35\n73.47\u00b12.19\nk = 10\n74.00\u00b10.87\n73.37\u00b10.94\n74.40\u00b10.82\nscalar\nk = 3\n76.14\u00b11.48\n77.37\u00b11.97\n77.21\u00b12.02\nk = 5\n78.35\u00b11.49\n77.67\u00b12.69\n78.37\u00b11.62\nk = 10\n79.42\u00b11.48\n78.72\u00b10.87\n79.70\u00b11.32\nTable 11: Analysis of partitioning methods. Random and BM25 represent random clustering and clustering based on BM25 scores, respectively. Bold text signifies the highest accuracy for each method.\n\nStatic and Random and only a slight performance improvement with BM25. However, there is a common performance enhancement when M O ICL scalar are applied. This indicates that our proposed method is not significantly affected by partitioning methods and can be applied in a complementary manner across them. As such, we decided to use only the Static method in the other experiments.\n\n# B.2 Logits vs. Probabilities for Mixing Experts\n\nAs stated in Section 2.2, we mix the experts in the log domain. However, it is also possible\u2014and perhaps more appropriate\u2014to use a regular mixture of probabilities, as in Eq. (5).\n\n(5)\n\nAccordingly, in Fig. 2, we compare the accuracy trends based on partitioning size when using weighting in the probability and logit domains. In uniform, whether logits or probabilities were used did not make a significant difference, but in scalar, the impact was substantial. This is likely because distinct differences in the distribution patterns among experts (and thus useful information in the mixture) get diluted during the normalisation process when using probabilities.\n\n# B.3 M O ICL in a Generation Task\n\nIn addition to the classification tasks in Section 4.1, we also apply our M O ICL on a generation task, NQ-open (Lee et al., 2019), in Table 12. However, unlike in classification tasks, M O ICL did not show significant EM improvements over baseline approaches. Nevertheless, as seen in Section 4.6, M O ICL exhibited strong robustness in situations\n\nMethods (n = 12)\nNQ-open (EM)\nConcat-based ICL\n0.4083\nEnsemble-based ICL (Min et al., 2022a)\n0.3753\nRandom Search\n0.4008\nMixture of ICL (uniform)\nk = 6\n0.3864\nk = 12\n0.3753\nMixture of ICL (uniform)\nk = 6\n0.3861\nk = 12\n0.3742\nMixture of ICL (Hyper-network)\nk = 6\n0.3848\nk = 12\n0.3842\nTable 12: Comparison between baseline methods and M O ICL on NQ-open using Llama-3-8B. k represents the number of demonstrations subset, where the total number of demonstrations (n) is 12\n\ninvolving noised demonstrations, proving the usefulness of the expert\u2019s tuned weights.\n\n# C Prompt Templates\n\nTable 13 presents the corresponding metric and prompt template for all tasks included in the experiments. For NQ, CNN/DM, and XSum, the delimiter for ICL demonstrations was \u2018\\n\\n\u2019. For the remaining tasks, \u2018\\n\u2019 was used as the delimiter.\n\n# D Computation Details\n\nThe experiments were conducted using NVIDIA A100 40GBs and 80GBs with 120GB of RAM. The GPU hours vary depending on the models and tasks; tuning M O ICL scalar weights (n, k = 30) on TweetEval offensive takes approximately 1 hour and 20 minutes per epoch.\n\nTask\nMetric\nPrompt Template\nTweetEval Offensive\nAccuracy\nClassify tweets that are offensive as offensive, and tweets that are not offensive as neutral.\n{{ICL Demonstrations}}\nTweet: {{tweet}}\nLabel:\nTweetEval Hate\nAccuracy\nClassify tweets that are hateful against immigrants or women as hate and tweets that are\nnot hateful against immigrants or women as neutral.\n{{ICL Demonstrations}}\nTweet: {{tweet}}\nLabel:\nSST2\nAccuracy\nClassify sentences that are negative as negative and sentences that are positive as positive.\n{{ICL Demonstrations}}\nSentence: {{sentence}}\nLabel:\nRTE\nAccuracy\nClassify two sentences that entail each other as true and two sentences that do not\nentail each other as false.\n{{ICL Demonstrations}}\nSentence1: {{first sentence}} Sentence2: {{second sentence}}\nLabel:\nFEVER\nAccuracy\nClassify claims that are false as refuted, and tweets that are true as supported.\n{{ICL Demonstrations}}\nClaim: {{claim}}\nLabel:\nPAWS\nAccuracy\nClassify the two sentences as yes if they are paraphrases of each other, and if not,\nclassify them as no.\n{{ICL Demonstrations}}\nsentence1: {{first sentence}} sentence2: {{second sentence}}\nlabel:\nQNLI\nAccuracy\nClassify as yes if the sentence contains the answer to the question, if not, classify as no.\n{{ICL Demonstrations}}\nsentence: {{sentence}}\nquestion: {{question}}\nlabel:\nNQ\nEM\n{{ICL Demonstrations}}\ntitle: {{title}} text: {{text}}\nQuestion: {{question}}\nAnswer:\n",
    "paper_type": "method",
    "attri": {
        "background": "In-context learning (ICL) adapts LLMs by providing demonstrations without fine-tuning the model parameters; however, it does not differentiate between demonstrations and quadratically increases the complexity of Transformer LLMs, exhausting the memory.",
        "problem": {
            "definition": "The problem addressed in this paper is the inefficiency of existing ICL methods that do not effectively select and weight demonstrations, leading to suboptimal performance and excessive memory usage.",
            "key obstacle": "The main difficulty is the quadratic growth in complexity and memory consumption associated with increasing the number of demonstrations, which limits the effectiveness of ICL."
        },
        "idea": {
            "intuition": "The idea originated from recognizing that not all demonstrations contribute equally to the model's performance, and that a method to dynamically weight these demonstrations could enhance learning.",
            "opinion": "The proposed Mixtures of In-Context Learners (M O ICL) method treats subsets of demonstrations as experts and learns a weighting function to combine their outputs, improving ICL performance.",
            "innovation": "M O ICL innovates by allowing the model to dynamically learn which subsets of demonstrations are most effective, contrasting with existing methods that apply a static approach to demonstration selection."
        },
        "method": {
            "method name": "Mixtures of In-Context Learners",
            "method abbreviation": "M O ICL",
            "method definition": "M O ICL partitions a set of demonstrations into subsets that are treated as experts, combining their outputs based on learned weights to optimize performance.",
            "method description": "M O ICL combines the outputs of multiple expert models, each trained on different subsets of demonstrations, through a learned weighting mechanism.",
            "method steps": [
                "Partition the set of demonstrations into k subsets.",
                "Pass each subset to the LLM as an expert.",
                "Combine the next-token distributions of the experts using a learned weighting function."
            ],
            "principle": "This method is effective because it reduces the input context length and allows for more efficient use of memory and computational resources, addressing the limitations of traditional ICL."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted using various classification datasets including TweetEval offensive/hate, SST2, RTE, FEVER, PAWS, and QNLI, with comparisons made against baseline methods such as concat-based ICL and random search.",
            "evaluation method": "Performance was assessed using accuracy for classification tasks and Exact Match (EM) for generation tasks, with results measured on development and test sets."
        },
        "conclusion": "M O ICL significantly improves accuracy across multiple datasets compared to strong baselines, demonstrating robustness to out-of-domain and noisy demonstrations while effectively mitigating label imbalance.",
        "discussion": {
            "advantage": "The key advantages of M O ICL include improved performance, reduced memory usage, and the ability to handle noisy and imbalanced datasets more effectively than traditional ICL methods.",
            "limitation": "A limitation of M O ICL is that it requires access to the logits of the model's output distributions, which limits its applicability to black-box models.",
            "future work": "Future research could explore black-box optimization methods to enable the use of M O ICL with models that do not provide access to internal parameters."
        },
        "other info": {
            "acknowledgments": "Giwon Hong was supported by the ILCC PhD program at the University of Edinburgh, while Pasquale Minervini and Emile van Krieken received funding from ELIAI and other sources.",
            "data efficiency": "M O ICL shows high data efficiency, achieving better performance than concat-based ICL with fewer annotated demonstrations."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "In-context learning (ICL) adapts LLMs by providing demonstrations without fine-tuning the model parameters."
        },
        {
            "section number": "1.2",
            "key information": "The problem addressed in this paper is the inefficiency of existing ICL methods that do not effectively select and weight demonstrations, leading to suboptimal performance and excessive memory usage."
        },
        {
            "section number": "1.3",
            "key information": "M O ICL innovates by allowing the model to dynamically learn which subsets of demonstrations are most effective, contrasting with existing methods that apply a static approach to demonstration selection."
        },
        {
            "section number": "3.1",
            "key information": "The main difficulty is the quadratic growth in complexity and memory consumption associated with increasing the number of demonstrations, which limits the effectiveness of ICL."
        },
        {
            "section number": "3.2",
            "key information": "The proposed Mixtures of In-Context Learners (M O ICL) method treats subsets of demonstrations as experts and learns a weighting function to combine their outputs, improving ICL performance."
        },
        {
            "section number": "4.1",
            "key information": "M O ICL combines the outputs of multiple expert models, each trained on different subsets of demonstrations, through a learned weighting mechanism."
        },
        {
            "section number": "6.1",
            "key information": "A limitation of M O ICL is that it requires access to the logits of the model's output distributions, which limits its applicability to black-box models."
        },
        {
            "section number": "7",
            "key information": "M O ICL significantly improves accuracy across multiple datasets compared to strong baselines, demonstrating robustness to out-of-domain and noisy demonstrations while effectively mitigating label imbalance."
        }
    ],
    "similarity_score": 0.6968499277189805,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2330_in-co/papers/Mixtures of In-Context Learners.json"
}