{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2101.06070",
    "title": "Efficient Semi-Implicit Variational Inference",
    "abstract": "In this paper, we propose CI-VI an efficient and scalable solver for semi-implicit variational inference (SIVI). Our method, first, maps SIVI\u2019s evidence lower bound (ELBO) to a form involving a nonlinear functional nesting of expected values and then develops a rigorous optimiser capable of correctly handling bias inherent to nonlinear nested expectations using an extrapolation-smoothing mechanism coupled with gradient sketching. Our theoretical results demonstrate convergence to a stationary point of the ELBO in general non-convex settings typically arising when using deep network models and an order of O(t\u22124/5) gradient-bias-vanishing rate. We believe these results generalise beyond the specific nesting arising from SIVI to other forms. Finally, in a set of experiments, we demonstrate the effectiveness of our algorithm in approximating complex posteriors on various data-sets including those from natural language processing.",
    "bib_name": "moens2021efficientsemiimplicitvariationalinference",
    "md_text": "# Efficient Semi-Implicit Variational Inference\nVincent Moens\nHuawei R&D UK\nvincent.moens@huawei.com\nHang Ren\nHuawei R&D UK\nhang.ren1@huawei.com\nAlexandre Maraval\nHuawei R&D UK\nalexandre.maravel@huawei.com\nRasul Tutunov\nHuawei R&D UK\nrasul.tutunov@huawei.com\nJun Wang\nHuawei R&D UK\nUniversity College London\nw.j@huawei.com\nHaitham Ammar \u2217\nHuawei R&D UK\nUniversity College London\nhaitham.ammar@huawei.com\n# Abstract\nIn this paper, we propose CI-VI an efficient and scalable solver for semi-implicit variational inference (SIVI). Our method, first, maps SIVI\u2019s evidence lower bound (ELBO) to a form involving a nonlinear functional nesting of expected values and then develops a rigorous optimiser capable of correctly handling bias inherent to nonlinear nested expectations using an extrapolation-smoothing mechanism coupled with gradient sketching. Our theoretical results demonstrate convergence to a stationary point of the ELBO in general non-convex settings typically arising when using deep network models and an order of O(t\u22124/5) gradient-bias-vanishing rate. We believe these results generalise beyond the specific nesting arising from SIVI to other forms. Finally, in a set of experiments, we demonstrate the effectiveness of our algorithm in approximating complex posteriors on various data-sets including those from natural language processing.\narXiv:2101.06070v1\n# 1 Introduction\nVariational Inference (VI) is an approximate Bayesian inference framework that recasts reasoning about latent variable models as an instance of numerical optimisation [15, 34]. This is achieved by positing a class of variational distributions and optimising an evidence lower-bound (ELBO) that involves log-joint densities rather than intractable posteriors. Classical VI introduces simplifying assumptions (e.g., mean-field and/or conditional conjugacy) to allow for tractable optimisation leading to algorithms that ascend to a stationary point of the ELBO [3, 15]. Though successful in many applications [21, 40, 49], such assumptions, unfortunately, restrict \u201crepresentation-power\u201d and thus, lead to models that underestimate the variance of the posterior. Realising this problem, numerous frameworks aiming at expanding expressiveness of variational families have been proposed. Works in [10, 11, 12, 13, 15, 24, 31, 33, 34, 37, 38], for instance, relax mean-field assumptions and attempt to restore some dependencies in variational distributions but still require analytical probability density functions. Others in [14, 22, 25, 35, 38], moreover, introduce implicit models by sampling noise vectors and propagating these through deep networks [36]. These techniques do lead to distributions that are implicit but render computing log-variational densities and\n\u2217Honorary position at UCL.\ntheir gradients intractable. For this reason, authors resort to density ratio estimation; a methodology hard-to-scale and stabilise in high-dimensional settings.\nTo avoid density ratio estimation, recent work in [46] proposed semi-implicit variational inference (SIVI) as a hierarchical framework that obtains variational distributions through a mixing parameter accompanied by known-noise priors [36]. Exploiting this definition, original SIVI optimises a sequence of lower bounds that asymptotically converge to the original ELBO. Rather than focusing on approximate lower (upper) bounds, an unbiased estimator of the exact gradient of SIVI\u2019s ELBO has been newly achieved [36] through a Hamiltonian Monte-Carlo simulator that draws samples from a reverse conditional acquiring state-of-the-art status. Though achieving better results than previous works, unbiased estimators based on Markov Chain Monte Carlo (MCMC) easily become computationally expensive in high-dimensional regimes. Hence, an efficient solver for models supporting semi-implicit variational family distributions, largely, remains an open problem to which we contribute in this paper. Tackling the above problem, we present CI-VI, an efficient semi-implicit solver with rigorous theoretical guarantees capable of scaling to high-dimensional scenarios. Our method first maps the ELBO in SIVI to a nonlinear nested expectation (or compositional) form2, i.e., E\u03bd[f\u03bd (E\u03c9[g\u03c9(\u03b8)])] with \u03bd and \u03c9 being random variables3, f\u03bd : Rn \u2192R, gw : Rp \u2192Rn are smooth, not necessarily convex functions, and \u03b8 the optimisation parameter \u2013 and then devises an algorithm capable of handling the bias resulting from the non-linear composition of E\u03c9[\u00b7] and E\u03bd[\u00b7] through f\u03bd(\u00b7). To do so, we introduce an extrapolation-smoothing step to an ADAM-like [18, 41] solver and, in turn, show vanishing gradient bias in the order of O(t\u22124/5) ultimately enabling convergence to a stationary point. Our resulting algorithm shares similarities to recent work from [41] but unlocks novel theoretical results analysing gradient-bias terms. Though similar in spirit to [41], we realise that the original version presented in Algorithm 1 fails to scale to high-dimensions due to the need of computing large matrix-vector products (see Gradients\u2019 instructions in Algorithm 1). Rectifying this problem, we lastly anchor a gradient-sketching mechanism allowing for batched matrix-vector products, and, further, study the theoretical outcomes of such a combination. Finally, we conduct an in-depth empirical study demonstrating that CI-VI outperforms other algorithms from SIVI, nested Monte-Carlo [30], and compositional optimisation [41, 44] literature.\n# 2 Compositional implicit variational inference (CI-VI):\nIn this section, we demonstrate the connection between semi-implicit variational inference and compositional stochastic optimisation4. We, first, present the semi-implicit inference framework as detailed in [36, 46], and then link to compositional optimisation in Section 2.2. We, finally, feature an efficient adaptive solver and provide its relevant theoretical guarantees in Section 2.3.\n# 2.1 Semi-implicit variational inference\nTo approximate the posterior p(z|x) of a probabilistic model p(x, z), we define a semi-implicit variational distribution q\u03b8(z) in a hierarchical fashion using a mixing parameter as introduced in [36]:\n\ufffd \ufffd\ufffd \ufffd Equation 1 reveals the reason behind q\u03b8(z) being implicit as we can obtain latent variable samples through \u03f5 but can not (tractably) compute the integral especially when using deep networks in representing q\u03b8(z|\u03f5). In this work, we impose two standard assumptions on the nature of the variational distribution as previously explained in [36, 46]. The first assumes that q\u03b8(z|\u03f5) is reparameterisable. That is, to obtain samples from z \u223cq\u03b8(z|\u03f5), one can draw an auxiliary variable u and then set z as a deterministic function h\u03b8(\u00b7) of the sampled u i.e., u \u223cq(u), z = h\u03b8(u; \u03f5) \u2261z \u223cq\u03b8(z|\u03f5). The second, moreover, assumes that we can evaluate the log-density of the conditional i.e., log q\u03b8(z|\u03f5) as well as its gradient. As noted in [36], such an assumption is not strong in that it holds for many\n2Please notice the decoupling between the inner and outer functions f\u03bd(\u00b7) and g\u03c9(\u00b7). This requires us to further analyse SIVI\u2019s ELBO; see Section 2.3. 3Please note we do not assume any independence between \u03bd and \u03c9 4We use compositional and nested stochastic optimisation interchangeably.\nreparameterisable distributions, e.g., Gaussian, Laplace, exponential, and many others. Analogous to standard variational inference, model parameters are fit by minimising the negate of an evidence-lowe (ELBO) bound that can be derived as follows:\nContrary to classical VI that assumes tractable expectations, SIVI introduces additional intractability (e.g., in the entropy term) due to the implicit nature of the variational distribution defined in Equation 1. To tackle such intractability, recently the authors in [36] proposed writing the gradient of the entropy term as an expectation and following an MCMC sampler [42], e.g., Hamiltonian Monte Carlo [2] to estimate the gradient of the ELBO. MCMC methods, however, are known to be computationally expensive and can exhibit high variance as they assume no model \u2013 see Section 3 for a detailed comparison. Rather than following MCMC, in this paper we contribute by showing that the semiimplicit ELBO can be written as an instance of compositional optimisation and devise an adaptive and efficient solver with rigorous theoretical guarantees.\n# 2.2 SIVI in a compositional nested form\nIn this section, we present a novel connection mapping implicit variational inference to compositional stochastic optimisation, paving-the-way for an efficient and scalable solver that we later develop in Section 2.3. To do so, we start by plugging-in the variational distribution from Equation 1 in the inner-part of the ELBO (i.e., Equation 2) to get: log p(x) \u2265Ez\u223cq\u03b8(z) \ufffd log p(x,z) q\u03b8(z) \ufffd = Ez\u223cq\u03b8(z) \ufffd log p(x,z) E\u02c6\u03f5\u223cq(\u03f5)[q\u03b8(z|\u02c6\u03f5)] \ufffd , where we used \u02c6\u03f5 to denote an inner-random variable also sampled according to q(\u03f5). As noted earlier, we assume that the conditional q\u03b8(z|\u03f5) is reparameterisable through an auxiliary variable u and a deterministic function h\u03b8(u; \u03f5) with \u03f5 \u223cq(\u03f5) but independent from \u02c6\u03f5. Rather than reparametrising both inner and outer expectations, we only reparameterise the outer expectation leading us to:\nRemembering that in variational inference one minimises the negate of the ELBO, we can further write:\nRemembering that in variational inference one minimises the negate of the ELBO, we can furthe write:\nwhere we used \u00b5 = {u, \u03f5} to concatenate outer random variables with q(\u00b5) = q(u, \u03f5) = q(u)q(\u03f5). Hence, the optimisation problem involved in SIVI can be written as: min\u03b8 E\u00b5[log E\u02c6\u03f5[J\u00b5,\u02c6\u03f5(\u03b8)]]. Superficially, the aforementioned problem looks compositional in nature due to the non-linear (through the logarithm) nesting of both expectations. It is worth emphasizing, however, that the standard nested form introduced in Section 1 assumes an inherent decoupling between the inner and outer expectations, i.e., E\u03bd[f\u03bd (E\u03c9[g\u03c9(\u03b8)])]. In light of this realisation, we now introduce a formalisation capable of achieving this decoupling. To do so, we consider a pool of n-\u00b5 samples distributed according to q(\u00b5): Pool = {\u00b5i = \u27e8ui, \u03f5i\u27e9}n i=1. Now, we define a vector-valued function, g\u02c6\u03f5(\u03b8), of size n corresponding to the evaluations of J\u00b5,\u02c6\u03f5(\u03b8) on each of the samples from the pool, i.e., \u2200j \u2208[1, n] we have: g\u02c6\u03f5(\u03b8) = [J\u00b51,\u02c6\u03f5(\u03b8), . . . , J\u00b5n,\u02c6\u03f5(\u03b8)]T, with J\u00b5j,\u02c6\u03f5(\u03b8) = q\u03b8(h\u03b8(uj;\u03f5j)|\u02c6\u03f5) p(x|h\u03b8(uj;\u03f5j))p(h\u03b8(uj;\u03f5j)). To achieve the decoupling between inner an outer expectations, we allow f\u03bd(y) = [log y]Te\u03bd with e\u03bd being the \u03bd\u2019th basis vector in Rn, i.e., a vector of all zeros except a value of one in the \u03bd\u2019th position. Sampling uniformly from the pool, we can finally write SIVI\u2019s optimisation problem in a compositional form as:\n\ufffd \ufffd \ufffd\ufffd   with f\u03bd(y) = [log y]Te\u03bd and g\u02c6\u03f5(\u03b8) = [J\u00b51,\u02c6\u03f5(\u03b8), . . . , J\u00b5n,\u02c6\u03f5(\u03b8)]T. Clearly, our problem becomes exact only when assuming an infinite number of samples, i.e., n \u2192\u221e. As such, one would naturally choose n to be large-enough for a small variance estimator of the loss. This, in turn, adds complexity\n(2)\n(3)\nin designing a solver that now has to handle nested expectations and high-dimensional regimes. In the next section, we introduce such an algorithm through a novel combination of extrapolation-smoothing and gradient sketching mechanisms.\n# 2.3 An adaptive solver\nWhen designing a solver for the optimisation problem in Equation 3, we consider three essential criteria. First, we would like a simple-to-implement (i.e., single loop) yet effective and scalable algorithm. Second, we aim to have a bias-controlling procedure5 and third, we need a rigorous and theoretically-grounded solver. When surveying optimisation literature, we realise that a promising direction is a first-order method as opposed to zero [9] or second-order [39] ones. Such a realisation is grounded in the fact that first-order methods only require gradient information, are typically simple to implement through a single-loop, and perform competitively in large-scale machine learning applications [6, 18, 26]. Among first-order methods, one can further categorise adaptive [6, 26, 48] and momentum-based [20, 28] algorithms. In spite of numerous theoretical developments [1, 7, 23], ADAM \u2013 an adaptive optimiser originally proposed in [18], and then theoretically grounded in [32, 47] \u2013 (arguably) retains state-of-the-art status. Therefore, following an adaptive-like update scheme to solving the problem in Equation 3 promises ease of implementation and scalability to real-world scenarios. Though meeting two out of the three criteria above, a simple adaptation of standard optimisation techniques to a compositional problem of the form in Equation 3 is challenging due to the bias incurred from a naive Monte-Carlo sampling of non-linear nested expectations; see [30] for a detailed discussion. Of course, such a problem is not unique to this paper and has been previously studied in [30, 43]. Current methods, however, are either not-scalable to high-dimensional large-data problems [4, 27] (e.g., require full gradients \u2013 over all data \u2013 for variance reduction), or solve a relaxed version that presumes a finite sum empirical-risk-minimisation6 problem [30, 43]. To meet our requirements, we next present a novel solver that combines extrapolation-smoothing for biasreduction and gradient-sketching for efficiency and scalability. It is worth noting that our optimiser shares similarities to the work by [41] but refines analysis to derive bias-handling results (Equation 5) and introduces additional constructs (e.g., gradient-sketching mechanisms). Such additions require new proof foundations and re-derivations that we present in the appendix for completeness. Algorithmic development We aim to offer an adaptive algorithm that exhibits similar (theoretical and practical) performance guarantees to ADAM but that is also capable of correctly handling the bias inherent to the problem in Equation 2. To do so, we introduce an update scheme that resembles ADAM but incorporates auxiliary variables that are updated in a subsequent step. Being at an iteration t, our algorithm first executes the following updates:\nWhen designing a solver for the optimisation problem in Equation 3, we consider three essential criteria. First, we would like a simple-to-implement (i.e., single loop) yet effective and scalable algorithm. Second, we aim to have a bias-controlling procedure5 and third, we need a rigorous and theoretically-grounded solver. When surveying optimisation literature, we realise that a promising direction is a first-order method as opposed to zero [9] or second-order [39] ones. Such a realisation is grounded in the fact that first-order methods only require gradient information, are typically simple to implement through a single-loop, and perform competitively in large-scale machine learning applications [6, 18, 26]. Among first-order methods, one can further categorise adaptive [6, 26, 48] and momentum-based [20, 28] algorithms. In spite of numerous theoretical developments [1, 7, 23], ADAM \u2013 an adaptive optimiser originally proposed in [18], and then theoretically grounded in [32, 47] \u2013 (arguably) retains state-of-the-art status. Therefore, following an adaptive-like update scheme to solving the problem in Equation 3 promises ease of implementation and scalability to real-world scenarios.\nAlgorithmic development We aim to offer an adaptive algorithm that exhibits similar (theoretical and practical) performance guarantees to ADAM but that is also capable of correctly handling the bias inherent to the problem in Equation 2. To do so, we introduce an update scheme that resembles ADAM but incorporates auxiliary variables that are updated in a subsequent step. Being at an iteration t, our algorithm first executes the following updates:\nPrimary \u21d2 mt = \u03b3(1) t mt\u22121 + \ufffd 1 \u2212\u03b3(1) t \ufffd \u2207L(\u03b8t) , vt = \u03b3(2) t vt\u22121 + \ufffd 1 \u2212\u03b3(2) t \ufffd [\u2207L(\u03b8t)] \u21dd\u03b8t+1 = \u03b8t \u2212\u03b1t mt \u221avt + \u03be , with \u03b1t being a learning rate, \u03be \u2208R>0, \u03b3(1) t and \u03b3(2) t denoting hyper-parameters.\nAssuming the availability of sub-sampled gradients of the loss (i.e., \u2207L(\u03b8t)), the above set of instructions simply performs an ADAM-like update on the model\u2019s free parameters7 \u03b8 starting from an initialisation for mt and vt. The problem, however, arises when aiming to acquire unbiased gradients of the objective in Equation 3 [30, 36, 46]. To illustrate this, consider computing the actual gradient of L(\u03b8) at some iteration t. This can be written as: \u2207L(\u03b8t) = E\u02c6\u03f5[\u2207g\u02c6\u03f5(\u03b8t)]TE\u03bd[\u2207f\u03bd (E\u02c6\u03f5[g\u02c6\u03f5(\u03b8t)])]. It is clear that one can easily implement a Monte-Carlo estimator of the first part of the gradient, i.e., E\u02c6\u03f5[\u2207g\u02c6\u03f5(\u03b8t)]. The second term, on the other hand, is much harder to estimate due to its nested nature:\n5Here, it is to be understood that bias is due to estimating nonlinear nested expectations. 6Please note that relaxed empirical-risk versions target a different problem all-together [43]. In other words, solving a finite-sum approximation does not guarantee convergence for the nested expectation problem presented in Equation 3. 7It is worth noting that later in our theoretical analysis we provide a rigorous scheme for tuning all hyperparameters. We also follow such a schedule in our experiments.\n5Here, it is to be understood that bias is due to estimating nonlinear nested expectations. 6Please note that relaxed empirical-risk versions target a different problem all-together [43]. In other words, solving a finite-sum approximation does not guarantee convergence for the nested expectation problem presented in Equation 3. 7It is worth noting that later in our theoretical analysis we provide a rigorous scheme for tuning all hyperparameters. We also follow such a schedule in our experiments.\nOf course, a simple Monte-Carlo estimator8 of the gradient\u2019s second part is biased. Our methodology in tackling this challenge is to find an \u201cunbiased\u201d approximation with properties allowing us to control such a bias at appropriate rates. To do so, we follow an extrapolation-smoothing scheme [41, 43, 44] originally established in time series [45] and differential equations literature [17]. These methods introduce a two-step procedure to approximate an unknown quantity, e.g., E\u03bd[\u2207f\u03bd (E\u02c6\u03f5[g\u02c6\u03f5(\u03b8t)])] in our case. In the first step, a linear extrapolation query vector, z, is computed while in the second, a smoothed average is evaluated around the extrapolated z. Precisely, given two model parameter updates \u03b8t and \u03b8t+1 we execute the following:\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c7ac/c7ac50d5-44b8-4cca-a9fd-83202dd8dd0b.png\" style=\"width: 50%;\"></div>\nAuxiliary \u21d2\nzt+1 =\n\ufffd\n1 \u22121/\u03b2t\n\ufffd\n\u03b8t + 1/\u03b2t\u03b8t+1\n\ufffd\n\ufffd\ufffd\n\ufffd\nExtrapolation\nand yt+1 = (1 \u2212\u03b2t)yt + \u03b2tgt(zt+1)\n\ufffd\n\ufffd\ufffd\n\ufffd\nSmoothing\n,\nwith \u03b2t being a free parameter, and gt(zt+1) is a sampled estimator of E\u02c6\u03f5[g\u02c6\u03f5 (zt+1)].\nSimply, the smoothing step is attempting to track E\u02c6\u03f5[g\u02c6\u03f5 (zt+1)] which can then be substituted in Equation 4 to approximate the second term of the gradient. Interestingly, we evaluate this smoothing step around a linearly extrapolated vector zt+1 and not only on the updated model parameters \u03b8t+1. Though an evaluation around \u03b8t+1 can guarantee convergence [43], we demonstrate that following the above extrapolation scheme leads to faster convergence rates by enabling a better control of the bias. Informally, we can, under further technical consideration, demonstrate that the difference between true and sub-sampled gradients abides by:\nwhere \u2207gt(\u03b8t) and \u2207ft(yt) denote estimate gradients of the functions g\u02c6\u03f5(\u00b7) and f\u03bd(\u00b7), and Etotal[\u00b7] the expectation under all incurred randomness in the algorithm. Importantly, the result in Equation 5 shows that the bias in our gradient estimator vanishes with an increased number of iterations. This, in turn, allows us to prove convergence of the resulting algorithm as studied in Section 2.3. We now introduce the complete algorithm combining both of the above primary and auxiliary steps. To that end, we assume a schedule of learning rates \u03b7-schedule = {\u27e8\u03b1t, \u03b2t, \u03b3(1) t , \u03b3(2) t \u27e9}T t=1, and a timevarying set of batch-sizes K-size = {\u27e8K(1) t , K(2) t , K(3) t \u27e9} needed to mini-batch \u2207f\u03bd(\u00b7), \u2207g\u02c6\u03f5(\u00b7), and E\u02c6\u03f5[g\u02c6\u03f5(\u00b7)] respectively. Our computations are achieved through two oracles that can return gradients and function values when needed9:\nOraclef \ufffd yt, K(1) t \ufffd = {\u27e8\u03bdti, \u2207f\u03bdti (yt)\u27e9}K(1) t i=1 , with {\u03bdti}K(1) t i=1 being i.i.d. Oracleg \ufffd zt, K(2) t \ufffd = {\u27e8\u02c6\u03f5ti, g\u02c6\u03f5ti (zt), \u2207g\u02c6\u03f5ti (zt)\u27e9}K(2) t i=1 , with {\u02c6\u03f5ti}K(2) t i=1 als\nIn addition, we define \u03b4 \u2208(0, 1) used to measure solution accuracy and a small positive constant \u03be for numerical stability. The overall procedure is practical requiring only one implementation loop and is summarised in Algorithm 1. It operates in three main steps. In the first, sub-sampled gradients are computed by calling Oraclef(\u00b7) and Oracleg(\u00b7). When estimated, the second step computes primary updates leading to improved model parameters \u03b8t+1. Given \u03b8t and \u03b8t+1, the third step executes extrapolation-smoothing to update an estimate of E\u02c6\u03f5[g\u02c6\u03f5(\u00b7)] guaranteeing vanishing bias with increased iterations. It is to be noted that the smoothing step requires an additional call to Oracleg(\u00b7) to sample gt(zt+1). The updated smoothed variable yt+1 is then used in subsequent iterations where the overall process repeats.\nOn practicability Algorithm 1, though successful, assumes an idealised setting in which computing products of gradient estimates is feasible. In most reasonably-sized problems, however, such products are prohibitively expensive due to the problem\u2019s dimensionality and number of samples available (e.g.,\n8We mean by a simple estimator the following: E\u03bd \ufffd 1 (E\u02c6\u03f5[g\u02c6\u03f5(\u03b8t)])\u03bd \ufffd \u2248 1 N \ufffdN i=1 \ufffd 1 ( 1 M \ufffdM j=1 gj(\u03b8t))i \ufffd . 9Please note that in Section 2.3 we provide explicit schedules for each of the hyper-parameters introduced.\n(5)\ngorithm 1 CI-VI: Compositional Implicit Variational Inference\nInputs: Initial variable \u03b81, \u03b4 \u2208(0, 1), \u03be, T = O(\u03b4\u22125/4), \u03b7-schedule and K-size\nInitialisation: Initialise z1 = \u03b81, y1 = 0, and m0 = v0 = 0\nor t = 1 to T do:\nCompute sub-sampled gradients by calling oracles:\n\u25b7Gradients\n\u2207ft(yt) = 1/K(1)\nt\nK(1)\nt\n\ufffd\ni=1\n\u2207f\u03bdti (yt)\n=\u21d2\u2207L(\u03b8t) = \u2207gt(\u03b8t)\nT\u2207ft(yt)\n\u2207gt(\u03b8t) = 1/K(2)\nt\nK(2)\nt\n\ufffd\nj=1\n\u2207g\u02c6\u03f5tj (\u03b8t)\nPerform the following primary updates:\n\u25b7Primary Update\nmt = \u03b3(1)\nt\nmt\u22121 +\n\ufffd\n1 \u2212\u03b3(1)\nt\n\ufffd\n\u2207L(\u03b8t)\n=\u21d2\u03b8t+1 = \u03b8t \u2212\u03b1t\nmt\n\u221avt+\u03be\nvt = \u03b3(2)\nt\nvt\u22121 +\n\ufffd\n1 \u2212\u03b3(2)\nt\n\ufffd\n[\u2207L(\u03b8t)]2\nPerform the following auxiliary updates:\n\u25b7Auxiliary Update\nzt+1 = (1 \u22121/\u03b2t) \u03b8t + 1/\u03b2t\u03b8t+1\n\ufffd\n\ufffd\ufffd\n\ufffd\nExtrapolation\nand yt+1 = (1 \u2212\u03b2t)yt + \u03b2tgt(zt+1)\n\ufffd\n\ufffd\ufffd\n\ufffd\nSmoothing\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/64fd/64fd0cea-91f1-498d-8ab8-26c347171343.png\" style=\"width: 50%;\"></div>\n\ufffd \ufffd\ufffd \ufffd \ufffd : Return solution as a uniform sample from {\u03b8t}T t=1\n\ufffd \ufffd\ufffd \ufffd Output: Return solution as a uniform sample from {\u03b8t}T t=\norder of thousands). To remedy this problem, we next present a matrix-sketching mechanism (not introduced previously in both variational inference and compositional optimisation literature) from randomised linear algebra [5] enabling scalability. Here, we simply replace gradient computations (in orange) in Algorithm 1 with the set of instructions10 in Algorithm 2 that eases implementation in that it allows for randomised matrix-vector products which come-in handy in big-data problems. Rather than needing to sum overall entries in the corresponding product, we can now simply enable a batch-like version through sketching. Chiefly, as we show in Section 3, we can further specialise Algorithm 2 by accounting for the sparsity pattern of our gradients for improved adjustability to the SIVI setting.\nAlgorithm 2 Gradient-Sketching for Large-Scale SIVI\nInputs: Oraclef(yt, K(1)\nt\n), Oracleg(\u03b8t, K(2)\nt\n), #-samples dt \u2208[1, n]\nSample subset St \u2286[1, . . . , n] of size dt, where Pr(k \u2208St) = 1/n for all k = 1, . . . , n.\nReturn: \u2207L(\u03b8t) = 1/K(1)\nt\n\ufffdK(1)\nt\na=1 [q/dt\n\ufffd\nk\u2208St \u2207gT\n\u02c6\u03f5ta (\u03b8t)(:, k)\u2207f\u03bdta (yt)(k)]\nOf course, sketching mechanisms can affect speeds of convergence due to additionally induced randomness. To gain insight into such phenomena, we next provide rigorous theoretical guarantees demonstrating convergence of the resulting algorithm (i.e., Algorithm 1 with Sketching for gradient computation) and quantifying oracle complexities.\nTheoretical guarantees We demonstrate that Algorithm 1 converges to a stationary point of the non-convex objective11 in Equation 3. As is standard in optimisation literature, we provide our result\n10In Algorithm 2, we use A(:, k) to denote the kth column of some matrix A, and b(k) the kth component of a vector b. 11Non-convexity is abundant in our problem due to the usage of neural networks. In these scenarios, one aims at a stationary point as even assessing a local-minimum is NP-Hard [16].\n# =\u21d2\u2207L(\u03b8t) = \u2207gt(\u03b8t) T\u2207ft(yt)\nin terms of the number of oracle calls needed to convergence12. Due to space constraints, we defer the proof to the appendix. Here, we provide the statement of the main theorem. Our main results are based on the following common assumptions: Assumption 1. We make the following assumptions13: 1) |f\u03bd(y)| \u2264Bf, and ||\u2207f\u03bd(y)|| \u2264Mf, for all y and \u03bd; 2) f\u03bd(\u00b7) is Lf-smooth, and g\u02c6\u03f5(x) is Mg- Lipschitz continuous, and Lg-smooth; 3) oracle sample-pairs are independent; and 4) oracles return unbiased gradient estimates with bounded variances.\nNow, we present the main theorem analysing convergence and oracle complexities of Algorithm 1: Theorem 1 (Convergence & Oracle Complexities). Consider a parameter setup given by: \u03b1t = C\u03b1/t 1 5 , \u03b2t = C\u03b2, K(1) t = C1t 4 5 , K(2) t = C2t 4 5 , K(3) t = C3t 4 5 , \u03b3(1) t = C\u03b3\u00b5t, \u03b3(t) 2 = 1 \u2212C\u03b1/t 2 5 (1 \u2212 C\u03b3\u00b5t)2, for some positive constants C\u03b1, C\u03b2, C1, C2, C3, C\u03b3, \u00b5 such that C\u03b2 < 1 and \u00b5 \u2208(0, 1). For any \u03b4 \u2208(0, 1), Algorithm 1 running gradient-sketching (i.e., using Algorithm 2 to compute gradient products) with a sample-size dt = O(1) outputs, in expectation, a \u03b4-approximate first-order stationary point \u02dc\u03b8 of L(\u03b8). That is: Etotal[||\u2207L(\u02dc\u03b8)||2 2] \u2264\u03b4, with \u201ctotal\u201d representing all incurred randomness. Moreover, Algorithm 1 acquires \u02dc\u03b8 with an overall oracle complexity of the order O \ufffd \u03b4\u22129/4\ufffd .\n# \ufffd \ufffd 3 Experiments and results\nIn this section, we present an empirical study demonstrating the effectiveness of CI-VI that we implement in PyTorch [29]. We benchmark on three broad tasks covering toy examples, Bayesian logistic regression and variational autoencoders. Of course, our derivations need to be specialised to each of these tasks. We provide such constructs in the appendix due to space constraints. We compare against standard semi-implicit variational inference algorithms (e.g., SIVI and UIVI) in addition to methods from nested Monte-Carlo [30] and compositional optimisation [43, 44]. To improve stability and computational efficiency, our implementation of CI-VI tracks log-gradients instead of \u2207L(\u03b8t). Furthermore, due to the special structures of f\u03bd(\u00b7) (e.g., logarithmic function) and g\u02c6\u03f5, we can further improve gradient sketching by only (uniformly) sampling non-zero elements from \u2207g\u02c6\u03f5(\u00b7) rather than the whole dt-set St in Algorithm 2. Due to space constraints, such adaptations in addition to exact experimental settings can be found in the appendix. We ran all experiments on a single NVIDIA GeForce RTX 2080 GPU. Crucially, CI-VI is highly efficient consuming 30 seconds for toy experiments and, at most, 1.5 hours for text modelling when using variational autoencoders. Toy Experiments: In this set of experiments, we apply our method to minimise a KL-divergence between semi-implicit and ground truth distributions on two-modal, star, and banana as taken from [36]. For all semi-implicit distributions,\nFor all semi-implicit distributions, we chose q(\u03f5) to be a multi-variate zero-mean identity-covariance-matrix Gaussian, i.e., q(\u03f5) = N(0, I3\u00d73). The conditional distribution q\u03b8(z|\u03f5), is also assumed Gaussian with a neural network (two layers 50 by 50 hidden units) parameterised mean and a parameterised diagonal covariance matrix, where q\u03b8(z|\u03f5) = N(\u00b5\u03b81(\u03f5), diag(\u03b82)) with \u03b81 denoting neural network parameters, and \u03b82 another set of free parameters. Figures 1 compares the contour plots of the optimised variational distribution\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2dfe/2dfee827-e6bd-44b4-8ce9-41c0deb2b353.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: Results demonstrating that CI-VI can approximate sophisticated distributions from [36]. Left: Two-Modal distribution, Middle: Star distribution, and Right: Banana distribution.</div>\nwith ground-truth. We can clearly see that CI-VI can accurately capture sophisticated patterns like skewness, kurtosis and multi-modality. Bayesian Logistic Regression: With our method performing well on toy examples, we ran CI-VI in Bayesian logistic regression that aims to acquire posteriors on classification tasks. Given a 12Please note that analysing other metrics, e.g., generalisation bounds is an interesting avenue for future research. 13Please note that for additional clarity, our assumptions are further elaborated in the appendix.\nwith ground-truth. We can clearly see that CI-VI can accurately capture sophisticated patterns like skewness, kurtosis and multi-modality.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c376/c376c883-496b-4267-bddf-75faa513d1aa.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5d01/5d0153fe-957f-4d29-bd65-f49401eb9636.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Nodal data-set</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/83a3/83a368dc-88d7-4eeb-905e-7f13b69dea45.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fashion-MNIST data-set <latexit sha1_base64=\"nH6HesRjHxu5dWkdrKiRHU2Kt9Q=\">ACBnicbVDLSgNBEJz1bXxFPYowGAQvCbsi6MGD IgelIhGhSE3knGTL7YKZXDEtOXvwVLx4U8eo3ePNvnDwOmljQUFPVzXSXHytpyHW/nYnJqemZ2bn5zMLi0vJKdnXtxkSJFlgSkYr0nQ8GlQyxRJIU3sUaIfAV3vrt45/e4/ayCi8pk6M1QCaoWxIAWSlWnazQvhA6QmYln3nzy/Orq5HQj yBqlby+bcgtsHyfekOTYEMVa9qtSj0QSYEhCgTFlz42pmoImKR2M5XEYAyiDU0sWxpCgKa9s/o8m2r1Hkj0rZC4n3190QKgTGdwLedAVDLjHo98T+vnFDjoJrKME4IQzH4qJEoThHvZcLrUqMg1bEhJZ2Vy5aoEGQTS5jQ/BGTx4nN7sFzy1 4l3u5o8NhHNsg2xHeaxfXbETlmRlZhgj+yZvbI358l5cd6dj0HrhDOcWd/4Hz+AKylmJM=</latexit> <latexit sha1_base64=\"nH6HesRjHxu5dWkdrKiRHU2Kt9Q=\">ACBnicbVDLSgNBEJz1bXxFPYowGAQvCbsi6MGD IgelIhGhSE3knGTL7YKZXDEtOXvwVLx4U8eo3ePNvnDwOmljQUFPVzXSXHytpyHW/nYnJqemZ2bn5zMLi0vJKdnXtxkSJFlgSkYr0nQ8GlQyxRJIU3sUaIfAV3vrt45/e4/ayCi8pk6M1QCaoWxIAWSlWnazQvhA6QmYln3nzy/Orq5HQj yBqlby+bcgtsHyfekOTYEMVa9qtSj0QSYEhCgTFlz42pmoImKR2M5XEYAyiDU0sWxpCgKa9s/o8m2r1Hkj0rZC4n3190QKgTGdwLedAVDLjHo98T+vnFDjoJrKME4IQzH4qJEoThHvZcLrUqMg1bEhJZ2Vy5aoEGQTS5jQ/BGTx4nN7sFzy1 4l3u5o8NhHNsg2xHeaxfXbETlmRlZhgj+yZvbI358l5cd6dj0HrhDOcWd/4Hz+AKylmJM=</latexit> <latexit sha1_base64=\"nH6HesRjHxu5dWkdrKiRHU2Kt9Q=\">ACBnicbVDLSgNBEJz1bXxFPYowGAQvCbsi6MGD IgelIhGhSE3knGTL7YKZXDEtOXvwVLx4U8eo3ePNvnDwOmljQUFPVzXSXHytpyHW/nYnJqemZ2bn5zMLi0vJKdnXtxkSJFlgSkYr0nQ8GlQyxRJIU3sUaIfAV3vrt45/e4/ayCi8pk6M1QCaoWxIAWSlWnazQvhA6QmYln3nzy/Orq5HQj yBqlby+bcgtsHyfekOTYEMVa9qtSj0QSYEhCgTFlz42pmoImKR2M5XEYAyiDU0sWxpCgKa9s/o8m2r1Hkj0rZC4n3190QKgTGdwLedAVDLjHo98T+vnFDjoJrKME4IQzH4qJEoThHvZcLrUqMg1bEhJZ2Vy5aoEGQTS5jQ/BGTx4nN7sFzy1 4l3u5o8NhHNsg2xHeaxfXbETlmRlZhgj+yZvbI358l5cd6dj0HrhDOcWd/4Hz+AKylmJM=</latexit> <latexit sha1_base64=\"nH6HesRjHxu5dWkdrKiRHU2Kt9Q=\">ACBnicbVDLSgNBEJz1bXxFPYowGAQvCbsi6MGD IgelIhGhSE3knGTL7YKZXDEtOXvwVLx4U8eo3ePNvnDwOmljQUFPVzXSXHytpyHW/nYnJqemZ2bn5zMLi0vJKdnXtxkSJFlgSkYr0nQ8GlQyxRJIU3sUaIfAV3vrt45/e4/ayCi8pk6M1QCaoWxIAWSlWnazQvhA6QmYln3nzy/Orq5HQj yBqlby+bcgtsHyfekOTYEMVa9qtSj0QSYEhCgTFlz42pmoImKR2M5XEYAyiDU0sWxpCgKa9s/o8m2r1Hkj0rZC4n3190QKgTGdwLedAVDLjHo98T+vnFDjoJrKME4IQzH4qJEoThHvZcLrUqMg1bEhJZ2Vy5aoEGQTS5jQ/BGTx4nN7sFzy1 4l3u5o8NhHNsg2xHeaxfXbETlmRlZhgj+yZvbI358l5cd6dj0HrhDOcWd/4Hz+AKylmJM=</latexit></div>\n<div style=\"text-align: center;\">Fashion-MNIST data-set</div>\n<div style=\"text-align: center;\">MNIST data-set</div>\nFigure 2: Results depicting performance of CI-VI on both Bayesian logistic regression (top 2 rows) and variational autoenconders (bottom row). We realise that CI-VI is closer in its estimation to MCMC than is mean-field variational Bayes (MFVB). On the variational autoencoders side, we realise the CI-VI outperforms others on MNIST, Fashion-MNIST, and PBT. We use NMC-1, NMC-2, NMC-3 to denote nested-Monte-Carlo algorithms that use ADAM [18], RMS-Prop [32], and SGD respectively.\ndata-set D = {xi, yi}N i=1 where xi = (xi1, . . . , xiD)T is a D-dimensional feature vector and yi \u2208{0, 1} a binary label, Bayesian logistic regression considers a probabilistic model p(D, z) = p(z) \ufffdN i=1 p(yi|xi, z) = p(z) \ufffdN i=1 Bernoulli \ufffd (1 + exp(\u2212xT i z))\u22121\ufffd and infers the posterior of z given the observed D. We experimented with the Waveform, Spam, and Nodal data-sets from [46]. We fixed the prior p(z) to be a zero-mean Gaussian given by: p(z) = N(0, 100 \u00d7 ID\u00d7D). For the semi-implicit setting, \u03f5 followed a standard Gaussian whose dimension varied across data-sets. q\u03b8(z|\u03f5) was again a Gaussian with parameterised mean (two layer neural network with 200 units each) but with a full covariance matrix: q\u03b8(z|\u03f5) = N(\u00b5\u03b81(\u03f5), L\u03b82LT \u03b82). Due to space constraints, the full set of results can be found in the appendix. In the first two rows in Figures 1, we demonstrate violin plots on all three data-sets. Clearly CI-VI captures the variance better than Mean-Field Variational Bias (MFVB in the figure) when compared to MCMC distributions 14 across all latent variables. Semi-implicit Variational Autoencoders: In our final evaluation, we extensively experimented with variational autoencoders [19] but ones that exhibited semi-implicit variational distributions. In fact, it has been shown that upon the usage of semi-implicit variational distributions, the gap between the ELBO and marginal data likelihood can further be reduced [36, 46]. We experimented with three data-sets, two of which are standard (MNIST and Fashion-MNIST), while the third considered a text modelling task with the Penn-Tree-Bank (PTB) as presented in [8]. All structural details in each of these scenarios can be found in the appendix. Our results depicted in Figures 2 (bottom-row) compare CI-VI with semi-implicit solvers [36, 46], nested Monte-Carlo algorithms, and compositional\n14Please note we also show a marginalised pair-wise posterior plot in the appendi\n<div style=\"text-align: center;\">Waveform data-set</div>\n<div style=\"text-align: center;\">PBT data-set <latexit sha1_base64=\"G+DAXyJcFWhg9lzdFsEbVf6Rmow=\">AB/HicbVDJSgNBEO1xjXEbzdFLYxC8GZE0IOH oBePEbJBMoSenpqkSc9Cd40YhvgrXjwo4tUP8ebf2FkOmvig4PFeFVX1/FQKjY7zba2srq1vbBa2its7u3v79sFhUyeZ4tDgiUxU2capIihgQIltFMFLPIltPzh7cRvPYDSIonrOErBi1g/FqHgDI3Us0tdhEfMazd1GjBkZxpw3LPLTsWZgi4 Td07KZI5az/7qBgnPIoiRS6Z1x3VS9HKmUHAJ42I305AyPmR96Bgaswi0l0+PH9MTowQ0TJSpGOlU/T2Rs0jrUeSbzojhQC96E/E/r5NheOXlIk4zhJjPFoWZpJjQSRI0EAo4ypEhjCthbqV8wBTjaPIqmhDcxZeXSfO84joV9/6iXL2ex1EgR+S YnBKXJIquSM10iCcjMgzeSVv1pP1Yr1bH7PWFWs+UyJ/YH3+AGlYlJU=</latexit> <latexit sha1_base64=\"G+DAXyJcFWhg9lzdFsEbVf6Rmow=\">AB/HicbVDJSgNBEO1xjXEbzdFLYxC8GZE0IOH oBePEbJBMoSenpqkSc9Cd40YhvgrXjwo4tUP8ebf2FkOmvig4PFeFVX1/FQKjY7zba2srq1vbBa2its7u3v79sFhUyeZ4tDgiUxU2capIihgQIltFMFLPIltPzh7cRvPYDSIonrOErBi1g/FqHgDI3Us0tdhEfMazd1GjBkZxpw3LPLTsWZgi4 Td07KZI5az/7qBgnPIoiRS6Z1x3VS9HKmUHAJ42I305AyPmR96Bgaswi0l0+PH9MTowQ0TJSpGOlU/T2Rs0jrUeSbzojhQC96E/E/r5NheOXlIk4zhJjPFoWZpJjQSRI0EAo4ypEhjCthbqV8wBTjaPIqmhDcxZeXSfO84joV9/6iXL2ex1EgR+S YnBKXJIquSM10iCcjMgzeSVv1pP1Yr1bH7PWFWs+UyJ/YH3+AGlYlJU=</latexit> <latexit sha1_base64=\"G+DAXyJcFWhg9lzdFsEbVf6Rmow=\">AB/HicbVDJSgNBEO1xjXEbzdFLYxC8GZE0IOH oBePEbJBMoSenpqkSc9Cd40YhvgrXjwo4tUP8ebf2FkOmvig4PFeFVX1/FQKjY7zba2srq1vbBa2its7u3v79sFhUyeZ4tDgiUxU2capIihgQIltFMFLPIltPzh7cRvPYDSIonrOErBi1g/FqHgDI3Us0tdhEfMazd1GjBkZxpw3LPLTsWZgi4 Td07KZI5az/7qBgnPIoiRS6Z1x3VS9HKmUHAJ42I305AyPmR96Bgaswi0l0+PH9MTowQ0TJSpGOlU/T2Rs0jrUeSbzojhQC96E/E/r5NheOXlIk4zhJjPFoWZpJjQSRI0EAo4ypEhjCthbqV8wBTjaPIqmhDcxZeXSfO84joV9/6iXL2ex1EgR+S YnBKXJIquSM10iCcjMgzeSVv1pP1Yr1bH7PWFWs+UyJ/YH3+AGlYlJU=</latexit> <latexit sha1_base64=\"G+DAXyJcFWhg9lzdFsEbVf6Rmow=\">AB/HicbVDJSgNBEO1xjXEbzdFLYxC8GZE0IOH oBePEbJBMoSenpqkSc9Cd40YhvgrXjwo4tUP8ebf2FkOmvig4PFeFVX1/FQKjY7zba2srq1vbBa2its7u3v79sFhUyeZ4tDgiUxU2capIihgQIltFMFLPIltPzh7cRvPYDSIonrOErBi1g/FqHgDI3Us0tdhEfMazd1GjBkZxpw3LPLTsWZgi4 Td07KZI5az/7qBgnPIoiRS6Z1x3VS9HKmUHAJ42I305AyPmR96Bgaswi0l0+PH9MTowQ0TJSpGOlU/T2Rs0jrUeSbzojhQC96E/E/r5NheOXlIk4zhJjPFoWZpJjQSRI0EAo4ypEhjCthbqV8wBTjaPIqmhDcxZeXSfO84joV9/6iXL2ex1EgR+S YnBKXJIquSM10iCcjMgzeSVv1pP1Yr1bH7PWFWs+UyJ/YH3+AGlYlJU=</latexit></div>\noptimisers. Again, it is clear that CI-VI outperforms others in terms of the number of epochs needed for convergence. Interestingly, such a gap is further signified on the PBT data-set15.\n# 4 Conclusions and Future Work\nWe proposed CI-VI, a compositional solver for scalable and efficient semi-implicit variational inference. Our method rewrites SIVI as an instance of a compositional optimisation and devises a solver that correctly handles nested bias through an extrapolation-smoothing and a gradient sketching mechanism. We tested our method on a variety of tasks, including text modelling from natural language processing. In all these instances, we showed CI-VI\u2019s effectiveness. In papers to follow, we plan to further scale our method to dialogue problems from NLP and to extend our analysis to time-series models. We also think our nested-expectation theoretical results can be broadly applied beyond this paper to cover topics from experimental design. We will also tackle this direction in the future.\n# References\n[1] Zeyuan Allen Zhu and Elad Hazan. Variance Reduction for Faster Non-Convex Optimization. In Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, volume 48, pages 699\u2013707, 2016. [2] Michael Betancourt. A Conceptual Introduction to Hamiltonian Monte Carlo. arXiv preprint arXiv:1701.02434, 2017. [3] David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational Inference: A Review for Statisticians. Journal of the American Statistical Association, 112(518):859\u2013877, 2017. [4] P.J. Davis and P. Rabinowitz. Methods of Numerical Integration. Dover Books on Mathematics Series. Dover Publications, 2007. [5] Petros Drineas, Ravi Kannan, and Michael W. Mahoney. Fast Monte Carlo Algorithms for Matrices I: Approximating Matrix Multiplication. SIAM J. Comput., 36(1):132\u2013157, July 2006. [6] John Duchi, Elad Hazan, and Yoram Singer. Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. J. Mach. Learn. Res., page 2121\u20132159, 2011. [7] Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. SPIDER: Near-Optimal NonConvex Optimization via Stochastic Path-Integrated Differential Estimator. In Advances in Neural Information Processing Systems 31, NeurIPS 2018, pages 687\u2013697, 2018. [8] Hao Fu, Chunyuan Li, Ke Bai, Jianfeng Gao, and Lawrence Carin. Flexible Text Modeling with Semi-Implicit Latent Representations. [9] Victor Gabillon, Rasul Tutunov, Michal Valko, and Haitham Bou Ammar. Derivative-Free & Order-Robust Optimisation. arXiv preprint arXiv:1910.04034, 2019. 10] Ryan Giordano, Tamara Broderick, and Michael I. Jordan. Linear Response Methods for Accurate Covariance Estimates from Mean Field Variational Bayes. In Advances in Neural Information Processing Systems 28, NeurIPS 2015, pages 1441\u20131449, 2015. 11] Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Rezende, and Daan Wierstra. DRAW: A Recurrent Neural Network For Image Generation. In Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, volume 37, pages 1462\u20131471, 2015. 12] Shaobo Han, Xuejun Liao, David B. Dunson, and Lawrence Carin. Variational Gaussian Copula Inference. In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, AISTATS 2016, volume 51, pages 829\u2013838, 2016. 13] Matthew D. Hoffman, David M. Blei, Chong Wang, and John Paisley. Stochastic Variational Inference. J. Mach. Learn. Res., 14(1):1303\u20131347, 2013. 14] Ferenc Husz\u00e1r. Variational Inference using Implicit Distributions. CoRR, abs/1702.08235, 2017.\n15Please note that we do not show the results of SIVI and UIVI in Figure 1 (h) as it was hard to get these to correctly operate on NLP tasks due to their source implementations. Staying fair to these methods, we opted-ou of demonstrating their performance.\n[15] Tommi S. Jaakkola and Michael I. Jordan. Variational Probabilistic Inference and the QMR-DT Network. J. Artif. Intell. Res., 10:291\u2013322, 1999. [16] Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M. Kakade, and Michael I. Jordan. How to Escape Saddle Points Efficiently. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, volume 70, pages 1724\u20131732, 2017. [17] D. C. Joyce. Survey of Extrapolation Process in Numerical Analysis. SIAM Review, 13(4):435\u2013 490, 1971. [18] Diederik P. Kingma and Jimmy Ba. ADAM: A Method for Stochastic Optimization. In 3rd International Conference on Learning Representations, ICLR 2015, 2015. [19] Diederik P. Kingma and Max Welling. Auto-Encoding Variational Bayes. In 2nd International Conference on Learning Representations, ICLR 2014, 2014. [20] Huan Li and Zhouchen Lin. Accelerated Proximal Gradient Methods for Nonconvex Programming. In Advances in Neural Information Processing Systems 28, NeurIPS 2015, pages 379\u2013387, 2015. [21] Minne Li, Lisheng Wu, Jun Wang, and Haitham Bou-Ammar. Multi-View Reinforcement Learning. In Advances in Neural Information Processing Systems 32, NeurIPS 2019, pages 1418\u20131429, 2019. [22] Yingzhen Li and Richard E. Turner. Gradient Estimators for Implicit Models. In 6th International Conference on Learning Representations, ICLR 2018, 2018. [23] Liu Liu, Ji Liu, Cho-Jui Hsieh, and Dacheng Tao. Stochastically controlled stochastic gradient for the convex and non-convex composition problem, 2018. [24] Lars Maal\u00f8e, Casper Kaae S\u00f8nderby, S\u00f8ren Kaae S\u00f8nderby, and Ole Winther. Auxiliary Deep Generative Models. In Proceedings of The 33rd International Conference on Machine Learning, ICML 2016, volume 48, pages 1445\u20131453, 2016. [25] Shakir Mohamed and Balaji Lakshminarayanan. Learning in Implicit Generative Models. CoRR, abs/1610.03483, 2016. [26] Mahesh Chandra Mukkamala and Matthias Hein. Variants of RMSProp and Adagrad with Logarithmic Regret Bounds. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, page 2545\u20132553, 2017. [27] Yuji Nakatsukasa. Approximate and Integrate: Variance Reduction in Monte Carlo Integration via Function Approximation. arXiv preprint arXiv:1806.05492, 2018. [28] Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Course. Springer Publishing Company, Incorporated, first edition, 2014. [29] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In Advances in Neural Information Processing Systems 32, NeurIPS 2019, pages 8024\u20138035. 2019. [30] Tom Rainforth, Robert Cornish, Hongseok Yang, and Andrew Warrington. On Nesting Monte Carlo Estimators. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, volume 80, pages 4264\u20134273, 2018. [31] Rajesh Ranganath, Dustin Tran, and David M. Blei. Hierarchical Variational Models. 33rd International Conference on Machine Learning, ICML 2016, 1:515\u2013528, 2016. [32] Sashank J. Reddi, Satyen Kale, and Sanjiv Kumar. On the Convergence of ADAM and Beyond. In 6th International Conference on Learning Representations, ICLR 2018, 2018. [33] Danilo Jimenez Rezende and Shakir Mohamed. Variational Inference with Normalizing Flows. In 32nd International Conference on Machine Learning, ICML 2015, volume 2, pages 1530\u2013 1538, 2015. [34] Lawrence K. Saul and Michael Jordan. Exploiting Tractable Substructures in Intractable Networks. In Advances in Neural Information Processing Systems 8, NeurIPS 1996, pages 486\u2013492, 1996.\n[35] Jiaxin Shi, Shengyang Sun, and Jun Zhu. Kernel Implicit Variational Inference. 6th International Conference on Learning Representations, ICLR 2018, 2018. [36] Michalis K. Titsias and Francisco J. R. Ruiz. Unbiased Implicit Variational Inference. In The 22nd International Conference on Artificial Intelligence and Statistics, AISTATS 2019, volume 89, pages 167\u2013176, 2019. [37] Dustin Tran, Rajesh Ranganath, and David M. Blei. The Variational Gaussian Process. In 4th International Conference on Learning Representations, ICLR 2016, pages 1\u201314, 2016. [38] Dustin Tran, Rajesh Ranganath, and David M. Blei. Hierarchical Implicit Models and Likelihood-Free Variational Inference. In Advances in Neural Information Processing Systems 30, NeurIPS 2017, pages 5523\u20135533, 2017. [39] Rasul Tutunov, Haitham Bou-Ammar, and Ali Jadbabaie. Distributed Newton Method for Large-Scale Consensus Optimization. IEEE Trans. Autom. Control., 64(10):3983\u20133994, 2019. [40] Rasul Tutunov, Dongho Kim, and Haitham Bou Ammar. Distributed Multitask Reinforcement Learning with Quadratic Convergence. In Advances in Neural Information Processing Systems 31, NeurIPS 2018, pages 8907\u20138916. 2018. [41] Rasul Tutunov, Minne Li, Jun Wang, and Haitham Bou-Ammar. Compositional ADAM: An Adaptive Compositional Solver. CoRR, abs/2002.03755, 2020. [42] Don van Ravenzwaaij, Peter Cassey, and Scott Brown. A Simple Introduction to Markov Chain Monte\u2013Carlo Sampling. Psychonomic Bulletin & Review, 25, 03 2016. [43] Mengdi Wang, Ethan X. Fang, and Han Liu. Stochastic Compositional Gradient Descent: Algorithms for Minimizing Compositions of Expected-value Functions. Math. Program., 161(1-2):419\u2013449, 2017. [44] Mengdi Wang, Ji Liu, and Ethan Fang. Accelerating Stochastic Composition Optimization. In Advances in Neural Information Processing Systems 29, NeurIPS 2016, pages 1714\u20131722. 2016. [45] Norbert Wiener. Extrapolation, Interpolation, and Smoothing of Stationary Time Series. The MIT Press, 1964. [46] Mingzhang Yin and Mingyuan Zhou. Semi-Implicit Variational Inference. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, volume 80, pages 5646\u20135655, 2018. [47] Manzil Zaheer, Sashank Reddi, Devendra Sachan, Satyen Kale, and Sanjiv Kumar. Adaptive Methods for Nonconvex Optimization. In Advances in Neural Information Processing Systems 31, NeurIPS 2018, pages 9793\u20139803. 2018. [48] Matthew D. Zeiler. Adadelta: An Adaptive Learning Rate Method. CoRR, abs/1212.5701, 2012. [49] Cheng Zhang, Judith B\u00fctepage, Hedvig Kjellstr\u00f6m, and Stephan Mandt. Advances in Variational Inference. IEEE Trans. Pattern Anal. Mach. Intell., 41(8):2008\u20132026, 2019.\n# A Practical implementation\nTo improve numerical stability and computational efficiency, our implementation of CI-VI has been adapted to properties of functions f\u03bd(\u00b7) and g\u02c6\u03f5(\u00b7) defined in Section 2.2. These adaptions are clarified below:\nTo improve numerical stability and computational efficiency, our implementation of CI-VI has been adapted to properties of functions f\u03bd(\u00b7) and g\u02c6\u03f5(\u00b7) defined in Section 2.2. These adaptions are clarified\nLog trick: The output from g\u02c6\u03f5(\u00b7) is a vector of density ratios whose value can be extreme, especially when the z and x are high-dimensional rvs. In order to do inference in such probabilistic model, we propose a CI-VI implementation which conducts most of the computations in log-scale. The\n\u2207L(\u03b8t) = \u2207gt(\u03b8t) T\u2207ft(yt) = [\u2207log gt(\u03b8t) T]p\u00d7n \u00b7 exp \ufffd log gt(\u03b8t) + log \u2207ft(yt) \ufffd n\u00d71 \ufffd \ufffd\ufffd \ufffd kt\nThe j-th element of kt is then given by Equation 6. Since yt is a smoothed average of gt(\u03b8t), their logarithms will cancel each other before the exponentiation is taken.\n\uf8f3  \ufffd Finalising this log-scale implementation, we track the value of log yt instead of yt for the auxiliar update as follow:\n \ufffd For large-scale CI-VI, updating all dimensions of log yt is challenging due to computational and memory constraints. Rather than performing a full update for log yt, we follow a batch-like mechanism that proved effective in our experiments. Namely, we split the index set [1, n] into smaller chunks and sample \u03bdt from one of these chunks to execute the updates. This way, only those dimensions indexed by the current chunk need to be updated rather than the whole high-dimensional vector log yt. Of course, such chunks have to vary across iterations so as to guarantee the update of log yt. To do so, we switch to a new chunk occasionally and re-initialize the dimensions of log yt indexed by the new chunk using the value of log gt(zt).\nSparse gradient-sketching: Another insight from Equation 6 is that the kt is a sparse vector with non-zero elements indexed by sampled \u03bdt. The gradient-sketching in Algorithm 2 can be adapted by removing the zero elements in kt and corresponding columns in [\u2207log gt(\u03b8t) T]p\u00d7n first. The set St is then sampled uniformly from the left indices.\n# B Experimental settings and results\nToy Experiments: In toy experiments, we minimize the KL-divergence between semi-implict variational distributions q\u03b8(z) and ground-truth distributions p(z). The compositional objective can be written as: \ufffd \ufffd \ufffd\ufffd\nesian Logistic Regression: Given a data-set D = {xi, yi}N i=1, we can write the compositional m of negative ELBO as:\nBayesian Logistic Regression: Given a data-set D = {xi, yi}N i=1, we can write the compositional form of negative ELBO as:\nwhere p(D|z) = \ufffdN i=1 p(yi|xi, z) = \ufffdN i=1 Bernoulli \ufffd (1 + exp(\u2212xT i z))\u22121\ufffd .\n(6)\n# Semi-implicit Variational Autoencoder: Given a dataset D = {xi}N i=1, the negative EL single datapoint xi is given by:\nSemi-implicit Variational Autoencoder: Given a dataset D = {xi}N i=1, the negative ELBO of a single datapoint xi is given by:\nin which the encoder parameter \u03b8 and decoder parameter \u02c6\u03b8 are optimized jointly. We can further construct an estimator of the negative ELBO of the full data-set: \ufffd \ufffd \ufffd\ufffd\nin which the encoder parameter \u03b8 and decoder parameter \u02c6\u03b8 are optimized jointly. We can further construct an estimator of the negative ELBO of the full data-set: \u2212ELBO(D) = N \u00b7 E \ufffd log E \ufffd q\u03b8(h\u03b8(ui; \u03f5i)|\u02c6\u03f5i, xi) \ufffd\ufffd ,\nin which the encoder parameter \u03b8 and decoder parameter \u02c6\u03b8 are optimized jointly. We can further construct an estimator of the negative ELBO of the full data-set: \u2212ELBO(D) = N \u00b7 Exi\u223cUniform(D),ui\u223cq(u),\u03f5i\u223cq(\u03f5) \ufffd log E\u02c6\u03f5i\u223cp(\u02c6\u03f5i) \ufffd q\u03b8(h\u03b8(ui; \u03f5i)|\u02c6\u03f5i, xi) p\u02c6 \u03b8(xi|h\u03b8(ui; \u03f5i)) \u00b7 p(h\u03b8(ui; \u03f5i)) \ufffd\ufffd ,\nTwo-Modal\nStar\nBanana\n0.5N\n\ufffd\ufffd\n\u22122\n0\n\ufffd\n, I2\u00d72\n\ufffd\n+\n0.5N\n\ufffd\ufffd\n2\n0\n\ufffd\n, I2\u00d72\n\ufffd\n0.5N\n\ufffd\n0,\n\ufffd\n2\n1.8\n1.8\n2\n\ufffd\ufffd\n+\n0.5N\n\ufffd\n0,\n\ufffd\n2\n\u22121.8\n\u22121.8\n2\n\ufffd\ufffd\nz =\n\ufffd\nz1\nz2 \u2212z2\n1 \u22121\n\ufffd\n\ufffd\nz1\nz2\n\ufffd\n\u223cN\n\ufffd\n0,\n\ufffd\n1\n0.9\n0.9\n1\n\ufffd\ufffd\nTable 1: Ground-truth distributions used in toy experiments\n\ufffd \ufffd \ufffd \u2212 \ufffd\ufffd \ufffd \ufffd \ufffd Table 1: Ground-truth distributions used in toy experiments\nTwo-Modal\nStar\nBanana\nq(\u03f5)\nN (0, I3\u00d73)\nN (0, I3\u00d73)\nN (0, I3\u00d73)\nq\u03b8(z|\u03f5)\nN(\u00b5\u03b81(\u03f5), diag(\u03b82))\nN(\u00b5\u03b81(\u03f5), diag(\u03b82))\nN(\u00b5\u03b81(\u03f5), diag(\u03b82))\n\u00b5\u03b81\nHidden units: (50, 50)\nHidden activation: ReLU\nInitializer: Xavier_normal\nHidden units: (50, 50)\nHidden activation: ReLU\nInitializer: Xavier_normal\nHidden units: (50, 50)\nHidden activation: ReLU\nInitializer: Xavier_normal\nHyper\nparams\nK(1)\nt\n= 1 \u00b7 102\nK(2)\nt\n= 1 \u00b7 103\nC\u03b1 = 3 \u00b7 10\u22124\nC\u03b2 = 0.99\nC\u03b3 = 0.9\n\u00b5 = 0.999\nK(1)\nt\n= 2 \u00b7 102\nK(2)\nt\n= 2 \u00b7 103\nC\u03b1 = 2 \u00b7 10\u22124\nC\u03b2 = 0.999\nC\u03b3 = 0.9\n\u00b5 = 0.999\nK(1)\nt\n= 2 \u00b7 102\nK(2)\nt\n= 2 \u00b7 103\nC\u03b1 = 3 \u00b7 10\u22124\nC\u03b2 = 0.999\nC\u03b3 = 1.0\n\u00b5 = 0.999\nTime\nelapsed\n0.037 sec/iter \u00d7 200 iters\n7.432 sec\n0.040 sec/iter \u00d7 300 iters\n11.972 sec\n0.042 sec/iter \u00d7 300 iters\n12.604 sec\nTable 2: Experimental settings for toy examples\nSpam\nNodal\nWaveform\nq(\u03f5)\nN (0, 100 \u00b7 I3\u00d73)\nN (0, 100 \u00b7 I3\u00d73)\nN (0, 100 \u00b7 I10\u00d710)\nq\u03b8(z|\u03f5)\nN(\u00b5\u03b81(\u03f5), L\u03b82LT\n\u03b82), z \u2208R3\nN(\u00b5\u03b81(\u03f5), L\u03b82LT\n\u03b82), z \u2208R6\nN(\u00b5\u03b81(\u03f5), L\u03b82LT\n\u03b82), z \u2208R22\n\u00b5\u03b81(\u03f5)\nHidden units: (200, 200)\nHidden activation: ReLU\nInitializer: Xavier_normal\nHidden units: (200, 200)\nHidden activation: ReLU\nInitializer: Xavier_normal\nHidden units: (200, 200)\nHidden activation: ReLU\nInitializer: Xavier_normal\nHyper\nparams\nK(1)\nt\n= 5 \u00b7 101\nK(2)\nt\n= 5 \u00b7 102\nC(\u03b81)\n\u03b1\n= 1.5 \u00b7 10\u22124\nC(\u03b82)\n\u03b1\n= 2 \u00b7 10\u22121\nC\u03b2 = 0.999\nC(\u03b81)\n\u03b3\n= 0.7\nC(\u03b82)\n\u03b3\n= 0.6\n\u00b5 = 0.999\nK(1)\nt\n= 2 \u00b7 102\nK(2)\nt\n= 2 \u00b7 103\nC(\u03b81)\n\u03b1\n= 1.7 \u00b7 10\u22124\nC(\u03b82)\n\u03b1\n= 1.7 \u00b7 10\u22124\nC\u03b2 = 0.99\nC(\u03b81)\n\u03b3\n= 0.75\nC(\u03b82)\n\u03b3\n= 0.85\n\u00b5 = 0.999\nK(1)\nt\n= 1 \u00b7 102\nK(2)\nt\n= 1 \u00b7 103\nC(\u03b81)\n\u03b1\n= 3 \u00b7 10\u22124\nC(\u03b82)\n\u03b1\n= 2.5 \u00b7 10\u22124\nC\u03b2 = 0.999\nC(\u03b81)\n\u03b3\n= 0.85\nC(\u03b82)\n\u03b3\n= 0.85\n\u00b5 = 0.999\nTime\nelapsed\n0.024 sec/iter \u00d7 600 iters\n14.180 sec\n0.015 sec/iter \u00d7 600 iters\n8.986 sec\n0.015 sec/iter \u00d7 3000 iters\n45.761 sec\nTable 3: Experimental settings for Bayesian logistic regression\nTable 3: Experimental settings for Bayesian logistic regression\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b33f/b33fbbe6-6c1c-4a8e-a519-d4ad65e70372.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3: Boxplot of marginal posteriors (left) and marginal & pairwise joint-posteriors (right) using MCMC, CIVI and MFVB on Spam data-set (top row) and Nodal data-set (bottom row). On the right (grid plots), MCMC is blue, CIVI is green and MFVB is orange.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2ca0/2ca08eab-c96b-449b-b9d3-6597cd81c702.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Boxplot of marginal posteriors using MCMC, CIVI and MFVB on Waveform data-set.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b0ea/b0ea820c-62f5-4da7-b421-90c972f8c7a5.png\" style=\"width: 50%;\"></div>\nFigure 5: Marginal posteriors and pairwise joint-posteriors using MCMC, CIVI and MFVB on Waveform dataset. MCMC is blue, CIVI is green and MFVB is orange.\nFigure 5: Marginal posteriors and pairwise joint-posteriors using MCMC, CIVI and MFVB on Waveform dataset. MCMC is blue, CIVI is green and MFVB is orange.\nMNIST\nFasionMNIST\nPBT\nq(\u03f5)\nN (0, I10\u00d710)\nN (0, I10\u00d710)\nN (0, I10\u00d710)\nq\u03b8(z|\u03f5, xi)\nN(\u00b5\u03b81(\u03f5, xi), diag(\u03b82))\nz \u2208R10\nN(\u00b5\u03b81(\u03f5, xi), diag(\u03b82))\nz \u2208R10\nN(\u00b5\u03b81(\u03f5, xi), diag(\u03b82))\nz \u2208R20\n\u00b5\u03b81(\u03f5, xi)\nHidden units: (200, 200)\nHidden activation: ReLU\nInitializer: Xavier_normal\nHidden units: (200, 200)\nHidden activation: ReLU\nInitializer: Xavier_normal\nEmbedding dim: 256\nLSTM hidden dim: 256\nMLP hidden dim: 256\nMLP activation: ReLU\np\u02c6\u03b8(xi|z)\n\ufffdD\ni=1 Bernoulli[\u03c0\u02c6\u03b8(z)]\n\ufffdD\ni=1 Bernoulli[\u03c0\u02c6\u03b8(z)]\n\ufffdD\ni=1 Categorical[\u03c0\u02c6\u03b8(z)]\n\u03c0\u02c6\u03b8(z)\nHidden units: (200, 200)\nHidden activation: ReLU\nInitializer: Xavier_normal\nHidden units: (200, 200)\nHidden activation: ReLU\nInitializer: Xavier_normal\nEmbedding dim: 256\nLSTM hidden dim: 256\nHyper\nparams\nK(1)\nt\n= 300\nK(2)\nt\n= 30\nC(\u03b81)\n\u03b1\n= 1 \u00b7 10\u22125\nC(\u03b82)\n\u03b1\n= 1 \u00b7 10\u22124\nC(\u02c6\u03b8)\n\u03b1\n= 5 \u00b7 10\u22124\nC\u03b2 = 0.999\nC(\u03b81)\n\u03b3\n= 0.2\nC(\u03b82)\n\u03b3\n= 0.2\nC(\u02c6\u03b8)\n\u03b3\n= 0.2\n\u00b5 = 0.999\nK(1)\nt\n= 300\nK(2)\nt\n= 30\nC(\u03b81)\n\u03b1\n= 1 \u00b7 10\u22125\nC(\u03b82)\n\u03b1\n= 1 \u00b7 10\u22124\nC(\u02c6\u03b8)\n\u03b1\n= 5 \u00b7 10\u22124\nC\u03b2 = 0.999\nC(\u03b81)\n\u03b3\n= 0.2\nC(\u03b82)\n\u03b3\n= 0.2\nC(\u02c6\u03b8)\n\u03b3\n= 0.2\n\u00b5 = 0.999\nK(1)\nt\n= 320\nK(2)\nt\n= 100\nC(\u03b81)\n\u03b1\n= 2 \u00b7 10\u22124\nC(\u03b82)\n\u03b1\n= 2 \u00b7 10\u22124\nC(\u02c6\u03b8)\n\u03b1\n= 5 \u00b7 10\u22124\nC\u03b2 = 0.99\nC(\u03b81)\n\u03b3\n= 0.1\nC(\u03b82)\n\u03b3\n= 0.1\nC(\u02c6\u03b8)\n\u03b3\n= 0.1\n\u00b5 = 0.999\nTime\nelapsed\n0.0218 sec/iter \u00d7 18000 iters\n392 sec\n0.0236 sec/iter \u00d7 18000 iters\n425 sec\n0.0989 sec/iter \u00d7 40000 iters\n3956 sec\nTable 4: Experimental settings for variational autoencoder.\nTable 4: Experimental settings for variational autoencoder.\nMethod\nTime (ms) per iteration\nSIVI\n155\nUIVI\n69\nASCPG\n157\nSCGD\n152\nCI-VI [this paper]\n56\n: Average time per iteration for training VAE on Intel i9-9900X\nverage time per iteration for training VAE on Intel i9-9900X 3.50GHz C\n# C Detailed Descriptions of Assumptions\nDue to the lack of space, we provide more detailed description of all assumptions required to establish theoretical convergence results for the proposed CI-VI Algorithm in this section. Recall, we target the following nested optimisation problem:\nue to the lack of space, we provide more detailed description of all assumptions required to establish heoretical convergence results for the proposed CI-VI Algorithm in this section.\nmin \u03b8\u2208Rp L(\u03b8) = E\u03bd [f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b8)])] re for any \u03bd, \u02c6\u03f5 we have f\u03bd(\u00b7) : Rn \u2192R and g\u02c6\u03f5(\u00b7) : Rp \u2192Rn and random e unknown distributions \u03bd \u223cp\u03bd(\u00b7) and \u02c6\u03f5 \u223cp\u02c6\u03f5(\u00b7) correspondingly. Ple ume that these distributions are independent. For brevity, let us denote f ) = E\u02c6\u03f5[g\u02c6\u03f5(\u03b8)], then it is easy to see: L(\u03b8) = f(g(\u03b8)), \u2207L(\u03b8) = E\u02c6\u03f5[\u2207g\u02c6\u03f5(\u03b8)T]E\u03bd[\u2207f\u03bd(E\u02c6\u03f5[g\u02c6\u03f5(\u03b8)])] = \u2207g(\u03b8)T\u2207f( the following assumption holds: umption 1: 1. Function f\u03bd(\u00b7) is bounded, i.e.\u2200y \u2208Rn: |f\u03bd(y)| \u2264Bf. for any v. 2. Function f\u03bd(\u00b7) is Lf\u2212smooth. i.e.\u2200y1, y2 \u2208Rn: ||\u2207f\u03bd(y1) \u2212\u2207f\u03bd(y2)||2 \u2264Lf||y1 \u2212y2||2. for any v. 3. Function f\u03bd(\u00b7) has bounded gradient, i.e \u2200y \u2208Rn: ||\u2207f\u03bd(y)||2 \u2264Mf. for any v. 4. Mapping g\u02c6\u03f5(\u03b8) is Mg Lipschitz continuous, i.e. \u2200\u03b8, z \u2208Rp: ||g\u02c6\u03f5(\u03b8) \u2212g\u02c6\u03f5(z)||2 \u2264Mg||\u03b8 \u2212z||2. for any \u02c6\u03f5. 5. Mapping g\u02c6\u03f5(\u03b8) is Lg\u2212smooth. i.e.\u2200\u03b8, z \u2208Rp: ||\u2207g\u02c6\u03f5(\u03b8) \u2212\u2207g\u02c6\u03f5(z)||2 \u2264Lg||\u03b8 \u2212z||2. for any \u02c6\u03f5. ause distributions \u03bd \u223cp\u03bd(\u00b7) and \u02c6\u03f5 \u223cp\u02c6\u03f5(\u00b7) are unknown, we assume the er oracles FOOf and FOOg, such that given fixed vectors zt \u2208Rp,  mbers K(1) t and K(2) t at time step t they return the following collections:\nwhere for any \u03bd, \u02c6\u03f5 we have f\u03bd(\u00b7) : Rn \u2192R and g\u02c6\u03f5(\u00b7) : Rp \u2192Rn and random variables \u03bd, \u02c6\u03f5 follow some unknown distributions \u03bd \u223cp\u03bd(\u00b7) and \u02c6\u03f5 \u223cp\u02c6\u03f5(\u00b7) correspondingly. Please notice, we do not assume that these distributions are independent. For brevity, let us denote f(y) = E\u03bd[f\u03bd(y)] and g(\u03b8) = E\u02c6\u03f5[g\u02c6\u03f5(\u03b8)], then it is easy to see: L(\u03b8) = f(g(\u03b8)), \u2207L(\u03b8) = E\u02c6\u03f5[\u2207g\u02c6\u03f5(\u03b8)T]E\u03bd[\u2207f\u03bd(E\u02c6\u03f5[g\u02c6\u03f5(\u03b8)])] = \u2207g(\u03b8)T\u2207f(g(\u03b8)).\nLet the following assumption holds:\n# Assumption 1:\n1. Function f\u03bd(\u00b7) is bounded, i.e.\u2200y \u2208Rn:\n|f\u03bd(y)| \u2264Bf.\n  ||\u2207f\u03bd(y1) \u2212\u2207f\u03bd(y2)||2 \u2264Lf||y1 \u2212y2||2.\n4. Mapping g\u02c6\u03f5(\u03b8) is Mg Lipschitz continuous, i.e. \u2200\u03b8, z \u2208Rp: ||g\u02c6\u03f5(\u03b8) \u2212g\u02c6\u03f5(z)||2 \u2264Mg||\u03b8 \u2212z||2.\nfor any \u02c6\u03f5.\n5. Mapping g\u02c6\u03f5(\u03b8) is Lg\u2212smooth. i.e.\u2200\u03b8, z \u2208Rp:\n||\u2207g\u02c6\u03f5(\u03b8) \u2212\u2207g\u02c6\u03f5(z)||2 \u2264Lg||\u03b8 \u2212z||2.\nfor any \u02c6\u03f5.\nBecause distributions \u03bd \u223cp\u03bd(\u00b7) and \u02c6\u03f5 \u223cp\u02c6\u03f5(\u00b7) are unknown, we assume the presence of two first order oracles FOOf and FOOg, such that given fixed vectors zt \u2208Rp, yt \u2208Rn and integer numbers K(1) t and K(2) t at time step t they return the following collections:\nFOOf[yt, K(1) t ] = {\u03bdta, \u2207f\u03bdta (yt)}K(1) t a=1 , where {\u03bdta}K(1) t a=1 are i.i.d FOOg[zt, K(2) t ] = {\u02c6\u03f5ta, g\u02c6\u03f5ta (zt), \u2207g\u02c6\u03f5ta (zt)}K(2) t a=1 , where {\u02c6\u03f5ta}K(2) t a=1 are i.i.d\nThe complexity of the proposed algorithm will be evaluated in terms of total number of calls to fir order oracles FOOf[\u00b7, \u00b7], FOOg[\u00b7, \u00b7].\nAssumption 2: At any given time step t, the oracles FOOf[y]t and FOOg[z]t satisfy the following two conditions for any z \u2208Rp and y \u2208Rn:\n(7)\n(8)\n\ufffd {\u03bd1a} K(1) 1 a=1 , {\u02c6\u03f51a} K(2) 1 a=1 \ufffd , \ufffd {\u03bd2a} K(1) 2 a=1 , {\u02c6\u03f52a} K(2) 2 a=1 \ufffd , . . . , \ufffd {\u03bdta}K(1) t a=1 , {\u02c6\u03f5ta}K(2) t a=1 \ufffd\nare independent. 2. Unbiased estimates: for any \u03b8 \u2208Rp, y \u2208Rn:\n2. Unbiased estimates: for any \u03b8 \u2208Rp, y \u2208Rn:\n\ufffd \ufffd \ufffd \ufffd for any t and a \u2208[1, . . . , K(2) t ], b \u2208[1, . . . , K(1) t ]. 3. Bounded variance of stochastic gradients: for any \u03b8 \u2208Rp, y \u2208Rn:\n\ufffd for any t and a \u2208[1, . . . , K(2) t ], b \u2208[1, . . . , K(1) t ].\n# D Theoretical Guarantees\nIn this section, we establish all theoretical results needed for proving the main theorem and then present its proof.\n# D.1 L-smoothness of function L(\u00b7)\nOur first result provides the important property of the overall compositional function L(\u00b7) which will be used later in the convergence analysis of the proposed CI-VI Algorithm. Lemma: Let Assumptions 1 and 2 hold, then function L(\u00b7) is L\u2212Lipschitz smooth, i,e: ||\u2207L(\u03b81) \u2212\u2207L(\u03b82)||2 \u2264L||\u03b81 \u2212\u03b82||2 \u2200\u03b81, \u03b82 \u2208Rp (9) with L = M 2 g Lf + LgMf.\nwith L = M 2 g Lf + LgMf.\nProof. Assumption 1 implies that ||\u2207g\u02c6\u03f5(\u03b8)||2 \u2264Mg for any \u03b8 \u2208Rp. Hence, using Jensen inequality as well as property of the norm we have:\n||\u2207L(\u03b81) \u2212\u2207L(\u03b82)||2 = ||E\u02c6\u03f5 \ufffd \u2207gT \u02c6\u03f5 (\u03b81) \ufffd E\u03bd [\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b81)])] \u2212E\u02c6\u03f5 \ufffd \u2207gT \u02c6\u03f5 (x2) \ufffd E\u03bd [\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b82)])] ||2 \u2264 ||E\u02c6\u03f5 \ufffd \u2207gT \u02c6\u03f5 (\u03b81) \ufffd E\u03bd [\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b81)])] \u2212E\u02c6\u03f5 \ufffd \u2207gT \u02c6\u03f5 (\u03b81) \ufffd E\u03bd [\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b82)])] ||2+ ||E\u02c6\u03f5 \ufffd \u2207gT \u02c6\u03f5 (\u03b81) \ufffd E\u03bd [\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b82)])] \u2212E\u02c6\u03f5 \ufffd \u2207gT \u02c6\u03f5 (x2) \ufffd E\u03bd [\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b82)])] ||2 \u2264 E\u02c6\u03f5 \ufffd ||\u2207gT \u02c6\u03f5 (\u03b81)||2 \ufffd ||E\u03bd [\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b81)])] \u2212E\u03bd [\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b82)])] ||2+ ||E\u02c6\u03f5 \ufffd \u2207gT \u02c6\u03f5 (\u03b81) \ufffd \u2212E\u02c6\u03f5 \ufffd \u2207gT \u02c6\u03f5 (x2) \ufffd ||2E\u03bd [||\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b82)]) ||2] \u2264 MgE\u03bd [||\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b81)]) \u2212\u2207f\u03bd (E\u02c6\u03f5 [g\u02c6\u03f5(\u03b82)]) ||2] + MfE\u02c6\u03f5 \ufffd ||\u2207gT \u02c6\u03f5 (\u03b81) \u2212\u2207gT \u02c6\u03f5 (\u03b82)||2 \ufffd \u2264MgLf||E\u02c6\u03f5 [g\u02c6\u03f5(\u03b81)] \u2212E\u02c6\u03f5 [g\u02c6\u03f5(\u03b82)] ||2+ MfE\u02c6\u03f5 \ufffd ||\u2207gT \u02c6\u03f5 (\u03b81) \u2212\u2207gT \u02c6\u03f5 (\u03b82)||2 \ufffd \u2264MgLfE\u02c6\u03f5 [||g\u02c6\u03f5(\u03b81) \u2212g\u02c6\u03f5(\u03b82)||2] + MfE\u02c6\u03f5 \ufffd ||\u2207gT \u02c6\u03f5 (\u03b81) \u2212\u2207gT \u02c6\u03f5 (\u03b82)||2 \ufffd \u2264MgLfE\u02c6\u03f5 [||g\u02c6\u03f5(\u03b81) \u2212g\u02c6\u03f5(\u03b82)||2] + MfLg||\u03b81 \u2212\u03b82||2 \u2264 M 2 g Lf||\u03b81 \u2212\u03b82||2 + MfLg||\u03b81 \u2212\u03b82||2 = \ufffd M 2 g Lf + MfLg \ufffd ||\u03b81 \u2212\u03b82||2 = L||\u03b81 \u2212\u03b8",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of semi-implicit variational inference (SIVI), which has been limited by previous methods that either require analytical probability density functions or are computationally expensive in high-dimensional settings. The need for an efficient solver for models supporting semi-implicit variational family distributions remains an open problem, which this paper aims to address with the introduction of CI-VI, a new method that optimizes SIVI's evidence lower bound (ELBO) and provides theoretical guarantees for convergence.",
        "problem": {
            "definition": "The problem this paper aims to solve is the inefficiency of existing solvers for semi-implicit variational inference, particularly in high-dimensional scenarios where traditional methods become computationally expensive.",
            "key obstacle": "The core obstacle preventing existing methods from effectively solving the problem is the bias introduced by non-linear nested expectations in the optimization process, which complicates the estimation of gradients and leads to high variance in the results."
        },
        "idea": {
            "intuition": "The intuition behind the proposed idea is to reformulate the optimization problem of SIVI as a compositional optimization problem, which can be approached more effectively using techniques from stochastic optimization.",
            "opinion": "The proposed idea involves developing an efficient solver, CI-VI, that utilizes an extrapolation-smoothing mechanism and gradient sketching to handle bias and improve computational efficiency in high-dimensional settings.",
            "innovation": "The primary innovation of CI-VI lies in its ability to handle the bias from non-linear nested expectations through a novel combination of extrapolation-smoothing and gradient sketching, which distinguishes it from existing methods."
        },
        "method": {
            "method name": "Compositional Implicit Variational Inference (CI-VI)",
            "method abbreviation": "CI-VI",
            "method definition": "CI-VI is an adaptive solver for semi-implicit variational inference that reformulates the ELBO into a compositional form and applies techniques to reduce bias and improve scalability.",
            "method description": "CI-VI combines extrapolation-smoothing and gradient sketching to efficiently optimize the evidence lower bound of semi-implicit variational inference.",
            "method steps": [
                "Define the semi-implicit variational distribution and its parameters.",
                "Reformulate the SIVI optimization problem into a compositional form.",
                "Implement the CI-VI algorithm using an adaptive scheme that incorporates bias reduction techniques."
            ],
            "principle": "The effectiveness of CI-VI in solving the problem is based on its ability to manage the bias introduced by non-linear nested expectations, allowing for more stable and efficient convergence in high-dimensional settings."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted on various datasets, including those from natural language processing, comparing CI-VI against standard semi-implicit variational inference algorithms and other optimization methods.",
            "evaluation method": "The performance of CI-VI was assessed through empirical studies that measured its ability to approximate complex posteriors and its efficiency in terms of computational time and convergence rates."
        },
        "conclusion": "The experiments demonstrated that CI-VI outperforms existing algorithms in approximating complex posteriors and is highly efficient, making it a significant contribution to the field of semi-implicit variational inference.",
        "discussion": {
            "advantage": "CI-VI's key advantages include its efficiency in high-dimensional scenarios and its ability to effectively handle the bias from non-linear nested expectations, leading to improved convergence rates compared to existing methods.",
            "limitation": "One limitation of CI-VI is that while it performs well in many scenarios, it may still face challenges in extremely high-dimensional problems or in cases where the assumptions about the variational distribution do not hold.",
            "future work": "Future research will focus on scaling CI-VI to dialogue problems in natural language processing and extending its applications to time-series models, as well as exploring the broader implications of its theoretical results."
        },
        "other info": {
            "authors": [
                {
                    "name": "Vincent Moens",
                    "affiliation": "Huawei R&D UK",
                    "email": "vincent.moens@huawei.com"
                },
                {
                    "name": "Hang Ren",
                    "affiliation": "Huawei R&D UK",
                    "email": "hang.ren1@huawei.com"
                },
                {
                    "name": "Alexandre Maraval",
                    "affiliation": "Huawei R&D UK",
                    "email": "alexandre.maravel@huawei.com"
                },
                {
                    "name": "Rasul Tutunov",
                    "affiliation": "Huawei R&D UK",
                    "email": "rasul.tutunov@huawei.com"
                },
                {
                    "name": "Jun Wang",
                    "affiliation": "Huawei R&D UK, University College London",
                    "email": "w.j@huawei.com"
                },
                {
                    "name": "Haitham Ammar",
                    "affiliation": "Huawei R&D UK, University College London",
                    "email": "haitham.ammar@huawei.com"
                }
            ]
        }
    },
    "mount_outline": [
        {
            "section number": "3",
            "key information": "This paper addresses the issue of semi-implicit variational inference (SIVI), which has been limited by previous methods that either require analytical probability density functions or are computationally expensive in high-dimensional settings."
        },
        {
            "section number": "3.1",
            "key information": "The primary innovation of CI-VI lies in its ability to handle the bias from non-linear nested expectations through a novel combination of extrapolation-smoothing and gradient sketching, which distinguishes it from existing methods."
        },
        {
            "section number": "3.2",
            "key information": "The experiments were conducted on various datasets, including those from natural language processing, comparing CI-VI against standard semi-implicit variational inference algorithms and other optimization methods."
        },
        {
            "section number": "3.3",
            "key information": "One limitation of CI-VI is that while it performs well in many scenarios, it may still face challenges in extremely high-dimensional problems or in cases where the assumptions about the variational distribution do not hold."
        },
        {
            "section number": "8.3",
            "key information": "Future research will focus on scaling CI-VI to dialogue problems in natural language processing and extending its applications to time-series models, as well as exploring the broader implications of its theoretical results."
        }
    ],
    "similarity_score": 0.5243283262840738,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-14-1730_natur/papers/Efficient Semi-Implicit Variational Inference.json"
}