{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2410.17448",
    "title": "In Context Learning and Reasoning for Symbolic Regression with Large Language Models",
    "abstract": "Large Language Models (LLMs) are transformer-based machine learning models that have shown remarkable performance in tasks for which they were not explicitly trained. Here, we explore the potential of LLMs to perform symbolic regression \u2014 a machine-learning method for finding simple and accurate equations from datasets. We prompt GPT-4 to suggest expressions from data, which are then optimized and evaluated using external Python tools. These results are fed back to GPT-4, which proposes improved expressions while optimizing for complexity and loss. Using chain-ofthought prompting, we instruct GPT-4 to analyze the data, prior expressions, and the scientific context (expressed in natural language) for each problem before generating new expressions. We evaluated the workflow in rediscovery of five well-known scientific equations from experimental data, and on an additional dataset without a known equation. GPT-4 successfully rediscovered all five equations, and in general, performed better when prompted to use a scratchpad and consider scientific context. We also demonstrate how strategic prompting improves the model\u2019s performance and how the natural language interface simplifies integrating theory with data. Although this approach does not outperform established SR programs where target equations are more complex, LLMs can nonetheless iterate toward improved solutions while following instructions and incorporating scientific context in natural language.",
    "bib_name": "sharlin2024contextlearningreasoningsymbolic",
    "md_text": "# IN CONTEXT LEARNING AND REASONING FOR SYMBOLIC REGRESSION WITH LARGE LANGUAGE MODELS\nSamiha Sharlin1 and Tyler R. Josephson1,2\nepartment of Chemical, Biochemical, and Environmental Engineering, University of Maryland Baltimore Coun 1000 Hilltop Circle, Baltimore, MD 21250 2Department of Computer Science and Electrical Engineering, University of Maryland Baltimore County, 1000 Hilltop Circle, Baltimore, MD 21250\n# ABSTRACT\nLarge Language Models (LLMs) are transformer-based machine learning models that have shown remarkable performance in tasks for which they were not explicitly trained. Here, we explore the potential of LLMs to perform symbolic regression \u2014 a machine-learning method for finding simple and accurate equations from datasets. We prompt GPT-4 to suggest expressions from data, which are then optimized and evaluated using external Python tools. These results are fed back to GPT-4, which proposes improved expressions while optimizing for complexity and loss. Using chain-ofthought prompting, we instruct GPT-4 to analyze the data, prior expressions, and the scientific context (expressed in natural language) for each problem before generating new expressions. We evaluated the workflow in rediscovery of five well-known scientific equations from experimental data, and on an additional dataset without a known equation. GPT-4 successfully rediscovered all five equations, and in general, performed better when prompted to use a scratchpad and consider scientific context. We also demonstrate how strategic prompting improves the model\u2019s performance and how the natural language interface simplifies integrating theory with data. Although this approach does not outperform established SR programs where target equations are more complex, LLMs can nonetheless iterate toward improved solutions while following instructions and incorporating scientific context in natural language.\narXiv:2410.17448v1\n# 1 Introduction\nData analysis is ubiquitous in all disciplines, where identifying correlations between variables is key to finding insights, informing conclusions, supporting hypotheses, or developing a new theory. For scientific data, we often aim to find expressions with few adjustable parameters explaining the data while ensuring that they align with theory. Symbolic regression is a machine learning technique that approaches equation-based scientific discovery \u2013 given a dataset, it searches through some \u201cspace of possible equations\u201d and identifies those that balance accuracy and simplicity. It is different from conventional regression methods, as symbolic regression infers the model structure from data rather than having a predetermined model structure. Mathematically, symbolic regression is formulated as some form of optimization, not just of the constants in an equation, but as a search through \u201cequation space\" for optimal expressions. In this way, symbolic regression is a form of machine learning \u2013 as data is received, an internal model is updated to match the data; when the model fits the data well and can make predictions about unseen data, the algorithm is said to have \u201clearned\" the underlying patterns in the data. In contrast to popular machine learning algorithms like neural networks, symbolic regression does not just only fit the constants in an equation but also finds functional forms that match the data.\nSymbolic regression methods mainly use genetic algorithms [1\u20134] that generate random expressions from data, optimize their parameters, and evaluate their fitness with respect to the data through an iterative process until a fitness level or a specific number of iterations is reached. Other approaches include using Markov chain Monte Carlo (MCMC) sampling [5,6], mixed integer nonlinear programming [7\u20139], greedy tree searches [10], pre-trained transformer-based models [11, 12], and sparse matrix algorithms [13\u201315]. These techniques are broadly geared towards accelerating equation search or efficient multi-objective optimization, but they do not integrate reasoning. Researchers have long explored ways to make these algorithms more informed by guiding the search space based on the context of the data [6,9,16\u201328], including using large language models integrated with genetic algorithms [29]. As scientific data is strongly tied to theory, encoding them in the program narrows the vast search space and can make the programs more effective. This work explores an approach to symbolic regression using large language models (LLMs) for equation discovery. LLMs are machine learning models adept at understanding and generating natural language. At its core, an LLM uses the transformer architecture\u2014a neural network developed by Google that scales very effectively and allows the training of models on massive datasets [30]. The term \u201clarge\" in the language model refers to the size and intricacy of the network, along with the dataset on which it was trained. Prior to GPT-3, natural language processing (NLP) tasks were solved by pretraining language models on vast text datasets and fine-tuning them for specific tasks. However, GPT-3 demonstrated that language models can excel at tasks using in-context learning without necessitating fine-tuning [31,32]. LLMs are now commonly used for tasks like chat, code generation, summarization, translation, etc. \u2212and quite remarkably, these tasks can be effectively accomplished by using English language as model input without the need for machine learning expertise. We have firsthand experience with these models\u2019 capabilities by interacting with AI chatbots on platforms like ChatGPT, Claude, or Gemini. LLMs have a wide understanding of the world from their training data and can even solve simple math problems expressed in natural language [33\u201335]. They are contributing significantly in education and research [36\u201339] medicine [40,41], physical and social sciences [42\u201344], as well as in legal [45,46], business [47,48], and entertainment [49\u201352] sectors. Existing transformer-based symbolic regression programs [11, 12, 53] use models pretrained on large databases of synthetically-generated dataset/expression pairs, designed specifically for symbolic regression tasks. Thus, these approaches learn to pattern-match between datasets and math expressions, but they don\u2019t employ iterations like those in genetic programming that optimize expressions for complexity and loss. In that respect, LLMs have been used to imitate evolutionary algorithms (EA) [54\u201360], and have specifically been applied to solve symbolic regression (SR) problems [56,59]. Meyerson and coworkers [56] developed a workflow that performs genetic programming (mutation, crossover, etc.) through prompts in LLMs and tested symbolic regression in two ways: first, by using a language model in all evolutionary operators except the fitness measure, and second, by only using a language model in the initialization, crossover, and mutation operators. The second approach more closely resembles our work, but what we do is even simpler: we task GPT-4 to generate and/or transform expressions freely. Furthermore, while these approaches leverage \u201cin-context\u201d learning and don\u2019t require pretraining [56,59], the context employed is limited to a list of previously-obtained expressions. We propose to expand the context to include data, as well natural language descriptions of the scientific context of the problem. To effectively use this context, we anticipate that the LLM will perform better if given time for analysis [61\u201363]. Therefore, we also incorporate zero-shot chain-of-thought prompting with a scratchpad [64] to frame equation generation for symbolic regression as a reasoning problem [65] in the context of the data and free-form scientific information. Symbolic regression requires equation generation and precise fitting of numerical constants. Yang and coworkers [66] show that LLMs can perform linear regression, optimizing constants in math expressions via feedback loops, without showing the LLM the analytical form. They find that \u201cLLM can often calculate the solution directly from the analytic form,\" however we find LLMs to be unreliable and inefficient for such tasks. Consequently, we interleave LLM-based optimization with gradient-based optimization, following a similar approach as [58], iteratively refining prompts for more accurate output. In our work, an LLM guides optimization of the symbolic structure of the math expressions, while SciPy performs numerical optimization of the constants. This work aligns closely with two recent works [67,68] in the literature in terms of methodology in that LLMs were used to generate expressions, and iterations were performed separately for optimization. Although there are some variations in the workflow and significant differences in the explored datasets, the unique contribution of this work lies in using data and context in natural language as model input, and implementing a scratchpad to record model output, which can help reveal if there was a case of \u201ctest set leakage.\u201d Merler and coworkers [67] used multimodal LLMs with image and text inputs (without context and/or scratchpad), but their benchmark datasets does not reflect scientific data. Conversely, Shojaee and coworkers [68] specifically focused on scientific problems (without data and/or scratchpad), and while their expression generation utilized cleaner Python functions it is difficult to evaluate if GPT-4 has encountered these questions as they do not include data but present the task as a problem similar to college homework assignments.\nThis work aligns closely with two recent works [67,68] in the literature in terms of methodology in that LLMs were used to generate expressions, and iterations were performed separately for optimization. Although there are some variations in the workflow and significant differences in the explored datasets, the unique contribution of this work lies in using data and context in natural language as model input, and implementing a scratchpad to record model output, which can help reveal if there was a case of \u201ctest set leakage.\u201d Merler and coworkers [67] used multimodal LLMs with image and text inputs (without context and/or scratchpad), but their benchmark datasets does not reflect scientific data. Conversely, Shojaee and coworkers [68] specifically focused on scientific problems (without data and/or scratchpad), and while their expression generation utilized cleaner Python functions it is difficult to evaluate if GPT-4 has encountered these questions as they do not include data but present the task as a problem similar to college homework assignments.\n# 2 Methods\n# Preliminary tests\nIn our initial tests, we asked GPT-4 to generate mathematical expressions from scientific data. We used a simple promp to assess its capability and tested GPT-3.5-turbo and GPT-4 at varying temperatures (Figures 1). In all cases, the models produced expressions while \u201challucinating\u201d arbitrary coefficients. We revised the prompts to ask the LLMs to \u201cshow al steps\" to gain insight into how the model selects these values [63]. In response, the output either provided Python code for optimization or, at times, mathematical steps for optimization.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ea23/ea23a1ba-d905-4d50-a136-7fa3d638006e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\nFigure 1: Illustration of GPT-4 attempting symbolic regression. GPT-4 predicts expressions with optimized coefficients when passed a dataset for nitrogen adsorption on mica [69]. The Python code snippet from Prompt 2 output has been truncated to keep the figure concise. Note that the actual parameter values produced by running the code differ from what GPT-4 generates. Figure 10 in SI shows the output from GPT-3.5 turbo which produces similar results. Although the generated code accurately performed curve-fitting, the LLM hallucinated incorrect coefficients. Nonetheless, the generated remarks about the data patterns hinted that they may have the potential to generate accurate functional forms that can be optimized outside the LLM.\nAlthough the generated code accurately performed curve-fitting, the LLM hallucinated incorrect coefficients. Nonetheless, the generated remarks about the data patterns hinted that they may have the potential to generate accurate functional forms that can be optimized outside the LLM.\n# System design\nTherefore, we designed a workflow (Figure 2) where we task GPT-4 with suggesting expressions without fitting constants, and subsequently, we optimize the coefficients of the expressions using SciPy outside the LLM. A Python class takes in expressions, optimizes them, then calculates their complexity and mean squared error (MSE). These results are stored as a dictionary, the text of which is passed back to GPT-4 in a subsequent prompt asking to suggest better expressions. We initially evaluated GPT-3.5-turbo, but found it less reliable in following instructions than GPT-4, more frequently generating expressions that didn\u2019t parse.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/eead/eeadbe3a-06e4-42e7-88cf-fb266a6fc5ca.png\" style=\"width: 50%;\"></div>\nWe use two prompts: 1) Initial Prompt - where we input data and ask GPT-4 to suggest expressions, and 2) Iteration Prompt - where, along with data, we provide feedback in JSON format. We sort the expressions in descending order of mean squared error, then share this list as feedback, asking GPT-4 to suggest new equations optimizing for complexity and loss. In addition to this, we also include a system message to guide the behavior of the language model, setting the tone of the conversation. We do not use chat history or any advanced forms of memory [72\u201375] in this workflow. The history of generated expressions is maintained externally and provided as feedback in the iteration prompt. A Python function maintains this feedback loop by sorting and filtering a list of dictionaries based on MSE and complexity. At the start of the search, up to 6 expressions are always returned; later, the least accurate expressions that are not on the Pareto front are pruned in order to manage the length of the context window. By making each call to GPT-4 independent, we aim to minimize hallucinations that have been observed when the chat history becomes too large in conversational models [76,77], as well as manage cost by pruning the large quantity of generated scratchpad text. We can get the most out of an LLM by providing strategic text in the prompt. Prompt engineering is an art that involves structuring prompts that guide the model toward generating desired outputs. However, there is no one-size-fits-all method for crafting optimal prompts, as outcomes depend on the specific task and model. Even minor changes in wording or structure can influence the model\u2019s output. Various prompting guidelines have been explored in the literature [78\u201381], including providing clear instructions, emphasizing relevant context using text delimiters, breaking tasks into multiple steps, and incorporating problem-solving conditions. We implemented strategies like incorporating examples and a scratch pad and subsequently refined the prompts.\n# Prompt Engineering\nWe prototyped our system by testing its ability to rediscover the Langmuir adsorption isotherm (q = c1 \u2217p/(c2 + p)) from experimental data [69]. This enabled us to quickly identify major structural improvements to the workflow; we further tailored the prompts while testing on more difficult problems. Removing bias: We aimed to make the workflow run smoothly without any human intervention and therefore, it was important to obtain machine-readable and precise output from GPT-4 to ensure the SciPy function runs without any errors. A simple way to illustrate the expected outcome was by providing examples in a few-shot context [31,82]. While this led to expressions matching the required syntax, we noticed the generated expressions resembled the examples we provided (Figure 3). While this taught the LLM correct syntax, it introduced bias that severely compromised the search.\nWe prototyped our system by testing its ability to rediscover the Langmuir adsorption isotherm (q = c1 \u2217p/(c2 + p)) from experimental data [69]. This enabled us to quickly identify major structural improvements to the workflow; we further tailored the prompts while testing on more difficult problems.\nRemoving bias: We aimed to make the workflow run smoothly without any human intervention and therefore, it was important to obtain machine-readable and precise output from GPT-4 to ensure the SciPy function runs without any errors. A simple way to illustrate the expected outcome was by providing examples in a few-shot context [31,82]. While this led to expressions matching the required syntax, we noticed the generated expressions resembled the examples we provided (Figure 3). While this taught the LLM correct syntax, it introduced bias that severely compromised the search.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2ff7/2ff780c2-32d0-4725-80ea-3bff5cf456e5.png\" style=\"width: 50%;\"></div>\nThis motivated our two-prompt setup, with an initial prompt tasking GPT-4 to generate unbiased expressions in LaTeX (which it generated more reliably than as Python strings), and an iteration prompt receiving previously-generated examples as Python script (now without bias). To bridge these, we converted the LaTeX text into SciPy-compatible text using a Python function for string formatting, which we developed after identifying the types of expressions GPT-4 was prone to generating. Although this approach did not completely resolve syntax errors, it effectively managed them for the GPT-4 model. Recording analysis in a scratchpad: Studies have shown that LLM performance can be improved by slowing down the model or breaking down its tasks into smaller steps [61,62]. One popular strategy is the \u201cscratch pad\" technique [64], which mimics how we solve problems by jotting down notes before presenting a final answer in exams. We implemented this in our workflow, instructing GPT-4 to generate responses in two parts: data analysis and observations in a scratch pad, followed by its conclusions. After implementing this technique, the model immediately generated higher-quality expressions (Figure 4).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c03e/c03ea43a-599d-402e-86e3-75998c353138.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) Effect of scratchpad on Langmuir Dataset</div>\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/50a5/50a5960f-ef9d-4fce-be4c-7981920e10ff.png\" style=\"width: 50%;\"></div>\nFigure 4: Illustration of scratchpad approach. We observe substantial, qualitative improvements in the predicted expressions after implementing the scratchpad technique (Prompt 2). The suggested expressions for (a) Langmuir\u2019s and (b) Kepler\u2019s Law dataset include operators (/ and sqrt, respectively) present in the target models (y = c1\u2217x c2+x and y2 = c1x 3 2 , respectively)\nPreventing redundant expressions: GPT-4 often generated expressions like x + c1 and x \u2212c1, implying they are different. However, since the constants are yet to be fitted, these expressions are the same from a symbolic regression perspective. While a computer algebra system like SymPy [83] could in principle catch some redundant expressions by simplification to a canonical form [6,28], this wouldn\u2019t distinguish \u201cSR-similar\" expressions that become equivalent after fitting constants. Instead, we used prompt engineering to guide generation toward unique expressions: we added a note in the iteration prompt with examples showing how expressions in symbolic regression are similar before parameters are optimized. While this didn\u2019t completely resolve the issue, we did observe a reduction in occurrences, and at times, the scratchpad revealed GPT-4 correctly addressing this by taking these examples into account (see Figure 5).\n\n\n\n\n# Figure 5: Illustration of GPT-4 outputs for SR-similar expressions.\nAvoiding uninteresting expressions: During the iterative runs, GPT-4 attempted to improve its accuracy by repeatedly adding linear terms to suggested expressions from previous iterations. To address this issue, we encouraged the model to explore diverse expressions in the prompt. Additionally, in cases involving datasets with multiple independent variables, GPT-4 sometimes recommended excluding variables that exhibited weak correlation with the overall dataset pattern. While this may be useful in some contexts, we wanted expressions that made use of all of the available data, so we explicitly instructed the use of all variables. Additional constraints we implemented included limiting the types of math operators to include and preventing generation of implicit functions, as shown in Figure 6. Consider scientific context: Our primary motivation for building this system was to test whether providing scientific context could shape the expressions generated by the LLM. SR programs often successfully generate expressions that fit the data well and are simple, yet they may not adhere to scientific principles or be otherwise \u201cmeaningful.\u201d Yet scientists often have valuable insights into their domain that extend beyond these constraints, and they may not always\n# \n\n# \n\nknow which specific expressions will best capture the nuances of their dataset or if entirely new expressions might be more effective. By incorporating scientific context, we aim to align the equation search to be consistent with scientific theories. Classical SR approaches always incorporate some amount of guidance from the practitioners (e.g. by limiting available math operators and variables and incorporating some bias toward parsimonious expressions); more recent work enables SR programs to explicitly account for limiting behavior (shape-constrained SR) and dimensional constraints [18,24,25,84\u201387]. Incorporating these into SR algorithms typically requires bespoke modification of research software; our strategy is to use LLM prompting in natural language to instill this context, which might additionally include more fluid constraints like \u201cgenerate diverse equations\" and \u201cconsider scientific context.\" For instance, the context we provide for Kepler\u2019s Law is a single line text stating, \u201cThe data is about planetary motion in astrophysics where the independent variable (x1) is semi-major axis, and the dependent variable (y) is period in days.\" Figure 11 in SI lists the context provided for all the datasets.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/daa6/daa6d40d-8fab-4a3b-8e0e-34dbaf4f9fc3.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9ac4/9ac4e9de-04ab-48bd-b02f-c5faca7fece0.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 6: Illustration of GPT-4 following restrictions from prompt.</div>\n# 3 Results\nWe evaluate our workflow using experimental datasets associated with meaningful scientific context. SR benchmarks often use synthetic data; we designed our tests around a benchmark [88] specifically curated for evaluating SR algorithms for scientific data. From here, we selected three experimental datasets from astronomical observations (Bode\u2019s Law, Hubble\u2019s Law, and Kepler\u2019s Law). To these, we added two experimental chemistry datasets: Langmuir and Dual-site Langmuir adsorption isotherm models [9].\nFigure 12 in SI illustrates all the datasets with the target expression for each. We also tested our workflow using a dataset on friction losses in pipe flow [89]. This phenomena doesn\u2019t have an established target model, and has been the subject of prior study by other SR programs [6]. We included the whole dataset for each problem in the prompt to GPT-4 at the start and in each iteration. Because the Hubble and Leavitt\u2019s datasets had an unreasonable number of digits following each entry, we rounded to 3 decimal places when sending data to GPT-4 but used the original dataset when optimizing constants in SciPy. This reduced the tokens (and cost) of running GPT-4. We pass the entire dataset SR is different than other machine learning models, as we feed the entire dataset for training where the test is the output expression [88]. We conducted eight sets of experiments on each of the six datasets, running each 5 times to evaluate robustness. In four of the experiments, we used basic binary operators (+, \u2212, \u2217, \u00f7), incorporating \u2018sqrt\u2019 for Kepler\u2019s data and \u2018\u02c6\u2019 and \u2018exp\u2019 for Bode\u2019s data. Empirical relations often involve field-specific operators, so the equation search should account for this. We refer to this set of tests as an \u201ceasy search\" because the space of possible equations is constrained to that generated by the operators in our dataset. In addition, we conducted four further tests adding common unary operators (sqrt, log, exp, square, cube) alongside the basic ones to evaluate a more difficult search. Temperature is a hyperparameter used in stochastic models like LLMs to regulate the randomness of the model output [90,91]. It adjusts the probabilities of the predicted words in the softmax output layer of the model. Lowering temperature favors words with higher probability, so when the model randomly samples the next word from the probability distribution, it will be more likely to choose a more predictable response. We tested the Langmuir dataset with five different temperature settings (0, 0.3, 0.5, 0.7, 1) and found 0.7 to be performing the best, which we later used for the rest of the datasets.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/739f/739f4c8b-2cf4-4208-a0ee-3315655d350e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5722/57222eab-9004-432e-89ed-31d7da999774.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 7: GPT-4 results on \u201ceasy\" and \u201chard\" searches. Easy search includes only basic operators while harder one adds more. All the datasets were run in four settings: without context, without data, without scratchpad and finally with all tools on. The score at each iteration is a total of x/5 independent runs where target model expressions were found. With these settings; dual-site Langmuir was never found after 50 iterations; with a modified feedback loop, it was only found 1/5 times in easy searches with and without tools.</div>\nFigure 7: GPT-4 results on \u201ceasy\" and \u201chard\" searches. Easy search includes only basic operators while harder one adds more. All the datasets were run in four settings: without context, without data, without scratchpad and finally with all tools on. The score at each iteration is a total of x/5 independent runs where target model expressions were found. With these settings; dual-site Langmuir was never found after 50 iterations; with a modified feedback loop, it was only found 1/5 times in easy searches with and without tools.\n<div style=\"text-align: center;\"></div>\nHubble: Hubble\u2019s Law is represented by the simple equation y = c1*x, which is often a first guess when few operators are made available. However, including context plays a role; this is especially apparent in the \u201chard\u201d search, where removing the scratchpad for reasoning or the context inhibited performance. This dataset is particularly noisy, as well; including the noisy data as context actually inhibits the search.\nBode: The results for Bode\u2019s Law indicate that, similar to other SR programs [88], GPT-4 encounters difficulty accurately rediscovering the target model expression. Curiously, it performs best when the context is excluded and worst when the data is excluded. This suggests that the context we provided was counterproductive for the search, and purely reasoning about the data led greater success. We also note that GPT-4 finds the target model as \u2014 c1 \u00d7exp(c2 \u00d7x1)+c3 when all operators are provided, which is a symbolically-equivalent way of expressing Bode\u2019s Law, though lacking the interpretability of the original form.\nKepler: We find strong evidence that the prompt has triggered GPT-4\u2019s memorization of Kepler\u2019s Law: the scratchpad reveals GPT-4 associates the variable names in the context with Kepler\u2019s Law, and it not only guesses the right answer in the first iteration, it names Kepler\u2019s Law in its justification. Perhaps because this relationship is routinely taught in high school and college physics courses, and thus likely to be more represented in GPT-4\u2019s training data than the other relationships. The hard search for Kepler\u2019s Law with all tools on has led GPT-4 to explore more complex expressions since the target model complexity is only 5 with MSE of 46.6886. GPT-4 also finds the target model in the form c1xc2 1 , with c2 left as a constant for optimization instead of 3 2. However, SciPy optimizes and fits c2 with to a floating point power (\u22481.5). We did not consider this to be a rediscovery of the target model as such expressions are not dimensionally consistent.\nLangmuir: Langmuir\u2019s model is more obscure, and was almost never guessed in the first round. In easier searches GPT-4 consistently found it within 15 iterations; inclusion of context and data seemed to improve performance. However the hard search was much more challenging, with Langmuir only discovered once, in the case with all tools on.\nDual-site Langmuir: The dual-site Langmuir model is particularly challenging for SR, because the target model does not significantly fit the data much better than many shorter expressions. In fact, GPT-4 found one expression that fits the data more accurately at complexity 11 (Figure 8). However extrapolation shows this model is not theoretically correct (Figure 13 in SI). This dataset was previously explored in literature [9,28] with three SR algorithms: Bayesian-based SR (BMS) [6], genetic programming-based SR (PySR) [88], and mixed-integer non-linear programming-based SR [92]. Because this expression is longer, we extended the run to 50 iterations, and dual-site Langmuir was still not found for any of the experimental settings with easy search. We modified the feedback loop passed into GPT-4 for this dataset to send more accurate and longer expressions in lieu of passing the entire Pareto front (keeping the top five expressions based on MSE in the loop). We found that when using basic operators and context, GPT-4 was getting close to finding the target model (Figure 8) upon running 15 iterations with this feedback loop. To investigate this further, we ran with basic operators (for runs with and without context) for 50 iterations and found the target model in 1/5 runs for both tests, indicating that more iterations were needed. Our prompts instruct GPT-4 to generate shorter expressions, so it outputs simpler expressions with reasonable MSEs; parsimony is a common goal in SR. But when targeting models like dual-site Langmuir, these instructions may have been a liability, and we needed to adjust the prompt and feedback sent to GPT-4 to allow for the exploration of more complex expressions.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6134/6134c4f8-3be3-47ef-9741-07a82b6a510f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 8: Pareto fronts for dual-site Langmuir dataset. The black line represents the best total front from the f independent runs. The target model is labeled as a blue star.</div>\nNikuradse: Finally, to test the scalability of the approach to larger datasets and to test a problem without a known target model, we evaluated the Nikuradse dataset, which is experimental data for turbulent friction in rough pipes conducted by Johann Nikuradse in the early 1930s [89] The Nikuradse dataset contains over 350 measurements; including the whole dataset in our prompts to GPT-4 exceeded the token limit. Even with long context windows, analyzing large datasets would be expensive, since each iteration is more costly, and because generating longer expressions requires more iterations. So, we developed a cost-saving scheme: only send a portion of the data in the prompt to GPT-4, while fitting and evaluating the generated expressions using the whole dataset (Figure 14 in SI). Since GPT-4 generated longer and more complex expressions for this dataset (seven or more fitted constants were common), numerical optimizing was also more challenging. We found the optimized coefficients varied slightly due to stochasticity in the basin-hopping algorithm; this could lead to inaccurate sorting of the generated expressions. So, we optimized constants ten times for each expression, then selected that with the lowest mean absolute error. Additionally, we stored the fitted parameters in the feedback loop to assess the expressions sent to GPT-4 for feedback. To manage the context window and encourage longer expressions, we used the modified feedback loop that proved modestly successful for the dual-site Langmuir dataset. Though there is no definitive target model for the Nikuradse data, we compared other candidate model expressions from different SR programs in the literature [6]. We modified the basic prompt to encourage GPT-4 to explore longer expressions and also tested the effect of \u201cprodding\" GPT-4 by sharing just the MSE achieved by a literature model (without leaking the model), and challenging it to do better. We conducted six experiments on Nikuradse data, with three slightly different versions of the prompt (P1,P2, and P3) and two sets (S1 and S2) of data points \u2014 one (S1) with 36 (10%) random data points and the second (S2) with another random 36 (20%) data points. Overall, feeding in more data generated better-fitted and more complex expressions. Figure 9 shows the top expressions with the lowest MAE out of the six experiments that were explored with binary math operators (+, \u2212, \u00f7, \u00d7 and \u02c6).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f4cb/f4cb1c96-5b5c-4233-9b8a-12759bfe36da.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 9: Models for Nikuradse dataset from GPT-4. Here P refers to prompt versions, and S refers to dataset. We notice unphysical behavior with fewer data in prompt versions 1 and 2 (Fig. 9 A-B) where GPT-4 is instructed to explore long expressions phrased in two different ways. However it generalizes better with fewer data for prompt version 3 where we challenge GPT-4 by providing information about the MAE and complexity of BMS model.</div>\nWe found an optimal expression from GPT-4 with a complexity of 41 and an MAE of 0.01086 (Figure 9 C). The MAE is approximately three times worse than the top-performing model identified by the Bayesian Machine Scientist (BMS). BMS uses Markov Chain Monte Carlo (MCMC)-based SR and discovered a more accurate expression at complexity 37 with an MAE of 0.00392. However unlike GPT-4, BMS evaluates thousands of expressions in more than 18000 Monte Carlo (MC) steps to identify this expression. Our GPT-4 model uses a portion of the data to find the best expression from only a pool of (50*3 + 3) 153 expressions. We additionally assessed BMS on its default move probabilities and using 40 temperatures for parallel tempering as mentioned in the paper, and ran it for 153 MC steps with Nikuradse data \u2212it generated a constant function, and upon running it longer (1000 MC steps), it suggests an expression with MAE 0.13436 and complexity 25. Thus, we can see that GPT-4\u2019s incremental suggestions for new expressions (at least in the initial stages of the search) are of much higher quality than those by BMS. However, BMS is far more efficient in terms of compute, it generates more expressions at a far lower cost. Using GPT-4 to generate 18000 trial expressions would\nbe far too expensive (the cost of GPT-4 API calls for 5 runs of our workflow was about $27 to obtain 153 expressions with the larger selected data points). BMS samples expressions from a probability distribution. Therefore, running for a long time is expected to be characterized by equilibration, in which the expressions converge to a region in the stationary distribution of expressions, after which no significant improvement would be observed apart from continuing to explore the region of most likely expressions. Genetic algorithms like Eureqa [3] do not converge to a stationary distribution and nor does our approach. On the contrary, running a chatbot for a very long time leads to degradation of its answers as the context gets longer [76,77], so, in principle, our method may exhibit similar degradation with very long runs. However, we expect this effect to be mitigated because we discard the majority of the context after each iteration, only passing the top and recent expressions. We also show a model from Eureqa in [6] which was run with default operator penalties and selected for the best expression from at least 1013 ones. The result from the EFS [85] model (best fit selected from 100 runs) in [6] is comparable to our model with an MAE of 0.00941. EFS is based on sparse regression that uses a genetic algorithm to generate basis functions automatically. EFS is known to be highly efficient, delivering expressions in seconds.\n# 4 Discussion and Conclusion\nSR programs that optimize for speed aim to generate expressions quickly. In contrast, our proposed method emphasizes informed optimization, leveraging contextual information more effectively. The clearest cases of \u201cleveraging the context\u201d occurred when GPT-4\u2019s first guess included the target model among three expressions. But even when the search took longer, we found incorporation of the context, data, and scratchpad to be helpful for improving the quality of generated expressions. However, including noisy data in the context sometimes undermined the search, as did including lower-quality scientific context. Nonetheless, this comes with great computational expense - especially since large datasets and long reasoning chains require so many tokens. In general, we found natural language to be a rather clumsy interface for controlling expression length. Different prompts and feedback mechanisms led to distributions of expressions with varying length. Classical approaches that incorporate expression length into measures of fitness or score are certainly more precise for controlling length, even if expression length is an imperfect measure of parsimony and meaningfulness in SR [93]. We ran separate, focused tests to evaluate the effect of prompting on expression length, and GPT-4 did not obey instructions that requested, for example, \"expressions of length 17.\" Even with a scratchpad available, it failed to both measure complexity of an expression accurately and to generate expressions of the target length. The LLM is better-suited for creative generation, while deterministic Python tools are more effective (and cheaper) at procedural tasks such as counting complexity. Testing our approach on equation rediscovery using GPT-4 invariably involves a form of \u201ctest set leakage\u201d since these expressions are on Wikipedia and countless additional Internet sources. Indeed, the data are publicly available, as well, though we think it unlikely that LLMs trained on natural language would devote a sufficient fraction of their network to memorize these datasets. We found strong evidence of this because of our scratchpad implementation, which revealed when it was thinking of Kepler\u2019s law before seeing the data. Nonetheless, we found evaluating the model outputs to be informative. Moreover, we foresee a use case for scientists trying to solve a mystery about their data while having a great deal of context to potentially include. This context may include experimental details, instrument specifications, and literature, and even a \u201cmemorized\u201d explanation of the data by an LLM or retrieved from context in a retrieval-augmented generation scheme [94] would be valuable. A true blind test would be to rediscover a novel scientific law using an LLM with a knowledge cutoff predating the seminal publication. There are two ways to implement in-context learning in LLMs through prompts. One is the Few-Shot prompting method, where we condition the model on a few specific examples related to the task that helps the model understand and perform the task more accurately. The other is the Zero-Shot prompting method, where the output relies solely on template-based prompts without specific task examples, allowing the model to infer how to handle the task from general instructions. Our approach does not provide examples of symbolic regression procedures within the prompts. Instead, we guide the model to engage in freeform chain-of-thought reasoning about the context as it prepares suggestions for new equations. Biasing the search space in a standard SR program can be challenging and requires advanced software and coding skills. Interdisciplinary work demands significant time and resources from researchers. Natural language interfaces in LLMs can help reduce some of these barriers by making program execution more accessible, even without expertise in software development. Well-crafted prompts empower language models to perform diverse tasks, allowing them to\nadapt to different contexts and objectives. We can guide these models through prompts to generate responses that align with our specific needs, whether solving complex problems, developing creative content, or analyzing data.\n# Acknowledgements\nWe thank Roger Guimer\u00e0 for sharing the detailed results of all models on Nikuradse dataset. This material is based upon work supported by the National Science Foundation under Grant No. #2138938.\nWe thank Roger Guimer\u00e0 for sharing the detailed results of all models on Nikuradse dataset. This material is ba upon work supported by the National Science Foundation under Grant No. #2138938.\n# Conflicts of Interest\nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n# Data Availability\nThe code, prompts, and data supporting the findings of this work are available at https://github.com/ATOMSLab/pySR_adsorption.\n# 5 Supporting Information\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d8e0/d8e071d9-38d5-41b3-9f79-b1940ffed9b5.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 10: Illustration of GPT-3.5 attempting to perform SR</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a9d9/a9d96a5b-4c10-4a21-8765-f7f6b20edd57.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 11: Context provided to GPT-4 for all the datasets</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d747/d74707c1-b674-4d06-a1bc-103642b55900.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 12: Datasets explored using GPT-4 for SR</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7cea/7ceae531-7b7d-4662-9dbc-9328f8ab5c8c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Pressure (p)</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a314/a314a029-d479-4e17-9954-3bc8ee4e9df0.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 14: Nikuradse Dataset. The red and yellow points represent the data sent to GPT-4 (selected randomly from the original dataset), while the grey ones show the original dataset sent to SciPy for optimization.</div>\n# References\n[1] Pat Langley. Data-driven discovery of physical laws. Cognitive Science, 5(1):31\u201354, 1981. [2] Arthur Kordon, Flor Castillo, Guido Smits, and Mark Kotanchek. Application Issues of Genetic Programming in Industry. In Tina Yu, Rick Riolo, and Bill Worzel, editors, Genetic Programming Theory and Practice III, volume 9, pages 241\u2013258. Kluwer Academic Publishers, Boston, 2006. Series Title: Genetic Programming. [3] Michael Schmidt and Hod Lipson. Distilling Free-Form Natural Laws from Experimental Data. Science, 324(5923):81\u201385, 2009. ISBN: 0036-8075. [4] Yan Liu, Zhi Long Cheng, Jing Xu, Jian Yang, and Qiu Wang Wang. Improvement and Validation of Genetic Programming Symbolic Regression Technique of Silva and Applications in Deriving Heat Transfer Correlations. Heat Transfer Engineering, 37(10):862\u2013874, 2016. [5] Ying Jin, Weilin Fu, Jian Kang, Jiadong Guo, and Jian Guo. Bayesian symbolic regression. arXiv preprint arXiv:1910.08892, 2019. [6] Roger Guimer\u00e0, Ignasi Reichardt, Antoni Aguilar-Mogas, Francesco A. Massucci, Manuel Miranda, Jordi Pallar\u00e8s, and Marta Sales-Pardo. A Bayesian machine scientist to aid in the solution of challenging scientific problems. Science Advances, January 2020. Publisher: American Association for the Advancement of Science. [7] Vernon Austel, Sanjeeb Dash, Oktay Gunluk, Lior Horesh, Leo Liberti, Giacomo Nannicini, and Baruch Schieber. Globally Optimal Symbolic Regression. NeurIPS, 2017. [8] Alison Cozad and Nikolaos V. Sahinidis. A global MINLP approach to symbolic regression. Mathematical Programming, 170(1):97\u2013119, 2018. Publisher: Springer Berlin Heidelberg. [9] Cristina Cornelio, Sanjeeb Dash, Vernon Austel, Tyler R Josephson, Joao Goncalves, Kenneth L Clarkson, Nimrod Megiddo, Bachir El Khadir, and Lior Horesh. Combining data and theory for derivable scientific discovery with ai-descartes. Nature Communications, 14(1):1777, 2023. 10] Fabr\u00edcio Olivetti de Fran\u00e7a. A greedy search tree heuristic for symbolic regression. Information Sciences, 442:18\u201332, 2018. 11] Pierre-Alexandre Kamienny, St\u00e9phane d\u2019Ascoli, Guillaume Lample, and Fran\u00e7ois Charton. End-to-end symbolic regression with transformers. Advances in Neural Information Processing Systems, 35:10269\u201310281, 2022. 12] St\u00e9phane d\u2019Ascoli, Pierre-Alexandre Kamienny, Guillaume Lample, and Fran\u00e7ois Charton. Deep symbolic regression for recurrent sequences. arXiv preprint arXiv:2201.04600, 2022.\n[13] Steven L. Brunton, Joshua L. Proctor, and J. Nathan Kutz. Discovering governing equations from data: Sparse identification of nonlinear dynamical systems. Proceedings of the National Academy of Sciences, 113(15):3932\u2013 3937, 2016. ISBN: 1091-6490 (Electronic) 0027-8424 (Linking). [14] Niall M. Mangan, Steven L. Brunton, Joshua L. Proctor, and J. Nathan Kutz. Inferring Biological Networks by Sparse Identification of Nonlinear Dynamics. IEEE Transactions on Molecular, Biological, and Multi-Scale Communications, 2(1):52\u201363, 2016. Publisher: Institute of Electrical and Electronics Engineers Inc. [15] Runhai Ouyang, Stefano Curtarolo, Emre Ahmetcik, Matthias Scheffler, and Luca M. Ghiringhelli. SISSO: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates. Physical Review Materials, 2(8):1\u201311, 2018. Publisher: American Physical Society. [16] David E Goldberg. Cenetic algorithms in search. Optimization, Machine Learning, 1989. [17] Dmitrii E Makarov and Horia Metiu. Fitting potential-energy surfaces: a search in the function space by directed genetic programming. The Journal of chemical physics, 108(2):590\u2013598, 1998. [18] Qiang Lu, Jun Ren, and Zhiguang Wang. Using genetic programming with prior formula knowledge to solve symbolic regression problem. Computational intelligence and neuroscience, 2016:1\u20131, 2016. [19] Silviu-Marian Udrescu and Max Tegmark. Ai feynman: A physics-inspired method for symbolic regression. Science Advances, 6(16):eaay2631, 2020. [20] Arijit Chakraborty, Abhishek Sivaram, and Venkat Venkatasubramanian. AI-DARWIN: A first principles-based model discovery engine using machine learning. Computers & Chemical Engineering, 154:107470, November 2021. [21] Ji\u02c7r\u00ed Kubal\u00edk, Erik Derner, and Robert Babu\u0161ka. Multi-objective symbolic regression for physics-aware dynamic modeling. Expert Systems with Applications, 182:115210, 2021. [22] Marissa R. Engle and Nikolaos V. Sahinidis. Deterministic symbolic regression with derivative information: General methodology and application to equations of state. AIChE Journal, 68(6):e17457, 2022. [23] Gabriel Kronberger, Fabricio Olivetti de Fran\u00e7a, Bogdan Burlacu, Christian Haider, and Michael Kommenda. Shape-constrained Symbolic Regression \u2013 Improving Extrapolation with Prior Knowledge. Evolutionary Computation, 30(1):75\u201398, March 2022. arXiv:2103.15624 [cs, stat]. [24] C. Haider, F.O. De Franca, B. Burlacu, and G. Kronberger. Shape-constrained multi-objective genetic programming for symbolic regression. Applied Soft Computing, 132:109855, January 2023. [25] Wassim Tenachi, Rodrigo Ibata, and Foivos I Diakogiannis. Deep symbolic regression for physics guided by units constraints: toward the automated discovery of physical laws. arXiv preprint arXiv:2303.03192, 2023. [26] Liron Simon Keren, Alex Liberzon, and Teddy Lazebnik. A computational framework for physics-informed symbolic regression with straightforward integration of domain knowledge. Scientific Reports, 13(1):1249, 2023. [27] Jorge Medina and Andrew D White. Active learning in symbolic regression performance with physical constraints. arXiv preprint arXiv:2305.10379, 2023. [28] Charles Fox, Neil D Tran, F Nikki Nacion, Samiha Sharlin, and Tyler R Josephson. Incorporating background knowledge in symbolic regression using a computer algebra system. Machine Learning: Science and Technology, 5(2):025057, 2024. [29] Arya Grayeli, Atharva Sehgal, Omar Costilla-Reyes, Miles Cranmer, and Swarat Chaudhuri. Symbolic regression with a learned concept library. arXiv preprint arXiv:2409.09359, 2024. [30] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in Neural Information Processing Systems, 30, 2017. [31] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901, 2020. [32] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021. [33] Felipe Urrutia and Roberto Araya. Who\u2019s the best detective? large language models vs. traditional machine learning in detecting incoherent fourth grade math answers. Journal of Educational Computing Research, 61(8):187\u2013218, 2024.\n[34] Pengfei Hong, Deepanway Ghosal, Navonil Majumder, Somak Aditya, Rada Mihalcea, and Soujanya Poria. Stuck in the quicksand of numeracy, far from agi summit: Evaluating llms\u2019 mathematical competency through ontology-guided perturbations. arXiv preprint arXiv:2401.09395, 2024. [35] Ankit Satpute, Noah Gie\u00dfing, Andre Greiner-Petter, Moritz Schubotz, Olaf Teschke, Akiko Aizawa, and Bela Gipp. Can llms master math? investigating large language models on math stack exchange. arXiv preprint arXiv:2404.00344, 2024. [36] Enkelejda Kasneci, Kathrin Se\u00dfler, Stefan K\u00fcchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan G\u00fcnnemann, Eyke H\u00fcllermeier, et al. Chatgpt for good? on opportunities and challenges of large language models for education. Learning and individual differences, 103:102274, 2023. [37] Tiffany H Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepa\u00f1o, Maria Madriaga, Rimel Aggabao, Giezel Diaz-Candido, James Maningo, et al. Performance of chatgpt on usmle: potential for ai-assisted medical education using large language models. PLoS digital health, 2(2):e0000198, 2023. [38] Nihang Fu, Lai Wei, Yuqi Song, Qinyang Li, Rui Xin, Sadman Sadeed Omee, Rongzhi Dong, Edirisuriya M Dilanga Siriwardane, and Jianjun Hu. Material transformers: deep learning language models for generative materials design. Machine Learning: Science and Technology, 4(1):015001, 2023. [39] Asbj\u00f8rn F\u00f8lstad, Theo Araujo, Effie Lai-Chong Law, Petter Bae Brandtzaeg, Symeon Papadopoulos, Lea Reis, Marcos Baez, Guy Laban, Patrick McAllister, Carolin Ischen, et al. Future directions for chatbot research: an interdisciplinary research agenda. Computing, 103(12):2915\u20132942, 2021. [40] Glen Coppersmith, Mark Dredze, and Craig Harman. Quantifying mental health signals in twitter. In Proceedings of the workshop on computational linguistics and clinical psychology: From linguistic signal to clinical reality, pages 51\u201360, 2014. [41] Kit-Kay Mak, Yi-Hang Wong, and Mallikarjuna Rao Pichika. Artificial intelligence in drug discovery and development. Drug Discovery and Evaluation: Safety and Pharmacokinetic Assays, pages 1\u201338, 2023. [42] Emilio Ferrara. What types of covid-19 conspiracies are populated by twitter bots? arXiv preprint arXiv:2004.09531, 2020. [43] Philippe Schwaller, Alain C Vaucher, Ruben Laplaza, Charlotte Bunne, Andreas Krause, Clemence Corminboeuf, and Teodoro Laino. Machine intelligence for chemical reaction space. Wiley Interdisciplinary Reviews: Computational Molecular Science, 12(5):e1604, 2022. [44] Mayk Caldas Ramos, Christopher J Collison, and Andrew D White. A review of large language models and autonomous agents in chemistry. arXiv preprint arXiv:2407.01603, 2024. [45] Ilias Chalkidis, Ion Androutsopoulos, and Nikolaos Aletras. Neural legal judgment prediction in english. arXiv preprint arXiv:1906.02059, 2019. [46] Neel Guha, Julian Nyarko, Daniel Ho, Christopher R\u00e9, Adam Chilton, Alex Chohlas-Wood, Austin Peters, Brandon Waldon, Daniel Rockmore, Diego Zambrano, et al. Legalbench: A collaboratively built benchmark for measuring legal reasoning in large language models. Advances in Neural Information Processing Systems, 36, 2024. [47] Johan Bollen, Huina Mao, and Xiaojun Zeng. Twitter mood predicts the stock market. Journal of computational science, 2(1):1\u20138, 2011. [48] John W Goodell, Satish Kumar, Weng Marc Lim, and Debidutta Pattnaik. Artificial intelligence and machine learning in finance: Identifying foundations, themes, and research clusters from bibliometric analysis. Journal of Behavioral and Experimental Finance, 32:100577, 2021. [49] Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Noam Shazeer, Ian Simon, Curtis Hawthorne, Andrew M Dai, Matthew D Hoffman, Monica Dinculescu, and Douglas Eck. Music transformer. arXiv preprint arXiv:1809.04281, 2018. [50] Miguel Civit, Javier Civit-Masot, Francisco Cuadrado, and Maria J Escalona. A systematic review of artificial intelligence-based music generation: Scope, applications, and future trends. Expert Systems with Applications, 209:118190, 2022. [51] Ishika Singh, Gargi Singh, and Ashutosh Modi. Pre-trained language models as prior knowledge for playing text-based games. arXiv preprint arXiv:2107.08408, 2021. [52] Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Tekin, Gaowen Liu, Ramana Kompella, and Ling Liu. A survey on large language model-based game agents. arXiv preprint arXiv:2404.02039, 2024.\n[53] Mojtaba Valipour, Bowen You, Maysum Panju, and Ali Ghodsi. Symbolicgpt: A generative transformer model for symbolic regression. arXiv preprint arXiv:2106.14131, 2021. [54] Vadim Liventsev, Anastasiia Grishina, Aki H\u00e4rm\u00e4, and Leon Moonen. Fully autonomous programming with large language models. In Proceedings of the Genetic and Evolutionary Computation Conference, pages 1146\u20131155, 2023. [55] Pier Luca Lanzi and Daniele Loiacono. Chatgpt and other large language models as evolutionary engines for online interactive collaborative game design. In Proceedings of the Genetic and Evolutionary Computation Conference, pages 1383\u20131390, 2023. [56] Elliot Meyerson, Mark J Nelson, Herbie Bradley, Adam Gaier, Arash Moradi, Amy K Hoover, and Joel Lehman. Language model crossover: Variation through few-shot prompting. arXiv preprint arXiv:2302.12170, 2023. [57] Herbie Bradley, Honglu Fan, Theodoros Galanos, Ryan Zhou, Daniel Scott, and Joel Lehman. The openelm library: Leveraging progress in language models for novel evolutionary algorithms. In Genetic Programming Theory and Practice XX, pages 177\u2013201. Springer, 2024. [58] Zixian Guo, Ming Liu, Zhilong Ji, Jinfeng Bai, Yiwen Guo, and Wangmeng Zuo. Two optimizers are better than one: Llm catalyst for enhancing gradient-based optimization. arXiv preprint arXiv:2405.19732, 2024. [59] Erik Hemberg, Stephen Moskal, and Una-May O\u2019Reilly. Evolving code with a large language model. arXiv preprint arXiv:2401.07102, 2024. [60] Shengcai Liu, Caishun Chen, Xinghua Qu, Ke Tang, and Yew-Soon Ong. Large language models as evolutionary optimizers. In 2024 IEEE Congress on Evolutionary Computation (CEC), pages 1\u20138. IEEE, 2024. [61] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021. [62] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. [63] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824\u201324837, 2022. [64] Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work: Scratchpads for intermediate computation with language models, 2021. URL https://arxiv. org/abs/2112.00114, 2021. [65] Fran\u00e7ois Chollet. How I think about llm prompt engineering. https://fchollet.substack.com/p/ how-i-think-about-llm-prompt-engineering. Accessed: 2024-08-13. [66] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. Large language models as optimizers, 2024. [67] Matteo Merler, Katsiaryna Haitsiukevich, Nicola Dainese, and Pekka Marttinen. In-context symbolic regression: Leveraging large language models for function discovery. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop), pages 589\u2013606, 2024. [68] Parshin Shojaee, Kazem Meidani, Shashank Gupta, Amir Barati Farimani, and Chandan K Reddy. Llm-sr: Scientific equation discovery via programming with large language models. arXiv preprint arXiv:2404.18400, 2024. [69] Irving Langmuir. The Adsorption of Gases on Plane Surfaces of Glass, Mica and Platinum. Journal of the American Chemical Society, 40(9):1361\u20131403, September 1918. Publisher: American Chemical Society. [70] John A Nelder and Roger Mead. A simplex method for function minimization. The computer journal, 7(4):308\u2013 313, 1965. [71] David J Wales and Jonathan PK Doye. Global optimization by basin-hopping and the lowest energy structures of lennard-jones clusters containing up to 110 atoms. The Journal of Physical Chemistry A, 101(28):5111\u20135116, 1997. [72] Sanghwan Bae, Donghyun Kwak, Soyoung Kang, Min Young Lee, Sungdong Kim, Yuin Jeong, Hyeri Kim, Sang-Woo Lee, Woomyoung Park, and Nako Sung. Keep me updated! memory management in long-term conversations. arXiv preprint arXiv:2210.08750, 2022. [73] Jing Xu, Arthur Szlam, and Jason Weston. Beyond goldfish memory: Long-term open-domain conversation. arXiv preprint arXiv:2107.07567, 2021.\n[74] Xinchao Xu, Zhibin Gou, Wenquan Wu, Zheng-Yu Niu, Hua Wu, Haifeng Wang, and Shihang Wang. Long time no see! open-domain conversation with long-term persona memory. arXiv preprint arXiv:2203.05797, 2022. [75] Hanxun Zhong, Zhicheng Dou, Yutao Zhu, Hongjin Qian, and Ji-Rong Wen. Less is more: Learning to refine dialogue history for personalized dialogue generation. arXiv preprint arXiv:2204.08128, 2022. [76] Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language models use long contexts. Transactions of the Association for Computational Linguistics, 12:157\u2013173, 2024. [77] Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H Chi, Nathanael Sch\u00e4rli, and Denny Zhou. Large language models can be easily distracted by irrelevant context. In International Conference on Machine Learning, pages 31210\u201331227. PMLR, 2023. [78] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys, 55(9):1\u201335, 2023. [79] Laria Reynolds and Kyle McDonell. Prompt programming for large language models: Beyond the few-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, pages 1\u20137, 2021. [80] Guanghui Qin and Jason Eisner. Learning how to ask: Querying lms with mixtures of soft prompts. arXiv preprint arXiv:2104.06599, 2021. [81] Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691, 2021. [82] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adri\u00e0 Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022. [83] Aaron Meurer, Christopher P. Smith, Mateusz Paprocki, Ond\u02c7rej \u02c7Cert\u00edk, Sergey B. Kirpichev, Matthew Rocklin, AMiT Kumar, Sergiu Ivanov, Jason K. Moore, Sartaj Singh, Thilina Rathnayake, Sean Vig, Brian E. Granger, Richard P. Muller, Francesco Bonazzi, Harsh Gupta, Shivam Vats, Fredrik Johansson, Fabian Pedregosa, Matthew J. Curry, Andy R. Terrel, \u0160t\u02c7ep\u00e1n Rou\u02c7cka, Ashutosh Saboo, Isuru Fernando, Sumith Kulal, Robert Cimrman, and Anthony Scopatz. Sympy: symbolic computing in python. PeerJ Computer Science, 3:e103, January 2017. [84] Michael D Schmidt and Hod Lipson. Incorporating expert knowledge in evolutionary search: a study of seeding methods. In Proceedings of the 11th Annual conference on Genetic and evolutionary computation, pages 1091\u20131098, 2009. [85] Ignacio Arnaldo, Una-May O\u2019Reilly, and Kalyan Veeramachaneni. Building predictive models via feature synthesis. In Proceedings of the 2015 annual conference on genetic and evolutionary computation, pages 983\u2013990, 2015. [86] Fran\u00e7ois-Michel De Rainville, F\u00e9lix-Antoine Fortin, Marc-Andr\u00e9 Gardner, Marc Parizeau, and Christian Gagn\u00e9. Deap: A python framework for evolutionary algorithms. In Proceedings of the 14th annual conference companion on Genetic and evolutionary computation, pages 85\u201392, 2012. [87] Jure Brence, Sa\u0161o D\u017eeroski, and Ljup\u02c7co Todorovski. Dimensionally-consistent equation discovery through probabilistic attribute grammars. Information Sciences, 632:742\u2013756, 2023. [88] Miles Cranmer. Interpretable machine learning for science with pysr and symbolicregression. jl. arXiv preprint arXiv:2305.01582, 2023. [89] Johann Nikuradse et al. Laws of flow in rough pipes. NASA, 1950. [90] David H Ackley, Geoffrey E Hinton, and Terrence J Sejnowski. A learning algorithm for boltzmann machines. Cognitive science, 9(1):147\u2013169, 1985. [91] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. [92] Vernon Austel, Sanjeeb Dash, Joao Goncalves, Lior Horesh, Tyler R. Josephson, and Nimrod Megiddo. Symbolic Regression using Mixed-Integer Nonlinear Optimization. arXiv preprint, 2020. [93] FO de Franca, M Virgolin, M Kommenda, MS Majumder, M Cranmer, G Espada, L Ingelse, A Fonseca, M Landajuela, B Petersen, et al. Srbench++: principled benchmarking of symbolic regression with domain-expert interpretation. IEEE Transactions on Evolutionary Computation, 2024.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of utilizing Large Language Models (LLMs) for symbolic regression, a machine learning method aimed at discovering simple and accurate equations from datasets. Previous methods primarily relied on genetic algorithms and other optimization techniques, which lacked the integration of reasoning and scientific context. The exploration of LLMs in this domain presents a breakthrough opportunity to enhance the search for equations by incorporating natural language understanding and contextual information.",
        "problem": {
            "definition": "The problem at hand is the challenge of efficiently discovering accurate mathematical expressions that explain scientific data using symbolic regression techniques. Existing methods often struggle with complexity and may not adequately incorporate scientific reasoning.",
            "key obstacle": "The main difficulty lies in the limitations of traditional symbolic regression approaches, which do not effectively utilize the contextual information inherent in scientific data, leading to suboptimal expression discovery."
        },
        "idea": {
            "intuition": "The idea is inspired by the observation that LLMs, such as GPT-4, can understand and generate expressions based on natural language prompts, potentially improving the symbolic regression process by using reasoning and context.",
            "opinion": "The proposed method involves prompting GPT-4 to generate mathematical expressions from data while optimizing these expressions iteratively using external tools, thus combining the strengths of LLMs with traditional optimization techniques.",
            "innovation": "The key innovation of this method is the integration of in-context learning and reasoning through a scratchpad approach, allowing the LLM to analyze data and prior expressions while incorporating scientific context to generate improved mathematical expressions."
        },
        "method": {
            "method name": "In-Context Learning and Reasoning for Symbolic Regression",
            "method abbreviation": "ICL-SR",
            "method definition": "This method utilizes Large Language Models to generate and optimize mathematical expressions for symbolic regression by incorporating data analysis, scientific context, and iterative feedback.",
            "method description": "The method operates by prompting the LLM to suggest expressions, optimizing these expressions with external tools, and iterating based on feedback to refine the results.",
            "method steps": [
                "Prompt GPT-4 with the dataset to generate initial expressions.",
                "Optimize the generated expressions using SciPy to fit coefficients.",
                "Evaluate the expressions based on complexity and mean squared error (MSE).",
                "Provide feedback to GPT-4 in JSON format to suggest improved expressions.",
                "Repeat the process iteratively to refine the expressions."
            ],
            "principle": "This method is effective due to its ability to leverage the reasoning capabilities of LLMs, allowing for a more informed search through the equation space while incorporating scientific context to guide expression generation."
        },
        "experiments": {
            "evaluation setting": "The experiments utilized five well-known scientific datasets, including Bode\u2019s Law, Hubble\u2019s Law, and Langmuir adsorption isotherm models, testing the method's ability to rediscover equations and evaluate performance against baseline symbolic regression methods.",
            "evaluation method": "The performance was assessed by measuring the accuracy of rediscovered equations, tracking the mean squared error (MSE) of generated expressions, and comparing results across different experimental settings, such as varying the inclusion of context and the use of a scratchpad."
        },
        "conclusion": "The experiments demonstrated that the proposed method successfully rediscovered all five target equations, highlighting the effectiveness of incorporating scientific context and iterative feedback in symbolic regression. While the method does not outperform traditional programs for more complex equations, it shows promise in generating improved solutions through reasoning and context.",
        "discussion": {
            "advantage": "The primary advantages of this approach include enhanced expression generation through reasoning, the ability to incorporate scientific context, and improved performance in rediscovering known equations.",
            "limitation": "The limitations include the computational expense of using LLMs for large datasets and the potential for noisy data to hinder performance. Additionally, the method may not always generate expressions that are dimensionally consistent.",
            "future work": "Future research should focus on optimizing the computational efficiency of the method, exploring the use of additional scientific context, and developing strategies to handle larger datasets without compromising performance."
        },
        "other info": {
            "data availability": "The code, prompts, and data supporting the findings of this work are available at https://github.com/ATOMSLab/pySR_adsorption.",
            "conflicts of interest": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The foundational concept of utilizing Large Language Models (LLMs) for symbolic regression highlights the integration of reasoning and scientific context in discovering equations from datasets."
        },
        {
            "section number": "1.2",
            "key information": "In-context learning enhances the search for equations by incorporating natural language understanding, making it significant in the field of symbolic regression."
        },
        {
            "section number": "3.1",
            "key information": "The method named 'In-Context Learning and Reasoning for Symbolic Regression' (ICL-SR) demonstrates how LLMs adapt to various contexts by generating and optimizing mathematical expressions based on scientific data."
        },
        {
            "section number": "3.4",
            "key information": "The ICL-SR method explores how LLMs utilize memory and adapt to context by prompting GPT-4 to generate expressions and iteratively refining them based on feedback."
        },
        {
            "section number": "4.1",
            "key information": "Effective prompt design is crucial as the method involves prompting GPT-4 with datasets to generate initial expressions, which significantly influences the outcomes of in-context learning."
        },
        {
            "section number": "6.2",
            "key information": "The computational expense of using LLMs for large datasets is identified as a limitation, highlighting concerns regarding efficiency in in-context learning applications."
        },
        {
            "section number": "7",
            "key information": "The conclusion emphasizes the effectiveness of incorporating scientific context and iterative feedback in symbolic regression, summarizing key findings from the experiments conducted."
        }
    ],
    "similarity_score": 0.7174312238390533,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2330_in-co/papers/In Context Learning and Reasoning for Symbolic Regression with Large Language Models.json"
}