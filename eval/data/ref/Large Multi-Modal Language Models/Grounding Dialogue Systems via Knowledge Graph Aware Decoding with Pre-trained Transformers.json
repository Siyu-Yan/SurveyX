{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2103.16289",
    "title": "Grounding Dialogue Systems via Knowledge Graph Aware Decoding with Pre-trained Transformers",
    "abstract": "Generating knowledge grounded responses in both goal and non-goal oriented dialogue systems is an important research challenge. Knowledge Graphs (KG) can be viewed as an abstraction of the real world, which can potentially facilitate a dialogue system to produce knowledge grounded responses. However, integrating KGs into the dialogue generation process in an end-to-end manner is a non-trivial task. This paper proposes a novel architecture for integrating KGs into the response generation process by training a BERT model that learns to answer using the elements of the KG (entities and relations) in a multi-task, end-to-end setting. The k-hop subgraph of the KG is incorporated into the model during training and inference using Graph Laplacian. Empirical evaluation suggests that the model achieves better knowledge groundedness (measured via Entity F1 score) compared to other state-of-the-art models for both goal and non-goal oriented dialogues.",
    "bib_name": "chaudhuri2021groundingdialoguesystemsknowledge",
    "md_text": "# Grounding Dialogue Systems via Knowledge Graph Aware Decoding with Pre-trained Transformers\nDebanjan Chaudhuri2, Md Rashad Al Hasan Rony1* \ufffd, and Jens Lehmann1,2\n1 Fraunhofer IAIS, Dresden, Germany rashad.rony@iais.fraunhofer.de, jens.lehmann@iais.fraunhofer.de 2 Smart Data Analytics Group, University of Bonn s6dechau@uni-bonn.de, jens.lehmann@cs.uni-bonn.de\nAbstract. Generating knowledge grounded responses in both goal and non-goal oriented dialogue systems is an important research challenge. Knowledge Graphs (KG) can be viewed as an abstraction of the real world, which can potentially facilitate a dialogue system to produce knowledge grounded responses. However, integrating KGs into the dialogue generation process in an end-to-end manner is a non-trivial task. This paper proposes a novel architecture for integrating KGs into the response generation process by training a BERT model that learns to answer using the elements of the KG (entities and relations) in a multi-task, end-to-end setting. The k-hop subgraph of the KG is incorporated into the model during training and inference using Graph Laplacian. Empirical evaluation suggests that the model achieves better knowledge groundedness (measured via Entity F1 score) compared to other state-of-the-art models for both goal and non-goal oriented dialogues.\nKeywords: Knowledge graph \u00b7 Dialogue system \u00b7 Graph encoding \u00b7 Knowledge integration.\nKeywords: Knowledge graph \u00b7 Dialogue system \u00b7 Graph encoding \u00b7 Knowledg\n# 1 Introduction\nRecently, dialogue systems based on KGs have become increasingly popular because of their wide range of applications from hotel bookings, customer-care to voice assistant services. Such dialogue systems can be realized using both goal and non-goal oriented methods. Whereas the former one is employed for carrying out a particular task, the latter is focused on performing natural (\u201dchit-chat\u201d) dialogues. Both types of dialogue system can be implemented using a generative approach. In a generative dialogue system, the response is generated (usually word by word) from the domain vocabulary given a natural language user query, along with the previous dialogue context. Such systems can benefit from the integration of additional world knowledge [12]. In particular, knowledge graphs, which are an abstraction of real world knowledge, have been shown to be useful for this purpose. Information of the real world can be stored in a KG in a structured (Resource Description Framework (RDF) triple, e.g., < subject, relation, object >) and abstract way (Paris is the capital city of France and be presented in < Paris, capital city, France >). KG based question answering\n*Equal contribution\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f8c5/f8c51d71-c96a-4d9d-b176-7e2a01ecefdc.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 1: Example of a knowledge grounded conversation.</div>\n(KGQA) is already a well-researched topic [6]. However, generative dialogue systems with integrated KGs have only been explored more recently [7,20,12]. To model the response using the KG, all current methods assume that the entity in the input query or a sub-graph of the whole KG, which can be used to generate the answer, is already known [20,36]. This assumption makes it difficult to scale such systems to real-world scenarios, because the task of extracting sub-graphs or, alternatively, performing entity linking in large knowledge graphs is non-trivial [27]. An example of a knowledge graph based dialogue system is shown in Figure 1. In order to generate the response James Cameron is the director, the system has to link the entity mentioned in the question in the first turn i.e. Titanic, and identify the relation in the KG connecting the entities Titanic with James Cameron, namely directed by. Additionally, to obtain a natural dialogue system, it should also reply with coherent responses (eg. \u201dJames Cameron is the director\u201d) and should be able to handle small-talk such as greetings, humour etc. Furthermore, in order to perform multi-turn dialogues, the system should also be able to perform co-reference resolution and connect the pronoun (he) in the second question with James Cameron. In order to tackle these research challenges, we model the dialogue generation process by jointly learning the entity and relation information during the dialogue generation process using a pre-trained BERT model in an end-to-end manner. The model\u2019s response generation is designed to learn to predict relation(s) from the input KG instead of the actual object(s) (intermediate representation). Additionally, a graph Laplacian based method is used to encode the input sub-graph and use it for the final decoding process. Experimental results suggest that the proposed method improves upon previous state-of-the-art approaches for both goal and non-goal oriented dialogues. Our code is publicly available on Github 3. Overall, the contributions of this paper are as follows:\n3https://github.com/SmartDataAnalytics/kgirnet/\n\u2013 A novel approach, leveraging the knowledge graph elements (entities and relations) in the questions along with pre-trained transformers, which helps in generating suitable knowledge grounded responses. \u2013 We have also additionally encoded the sub-graph structure of the entity of the input query with a Graph Laplacian, which is traditionally used in graph neural networks. This novel decoding method further improves performance. \u2013 An extensive evaluation and ablation study of the proposed model on two datasets requiring grounded KG knowledge: an in-car dialogue dataset and soccer dialogues for goal and non-goal oriented setting, respectively. Evaluation results show that the proposed model produces improved knowledge grounded responses compared to other state-of-the-art dialogue systems w.r.t. automated metrics, and humanevaluation for both goal and non-goal oriented dialogues.\n# 2 Model Description\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ff72/ff72a0b7-b131-4f7b-bc15-6b792b962966.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 2: KGIRNet model diagram.</div>\nWe aim to solve the problem of answer generation in a dialogue using a KG as defined below. Definition 1 (Knowledge Graph). Within the scope of this paper, we define a knowledge graph KG as a labelled, undirected multi-graph consisting of a set V of nodes and a set E of edges between them. There exists a function, fl that maps the nodes and\nvertices of a graph to a string. The neighborhood of a node of radius k (or k-hop) is the set of nodes at a distance equal to or less than k.\nThis definition is sufficiently generic to be applicable to knowledge graphs based on RDF4 (Resource Description Framework) as well as property graphs [13]. The vertices V of the KG represent entities e \u2208V , while the edges represent the relationships between those entities. A fact is an ordered triple consisting of an entity e (or subject s), an object o and the relation r (a.k.a. predicate p) between them, denoted by (s, p, o). The proposed model for dialogue generation, which we call KGIRNet, is quintessentially a sequence-to-sequence based model with a pre-trained transformer serving as its input as illustrated in Figure 2. In contrast to previous works, we introduce an intermediate query representation using the relation information, for training. We also employ a Graph Laplacian based method for encoding the input sub-graph of the KG that aids in predicting the correct relation(s) as well as filter out irrelevant KG elements. Our approach consists of the following steps for which more details are provided below: Firstly, we encode the input query q with a pre-trained BERT model (Section 2.1). Next we detect a core entity e occurring in q (Section 2.2). Input query q and generated output is appended to the dialogue context in every utterance. The input query, encoded using the BERT model is then passed through an LSTM encoder to get an encoded representation (Section 2.3). This encoded representation is passed onto another LSTM decoder (Section 2.5), which outputs a probability distribution for the output tokens at every time-step. Additionally, the model also extracts the k-hop neighbourhood of e in the KG and encodes it using graph based encoding (Section 2.6) and perform a Hadamard product with token probability distribution from the decoder. The decoding process stops when it encounters a special token, < EOS > (end of sentence). Dotted lines in the model diagram represent operations performed at a different time-step t in the decoding process where solid lines are performed once for each utterance or input query. In this work, we define complex questions as questions which require multiple relations to answer the given question. For example, for the following query: \u201cplease tell me the location, time and the parties that are attending my meeting\u201d, the model needs to use 3 relations from the KG for answering, namely location, time and parties. The answer given by the model could be : \u201cyou have meeting scheduled on friday at 10am with boss in conference room 102 to go over budget\u201d. The model is able to retrieve important relation information from the KG during decoding. However, the model is not able to handle questions which go beyond the usage of explicitly stored relations and require inference capabilities .\n# 2.1 Query Encoding\nBERT is a pre-trained multi-layer, bi-directional transformer [32] model proposed in [8] It is trained on unlabelled data for two-phased objective: masked language model and next sentence prediction. For encoding any text, special tokens [CLS] and [SEP] are inserted at the beginning and the end of the text, respectively. In the case of KGIRNet,\n4https://www.w3.org/RDF/\nthe input query q = (q1, q2, ...qn) at turn td in the dialogue, along with the context up to turn td \u22121 is first encoded using this pre-trained BERT model which produces hidden states (T1, T2....Tn) for each token and an aggregated hidden state representation C for the [CLS] (first) token. We encode the whole query q along with the context, concatenated with a special token, < EOU > (end of utterance).\n# 2.2 Entity Detection\nThe aggregated hidden representation from the BERT model C is passed to a fully connected hidden layer to predict the entity einp \u2208V in the input question as given by\nhere, went and bent are the parameters of the fully connected hidden laye\n# 2.3 Input Query Encoder\nThe hidden state representations (T1, T2....Tn) of the input query q (and dialogue context) using BERT is further encoded using an LSTM [14] encoder which produces a final hidden state at the n-th time-step given by\nfenc is a recurrent function and Tn is the hidden state for the input token qn from BERT. The final representation of the encoder response is a representation at every n denoted by\n# 2.4 Intermediate Representation\nAs an intermediate response, we let the model learn the relation or edge label(s) required to answer the question, instead of the actual object label(s). In order to do this, we additionally incorporated the relation labels obtained by applying the label function fl to all edges in the KG into the output vocabulary set. If the output vocabulary size for a vanilla sequence-to-sequence model is vo, the total output vocabulary size becomes vod which is the sum of vo and vkg. The latter being the labels from applying the fl to all edges (or relations) in the KG. For example, if in a certain response, a token corresponds to an object label ol (obtained by applying fl to o) in the fact (e, r, o), the token is replaced with a KG token vkg corresponding to the edge or relation label rl of r \u2208E in the KG. During training, the decoder would see the string obtained by applying fl to the edge between the entities Titanic and James Cameron, denoted here as r:directedBy. Hence, it will try to learn the relation instead of the actual object. This makes the system more generic and KG aware, and easily scalable to new facts and domains. During evaluation, when the decoder generates a token from vkg, a KG lookup is done to decode the label ol of the node o \u2208V in the KG (V being the set of nodes or vertices in the KG). This is generally done using a SPARQL query.\n(1)\n(2)\n(3)\n# 2.5 Decoding Process\nThe decoding process generates an output token at every time-step t in the response generation process. It gets as input the encoded response He and also the KG distribution from the graph encoding process as explained later. The decoder is also a LSTM, which is initialized with the encoder last hidden states and the first token used as input to it is a special token, < SOS > (start of sentence). The decoder hidden states are similar to that of the encoder as given by the recurrent function fdec\nThis hidden state is used to compute an attention over all the hidden states of the encoder following [19], as given by\nWhere, Wc and Ws are the weights of the attention model. The final weighted context representation is given by \ufffd\n\ufffd This representation is concatenated (represented by ;) with the hidden states of the decoder to generate an output from the vocabulary with size vod. The output vocab distribution from the decoder is given by\nIn the above equation, Wo are the output weights with dimension RhdimXvod. hdim being the dimension of the hidden layer of the decoder LSTM. The total loss is the sum of the vocabulary loss and the entity detection loss. Finally, we use beam-search [31] during the the decoding method.\n# 2.6 Sub-Graph Encoding\nIn order to limit the KGIRNet model to predict only from those relations which are connected to the input entity predicted from step 2.2, we encode the sub-graph along with its labels and use it in the final decoding process while evaluating. The k-hop sub-graph of the input entity is encoded using Graph Laplacian [16] given by\nWhere, \u02dcA = A + I. A being the adjacency matrix, I is the identity matrix and D is the degree matrix. fin is a feature representation of the vertices and edges in the input graph. Genc is a vector with dimensions Rik corresponding to the total number of nodes and edges in the k-hop sub-graph of e. An example of the sub-graph encoding mechanism is shown in Figure 3. The final vocabulary distribution Of \u2208Rvod is a Hadamard product of this graph vector and the vocabulary distribution output from the decoder.\n(5)\n(6)\n(7)\n(8)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/cd05/cd057354-0621-4319-a979-fb7769d8c0ad.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 3: Sub-Graph Encoding using Graph Laplacian.</div>\n \u2299 This step essentially helps the model to give additional importance to the relations connected at k-hop based on its similarity with the query also to filter(mask) out relations from the response which are not connected to it. For the query in 3 who is the director of Avatar and how was it rated ? The graph laplacian based encoding method using only relation labels already gives higher scores for the relations directed by and rating, which are required by the question. This vector when multiplied with the final output vocabulary helps in better relation learning.\n# 3 Experimental Setup\n# 3.1 Datasets\nAvailable datasets for knowledge grounded conversations are the in-car dialogue data as proposed by [12] and soccer dialogues over football club and national teams using a knowledge graph [7]. The former contains dialogues for assisting the driver of a car with data related to weather, schedules and navigation, in a goal-oriented setting. The soccer dataset contains non-goal oriented dialogues about questions on different soccer teams along with a knowledge graph consisting of facts extracted from Wikipedia about the respective clubs and national soccer teams. Both the datasets were collected using Amazon Mechanical Turk (AMT) by the respective authors [12,7]. The statistics of the datasets are provided in Table 1. As observed, the number of dialogues for both the dataset is low.\n(9)\nTo perform a KG grounded dialogue as in KG based question-answering [10], it is important to annotate the dialogues with KG information such as the entities and relations, the dialogues are about. Such information were missing in the soccer dataset, hence we have semi-automatically annotated them with the input entity einp in the query q and the relations in the k-hop sub-graph of the input entity required to answer q. For the domain of in-car it was possible to automatically extract the entity and relation information from the dialogues and input local KG snippets.\n<div style=\"text-align: center;\">Table 1: Dataset statistics.</div>\nTable 1: Dataset statistics.\nIn-car dialogues\nSoccer dialogues\nNumber of triples, entity, relations\n8561, 271, 36\n4301, 932, 30\nTrain Validation Test Train Validation Test\nNumber of dialogues\n2011\n242\n256\n1328\n149\n348\nNumber of utterances\n5528\n657\n709\n6523\n737\n1727\nKG-grounded questions (%)\n44.95\n33.94\n43.84 6.53\n4.61\n3.88\n# 3.2 Evaluation Metrics\nWe evaluate the models using the standard evaluation metrics BLEU [25] and Entity F1 scores as used in the discussed state-of-the-art models. However, unlike [20] we use Entity F1 scores based on the nodes V of the KG, as inspired by previous works on KG based question answering [3]. Additionally, we use METEOR [1] because it correlates the most with human judgement scores [30].\n# 3.3 Model Settings\n<div style=\"text-align: center;\">Table 2: Evaluation on goal and non-goal oriented dialogues.</div>\nModels\nIn-Car Dialogues\nSoccer Dialogues\nInference time\nBLEU Entity F1 METEOR BLEU Entity F1 METEOR utterances/sec\nSeq2Seq\n4.96\n10.70\n21.20\n1.37\n0.0\n7.8\n133\nMem2Seq[20]\n9.43\n24.60\n28.80\n0.82\n04.95\n7.8\n88\nGLMP[36]\n9.15\n21.28\n29.10\n0.43\n22.40\n7.7\n136\nTransformer[32] 8.27\n24.79\n29.06\n0.45\n0.0\n6.7\n7\nDialoGPT[39]\n7.35\n21.36\n20.50\n0.76\n0.0\n5.5\n2\nKG-Copy[7]\n-\n-\n-\n1.93\n03.17\n10.89\n262\nKGIRNet\n11.76\n32.67\n30.02\n1.51\n34.33\n8.24\n37\nFor entity detection we used a fully connected layer on top of CNN-based architecture. Size of the hidden layer in the fully connected part is 500 and a dropout value of 0.1 is used and ReLU as the activation function. In the CNN part we have used 300 filters\nwith kernel size 3, 4 and 5. We use BERT-base-uncased model for encoding the input query. The encoder and decoder is modelled using an LSTM (long short term memory) with a hidden size of 256 and the KGIRNet model is trained with a batch size of 20. The learning rate of the used encoder is 1e-4. For the decoder we select a learning rate of 1e-3. We use the Adam optimizer to optimize the weights of the neural networks. For all of our experiments we use a sub-graph size of k=2. For calculating fin as in Equation 8, we use averaged word embedding similarity values between the query and the labels of the sub-graph elements. The similarity function used in this case is cosine similarity. We save the model with best validation Entity f1 score.\n<div style=\"text-align: center;\">Table 3: Relation Linking Accuracy on SQB [37] Dataset.</div>\nTable 3: Relation Linking Accuracy on SQB [37] Dataset.\nMethod\nModel\nAccuracy\nSupervised\nBi-LSTM [21]\n38.5\nHR-LSTM [38]\n64.3\nUnsupervised\nEmbedding Similarity\n60.1\nGraph Laplacian (this work)\n69.7\n# 4 Results\nIn this section, we summarize the results from our experiments. We evaluate our proposed model KGIRNet against the current state-of-the-art systems for KG based dialogues; namely Mem2Seq [20], GLMP [36], and KG-Copy [7]5. To include a baseline method, the results from a vanilla Seq2Seq model using an LSTM encoder-decoder are also reported in Table 2, along with a vanilla transformer [32] and a pre-trained GPT-2 model, DialoGPT [39] fine-tuned individually on both the datasets. We observe that KGIRNet outperforms other approaches for both goal (in-car) and non-goal oriented (soccer) dialogues except for BLEU and METEOR scores on the soccer dataset. The effect of knowledge groundedness is particularly visible in the case of soccer dialogues, where most models (except GLMP) produces feeble knowledge grounded responses. The Entity F1 score used here is adapted from [3] and is defined as the average of F1-scores of the set of predicted objects, for all the questions in the test set. In addition to evaluating dialogues, we also evaluate the proposed graph laplacian based relation learning module for the task of knowldge-graph based relation linking. Although, it is a well-researched topic and some systems claim to have solved the problem [26], but such systems are not able to handle relations which are not present in the training data [37]. The latter also proposed a new, balanced dataset (SQB) for simple question answering which has same proportions of seen and unseen relations in the test or evaluation set. We have evaluated our unsupervised graph laplacian based method for relation linking on the SQB dataset against supervised methods namely Bi-LSTM [21], hr-bilstm [38] and unsupervised method such as text embedding based similarity between the query and the relations connected to the subject entity with 1-hop.\n5KG-Copy reports on a subset of the in-car testset hence it is not reported here\n5KG-Copy reports on a subset of the in-car testset hence it is not reported here\nThe results are reported in Table 3. As observed, Graph Laplacian performs better wrt. supervised methods on unseen relations and also better than shallow embedding based similarity. This is one of the motivation for using this simple method during KGIRNet\u2019s decoding process. We run all the inference on a setup with 32GB of RAM and 8GB of VGA and a Bandwidth of 256.3 GB/s.\n# 5 Discussion\nFor in-car dialogues, we train and evaluate on queries which require knowledge from the KG, hence we omit the scheduling conversations where the driver asks the car to schedule a meeting/conference. In order to get the knowledge graph candidate triples for all the other models (Mem2Seq and GLMP), we provide them with the 2-hop sub-graph of the correct input entity instead of the local knowledge as used in the respective models; this, represents a scenario closer to a real-world KG grounded conversation. For the in-car dataset, the human baseline BLEU score as reported in [12] is 13.5 (the KGIRNet score is 11.76). The BLEU scores for soccer are low because non-goal oriented dialogues are more complicated to model due to large vocabulary sizes (more than 3 times the vocabulary size of the of in-car dataset). Also in the case of soccer dialogues, number of factual conversation is low (4%) compared to the total number of utterances and also the conversations are more generic and repetitive in nature.\n<div style=\"text-align: center;\">Table 4: Analyzing sample predictions.</div>\nInput Query\nTrue Response\nPredicted Responses\nGLMP\nMem2Seq\nKGIRNet\n(S) who is currently\ncoaching bvb dortmund\n?\nlucien favre\nthe is the coach\nyes , they have a good\nlucien favre is the coach\nof bvb dortmund\n(S) when did italy last\nwin the world cup ?\n2006\nitaly won the world cup\nin 2006\ni think they have a good\nteam\nitaly won the world cup\nin 2006\n(C) what time is my doc-\ntorappointment?\nyour doctorappoint-\nment is scheduled\nfor friday at 11am\nyour next is is at 1pm at\n7pm\nyour doctorappointment is\nat 1pm\nyour doctorappointment\nis on friday at 11am\n(C) i need gas\nvalero\nis\n4 miles\naway\nthere is a valero away\nchevron is gas station away\nchevron is at away\nthere is a valero nearby\n# 5.1 Human Evaluation\nWe perform a human-based evaluation on the whole test dataset of the generated responses from the KGIRNet model and its closest competitors, i.e. Mem2Seq, GLMP and DialoGPT models. We asked 3 internal independent annotators who are not the authors of this paper (1 from CS and 2 from non-CS background) to rate the quality of the generated responses between 1-5 with respect to the dialogue context (higher is better). Note that for each dataset, we provide the annotators with 4 output files in CSV format (containing the predictions of each model) and the knowledge graph in RDF format. Each of the CSV files contains data in 5 columns: question, original response, predicted response, grammatical correctness, similarity between original and predicted response. In the provided files, the 4th (grammatically correctness) and 5th (similarity between\noriginal and predicted response) columns are empty and we ask the annotators to fill them with values (within a range of 1-5) according to their judgement. The measures requested to evaluate upon are correctness (Corr.) and human-like (human) answer generation capabilities. Correctness is measured by comparing the response to the correct answer object. Reference responses are provided besides the system generated response in order to check the factual questions. The results are reported in Table 5a. Cohen\u2019s Kappa of the annotations is 0.55.\n# 5.2 Ablation Study\nAs an ablation study we train a sequence-to-sequence model with pre-trained fasttext embeddings as input (S2S), and the same model with pre-trained BERT as input embedding (S2S BERT). Both these models do not have any information about the structure of the underlying knowledge graph. Secondly, we try to understand how much the intermediate representation aids to the model, so we train a model (KGIRNet NB) with fasttext embeddings as input instead of BERT along with intermediate relation representation. Thirdly, we train a model with pre-trained BERT but without the haddamard product of the encoded sub-graph and the final output vocabulary distribution from Step 2.6. This model is denoted as KGIRNet NS. As observed, models that are devoid of any KG structure has very low Entity F1 scores, which is more observable in the case of soccer dialogues since the knowledge grounded queries are very low, so the model is not able to learn any fact(s) from the dataset. The proposed intermediate relation learning along with Graph Laplacian based sub-graph encoding technique observably assists in producing better knowledge grounded responses in both the domains; although, the latter aids in more knowledge groundedness in the domain of soccer dialogues (higher Entity F1 scores). We also did an ablation study on the entity detection accuracy of the end-to-end KGIRNet model in the domain of in-car and compared it with a standalone Convolutional neural network (CNN) model which predicts the entity from the input query, the accuracies are 79.69 % and 77.29% respectively.\n<div style=\"text-align: center;\">Table 5: In-depth evaluation of KGIRNet model.</div>\nModels\nIn-Car\nSoccer\nCorr. Human Corr. Human\nMem2Seq 3.09\n3.70\n1.14\n3.48\nGLMP\n3.01\n3.88\n1.10\n2.17\nDialoGPT 2.32\n3.43\n1.32\n3.88\nKGIRNet 3.60\n4.42\n1.59\n3.78\nModels\nIn-Car Dialogues Soccer Dialogues\nBLEU\nEntityF1\nBLEU\nEntityF1\nS2S\n4.96\n10.70\n1.49\n0.0\nS2S BERT\n7.53\n09.10\n1.44\n0.0\nKGIRNet NB 9.52\n29.03\n0.91\n29.85\nKGIRNet NS 11.40\n33.03\n1.05\n28.35\nKGIRNet\n11.76\n32.67\n1.51\n34.32\nModels\nIn-Car\nSoccer\nCorr. Human Corr. Human\nMem2Seq 3.09\n3.70\n1.14\n3.48\nGLMP\n3.01\n3.88\n1.10\n2.17\nDialoGPT 2.32\n3.43\n1.32\n3.88\nKGIRNet 3.60\n4.42\n1.59\n3.78\n(a) Human evaluation.\n# 5.3 Qualitative Analysis\nThe responses generated by KGIRNet are analyzed in this section. Responses from some of the discussed models along with the input query are provided in Table 4 6. We 6In the table (S) and (C) refers to example from Soccer and In-car dataset respectively.\n(b) Ablation study.\ncompare the results with two other state-of-the-art models with the closest evaluation scores, namely Mem2Seq and GLMP. The first two responses are for soccer dialogues, while the latter two are for in-car setting. We inspect that qualitatively the proposed KGIRNet model produces better knowledge grounded and coherent responses in both the settings. In the case of soccer dialogues, predicting single relation in the response is sufficient, while for the case of in-car dialogues, responses can require multiple relation identification. KGIRNet model is able to handle such multiple relations as well (e.g., r:date friday and r:time 11am for the third utterance).\n<div style=\"text-align: center;\">Table 6: Analyzing fact-fullness of KGIRNet.</div>\nInput Query\nTrue Response\nPredicted Response Intermediate Response\nwho is senegal captain ? cheikhou kouyate\nsadio mane is the cap-\ntain of senegal\nr:captain is the captain of\n@entity\nwho is the goalie for ice-\nland ?\nhannes halldorsson\nrunar alex runarsson r goalkeeper\nTo understand more about the advantages of KG grounded generation process, consider the examples from the soccer dataset below in Table 6, in which the model has failed. We have also included the intermediate responses that are generated from the decoder before the KG lookup phase for the reference. In the first case, while constructing the KG, the captain was Sadio Mane, whereas the during the dialogue collection phase the probable captain was Checikhou Kouyate (as per the annotator). These errors on temporal information can easily be tackled using Knowledge Grounded dialogue systems, where the system can potentially reflect current information with updated real world knowledge. For the second case, the current main goalkeeper for the Iceland national football team is Hannes Halld\u00b4orsson; however, R\u00b4unar Alex R\u00b4unarsson is also among the 3 goalkeepers for the team and the model has no additional information to disambiguate between them to produce the same response as the human annotator. KGIRNet is also able to infer conversational context implicitly in dialogues with the system (Table 7).\n<div style=\"text-align: center;\">Table 7: A conversation with KGIRNet.</div>\nUser:\nwhat s the weather forecast for today and tomorrow ?\nKGIRNet:\nwhat city do you want the weather for\nUser:\nlos angeles\nKGIRNet:\nit will be 40f - 60f on monday warm on tuesday windy on wednesday hot on\nthursday\nUser:\nthanks\nKGIRNet:\nyou are welcome\n# 5.4 Error Analysis\nTo analyze more on the shortcomings of our proposed KGIRNet, we stated some sample erroneous responses from the model in Table 8. The first three are from soccer and the rest in-car dialogues. The model often produces generic responses for soccer as in the first example. Our model is only able to handle simple factoid queries and not able to\nanswer queries requiring comparative reasoning such as best player, youngest player etc, as observable from the second and third cases. In the second case, the model answers with the coach\u2019s name and when asked for the best player for Argentina and it replies with the name of an Uruguayan player in the third case. The model also produces generic relations like coach name, number of world cup championship as response when any such keyword is present in the input. For the in-car dataset, the replies are less generic and more coherent; however, in cases like the fourth example, the model is not able to perform logical reasoning (negation). Moreover, the model fails in cases where the input entity is not recognized correctly as in case of the last example. Although, the name of the friend is fetched from the vocabulary, but the predicted entity is wrong hence the model is not able to decode the relation r:address from the KG during decoding. In\n<div style=\"text-align: center;\">Table 8: Error analysis of KGIRNet.</div>\nInput Query\nTrue Response\nPredicted Response\nportugal win the last eurocup ?\nyes they won the last europcup\nportugal has won the world cup.\nwho is switzerland\u00b4s best player ? xherdan shaqiri\npetkovic is the coach of switzerland\nwho is considered their best\nplayer ?\ntraditionally their top scorers.\nluis suarez is the best player in argentina\nwill it be warm in grand rapids on\nsaturday\nit will not be warm in grand rapids on\nsaturday\nit is not predicted to fall on tuesday in\ngrand rapids\nwhere does my friend live ?\ntom lives at 580 van ness ave\ntom s house is located at r:address\ngeneral, the model\u2019s entity detection fails in case of conversations with long dialogue contexts. Incorporating KG information into the entity detection process, where we consider the sub-graph of the entity in the first interaction can potentially help in further performance improvements.\n# 6 Related Work\nLeveraging background information for dialogue system improvement is a well-researched topic, especially in goal-oriented setting [2,9,35]. [12] proposed the in-car dataset which uses a knowledge base for in-car conversation about weather, location etc. Recently, [20] proposed memory-network based encoder-decoder architecture for integrating knowledge into the dialogue generation process on this dataset. Improved models in this task are proposed by [15,36]. [7] proposed a soccer dialogue dataset along with a KGCopy mechanism for non-goal oriented dialogues which are KG-integrated. In a slightly similar research line, in past years, we also notice the use of variational autoencoders (VAE) [40,17] and generative adversarial networks (GANs) [23,18] in dialogue generation. However, knowledge graph based dialogue generation is not well-explored in these approaches. More recently, transformer-based [32] pre-trained models have achieved success in solving various downstream tasks in the field of NLP such as question answering [29] [8], machine translation [34], summarization [11]. Following the trend, a hierarchical transformer is proposed by [28] for task-specific dialogues. The authors experimented on MultiWOZ dataset [5], where the belief states are not available. However, they found\nthe use of hierarchy based transformer models effective in capturing the context and dependencies in task-specific dialogue settings. In a different work, [24] experimented transformer-based model on both the task-specific and non-task specific dialogues in multi-turn setting. In a recent work, [39] investigated on transformer-based model for non-goal oriented dialogue generation in single-turn dialogue setting. Observing the success of transformer-based models over the recurrent models in this paper we also employ BERT in the dialogue generation process which improves the quality of generated dialogues (discussed in section 4 and 5). In past years, there is a lot of focus on encoding graph structure using neural networks, a.k.a. Graph Neural Networks (GNNs) [4,33]. In the field of computer vision, Convolutional Neural Networks (CNNs) are used to extract the most meaningful information from grid-like data structures such as images. A generalization of CNN to graph domain, Graph Convolutional Networks (GCNs) [16] has become popular in the past years. Such architectures are also adapted for encoding and extracting information from knowledge graphs [22]. Following a similar research line, in this paper, we leverage the concept of Graph Laplacian [16] for encoding sub-graph information into the learning mechanism.\n# 7 Conclusion and Future Work\nIn this paper, we have studied the task of generating knowledge grounded dialogues. We bridged the gap between two well-researched topics, namely knowledge grounded question answering and end-to-end dialogue generation. We propose a novel decoding method which leverages pre-trained transformers, KG structure and Graph Laplacian based encoding during the response generation process. Our evaluation shows that out proposed model produces better knowledge grounded response compared to other state-of-the-art approaches, for both the task and non-task oriented dialogues. As future work, we would like to focus on models with better understanding of text in order to perform better KG based reasoning. We also aim to incorporate additional KG structure information in the entity detection method. Further, a better handling of infrequent relations seen during training may be beneficial.\n# Acknowledgement\nWe acknowledge the support of the excellence clusters ScaDS.AI (BmBF IS18026A-F), ML2R (BmBF FKZ 01 15 18038 A/B/C), TAILOR (EU GA 952215) and the projects SPEAKER (BMWi FKZ 01MK20011A) and JOSEPH (Fraunhofer Zukunftsstiftung).\n1. Banerjee, S., Lavie, A.: Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In: Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. pp. 65\u201372 (2005) 2. Bordes, A., Boureau, Y.L., Weston, J.: Learning end-to-end goal-oriented dialog. arXiv preprint arXiv:1605.07683 (2016)\n1. Banerjee, S., Lavie, A.: Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In: Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. pp. 65\u201372 (2005) 2. Bordes, A., Boureau, Y.L., Weston, J.: Learning end-to-end goal-oriented dialog. arXiv preprint arXiv:1605.07683 (2016)\n3. Bordes, A., Usunier, N., Chopra, S., Weston, J.: Large-scale simple question answering with memory networks. ArXiv abs/1506.02075 (2015) 4. Bronstein, M.M., Bruna, J., LeCun, Y., Szlam, A., Vandergheynst, P.: Geometric deep learning: going beyond euclidean data. IEEE Signal Processing Magazine 34(4), 18\u201342 (2017) 5. Budzianowski, P., Wen, T.H., Tseng, B.H., Casanueva, I., Ultes, S., Ramadan, O., Ga\u02c7si\u00b4c, M.: Multiwoz-a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling. arXiv preprint arXiv:1810.00278 (2018) 6. Chakraborty, N., Lukovnikov, D., Maheshwari, G., Trivedi, P., Lehmann, J., Fischer, A.: Introduction to neural network based approaches for question answering over knowledge graphs (2019) 7. Chaudhuri, D., Rony, M.R.A.H., Jordan, S., Lehmann, J.: Using a kg-copy network for nongoal oriented dialogues. In: International Semantic Web Conference. pp. 93\u2013109. Springer (2019) 8. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirectional transformers for language understanding. In: NAACL-HLT (1) (2019) 9. Dhingra, B., Li, L., Li, X., Gao, J., Chen, Y.N., Ahmed, F., Deng, L.: Towards end-to-end reinforcement learning of dialogue agents for information access (2016) 10. Diefenbach, D., Lopez, V., Singh, K., Maret, P.: Core techniques of question answering systems over knowledge bases: a survey. Knowledge and Information systems 55(3), 529\u2013569 (2018) 11. Egonmwan, E., Chali, Y.: Transformer-based model for single documents neural summarization. In: Proceedings of the 3rd Workshop on Neural Generation and Translation. pp. 70\u201379 (2019) 12. Eric, M., Krishnan, L., Charette, F., Manning, C.D.: Key-value retrieval networks for taskoriented dialogue. In: Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue (Aug 2017) 13. Gubichev, A., Then, M.: Graph pattern matching: Do we have to reinvent the wheel? In: Proceedings of Workshop on GRAph Data. ACM (2014) 14. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation 9(8), 1735\u2013 1780 (1997) 15. Kassawat, F., Chaudhuri, D., Lehmann, J.: Incorporating joint embeddings into goal-oriented dialogues with multi-task learning. In: European Semantic Web Conference. pp. 225\u2013239. Springer (2019) 16. Kipf, T.N., Welling, M.: Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016) 17. Li, R., Li, X., Chen, G., Lin, C.: Improving variational autoencoder for text modelling with timestep-wise regularisation. In: Proceedings of the 28th International Conference on Computational Linguistics (Dec 2020) 18. L\u00b4opez Zorrilla, A., De Velasco V\u00b4azquez, M., Torres Bara\u02dcnano, M.I.: A differentiable generative adversarial network for open domain dialogue (2019) 19. Luong, M.T., Pham, H., Manning, C.D.: Effective approaches to attention-based neural machine translation. arXiv preprint arXiv:1508.04025 (2015) 20. Madotto, A., Wu, C.S., Fung, P.: Mem2Seq: Effectively incorporating knowledge bases into end-to-end task-oriented dialog systems. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (Jul 2018) 21. Mohammed, S., Shi, P., Lin, J.: Strong baselines for simple question answering over knowledge graphs with and without neural networks. In: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers) (Jun 2018) 22. Neil, D., Briody, J., Lacoste, A., Sim, A., Creed, P., Saffari, A.: Interpretable graph convolutional neural networks for inference on noisy knowledge graphs (2018)\n23. Olabiyi, O., Salimov, A.O., Khazane, A., Mueller, E.: Multi-turn dialogue response generation in an adversarial learning framework. In: Proceedings of the First Workshop on NLP for Conversational AI (Aug 2019) 24. Oluwatobi, O., Mueller, E.: Dlgnet: A transformer-based model for dialogue response generation. In: Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI. pp. 54\u201362 (2020) 25. Papineni, K., Roukos, S., Ward, T., Zhu, W.J.: Bleu: a method for automatic evaluation of machine translation. In: Proceedings of the 40th annual meeting on association for computational linguistics. pp. 311\u2013318. Association for Computational Linguistics (2002) 26. Petrochuk, M., Zettlemoyer, L.: SimpleQuestions nearly solved: A new upperbound and baseline approach. In: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (Oct-Nov 2018) 27. Rosales-M\u00b4endez, H., Poblete, B., Hogan, A.: What should entity linking link? In: AMW (2018) 28. Santra, B., Anusha, P., Goyal, P.: Hierarchical transformer for task oriented dialog systems. arXiv preprint arXiv:2011.08067 (2020) 29. Shao, T., Guo, Y., Chen, H., Hao, Z.: Transformer-based neural network for answer selection in question answering. IEEE Access 7, 26146\u201326156 (2019) 30. Sharma, S., El Asri, L., Schulz, H., Zumer, J.: Relevance of unsupervised metrics in taskoriented dialogue for evaluating natural language generation. arXiv preprint arXiv:1706.09799 (2017) 31. Tillmann, C., Ney, H.: Word reordering and a dynamic programming beam search algorithm for statistical machine translation. Computational linguistics 29(1), 97\u2013133 (2003) 32. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, \u0141., Polosukhin, I.: Attention is all you need. In: Advances in neural information processing systems. pp. 5998\u20136008 (2017) 33. Veli\u02c7ckovi\u00b4c, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., Bengio, Y.: Graph attention networks. arXiv preprint arXiv:1710.10903 (2017) 34. Wang, Q., Li, B., Xiao, T., Zhu, J., Li, C., Wong, D.F., Chao, L.S.: Learning deep transformer models for machine translation. arXiv preprint arXiv:1906.01787 (2019) 35. Wen, T.H., Vandyke, D., Mrksic, N., Gasic, M., Rojas-Barahona, L.M., Su, P.H., Ultes, S., Young, S.: A network-based end-to-end trainable task-oriented dialogue system. arXiv preprint arXiv:1604.04562 (2016) 36. Wu, C.S., Socher, R., Xiong, C.: Global-to-local memory pointer networks for task-oriented dialogue. arXiv preprint arXiv:1901.04713 (2019) 37. Wu, P., Huang, S., Weng, R., Zheng, Z., Zhang, J., Yan, X., Chen, J.: Learning representation mapping for relation detection in knowledge base question answering. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (Jul 2019) 38. Yu, M., Yin, W., Hasan, K.S., dos Santos, C., Xiang, B., Zhou, B.: Improved neural relation detection for knowledge base question answering. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (Jul 2017) 39. Zhang, Y., Sun, S., Galley, M., Chen, Y.C., Brockett, C., Gao, X., Gao, J., Liu, J., Dolan, B.: Dialogpt: Large-scale generative pre-training for conversational response generation (2019) 40. Zhao, T., Zhao, R., Eskenazi, M.: Learning discourse-level diversity for neural dialog models using conditional variational autoencoders. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (Jul 2017)\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the challenge of generating knowledge grounded responses in dialogue systems, emphasizing the integration of Knowledge Graphs (KGs) into the dialogue generation process. Previous methods have struggled with this integration, highlighting the necessity for a novel approach to enhance dialogue systems.",
        "problem": {
            "definition": "The problem defined in this paper is the difficulty of generating coherent responses in dialogue systems that are grounded in knowledge, particularly when using KGs to inform the generation process.",
            "key obstacle": "A major challenge is the assumption that entities in the input query or relevant sub-graphs of the KG are already known, which complicates the scalability of these systems to real-world applications."
        },
        "idea": {
            "intuition": "The proposed idea stems from the observation that incorporating structured knowledge from KGs can improve the relevance and accuracy of responses in dialogue systems.",
            "opinion": "The idea involves training a BERT model to generate responses by learning to utilize entities and relations from KGs in a multi-task, end-to-end manner.",
            "innovation": "This method distinguishes itself by integrating a graph Laplacian for encoding the k-hop sub-graph of the KG, enhancing the model's ability to generate knowledge grounded responses compared to existing approaches."
        },
        "method": {
            "method name": "KGIRNet",
            "method abbreviation": "KGIRNet",
            "method definition": "KGIRNet is a sequence-to-sequence model that leverages pre-trained transformers and incorporates KG elements to generate responses in dialogue systems.",
            "method description": "The core of KGIRNet involves encoding user queries with a BERT model and generating responses by decoding the learned relationships from the KG.",
            "method steps": [
                "Encode the input query using a pre-trained BERT model.",
                "Detect the core entity in the query.",
                "Pass the encoded representation through an LSTM encoder.",
                "Decode the output using another LSTM decoder while incorporating KG information.",
                "Use graph Laplacian to encode the k-hop sub-graph of the input entity."
            ],
            "principle": "The effectiveness of this method lies in its ability to learn relevant relations from the KG during response generation, allowing for more accurate and contextually relevant outputs."
        },
        "experiments": {
            "evaluation setting": "The evaluation was conducted on two datasets: an in-car dialogue dataset and a soccer dialogues dataset, comparing KGIRNet against several state-of-the-art models.",
            "evaluation method": "Performance was assessed using standard metrics such as BLEU and Entity F1 scores, alongside human evaluations for response quality."
        },
        "conclusion": "The experiments demonstrated that KGIRNet significantly improves knowledge grounded responses compared to existing methods, validating the proposed approach's effectiveness in both goal-oriented and non-goal oriented dialogue settings.",
        "discussion": {
            "advantage": "KGIRNet stands out due to its ability to effectively integrate KG information into the dialogue generation process, resulting in more coherent and contextually relevant responses.",
            "limitation": "The model faces challenges with complex queries requiring inference beyond the explicitly stored relations in the KG.",
            "future work": "Future research will focus on enhancing the model's understanding of text for improved KG-based reasoning and better handling of infrequent relations."
        },
        "other info": {
            "acknowledgement": "The authors acknowledge support from various excellence clusters and projects.",
            "dataset statistics": {
                "in-car dialogues": {
                    "number of triples": 8561,
                    "number of dialogues": 2011
                },
                "soccer dialogues": {
                    "number of triples": 4301,
                    "number of dialogues": 1328
                }
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.2",
            "key information": "This paper addresses the challenge of generating knowledge grounded responses in dialogue systems, emphasizing the integration of Knowledge Graphs (KGs) into the dialogue generation process."
        },
        {
            "section number": "2.1",
            "key information": "The problem defined in this paper is the difficulty of generating coherent responses in dialogue systems that are grounded in knowledge, particularly when using KGs to inform the generation process."
        },
        {
            "section number": "3.1",
            "key information": "KGIRNet is a sequence-to-sequence model that leverages pre-trained transformers and incorporates KG elements to generate responses in dialogue systems."
        },
        {
            "section number": "5.1",
            "key information": "The core of KGIRNet involves encoding user queries with a BERT model and generating responses by decoding the learned relationships from the KG."
        },
        {
            "section number": "6.5",
            "key information": "The experiments demonstrated that KGIRNet significantly improves knowledge grounded responses compared to existing methods, validating the proposed approach's effectiveness in both goal-oriented and non-goal oriented dialogue settings."
        },
        {
            "section number": "7.1",
            "key information": "The model faces challenges with complex queries requiring inference beyond the explicitly stored relations in the KG."
        }
    ],
    "similarity_score": 0.5856557121346729,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-1421_trans/papers/Grounding Dialogue Systems via Knowledge Graph Aware Decoding with Pre-trained Transformers.json"
}