{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1808.05075",
    "title": "Multi-feature Fusion for Image Retrieval Using Constrained Dominant Sets",
    "abstract": "Aggregating different image features for image retrieval has recently shown its effectiveness. While highly effective, though, the question of how to uplift the impact of the best features for a specific query image persists as an open computer vision problem. In this paper, we propose a computationally efficient approach to fuse several hand-crafted and deep features, based on the probabilistic distribution of a given membership score of a constrained cluster in an unsupervised manner. First, we introduce an incremental nearest neighbor (NN) selection method, whereby we dynamically select k-NN to the query. We then build several graphs from the obtained NN sets and employ constrained dominant sets (CDS) on each graph G to assign edge weights which consider the intrinsic manifold structure of the graph, and detect false matches to the query. Finally, we elaborate the computation of feature positive-impact weight (PIW) based on the dispersive degree of the characteristics vector. To this end, we exploit the entropy of a cluster membership-score distribution. In addition, the final NN set bypasses a heuristic voting scheme. Experiments on several retrieval benchmark datasets show that our method can improve the state-of-the-art result. Keywords: Image retrieval, multi-feature fusion, diffusion process. ]  15 Aug 2018",
    "bib_name": "alemu2018multifeaturefusionimageretrieval",
    "md_text": "# Multi-feature Fusion for Image Retrieval Using Constrained Dominant Sets\nAlemu Leulseged Tesfayea,\u2217, Marcello Pelilloa,b\naDAIS, Ca\u2019 foscari University of Venice, Via Torino 155, Mestre, Venezia, Italy bECLT, European Center for Living Technology, S. Marco 2940, 30124 Venezia, Italy\n# Abstract\nAggregating different image features for image retrieval has recently shown its effectiveness. While highly effective, though, the question of how to uplift the impact of the best features for a specific query image persists as an open computer vision problem. In this paper, we propose a computationally efficient approach to fuse several hand-crafted and deep features, based on the probabilistic distribution of a given membership score of a constrained cluster in an unsupervised manner. First, we introduce an incremental nearest neighbor (NN) selection method, whereby we dynamically select k-NN to the query. We then build several graphs from the obtained NN sets and employ constrained dominant sets (CDS) on each graph G to assign edge weights which consider the intrinsic manifold structure of the graph, and detect false matches to the query. Finally, we elaborate the computation of feature positive-impact weight (PIW) based on the dispersive degree of the characteristics vector. To this end, we exploit the entropy of a cluster membership-score distribution. In addition, the final NN set bypasses a heuristic voting scheme. Experiments on several retrieval benchmark datasets show that our method can improve the state-of-the-art result. Keywords: Image retrieval, multi-feature fusion, diffusion process. ]  15 Aug 2018\nThe goal of semantic image search, or content-based image retrieval (CBIR), is to search for a query image from a given image dataset. This is done by computing image similarities based on low-level image features, such as color, texture, shape and spatial relationship of images. Variation of images in illumination, rotation, and orientation has remained a major challenge for CBIR. Scaleinvariant feature transform (SIFT) [1] based local feature such as Bag of words (BOW) [2], [3], [4], has served as a backbone for most image retrieval processes. Nonetheless, due to the inefficiency of using only a local feature to describe the content of an image, local-global feature fusion has recently been introduced. Multi-feature based CBIR attacks the CBIR problem by introducing an approach which utilizes multiple lowlevel visual features of an image. Intuitively, if the to-befused feature works well by itself, it is expected that its aggregation with other features will improve the accuracy of the retrieval. Nevertheless, it is quite hard to learn in advance the effectiveness of the to-be-fused features for a specific query image. Different methods have recently been proposed to tackle this problem [5], [6], [7]. Zhang et al. [6] developed a graph-based query specific fusion method, whereby local and global rank lists are merged with equal weight by conducting a link analysis on a fused graph. arXiv:1808.05075v1  [c\n\u2217Corresponding author Email address: leulseged.alemu@unive.it (Alemu Leulseged Tesfaye) Preprint submitted to Elsevier\n\u2217Corresponding author Email address: leulseged.alemu@unive.it (Alemu Leulseged Tesfaye)\nPreprint submitted to Elsevier\nZheng et al. [7] proposed a score level fusion model called Query Adaptive Late Fusion (QALF) [7], in which, by approximating a score curve tail with a reference collected on irrelevant data, they able to estimate the effectiveness of a feature as negatively related to the area under the normalized curve. Yang et al. [5] used a mixture Markov model to combine given graphs into one. Unlike [6] where graphs are equally weighted, [5] proposed a method to compute a weight which quantifies the usefulness of the given graph based on a naive Bayesian formulation, which depends only on the statistics of image similarity scores. However, existing multi-feature fusion methods have different drawbacks. For instance, [7], [6], [8], [9] heavily rely on a pre-calculated and offline stored data, which turns out to be computationally expensive when new images are constantly added to the dataset. On the other hand, Ensemble Diffusion (ED)[10] requires O(n3) to perform a similarity diffusion. In addition to that, its featureweight computation approach is not a query specific. Inspired by [7], in this work we present a novel and simple CBIR method based on a recently introduced constrained cluster notion. Our approach presents two main advantages. Firstly, compared to the state of the art methods, it can robustly quantify the effectiveness of features for a specific query, without any supervision. Secondly, by diffusing the pairwise similarity between the nearest neighbors, our model can easily avoid the inclusion of false positive matches in the final shortlist. Towards this end, we first dynamically collect the nearest neighbors to the query, therefore, for each feature, we will have a different number\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ec66/ec6697a4-adb9-47a0-aab8-a3afc2e02b93.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: Overview of the proposed image retrieval framework. Based on the given features, F1, F2, ...Fn, we first incrementally collect the NN\u2032s to the query Q, denoted as NN1, NN2, ...NNn. Next, for each NN we build the corresponding graph G\u2032 1, G\u2032 2, ...G\u2032 n, and then, we apply CDS on each graph to learn the PIW of each feature, PIW1, PIW2, ...PIWn, in the subsequent plot, the blue and red curves depict the ranked score of NN\u2019s before and after the application of CDS, respectively. Following, the final candidates, which come from each feature, pass through a voting scheme. Finally, using the obtained votes and PIW\u2019s we compute the final similarity, Fsim(Q, D), between the query and the dataset images by equ. 10 .</div>\nof NNs. Subsequently, we set up the problem as finding a cluster from the obtained NNs, which is constrained to contain the given query image. To this end, we employ a graph-theoretic method called constrained dominant sets [11]. Here is our assumption: if the nearest neighbor to the query image is a false match, after the application of CDS its membership score to the resulting constrained cluster should be less than the fixed threshold \u03b6, which leads us to detect and exclude the outliers. Furthermore, we introduce the application of entropy to quantify the effectiveness of the given features based on the obtained membership score. In contrast to [7], our method does not need any reference or external information to learn a query specific feature-weight. Fig. 1 shows the pipline of the proposed method. In particular, we make the following contributions. 1) Compared to the previous work [6], [7], we propose a simple but efficient entropy-based feature effectiveness weighting system; in addition to that, we demonstrate an effective way of outlier or false nearest neighbor detection method. 2) Most importantly, our proposed model is a generic approach, which can be adapted to distinct computer vision problems, such as object detection and person re-identification. 3) We show that our unsupervised graph fusion model easily alleviates the asymmetry neighborhood problem. This paper is structured as follows. In section 2 we briefly survey literature relevant to our problem, followed by technical details of the proposed approach in Sec. 3.\nAnd, in Sec. 4 we show the performance of our framewo on different benchmark datasets.\n# 2. Related Work\nCBIR has become a well-established research topic in the computer vision community. The introduction of SIFT feature plays a vital role in the application of BOW model on the image retrieval problem. Particularly, its robustness in dealing with the variation of images in scale, translation, and rotation provide a significant improvement in the accuracy of similar image search. Sivic et al. [2] first proposed BOW-based image retrieval method by using SIFT, in that, local features of an image are quantized to visual words. Since then, CBIR has made a remarkable progress by incorporating k-reciprocal neighbor [12], query expansion [13], [12], [14], large visual codebook [15], [16], diffusion process [5] [17] and spacial verification [15]. Furthermore, several methods, which consider a compact representation of an image to decrease the memory requirement and boost the search efficiency have been proposed. Jegou et al. [18] developed a Vector of Locally Aggregated Descriptor(VLAD), whereby the residuals belonging to each of the codewords are accumulated. While SIFT-based local features have considerably improved the result of image search, it does not leverage the discriminative information encoded in the global feature of an image, for instance, the color feature yields a better representation for smooth images. This motivates the\nintroduction of multiple feature fusion for image retrieval. In [6], a graph-based query specific fusion model has been proposed, in which multiple graphs are combined and reranked by conducting a link analysis on a fused graph. Following, [5] developed a re-ranking algorithm by fusing multi-feature information, whereby they apply a locally constrained diffusion process (LCDP) on the localized NNs to obtain a consistent similarity score. Although the aggregation of handcrafted local and globa features has shown promising results, the advent of a seminal work by A.Krizhevsky et al. [19] in 2012 changed the focus of the computer vision community. Since then, convolutional neural network (CNN) feature has been used as a main holistic cue in different computer vision problems, including CBIR. Despite its significant improvement on the result of image retrieval, CNN feature still can not endow the demanded accuracy on different benchmark retrieval datasets, especially without the use of fine-tuning. Thus, aggregating graphs which are built from a handengineered and CNN-based image features has shown improvement in the accuracy of the retrieval [2], [18], [20], [21], [22], [23]. In addition to that, Yang et al. [5] applied a diffusion process to understand the intrinsic manifold structure of the fused graph. Despite a significant improvement on the result, employing the diffusion process on the final (fused) graph restricts the use of the information which is encoded in the pairwise similarity of the individual graph. Instead, our proposed framework applies CDS on each graph which is built from the corresponding feature. Thus, we are able to propagate the pairwise similarity score throughout the graph. Thereby, we exploit the underutilized pairwise similarity information of each feature and alleviate the negative impact of the inherent asymmetry of a neighborhood.\n# 3. Proposed Method\n# 3.1. Incremental NN Selection\nIn this subsection, we show an incremental nearest neighbor collection method to the given query image. We start with an intuitive clustering concept that similar nodes with common features should have an approximate score distribution, while outliers, or nodes which do not belong to a similar semantic class, have different score values. Accordingly, we propose a technique to search for the transition point where our algorithm starts including the outlier nodes. To this end, we examine how distinctive two subsequent nodes are in a ranked list of neighbors. Thus, we define a criterion called neighbors proximity coefficient(NPC), which is defined as the ratio of two consecutive NNs in the given ranked list. Therefore, images are added only if the specified criterion is met, which is designed in such a way that only images that are very likely to be similar to the query image are added. Thereby, we are able to decrease the number of false matches to the query in the k-nearest neighbors set.\nGiven an initial ranked list R. And then, we define top-k nearest neighbors (kNN) to query Q as\n(1)\nwhere |kNN(q, k)| = k, and |.| represents the cardinality of a set.\nkNN(q, k) = {n1, n2, ...nk}, where kNN(q, k) \u2286R\n(2)\n# 3.2. Graph Construction\nDifferent features, F = F1, F2...Fn, are extracted from images in the dataset D and the query image Q, where each feature encodes discriminative information of the given image in different aspects. We then compute the distance between the given images based on a distance metric function d\u2032(Ii, Ij), where Ii and Ij denote the given feature vector extracted from image i and j respectively. Following, we compute symmetric affinity matrices A\u2032 1, A\u2032 2, . . . A\u2032 n from each distance matrix Di using a similarity function S(Di). We then apply minimax normalization on each similarity matrix as: Ai = V ij \u03b1 \u2212min(V\u03b1) max(V\u03b1)\u2212min(V\u03b1), where V\u03b1 is a column vector taken from matrix A\u2032 i, which comprises the pairwise similarity score between a given image V i \u03b1 and images in the dataset V j, which is denoted as V ij \u03b1 . Next, we build undirected edge-weighted graphs with no self-loops G1, G2...Gn from the affinity matrices A1, A2, ...An, respectively. Each graph Gn is defined as Gn = (Vn, En, wn), where Vn = 1, ..., n is vertex set, En \u2286 Vn \u00d7 Vn is the edge set, and wn : E \u2212\u2192IR\u2217 + is the (positive) weight function. Vertices in G correspond to the given images, edges represent neighborhood relationships, and edge-weights reflect similarity between pairs of linked vertices.\n# 3.3. PIW Using Entropy of CDS\nSince the nearest neighbor selection method heavily relies on the initial pairwise similarity, it is possible that the NN set easily includes false matches to the given query. This usually happens due to the lack of technics which consider the underlying structure of the data manifold, especially the inherent asymmetry of a neighborhood is a major shortcoming of such systems. For instance, although Sim(ni, q) = Sim(q, ni), the nearest neighbor relationship between query Q and image ni may not be symmetric, which implies that mi \u2208kNN(q, k) but mi /\u2208 kNN(ni, k). As demonstrated in the past retrieval works, the k-reciprocal neighbors [12] and similarity diffusion process [24] have been vastly taken as the optimal options to tackle this issue. However, the existing methods are not computationally efficient. In this work, we remedy the existing limitations using an unsupervised constrained clustering algorithm whereby we exploit the pairwise similarity\nto find a cohesive cluster which incorporates the specified query.\n3.3.1. Constrained Clustering for Coherent Neighbor Se-\nTowards collecting true matches to the query image, we employ an unsupervised clustering algorithm on the top of the previous steps. Our hypothesis to tackle the asymmetry problem between the given query and its nearest neighbors is that images which are semantically similar to each other tend to be clustered in some feature space. As can be seen in the synthetic example (See Fig. 2), retrieved image i4 and i6 are outliers or false positives to the query image Q. We can confirm this by observing the common neighbors of Q with i4 and i6. But due to the lack of contextual information, the system considers them as a true match (neighbor) to the query. In our proposed model, to attack this issue, we represent the set of kNN as a graph G\u2032 accordingly to subsection 3.2. Then, we treat outliers finding problem as an unsupervised clustering problem. We first convert graph G\u2032 into a symmetric affinity matrix A, where the diagonal corresponding to each node is set to 0, and the ij \u2212th entry denotes the edge-weight wij of the graph so that Aij \u2261Aji. Accordingly, given graph G\u2032 and query Q, we cast detecting outliers from a given NN set as finding the most compact and coherent cluster from graph G\u2032, which is constrained to contain the query image Q. To this end, we adopt constrained dominant sets [11], [25], which is a generalization of a well known graphtheoretic notion of a cluster. We are given a symmetric affinity matrix A and parameter \u00b5 > 0, and then we define the following parametrized quadratic program\nwhere a prime denotes transposition and\n\u2206= \ufffd X \u2208Rn : n \ufffd i=1 Xi = 1, and Xi \u22650 for all i = 1 . . . n\n\u2206is the standard simplex of Rn. \u02c6\u0393Q represents n \u00d7 n diagonal matrix whose diagonal elements are set to zero in correspondence to the query Q and to 1 otherwise. And \u02c6A is defined as,\n\uf8ed \uf8f8 where the dots denote the ij th entry of matrix A. Note that matrix \u02c6A is scaled properly to avoid negative values. Let Q \u2286V, with Q \u0338= \u2205and let \u00b5 > \u03bbmax(AV \\Q), where \u03bbmax(AV \\q) is the largest eigenvalue of the principal submatrix of A indexed by the element of V \\q. If X is a\nlocal maximizer of f \u00b5 Q(X) in \u2206, then \u03b4(X)\u2229Q \u0338= \u2205, where, \u03b4(X) = i \u2208V : Xi > 0. We refer the reader to [11] for the proof. The above result provides us with a simple technique to determine a constrained dominant set which contains the query vertex Q. Indeed, if Q is the vertex corresponding the query image, by setting\n(4)\n \\ we are guaranted that all local solutions of eq (3) will have a support that necessarily contains the query element. The established correspondence between dominant set (coherent cluster) and local extrema of a quadratic form over the standard simplex allow us to find a dominant set using straightforward continuous optimization techniques known as replicator dynamics, a class of dynamical systems arising in evolutionary game theory [21]. The obtained solution provides a principled measure of a cluster cohesiveness as well as a measure of vertex participation. Hence, we show that by fixing an appropriate threshold \u03b6 on the membership score of vertices, to extract the coherent cluster, we could easily be able to detect the outlier nodes from the k-nearest neighbors set. For each Xi, \u03b6i is dynamically computed as\n(5)\nwhere max(X) and min(X) denote the maximum and minimum membership score of Xi, respectively. \u039b is a scaling parameter and L stands for length of Xi. Moreover, we show an effective technique to quantify the usefulness of the given features based on the dispersive degree of the obtained characteristics vector X.\n# 3.3.2. PIW Using Entropy of Constrained Cluster.\n\ufffd Entropy has been successfully utilized in a variety of computer vision applications, including object detection [26], image retrieval [27] and visual tracking [28]. In this paper, we exploit the entropy of a membership-score of nodes in the constrained dominant set to quantify the usefulness of the given features. To this end, we borrowed the concept of entropy in the sense of information theory (Shannon entropy). We claim that the discriminative power of a given feature is inversely proportional to the entropy of the score distribution, where the score distribution is a stochastic vector. Let us say we are given a random variable C with possible values c1, c2, ...cn, according to statistical point of view the information of the event (C = ci) is inversely proportional to its likelihood, which is denoted by I(Ci) and defined as\n(6)\n\ufffd \ufffd Thus, as stated by [29], the entropy of C is the expected value of I, which is given as\n(7)\nFor each characteristic vector Xi, Xi+1...Xz, where Xi = \ufffd Xi \u00b5, Xi \u00b5+1...Xi n \ufffd , we compute the entropy H(exp(Xi)). Eac Xi corresponds to the membership score of nodes in the CDS, which is obtained from the given feature F i. Assume that the top NNs obtained from feature x are irrelevant to the query Q, thus the resulting CDS will only contain the constraint element Q. Based on our previous claim, since the entropy of a singleton set is 0, we can infer that the feature is highly discriminative. Although this conclusion is right, assigning a large weight to feature with irrelevant NNs will have a negative impact on the final similarity. To avoid such unintended impact, we consider the extreme case where the entropy is 0. Following, we introduce a new term Ca, which is obtained from the cardinality of a given cluster, Kc, as Cai = Ki c \ufffdz i=1 Kic . As a result, we formulate the PIW computation from the additive inverse of the entropy \u03b5i = 1 \u2212H(Xi), and Ci a, as:\n(8)\n\ufffd where \u03d1i = \u03b5i + Ci a, and i represents the corresponding feature.\n# 3.4. Naive Voting Scheme and Similarity Fusion\nIn this section, we introduce a simple yet effective voting scheme, which is based on the member nodes of knearest neighbor sets and the constrained dominant sets, let NN1, NN2...NNz and CDS1, CDS2...CDSz represent the NN and CDS sets respectively, which are obtained from G\u2032 1, G\u2032 2...G\u2032 z. Let us say \u03be = 2(z \u22121)\u22121, and then we build \u03be different combinations of NN sets, \u03d51, \u03d52...\u03d5\u03be. Each \u03d5 represents an intersection between z \u22121 unique combinations of NN sets. We then form a super-set \u03d6 which contains the union of \u03d5 sets, with including repeated nodes. Assume that NNs = {NN1, NN2, NN3}, \u03be = 3, thus each \u03d5 set contains the intersection of two NN sets as \u03d51 = {NN1 \u2229NN2}, \u03d52 = {NN1 \u2229NN3} and \u03d53 = {NN2 \u2229NN3}. Hence the resulting \u03d6 is defined as \u03d6 = (\u03d51 \u2296\u03d52 \u2296\u03d53), where (.\u2296.) is an operator which returns the union of given sets, including repeated nodes. We have also collected the union of CDS sets as \u03c9 = (CDS1 \u2296CDS2 \u2296CDS3). Following, we compute \u03ba as (\u03ba = \u03d51 \u2229\u03d52 \u2229...\u03d5\u03be). Thereby we find super-sets \u03d6, \u03c9 and \u03ba. Next, we design three different counters, which are formulated to increment when the NN node appears in the corresponding super-sets. Based on the value obtained from each counter, we finally compute the vote scores for each NN node to the query as v1 = v1/\u03b7, v2 = v2/\u03b8 and v3 = v3/\u03b9, where \u03b7, \u03b8 and \u03b9 are parameters which are fixed empirically. Note that the outlier detecting capability of our framework is encoded in the voting process. Thus, if a NN node ni is contained in more than one cluster, its probability to be given a large weight is higher. This is due to the number of votes it gets from each cluster.\n# 3.4.1. Final Similarity.\nAfter obtaining the aforementioned terms, we compute the final similarity as follows: say we are given n features, Q is the query image and D denotes image dataset, then the initial similarity of D to Q, with respect to feature Fi, i = 1...n, ,is given as S(i) D,Q. Let PIW (i) Q , i = 1...n, encode the weight of feature Fi for query Q, and then the final similarity score, Fsim(Q,D), between Q and D is given as\n(9)\n(10)\n\ufffd where \u03a8 = 3, is the total number of voter sets. And \u03bb \u2208[0, 1] defines the penalty factor which penalizes the similarity fusion, when \u03bb = 1 only Fs is considered, otherwise, if \u03bb = 0, only v is considered.\n# 4. Experiments\nIn this section, we present the details about the features, datasets and evaluation methodology we used along with rigorous experimental analysis.\n# 4.1. Datasets and Metrics\nTo provide a thorough evaluation and comparison, we evaluate our approach on INRIA Holiday, Ukbench, Oxford5k and Paris6k datasets. Ukbench Dataset [30]. Contains 10,200 images which are categorized into 2,550 groups, each group consists of three similar images to the query which undergo severe illumination and pose variations. Every image in this dataset is used as a query image in turn while the remaining images are considered as dataset images, in \u201cleaveone-out\u201d fashion. As customary, we used the N-S score to evaluate the performance of our method, which is based on the average recall of the top 4 ranked images. INRIA Holiday Dataset [31]. Comprises 1491 personal holiday pictures including 500 query images, where most of the queries have one or two relevant images. Mean average precision (MAP) is used as a performance evaluation metric. Oxford5k Dataset [15]. It is one of the most popular retrieval datasets, which contains 5062 images, collected from flicker-images by searching for landmark buildings in the Oxford campus. 55 queries corresponding to 11 buildings are used. Paris6k Dataset [32]. Consists of 6392 images of Paris landmark buildings with 55 query images that are manually annotated.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bcd7/bcd7964c-077c-490c-bcb8-d07db82155e5.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d28e/d28e6d14-0433-464d-907c-13cc5b1e2b52.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">NN to the Query (Q</div>\n<div style=\"text-align: center;\">2: (a) Initial score distribution of the top k nearest neighbors to the query Q, green and red points denote the false-negative and setive NNs. (b) Graph G\u2032, built from the initial pairwise similarity of the k-nearest neighbor set. And the blue box contains the CDS which are obtained by running CDS on graph G\u2032. (c) The resulting constrained dominant set membership-score distribution.</div>\nFigure 2: (a) Initial score distribution of the top k nearest neighbors to the query Q, green and red points denote the false-negative and false-posetive NNs. (b) Graph G\u2032, built from the initial pairwise similarity of the k-nearest neighbor set. And the blue box contains the CDS nodes which are obtained by running CDS on graph G\u2032. (c) The resulting constrained dominant set membership-score distribution.\nObject Level Deep Feature Pooling (OLDFP)[33] OLDFP is a compact image representation, whereby images are represented as a vector of pooled CNN features describing the underlying objects. Principal Component Analysis (PCA) has been employed to reduce the dimensionality of the compact representation. We consider the top 512-dimensional vector in the case of the Holiday datase while considering the top 1024-dimensional vector to describe images in the Ukbench dataset. As suggested in [33], we have applied power normalization (with exponent 0.5), and l2 normalization on the PCA projected image descriptor. BOW. Following [34], [7], we adopt Hamming Embedding [31]. SIFT descriptor and Hessian-Affine detector are used in feature extraction, and we used 128-bit vector binary signatures of SIFT. The Hamming threshold and weighting parameters are set to 30 and 16 respectively, and three visual words are provided for each key-point. Flickr60k data [31] is used to train a codebook of size 20k. We also adopt root sift as in [35], average IDF as defined in [36] and the burstiness weighting [37]. NetVLAD [38]. NetVLAD is an end-to-end trainable CNN architecture that incorporates the generalized VLAD layer. HSV Color Histogram. Like [5], [7], for each image, we extract 1000-dimensional HSV color histograms where the number of bins for H, S, V are 20, 10, 5 respectively.\n# 4.3. Experiment on Holiday and Ukbench Datasets\nAs it can be seen in Fig.3(a), the noticeable similarity between the query image and the irrelevant images, in the Holiday dataset, makes the retrieval process challenging. For instance, (See Fig.3(a)), at a glance all images seem similar to the query image while the relevant are only the first two ranked images. Moreover, we can observe that\nthe proposed scheme is invariant to image illumination and rotation change. Table 2 shows that our method significantly improves the MAP of the baseline method [33] on Holiday dataset by 7.3 % while improving the state-ofthe-art method by 1.1 %. Likewise, it can be seen that our method considerably improves the N-S score of the baseline method [33] on the Ukbench dataset by 0.15 while improving the state-of-the-art method by 0.03. Furthermore, to show how effective the proposed feature weighting system is, we have experimented by fusing the given features with and without PIW. Naive fusion (NF) denotes our approach with a constant PIW for all features used, thus the final similarity Fs defined as Fs = 1 k(\ufffdk i=1(S(i) D,Q)). In Fig.6 we have demonstrated the remarkable impact of the proposed PIW. As can be observed, our scheme effectively uplifts the impact of a discriminative feature while downgrading the inferior one. Note that in the PIW computation we have normalized the minimum entropy (See eq.8), thus its values range between 0 and 1. Accordingly, one implies that the feature is highly discriminative, while zero shows that the feature is indiscriminate. In order to demonstrate that our scheme is robust in handling outliers, we have conducted an experiment by fixing the number of NNs (disabling the incrimental NNs selection) to different numbers. As is evident from Fig.6, the performance of our method is consistent regardless of the number of kNN. As elaborated in subsection 3.3.1, the robustness of our method to the number of k comes from the proposed outlier detection method. Since the proposed outliers detector is formulated in a way that allows us to handle the outliers, we are easily able to alleviate the false matches which are incorporated in the nearest neighbors set. This results in finding a nearly constant number of nearest neighbors regardless of the choice of k.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e028/e0284bb7-0b7e-45cc-b153-26bfb310af65.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4568/45687780-6e00-418d-9da8-74f096a9326f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4698/46983315-7e35-48e5-8e35-07c356fe70fe.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/dba2/dba25e85-264c-4a8c-85c3-e49a27e9a302.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Feature positive-impact weights (PIW\u2019s) learned by our algorithm. Top-left, top-ri Ukbench, Oxford5k and Paris6k datasets, respectively.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d934/d9346c63-e65c-4f06-aa17-394a04b1f95e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f469/f469c8cf-be4f-4ef7-adad-2e85f0c3b06c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Table 1: The performance of baseline features on Holidays, Ukbench, Oxford5k and Paris6k datasets.</div>\nDatasets\nMetrics\nNetVLAD [38]\nBOW\nOLDFP\nHSV\nRres[24]\nGres[24]\nRvgg [24]\nGvgg[24]\nHolidays\nMAP\n84\n80\n87\n65\n-\n-\n-\n-\nUkbench\nN-S score\n3.75\n3.58\n3.79\n3.19\n-\n-\n-\nOxford5k\nMAP\n69\n-\n-\n-\n95.8\n87.7\n93\n-\nParis6k\nMAP\n-\n-\n-\n-\n96.8\n94.1\n96.4\n95.6\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1315/1315a42c-be68-43a3-b21f-a180a3770c3b.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 5: The cardinality of constrained dominant sets for the given feature</div>\n# 4.4. Experiment on Oxford5k and Paris6k Datasets\nIn the same fashion as the previous analysis, we have conducted extensive experiments on the widely used Oxford5k and Paris6k datasets. Unlike the Holiday and Ukbench datasets, we adapt affinity matrices which are obtained through a diffusion process on a regional Resnet and V GG representation [24], and they are denoted as Rres and Rvgg respectively, as well as affinity matrices Gres and Gvgg which are also obtained through a diffusion process on a global Resnet and V GG representation, respectively. Table 2 shows that the proposed method slightly improves the state-of-the-art result. Even if the performance gain is not significant, our scheme marginally achieves better MAP over the state-of-the-art methods. Furthermore, as shown in Fig 4, the proposed model learns the PIW of the given features effectively. Therefore, a smaller average weight is assigned to Gvgg and NetV LAD feature comparing to Rres and Rvgg.\n4.5. Robustness of Proposed PIW As can be seen in Fig 4, for all datasets, our algorithm has efficiently learned the appropriate weights to the corresponding features. Fig. 4 shows how our algorithm assigns PIW in a query adaptive manner. In Holiday and Ukbench datasets, the average weight given to HSV feature is much smaller than all the other features used. Conversely, a large PIW is assigned to OLDFP and NetVLAD features. Nevertheless, it is evident that in some cases a large value of PIW is assigned to HSV and BOW features as well, which is appreciated considering its effectiveness on discriminating good and bad features in a query adaptive manner.\n# 4.6. Impact of Parameters\nTo evaluate the robustness of our method we have performed different experiments by changing one parameter at a time. Thereby, we have observed that setting \u039b to a large value results in assigning insignificant PIW to indiscriminate features. The reason is that after the application of CDS, the cluster membership-score of the dissimilar\n<div style=\"text-align: center;\">Table 2: Comparison among various retrieval methods with our method on benchmark datasets, where QALF is implemented w he same baseline similarities used in our experiments.</div>\n<div style=\"text-align: center;\">able 2: Comparison among various retrieval methods with our method on benchmark datasets, where QALF is implemente he same baseline similarities used in our experiments.</div>\n same baseline similarities used in our experiments.\nDatasets\nMetrics\nBaselines\nQALF[7]\n[5]\nNF\nED[39]\n[40]\n[41]\n[42]\n[43]\nOurs\nUkbench\nN-S score\n3.79[33]\n3.84\n3.86\n3.86\n3.93\n-\n-\n-\n3.76\n3.94\nHoliday\nMAP\n87[33]\n88\n88\n91\n93\n90\n83\n89\n77\n94\nOxford5k\nMAP\n95.8[24]\n-\n76.2\n94.4\n-\n89.1\n79.7\n81.4\n67.6\n96.2\nParis6k\nMAP\n96.8[24]\n-\n83.3\n-\n-\n91.2\n83.8\n88.9\n-\n97.4\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5e58/5e588c12-7e07-4e09-bd3e-ddebd528b3b4.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 6: Comparison with state-of-the-art fusion methods with respect to varying k. Naive Fusio (RMFD) [5], and QALF [7].</div>\n<div style=\"text-align: center;\">gure 6: Comparison with state-of-the-art fusion methods with respect to varying k. Naive Fusion (NF), Reranking by Multi-feature Fusion MFD) [5], and QALF [7].</div>\nimages to the query will become smaller. Thus, since the threshold fixed to choose the true neighbors is tighter, the resulting constrained dominant set will be forced to yield a singleton cluster. As a result, we obtained a very small PIW due to the cardinality of the constrained-cluster. In addition to that, we observe that the MAP start to decline when \u03bb is set to a very large value (See. Fig 7, right).\n# 4.7. Impact of Cluster Cardinality\nOn the Ukbench dataset, as can be observed in Fig. 5, the average cardinality of the constrained clusters which is obtained from HSV and BOW feature is 3 and 1.7, respectively. In contrast, for NetVLAD and OLDFP, the average cluster cardinality is 3.4 and 3.5, respectively . Similarly, in the case of the Holiday dataset, the cluster cardinality obtained from HSV feature is one while for BOW, NetVLAD and OLDFP is 4.5, 5 and 5.6, respectively. Thus, from this, we can draw our conclusion that the cardinality of a constrained dominant set, in a certain condition, has a direct relationship with the effectiveness of the given feature.\n# 4.8. Computational Time\nIn Fig. 7 we depict the query time taken to search for each query image, red and blue lines represent our method and QALF, respectively. The vertical axis denotes the CPU time taken in seconds, and the horizontal axis shows the query images. As can be seen from the plot, the proposed framework is faster than the fastest state-of-the-art feature-fusion method [7]. As for time complexity, in our experiment we used a replicator dynamics to solve problem\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/99fb/99fbe6dd-f5d4-4db4-b1b5-0cbc38cccbd0.png\" style=\"width: 50%;\"></div>\n(3), hence, for a graph with N nodes, the time complexity per step is O(N 2), and the algorithm usually takes a few steps to converge, while that of [10] is O(N 3). However, we note that by using the Infection-immunization algorithm [44] we can achieve even faster convergence as its per-step complexity would be linear in the number of nodes.\n# 5. Conclusion\nIn this paper, we addressed a multi-feature fusion problem in CBIR. We developed a novel and computationally efficient CBIR method based on a constrained-clustering concept. In particular, we showed an efficient way of estimating a positive impact weight of features in a queryspecific manner. Thus it can be readily used for feature combination. Furthermore, the proposed scheme is fully unsupervised, and can easily be able to detect falsepositive NNs to the query, through the diffused similarity of the NNs. To demonstrate the validity of our method, we performed extensive experiments on benchmark datasets. Besides the improvements achieved on the state-of-the-art results, our method shows its effectiveness in quantifying the discriminative power of given features. Moreover, its effectiveness on feature-weighting can also be exploited in other computer vision problems, such as person reidentification, object detection, and image segmentation.\n# References\n# References References\n# References\n[1] D. G. Lowe, Distinctive image features from scale-invariant keypoints, International Journal of Computer Vision 60 (2) (2004)\n[1] D. G. Lowe, Distinctive image features from scale-invariant keypoints, International Journal of Computer Vision 60 (2) (2004)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b38c/b38ca4f8-771d-424a-84aa-2f3dbb1b6afb.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6967/69671455-90d2-4f56-a48f-742b923345ef.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Queries</div>\nFigure 7: Left: Time complexity of our algorithm (red) and QALF[7] (blue) on Holiday data performance, on Holiday dataset.\n91\u2013110. [2] J. Sivic, A. Zisserman, Video google: A text retrieval approach to object matching in videos, in: 9th IEEE International Conference on Computer Vision (ICCV 2003), 14-17 October 2003, Nice, France, 2003, pp. 1470\u20131477. [3] M. Jain, R. Benmokhtar, H. J\u00b4egou, P. Gros, embedding similarity-based image classification, in: International Conference on Multimedia Retrieval, ICMR \u201912, Hong Kong, China, June 5-8, 2012, 2012, p. 19. [4] Y. Yang, F. Nie, D. Xu, J. Luo, Y. Zhuang, Y. Pan, A multimedia retrieval framework based on semi-supervised ranking and relevance feedback, IEEE Trans. Pattern Anal. Mach. Intell. 34 (4) (2012) 723\u2013742. [5] F. Yang, B. Matei, L. S. Davis, Re-ranking by multi-feature fusion with diffusion for image retrieval, in: 2015 IEEE Winter Conference on Applications of Computer Vision, WACV 2015, Waikoloa, HI, USA, January 5-9, 2015, 2015, pp. 572\u2013579. [6] S. Zhang, M. Yang, T. Cour, K. Yu, D. N. Metaxas, Query specific rank fusion for image retrieval, IEEE, Trans. Pattern Anal. Mach. Intell. 37 (4) (2015) 803\u2013815. [7] L. Zheng, S. Wang, L. Tian, F. He, Z. Liu, Q. Tian, Query-adaptive late fusion for image search and person reidentification, in: IEEE, CVPR, 2015, pp. 1741\u20131750. [8] C. Deng, R. Ji, W. Liu, D. Tao, X. Gao, Visual reranking through weakly supervised multi-graph learning, in: IEEE International Conference on Computer Vision, ICCV 2013, Sydney, Australia, December 1-8, 2013, 2013, pp. 2600\u20132607. [9] S. Zhang, M. Yang, X. Wang, Y. Lin, Q. Tian, Semantic-aware co-indexing for image retrieval, in: IEEE International Conference on Computer Vision, ICCV 2013, Sydney, Australia, December 1-8, 2013, 2013, pp. 1673\u20131680. 10] S. Bai, Z. Zhou, J. Wang, X. Bai, L. J. Latecki, Q. Tian, Ensemble diffusion for retrieval, in: IEEE International Conference on Computer Vision, ICCV 2017, Venice, Italy, October 22-29, 2017, 2017, pp. 774\u2013783. 11] E. Zemene, M. Pelillo, Interactive image segmentation using constrained dominant sets, in: Computer Vision - ECCV 2016 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VIII, 2016, pp. 278\u2013294. 12] D. Qin, S. Gammeter, L. Bossard, T. Quack, L. J. V. Gool, Hello neighbor: Accurate object retrieval with k-reciprocal nearest neighbors, in: 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2011), 2011, pp. 777\u2013784. 13] O. Chum, A. Mikul\u00b4\u0131k, M. Perdoch, J. Matas, Total recall II: query expansion revisited, in: The 24th IEEE Conference on\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/95e6/95e61aad-5335-4479-94e6-001dc79d1da2.png\" style=\"width: 50%;\"></div>\nComputer Vision and Pattern Recognition, CVPR, Colorado Springs, CO, USA, 20-25 June 2011, 2011, pp. 889\u2013896. [14] G. Tolias, H. J\u00b4egou, Visual query expansion with or without geometry: Refining local descriptors by feature aggregation, Pattern Recognition 47 (10) (2014) 3466\u20133476. [15] J. Philbin, O. Chum, M. Isard, J. Sivic, A. Zisserman, Object retrieval with large vocabularies and fast spatial matching, in: 2007 IEEE Computer Society Conference on Computer Vision and Pattern Recognition CVPR, 18-23 June 2007, Minneapolis, Minnesota, USA, 2007. [16] Y. S. Avrithis, Y. Kalantidis, Approximate gaussian mixtures for large scale vocabularies, in: Computer Vision - ECCV 2012 12th European Conference on Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part III, 2012, pp. 15\u201328. [17] E. Zemene, L. T. Alemu, M. Pelillo, Constrained dominant sets for retrieval, in: 23rd International Conference on Pattern Recognition, ICPR 2016, Canc\u00b4un, Mexico, December 4-8, 2016, 2016, pp. 2568\u20132573. [18] H. J\u00b4egou, F. Perronnin, M. Douze, J. S\u00b4anchez, P. P\u00b4erez, C. Schmid, Aggregating local image descriptors into compact codes, IEEE Trans. Pattern Anal. Mach. Intell. 34 (9) (2012) 1704\u20131716. [19] A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classification with deep convolutional neural networks, in: NIPSAdvances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States., 2012, pp. 1106\u20131114. [20] F. Perronnin, C. R. Dance, Fisher kernels on visual vocabularies for image categorization, in: 2007 IEEE Computer Society Conference on Computer Vision and Pattern Recognition CVPR, 18-23 June 2007, Minneapolis, Minnesota, USA, 2007. [21] H. J\u00b4egou, A. Zisserman, Triangulation embedding and democratic aggregation for image search, in: 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR, Columbus, OH, USA, June 23-28, 2014, pp. 3310\u20133317. [22] T. Do, Q. D. Tran, N. Cheung, Faemb: A function approximation-based embedding method for image retrieval, in: IEEE Conference on Computer Vision and Pattern Recognition, CVPR , Boston, MA, USA, June 7-12, 2015, 2015, pp. 3556\u2013 3564. [23] Y. Kalantidis, C. Mellina, S. Osindero, Cross-dimensional weighting for aggregated deep convolutional features, in: Computer Vision - ECCV 2016 Workshops - Amsterdam, The Netherlands, October 8-10 and 15-16, 2016, Proceedings, Part I, 2016, pp. 685\u2013701.\n[24] A. Iscen, G. Tolias, Y. S. Avrithis, T. Furon, O. Chum, Efficient diffusion on region manifolds: Recovering small objects with compact CNN representations, in: 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR, Honolulu, HI, USA, July 21-26, 2017, 2017, pp. 926\u2013935. [25] E. Zemene, L. T. Alemu, M. Pelillo, Dominant sets for \u201dconstrained\u201d image segmentation, CoRR abs/1707.05309. [26] R. Sznitman, C. J. Becker, F. Fleuret, P. Fua, Fast object detection with entropy-driven evaluation, in: 2013 IEEE Conference on Computer Vision and Pattern Recognition, Portland CVPR, OR, USA, June 23-28, 2013, 2013, pp. 3270\u20133277. [27] T. Deselaers, T. Weyand, H. Ney, Image retrieval and annotation using maximum entropy, in: Evaluation of Multilingual and Multi-modal Information Retrieval, 7th Workshop of the Cross-Language Evaluation Forum, CLEF 2006, Alicante, Spain, September 20-22, 2006, Revised Selected Papers, 2006, pp. 725\u2013734. [28] L. Ma, J. Lu, J. Feng, J. Zhou, Multiple feature fusion via weighted entropy for visual tracking, in: 2015 IEEE International Conference on Computer Vision, ICCV 2015, Santiago, Chile, December 7-13, 2015, 2015, pp. 3128\u20133136. [29] Shannon, A mathematical theory of communication., Bell Syst. Tech. J. (1948) 27, 379423. [30] D. Nist\u00b4er, H. Stew\u00b4enius, Scalable recognition with a vocabulary tree, in: 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition CVPR, 17-22 June 2006, New York, NY, USA, 2006, pp. 2161\u20132168. [31] H. Jegou, M. Douze, C. Schmid, Hamming embedding and weak geometric consistency for large scale image search, in: Computer Vision - ECCV 2008, 10th European Conference on Computer Vision, Marseille, France, October 12-18, 2008, Proceedings, Part I, 2008, pp. 304\u2013317. [32] J. Philbin, O. Chum, M. Isard, J. Sivic, A. Zisserman, Lost in quantization: Improving particular object retrieval in large scale image databases, in: 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition CVPR, 24-26 June 2008, Anchorage, Alaska, USA, 2008. [33] K. R. Mopuri, R. V. Babu, Object level deep feature pooling for compact image representation, in: 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops, Boston, MA, USA, June 7-12, 2015, 2015, pp. 62\u2013 70. [34] L. Zheng, S. Wang, Z. Liu, Q. Tian, Packing and padding: Coupled multi-index for accurate image retrieval, in: 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR, Columbus, OH, USA, June 23-28, 2014, 2014, pp. 1947\u20131954. [35] R. Arandjelovic, A. Zisserman, Three things everyone should know to improve object retrieval, in: 2012 IEEE Conference on Computer Vision and Pattern Recognition, Providence, RI, USA, June 16-21, 2012, 2012, pp. 2911\u20132918. [36] L. Zheng, S. Wang, Z. Liu, Q. Tian, Lp-norm IDF for large scale image search, in: 2013 IEEE Conference on Computer Vision and Pattern Recognition, Portland CVPR, OR, USA, June 2328, 2013, 2013, pp. 1626\u20131633. [37] H. Jegou, M. Douze, C. Schmid, On the burstiness of visual elements, in: 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition CVPR, 20-25 June 2009, Miami, Florida, USA, 2009, pp. 1169\u20131176. [38] R. Arandjelovic, P. Gron\u00b4at, A. Torii, T. Pajdla, J. Sivic, Netvlad: CNN architecture for weakly supervised place recognition, in: 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR, Las Vegas, NV, USA, June 27-30, 2016, 2016, pp. 5297\u20135307. [39] S. Bai, Z. Zhou, J. Wang, X. Bai, L. J. Latecki, Q. Tian, Ensemble diffusion for retrieval, in: IEEE International Conference on Computer Vision, ICCV 2017, Venice, Italy, October 22-29, 2017, 2017, pp. 774\u2013783. [40] A. Gordo, J. Almaz\u00b4an, J. Revaud, D. Larlus, Deep image retrieval: Learning global representations for image search, in: Computer Vision - ECCV 2016 - 14th European Conference,\nAmsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VI, 2016, pp. 241\u2013257. [41] F. Radenovic, G. Tolias, O. Chum, CNN image retrieval learns from bow: Unsupervised fine-tuning with hard examples, in: Computer Vision - ECCV 2016 - 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part I, 2016, pp. 3\u201320. [42] J. Xu, C. Shi, C. Qi, C. Wang, B. Xiao, Part-based weighting aggregation of deep convolutional features for image retrieval, CoRR abs/1705.01247. [43] A. Babenko, A. Slesarev, A. Chigorin, V. S. Lempitsky, Neural codes for image retrieval, in: Computer Vision - ECCV 2014 - 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I, 2014, pp. 584\u2013599. [44] S. Rota Bul`o, M. Pelillo, I. M. Bomze, Graph-based quadratic optimization: A fast evolutionary approach, Computer Vision and Image Understanding 115 (7) (2011) 984\u2013995.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the multi-feature fusion problem in content-based image retrieval (CBIR), highlighting the limitations of existing methods that rely on pre-calculated data and are computationally expensive. Previous approaches, such as local-global feature fusion, have shown effectiveness, but the challenge remains in determining the best features for specific queries.",
        "problem": {
            "definition": "The problem is to enhance the effectiveness of image retrieval systems by efficiently fusing multiple image features to improve similarity assessments for specific query images.",
            "key obstacle": "Existing methods struggle to dynamically assess the effectiveness of features for specific queries, leading to high computational costs and the inclusion of false matches."
        },
        "idea": {
            "intuition": "The proposed idea is inspired by the need to dynamically assess and enhance the impact of various features in image retrieval based on their effectiveness for specific queries.",
            "opinion": "The paper introduces a novel method that fuses both hand-crafted and deep features using a probabilistic approach, allowing for unsupervised assessment of feature effectiveness.",
            "innovation": "The primary innovation lies in the use of constrained dominant sets (CDS) to dynamically weight features based on their impact and to detect false matches, improving upon traditional methods that lack query-specific adaptability."
        },
        "method": {
            "method name": "Multi-feature Fusion for Image Retrieval Using Constrained Dominant Sets",
            "method abbreviation": "MF-CDS",
            "method definition": "This method fuses multiple image features based on a constrained clustering approach to improve the accuracy of image retrieval.",
            "method description": "The method incrementally selects nearest neighbors and employs constrained dominant sets to assign weights to features based on their positive impact.",
            "method steps": [
                "1. Incrementally select k-nearest neighbors to the query image.",
                "2. Construct graphs from the selected nearest neighbors.",
                "3. Apply constrained dominant sets to detect false matches and assign feature weights.",
                "4. Compute the final similarity score using the feature weights."
            ],
            "principle": "The method is effective because it leverages the intrinsic structure of the data manifold, allowing for more accurate identification of relevant features while filtering out false positives."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted on benchmark datasets including INRIA Holiday, Ukbench, Oxford5k, and Paris6k, comparing the proposed method against state-of-the-art techniques.",
            "evaluation method": "Performance was measured using metrics such as Mean Average Precision (MAP) and N-S scores, assessing the accuracy of retrieved images based on the proposed method's feature weighting."
        },
        "conclusion": "The proposed method demonstrates significant improvements in image retrieval performance over existing state-of-the-art methods, effectively quantifying feature discriminative power and detecting false positives in an unsupervised manner.",
        "discussion": {
            "advantage": "Key advantages include the ability to dynamically assess feature effectiveness for specific queries, leading to improved retrieval accuracy and reduced computational costs.",
            "limitation": "The method may still face challenges in scenarios with highly similar images or when the quality of extracted features is low.",
            "future work": "Future research could explore further enhancements in feature weighting algorithms and their applications in other areas of computer vision, such as object detection and segmentation."
        },
        "other info": [
            {
                "info1": "The method is fully unsupervised and adaptable to various computer vision tasks.",
                "info2": {
                    "info2.1": "The proposed framework is computationally efficient compared to existing methods.",
                    "info2.2": "Extensive experiments validate the effectiveness of the method across multiple datasets."
                }
            }
        ]
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The foundational idea behind semi-supervised algorithms is to leverage both labeled and unlabeled data to enhance learning outcomes, similar to the proposed method that fuses multiple image features to improve retrieval effectiveness."
        },
        {
            "section number": "1.2",
            "key information": "The motivation behind the development of the proposed method is to address the limitations of existing methods in content-based image retrieval, which struggle with computational costs and false matches."
        },
        {
            "section number": "3.5",
            "key information": "The paper introduces a novel method called Multi-feature Fusion for Image Retrieval Using Constrained Dominant Sets (MF-CDS), which dynamically assesses feature effectiveness for specific queries."
        },
        {
            "section number": "4.1",
            "key information": "The importance of data labeling in the context of the proposed method is reflected in its ability to dynamically weight features based on their positive impact, which is crucial for effective image retrieval."
        },
        {
            "section number": "7.1",
            "key information": "Challenges in scalability and computational complexity are addressed by the proposed method, which is designed to be computationally efficient compared to existing techniques."
        },
        {
            "section number": "7.3",
            "key information": "The proposed method's approach to dynamically weighting features can be seen as a strategy for effectively integrating unlabeled data in the learning process, enhancing the retrieval accuracy."
        },
        {
            "section number": "8",
            "key information": "The conclusion highlights that the proposed method demonstrates significant improvements in image retrieval performance, emphasizing the potential of semi-supervised learning to enhance accuracy by utilizing both labeled and unlabeled data."
        }
    ],
    "similarity_score": 0.579898149184968,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-2055_semi-/papers/Multi-feature Fusion for Image Retrieval Using Constrained Dominant Sets.json"
}