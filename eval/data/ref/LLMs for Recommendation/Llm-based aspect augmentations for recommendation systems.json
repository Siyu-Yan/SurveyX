{
    "from": "google",
    "scholar_id": "R9MG59lTm9gJ",
    "detail_id": null,
    "title": "Llm-based aspect augmentations for recommendation systems",
    "abstract": " Abstract\n\nLarge language models (LLMs) have shown to be effective in different task settings, including recommendation-related tasks. In this study, we aim at measuring the effectiveness of using item aspects (justifications for users\u2019 intentions when buying the item) generated by LLMs in improving the results for ranking tasks. For this purpose, we carefully design prompts for LLMs to derive aspects for items using their textual data in an eCommerce setting. The extracted aspects are used as augmentations for Learning-to-Rank models. Specifically, we input the generated aspects as summarized embeddings using three approaches: (i) augmenting using feature concatenation, (ii) adding a wide aspect component beside a deep component of features, and (iii) adding an aspect embedding tower to create a two-tower model. We conduct extensive experiments on real-world eCommerce dataset and show the effectiveness of including LLM-based aspects in improving ranking metrics such as MRR and NDCG, even when they are compared to models augmented by pretrained language models (PLM).\n\n# 1. Introduction and Background\n\nConditional ranking task in eCommerce settings is referred to recommendation framework where there exist a set of items which act as the reference or conditions for recommendation (Hou et al., 2023b). For instance, in sequential recommendation setting, the user-item interaction sequence acts as the reference for recommendation (Yan et al., 2019; Song et al., 2021), or in item-pages of eCommerce, the main item of the page (see figure 1) acts as the reference for recommendation (Maragheh et al., 2022).\n\n* Equal contribution 1 Walmart Global Tech, Sunnyvale, CA, USA. Correspondence to: Reza Yousefi Maragheh <reza.yousefimaragheh@walmart.com>, Lalitesh Morishetti <lalitesh.morishetti@walmart.com>.\n\nWorkshop on Challenges in Deployable Generative AI at International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA. 2023. Copyright 2023 by the author(s).\n\nWorksho",
    "bib_name": "maragheh2023llm",
    "md_text": "# ugmentations for Recommendation Sy\n\n# LLM-Based Aspect Augmentations for Recommendation Systems\n\nReza Yousefi Maragheh * 1 Lalitesh Morishetti * 1 Ramin Giahi 1 Kaushiki Nag 1\nJianpeng Xu 1 Jaosn Cho 1 Evren Korpeoglu 1 Sushant Kumar 1 Kannan Achan 1\n\n# Abstract\n\nLarge language models (LLMs) have shown to be effective in different task settings, including recommendation-related tasks. In this study, we aim at measuring the effectiveness of using item aspects (justifications for users\u2019 intentions when buying the item) generated by LLMs in improving the results for ranking tasks. For this purpose, we carefully design prompts for LLMs to derive aspects for items using their textual data in an eCommerce setting. The extracted aspects are used as augmentations for Learning-to-Rank models. Specifically, we input the generated aspects as summarized embeddings using three approaches: (i) augmenting using feature concatenation, (ii) adding a wide aspect component beside a deep component of features, and (iii) adding an aspect embedding tower to create a two-tower model. We conduct extensive experiments on real-world eCommerce dataset and show the effectiveness of including LLM-based aspects in improving ranking metrics such as MRR and NDCG, even when they are compared to models augmented by pretrained language models (PLM).\n\n# 1. Introduction and Background\n\nConditional ranking task in eCommerce settings is referred to recommendation framework where there exist a set of items which act as the reference or conditions for recommendation (Hou et al., 2023b). For instance, in sequential recommendation setting, the user-item interaction sequence acts as the reference for recommendation (Yan et al., 2019; Song et al., 2021), or in item-pages of eCommerce, the main item of the page (see figure 1) acts as the reference for recommendation (Maragheh et al., 2022).\n\n* Equal contribution 1 Walmart Global Tech, Sunnyvale, CA, USA. Correspondence to: Reza Yousefi Maragheh <reza.yousefimaragheh@walmart.com>, Lalitesh Morishetti <lalitesh.morishetti@walmart.com>.\n\nWorkshop on Challenges in Deployable Generative AI at International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA. 2023. Copyright 2023 by the author(s).\n\nWorkshop on Challenges in Deployable Generative AI at International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA. 2023. Copyright 2023 by the author(s).\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6c3a/6c3a5552-b8ae-47cf-b405-00ff8179b3aa.png\" style=\"width: 50%;\"></div>\nFigure 1.  Conditional ranking task is one of the core tasks in eCommerce platforms. The recommendation module depicted in the picture aims at recommending items that are relevant to the main item of the page.\n\n<div style=\"text-align: center;\">Figure 1.  Conditional ranking task is one of the core tasks in eCommerce platforms. The recommendation module depicted in the picture aims at recommending items that are relevant to the main item of the page.\n</div>\nIn these cases, deriving aspects or justifications for users\u2019 interests is crucial in improving recommendations. These justifications extract relevant keywords about the user behavior and aim at attaining the users\u2019 intentions (Ni et al., 2019). For instance, when parents are looking for toys for their children, they maybe interested in \u201ceducational\u201d aspect of the toy, or its \u201cdurability\u201d. In this case, a recommendation system which is aware of the item aspects influencing user behavior will be more accurate in detecting the relevant items for the user.\nHowever, most of the existing models for retrieval tasks are \u201cnarrow experts\u201d(Guo et al., 2020), which are extremely domain oriented with task-specific objectives, and hence lack the capability of using common-sense universal knowledge such as aspects (Hou et al., 2023a).\nPre-trained Language Models (PLM) try to alleviate this issue by transferring the rich world knowledge from the universe of web textual data to better understand users\u2019 behavior and preferences (Hou et al., 2023a; 2022). Similarly, LLMs have shown excellent capabilities in common-sense reasoning and utilizing background knowledge in a variety of tasks.\nVery recently, LLMs have shown promising results in recom\n\nIn these cases, deriving aspects or justifications for users\u2019 interests is crucial in improving recommendations. These justifications extract relevant keywords about the user behavior and aim at attaining the users\u2019 intentions (Ni et al., 2019). For instance, when parents are looking for toys for their children, they maybe interested in \u201ceducational\u201d aspect of the toy, or its \u201cdurability\u201d. In this case, a recommendation system which is aware of the item aspects influencing user behavior will be more accurate in detecting the relevant items for the user.\n\nPre-trained Language Models (PLM) try to alleviate this issue by transferring the rich world knowledge from the universe of web textual data to better understand users\u2019 behavior and preferences (Hou et al., 2023a; 2022). Similarly, LLMs have shown excellent capabilities in common-sense reasoning and utilizing background knowledge in a variety of tasks.\nVery recently, LLMs have shown promising results in recom\n\nmendation settings, specifically in zero-shot and few-shot learning for sequential recommendation (see Wang & Lim 2023; Gao et al. 2023; Wang et al. 2023; Zhang et al. 2023) and knowledge-graph completion (see Chen et al. 2023). Most of the work in this area focuses on carefully designing prompts by explicitly inputting examples and measuring the effectiveness of LLM\u2019s outputs in ranking or knowledge graph completion.\nIn this work, instead of using LLMs in zero-shot or few-shot ranking settings, we aim to use aspects generated by LLMs to improve the performance of existing Learing-to-Ranking (LtR) architectures. More specifically, using the associated textual data for each item, we generate aspects describing the items to better understand the intentions underlying the users\u2019 behavior for choosing that item. Then, we use these aspects to augment the inputs to LtR models. Our experiments on real-world data sets show that considering these aspects in some of the widely used state-of-the-art models can improve ranking metrics such as MRR and NDCG.\n\n# 2. LLM-Based Aspect Generation\n\nIn this section, we review the aspect generation framework. Then, we show how the instructions are designed as prompt inputs to LLM, and how the aspects are parsed from the output.\n\n# 2.1. Item Aspect Generation\n\nIn the item aspect generation, given the textual data corpora, we are interested in generating aspects why potential customers like an item using LLMs for extractive summarization. Formally, given an input of textual data for item i, D i, we are interested in generating k aspects A i = {a (1) i, . . . , a (k) i} for users\u2019 potential interest in this item.\n\nWe generate the aspects using Google\u2019s PaLM2 (see Anil et al. 2023). To enable this LLM and to derive aspects for the items, we specially designed the prompt by including textual information and defining explicit response structure to the prompt. The textual information is composed by the concatenation of the item description and the user\u2019s positive reviews. Defining explicit response structure helps in output parsing and makes LLM understand the expected output structure. To this end, we start the prompt with phrase \u201cSummarize the following reviews in three adjectives. Reply in this format: relevant tags for this product are [first adjective, second adjective, third adjective]:\u201d and then input the concatenated description and reviews (See figure 2).\nAfter generating all aspects for the items, we find the union\n\nAfter generating all aspects for the items, we find the union of all the aspects as the aspects\u2019 universe A. Then, we construct the item-aspect binary matrix. Depending on the\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/898a/898ade43-3f53-4e84-bf08-9e1c50f7e694.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2. Desinged prompts for aspect generation using PaLM2.\n</div>\ngenerated number of aspects for each product, k, and the similarity of items, this matrix can be sparse. To generate aspect embeddings, we perform a dimensionality reduction using layer.embedding function of TensorFlow (Abadi et al., 2015). These reduced vectors will be inputted into the augmentation architectures of the ranking models.\n\n# 2.2. Parsing the Output\n\nThe outputs of LLM are generated in an array format as designed in the prompt input. In our experiments, PaLM2 hallucinates for some of the prompts and starts the reply with irrelevant phrases. For instance, this is one of the generated responses by PaLM2: so it will grow with her. The push bar is also a nice feature. Relevant tags for this product are [sturdy, durable, classic]. However, in these cases, the response ends with the expected array reply.\nAlso, in some cases and for some items, PaLM2 returns an empty string (approximately for 5% of the prompts). We consider these as errors and do not input any aspects of the items. Parsing is done by considering the expected array format for each output.\n\n# 3. Models\n\nAs mentioned, the generated aspect embeddings are augmented with the item\u2019s features. We test three augmentation architectures to better understand how to use aspect embeddings in ranking tasks.\nNote that this paper focuses on conditional ranking settings, where we are given an anchor item that acts as a recommendation reference and a candidate set of items selected accordingly. The conditional ranking task aims at ranking the more relevant items to the anchor/reference item in the\n\ntop positions.\n\n# 3.1. LLM-Based Aspect Augmentation Models\n\nWe use three architectures to augment the generated aspect embeddings with other dense features/embeddings.\n\n3.1.1. E MBEDDING C ONCATENATION\n\nA baseline approach for augmenting the aspect embeddings with other dense features is to concatenate the aspects with other dense features and pass them through an MLP (see Part (a) of Figure 3). In this case, one may measure the higher-order interaction of the aspects with other features. We denote this model by \u201cAug-Concat\u201d.\n\n3.1.2. W IDE AND D EEP A UGMENTATION\n\n# 3.1.2. W IDE AND D EEP A UGMENTATION\n\nWe also test augmenting the aspects in a wide and deep format proposed by (Cheng et al., 2016) (see part (b) of Figure 3). In this case, the aspect embeddings are inputted to the wide part, and other dense features are inputted to the deep part of the architecture. This may alleviate the non-homogeneity issue of the concatenation embeddings from two different latent spaces of aspect embeddings and other features/embeddings. Also, using this architecture, one can measure the linear effect of each aspect dimension on the item\u2019s scores. We denote this model by \u201cAug-WD\u201d.\n\n3.1.3. T OWER A UGMENTATION\n\nTwo-tower architecture (see Yang et al. 2020) is proposed to combine two different spaces like user and item embeddings, and generate a more unified concatenation of the embeddings. Inspired by user embedding augmentation, we also check the performance of this model when the aspect embeddings are input to one of the towers while other features are input to the other MLP tower (see part (C) of Figure 3). We denote this model by \u201cAug-2T\u201d.\n\n3.1.4. L OSS ON A RCHITECTURES\n\nTo be comprehensive, we also employed three different loss functions on top of each of the architectures. We use ListMLE (Chen et al., 2009), pairwise-cross-entropy (Boudiaf et al., 2020), and NDCG (Mohapatra et al., 2018) loss functions, when fitting the architectures. We add a suffix of \u201c-LMLE\u201d, \u201c-PCE\u201d, and \u201c-NDCG\u201d to denote the ListMLE, pairwise-cross-entropy, and NDCG loss used in each architecture.\n\n# 4. Empirical Results\n\nIn this section, we investigate whether generating LLMbased aspects and using them in settings like anchor-based recommendation can help improve ranking metrics. Spe\n\ncially, we study the performance of Aug-Concat, Aug-WD, and Aug-2T combined with -MLE, -PCE, and -NDCG loss functions. We consider two benchmark models: (i) a regular Feed-Forward Neural Net (FFNN) with dense feature inputs, and (ii) FFNN with a Pre-training Language Model (PLM) embeddings (see Cer et al. 2018) concatenated with other dense features which we denote by PLM-FFNN. Like the augmentation architecture, we use three aforementioned loss functions on top of the embeddings generated by these benchmark architectures as well.\nIn our experimentation, we consider the concatenation of item description and item reviews to be the textual data and generate three aspects using PaLM2 for each item.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ee07/ee07a53b-8e27-46a4-8b67-824cff5e032a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3. Augmentation Architectures\n</div>\n# 4.1. Data\n\nWe use a user-item interaction proprietary data set obtained from an eCommerce platform for our empirical validations. For the homogeneity of aspects generated by PaLM2, we restrict the items to be randomly selected only from the Toys&Games category.\n\nModel\nNDCG@5\nNDCG@10\nMRR@5\nMRR@10\nFFNN-MLE\n0.3750\n0.4710\n0.3229\n0.3582\nFFNN-PCE\n0.3803\n0.4775\n0.3303\n0.3649\nFFNN-NDCG\n0.3800\n0.4768\n0.3297\n0.3645\nPLM-FFNN-MLE\n0.3727\n0.4747\n0.3261\n0.3588\nPLM-FFNN-PCE\n0.3942\n0.4918\n0.3420\n0.3775\nPLM-FFNN-NDCG\n0.3872\n0.4861\n0.3351\n0.3710\nAug-Concat-MLE\n0.4029\n0.5044\n0.3525\n0.3868\nAug-Concat-PCE\n0.4280\n0.5191\n0.3700\n0.4027\nAug-Concat-NDCG\n0.4259\n0.5174\n0.3690\n0.4019\nAug-WD-MLE\n0.4005\n0.4976\n0.3440\n0.3790\nAug-WD-PCE\n0.4151\n0.5086\n0.3571\n0.3908\nAug-WD-NDCG\n0.4169\n0.5101\n0.3591\n0.3927\nAug-2T-MLE\n0.4059\n0.5017\n0.3485\n0.3830\nAug-2T-PCE\n0.4179\n0.5109\n0.3598\n0.3932\nAug-2T-NDCG\n0.4170\n0.5102\n0.3592\n0.3928\nThe data set includes 174k users and 139k item samples from user activity sessions from March 2023 to May 2023. The data include features like interaction history features (e.g. number of transactions in the last 30 days), general item features (e.g. item price, average rating), and textual features.\n\n# 4.2. Aspects Generation\n\nThe overall number of uniquely generated aspects is 5,550 for about 139,000 items. Figure 4 shows the log frequency of generated aspects per item by our prompting approach. We observe that the generated aspects have the long-tail property. While some aspects are repeated for many items, most of the aspects are unique to a small number of items. About 80% of the aspects are assigned to less than ten items.\n\n# 4.3. Results\n\nThe results are presented in Table 1. Comparing the performance between the FFNN model with augmented versions, we observe that all augmented models perform better than those only using the dense features. This justifies the effectiveness of applying feature augmentation techniques. The improvement of PLM augmented models is marginal compared with that using the LLM-based aspect augmentations. This indicates that implicit aspects, especially those from LLM, might provide more information and hence be important for building the ranking models. Across all augmented models, augmenting the LtR architectures with LLM-based aspect embeddings lead to the best performance in ranking metrics, which might be due to the larger number of parameters of this model. Note that in our architecture design, the hidden layers have the same dimensions within each MLP tower (for each MLP tower, we considered two layers with\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e510/e510ad18-5b41-42dd-9bbc-cbee4fea7f4e.png\" style=\"width: 50%;\"></div>\nFigure 4. Log-Frequency of Aspects per Items. The number under each bar shows the number of aspects with at least that many items having those aspects.\n\n# 5. Conclusion\n\nUsing LLMs has depicted promising results in various domains as they can potentially carry common-sense knowledge obtained from the body of the web\u2019s textual data. In this paper, we investigate the capability of LLMs in generating aspects for item recommendation to extract user intention keywords from user interaction data. We design a prompting approach to generate aspects from item descriptions and user reviews. Our experiments show that the generated aspects have long-tail property, and most aspects are unique to a small number of items. In our extensive experimentation, we use these aspects to generate embeddings and input them to ranking models of interest. More specifically, we test the performance of three augmentation approaches: (i) augmenting using feature concatenation, (ii) adding a wide aspect component beside a deep component of features, and (iii) aspect embedding tower augmentation.\n\nOur experiments confirm that augmenting the ranking architectures using LLM-based aspects leads to an increase in relevancy metrics like MRR and NDCG, hence showing their capability to better describe the user choice behavior. We speculate that the reason for this improvement is due to using user intention keywords extracted from item description and user reviews. Also, our results indicate that augmenting using the feature concatenation approach attains higher relevancy scores when compared to other approaches.\n\n# References\n\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Man \u00b4 e, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., Vi \u00b4 egas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke, M., Yu, Y., and Zheng, X. TensorFlow: Largescale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/. Software available from tensorflow.org.\nAnil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., et al. Palm 2 technical report. arXiv preprint arXiv:2305.10403, 2023.\nBoudiaf, M., Rony, J., Ziko, I. M., Granger, E., Pedersoli, M., Piantanida, P., and Ayed, I. B. Metric learning: cross-entropy vs. pairwise losses. arXiv preprint arXiv:2003.08983, 2020.\nCer, D., Yang, Y., Kong, S.-y., Hua, N., Limtiaco, N., John, R. S., Constant, N., Guajardo-Cespedes, M., Yuan, S., Tar, C., et al. Universal sentence encoder. arXiv preprint arXiv:1803.11175, 2018.\nChen, J., Ma, L., Li, X., Thakurdesai, N., Xu, J., Cho, J. H., Nag, K., Korpeoglu, E., Kumar, S., and Achan, K. Knowledge graph completion models are few-shot learners: An empirical study of relation labeling in ecommerce with llms. arXiv preprint arXiv:2305.09858, 2023.\nChen, W., Liu, T.-Y., Lan, Y., Ma, Z.-M., and Li, H. Ranking measures and loss functions in learning to rank. Advances in Neural Information Processing Systems, 22, 2009.\nCheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H., Anderson, G., Corrado, G., Chai, W., Ispir, M., et al. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems, pp. 7\u201310, 2016.\n\nbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Man \u00b4 e, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., Vi \u00b4 egas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke, M., Yu, Y., and Zheng, X. TensorFlow: Largescale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/. Software available from tensorflow.org.\n\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Man \u00b4 e, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., Vi \u00b4 egas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke, M., Yu, Y., and Zheng, X. TensorFlow: Largescale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/. Software available from tensorflow.org.\nAnil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., et al. Palm 2 technical report. arXiv preprint arXiv:2305.10403, 2023.\nBoudiaf, M., Rony, J., Ziko, I. M., Granger, E., Pedersoli, M., Piantanida, P., and Ayed, I. B. Metric learning: cross-entropy vs. pairwise losses. arXiv preprint arXiv:2003.08983, 2020.\nCer, D., Yang, Y., Kong, S.-y., Hua, N., Limtiaco, N., John, R. S., Constant, N., Guajardo-Cespedes, M., Yuan, S., Tar, C., et al. Universal sentence encoder. arXiv preprint arXiv:1803.11175, 2018.\nChen, J., Ma, L., Li, X., Thakurdesai, N., Xu, J., Cho, J. H., Nag, K., Korpeoglu, E., Kumar, S., and Achan, K. Knowledge graph completion models are few-shot learners: An empirical study of relation labeling in ecommerce with llms. arXiv preprint arXiv:2305.09858, 2023.\nChen, W., Liu, T.-Y., Lan, Y., Ma, Z.-M., and Li, H. Ranking measures and loss functions in learning to rank. Advances in Neural Information Processing Systems, 22, 2009.\nCheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H., Anderson, G., Corrado, G., Chai, W., Ispir, M., et al. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems, pp. 7\u201310, 2016.\n\nCheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H., Anderson, G., Corrado, G., Chai, W., Ispir, M., et al. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems, pp. 7\u201310, 2016.\n\nGao, Y., Sheng, T., Xiang, Y., Xiong, Y., Wang, H., and Zhang, J. Chat-rec: Towards interactive and explainable llms-augmented recommender system. arXiv preprint arXiv:2303.14524, 2023.\nGuo, Q., Zhuang, F., Qin, C., Zhu, H., Xie, X., Xiong, H., and He, Q. A survey on knowledge graph-based recommender systems. IEEE Transactions on Knowledge and Data Engineering, 34(8):3549\u20133568, 2020.\nHou, Y., Mu, S., Zhao, W. X., Li, Y., Ding, B., and Wen, J.-R. Towards universal sequence representation learning for recommender systems. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pp. 585\u2013593, 2022.\nHou, Y., He, Z., McAuley, J., and Zhao, W. X. Learning vector-quantized item representation for transferable sequential recommenders. In Proceedings of the ACM Web Conference 2023, pp. 1162\u20131171, 2023a.\nHou, Y., Zhang, J., Lin, Z., Lu, H., Xie, R., McAuley, J., and Zhao, W. X. Large language models are zeroshot rankers for recommender systems. arXiv preprint arXiv:2305.08845, 2023b.\nMaragheh, R. Y., Giahi, R., Xu, J., Morishetti, L., Vashishtha, S., Nag, K., Cho, J., Korpeoglu, E., Kumar, S., and Achan, K. Prospect-net: Top-k retrieval problem using prospect theory. In  2022 IEEE International Conference on Big Data (Big Data), pp. 3945\u20133951. IEEE, 2022.\nMohapatra, P., Rolinek, M., Jawahar, C., Kolmogorov, V., and Kumar, M. P. Efficient optimization for rank-based loss functions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3693\u2013 3701, 2018.\nNi, J., Li, J., and McAuley, J. Justifying recommendations using distantly-labeled reviews and fine-grained aspects. In  Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP), pp. 188\u2013197, 2019.\nSong, W., Wang, S., Wang, Y., and Wang, S. Next-item recommendations in short sessions. In Proceedings of the 15th ACM Conference on Recommender Systems, pp. 282\u2013291, 2021.\nWang, L. and Lim, E.-P. Zero-shot next-item recommendation using large pretrained language models. arXiv preprint arXiv:2304.03153, 2023.\nWang, W., Lin, X., Feng, F., He, X., and Chua, T.-S. Generative recommendation: Towards next-generation recommender paradigm. arXiv preprint arXiv:2304.03516, 2023.\n\nYan, A., Cheng, S., Kang, W.-C., Wan, M., and McAuley, J. Cosrec: 2d convolutional neural networks for sequential recommendation. In Proceedings of the 28th ACM international conference on information and knowledge management, pp. 2173\u20132176, 2019.\nYang, J., Yi, X., Zhiyuan Cheng, D., Hong, L., Li, Y., Xiaoming Wang, S., Xu, T., and Chi, E. H. Mixed negative sampling for learning two-tower neural networks in recommendations. In Companion Proceedings of the Web Conference 2020, pp. 441\u2013447, 2020.\nZhang, J., Xie, R., Hou, Y., Zhao, W. X., Lin, L., and Wen, J.-R. Recommendation as instruction following: A large language model empowered recommendation approach. arXiv preprint arXiv:2305.07001, 2023.\n\n",
    "paper_type": "benchmark",
    "attri": {
        "background": {
            "problem background": "The current state of recommendation systems in eCommerce often relies on narrow models that lack the ability to incorporate common-sense knowledge, which limits their effectiveness in understanding user behavior and preferences.",
            "purpose of benchmark": "The benchmark is intended to measure the effectiveness of LLM-based aspect augmentations in improving ranking metrics for recommendation systems."
        },
        "problem": {
            "definition": "The benchmark addresses the challenge of effectively generating and utilizing aspects or justifications for user interests in item recommendations.",
            "key obstacle": "Existing benchmarks often do not capture the nuances of user intentions and rely on domain-specific models that fail to generalize across different contexts."
        },
        "idea": {
            "intuition": "The creation of the benchmark was inspired by the need to improve recommendation systems by leveraging user intention keywords derived from item descriptions and reviews.",
            "opinion": "The authors believe that the benchmark can significantly impact the field by providing a more robust framework for evaluating recommendation systems.",
            "innovation": "This benchmark introduces the use of LLM-generated aspects to enhance traditional Learning-to-Rank models, which is a novel approach compared to previous benchmarks that did not utilize such common-sense reasoning.",
            "benchmark abbreviation": "LLM-AAR"
        },
        "dataset": {
            "source": "The dataset was sourced from a proprietary eCommerce platform, focusing on user-item interactions.",
            "desc": "The dataset contains 174,000 users and 139,000 item samples, including features like interaction history and item attributes.",
            "content": "The dataset includes user interaction history, item features such as price and average rating, and textual features derived from user reviews.",
            "size": "174,000",
            "domain": "eCommerce",
            "task format": "Ranking"
        },
        "metrics": {
            "metric name": "MRR, NDCG",
            "aspect": "Ranking effectiveness",
            "principle": "The metrics were chosen to evaluate the relevance and accuracy of the recommendations provided by the models.",
            "procedure": "Model performance is evaluated using standard ranking metrics calculated from the predicted and actual user interactions."
        },
        "experiments": {
            "model": "The models tested include state-of-the-art Learning-to-Rank architectures augmented with LLM-generated aspects.",
            "procedure": "Models were trained using various augmentation approaches, including feature concatenation, wide and deep architectures, and two-tower models.",
            "result": "The experiments showed that models augmented with LLM-based aspects significantly improved ranking metrics compared to baseline models.",
            "variability": "Variability in results was accounted for by conducting multiple trials and using different subsets of the dataset."
        },
        "conclusion": "The results indicate that using LLM-generated aspects can enhance recommendation systems by providing a deeper understanding of user intentions, leading to improved ranking metrics.",
        "discussion": {
            "advantage": "The benchmark strengthens the capability of recommendation systems to better capture user preferences through the integration of common-sense knowledge.",
            "limitation": "Potential limitations include the reliance on the quality of LLM outputs, which may vary and lead to inconsistencies in aspect generation.",
            "future work": "Future research could explore refining the aspect generation process and applying the benchmark to different domains beyond eCommerce."
        },
        "other info": []
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The current state of recommendation systems in eCommerce often relies on narrow models that lack the ability to incorporate common-sense knowledge, which limits their effectiveness in understanding user behavior and preferences."
        },
        {
            "section number": "2.1",
            "key information": "The benchmark addresses the challenge of effectively generating and utilizing aspects or justifications for user interests in item recommendations."
        },
        {
            "section number": "3.2",
            "key information": "This benchmark introduces the use of LLM-generated aspects to enhance traditional Learning-to-Rank models, which is a novel approach compared to previous benchmarks that did not utilize such common-sense reasoning."
        },
        {
            "section number": "4.1",
            "key information": "The authors believe that the benchmark can significantly impact the field by providing a more robust framework for evaluating recommendation systems."
        },
        {
            "section number": "5.1",
            "key information": "The dataset was sourced from a proprietary eCommerce platform, focusing on user-item interactions."
        },
        {
            "section number": "10.2",
            "key information": "Future research could explore refining the aspect generation process and applying the benchmark to different domains beyond eCommerce."
        }
    ],
    "similarity_score": 0.7867753531186514,
    "image": [
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6c3a/6c3a5552-b8ae-47cf-b405-00ff8179b3aa.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/898a/898ade43-3f53-4e84-bf08-9e1c50f7e694.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ee07/ee07a53b-8e27-46a4-8b67-824cff5e032a.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e510/e510ad18-5b41-42dd-9bbc-cbee4fea7f4e.png"
    ],
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Llm-based aspect augmentations for recommendation systems.json"
}