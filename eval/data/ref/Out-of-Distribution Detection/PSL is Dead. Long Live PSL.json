{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2205.14136",
    "title": "PSL is Dead. Long Live PSL",
    "abstract": "Property Specification Language (PSL) is a form of temporal logic that has been mainly used in discrete domains (e.g. formal hardware verification). In this paper, we show that by merging machine learning techniques with PSL monitors, we can extend PSL to work on continuous domains. We apply this technique in machine learning-based anomaly detection to analyze scenarios of real-time streaming events from continuous variables in order to detect abnormal behaviors of a system. By using machine learning with formal models, we leverage the strengths of both machine learning methods and formal semantics of time. On one hand, machine learning techniques can produce distributions on continuous variables, where abnormalities can be captured as deviations from the distributions. On the other hand, formal methods can characterize discrete temporal behaviors and relations that cannot be easily learned by machine learning techniques. Interestingly, the anomalies detected by machine learning and the underlying time representation used are discrete events. We implemented a temporal monitoring package (TEF) that operates in conjunction with normal data science packages for anomaly detection machine learning systems, and we show that TEF can be used to perform accurate interpretation of temporal correlation between events.",
    "bib_name": "smith2022psldeadlonglive",
    "md_text": "# PSL is Dead. Long Live PSL\nKevin Smith Rice University Houston, U.S.A. kwsmith@rice.edu Hai Lin Palo Alto Networks Santa Clara, U.S.A. halin@paloaltonetworks.com\nHai Lin Palo Alto Networks Santa Clara, U.S.A. halin@paloaltonetworks.com\nMarjorie Sayer Palo Alto Networks Santa Clara, U.S.A. msayer@paloaltonetworks.com\nAbstract\u2014Property Specification Language (PSL) is a form of temporal logic that has been mainly used in discrete domains (e.g. formal hardware verification). In this paper, we show that by merging machine learning techniques with PSL monitors, we can extend PSL to work on continuous domains. We apply this technique in machine learning-based anomaly detection to analyze scenarios of real-time streaming events from continuous variables in order to detect abnormal behaviors of a system. By using machine learning with formal models, we leverage the strengths of both machine learning methods and formal semantics of time. On one hand, machine learning techniques can produce distributions on continuous variables, where abnormalities can be captured as deviations from the distributions. On the other hand, formal methods can characterize discrete temporal behaviors and relations that cannot be easily learned by machine learning techniques. Interestingly, the anomalies detected by machine learning and the underlying time representation used are discrete events. We implemented a temporal monitoring package (TEF) that operates in conjunction with normal data science packages for anomaly detection machine learning systems, and we show that TEF can be used to perform accurate interpretation of temporal correlation between events. Index Terms\u2014formal methods, PSL, anomaly detection\n# I. INTRODUCTION\nProperty Specification Language (PSL) is a form of temporal logic that is designed to capture temporal relations between discrete variables over discrete time. Due to this nature, PSL has been mainly used in hardware design and verification since it was standardized by IEEE in 2004 [1], [2], [8]. There have been attempts to extend PSL to deal with continuous variables over continuous time [6]. Due to its inherent limitation of expressibility, there have not been many successful applications. In recent years, anomaly detection has been widely used in practice [3], [13]. There are many applications where realtime streaming events are monitored and analyzed in order to detect abnormal behaviors. For example, if the amount of free memory of a computer is below a certain threshold, it can be considered as an anomaly. As another example, if there is an anomalous drop in purchase of a product in an online store, it is possible that the product is out of stock, which needs attention. The state-of-the-art technique\nPraveen Tiwari Palo Alto Networks Santa Clara, U.S.A. prtiwari@paloaltonetworks.com\nClaudionor Coelho Palo Alto Networks Santa Clara, U.S.A. ccoelho@paloaltonetworks.com\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/480e/480e2671-3835-47fb-bce5-ea8a7bd9c360.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 1. A New Framework for Anomaly Detection</div>\nfor anomaly detection is machine learning [4], [7], [9], [11], [12], [14]. Machine learning techniques learn distributions on continuous variables. Anomaly events can be captured as deviations from established patterns (distributions). However, there are certain temporal behaviors and relations that cannot be easily learned by machine learning techniques, but can be easily characterized by formal languages such as PSL. In this paper, we propose a new framework called TEmporal Filtering (TEF) for anomaly detection (Fig. 1). The idea is to merge machine learning with PSL monitors. The machine learning module takes as input a number of continuous variables x1, x2, . . . . . . , xm, and outputs some discrete events y1, y2, . . . . . . , yn, which become the input of the PSL monitor. The PSL monitor encodes a user-defined temporal relation, which filters the output from the machine learning module. In this new framework, machine learning techniques extend the capability of PSL by discretizing continuous time and events; the PSL monitor refines the results produced by the machine learning module. This combination of machine learning and formal methods yields a whole that is greater than the sum of its parts. The rest of this paper is organized as follows. In Section II, we give a brief introduction to anomaly detection. Section III discusses the overall architecture of TEF. In Section IV, we describe how TEF is implemented. Section V illustrates how TEF can be used to capture temporal relations. Section VI summarizes the conclusions of the paper and future work.\n# II. ANOMALY DETECTION\nAnomaly detection is the process of identifying events that deviate from established patterns. Anomaly detection is widely used in many applications such as detecting cyber intrusions, credit card fraud, and health monitoring. In many applications, input variables have continuous values that vary with time, such as temperature. A time series anomaly detection model learns baseline behavior from training data and predicts a discrete set of anomalies. In time series anomaly detection the discretizing mechanism is simply that input timestamps are taken from discrete measurements, and there will always be a minimum nonzero granularity of inputs. These models provide a rich set of examples where a continuous valued problem maps to a discrete space, where formal methods can be applied. Anomaly detection modeling faces two major challenges. One, unbalanced data sets: anomalies are rare, and thus data sets will have few examples of anomalies which the model can learn. Two, characterization of anomalies: different types of models detect different types of anomalies. Level based methods find metric outliers. Distribution based methods find anomalies in distributions. Features might not contain the signal needed to detect anomalies. Being able to characterize anomalies helps, but unseen anomalies cannot be characterized. In such cases, model selection is difficult. The next sections describe some common types of anomaly detection models.\n# A. Level-Based Anomaly Detection\nIn these types of models, anomalies in continuous data are defined as values beyond a specific threshold. The threshold level is typically calibrated to the expected fraction of anomalies to be detected. A level that is too low results in false negatives, and one that is high results in false positives. Often an immediate limitation of level based models is they do not account for the frequency of threshold crossings. But threshold crossings and the timestamps they occur do make up a discrete event space for study.\n# B. Distribution-Based Anomaly Detection\nDistribution based models learn the statistical distribution of data in a baseline or normal state. Anomalies are categorized as events whose predicted probabilities are lower than a learned threshold. These models can learn more sophisticated behavior than level-based models - in particular, nonlinear decision boundaries between anomalous and normal events can be learned. The challenge of tuning the model remains: both the parameters that affect the machine learning of the model, and the final tuning of the anomaly probability thresholds. These challenges are documented in [10].\n# C. Forecasting Error Methods\nA wide range of time series forecasting methods, such as ARIMA, can be used to predict probable events from past data. Predictions from a recent past period can be compared with actual data values to determine if the actual values are\n# anomalous. The comparison of prediction and truth can in turn be level based or distribution based.\nanomalous. The comparison of prediction and truth can in turn be level based or distribution based.\n# D. Template-based Anomaly Detection\nIf anomalies follow templates of behavior, established rules of feature interaction and evolution through time, it\u2019s reasonable to hope that a machine learning model will learn the rules. The success of machine learning in many applications has led to extensive efforts in applying machine learning models to anomaly detection. Given enough features, enough data, enough compute power, the reasoning goes, a machine learning model will learn all of the intricate influences that distinguish anomalous behavior from normal. First, we demonstrate that there are cases where enough data is theoretically impossible. For instance, in a time stream of data, the event consisting of repeated events a followed by an event b are not possible to learn from a finite dataset. Second, while it may be possible to learn an underlying template for anomalies, the amount of data and compute resources required for sufficiently accurate results might be prohibitive.\n# E. A Hybrid Method\nBecause anomaly detection models create discrete sets of events they naturally can be described using PSL. Machine learning can make PSL relevant in continuous applications. Because PSL can easily characterize infinite sets such as the \u201darbitrary stream of a followed by b\u201d example as a simple PSL expression: a[+]; b, machine learning anomaly detection can be enhanced. We aim to show in this paper that time series anomaly detection together with TEF can improve overall model performance.\n# III. TEF OVERVIEW\nTEF implements a subset of PSL. PSL is an extension of linear temporal logic and adds a number of operators to express temporal constraints. In particular, PSL makes use of Sequential Extended Regular Expressions (SEREs), defined below. If a PSL formula is composed entirely of SEREs, it is said to be written in SERE-style PSL. TEF implements most of SERE-style PSL. Propositional formulas (i.e., boolean variables closed under conjunction, disjunction, and negation) are the atoms of SEREs. SEREs are SERE atoms closed under the SERE operators, which are analogous to the operators of regular expressions and also include supplemental operators representing useful syntactic sugar. Just as regular expressions are used to match strings, SEREs are used to match traces, that is, sequences of truth assignments. A SERE atom matches a truth assignment when the truth assignment makes the atom true. The semantics of compound SEREs are shown in Fig. 3 and Fig. 4. One of the advantages in using a temporal logic to specify properties is that logics are declarative. The result can be precisely described without the use of control flow or statements that modify a program\u2019s state. This allows those without a background in software engineering to write useful properties.\nHowever, the operators of linear temporal logic, although conceptually simple, are not trivial to use in practice, and most people are unfamiliar with them. An advantage of SERE-style PSL is that the functionality of LTL operators is subsumed by the SERE operators and so familiarity with LTL is not a requirement to writing properties. The close resemblance between SEREs and standard regular expressions make the former exceptionally easy to learn if one is familiar with the latter. And regular expressions are common currency not just in software engineering, but in data analysis and related fields as well. This makes SERE-style PSL easily accessible to those with a wide variety of backgrounds. So SERE-style PSL is a natural choice for TEF, which aims to provide a simple and accessible way to express and evaluate temporal constraints. In fact, TEF extends SERE-style PSL in an intuitive and useful way by allowing the use of Boolean expressions wherever Boolean variables may occur in SEREs. Another natural choice is the decision to package TEF as an extension to Pandas, which is also common currency in the Python world. TEF makes use of Python\u2019s regex engine, which takes as input a regex pattern (regular expression) and a string. The regex engine reports all segments of the string that match the regex pattern. Python\u2019s regex engine is highly optimized and efficient. Fig. 3 lists the main temporal operators, which TEF implements, and compares them with Python\u2019s regex patterns. In this table, r values are SEREs, s values are sequences of rows in a DataFrame, r\u2032 values are regex patterns, s\u2032 values are strings. Readers are referred to [15] for the formal semantics of SERE-style expressions. At a high level, TEF takes advantage of the highly efficient regex engine and the similarity between SERE expressions and regex patterns (shown in Fig. 3). TEF reduces the problem of checking if a SERE expression matches rows of a data frame to checking if a regex expression matches a string (Fig. 2). The reduction is based on the following observation. Let E be the set of all SERE expressions, R be the set of sequences of rows in a data frame, P be the set of all regex patterns, and S be the set of strings. There exist two functions f : E \u2192P and g : R \u2192S s.t. \u2200e : E, r : R. matches(e, r) \u2194matches(f(e), g(r)). Intuitively, Fig. 3 justifies this observation.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/12e0/12e09a96-f7a2-4ec0-9934-c55448b6e317.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 2. How TEF is implemented</div>\nsugar (shown in Fig. 4). TEF also adds the \u201c[]\u201d operator for use in Boolean expressions, which allows further flexibility in the expression of temporal relations. It functions in the following way. Suppose we have a data frame with a column c. Then c[\u22121] refers to the value at the previous row in column c. Also, c[1] refers to the value at the next row in column c. In general, if i is the index of the current row and j is an integer, then c[j] refers to the value at row i + j of column c. As syntactic sugar, c may be used as an abbreviation for c[0]. An illustrative example of a property making use of the \u201c[]\u201d operator is (c > c[\u22121])[\u22175], which matches all segments of the trace in which the value at c increases five times consecutively.\nAlgorithm 1 An algorithm for converting a SERE expression\ne to a regex expression\n1: function PSL TO REGEX(e)\n2:\nif e is a Boolean expression b then\n3:\nreturn the disjunction of truth assignments that\nmake b true, in string form.\n4:\nelse if e is r1; r2 then\n5:\ns1 \u2190PSL TO REGEX(r1)\n6:\ns2 \u2190PSL TO REGEX(r2)\n7:\nreturn \u2018(\u2019 + s1 + s2 + \u2018)\u2019\n8:\nelse if e is r1|r2 then\n9:\ns1 \u2190PSL TO REGEX(r1)\n10:\ns2 \u2190PSL TO REGEX(r2)\n11:\nreturn \u2018(\u2019 + s1+ \u2018|\u2019 +s2 + \u2018)\u2019\n12:\nelse if e is r1&r2 then\n13:\ns1 \u2190PSL TO REGEX(r1)\n14:\ns2 \u2190PSL TO REGEX(r2)\n15:\nleft = \u2019(\u2019 + \u2019(?=\u2019 + s1 + \u2019)\u2019 + s2 + \u2019)\u2019\n16:\nright = \u2019(\u2019 + \u2019(?=\u2019 + s2 + \u2019)\u2019 + s1 + \u2019)\u2019\n17:\nreturn \u2019(\u2019 + left + \u2019|\u2019 + right + \u2019)\u2019\n18:\nelse if e is r[\u2217] then\n19:\ns \u2190PSL TO REGEX(r)\n20:\nreturn \u2018(\u2019 + s + \u2018*\u2019 + \u2018)\u2019\n21:\nelse if e is r[+] then\n22:\ns \u2190PSL TO REGEX(r)\n23:\nreturn \u2018(\u2019 + s + \u2018+\u2019 + \u2018)\u2019\n24:\nelse if e is r[\u2217n] then\n25:\ns \u2190PSL TO REGEX(r)\n26:\nreturn \u2019((\u2019 + s + \u2019)\u2019 + \u2019{\u2019 + n + \u2019}\u2019 + \u2019)\u2019\n27:\nelse if e is r[\u2217n..m] then\n28:\ns \u2190PSL TO REGEX(r)\n29:\nreturn \u2019((\u2019 + s + \u2019)\u2019 + \u2019{\u2019 + n + \u2018,\u2019 + m + \u2019}\u2019 +\n\u2019)\u2019\n30:\nelse if e is r[\u2217n..] then\n31:\ns \u2190PSL TO REGEX(r)\n32:\nreturn \u2019((\u2019 + s + \u2019)\u2019 + \u2019{\u2019 + n + \u2018,\u2019 + \u2019}\u2019 + \u2019)\u2019\n33:\nelse if e is r[\u2217..m] then\n34:\ns \u2190PSL TO REGEX(r)\n35:\nreturn \u2019((\u2019 + s + \u2019)\u2019 + \u2019{0\u2019 + \u2018,\u2019 + m + \u2019}\u2019 + \u2019)\u2019\n36:\nend if\n37: end function\nSERE Syntax\nMeaning\nRegex Syntax\nMeaning\nr1; r2\nmatches s if s = s1s2, r1 matches s1 and r2 matches s2\nr\u2032\n1r\u2032\n2\nmatches s\u2032 if s\u2032 = s\u2032\n1s\u2032\n2, r\u2032\n1 matches s\u2032\n1 and r\u2032\n2 matches s\u2032\n2\nr1|r2\nmatches s if r1 matches s or r2 matches s\nr\u2032\n1|r\u2032\n2\nmatches s\u2032 if r\u2032\n1 matches s\u2032 or r\u2032\n2 matches s\u2032\nr1&r2\nmatches s if r1 matches s and r2 matches s\n? = r\u2032\nmatches s\u2032 if r\u2032 matches s\u2032, butitdoesnotconsumeanyr\u2032\nr[\u2217]\nmatches s if 0 or more concatenations of r matches s\nr\u2032\u2217\nmatches s\u2032 if 0 or more concatenations of r\u2032 matches s\u2032\nr[+]\nmatches s if 1 or more concatenations of r matches s\nr\u2032+\nmatches s\u2032 if 1 or more concatenations of r\u2032 matches s\u2032\nr[\u2217n]\nmatches s if n concatenations of r matches s\nr\u2032{n}\nmatches s\u2032 if n concatenations of r\u2032 matches s\u2032\nr[\u2217n..m]\nmatches s if between n and m concatenations of r matches s\nr\u2032{n, m}\nmatches s\u2032 if between n and m concatenations of r\u2032 matches s\u2032\nr[\u2217n..]\nmatches s if n or more concatenations of r matches s\nr\u2032{n, }\nmatches s\u2032 if n or more concatenations of r\u2032 matches s\u2032\nr[\u2217..m]\nmatches s if m or fewer concatenations of r matches s\nr{0, m}\nmatches s\u2032 if m or fewer concatenations of r\u2032 matches s\u2032\n<div style=\"text-align: center;\">Fig. 3. SERE expressions and Python\u2019s regex patterns</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2117/211774e7-12ab-40d2-b712-b0bc9ffa03d9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 4. Additional SERE-style operators</div>\n<div style=\"text-align: center;\">IV. TEF IMPLEMENTATION</div>\nTEF shadows the Pandas DataFrame eval method. It takes as input a SERE-style PSL property in the form of a string, and it matches it against the DataFrame, which is interpreted as a trace. As we discussed in Section III, TEF reduces the problem of checking if a SERE expression matches rows of a data frame to checking if a Python regex pattern matches a string. In order to make the reduction work, we just need to build two functions: (1) f which converts a SERE expression to a regex pattern. (2) g which converts a data frame to a string. To build the function f, we use a simple recursion based on how the SERE expression is constructed. The simplest SERE expression is a Boolean expression. To convert a Boolean expression to a regex pattern, we rewrite the expression in the form of the disjunction of its set of satisfying truth assignments, in string form. As a result, the length of the pattern is exponential in the number of distinct boolean expressions used in the property. In practice we have found that many problems need make use of only a few expressions. Often only a single expression is used to express a useful property. To convert more complicated SERE expressions involving SERE operators, the individual pieces are converted recursively, then the results are combined based on the SERE operator. For example, suppose that we want to convert r1; r2. We first recursively convert r1 and r2, get two regex strings, and then concatenate the two regex strings. The details of converting a SERE expression into a Python regex pattern is shown in Algorithm 1.\nTo build the function g, TEF does two steps: \u2022 Step 1 (Booleanize a data frame) TEF identifies all the Boolean expressions used in the property, and evaluates them with respect to each row in the data frame. It keeps track of the results in a new data frame, in which the results of each Boolean expression are kept in new columns. The details of Booleanizing a data frame is shown in Algorithm 2. \u2022 Step 2 (convert to a string) The Booleanized DataFrame is converted to a string by using \u2018,\u2019 to seperate columns and using \u2018()\u2019 to group characters within the same rows. After converting a SERE expression into a regex pattern and converting a data frame into a string, Python\u2019s regex engine is used to find matches. Results are returned in the form of a list of index pairs indicating where in the trace the property is satisfied.\nAlgorithm 2 An algorithm for Booleanizing a data frame df\nw.r.t. a compound Boolean expression e\n1: function BOOLEANIZE DATAFRAME(df, e)\n2:\nInitialize b df to be an empty data frame.\n3:\nfor all row r in df do\n4:\nInitialize r\u2032 to be an empty row.\n5:\nfor all atom a in e do\n6:\nEvaluate a w.r.t. r, add the result to r\u2032\n7:\nend for\n8:\nAdd r\u2032 to b df\n9:\nend for\n10:\nreturn b df\n11: end function\n# A. Analyzing Weather Patterns using TEF\nFigure 5 shows a data frame containing the weather information in Amarillo, TX, in April 2021. The weather data is taken from [16]. We make the following queries to the data frame. Pandas DataFrame eval method can handle queries involving only one row. If the query refers to multiple rows, we need to use TEF eval method. 1. Find all individual days, when the temperature is either too hot (temp high \u226580) or too cold(temp low \u226440). We can use Pandas DataFrame eval method, which returns the set of individual rows, where the constraint is satisfied (Fig. 7).\n\n\n\n<div style=\"text-align: center;\">Fig. 5. Data Frame: df Fig. 6. Booleanized Data Frame: b df</div>\n<div style=\"text-align: center;\">Fig. 6. Booleanized Data Frame: b df</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e6a1/e6a13f95-58d5-4a72-a9d5-7d5600833352.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 7. Query using Pandas DataFrame eval method</div>\n2. Find two consecutive days where a hot day (temp high \u226580) is followed by a cold day (temp low \u226440). The Pandas DataFrame eval method cannot handle this query, since it cannot reason about temporal relations involving multiple rows of a data frame. We use TEF eval method instead. TEF does the following 3 steps to evaluate \u201ctemp high \u226580; temp low \u226440\u201d against the data frame df (Fig. 5).\n2. Find two consecutive days where a hot day (temp high \u226580) is followed by a cold day (temp low \u226440). The Pandas DataFrame eval method cannot handle this query, since it cannot reason about temporal relations involving multiple rows of a data frame. We use TEF eval method instead. TEF does the following 3 steps to evaluate \u201ctemp high \u226580; temp low \u226440\u201d against the data frame df (Fig. 5). \u2022 Step 1: As discussed in Section IV, TEF identifies all the Boolean expressions used in the property, and evaluates them with respect to each row in df. This particular query contains two Boolean expressions \u201chigh temperature \u2265 80\u201d and \u201clow temperature \u226440\u201d. The Booleanized data\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4538/45388b3d-e510-4248-a3f1-d46c779dfefa.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 8. Query using TEF eval method</div>\nframe b df (Fig. 6) has two columns and has the same number of rows as df. b df is transformed into the following string by using \u2018,\u2019 to seperate columns and using \u2018()\u2019 to group characters within the same rows. (0,1)(0,0)(0,0)(0,0)(1,0)(1,0)(0,0)(0,0)(0,0)(0,1)(1,0) (0,1)(0,1)(0,0)(0,0)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1) (0,0)(0,0)(1,0)(1,0)(0,0)(0,0)(0,0)(0,0) \u2022 Step 2: The PSL property is compiled to a Python regex pattern: (\\ (1, 0\\) |\\ (1, 1\\))(\\ (0, 1\\) |\\ (1, 1\\)). \u2022 Step 3: Python\u2019s regex engine is used to find matches. The result is shown in Fig. 8. 3. Find two consecutive days when (1) temp high \u226480 and temp low \u226540 (2) humidity \u226520 and humidity \u226470 (3) wind speed < 30. Again, this is a temporal relation involving multiple rows of the data frame. We should use TEF eval method. The result is shown in Fig. 9.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bf39/bf39c655-23b3-4db0-89c6-32399ac6e46d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 9. Query using TEF eval method</div>\nB. Analyzing Dow Jones Industrial Average (DJIA) index using TEF In this section, we show how TEF can be used to analyze patterns in Dow Jones Industrial Average (DJIA) index. This dataset contains data from 01/01/1980 to 12/31/2012, and is taken from [17]. All experiments are done on a Macbook, with 2.6 GHz 6-Core Intel Core i7 and 16 GB 2667 MHz DDR4. 1. [Rise after Drop] Find all periods where the index has been dropping for 5 consecutive days and rises on the next day. The result is shown in Fig. 10.\n# B. Analyzing Dow Jones Industrial Average (DJIA) index using TEF\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/456f/456f115c-4b42-4a9d-9a44-440ec90e6688.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 10. Rise after Drop</div>\n2. [Fluctuation] Find all periods where the index decreases on one day and increases on the next day, and this pattern repeats for at least 5 times. The result is shown in Fig. 11.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/429b/429bac4d-c37b-4292-89b8-43b607425fe9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 11. Flunctuation</div>\n3. [Steady] Find all periods where the index stays between 5000 and 6000 for at least 10 days. The result is shown in Fig. 12.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/376e/376e3830-b6ba-4d6a-bc86-29cf76defcbd.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 12. Steady</div>\n4. [Jump] Find all periods where the index increases by at least 10% compared to the previous day. The result is shown in Fig. 13.\nUsing examples from publicly available data sets, we show cases where false positives from a trained isolation forest model can be filtered by rules. The data is taken from [18]. The\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2cf7/2cf7da57-b61d-450a-bca1-e2cb665a63a1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 13. Jump</div>\nentire dataset collection consists of 250 datasets from domains such as medical monitoring, motion sensors, and weather. We identified 130 examples where the model output could be improved by a rule based filter.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1757/1757c7b0-05f2-4131-af96-d4aa9e4d8576.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 14. Identify cluster of predictions</div>\nIn Fig. 14 the anomaly is difficult to detect as it has similar amplitude and frequency to the baseline pattern. But the detected anomalies are clustered in time and anomalies that are farther apart could be ruled out by a simple rule filter. We can use TEF to specify that within a cluster, the total number of anomalies needs to reach a certain threshold. For example, cluster2,5 = \u201canomaly[\u22122] + anomaly[\u22121] + anomaly + anomaly[1] + anomaly[2] \u22652\u201d specifies that at least 2 anomalies need to occur within a cluster of width 5. The width of the cluster and the threshold can be adjusted for different applications. Fig. 15 is an example where the anomaly can be detected by a gap that follows detected anomalies. In order to specify that a gap of width x needs to follow a detected anomaly, we can use: \u201c[\u2217]; anomaly; !anomaly[\u2217x]\u201d. The original data, shown in the upper graph, has an anomaly that is difficult to characterize. As a final example, Fig. 16 shows a case where a suitable filtering rule would take into account both cluster and gap behavior. \u201ccluster2,5; !anomaly[\u22175]; cluster2,5\u201d specifies a sequence of events: at least 2 anomalies occur within a cluster of width 5, followed by a gap of width 5, followed by at least 2 anomalies occurring within a cluster of width 5. Again, the width of the cluster and the width of the gap can be adjusted for different applications.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/05e6/05e6d6d7-ad41-4d40-88b7-706d774795ab.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 15. Identify by gap</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/074f/074f7302-6299-4706-b41b-6ad4965efd98.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 16. Identify by gap</div>\nFor many years, the use of PSL has been limited to hardware design and verification, since PSL is designed to deal with discrete variables over discrete time. In this paper, we propose that PSL can be used in continuous domain for anomaly detection. The idea is to merge PSL with machine learning and use a hybrid framework for anomaly detection. This hybrid framework consists of a machine learning module and a PSL monitor. The machine learning module outputs anomalies in the form of discrete time and events. The PSL monitor further refines the output of the machine learning module by checking if some user-defined temporal relation is satisfied. We implemented a temporal monitoring package (TEF), and we show that TEF can be used to perform accurate interpretation of temporal correlation between events. For future work we are experimenting with the following cases: multivariate anomaly detection problems, and TEF in conjunction with ensemble models. With TEF, we have the opportunity to transform anomaly characterization rules into data, and develop models from there.\n# REFERENCES\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the limitations of Property Specification Language (PSL) in dealing with continuous variables over continuous time, which has hindered its application in anomaly detection despite its strengths in formal verification.",
        "problem": {
            "definition": "The problem is the inability of PSL to effectively handle continuous time and variables, limiting its application in real-time anomaly detection scenarios where continuous data is prevalent.",
            "key obstacle": "The core obstacle is PSL's inherent limitation in expressibility, which results in challenges in capturing temporal behaviors and relations in continuous domains."
        },
        "idea": {
            "intuition": "The idea was inspired by the need to leverage the strengths of both machine learning techniques, which can model continuous distributions, and formal methods like PSL, which can characterize discrete temporal relations.",
            "opinion": "The proposed idea is to create a framework called TEmporal Filtering (TEF) that integrates machine learning and PSL monitors to enhance anomaly detection in continuous domains.",
            "innovation": "The key innovation lies in merging machine learning outputs with PSL monitors, allowing for the discretization of continuous time and events, thus refining anomaly detection capabilities."
        },
        "method": {
            "method name": "TEmporal Filtering",
            "method abbreviation": "TEF",
            "method definition": "TEF is a hybrid framework that combines machine learning techniques for anomaly detection with PSL monitors to filter and refine detected anomalies based on user-defined temporal relations.",
            "method description": "TEF processes continuous variables through machine learning to detect anomalies and utilizes PSL to evaluate temporal correlations in the detected events.",
            "method steps": [
                "Step 1: Input continuous variables into the machine learning module.",
                "Step 2: Output discrete events from the machine learning module.",
                "Step 3: Apply PSL monitors to filter the machine learning outputs based on specified temporal relations."
            ],
            "principle": "TEF is effective because it leverages the ability of machine learning to identify anomalies in continuous data while using PSL to enforce temporal constraints that are not easily captured by machine learning alone."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted using real-time streaming datasets, including weather data and financial indices, to validate the effectiveness of TEF in anomaly detection.",
            "evaluation method": "The performance of TEF was assessed by comparing its anomaly detection results against traditional methods and analyzing the accuracy of temporal correlations in the detected anomalies."
        },
        "conclusion": "The experiments demonstrated that TEF successfully integrates machine learning and PSL to enhance anomaly detection in continuous domains, providing a more accurate interpretation of temporal correlations between events.",
        "discussion": {
            "advantage": "TEF stands out due to its ability to combine the strengths of machine learning and formal methods, allowing for improved anomaly detection in scenarios involving continuous data.",
            "limitation": "One limitation of TEF is the complexity involved in tuning the machine learning models and the PSL specifications, which may require significant expertise.",
            "future work": "Future research directions include exploring multivariate anomaly detection problems and enhancing TEF with ensemble models to improve its robustness and applicability."
        },
        "other info": {
            "info1": "TEF is implemented as a package that extends the capabilities of Pandas in Python.",
            "info2": {
                "info2.1": "TEF uses a regex engine for efficient pattern matching.",
                "info2.2": "The framework allows for flexible definitions of temporal relations through SERE-style PSL expressions."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "2.3",
            "key information": "The problem is the inability of Property Specification Language (PSL) to effectively handle continuous time and variables, limiting its application in real-time anomaly detection scenarios where continuous data is prevalent."
        },
        {
            "section number": "3.5",
            "key information": "The proposed idea is to create a framework called TEmporal Filtering (TEF) that integrates machine learning and PSL monitors to enhance anomaly detection in continuous domains."
        },
        {
            "section number": "5.1",
            "key information": "TEF is effective because it leverages the ability of machine learning to identify anomalies in continuous data while using PSL to enforce temporal constraints that are not easily captured by machine learning alone."
        },
        {
            "section number": "7.1",
            "key information": "One limitation of TEF is the complexity involved in tuning the machine learning models and the PSL specifications, which may require significant expertise."
        },
        {
            "section number": "7.2",
            "key information": "Future research directions include exploring multivariate anomaly detection problems and enhancing TEF with ensemble models to improve its robustness and applicability."
        }
    ],
    "similarity_score": 0.6230682255542094,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/PSL is Dead. Long Live PSL.json"
}