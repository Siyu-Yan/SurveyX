{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2306.07104",
    "title": "Unveiling the Hessian's Connection to the Decision Boundary",
    "abstract": "Understanding the properties of well-generalizing minima is at the heart of deep learning research. On the one hand, the generalization of neural networks has been connected to the decision boundary complexity, which is hard to study in the high-dimensional input space. Conversely, the flatness of a minimum has become a controversial proxy for generalization. In this work, we provide the missing link between the two approaches and show that the Hessian top eigenvectors characterize the decision boundary learned by the neural network. Notably, the number of outliers in the Hessian spectrum is proportional to the complexity of the decision boundary. Based on this finding, we provide a new and straightforward approach to studying the complexity of a high-dimensional decision boundary; show that this connection naturally inspires a new generalization measure; and finally, we develop a novel margin estimation technique which, in combination with the generalization measure, precisely identifies minima with simple wide-margin boundaries. Overall, this analysis establishes the connection between the Hessian and the decision boundary and provides a new method to identify minima with simple wide-margin decision boundaries.",
    "bib_name": "sabanayagam2023unveilinghessiansconnectiondecision",
    "md_text": "# Unveiling the Hessian\u2019s Connection to the Decision Boundary\nMahalakshmi Sabanayagam\u2217 School of Computation, Information and Technology, Technical University of Munich, Germany sabanaya@cit.tum.de\n# Freya Behrens\u2217 Statistical Physics of Computation Lab, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland freya.behrens@epfl.ch\nUrte Adomaityte Department of Mathematics, King\u2019s College London, United Kingdom urte.adomaityte@kcl.ac.uk\nAnna Dawid\u2020 Center for Computational Quantum Physics, Flatiron Institute, USA adawid@flatironinstitute.org\n# Abstract\nUnderstanding the properties of well-generalizing minima is at the heart of deep learning research. On the one hand, the generalization of neural networks has been connected to the decision boundary complexity, which is hard to study in the high-dimensional input space. Conversely, the flatness of a minimum has become a controversial proxy for generalization. In this work, we provide the missing link between the two approaches and show that the Hessian top eigenvectors characterize the decision boundary learned by the neural network. Notably, the number of outliers in the Hessian spectrum is proportional to the complexity of the decision boundary. Based on this finding, we provide a new and straightforward approach to studying the complexity of a high-dimensional decision boundary; show that this connection naturally inspires a new generalization measure; and finally, we develop a novel margin estimation technique which, in combination with the generalization measure, precisely identifies minima with simple wide-margin boundaries. Overall, this analysis establishes the connection between the Hessian and the decision boundary and provides a new method to identify minima with simple wide-margin decision boundaries.\n# 1 Introduction\nThe loss landscape of a deep neural network is a high-dimensional non-convex object exhibiting mu tiple equivalent local minima and saddle points (Auer et al., 1995; Dauphin et al., 2014; Choromansk et al., 2015; Sagun et al., 2017; Alain et al., 2018). The complex geometry of the loss landscape mak it notoriously difficult to analyze. In the context of gradient descent-based optimization, it is wide\nobserved that the network converges to a local minimum that generalizes reasonably well (Keskar et al., 2017). Still, the properties of minima exhibiting good generalization are highly debated. To understand those properties, some works study the decision boundary corresponding to a given minimum. Researchers often follow Occam\u2019s razor by assuming that among minima with similarly high training accuracy, the ones with simpler decision boundaries will have a higher test accuracy (Guan & Loew, 2020). Then, they attempt to define the complexity of the decision boundary using various approaches, e.g., using topological measures (Ramamurthy et al., 2018), or curvature of the loss around the boundary in the input space (Fawzi et al., 2018), or via generation of adversarial examples (Guan & Loew, 2020; Karimi & Derr, 2022). Another proxy for the decision boundary complexity is the number of its linear segments (Kienitz et al., 2023) but it is limited to the lowdimensional input space. Other works study minima by analyzing their curvature in the model parameter space and developing heuristics indicating their generalization abilities. A few notable results suggest that flat minima generalize better than sharp minima (Keskar et al., 2017; Wu et al., 2017; Izmailov et al., 2018; He et al., 2019). One approach to analyzing the curvature of the minimum is through the Hessian of the training loss. Specifically, the intuition that a flat minimum has a smaller sum of Hessian eigenvalues (trace) than a sharp minimum is used as a straightforward metric for generalization (Hochreiter & Schmidhuber, 1997; Keskar et al., 2017). However, these results are extensively contested and discussed (Zhang et al., 2021), since flatness is not a well-defined concept in nonconvex landscapes of deep models (Dinh et al., 2017). On the one hand, works such as Sagun et al. (2018); Jastrzebski et al. (2019); Petzka et al. (2021); Andriushchenko et al. (2023) illustrate the superfluousness of Hessian-based generalization measures and observe that flatness is not well correlated with generalization. On the other hand, Kwon et al. (2021) and Petzka et al. (2021) suggest improvements to the direct Hessian-based metric and compute the adaptive flatness and relative flatness of the minimum, respectively. Despite the intuitive understanding that the simple decision boundary and a properly defined flatness of minima together promote good generalization of neural networks, to the best of our knowledge, no explicit connection between the two has been established so far. Advancing an understanding of this connection is precisely the goal of this work. To do so, we take a closer look at properties of the Hessian that are observed to be universal across different deep learning setups. Firstly, the spectrum of the Hessian at a minimum separates into the bulk centered around zero and a few outliers, whose number is roughly equal to the number of classes in the data (Sagun et al., 2017, 2018; Ghorbani et al., 2019; Papyan, 2019, 2020). We ask what is the significance of those outliers, and why is their number approximately equal to the number of classes? Secondly, why does the gradient information reside in a small subspace spanned by the Hessian top eigenvectors as noted by Gur-Ari et al. (2019)? In our work, we give an understanding of these properties by revealing their connection to the decision boundary. In particular, we compare the gradient directions of the loss for individual training data with the Hessian eigenvectors and see that they align when the samples are at the decision boundary. As a consequence, we propose a new generalization measure and a margin estimation technique that show promising empirical success in capturing the generalization of neural networks. Contributions. We perform a rigorous numerical analysis of the deep neural network loss landscape for classification tasks through the Hessian of the training loss, and we observe the following: (1) The top eigenvectors of the Hessian of the training loss encode the decision boundary learned by the neural network. In particular, there is a clear information separation across the eigenvectors, which encode separate sections of the decision boundary. (2) The number of encoding eigenvectors is usually equal to the number of spectrum outliers which is directly proportional to the complexity of the decision boundary. To elaborate, more eigenvectors are needed to encode a complex, highly non-linear decision boundary than a simpler counterpart. (3) We propose a new, improved generalization measure that considers the simplicity of the decision boundary via the Hessian eigenvectors. In addition, we develop a technique to estimate the narrowest margin of the decision boundary in the input space. Our approach. To detail our approach, consider a simple two-layer fully-connected ReLU network f\u03b8 trained to classify one-dimensional (1D) training data into two classes as presented in Figure 1 (A)-(B). In this 1D input space, the network learns a decision boundary located at two points, xL and xR (Figure 1 (C.1)). Consider gradients of the loss function of individual data points in the input space as in Figure 1 (C.3). Those gradients align with the directions in the parameter space\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5c76/5c7662ea-7091-4ab2-8075-020cb1df8175.png\" style=\"width: 50%;\"></div>\ncorresponding to the largest increase of error on the data. Overall, the largest error is made on the data that is on the boundary by shifting it across the boundary. Moreover, gradients on the opposite sides of the boundary point in opposite directions as moving the boundary benefits samples from one class but hurts samples from another. Indeed, we see that gradients on either side of xL and xR point in opposite directions. These directions align with the top two Hessian eigenvectors v1 and v2 corresponding to the two outliers in its eigenspectrum (Figure 1 (C.2,C.4)). We see that gradients around xR align perfectly with the top eigenvector v1: The cosine similarity flips from \u22121 to 1 as the decision boundary is crossed (Figure 1 (C.5)). The gradients around xL align with the second top eigenvector v2. We conclude that the top Hessian eigenvectors encode separate pieces of the decision boundary learned by the network. In the remainder of this work, we give a formal definition of our framework in Section 2 along with the mathematical intuition and main observations; propose the generalization measure and margin estimation technique in Section 3; validate our results on real data in Section 3.4; discuss the implications of our findings in Section 4 and conclude in Section 5.\nWe consider a C class classification problem with training data D = {xi, yi}n i=1 where xi \u2208Rd and yi \u2208{1, . . . , C} is the class label. Let the neural network be f\u03b8 : Rd \u2192RC parameterized by \u03b8 \u2208Rp where we focus on the over-parameterized setting, that is, p \u226bnd. We obtain the class prediction as \u02c6yi = arg max f\u03b8(xi). The training of the network f\u03b8 is done using stochastic gradient descent (SGD) and cross-entropy loss L(\u03b8; D) = \ufffdn i=1 \ufffdC c=1 1[yi = c] log[f\u03b8(xi)]c where 1[\u00b7] is the indicator function. The pairwise decision boundary of the classifier (between two classes c and c\u2032) is defined as a set of points in the input space B = {z : [f\u03b8(z)]c = [f\u03b8(z)]c\u2032 = maxf\u03b8(z)} which f classifies as being equally likely to belong to class c and c\u2032. Within this work, we focus on datasets where we can visualize the decision boundary. Therefore, we follow Kienitz et al. (2023) and define the geometric complexity of the decision boundary as the number of its linear segments. In a similar spirit to Fort & Ganguli (2019), we define the reinforcing gradient g\u03b8 : Rd \u2192Rp of a given input x to be the gradient direction in parameter space that strengthens the dominating class in\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e395/e395bf43-f8d7-42de-a2ce-ee2287e48179.png\" style=\"width: 50%;\"></div>\nFigure 2: Experimental results on gaussian dataset. (First column) The decision boundary in the data space obtained by training a two-layer fully connected network. (Other columns) The alignment of reinforcing gradients with the top five eigenvectors illustrates that the top eigenvectors encode the decision boundary.\nthe distribution of the current prediction from f\u03b8 at an input x:\nLet the Hessian matrix of the training loss on data D be the square matrix H \u2208Rp\u00d7p such that Hi,j = \u22022 \u2202\u03b8i\u03b8j L(D). Each eigenvalue and its corresponding normalized eigenvector of H is denoted by \u03bbi and vi \u2208Rp, \u2200i \u2208[p] respectively. We assume that the ordering is descending in value of the eigenvalues \u03bbi. Therefore, the top k Hessian eigenvectors correspond to the first k largest Hessian eigenvalues. Then, we define the alignment between the reinforcing gradient g\u03b8(x) of an input x with eigenvector vi in terms of the cosine similarity as\nwhere \u27e8\u00b7, \u00b7\u27e9is the scalar product, and \u2225\u00b7\u2225is the Euclidean norm of the vector. Note that this alignment crucially depends on \u03b8 in parameter space from which the Hessian H is derived. The cosine similarity is more informative than the common scalar product, as discussed in Appendix A. To showcase the connection between the Hessian top eigenvectors and decision boundary as well as the effectiveness of the generalization measure, we conduct a series of experiments on small datasets.\nDatasets and architectures. We consider five two-dimensional (2D) simulated datasets: gaussian with three classes sampled from Gaussian mixtures, concentric circle and half-moon datasets with two classes each, hierarchical gaussian with four classes, and checkerboard dataset with two classes. We also validate our findings on real datasets such as Iris and MNIST. In the main body of the manuscript, we focus on results for gaussian, checkerboard, and MNIST-017. The other results are presented in Appendix B. We study both two-layered fully-connected neural networks and convolutional neural networks with a number of model parameters around 105. Detailed descriptions of the datasets and the models are provided in the code.3 Since the models and datasets are of tractable sizes, we compute the Hessian exactly using the torch.autograd module from PyTorch (Paszke et al., 2019). We measure the alignment of the training data with respect to each eigenvector of the Hessian for a converged network f\u02c6\u03b8 where the training loss is converged but not necessarily equal to 0, and conduct extensive empirical analysis leading to the following results.\n# 2.1 Top Hessian eigenvectors encode the decision boundary\nWe plot the alignment of reinforcing gradients and each of the top k = 5 eigenvectors for the 2D gaussian dataset in Figure 2. For the topmost eigenvectors, we observe a close-to-one absolute alignment with gradients of loss of the points on the decision boundary learned by the network. Moreover, for these points, we see a transition from maximal positive to negative cosine similarity values, i.e., a switch of the alignment sign. Those results hold for all other considered 2D datasets (circle, half-moon, and hierarchical gaussian) as presented in Appendix B. We interpret this alignment of the topmost eigenvectors with gradients of samples on the boundary in two ways. When we shift the model parameters \u03b8 along the direction of the top eigenvector, the points in input space with high alignment to this vector would either reinforce their class by increasing the output corresponding to their class prediction or weaken their class prediction by decreasing the\n(2)\ncorresponding output. Alternatively, we can think of a gradient aligning with the direction in the parameter space corresponding to the direction of the largest error increase on the respective data. On the boundary, the largest error occurs by shifting the boundary; therefore, gradients there align with parameters whose change would shift the decision boundary. In every case, we see that the reinforcing gradients on the boundary align with the top Hessian eigenvectors indicating that they encode the same information as the direction in the parameter space that would shift the boundary. We can strengthen this observation mathematically by expanding the loss around a minimum \u03b8\u2217using second-order Taylor\u2019s approximation at \u03b8\u2217+ \u2206\u03b8 and considering \u2206\u03b8 = g\u03b8(x) ||g\u03b8(x)||, resulting in\nFrom (3), for the loss to have a maximal change, the reinforcing gradient of x should be aligned with the direction of the steepest ascent of f(\u03b8\u2217, X). This implies that moving data x in the direction of the gradient of f(\u03b8\u2217, X) potentially changes the predicted class for x, thus increasing the loss. In other words, the alignment of the reinforcing gradient of x with the function\u2019s gradient is high for x near the decision boundary. From this understanding and the right-hand side of (3), we infer that the alignment of x with the top Hessian eigenvectors is larger for x near the boundary than data points farther away, explaining our numerical observation. A detailed analysis is provided in Appendix C. Additionally, we see that each top eigenvector may capture only a section of the complete boundary. This information on the sections of decision boundary can be well separated across eigenvectors as in the case of gaussian in Figure 2, where the top eigenvector encodes a section of the boundary between one pair of classes, and the second top eigenvector between another pair of classes. Furthermore, the alignment does not necessarily switch between extreme values +1 and \u22121 across the decision boundary. The exact extreme values do not seem informative in contrast to the sign switch itself. However, for the topmost eigenvectors and standard training, the absolute alignment value is usually close to 1. Finally, the largest alignment across the input space is always for points on the boundary. In Appendix D, we showcase that the top few eigenvectors are sufficient to encode the entire decision boundary, and the other directions in parameter space do not exhibit the same property. Interestingly, when we analyze the Hessian with respect to the loss that only considers a specific class c, we observe that the top eigenvectors are now restricted to the boundaries that are relevant to deciding the \u201call-against-one\u201d for the selected class c (Appendix E). Moreover, in Appendix F, we show that the connection between the topmost eigenvectors and the decision boundary is invariant to the architecture and loss function. The dependence on the optimizer is more subtle, and we discuss it in more detail in the same appendix. In Appendix G, we show that the top eigenvectors of the covariance matrix of training samples\u2019 gradients actually encode the same information as the top Hessian eigenvectors at the minimum as observed by Ghorbani et al. (2019) and Fort & Ganguli (2019). Finally, we see that the same connection between the top Hessian eigenvectors and decision boundary is not restricted to a minimum and persists throughout the training (Appendix H).\n# 2.2 A complex boundary is characterized by many eigenvectors\nPast works indicate that the number of outliers in the Hessian spectrum is roughly equal to the number of classes in the dataset. However, we hypothesize that the number of outliers depends on the simplicity of the learned decision boundary. An increased number of eigenvectors, corresponding to an increased number of outliers, is needed to characterize a more complex decision boundary.\nTo verify our hypothesis, we follow different training procedures to reach poorly generalizing minima which, by Occam\u2019s razor, usually imply complex decision boundaries. We use two such methods. One is an adversarial initialization as introduced by Liu et al. (2020). Briefly, the procedure consists in initializing the network with parameters \u03b8 that fit the data with random labels. We notice that such an initialization always exhibits a large L2 norm. Therefore, another method we use consists in simply large norm initialization of the model. Usually, the adversarial and large norm initializations lead to much more complex and slightly more complex decision boundary than the regular initialization, respectively, as presented in the first column of Figure 3. We compute the alignment of reinforcing gradients with the top Hessian eigenvectors corresponding to the outliers for all the initialization methods on gaussian as shown in Figure 3, which demonstrates more eigenvectors are needed to describe the learned decision boundary from both adversarial and large norm initializations.\n(3)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/afd6/afd62bbd-00b0-4a1e-a247-a48239f45ab8.png\" style=\"width: 50%;\"></div>\nFigure 3: Decision boundaries of different complexities for gaussian. Alignment plots and histograms of the Hessian spectra for models obtained from normal training, an adversarial initialization (Liu et al., 2020), and a large norm initialization.\n<div style=\"text-align: center;\">Figure 3: Decision boundaries of different complexities for gaussian. Alignment plots and histograms of the Hessian spectra for models obtained from normal training, an adversarial initialization (Liu et al., 2020), and a large norm initialization.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6512/6512c08c-35ae-45ed-ba2e-5c885439c1f7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 4: Alignment of all training data with the top 25 Hessian eigenvectors for gaussian with classes {0, 1, 2} and different initializations. The dark lines show the mean of each class alignment.</div>\nTo complete the picture, the last column of Figure 3 shows the histogram of Hessian eigenvalues for gaussian dataset illustrating that different training procedures lead to a different number of outliers. In particular, normal training leads to 2 outliers following the conjectures from the past works, whereas the adversarial initialization shows more outliers. It is important to note that the number of the top Hessian eigenvectors that encode sections of the decision boundary does not correspond one-to-one to the number of outliers in the spectra. So far, we have studied the alignment of reinforcing gradients of samples across the whole input space, which is feasible only for low input space dimensions. In realistic setups, we only have access to training gradients. Therefore, we plot the alignment of gradients of loss of training samples with the top Hessian eigenvectors in Figure 4 and confirm that our main observation holds also for this subset of the input space: indeed, a more complex decision boundary leads to a larger number of Hessian eigenvectors with non-zero alignment with training reinforcing gradients. Moreover, for simpler decision boundary (normal initialization) the gradients are much more localized in the Hessian space, that is, the alignment is significantly greater than 0 only for the top eigenvectors, than in the other initializations. Interestingly, we also see that gradients at the better generalizing minimum are more aligned with one another according to their classes.\n# 3 Generalization measure and margin estimation technique\nGoing with the conventional wisdom that a simple decision boundary generalizes better than a complex one and the results from Section 2, we naturally define a generalization measure G\u03b8 that counts the number of eigenvectors needed to describe the decision boundary. Mathematically, we define G\u03b8 to be the ratio of Hessian eigenvectors with non-zero absolute mean alignment A with the training samples to the total number of eigenvectors, computed at the minimum \u03b8:\nwhere \u03f5 is close to zero,4 | \u00b7 | is the absolute value, and mi denotes the mean of absolute alignment of the training samples with respect to eigenvector vi. A better generalizing minimum has a smaller number of eigenvectors with a non-zero alignment of individual training data gradients, G\u03b8, signifying a simpler (therefore, better generalizing) decision boundary compared to other minima of the same 4To be precise, is set to a small number being the average maximum alignment with several random\n(4)\nnetwork on the same data. In other words, there are fewer directions in the parameter space wh shift corresponds to large errors in the training data. Finally, as G\u03b8 depends crucially on train samples and the number of Hessian eigenvectors, the comparison of G\u03b8 between minima is meaning only when they are reached with models with the same architecture and trained on the same data. N that its value changes between training procedures with fixed hyperparameters due to randomness the initialization.\nWe compute our generalization measure G\u03b8 as in (4) for all the datasets trained from normal, adversarial, and large norm initializations, leading to decision boundaries of varied complexity and observe that G\u03b8 captures the correct generalization order of the three minima in all cases as seen in Figure 3 and Table 1. We also compare the G\u03b8 with the standard flatness measures like the Hessian trace and its spectral norm. We confirm their superfluousness in Table 1, where the Hessian trace and spectral norm of the normally initialized network with the simplest decision boundary are larger than for networks with adversarial and large norm initializations. Interestingly, the L2 norm of the parameters also fails as a generalization measure despite the observation that the well-generalizing solutions tend to have a minimum norm (Wilson et al., 2017). Those observations hold across the simulated and real datasets as presented in Appendices I and M, respectively.\nDataset\nTraining\nG\u03b8 \u2193\ntrace(H) \u2193\n\u03bbmax(H) \u2193\n||\u03b8\u2217||2 \u2193\ngaussian\nnormal\n0.055 \u00b1 0.004\n0.176 \u00b1 0.010\n0.114 \u00b1 0.010\n19.60 \u00b1 0.15\nadversarial\n0.156 \u00b1 0.035\n0.003 \u00b1 0.001\n0.002 \u00b1 0.001\n105.00 \u00b1 0.005\nlarge norm\n0.114 \u00b1 0.040\n0.021 \u00b1 0.018\n0.017 \u00b1 0.012\n98.169 \u00b1 0.413\nMNIST-017\nnormal\n0.037 \u00b1 0.028\n6.288 \u00b1 4.697\n3.758 \u00b1 3.215\n2237.62 \u00b1 3526.8\nadversarial\n0.109 \u00b1 0.002\n0.945 \u00b1 0.117\n0.479 \u00b1 0.097\n938.378 \u00b1 0.032\nThe proposed generalization measure also overcomes another weakness of the standard Hessian measures and is invariant to the reparametrization as presented in Appendix J, as it relies on the decision boundary complexity which is also invariant to the reparametrization. The G\u03b8 has also limitations. As it arises from the alignment of the gradients of loss of training samples with the Hessian eigenvectors encoding various sections of the boundary, it may fail to signal an increased complexity of the decision boundary far from any training sample (see Appendix I for more details). The second limitation is related to the simplicity bias of neural networks.\n# 3.2 Shortcomings of our method due to simplicity bias\nSimplicity bias is the tendency of neural networks to learn \u201csimple\u201d models and has been hypothesized to explain generalization properties of neural networks (Arpit et al., 2017; Nakkiran et al., 2019). Shah et al. (2020) claims that simplicity bias may instead hurt generalization (in SGD and its variants), when networks prefer simpler features over complex ones that are more informative for prediction. In the context of the decision boundary, the simplicity bias is related to a bias towards a more linear boundary. As our generalization metric measures the simplicity of the decision boundary, it may fail to signal when the generalization capability of a model is diminished by simplicity bias. To validate it, we use the synthetic checkerboard dataset of Gaussian clusters, similar to the one analyzed by Shah et al. (2020); it has two classes and two features \u2013 one feature is simple (single linear boundary sufficient for 100% accuracy), and the other is complex (100% prediction needs at least n \u22121 linear pieces for n clusters). We study the minima reached by models trained to classify this dataset in two settings. The first setting is normal initialization, affected by simplicity bias, resulting in a more linear boundary and a narrow margin. In the second setting, which we call wide-margin, we encourage a boundary with a wider margin by pretraining on another dataset as explained in Appendix B, and then training on the same checkerboard dataset as in the first setting. In Figure 5, we show the decision boundary and the alignment of reinforcing gradients in input space with the top three eigenvectors vi. The Hessian eigenspectrum, presented in the fifth column, exhibits two outliers for both initializations. While the second setting has a wider margin and thus exhibits\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ce6f/ce6fbb11-0c68-434a-b86c-654a46b11dc0.png\" style=\"width: 50%;\"></div>\nFigure 5: Simplicity bias and margin estimation for checkerboard. We compare the alignments of the top three eigenvectors vi and the eigenspectrum, trained using two different initializations, normal (top row) and wide-margin initialization (bottom row). Both initializations have very similar generalization measures. (Last column) Margin estimation from xb, xmax i and xmin i .\nbetter generalization, the difference between G\u03b8 for normal and wide-margin initializations is small. To properly distinguish those solutions, we can instead estimate the margin width of the decision boundary as described in the next section.\n# 3.3 The order of eigenvectors is related to the margin width of the decision boundary\nWe observe in every setup (Figure 2 and Appendix B) that the order of the top eigenvectors follows the increasing margin of the encoded sections of the boundary. The topmost eigenvector captures the boundary section that separates the closest training data from two classes in the input space.\nThis opens up a possibility to estimate the margin of the decision boundary in higher input dimensions. To do so, we need two data points from the input space: a training sample xt that is closest to the boundary (the one that determines the smallest margin of the decision boundary) and a sample on the boundary xb, which should be as close to xt as possible, as this determines how good estimate of the margin we have. xt is chosen to have the largest alignment with the top Hessian eigenvector v1. Note that, a priori, we do not know the alignment sign of the training data xt closest to the artificial sample on the boundary xb. Hence, xmin t and xmax t are the smallest and largest alignments with v1 (yellow and purple dots in the last column of Figure 5). To find the sample on the boundary (red dots in Figure 5), we can optimize the features of an input sample such that its gradient has a maximum alignment with the top Hessian eigenvector. Then we compute the L2 distance between xb and xmin t , and between xb and xmax t in the input space and choose the smaller L2 distance as the margin. An example of such a margin width estimation is presented in Figure 5, where we correctly see that the less linear decision boundary corresponds to a wider margin compared to the linear decision boundary. This simple yet effective margin estimation technique, together with our generalization measure G\u03b8, enables a better understanding of the generalization ability of deep neural networks.\n# 3.4 Validation of our results on real data\nWe focused our analysis so far on low-dimensional datasets which allow to visualize the decision boundary and avoid relying on a proxy for its complexity. We now extend a part of our analysis to more realistic datasets by studying minima obtained within two settings, that is, normal and adversarial initialization. We obtain the results for Iris and four subsets of MNIST: MNIST-017, MNIST-179, MNIST-0179, and MNIST-1379, where numbers indicate selected classes of digits. Here we focus on results for MNIST-017, yet the full analysis is in Appendices K-M.\nIn particular, we see that the generalization measure G\u03b8 precisely distinguishes models trained with different initializations having different generalization abilities (Table 1). Moreover, we visualize the dataset using t-SNE in Figure 6 and color code the alignment between the training gradients and top Hessian eigenvectors. While t-SNE does not necessarily have the same data representation as a trained neural network, the alignment behavior for models obtained with the normal and adversarial initialization training seems to follow the one for the 2D datasets. It suggests that the top eigenvectors also encode the decision boundary. Finally, we also see a higher number of outliers in the eigenspectrum for complex boundary (last column of Figure 6).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/62ae/62aefea2-f114-4863-8bae-db8658df1d19.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 6: Normal and adversarial initialization training for MNIST-017 with t-SNE visualization. We visualize the MNIST-017 dataset with t-SNE and color code the alignments of gradients of all training samples onto the top 5 eigenvectors. (Last column) The eigenspectrum with the outliers.</div>\nProperties of the Hessian. Our work sheds light on various universal aspects of the training loss Hessian. While the localization of the gradient information in the top subspace of the Hessian is known (Gur-Ari et al., 2019), the observation that the top Hessian eigenvectors align with the gradients of samples at the decision boundary, therefore, they encode the decision boundary, provides a new perspective and a simpler way to study the complexity of high-dimensional decision boundary. In fact, our work aligns with the mathematical analysis of Papyan (2020) who connected the emergence of outliers (and therefore the top Hessian eigenvectors) to the \u201cbetween-class gradient second moment\u201d. Moreover, our work illustrates that the number of outliers in the Hessian spectrum is related to the complexity of the learned decision boundary, which was so far rather connected to the number of classes. Our findings shed light on the observation of Jastrzebski et al. (2019) that the loss in the subspace of the top Hessian eigenvectors is \u201cbowl-like\u201d and that decreasing learning rate within this subspace leads to better generalizing solutions: this procedure may lead to maximizing the margin of the decision boundary. Generalization. We confirm that the Hessian-based metrics like the trace or the largest eigenvalue are unreliable proxies for measuring the generalization ability of deep learning models. Instead, these metrics are more dependent on the training parameters like the number of epochs, as observed in Sagun et al. (2017). For example, Table 1 shows that the Hessian trace is the smallest for badly generalizing minima, which required the largest number of epochs to train. Interestingly, we see that within-class gradients at the minimum are more aligned with each other in the better generalizing case, as noted in Chatterjee & Zielinski (2022). Our findings suggest that this gradient \u201ccoherence\u201d emerges from the simplicity of the decision boundary and disappears as the complexity increases. Robustness and interpretability. The robustness of neural networks is an active area of research aiming to produce stable outputs towards small, semantically irrelevant input perturbations. Feng & Tu (2022) mapped the variations in inputs to variations of specific weight parameters, through which the Hessian connection between the input and parameter space is established. Combining this with our work may lead to a better understanding of why Hessian-based techniques could lead to more robust models (Moosavi-Dezfooli et al., 2019; Qin et al., 2019; Zhang et al., 2019; Srinivas et al., 2022) or more robust gradient-based explanations Dombrowski et al. (2019, 2022). In fact, they may simplify the decision boundary, causing gradients of similar inputs to align in one direction. This also explain the success of Hessian-based interpretation of neural networks (Koh & Liang, 2017; Madras et al., 2020; Dawid et al., 2022) and in pruning (LeCun et al., 1989; Yu et al., 2021). Practical implications. Establishing the connection between Hessian and the decision boundary learned by the network provides a new tool to study the boundary in high input dimensions. However, exact computation of the Hessian and its spectrum is hard for both large data and models. Instead, we can follow the observation from Appendix G and Ghorbani et al. (2019) that the top eigenvectors of the Hessian at the minimum have a large overlap with the top eigenvectors of the gradient covariance matrix, which enables efficient alignment computation but still requires an expensive eigendecomposition. We can also use efficient approximation techniques based on the Hessianvector product (Pearlmutter, 1994; Agarwal et al., 2017; Golmant et al., 2018) and the generalized Gauss-Newton decomposition of the Hessian (Sagun et al., 2017; Papyan, 2019, 2020).\nIn this work, we establish that the top Hessian eigenvectors characterize the decision boundary learned by the neural networks. With this understanding, we propose a generalization measure that shows promising empirical results in capturing the generalization of neural networks as it aims to quantify the complexity of the decision boundary. While this is the strength of our approach, it can also lead to overlooking the simplicity bias when it hurts generalization, as discussed in Section 3.2. In such a case, we propose a novel technique for estimating the margin of the decision boundary using the alignment with the top Hessian eigenvector. Naturally, one can also study the per-class margin through the boundary encompassing each class (Appendix E). While we show the invariance of our main result to architectures and choice of the loss function in Appendix F and confirm the observations for real datasets in Section 3.4 and Appendices K-M, we acknowledge the need to expand the study to more diverse datasets which is left for future work. Our work opens various avenues for further research. For instance, the meaning of the exact values of the alignment and their connection to the margin (if any) are elusive. Moreover, a trace of the Hessian sometimes correlates with a good generalization, which begs the question of the meaning of eigenvalues besides their respective order. We also see that eigenvectors encoding the simple boundary tend to be much sparser than the ones encoding the complex boundary. Determining if the alignment behavior of memorized samples is significantly different than the learned examples could shed light on understanding memorization and when it happens. Moreover, we observe differences in the alignment behavior between the optimizers, which may hint at different properties of minima that those optimizers lead to. To answer any of these questions, the key is to rigorously understand the connection between the top Hessian eigenvectors and the decision boundary in simplified models. Our results are also useful for improving pruning techniques and fighting catastrophic forgetting, e.g., by freezing parameters corresponding to the decision boundary learned so far. The Hessian-based access to the decision boundary can also open new directions in assessing the uncertainty of deep models\u2019 predictions. For example, uncertainty could be connected to the distance of the test sample to the closest boundary. Finally, provided efficient computation, our generalization measure and margin estimation technique could be used during training to promote better generalizing minima.\n# Acknowledgments and Disclosure of Funding\nWe thank Tony Bonnaire, Francesa Mignacco, Stefani Karp, Yatin Dandi, Artem Vysogorets, Boris Hanin, and Julia Kempe for useful discussions. This work started as an open problem posed by A.D. during the 2022 Les Houches Summer School on Statistical Physics and Machine Learning organized by Lenka Zdeborov\u00e1 and Florent Krzakala. M.S. is supported by the German Research Foundation (Research Training Group GRK 2428). A.D. acknowledges the financial support from the Foundation for the Polish Science. The Flatiron Institute is a division of the Simons Foundation.\nWe thank Tony Bonnaire, Francesa Mignacco, Stefani Karp, Yatin Dandi, Artem Vysogorets, Boris Hanin, and Julia Kempe for useful discussions. This work started as an open problem posed by A.D during the 2022 Les Houches Summer School on Statistical Physics and Machine Learning organized by Lenka Zdeborov\u00e1 and Florent Krzakala.\nM.S. is supported by the German Research Foundation (Research Training Group GRK 2428). A.D. acknowledges the financial support from the Foundation for the Polish Science. The Flatiron Institute is a division of the Simons Foundation.\n# References\nAgarwal, N., Bullins, B., and Hazan, E. Second-order stochastic optimization for machine learning in linear time. J. Mach. Learn. Res., 18:1\u201340, 2017. ISSN 15337928.\nAlain, G., Roux, N. L., and Manzagol, P.-A. Negative eigenvalues of the Hessian in deep neural networks, 2018. URL https://openreview.net/forum?id=S1iiddyDG.\nArpit, D., Jastrzebski, S., Ballas, N., Krueger, D., Bengio, E., Kanwal, M. S., Maharaj, T., Fischer, A., Courville, A., Bengio, Y., and Lacoste-Julien, S. A closer look at memorization in deep networks. In Precup, D. and Teh, Y. W. (eds.), Proceedings of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pp. 233\u2013242. PMLR, 06\u201311 Aug 2017. URL https://proceedings.mlr.press/v70/arpit17a.html.\nZhang, H., Yu, Y., Jiao, J., Xing, E., Ghaoui, L. E., and Jordan, M. Theoretically principled trade-off between robustness and accuracy. In Chaudhuri, K. and Salakhutdinov, R. (eds.), Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 7472\u20137482. PMLR, 09\u201315 Jun 2019. URL https://proceedings.mlr. press/v97/zhang19p.html.\n# Supplementary material\n# accompanying \u201cUnveiling the Hessian\u2019s Connection to the Decision Boundary\u201d\nWe provide the following results in the supplementary material.\n\u2022 Section A: Alignment of vectors: cosine similarity vs scalar product \u2022 Section B: The top Hessian eigenvectors and decision boundary for the additional datasets \u2022 Section C: Theoretical analysis \u2022 Section D: Directions other than the top Hessian eigenvectors do not align with the decision boundary \u2022 Section E: Decision boundary per class \u2022 Section F: Results are invariant to an architecture, loss, and optimizer: gaussian \u2022 Section G: The gradient covariance matrix vs the Hessian at the minimum \u2022 Section H: Decision boundaries during the training \u2022 Section I: Generalization measure for all simulated datasets and its limitations \u2022 Section J: Generalization measure is invariant to model reparameterization \u2022 Section K: Hessian analysis for Iris \u2022 Section L: Hessian analysis for MNIST \u2022 Section M: Generalization measure for Iris and MNIST\n# A Alignment of vectors: cosine similarity vs scalar product\nIn Equation (2), we have defined the alignment between the reinforcing gradient g\u03b8(x) from Equation (1) of an input x with eigenvector vi in terms of the cosine similarity as\nwhere \u27e8\u00b7, \u00b7\u27e9is the scalar product, and \u2225\u00b7 \u2225is the Euclidean norm of the vector.\n \u27e8\u00b7 \u00b7\u27e9 \u2225\u00b7 \u2225 As the main findings of our work result from comparing gradients of loss of individual training samples with the Hessian top eigenvectors, one may ask why we chose cosine similarity as the measure of similarity between the vectors instead, e.g., of the scalar product itself, \u27e8g\u03b8(x), vi\u27e9. We compare the two similarity metrics in Figure 7, where we immediately see the main weakness of the scalar product when it comes to studying the input space. First of all, due to the lack of gradients\u2019 normalization, the overlap highlights only points on the decision boundary. Large norm of gradients on the boundary dominates any existing alignment between the Hessian eigenvectors and gradients of samples far from the boundary. Secondly, contrary to the cosine similarity, the scalar product has no maximal value, which could guide the analysis of the decision boundary decomposition in terms of the Hessian eigenvectors.\n# B The top Hessian eigenvectors and decision boundary for the additional\n# B The top Hessian eigenvectors and decision boundary for the additional simulated datasets\nWithin this work, we use five simulated 2D datasets: gaussian with three classes, concentric circle and half-moon datasets with two classes, hierarchical gaussian with four classes, and checkerboard dataset with two classes. Details on their generation can be found in the code available here (src/datasets.py).\n(5)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5298/52988e52-d9ab-4a68-b84b-fb92ac30f31e.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 7: Comparison of similarity metrics for gaussian. (Top) Cosine similarity. (Bottom) Scalar product with a color bar limited to [\u22121, +1] (without normalizing the scalar product values).</div>\nIn Figure 8, we present the alignment of the reinforcing gradients of input samples with the top five Hessian eigenvectors for all the simulated datasets. We see consistently that the top Hessian eigenvectors align with gradients of loss of samples at the boundary. Finally, let us here specify how we have obtained the narrow- and wide-margin solutions for the classification of the checkerboard dataset in section 3.2. The mentioned checkerboard dataset consists of the two-class Gaussian mixture and is presented in the left panel of Figure 9. We train on it to achieve the linear boundary with a narrow margin due to simplicity bias inherent to neural\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/738b/738bdbaf-b041-4971-bd7e-00f210432ef6.png\" style=\"width: 50%;\"></div>\nFigure 8: Top Hessian eigenvectors and decision boundaries for all simulated datasets. (First column) The decision boundary in the data space obtained by training a two-layered fully connected network. (Other columns) The alignment with the top five eigenvectors illustrates that the top eigenvectors encode the decision boundary.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f86c/f86ce920-2cda-4b0f-99cd-fb1b45515f23.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 9: The checkerboard datasets used for (Left) training and (Right) pretraining the wide-margin setup in section 3.2 on simplicity bias analysis.</div>\nnetworks. The narrow-margin solution is presented in the top row of Figure 5. We call this \u201cnormal initialization\u201d, and we follow the same training procedure here as for all other normally initialized datasets. To obtain the wide-margin solutions presented both in the bottom row in Figure 5 and in the last row of Figure 8, we initialize the network with what we call the wide-margin initialization. We achieve this initialization as follows. First, we pretrain until 100% accuracy using the usual procedure on the dataset presented in the right panel of Figure 9. These are also Gaussian mixture clusters with the same variance parameters as the checkerboard dataset but with means in feature \u03d51 that bring the clusters closer, keeping feature \u03d52 the same. Then, we train on the first checkerboard dataset until 100% accuracy. Such a pretraining results in a decision boundary with a wider margin than without pretraining. Let us also note the difference between the wide-margin solutions presented in the bottom row in Figure 5 and in the last row of Figure 8. Interestingly, the top Hessian eigenvectors aligns with samples at the decision boundary in different ways resulting from the stochasticity of the training. In the bottom row in Figure 5, we see that the top Hessian eigenvector aligns with almost all samples across the decision boundary. Here, in the last row of Figure 8, the alignment separates across two top Hessian eigenvectors. Both solutions have approximately equally wide margins and similar generalization abilities. It further shows that the separation across the top Hessian eigenvectors results not only from the complexity of the decision boundary, but can change across runs and initializations.\n# C Theoretical analysis\nWe consider that the converged minimum \u03b8 := \u03b8\u2217is an exact minimum, meaning that the loss and its gradient at \u03b8\u2217is zero, i.e., L(\u03b8\u2217; D) = 0 and \u2207\u03b8L(\u03b8\u2217; D) = 0. Using this information, we expand the loss using the second-order Taylor\u2019s approximation at \u03b8 := \u03b8\u2217.\nL(\u03b8\u2217+ \u2206\u03b8; D) = 1 2\u2206\u03b8T H\u03b8\u2217\u2206\u03b8\nH\u03b8\u2217is the Hessian of the training loss function evaluated at the minimum. We denote its eigenvectors and corresponding eigenvalues as vi and \u03bbi. Now, let\u2019s consider \u2206\u03b8 := g\u03b8(x) ||g\u03b8(x)|| to be a reinforcing gradient of some input x in the dataset D := {X, Y}, and an overparametrized classifier (e.g., neural\nFrom Equation (6), for the loss to have a maximal change, the reinforcing gradient of x should be aligned with the direction of the steepest ascent of f(\u03b8\u2217, X). This implies that moving data x in the direction of the gradient of f(\u03b8\u2217, X) potentially changes the predicted class for x, thus increasing the loss. In other words, the alignment of the reinforcing gradient of x with the function\u2019s gradient is high for x near the decision boundary. From this understanding, we infer that the alignment of x with the Hessian eigenvectors is larger for x near the boundary than data points farther away from the right-hand side of Equation (6). As the alignment A(x) considers a normalized g\u03b8(x), this variability comes only from a different alignment of g\u03b8(x) for x\u2019s close and far from the boundary with different Hessian eigenvectors. As stated multiple times, the behavior of the Hessian spectra in deep learning setups is universal. Its spectrum has a small number of positive non-zero eigenvalues, \u03bb0, \u03bb1, . . . , \u03bbt, and the rest of the eigenvalues is close to zero. This, in turn, implies that the right side of the equation is large when g\u03b8(x) is aligned with the top Hessian eigenvectors with the largest eigenvalues \u03bb0, \u03bb1, . . . , \u03bbt. This implication strengthens our numerical observations about the top Hessian eigenvectors being aligned with the gradients of loss of data at the boundary.\n# D Directions other than the top Hessian eigenvectors do not align with the decision boundary\n# D Directions other than the top Hessian eigenvectors do not align with the\nTo test our finding connecting the top Hessian eigenvectors and decision boundary, we check the alignment of reinforcing gradients of individual input samples with vectors pointing in other directions in parameter space. In Figure 10 we compare the gradients\u2019 alignment with (1) the top five Hessian eigenvectors, (2) the bottom five Hessian eigenvectors (that correspond to the five smallest eigenvalues, i.e., five largest negative eigenvalues), (3) five randomly selected Hessian eigenvectors, and (4) five random directions in parameter space where each vector element is sampled from a standard Gaussian. Within this comparison, the color bar is normalized across the plots to [\u22121, +1]. We immediately see that directions other than the top Hessian eigenvectors are not aligned with reinforcing gradients in the slightest. Interestingly, when we use separate color bars for each plot and repeat the comparison in Figure 11, we see that the random directions may sometimes reflect the alignment of the gradients resulting from the decision boundary. Tiny alignment values around 10\u22122 show, however, that it reflects the coherence of gradients rather than encodes relevant directions in parameter space. The average of the maximal alignment of training reinforcing gradients with five randomly sampled directions in the\nTo test our finding connecting the top Hessian eigenvectors and decision boundary, we check the alignment of reinforcing gradients of individual input samples with vectors pointing in other directions in parameter space. In Figure 10 we compare the gradients\u2019 alignment with (1) the top five Hessian eigenvectors, (2) the bottom five Hessian eigenvectors (that correspond to the five smallest eigenvalues, i.e., five largest negative eigenvalues), (3) five randomly selected Hessian eigenvectors, and (4) five random directions in parameter space where each vector element is sampled from a standard Gaussian Within this comparison, the color bar is normalized across the plots to [\u22121, +1]. We immediately see that directions other than the top Hessian eigenvectors are not aligned with reinforcing gradients in the slightest.\n# E Decision boundary per class\nThe Hessian eigenvectors crucially depend on the loss landscape, which in turn depends on the data. When we analyze the Hessian with respect to the loss that only considers a specific class c, we observe that the top eigenvectors are now restricted to the boundaries that are relevant to deciding the \u201call-against-one\u201d for the selected class c. The results are presented in Figure 12.\n(6)\n# esults are invariant to an architecture, loss, and optimizer\nHere, we show that while the decision boundary may shift and the alignment values change, the connection between the topmost eigenvectors and the decision boundary is invariant to the architecture (Figure 13), the choice of the optimizer (Figure 14), and loss function (Figure 15).\nInterestingly, while SGD, Adam, AdamW, and RMSprop in Figure 14 reach similar decision boundaries, values of alignment of gradients across the input space with the top eigenvectors vary significantly. In particular, in SGD, the non-zero alignment with the top eigenvectors is preserved for gradients far from the boundary. In Adam, AdamW, and RMSprop, the alignment goes quickly to zero with the distance from the boundary. It may suggest that in such cases, the gradient-based interpretation methods such as influence functions (Koh & Liang, 2017) may fail to find examples that are similar to a sample far from the boundary. At the same time, the connection between the decision boundary itself and the top Hessian eigenvectors is preserved regardless of the optimizer.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/020e/020e77dd-8e33-4924-94a4-b1a560f4ed04.png\" style=\"width: 50%;\"></div>\nFigure 10: Comparison of different directions in parameter space and their alignment with the reinforcing gradients of input points in the 2D plane. Alignment color normalized to the interval between [\u22121, +1]. We show the top eigenvectors v1, . . . , v5 and compare them to the eigenvectors with the smallest eigenvalues where v\u22121 has the smallest eigenvalue and v\u22125 the fifth-smallest eigenvalue. We also sample some random directions from the Hessian eigenspace and finally compare to random directions in parameter space where each entry of the vector is sampled from a standard Gaussian.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6af0/6af09d91-1da6-4f5c-9de2-48e462b13cf1.png\" style=\"width: 50%;\"></div>\nFigure 11: Comparison of different directions in parameter space and their alignment with the reinforcing gradients of input points in the 2D plane - The color bars are normalized per plot. We show the top eigenvectors v1, . . . , v5 and compare them to the eigenvectors with the smallest eigenvalues where v\u22121 has the smallest eigenvalue and v\u22125 the fifth-smallest eigenvalue. We also sample some random directions from the Hessian eigenspace and finally compare to random directions in parameter space where each entry of the vector is sampled from a standard Gaussian.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f913/f9138686-078f-4a7e-a5e3-fd4e53bcefcd.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 12: Loss decomposed into separate classes. The decision boundaries are equivalent to those from Figure 2. Here, the training loss is decomposed into the losses of individual training points associated with a given class. The Hessian eigenvectors look different for each decomposition, and the top eigenvectors exactly show the decision boundary enclosing this class. Only the relevant class is shown.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/65b4/65b43647-bf78-4d94-be21-7ae726ca8878.png\" style=\"width: 50%;\"></div>\nFigure 13: Top eigenvectors of the Hessian for alternative model architectures. (First row) A two-layer neural network with 100 neurons per layer and the ReLU activation function. (Second row) The same with sigmoid activations. (Third row) The same as first but with 50 neurons per layer instead.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/071c/071c1d6c-54c3-439e-805f-4ef0b560cc07.png\" style=\"width: 50%;\"></div>\nFigure 14: Top eigenvectors of the Hessian for different optimizers: (First row) SGD, (Second row) Adam, (Third row) AdamW, and (Fourth row) RMSprop with the same learning rate of 0.2 and a batch size of 64. For optimizers besides SGD, the boundaries are more \u201cclear cut\u201d; The gradient at many places in the input space has zero alignment with their counterparts on the boundary.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/dc61/dc61f9b1-ab30-4dbd-a35b-37da96500664.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 15: Top eigenvectors of the Hessian for the negative log-likelihood loss (NLLLoss): (Top) gaussian dataset. (Middle) circle dataset. (Bottom) half-moon dataset.</div>\nHere, we study the covariance matrix of gradients of loss of individual training samples at th minimum defined as\nwhere training data D = {xi, yi}n i=1, xi \u2208Rd, and yi \u2208{1, . . . , C} is the class label. In Figure 16, we show that the top few eigenvectors of the covariance matrix \u03a3(\u03b8; D) actually encode the same information as the top few Hessian eigenvectors at the minimum as observed by Ghorbani et al. (2019) and Fort & Ganguli (2019). This observation can also be justified by the Hessian approximation with the gradient outer product holds well at the minimum. Therefore, the top subspace of \u03a3(\u03b8; D) can be used instead of the more computationally expensive Hessian to study the decision boundary.\nFigure 16: Gradient covariance matrix vs. Hessian. We compare the alignment of gradients of loss of input samples with the top eigenvectors of (Top) the Hessian H and (Bottom) the gradient covariance matrix \u03a3(\u03b8; D) defined in Equation 7. For the first two eigenvectors of both matrices, their alignment with gradients of input samples is very similar across the input space. The cosine similarity \u03b2i = \u27e8vH i , v\u03a3 i \u27e9of between the Hessian eigenvectors vH i and the gradient covariance matrix\u2019 eigenvectors vC i decreases with the values of their eigenvalues.\n# H Decision boundaries during the training\nInterestingly, we see that the top Hessian eigenvectors encode the decision boundary also away from the minimum during the training dynamics. We believe that the gradient covariance matrix will not exhibit this behavior since it is not at the minimum. We present the usual alignment analysis between gradients of loss of input samples and the top five Hessian eigenvectors for selected epochs of the regular training in Figure 17 and training starting from the adversarial initialization of Liu et al. (2020) in Figure 18.\n(7)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b6ff/b6ff8156-235e-4b27-810d-3f964d91e1a4.png\" style=\"width: 50%;\"></div>\nFigure 17: Top Hessian eigenvectors encode boundaries also away from the minimum. The overlap plots during different epochs in for normal training on gaussian. Epoch 0 is the boundary at initialization before training.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6f49/6f4925f7-29cc-47e4-8934-f646739f7df5.png\" style=\"width: 50%;\"></div>\n# eneralization measure for all simulated datasets and its lim\nIn Table 2, we present values of the generalization measure G\u03b8 introduced in Equation 4 for models trained on various simulated datasets and from different initializations. \u201cNormal training\u201d indicates the regular initialization of the neural networks, \u201cadversarial initialization\u201d follows the initialization procedure by Liu et al. (2020) that consists in pretraining the model on the same data but with random labels, and the \u201clarge norm training\u201d means starting from a default random initialization with the imposed large norm, as discussed in Section 2.2. We compare G\u03b8 with other metrics calculated at the minimum like the Hessian trace, its spectral norm, and L2 norm of the solution. We consistently see that models initialized adversarially or with a large norm learn more complex decision boundaries that generalize worse than the simple boundary learned by regularly trained models. The generalization measure G\u03b8 successfully distinguishes between those models in a large majority of cases, and other metrics are unreliable. The analogous results for real datasets like Iris and MNIST are in Appendix M. Table 2: Generalization measures comparison for the five simulated 2D datasets. We provide the mean of those measures and their standard deviation over 5 runs. A bold font marks the best generalizing minimum according to the studied metric, green (red) color indicates whether the indication is correct (wrong). With yellow, we mark correct indications with standard deviations being larger than the difference of compared means.\nDataset\nTraining\nG\u03b8 \u2193\ntrace(H) \u2193\n\u03bbmax(H) \u2193\n||\u03b8\u2217||2 \u2193\ngaussian\nnormal\n0.055 \u00b1 0.004\n0.176 \u00b1 0.010\n0.114 \u00b1 0.010\n19.60 \u00b1 0.15\nadversarial\n0.156 \u00b1 0.035\n0.003 \u00b1 0.001\n0.002 \u00b1 0.001\n105.00 \u00b1 0.005\nlarge norm\n0.114 \u00b1 0.040\n0.021 \u00b1 0.018\n0.017 \u00b1 0.012\n98.169 \u00b1 0.413\ncircle\nnormal\n0.044 \u00b1 0.007\n8.028 \u00b1 0.777\n4.965 \u00b1 0.514\n22.884 \u00b1 0.139\nadversarial\n0.059 \u00b1 0.003\n0.795 \u00b1 0.051\n0.439 \u00b1 0.037\n41.630 \u00b1 0.006\nlarge norm\n0.057 \u00b1 0.003\n6.320 \u00b1 0.833\n4.350 \u00b1 0.735\n41.840 \u00b1 0.226\nhalf-moon\nnormal\n0.036 \u00b1 0.003\n4.202 \u00b1 0.637\n2.958 \u00b1 0.479\n21.529 \u00b1 0.285\nadversarial\n0.072 \u00b1 0.006\n0.037 \u00b1 0.001\n0.017 \u00b1 0.001\n68.988 \u00b1 0.009\nlarge norm\n0.042 \u00b1 0.004\n1.119 \u00b1 0.563\n0.868 \u00b1 0.431\n64.807 \u00b1 0.201\nhierarchical\nnormal\n0.053 \u00b1 0.001\n12.450 \u00b1 0.595\n7.102 \u00b1 0.189\n20.034 \u00b1 0.202\nadversarial\n0.118 \u00b1 0.024\n3.394 \u00b1 1.035\n2.645 \u00b1 0.877\n121.675 \u00b1 0.062\nlarge norm\n0.059 \u00b1 0.009\n93.104 \u00b1 12.985\n36.787 \u00b1 3.936\n112.579 \u00b1 0.404\ncheckerboard\nnarrow-margin\n0.046 \u00b1 0.005\n0.240 \u00b1 0.050\n0.127 \u00b1 0.028\n19.267 \u00b1 0.097\nwide-margina\n0.043 \u00b1 0.001\n0.029 \u00b1 0.000\n0.014 \u00b1 0.000\n19.910 \u00b1 0.000\naThe standard deviation is almost since we initialize models across runs with the same pretrained solution to promote a wide margin.\nThe first case where G\u03b8 gives ambiguous results is distinguishing between the narrow- and widemargin minima as already discussed in Section 3.2. There, the G\u03b8 correctly indicated that both minima have similarly simple decision boundaries. The difference in the margin width can be detected with the margin width estimation technique proposed in Section 3.2. The second case of ambiguous results takes place when distinguishing between the minima obtained with the normal and large norm training for hierarchical gaussian, marked in yellow in Table 2. While on average G\u03b8 successfully indicates that minima obtained with normal initialization have simpler decision boundaries than those obtained with the large norm initialization, the standard\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b067/b0672946-771a-4881-9ae6-1e09f0dbbb30.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 19: Decision boundaries of different complexities for hierarchical gaussian. Alignment plots and histograms of the Hessian spectra for models obtained from normal training and a large norm initialization.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6c48/6c483e9e-f5c2-4a31-83c0-a01bbbffd52a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 20: Alignment of all training data with the top 25 eigenvectors for hierarchical gaussian for models obtained from the (Left) normal training and the(Right) large norm initialization. There are four classes {0, 1, 2, 3}. The dark lines show the mean of each class alignment.</div>\ndeviation exceeds the difference between the means. We identify a single case where our G\u03b8 fails in distinguishing minima with different complexities of decision boundaries and make a full analysis of the alignment in Figures 19 and 20 for the hierarchical gaussian with four classes. Firstly, we see from the first column of Figure 19 that the complexity of the decision boundary increases in the region with a small number of training samples. It indicates a limitation of our measure that is based on the \u201cinteraction\u201d between the training samples and neighboring decision boundary. If the decision boundary is simple close to the training samples but complex away from them, G\u03b8 may struggle in detecting this. Secondly, the number of outliers in the Hessian spectrum in the large norm case remains larger than in the normal case as visible in the last column of Figure 19. Finally, we take a closer look at the alignment of the top Hessian eigenvectors and gradients of loss of training samples in Figure 20 at the minima studied in Figure 19. We still see that for simpler decision boundaries the alignment of the training gradients localizes much more in the top Hessian subspace than for the complex boundaries. At the same time, G\u03b8 is almost the same for both cases, meaning it is an imperfect measure for the gradient alignment localization that seems to be a prevailing characteristic of minima with simple decision boundaries. We leave improvement of this scalar measure for further study. At the same time, we stress that G\u03b8 has correctly distinguished between minima with simple and complex decision boundaries from adversarial initializations in all the studied cases, and the ambiguity arises only in the large norm initializations.\n# Generalization measure is invariant to model reparamete\nA natural assumption is that if a model after a reparameterization yields the same output as the original one, their generalization abilities (and measures) should also be equal. This is not the case for metrics based on Hessian trace and ReLU networks; One can \u201cartificially\u201d sharpen a minimum while retaining the predictions of the original model using the \u03b1-scale transformation proposed by Dinh et al. (2017). In Figure 21, we see that while such a reparameterization indeed affects the Hessian\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ff68/ff6853a0-7391-4cf3-9481-37c2840899d2.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/78c2/78c2739d-ac3f-42f2-bb76-f7f7640684a1.png\" style=\"width: 50%;\"></div>\nFigure 22: Alignment of all training data with the top 25 Hessian eigenvectors for Iris. (Left) Normal training. (Right) Adversarial initialization. There are three classes {0, 1, 2}. The dark lines show the mean of each class alignment.\nspectrum, it does not impact the connection between the top Hessian eigenvectors and decision boundary. As a result, our generalization metric is also invariant to the reparameterization as it is based on the simplicity of the decision boundary that stays the same. At the same time, we see that the reparameterization may change the sign and values of the alignment. It is yet unclear why this happens, but this may further suggest that the exact values of the alignment are not informative.\n# K Hessian analysis for Iris\nWe have conducted our Hessian analysis for 2D datasets enabling straightforward visualization of the learned decision boundary. This approach has enabled a clear visual distinction between a simple or complex decision boundaries. Such a visual distinction is much needed in view of a limited (to our knowledge) theoretical description of the complexity of the decision boundary. At the same time, visualization of the decision boundary is hardly possible for high-dimensional datasets.\nHere, we extend our analysis to real datasets, that is to Iris dataset in this section and MNIST-based datasets in Appendix L. Firstly, we show that with our Hessian analysis, we distinguish between well- and badly generalizing minima in realistic deep learning setups. To do so, we compare the models trained with a regular initialization and the adversarial initialization (Liu et al., 2020), which are believed to reach a well- and badly generalizing minimum, respectively. For Iris, we show the corresponding Hessian spectra in the last column of Figure 23 and alignments of gradients of loss of individual training samples with the Hessian eigenvectors in Figure 22, respectively. We again see the larger number of outliers in the spectra in the case of more complex decision boundary. Most importantly, we see that the gradients have non-zero alignment with a much smaller number of Hessian eigenvectors in the case of normal training than in the adversarial case (Figure 22). We again see that the gradients are more aligned with each other in the well generalizing than badly generalizing minimum, as observed during the training dynamics in Chatterjee & Zielinski (2022).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/84b9/84b9f46f-724b-4427-af37-01c2d6c470b1.png\" style=\"width: 50%;\"></div>\nFigure 23: Experimental results on Iris. (First column) Two features (petal and sepal length) out of four of the Iris dataset with color-coded classes. (Other columns) The alignment of gradients of the loss of individual training samples with the top five Hessian eigenvectors. (Last column) Histograms of the Hessian spectra. (Top) Well-generalizing minimum obtained with normal training. (Bottom) Badly generalizing minimum obtained with an adversarial initialization (Liu et al., 2020).\nThe generalization metric G\u03b8 captures this difference as expected (is lower for well generalizing minimum) and is listed along with the MNIST results in Table 3 in Appendix M. Moreover, our low-dimensional analysis in the main body shows that the drastically different behavior of training gradients alignment with the Hessian eigenvectors results from a different complexity of the decision boundary. In other words, training gradients align with a larger number of the top Hessian eigenvectors because around training samples in input space, there are numerous sections of the decision boundary encoded in multiple directions in parameter space. While we could make this connection clear in the case of 2D datasets, it is more challenging for four dimensions and impractical for significantly larger dimensions. For Irises, we instead visualize samples by selecting only two features out of four and without the decision boundaries. Then we color code the alignment of the gradient of their individual losses at the minimum with the top Hessian eigenvectors. We present the normal and adversarial training results in Figure 23. We can see a clearly different behavior of the alignment between the well- and badly-generalizing minimum. This suggests a different complexity of the decision boundary following results from the low-dimensional data.\n# L Hessian analysis for MNIST\nFinally, we make an analogous Hessian analysis for the MNIST-based datasets. To decrease the complexity of the dataset and better understand the dependence of the results on the number of classes, we create four subsets of MNIST: MNIST-017, MNIST-179, MNIST-0179, and MNIST-1379, where numbers indicate selected classes of digits. Each class has a few hundred samples sampled randomly from the MNIST dataset. The analysis of the alignment of the gradients of loss of individual training samples and the top Hessian eigenvectors is presented in Figure 24. We continue to see that the alignment for the regular training is more localized in the space spanned by the top Hessian eigenvectors. We also see selfalignment of the gradients (Chatterjee & Zielinski, 2022) that maybe stops being so apparent in the top few eigenvectors. Moreover, as we mentioned in Appendix K, while we could make a clear connection between Hessian-gradient alignment and complexity of decision boundary in the case of 2D datasets, such a visualization is impractical for high input dimensions. Instead, we make the following non-rigorous analysis. We visualize the high-dimensional MNIST samples in a 2D plot using t-distributed stochastic neighbor embedding (t-SNE) and then color code the alignment of the gradient of their individual losses at the minimum. We present the normal and adversarial training results in Figure 25. Even if there is no guarantee that the neural network representation of the data is related to the one obtained by t-SNE nor that the learned decision boundary in the input space corresponds simply to the boundaries between t-SNE generated clusters, we still can see a clearly different behavior of the alignment between the well- and badly-generalizing minimum. Finally, the Hessian spectra for all MNIST-based datasets are in the last column of Figure 25. We consistently see that the number of outliers increases for the badly generalizing minima. We also see that metrics like the Hessian trace or its largest eigenvalue fail to capture the difference between the minima\u2019s generalizing abilities. On the other hand, our generalization measure, G\u03b8, consistently provides correct indications. We make this comparison apparent in Table 3 in Appendix M.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/270e/270e606e-b9ea-4705-93c8-be1719ac0849.png\" style=\"width: 50%;\"></div>\nFigure 24: Normal and adversarial initialization training for MNIST-017, MNIST-179, MNIST0179, and MNIST-1379. We plot the alignments of gradients of all training samples onto all eigenvectors ordered by their eigenvalues. Only the largest eigenvectors have non-zero alignment with the gradients of training samples, and their number increases for the training from the adversarial initialization.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3d6e/3d6e3575-4e1f-4010-accf-0cd79776d845.png\" style=\"width: 50%;\"></div>\nFigure 25: Normal and adversarial initializations training for MNIST-179, MNIST-0179, and MNIST-1379 with t-SNE visualization and Hessian eigenspectra. We visualize the MNIST-based datasets with t-SNE and color code the alignments of gradients of all training samples onto all eigenvectors ordered by their eigenvalues. Multiple eigenvectors have non-zero alignment with the gradients of training samples, and there is little ordering of the samples\u2019 colors suggesting complex decision boundaries. (Last column) Hessian eigenspectra.\n<div style=\"text-align: center;\">Table 3: Generalization measure comparison for real datasets Iris and different subsets of MNIST under different initializations. We provide the mean of those measures and their standard deviation over 5 runs. A bold font marks the best generalizing minimum according to the studied metric, green (red) color indicates whether the indication is correct (wrong).</div>\nDataset\nTraining\nG\u03b8 \u2193\ntrace(H) \u2193\n\u03bbmax(H) \u2193\n||\u03b8\u2217||2 \u2193\nIris\nnormal\n0.031\u00b10.006\n67.857\u00b15.943\n65.005\u00b16.072\n13.998\u00b10.221\nadversarial\n0.094\u00b10.002\n8.324\u00b10.235\n5.934\u00b10.067\n68.361\u00b12.040\nMNIST-017\nnormal\n0.037\u00b10.028\n6.288\u00b14.697\n3.758\u00b13.215\n2237.6\u00b13526.8\nadversarial\n0.109\u00b10.002\n0.945\u00b10.117\n0.479\u00b10.097\n938.38\u00b10.03\nMNIST-179\nnormal\n0.045\u00b10.063\n14.714\u00b114.783\n8.270\u00b18.262\n731.65\u00b1716.37\nadversarial\n0.209\u00b10.006\n5.222\u00b10.740\n1.611\u00b10.271\n268.65\u00b10.06\nMNIST-0179\nnormal\n0.043\u00b10.010\n28.472\u00b19.840\n13.254\u00b16.312\n387.54\u00b1129.66\nadversarial\n0.110\u00b10.003\n3.180\u00b10.399\n0.946\u00b10.203\n209.41\u00b10.01\nMNIST-1379\nnormal\n0.077\u00b10.031\n18.380\u00b116.588\n6.868\u00b16.368\n249.63\u00b1135.32\nadversarial\n0.135\u00b10.015\n2.938\u00b10.164\n0.844\u00b10.029\n398.19\u00b10.17\n# M Generalization measure for Iris and MNIST\nFor the convenience of the reader, in Table 3, we present values of the generalization metric G\u03b8 introduced in Equation 4 for models trained on various real datasets and from different initializations. \u201cNormal training\u201d indicates the regular initialization of the neural networks. Adversarial initialization follows the initialization by Liu et al. (2020) that consists in pretraining on the same data but with random labels, as discussed in Section 2.2. In the low-dimensional datasets, we consistently see that models initialized adversarially learn more complex decision boundaries that generalize worse than the simple boundary learned by regularly trained models. As we cannot visualize the decision boundary for the high-dimensional data, we skip the analysis of the large-norm initialization here. Instead, we use only the established adversarial initialization by Liu et al. (2020), which has been shown to produce complex boundaries and badly generalizing minima. The generalization metric successfully distinguishes between those models. The analogous results for simulated 2D datasets are in Appendix I.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of understanding the properties of well-generalizing minima in deep learning, highlighting the connection between decision boundary complexity and Hessian eigenvalues. Previous methods struggled to establish this link, necessitating a new approach to further research in this area.",
        "problem": {
            "definition": "The paper aims to solve the issue of characterizing the decision boundary learned by neural networks and understanding its complexity in relation to generalization.",
            "key obstacle": "Existing methods lack a clear connection between decision boundary complexity and the properties of minima, particularly concerning the role of Hessian eigenvalues."
        },
        "idea": {
            "intuition": "The inspiration for this idea stems from the observation that the number of outliers in the Hessian spectrum correlates with the complexity of the decision boundary learned by the neural network.",
            "opinion": "The proposed idea involves using the top eigenvectors of the Hessian to characterize the decision boundary, leading to a new generalization measure and margin estimation technique.",
            "innovation": "The primary innovation lies in establishing that the top eigenvectors of the Hessian encode information about the decision boundary, providing a new metric for assessing generalization."
        },
        "method": {
            "method name": "Hessian-based Decision Boundary Analysis",
            "method abbreviation": "HDBA",
            "method definition": "This method utilizes the top eigenvectors of the Hessian matrix of the training loss to analyze and characterize the decision boundary of neural networks.",
            "method description": "The core of the method involves aligning the gradients of training samples with the top Hessian eigenvectors to assess decision boundary complexity.",
            "method steps": [
                "Calculate the Hessian matrix of the training loss.",
                "Obtain the eigenvalues and eigenvectors of the Hessian.",
                "Align gradients of training samples with the top eigenvectors.",
                "Count the number of eigenvectors with non-zero alignment to derive the generalization measure."
            ],
            "principle": "The effectiveness of this method is grounded in the observation that gradients on the decision boundary align with the top Hessian eigenvectors, indicating their role in defining the boundary's complexity."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted on various simulated datasets (e.g., Gaussian mixtures, concentric circles) and real datasets (e.g., Iris, MNIST) to validate the proposed method.",
            "evaluation method": "The performance of the method was assessed by comparing the generalization measure across different training initializations and analyzing the alignment of gradients with Hessian eigenvectors."
        },
        "conclusion": "The experiments demonstrate that the proposed Hessian-based generalization measure effectively captures the complexity of decision boundaries, with clear distinctions between well- and poorly generalizing minima.",
        "discussion": {
            "advantage": "The key advantage of the proposed approach is its ability to provide a direct link between the Hessian eigenvalues and decision boundary complexity, offering a new perspective on generalization in neural networks.",
            "limitation": "A limitation is the potential for simplicity bias in neural networks, which may lead to underestimating the complexity of certain decision boundaries.",
            "future work": "Future research should explore the implications of the findings on model robustness, investigate the relationship between eigenvalue distributions and generalization, and extend the analysis to more diverse datasets."
        },
        "other info": {
            "acknowledgments": "The authors thank various individuals for discussions and support during the research. Funding sources include the German Research Foundation and the Foundation for Polish Science."
        }
    },
    "mount_outline": [
        {
            "section number": "1.2",
            "key information": "The paper aims to solve the issue of characterizing the decision boundary learned by neural networks and understanding its complexity in relation to generalization."
        },
        {
            "section number": "2.1",
            "key information": "The proposed idea involves using the top eigenvectors of the Hessian to characterize the decision boundary, leading to a new generalization measure and margin estimation technique."
        },
        {
            "section number": "3.1",
            "key information": "The method utilizes the top eigenvectors of the Hessian matrix of the training loss to analyze and characterize the decision boundary of neural networks."
        },
        {
            "section number": "4.3",
            "key information": "The key advantage of the proposed approach is its ability to provide a direct link between the Hessian eigenvalues and decision boundary complexity, offering a new perspective on generalization in neural networks."
        },
        {
            "section number": "6.2",
            "key information": "Future research should explore the implications of the findings on model robustness, investigate the relationship between eigenvalue distributions and generalization, and extend the analysis to more diverse datasets."
        }
    ],
    "similarity_score": 0.5546114072905404,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-0115_inter/papers/Unveiling the Hessian's Connection to the Decision Boundary.json"
}