{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2403.01744",
    "title": "NoteLLM: A Retrievable Large Language Model for Note Recommendation",
    "abstract": "People enjoy sharing \"notes\" including their experiences within online communities. Therefore, recommending notes aligned with user interests has become a crucial task. Existing online methods only input notes into BERT-based models to generate note embeddings for assessing similarity. However, they may underutilize some important cues, e.g., hashtags or categories, which represent the key concepts of notes. Indeed, learning to generate hashtags/categories can potentially enhance note embeddings, both of which compress key note information into limited content. Besides, Large Language Models (LLMs) have significantly outperformed BERT in understanding natural languages. It is promising to introduce LLMs into note recommendation. In this paper, we propose a novel unified framework called NoteLLM, which leverages LLMs to address the item-to-item (I2I) note recommendation. Specifically, we utilize Note Compression Prompt to compress a note into a single special token, and further learn the potentially related notes' embeddings via a contrastive learning approach. Moreover, we use NoteLLM to summarize the note and generate the hashtag/category automatically through instruction tuning. Extensive validations on real scenarios demonstrate the effectiveness of our proposed method compared with the online baseline and show major improvements in the recommendation system of Xiaohongshu.",
    "bib_name": "zhang2024notellmretrievablelargelanguage",
    "md_text": "# NoteLLM: A Retrievable Large Language Model for Note Recommendation\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bec6/bec6bda6-f358-48fb-a7a5-fa89b0b69081.png\" style=\"width: 50%;\"></div>\n25 Mar 2024\nPeople enjoy sharing \"notes\" including their experiences within online communities. Therefore, recommending notes aligned with user interests has become a crucial task. Existing online methods only input notes into BERT-based models to generate note embeddings for assessing similarity. However, they may underutilize some important cues, e.g., hashtags or categories, which represent the key concepts of notes. Indeed, learning to generate hashtags/categories can potentially enhance note embeddings, both of which compress key note information into limited content. Besides, Large Language Models (LLMs) have significantly outperformed BERT in understanding natural languages. It is promising to introduce LLMs into note recommendation. In this paper, we propose a novel unified framework called NoteLLM, which leverages LLMs to address the item-to-item (I2I) note recommendation. Specifically, we utilize Note Compression Prompt to compress a note into a single special token, and further learn the potentially related notes\u2019 embeddings via a contrastive learning approach. Moreover, we use NoteLLM to summarize the note and generate the hashtag/category automatically through instruction tuning. Extensive validations on real scenarios demonstrate the effectiveness of our proposed method compared with the online baseline and show major improvements in the recommendation system of Xiaohongshu.\n[cs.IR]\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WWW \u201924 Companion, May 13\u201317, 2024, Singapore, Singapore \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0172-6/24/05...$15.00 https://doi.org/10.1145/3589335.3648314\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/71b4/71b4acc3-f2c5-446f-9f64-f90f93f57fd4.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><Instruc)on> <Output Guidance> <Input Note> <Note Embed></div>\nFigure 1: An example of recommending the relevant note from millions-level notes pool via NoteLLM. Learning hashtag generation benefits item-to-item recommendation tasks.\n# CCS CONCEPTS \u2022 Information systems \u2192Recommender systems.\n# CCS CONCEPTS\nKEYWORDS\n# KEYWORDS\nLarge Language Model; Recommendation; Hashtag Generation\nACM Reference Format: Chao Zhang, Shiwei Wu, Haoxin Zhang, Tong Xu, Yan Gao, Yao Hu, Di Wu, and Enhong Chen. 2024. NoteLLM: A Retrievable Large Language Model for Note Recommendation. In Companion Proceedings of the ACM Web Conference 2024 (WWW \u201924 Companion), May 13\u201317, 2024, Singapore, Singapore. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/ 3589335.3648314\n# 1 INTRODUCTION\nFocused on user-generated content (UGC) and providing a more authentic and personalized user experience, social media like Xiaohongshu and Lemon8 have gained significant popularity among users. These platforms encourage users to share their product reviews, travel blogs, and life experiences, among other content, also referred to as \"notes\". By providing more personalized notes based on user preferences, note recommendation plays a crucial part in enhancing user engagement [16, 34, 48, 64]. Item-to-item (I2I) note recommendation is a classic way to retrieve notes of potential interest to the user from the millions-level notes pool [19, 65]. Given a target note, I2I methods select the relevant notes according to content [65] or collaborative signals [19]. Existing online methods of I2I note recommendation usually input whole note content into BERT-based models [3] to generate embeddings of notes, and recommend relevant notes based on embedding similarity [11, 36]. However, these methods merely treat hashtags/categories as a component of note content, underutilizing their potential. As shown in Figure 1, hashtags/categories (e.g., # Singapore) represent the central ideas of notes, which are crucial in determining whether two notes contain related content. In fact, we find that generating hashtags/categories is similar to producing note embeddings. Both compress the key note information into limited content. Therefore, learning to generate hashtags/categories can potentially enhance the quality of embeddings. Besides, Large Language Models (LLMs) have recently exhibited powerful abilities in natural languages [10, 24, 42, 54] and recommendations [1, 2, 34, 59]. However, there is a scarcity of research investigating the application of LLMs in I2I recommendations. Utilizing LLMs to improve I2I note recommendations holds considerable promise. Inspired by the above insights, we propose a unified multi-task approach called NoteLLM in this paper. Based on LLMs, NoteLLM learns from the I2I note recommendation and hashtag/category generation tasks, aiming to enhance the I2I note recommendation ability by learning to extract condensed concepts. Specifically, we first construct a unified Note Compression Prompt for each note sample and then decode via pre-trained LLMs (e.g., LLaMA 2 [42]), which utilize a special token to compress the note content and generate hashtags/categories simultaneously. To construct the related note pairs, we count the co-occurrence scores for all note pairs from user behaviours, and form the set of co-occurrence scores for each note. We select notes with the highest co-occurrence scores in the set as the related notes for a given note. Further, to recommend the relevant notes for each sample, Generative-Contrastive Learning (GCL) utilizes the compressed tokens as the embedding of each note, and then trains the LLMs to identify the related notes from in-batch negatives. Simultaneously, we employ Collaborative Supervised Fine-tuning (CSFT) approach to train models to generate hashtags/categories for each note. Since both the compression token learned by the I2I note recommendation task and the hashtag/category generation task aim to extract the key concept of the note content, CSFT can enhance note embeddings effectively. Our paper makes the following contributions:\n\u2022 To the best of our knowledge, our NoteLLM framework is the first to address the I2I recommendation task utilizing LLMs. It reveals\nthat introducing LLMs is a practical and promising strategy to enhance I2I recommendation systems. \u2022 We propose a multi-task framework to learn I2I recommendation task and hashtag/category generation task to enhance note embeddings. We demonstrate that learning to generate the compressed concepts is beneficial to the I2I recommendation task. \u2022 Extensive validations on offline experiments and online industrial scenarios of Xiaohongshu demonstrate the effectiveness of our proposed technical framework for note recommendation.\n# 2 RELATED WORK\n# 2.1 I2I Recommendation\nI2I recommendation is a crucial technique that can recommend a ranked list of items from a large-scale item pool based on a target item. I2I recommendation either pre-constructs the I2I index [55] or retrieves relevant items online using the approximate k-nearest neighbor method [12]. Traditional I2I recommendations typically rely solely on collaborative signals from user behaviors [55, 67]. However, these methods cannot manage cold-start items due to lack of user-item interaction [65]. To address this issue, numerous studies have investigated content-based I2I recommendations [8, 65]. We focus on the text-based I2I recommendation system, which measures the similarity of items based on their textual content. Initially, representation of text-based I2I recommendation relied on a termbased sparse vector matching mechanism [35, 37]. With the advent of deep learning, neural networks have proven more adept at representing text information [3, 27]. Previous works [13, 25, 52, 53] transform texts into embeddings in the same latent space to measure their relationship through embedding similarity. LLMs have recently gained great attention for their impressive abilities [33, 54, 56]. However, the application of LLMs in I2I recommendation remains unexplored. Besides, some studies treat LLMs solely as encoders for generating embeddings [10, 26, 28], failing to leverage their full potential for generation. In NoteLLM, we utilize LLMs to generate hashtags/categories, which can enhance note embeddings.\n# 2.2 LLMs for Recommendation\nLLMs have recently made significant advancements [31, 41, 42]. Consequently, numerous studies incorporate LLMs into recommendation tasks [5, 18, 50]. There are three main methods of integrating LLMs with recommendations [18, 50]. The first method is utilizing LLMs to augment data [21, 29, 51]. Due to the abundant world knowledge contained by LLMs, the augmented data are more prominent and diverse than the raw data [23, 46, 51]. However, these methods require continuous preprocessing of the testing data to align with the augmented training data and are highly dependent on the quality of LLMs\u2019 generation. The second method is leveraging LLMs to recommend directly. These methods design special prompts [9, 20, 43] or use supervised finetuning [1, 2, 59] to induce LLMs to answer the given questions. Nevertheless, because of the limited context length, these methods only focus on the reranking stage [7, 59], which only contains dozens of candidate items. The last method is adopting LLMs as the encoders to generate embeddings representing specific items [15, 49]. Although these methods are effective to extract information, they all discard the generative\ncapabilities of LLMs. In contrast to above methods, NoteLLM employs LLMs during the recall phase and learns hashtag generation to improve LLMs\u2019 ability to produce embeddings.\n# 2.3 Hashtag/Category Generation from Text\nHashtags and categories, as tagging mechanisms on social media, streamline the identification of topic-specific messages and aid users in finding themed content. Generating these from text can assist in creating identifiers for untagged notes or suggesting options to users based on their preferences. In this domain, there are three main methods: extractive, classification, and generative methods. Extractive methods identify key phrases in texts as hashtags or categories [61, 63], but cannot obtain those not present in the original text. Classification methods view this task as a text classification problem [14, 58, 60]. However, these may yield sub-optimal results due to the diverse, free-form nature of human-generated hashtags. Generative methods generate the hashtags/categories directly according to input texts [4, 44, 45]. Whereas, these methods are limited to solving the hashtag/category generation task. In NoteLLM, LLMs perform multi-task learning, simultaneously executing I2I recommendation and hashtag/category generation. Due to the similarity of these two tasks, learning to generate the hashtag/category can also enhance the I2I recommendation.\n# 3 PROBLEM DEFINITION\nIn this section, we introduce the problem definition. We assume N = {\ud835\udc5b1,\ud835\udc5b2, ...,\ud835\udc5b\ud835\udc5a} as note pool, where \ud835\udc5ais the number of notes. Each note contains a title, hashtag, category, and content. We denote the \ud835\udc56-th note as \ud835\udc5b\ud835\udc56= (\ud835\udc61\ud835\udc56,\ud835\udc61\ud835\udc5d\ud835\udc56,\ud835\udc50\ud835\udc56,\ud835\udc50\ud835\udc61\ud835\udc56), where \ud835\udc61\ud835\udc56, \ud835\udc61\ud835\udc5d\ud835\udc56, \ud835\udc50\ud835\udc56, \ud835\udc50\ud835\udc61\ud835\udc56mean the title, the hashtag, the category and the content respectively. In the I2I note recommendation task, given a target note \ud835\udc5b\ud835\udc56, the LLMbased retriever aims to rank the top-\ud835\udc58notes, which are similar to the given note, from the note pool N\\{\ud835\udc5b\ud835\udc56}. In the hashtag/category generation task, the LLM is utilized to generate the hashtag \ud835\udc61\ud835\udc5d\ud835\udc56 according to \ud835\udc61\ud835\udc56and \ud835\udc50\ud835\udc61\ud835\udc56. Besides, in the category generation task, the LLM is to generate the category \ud835\udc50\ud835\udc56according to \ud835\udc61\ud835\udc56, \ud835\udc61\ud835\udc5d\ud835\udc56and \ud835\udc50\ud835\udc61\ud835\udc56.\n# 4 METHODOLOGY\n# 4.1 Framework of NoteLLM\nIn this subsection, we introduce the framework of NoteLLM, which comprises three key components: Note Compression Prompt Construction, GCL, and CSFT, as illustrated in Figure 2. We employ Note Compression Prompt to flexibly manage the I2I recommendation and hashtag/category generation tasks. These prompts are then tokenized and fed into LLMs. NoteLLM integrates both collaborative signals and semantic information into the hidden states. GCL uses the hidden states of the generated compressed word to conduct contrastive learning, thereby acquiring collaborative signals. Furthermore, CSFT leverages the semantic and collaborative information of the note to generate hashtags and categories.\n# 4.2 Note Compression Prompt\nWe employ a unified Note Compression Prompt to facilitate both I2I recommendation and generation tasks. To leverage the generative capabilities of autoregressive LLMs for I2I recommendation\ntasks [10], our aim is to condense the note content into a single\nspecial token. This condensed special token is then used to acquire\ncollaborative knowledge through GCL. Subsequently, we generate\nhashtags/categories using this knowledge via CSFT.\nSpecifically, we propose the following prompt template for gen-\neral note compression and hashtags/categories generation:\nPrompt: [BOS]<Instruction> <Input Note> The compression\nword is:\"[EMB]\". <Output Guidance> <Output>[EOS]\nIn this template, [BOS], [EMB], and [EOS] are special tokens,\nwhile <Instruction>, <Input Note>, <Output Guidance>, and <Out-\nput> are placeholders replaced by specific content. The specific\ncontent for category generation is defined as follows:\nNote Compression Prompt for Category Generation.\n<Instruction>: Extract the note information in json format,\ncompress it into one word for recommendation, and generate\nthe category of the note.\n<Input Note>: {\u2019title\u2019: \ud835\udc61\ud835\udc56, \u2019topic\u2019: \ud835\udc61\ud835\udc5d\ud835\udc56, \u2019content\u2019: \ud835\udc50\ud835\udc61\ud835\udc56}.\n<Output Guidance>: The category is:\n<Output>: \ud835\udc50\ud835\udc56\nThe template for hashtag generation is presented below:\nNote Compression Prompt for Hashtag Generation.\n<Instruction>: Extract the note information in json format,\ncompress it into one word for recommendation, and generate\n<j> topics of the note.\n<Input Note>: {\u2019title\u2019: \ud835\udc61\ud835\udc56, \u2019content\u2019: \ud835\udc50\ud835\udc61\ud835\udc56}.\n<Output Guidance>: The <j> topics are:\n<Output>: <j> topics from \ud835\udc61\ud835\udc5d\ud835\udc56\nGiven the unpredictability of the number of hashtags generated by users, we randomly select a subset of original hashtags as the output target for hashtag generation to minimize potential misguidance to LLMs. The number of randomly selected hashtags, denoted as <j>, is incorporated into both the <Instruction> and <Output Guidance>. Once the prompts are completed, they are tokenized and fed into the LLM. The LLM then distills the collaborative signals and key semantic information into the compressed word and generates hashtags/categories based on the central ideas of notes.\nPre-trained LLMs usually learn new knowledge via instruction tuning [47, 62] or Reinforcement Learning from Human Feedback (RLHF) [32, 38]. These methods mainly focus on leveraging semantic information to enhance the effectiveness and safety of the LLMs. However, relying solely on semantic information in LLMs is insufficient for recommendation tasks [6, 20]. Collaborative signals, which are absent in LLMs, play a vital role in identifying the notes that are of specific interest to users [6, 20]. Therefore, we propose GCL to empower LLMs to capture stronger collaborative signals. In contrast to learning from specific answers or reward models, GCL adopts contrastive learning, which learns the relational proximity among notes from a holistic perspective. In order to integrate collaborative signals into LLMs, we adopt the co-occurrence mechanism to construct the related note pairs based on user behaviours. This mechanism is based on the assumption that notes frequently read together are likely related. Therefore, we collect user behavior data within one week for the co-occurrence\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bf88/bf883e30-021c-4b03-a910-bcb47d385007.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d258/d258aa5e-2bd7-474d-8276-0df3e3dd4f53.png\" style=\"width: 50%;\"></div>\nGenerative-Contrastive Learning\nHidden States\n...\n...\n\u201c   [EMB]   \u201d\nToken\nCollaborative Positive\nIn-batch Negative\n\ud835\udc3f\ufffd\ufffd\nCollaborative Supervised Fine Tuning\nOutput Hidden States\n...\n...\nTarget\n\ud835\udc3f\ufffd\ufffd\ufffd\nFree-form Hashtag Output: \n\ud835\udc61\ud835\udc5d\ufffd\nCloset Category Output:  \n\ud835\udc50\ufffd\n<Instruction>\n<Input Note>\n<Note Embed>\n<Output Guidance>\n<Output>\n[EOS]\nExtract the note \ninformation \u2026\nThe compression \nword is: [EMB]\nThe hashtag/ \ncategory is: \n\ud835\udc61\ud835\udc5d\ufffd/\ud835\udc50\ufffd\n{\u2019title\u2019: \ud835\udc61\ufffd, ..., \n\u2018content\u2019: \ud835\udc50\ud835\udc61\ufffd}\n[BOS]\nNote Compression Prompt\nPre-trained Large Language Model \n(e.g., LLaMA 2)\nRelated Note Pair Construction\nUser #1\nNote #1\nUser #2\nNote #2\nNote #3\n\ud835\udc3f\ufffd\ufffd\n\ud835\udc3f\ufffd\ufffd\ufffd\nCalculate loss \ud835\udc3f\nI2I Note Recommend\nNote Hashtag Generation\nNote Category Generation\nn\n#Singapore\n#WWW conference\nTravel -> Asia\nAcademic Conference\nTarget\nNote Pool\nCandidate\nOnline  Application\nOffline  Training\n<div style=\"text-align: center;\">Note Compression Prompt</div>\nFigure 2: The NoteLLM framework uses a unified prompt for I2I note recommendations and hashtag/category generation. Notes are compressed via the Note Compression Prompt and processed by pre-trained LLMs. We utilize the co-occurrence mechanism o construct the related note pairs and train the I2I recommendation task using Generative-Contrasting Learning. NoteLLM also extracts note\u2019s key concepts for hashtag/category generation, enhancing the I2I recommendation task.\ncount. We count the occurrences in which users viewed note \ud835\udc5b\ud835\udc34and subsequently clicked on note \ud835\udc5b\ud835\udc35. Simultaneously, to differentiate the contribution of co-occurrence from different users, we assigned varying weights to distinct clicks. Specifically, we compute the co-occurrence score as following:\nwhere \ud835\udc60\ud835\udc5b\ud835\udc34\u2192\ud835\udc5b\ud835\udc35represents the co-occurrence score from note \ud835\udc5b\ud835\udc34to note \ud835\udc5b\ud835\udc35, \ud835\udc48is the number of users in this user behavior data, and \ud835\udc41\ud835\udc56 denotes the quantity of the note set clicked by the \ud835\udc56-th user in the user behavior data. This operation aims to prevent the misdirection of active users, who might indiscriminately click on every note recommended to them. After calculating the co-occurrence score for all note pairs, we construct the set of co-occurrence scores S\ud835\udc5b\ud835\udc56from note \ud835\udc5b\ud835\udc56to all other notes. Specifically, S\ud835\udc5b\ud835\udc56is defined as {\ud835\udc60\ud835\udc5b\ud835\udc56\u2192\ud835\udc5b\ud835\udc57|1 \u2264\ud835\udc57\u2264\ud835\udc5a,\ud835\udc56\u2260\ud835\udc57}. Next, we filter outlier notes whose cooccurrence scores are either above \ud835\udc62or below the threshold \ud835\udc59from S\ud835\udc5b\ud835\udc56. Finally, we select the \ud835\udc61notes with the highest co-occurrence scores from the filtered set as the related notes for note \ud835\udc5b\ud835\udc56. After constructing the related notes pairs, we train NoteLLM to determine the relevance of notes based on textual semantics and collaborative signals. Different from simply taking a special pooling\n<div style=\"text-align: center;\">Pre-trained Large Language Model (e.g., LLaMA 2)</div>\nword to represent the note [26], we utilize prompts to compress the note information to generate one virtual word. The last hidden state of the compressed virtual word contains the semantic information and collaborative signals of the given note, which can represent the note. Specifically, due to the autoregressive nature of LLMs, we take the last hidden state of the previous token of [EMB] and use a linear layer to transform it to note embedding space, whose dimension is \ud835\udc51. We denote the embedding of \ud835\udc56-th note \ud835\udc5b\ud835\udc56as \ud835\udc8f\ud835\udc56. We assume each minibatch contains \ud835\udc35related note pairs, resulting in a total of 2\ud835\udc35notes per minibatch. We denote the related note of the note \ud835\udc5b\ud835\udc56as \ud835\udc5b+ \ud835\udc56, and its embedding as \ud835\udc8f+ \ud835\udc56. Following [30], the loss of GCL is computed as follows:\n(2)\n\ufffd where \ud835\udc3f\ud835\udc50\ud835\udc59denotes the loss of GCL, \ud835\udf0fmeans the learnable temperature and \ud835\udc60\ud835\udc56\ud835\udc5a(\ud835\udc4e,\ud835\udc4f) = \ud835\udc4e\u22a4\ud835\udc4f/(\u2225\ud835\udc4e\u2225\u2225\ud835\udc4f\u2225).\n# 4.4 Collaborative Supervised Fine-Tuning\nLLMs have gained prominence due to their robust capabilities in semantic understanding and generation. Several existing works attempt to apply the impressive abilities of LLMs to sentence embeddings [10, 26, 28, 30, 39]. However, these methods overlook the\ngenerative capabilities of LLMs, reducing them to mere embedding generators and failing to fully exploit their potential. Besides, these methods underutilize hashtags/categories, which represent the key concepts of notes. In fact, generating hashtags/categories is similar to producing note embeddings. Both tasks aim to summarize note content. The task of generating hashtags/categories extracts key note information from a text generation perspective, while the task of producing note embeddings compresses notes into a virtual word from a collaborative viewpoint for I2I recommendation. To this end, our NoteLLM jointly models the GCL and CSFT tasks to potentially enhance the quality of embeddings. We integrate these two tasks into a single prompt, providing additional information for both tasks and streamlining the training process. Specifically, we adopt CSFT, which leverages the semantic content of the notes and the collaborative signals in the compressed token to generate hashtags/categories. To enhance training efficiency and prevent the forgetting problem [40], we select \ud835\udc5fnotes from each batch for the hashtag generation task, while the remaining notes are allocated for the category generation task. Specifically, we compute the CSFT loss as follows:\n(3)\n\u2211\ufe01 where \ud835\udc3f\ud835\udc54\ud835\udc52\ud835\udc5bis the CSFT loss, \ud835\udc47is the length of the output, \ud835\udc5c\ud835\udc56means the \ud835\udc56-th token in output sequence \ud835\udc5cand \ud835\udc56is the input sequence. Finally, we define the loss function of NoteLLM to incorporate both GCL and CSFT, as follows:\n(4)\n + where \ud835\udc3fis the total loss of NoteLLM and \ud835\udefcis the hyperparameter. Through model updates, NoteLLM is capable of concurrently executing I2I recommendation tasks and hashtag/category generation tasks for note recommendation scenarios.\n# 5 EXPERIMENTS\n# 5.1 Dataset and Experiment Setting\nTable 1: Detailed statistics of training and testing dataset.\ntraining dataset\n#notes\n458,221 #note pairs\n312,564\navg. #words per title\n11.54 avg. #hashtag per note\n3.02\navg. #words per hashtag\n4.19 avg. #words per content\n47.67\ntesting dataset\n#notes\n257,937 #note pairs\n27,999\navg. #words per title\n13.70 avg. #hashtag per note\n5.49\navg. #words per hashtag\n4.53 avg. #words per content\n182.45\nWe conduct offline experiments on Xiaohongshu product datasets. To balance the model\u2019s training, we generate the training set by extracting a fixed number of note pairs from each category combination based on a week\u2019s product data. Then, we randomly select notes from the upcoming month to form the note pool of testing set, excluding any notes that are already in the training dataset. The detailed statistics of the training and testing dataset are shown in Table 1. Besides, there are more than 500 categories in our dataset.\nIn our experiments, we leverage Meta LLaMA 2 [42] as the base LLMs. In related note pair construction, we set the upper bound of the co-occurrence score \ud835\udc62as 30 and the lower bound \ud835\udc59as 0.01. And we set \ud835\udc61as 10. Besides, the dimension \ud835\udc51of note embedding is set to 128. The batch size \ud835\udc35is set to 641. Each batch contains 128 notes. Due to context length restriction, we truncate the titles exceeding 20 tokens, and truncate the contents exceeding 80 tokens. The temperature \ud835\udf0fis initialized as 3. We set \ud835\udefcin Equation 4 to 0.01. The ratio \ud835\udc5ffor the hashtag generation task is set at 40%. To assess the offline performance of the I2I recommendation model, we choose the prompt for category generation, which contains all input note information. We select the first note from each note pair as the target note, and the other as the ground truth. Subsequently, we rank all the notes in the test pool, excluding the target note, according to the target note. We then use Recall@100, Recall@1k, Recall@10k and Recall@100k to validate the model effectiveness for I2I note recommendation. For closet category generation tasks, we use accuracy (Acc.) and illusory proportions (Ill.) as the evaluation metrics. Ill. represent the proportion of categories generated by the model that are not in the closet. For free-form hashtag generation tasks, we use BLEU4, ROUGE1, ROUGE2 and ROUGEL to evaluate models.\n# 5.2 Offline Performance Evaluation\nIn this subsection, we demonstrate the effectiveness of NoteLLM for I2I note recommendation. We compare our NoteLLM with the following text-based I2I recommendation methods:\n\u2022 zero-shot utilizes LLMs to generate the embeddings without any prompts and then conducts zero-shot retrieval. \u2022 PromptEOL zero-shot [10] is a zero-shot LLMs sentence embedding method that uses the explicit one-word limitation prompt. \u2022 SentenceBERT [36] adopts BERT to learn the note similarity based on contrastive learning, serving as the online baseline. \u2022 PromptEOL+CSE [10] uses the explicit one-word limitation prompt and leverages contrastive learning to update LLMs. \u2022 RepLLaMA [26], a bi-encoder dense retriever based on LLMs without any prompts.\nThe results, as presented in Table 2, offer several insightful observations. Despite their potential, zero-shot methods are still unable to surpass the performance of fine-tuned methods, suggesting that the latter\u2019s specific knowledge in the note recommendation domain gives them an edge. Further, we find that the comparison between methods based on LLaMA 2 and SentenceBERT reveals a significant advantage for the former, indicating a superior ability of LLMs to understand notes. The performance of PromptEOL+CSE with specific prompts matches that of RepLLaMA without prompts, indicating that prompts boost zero-shot retrieval but their effect lessens after fine-tuning. Lastly, our NoteLLM outperforms other LLM-based methods, primarily due to CSFT\u2019s effective transfer of summary ability into note embedding compression, which efficiently distills key points for improved note embeddings.\n1We utilize Distributed Data Parallel training on 8 \u00d7 80GB Nvidia A100 GPUs and the batch size per each GPU is 8.\n<div style=\"text-align: center;\">Table 2: Performance of different methods in I2I recommendation tasks (%).</div>\nModel Size\nRecall@100\nRecall@1k\nRecall@10k\nRecall@100k\nAvg.\nLLaMA 2 zero-shot\n7B\n11.94\n19.44\n32.53\n68.81\n33.18\nPromptEOL zero-shot [10]\n7B\n55.27\n74.47\n88.71\n98.04\n79.12\nSentenceBERT (Online) [36]\n110M\n70.72\n87.88\n96.29\n99.62\n88.63\nPromptEOL+CSE [10]\n7B\n83.28\n95.26\n99.20\n99.96\n94.43\nRepLLaMA [26]\n7B\n83.63\n95.10\n99.27\n99.94\n94.49\nNoteLLM\n7B\n84.02\n95.23\n99.23\n99.96\n94.66\nrmance of different methods for low exposure notes and high exposure notes in I2I recommendation tasks (%).\nLow Exposure\nHigh Exposure\nOverall\nRecall@100\nRecall@1k\nRecall@100\nRecall@1k\nRecall@100\nRecall@1k\nSentenceBERT (Online) [36]\n75.00\n90.54\n59.03\n81.91\n70.72\n87.88\nPromptEOL+CSE [10]\n86.28\n96.63\n72.46\n91.40\n83.28\n95.26\nRepLLaMA [26]\n86.54\n96.18\n72.64\n91.37\n83.63\n95.10\nNoteLLM\n87.85\n96.63\n73.46\n91.26\n84.02\n95.23\n# 5.3 Effect on Different Exposure Notes\nIn this subsection, we demonstrate the efficacy of our NoteLLM in handling notes with varying levels of exposure. For a more comprehensive analysis, we have divided the ground truth notes into two distinct categories based on their exposure levels. The first category encompasses notes with low-exposure, specifically those with an exposure of less than 1, 500. Despite constituting 30% of all test notes, their cumulative exposure only amounts to 0.5%. On the other hand, the second category includes notes with high-exposure, characterized by an exposure exceeding 75, 000. Even though they represent only 10% of all test notes, their collective exposure is substantial, accounting for 75% of the total. We then separately calculate the recall for these two groups to further understand the performance of our NoteLLM across different exposure levels. The results are presented in Table 3. NoteLLM consistently outperforms other methods for both low and high exposure notes in most cases, which indicates that the incorporation of CSFT module provides consistent benefits across all notes, irrespective of their exposure levels. It\u2019s worth noting that while these methods exhibit commendable performance with low-exposure notes, they falter when dealing with high-exposure notes. The decline in performance can be attributed to neglecting the popularity bias [17]. Such properties enhance the model\u2019s ability to recall based on the content of the notes, making it particularly suitable for retrieving cold-start notes. This can motivate users to post more new notes, creating richer content for the entire community.\n# 5.4 Ablation Study\nIn this subsection, we conduct an ablation study to underscore the effectiveness of the key innovations in our work. To enhance our analysis, we also show performance on the category and hashtag generation tasks in the following experiments. We compare our NoteLLM with following variants:\n\u2022 w/o CSFT, a method solely employs the GCL module. \u2022 w/o GCL (\ud835\udc5f= 40%) only adopts CSFT module to guide LLMs in summarizing the hashtags and categories. \u2022 w/o GCL (\ud835\udc5f= 0%) only has category summary task. \u2022 w/o GCL (\ud835\udc5f= 100%) only instructs LLMs to summarize hashtags.\nThe results are presented in Table 4, from which we can draw several conclusions. Firstly, we observe that the ablation without CSFT performs worse than NoteLLM in I2I recommendation task, and completely loses the ability to generate hashtags and categories. This highlights the crucial role of the CSFT module in enhancing note embeddings and suggests that a single model can handle both recommendation and generation tasks. Secondly, we find that the ablation without GCL module outperforms PromptEOL zero-shot in I2I recommendation tasks. This indicates that the hashtag/category generation task can enhance I2I recommendation tasks. Thirdly, the ablation without GCL (\ud835\udc5f= 40%) performs better in I2I recommendation tasks than the version without GCL (\ud835\udc5f= 0%) and without GCL (\ud835\udc5f= 100%). This suggests that task diversity is important for CSFT [22]. Finally, we observe a clear seesaw phenomenon [66] for hashtag and category generation tasks. The ablation without GCL (\ud835\udc5f= 0%) can generate correct categories for 80.64% of notes, but struggles to summarize useful hashtags. Conversely, the version without GCL (\ud835\udc5f= 100%) generates high-quality hashtags, but the generated categories are mostly incorrect.\n# 5.5 Impact of Data Diversity in CSFT Module\nIn this subsection, we investigate the impact of data diversity in CSFT module. The performance of the model for different tasks under varying data type proportions is presented in Table 5. For I2I recommendation tasks, performance improves as \ud835\udc5fincreases. This is attributed to the enhanced data diversity of instruction tuning with a higher \ud835\udc5f, which more effectively instructs LLMs to summarize and compress various types of information.\n<div style=\"text-align: center;\">Table 4: Ablation study for NoteLLM in I2I recommendation, category generation and hashtag generation tasks (%).</div>\nModel\nR@100\nR@1k\nR@10k\nR@100k\nAvg.\nAcc.\nIll.\nBLEU4\nROUGE1\nROUGE2\nROUGEL\nNoteLLM\n84.02\n95.23\n99.23\n99.96\n94.66\n66.17\n0.50\n1.38\n22.31\n8.02\n21.03\nw/o CSFT\n83.28\n95.26\n99.20\n99.96\n94.43\n0.00\n100.00\n0.01\n0.00\n0.00\n0.00\nw/o GCL (\ud835\udc5f= 40%)\n75.38\n90.33\n97.09\n98.93\n90.43\n75.12\n2.27\n1.28\n26.50\n13.02\n23.27\nw/o GCL (\ud835\udc5f= 0%)\n60.38\n83.22\n96.13\n98.84\n84.64\n80.64\n0.07\n0.00\n1.54\n0.00\n1.54\nw/o GCL (\ud835\udc5f= 100%)\n71.98\n87.86\n95.59\n98.51\n88.49\n0.18\n99.70\n1.30\n27.66\n14.19\n24.11\n<div style=\"text-align: center;\">Table 5: Performance of NoteLLM under different data diversity in CSFT module for I2I recommendation, category generat and hashtag generation tasks (%).</div>\n<div style=\"text-align: center;\">able 5: Performance of NoteLLM under different data diversity in CSFT module for I2I recommendation, category generation nd hashtag generation tasks (%).</div>\n\ud835\udc5f\nR@100\nR@1k\nR@10k\nR@100k\nAvg.\nAcc.\nIll.\nBLEU4\nROUGE1\nROUGE2\nROUGEL\n0%\n83.29\n95.07\n99.14\n99.96\n94.37\n71.00\n0.12\n0.00\n0.00\n0.00\n0.00\n20%\n83.81\n95.28\n99.26\n99.96\n94.58\n69.70\n0.09\n1.59\n22.57\n7.73\n21.64\n40%\n84.02\n95.23\n99.23\n99.96\n94.66\n66.17\n0.50\n1.38\n22.31\n8.02\n21.03\n60%\n83.37\n95.03\n99.25\n99.96\n94.40\n63.37\n0.90\n1.33\n21.92\n7.88\n20.62\n80%\n83.15\n95.06\n99.27\n99.97\n94.36\n53.60\n2.67\n1.34\n22.48\n8.31\n21.10\n100%\n82.49\n94.49\n99.11\n99.96\n94.01\n0.00\n100.00\n1.33\n21.88\n7.99\n20.47\nModel\nR@100\nR@1k\nR@10k\nR@100k\nAvg.\nAcc.\nIll.\nBLEU4\nROUGE1\nROUGE2\nROUGEL\n\ud835\udefc= 0\n83.42\n95.13\n99.31\n99.96\n94.46\n0.00\n100.00\n0.05\n0.91\n0.01\n0.87\n\ud835\udefc= 0.001\n83.73\n95.09\n99.26\n99.97\n94.51\n49.04\n6.84\n1.82\n15.13\n3.23\n14.80\n\ud835\udefc= 0.01\n84.02\n95.23\n99.23\n99.96\n94.66\n66.17\n0.50\n1.38\n22.31\n8.02\n21.03\n\ud835\udefc= 0.1\n83.51\n95.18\n99.31\n99.96\n94.49\n73.33\n0.04\n1.33\n24.44\n10.42\n22.28\n\ud835\udefc= 1\n83.79\n94.79\n99.26\n99.97\n94.45\n74.69\n0.82\n1.33\n26.94\n13.21\n23.90\n\ud835\udefc= 10\n82.92\n94.28\n98.94\n99.96\n94.03\n75.15\n2.08\n1.30\n27.63\n13.95\n24.21\nHowever, as \ud835\udc5fcontinues to increase and the data for instruction tuning becomes more skewed towards the hashtag generation task, performance begins to decline. For category generation tasks, as the data becomes more biased towards the hashtag generation task, the performance on category generation deteriorates. However, as \ud835\udc5fcontinues to increase from 20%, there is not much significant change in the hashtag generation task. This may be because the category generation task is a closet task, which requires a stringent match. In contrast, the hashtag generation task is a free-form generation task, which allows for greater flexibility.\n# 5.6 Impact of the Magnitude of CSFT Module\nIn this subsection, we explore the impact of the magnitude of CSFT module on task performance. We present the results of our experiments in Table 6. Our findings suggest that a slight increase in \ud835\udefc enhances the performance of both recommendation and generation tasks. However, as \ud835\udefccontinues to increase, the performance of the recommendation task begins to decline, while the performance of the generation task continues to improve. This reveals a trade-off\nbetween generation and I2I recommendation tasks, highlighting the need for a balanced approach.\n# 5.7 Case Study\nFinally, we show some cases for note recommendation and generation tasks as shown in Figure 3. In Figure 3(a), the query note suggests which summer clothes to avoid buying, while all baselines recommend summer outfits. NoteLLM can accurately recommend notes that are related to simple living. In Figure 3(b), baselines misinterpret \u2019rabbit\u2019 in the note as a live rabbit, instead of the toy rabbit from Keep strangers away. Figure 3(c) and Figure 3(d) show the cases for hashtag generation tasks, which shows the benefits of NoteLLM. RedHashtag is an online hashtag generation method for Xiaohongshu, which is based on classification from the fixed hashtag set. In Figure 3(c), NoteLLM is not deceived by the semantic information \u2019factories\u2019. Instead, NoteLLM correctly identifies that the note\u2019s content primarily focuses on taking photos. In Figure 3(d), NoteLLM is capable of generating more specific and long-tail hashtags, as opposed to the more generic ones. However, our method still suffers from the hallucination problem [57].\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ec8a/ec8a0ef7-41c4-4805-9908-d31c9586612a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3: The visualization cases of NoteLLM and other baselines. Figure 3(a) and 3(b) show the cases in I2I recommendatio asks, where the left query note is the user\u2019s clicked note, and the remaining notes are the top-1 ranked results retrieved b different methods. Figure 3(c) and 3(d) show the cases in hashtag generation tasks. RedHashtag is the online hashtag generatio method. GT means the ground truth hashtags.</div>\nFigure 3: The visualization cases of NoteLLM and other baselines. Figure 3(a) and 3(b) show the cases in I2I recommendation tasks, where the left query note is the user\u2019s clicked note, and the remaining notes are the top-1 ranked results retrieved by different methods. Figure 3(c) and 3(d) show the cases in hashtag generation tasks. RedHashtag is the online hashtag generation method. GT means the ground truth hashtags.\n# 5.8 Online Experiments\nWe conduct week-long online I2I recommendation experiments on Xiaohongshu. Compared to the previous online method that adopts SentenceBERT, our NoteLLM improves the click-through rate by 16.20%. Furthermore, the enhanced recall performance increases the number of comments by 1.10% and the average weekly number of publishers (WAP) by 0.41%. These results indicate the introduction of LLMs into I2I note recommendation tasks can improve recommendation performance and user experience. Besides, we observe a noteworthy increase of 3.58% in the number of comments on new notes within a single day. This denotes the generalization of LLMs is beneficial to cold start notes. Now, we have deployed our NoteLLM into the I2I note recommendation task on Xiaohongshu.\n# 6 CONCLUSION\nIn this work, we propose retrievable LLMs, called NoteLLM, for note recommendation with three key components: Note Compression Prompt, GCL, and CSFT. To manage both I2I recommendation and\nhashtag/category generation tasks, we utilize Note Compression Prompt to form the compressed word embeddings and generate the hashtag/category simultaneously. Then, we use GCL to conduct contrastive learning based on the hidden states of the compressed word, which acquires collaborative signals. Additionally, we employ CSFT to preserve the generation capability of NoteLLM while leveraging the semantic and collaborative information of the note to generate hashtags and categories, which can enhance the embeddings for recommendation. Comprehensive experiments are conducted, which validate the effectiveness of NoteLLM.\n# ACKNOWLEDGEMENTS\nThis work was supported in part by the grants from National Natural Science Foundation of China (No.62222213, U22B2059, 62072423), and the USTC Research Funds of the Double First-Class Initiative (No.YD2150002009).\n# REFERENCES\n[1] Keqin Bao, Jizhi Zhang, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng Luo, Fuli Feng, Xiangnaan He, and Qi Tian. 2023. A bi-step grounding paradigm for large language models in recommendation systems. arXiv preprint arXiv:2308.08434 (2023). [2] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation. In RecSys. [3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018). [4] Shizhe Diao, Sedrick Scott Keh, Liangming Pan, Zhiliang Tian, Yan Song, and Tong Zhang. 2023. Hashtag-Guided Low-Resource Tweet Classification. In WWW. 1415\u20131426. [5] Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, and Qing Li. 2023. Recommender systems in the era of large language models (llms). arXiv preprint arXiv:2307.02046 (2023). [6] Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck, Dawen Liang, Yesu Feng, Bodhisattwa Prasad Majumder, Nathan Kallus, and Julian McAuley. 2023. Large language models as zero-shot conversational recommenders. In CIKM. 720\u2013730. [7] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, and Wayne Xin Zhao. 2023. Large language models are zero-shot rankers for recommender systems. arXiv preprint arXiv:2305.08845 (2023). [8] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In CIKM. 2333\u20132338. [9] Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie. 2023. Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations. arXiv preprint arXiv:2308.16505 (2023). [10] Ting Jiang, Shaohan Huang, Zhongzhi Luan, Deqing Wang, and Fuzhen Zhuang. 2023. Scaling Sentence Embeddings with Large Language Models. arXiv preprint arXiv:2307.16645 (2023). [11] Ting Jiang, Jian Jiao, Shaohan Huang, Zihan Zhang, Deqing Wang, Fuzhen Zhuang, Furu Wei, Haizhen Huang, Denvy Deng, and Qi Zhang. 2022. PromptBERT: Improving BERT Sentence Embeddings with Prompts. In EMNLP. 8826\u2013 8837. [12] Jeff Johnson, Matthijs Douze, and Herv\u00e9 J\u00e9gou. 2019. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data 7, 3 (2019), 535\u2013547. [13] Vladimir Karpukhin, Barlas O\u011fuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for opendomain question answering. arXiv preprint arXiv:2004.04906 (2020). [14] Fei-Fei Kou, Jun-Ping Du, Cong-Xian Yang, Yan-Song Shi, Wan-Qiu Cui, Mei-Yu Liang, and Yue Geng. 2018. Hashtag recommendation based on multi-features of microblogs. JCST 33 (2018), 711\u2013726. [15] Ruyu Li, Wenhao Deng, Yu Cheng, Zheng Yuan, Jiaqi Zhang, and Fajie Yuan. 2023. Exploring the Upper Limits of Text-Based Collaborative Filtering Using Large Language Models: Discoveries and Insights. arXiv preprint arXiv:2305.11700 (2023). [16] Mengqi Liao, S Shyam Sundar, and Joseph B. Walther. 2022. User trust in recommendation systems: A comparison of content-based, collaborative and demographic filtering. In CHI. 1\u201314. [17] Allen Lin, Jianling Wang, Ziwei Zhu, and James Caverlee. 2022. Quantifying and mitigating popularity bias in conversational recommender systems. In CIKM. 1238\u20131247. [18] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, et al. 2023. How Can Recommender Systems Benefit from Large Language Models: A Survey. arXiv preprint arXiv:2306.05817 (2023). [19] Greg Linden, Brent Smith, and Jeremy York. 2003. Amazon. com recommendations: Item-to-item collaborative filtering. IEEE Internet computing 7, 1 (2003), 76\u201380. [20] Junling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan Zhang. 2023. Is chatgpt a good recommender? a preliminary study. arXiv preprint arXiv:2304.10149 (2023). [21] Qijiong Liu, Nuo Chen, Tetsuya Sakai, and Xiao-Ming Wu. 2023. A First Look at LLM-Powered Generative News Recommendation. arXiv preprint arXiv:2305.06566 (2023). [22] Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. 2023. The flan collection: Designing data and methods for effective instruction tuning. arXiv preprint arXiv:2301.13688 (2023). [23] Hanjia Lyu, Song Jiang, Hanqing Zeng, Yinglong Xia, and Jiebo Luo. 2023. Llmrec: Personalized recommendation via prompting large language models. arXiv preprint arXiv:2307.15780 (2023). [24] Yuanjie Lyu, Zhiyu Li, Simin Niu, Feiyu Xiong, Bo Tang, Wenjin Wang, Hao Wu, Huanyong Liu, Tong Xu, and Enhong Chen. 2024. CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models. arXiv preprint arXiv:2401.17043 (2024).\n[25] Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan, and Xueqi Cheng. 2022. Pre-train a discriminative text encoder for dense retrieval via contrastive span prediction. In SIGIR. 848\u2013858. [26] Xueguang Ma, Liang Wang, Nan Yang, Furu Wei, and Jimmy Lin. 2023. FineTuning LLaMA for Multi-Stage Text Retrieval. arXiv preprint arXiv:2310.08319 (2023). [27] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013). [28] Niklas Muennighoff. 2022. Sgpt: Gpt sentence embeddings for semantic search. arXiv preprint arXiv:2202.08904 (2022). [29] Sheshera Mysore, Andrew McCallum, and Hamed Zamani. 2023. Large Language Model Augmented Narrative Driven Recommendations. arXiv preprint arXiv:2306.02250 (2023). [30] Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas Tezak, Jong Wook Kim, Chris Hallacy, et al. 2022. Text and code embeddings by contrastive pre-training. arXiv preprint arXiv:2201.10005 (2022). [31] OpenAI. 2023. GPT-4 Technical Report. arXiv preprint arXiv:2303.08774 (2023). [32] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. NeurIPS 35 (2022), 27730\u201327744. [33] Wenjun Peng, Guiyang Li, Yue Jiang, Zilong Wang, Dan Ou, Xiaoyi Zeng, Enhong Chen, et al. 2023. Large Language Model based Long-tail Query Rewriting in Taobao Search. arXiv preprint arXiv:2311.03758 (2023). [34] Wenjun Peng, Derong Xu, Tong Xu, Jianjin Zhang, and Enhong Chen. 2023. Are gpt embeddings useful for ads and recommendation?. In KSEM. Springer, 151\u2013162. [35] Juan Ramos et al. 2003. Using tf-idf to determine word relevance in document queries. In Proceedings of the first instructional conference on machine learning, Vol. 242. Citeseer, 29\u201348. [36] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In EMNLP-IJCNLP. [37] Stephen Robertson, Hugo Zaragoza, et al. 2009. The probabilistic relevance framework: BM25 and beyond. Foundations and Trends\u00ae in Information Retrieval 3, 4 (2009), 333\u2013389. [38] Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F Christiano. 2020. Learning to summarize with human feedback. NeurIPS 33 (2020), 3008\u20133021. [39] Hongjin Su, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen-tau Yih, Noah A Smith, Luke Zettlemoyer, Tao Yu, et al. 2023. One embedder, any task: Instruction-finetuned text embeddings. ACL Findings (2023). [40] Mariya Toneva, Alessandro Sordoni, Remi Tachet des Combes, Adam Trischler, Yoshua Bengio, and Geoffrey J Gordon. 2018. An empirical study of example forgetting during deep neural network learning. arXiv preprint arXiv:1812.05159 (2018). [41] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023). [42] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023). [43] Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. 2023. Recmind: Large language model powered agent for recommendation. arXiv preprint arXiv:2308.14296 (2023). [44] Yue Wang, Jing Li, Hou Pong Chan, Irwin King, Michael R Lyu, and Shuming Shi. 2019. Topic-Aware Neural Keyphrase Generation for Social Media Language. In ACL. 2516\u20132526. [45] Yue Wang, Jing Li, Irwin King, Michael R Lyu, and Shuming Shi. 2019. Microblog hashtag generation via encoding conversation contexts. arXiv preprint arXiv:1905.07584 (2019). [46] Zifeng Wang, Chufan Gao, Cao Xiao, and Jimeng Sun. 2023. AnyPredict: Foundation Model for Tabular Prediction. arXiv preprint arXiv:2305.12081 (2023). [47] Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652 (2021). [48] Chuhan Wu, Fangzhao Wu, Yongfeng Huang, and Xing Xie. 2023. Personalized news recommendation: Methods and challenges. ACM Transactions on Information Systems 41, 1 (2023), 1\u201350. [49] Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2021. Empowering news recommendation with pre-trained language models. In SIGIR. 1652\u20131656. [50] Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, et al. 2023. A Survey on Large Language Models for Recommendation. arXiv preprint arXiv:2305.19860 (2023).\n[51] Yunjia Xi, Weiwen Liu, Jianghao Lin, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Rui Zhang, and Yong Yu. 2023. Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models. arXiv preprint arXiv:2306.10933 (2023). [52] Shitao Xiao, Zheng Liu, Weihao Han, Jianjin Zhang, Yingxia Shao, Defu Lian, Chaozhuo Li, Hao Sun, Denvy Deng, Liangjie Zhang, et al. 2022. Progressively optimized bi-granular document representation for scalable embedding based retrieval. In WWW. 286\u2013296. [53] Shitao Xiao, Zheng Liu, Yingxia Shao, Tao Di, Bhuvan Middha, Fangzhao Wu, and Xing Xie. 2022. Training large-scale news recommenders with pretrained language models in the loop. In KDD. 4215\u20134225. [54] Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu, Xiangyu Zhao, Xian Wu, Yefeng Zheng, and Enhong Chen. 2023. Large Language Models for Generative Information Extraction: A Survey. arXiv preprint arXiv:2312.17617 (2023). [55] Xiaoyong Yang, Yadong Zhu, Yi Zhang, Xiaobo Wang, and Quan Yuan. 2020. Large scale product graph construction for recommendation in e-commerce. arXiv preprint arXiv:2010.05525 (2020). [56] Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. 2023. A Survey on Multimodal Large Language Models. arXiv preprint arXiv:2306.13549 (2023). [57] Shukang Yin, Chaoyou Fu, Sirui Zhao, Tong Xu, Hao Wang, Dianbo Sui, Yunhang Shen, Ke Li, Xing Sun, and Enhong Chen. 2023. Woodpecker: Hallucination correction for multimodal large language models. arXiv preprint arXiv:2310.16045 (2023). [58] Jichuan Zeng, Jing Li, Yan Song, Cuiyun Gao, Michael R Lyu, and Irwin King. 2018. Topic Memory Networks for Short Text Classification. In EMNLP. 3120\u20133131.\n[59] Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Recommendation as instruction following: A large language model empowered recommendation approach. arXiv preprint arXiv:2305.07001 (2023). [60] Qi Zhang, Jiawen Wang, Haoran Huang, Xuanjing Huang, and Yeyun Gong. 2017. Hashtag Recommendation for Multimodal Microblog Using Co-Attention Network.. In IJCAI. 3420\u20133426. [61] Qi Zhang, Yang Wang, Yeyun Gong, and Xuan-Jing Huang. 2016. Keyphrase extraction using deep recurrent neural networks on twitter. In EMNLP. 836\u2013845. [62] Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, et al. 2023. Instruction tuning for large language models: A survey. arXiv preprint arXiv:2308.10792 (2023). [63] Yingyi Zhang, Jing Li, Yan Song, and Chengzhi Zhang. 2018. Encoding conversation context for neural keyphrase extraction from microblog posts. In NAACL. 1676\u20131686. [64] Weihao Zhao, Han Wu, Weidong He, Haoyang Bi, Hao Wang, Chen Zhu, Tong Xu, and Enhong Chen. 2023. Hierarchical Multi-modal Attention Network for Time-sync Comment Video Recommendation. IEEE Transactions on Circuits and Systems for Video Technology (2023). [65] Xinping Zhao, Ying Zhang, Qiang Xiao, Yuming Ren, and Yingchun Yang. 2023. Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching. In WWW. 351\u2013355. [66] Shen Zheng, Yuyu Zhang, Yijie Zhu, Chenguang Xi, Pengyang Gao, Xun Zhou, and Kevin Chen-Chuan Chang. 2023. GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond. arXiv preprint arXiv:2309.16583 (2023). [67] Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai. 2018. Learning tree-based deep model for recommender systems. In KDD. 1079\u20131088.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of note recommendation in online communities, emphasizing the need for improved methods that leverage user-generated content. Existing approaches primarily utilize BERT-based models to generate note embeddings, which may not fully exploit important cues like hashtags or categories that encapsulate key concepts of notes. The introduction of Large Language Models (LLMs) presents an opportunity to enhance note recommendation capabilities.",
        "problem": {
            "definition": "The problem revolves around efficiently recommending relevant notes from a large pool based on user interests, specifically through item-to-item (I2I) recommendation methods that consider both content and collaborative signals.",
            "key obstacle": "The main challenge lies in the underutilization of hashtags and categories in existing methods, which limits their ability to accurately assess the similarity and relevance of notes."
        },
        "idea": {
            "intuition": "The idea is inspired by the observation that generating hashtags and categories can enhance note embeddings, similar to how these embeddings compress key information from notes.",
            "opinion": "The proposed method, NoteLLM, integrates LLMs to simultaneously perform I2I recommendation and generate hashtags/categories, aiming to improve the overall recommendation system.",
            "innovation": "NoteLLM differentiates itself from existing approaches by employing a unified framework that leverages LLMs for both recommendation and hashtag/category generation, enhancing the quality of note embeddings."
        },
        "method": {
            "method name": "NoteLLM",
            "method abbreviation": "NLLM",
            "method definition": "NoteLLM is a unified framework that utilizes Large Language Models to enhance item-to-item note recommendation while generating corresponding hashtags and categories.",
            "method description": "The core of NoteLLM involves compressing notes into a single token using a Note Compression Prompt and learning related note embeddings through contrastive learning.",
            "method steps": [
                "Construct a unified Note Compression Prompt for each note.",
                "Utilize pre-trained LLMs to generate a compressed token representing the note.",
                "Learn related note embeddings using Generative-Contrastive Learning (GCL).",
                "Employ Collaborative Supervised Fine-tuning (CSFT) to generate hashtags and categories."
            ],
            "principle": "The effectiveness of NoteLLM stems from its ability to integrate collaborative signals and semantic information, allowing for better note representation and enhanced recommendation accuracy."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted using a dataset from Xiaohongshu, consisting of 458,221 training notes and 257,937 testing notes, with various metrics including Recall@k and accuracy for evaluation.",
            "evaluation method": "Performance was assessed by comparing NoteLLM against several baseline methods in terms of recall metrics for note recommendation and accuracy metrics for category generation."
        },
        "conclusion": "The results demonstrate that NoteLLM significantly improves the effectiveness of note recommendations compared to existing methods, validating the proposed framework's contributions to the field of recommendation systems.",
        "discussion": {
            "advantage": "NoteLLM's key advantages include its ability to leverage LLMs for both recommendation and generation tasks, leading to improved note embeddings and user engagement.",
            "limitation": "One limitation is the potential for hallucination in generated hashtags/categories, which may affect the quality of recommendations.",
            "future work": "Future research could focus on refining the hashtag/category generation process and exploring further enhancements in the recommendation capabilities of LLMs."
        },
        "other info": {
            "acknowledgements": "This work was supported by grants from the National Natural Science Foundation of China and the USTC Research Funds of the Double First-Class Initiative."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper emphasizes the need for improved methods in note recommendation that leverage user-generated content, highlighting the significance of recommendation algorithms in enhancing user experience."
        },
        {
            "section number": "1.2",
            "key information": "The introduction of Large Language Models (LLMs) presents an opportunity to enhance note recommendation capabilities, showcasing the role of LLMs in advancing recommendation systems."
        },
        {
            "section number": "2.1",
            "key information": "The paper defines the problem of efficiently recommending relevant notes from a large pool based on user interests, specifically through item-to-item (I2I) recommendation methods."
        },
        {
            "section number": "2.3",
            "key information": "NoteLLM is introduced as a unified framework that utilizes Large Language Models to enhance item-to-item note recommendation while generating corresponding hashtags and categories."
        },
        {
            "section number": "3.2",
            "key information": "NoteLLM employs a unified framework that leverages LLMs for both recommendation and hashtag/category generation, enhancing the quality of note embeddings."
        },
        {
            "section number": "4.1",
            "key information": "The core of NoteLLM involves compressing notes into a single token using a Note Compression Prompt and learning related note embeddings through contrastive learning."
        },
        {
            "section number": "4.2",
            "key information": "The proposed method integrates LLMs to simultaneously perform I2I recommendation and generate hashtags/categories, aiming to improve the overall recommendation system."
        },
        {
            "section number": "10.1",
            "key information": "The main challenge in existing methods is the underutilization of hashtags and categories, which limits their ability to accurately assess the similarity and relevance of notes."
        },
        {
            "section number": "10.2",
            "key information": "Future research could focus on refining the hashtag/category generation process and exploring further enhancements in the recommendation capabilities of LLMs."
        }
    ],
    "similarity_score": 0.7249555934164224,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/NoteLLM_ A Retrievable Large Language Model for Note Recommendation.json"
}