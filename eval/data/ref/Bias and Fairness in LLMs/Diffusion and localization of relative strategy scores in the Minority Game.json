{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1509.08236",
    "title": "Diffusion and localization of relative strategy scores in the Minority Game",
    "abstract": "We study the equilibrium distribution of relative strategy scores of agents in the asymmetric phase ($\u03b1\\equiv P/N\\gtrsim 1$) of the basic Minority Game using sign-payoff, with $N$ agents holding two strategies over $P$ histories. We formulate a statistical model that makes use of the gauge freedom with respect to the ordering of an agent's strategies to quantify the correlation between the attendance and the distribution of strategies. The relative score $x\\in\\mathbb{Z}$ of the two strategies of an agent is described in terms of a one dimensional random walk with asymmetric jump probabilities, leading either to a static and asymmetric exponential distribution centered at $x=0$ for fickle agents or to diffusion with a positive or negative drift for frozen agents. In terms of scaled coordinates $x/\\sqrt{N}$ and $t/N$ the distributions are uniquely given by $\u03b1$ and in quantitative agreement with direct simulations of the game. As the model avoids the reformulation in terms of a constrained minimization problem it can be used for arbitrary payoff functions with little calculational effort and provides a transparent and simple formulation of the dynamics of the basic Minority Game in the asymmetric phase.",
    "bib_name": "granath2016diffusionlocalizationrelativestrategy",
    "md_text": "# Diffusion and localization of relative strategy scores in the Minority Game\nMats Granath1 and Alvaro Perez-Diaz 2 1Department of Physics, University of Gothenburg, SE-41296 Gothenburg, Sweden and 2Faculty of Engineering and the Environment, University of Southampton, SO16 7QF, UK (Dated: October 27, 2021)\nWe study the equilibrium distribution of relative strategy scores of agents in the asymmetric phase (\u03b1 \u2261P/N \u22731) of the basic Minority Game using sign-payoff, with N agents holding two strategies over P histories. We formulate a statistical model that makes use of the gauge freedom with respect to the ordering of an agent\u2019s strategies to quantify the correlation between the attendance and the distribution of strategies. The relative score x \u2208Z of the two strategies of an agent is described in terms of a one dimensional random walk with asymmetric jump probabilities, leading either to a static and asymmetric exponential distribution centered at x = 0 for fickle agents or to diffusion with a positive or negative drift for frozen agents. In terms of scaled coordinates x/ \u221a N and t/N the distributions are uniquely given by \u03b1 and in quantitative agreement with direct simulations of the game. As the model avoids the reformulation in terms of a constrained minimization problem it can be used for arbitrary payoff functions with little calculational effort and provides a transparent and simple formulation of the dynamics of the basic Minority Game in the asymmetric phase.\nPACS numbers: 89.75.Fb, 05.40.-a, 89.65.Gh\n# I. INTRODUCTION\nA minority game can be exemplified by the following simple market analogy; An odd number N of traders (agents) must at each time step choose between two options, buying or selling a share, with the aim of picking the minority group. If sell is in minority and buy in majority one may expect the price to go up to satisfy demand and vice versa if buy is in minority, thus motivating the minority character of the game. Clearly, there is no way to make everyone content, at least half of the agents will inevitably end up in the majority group each round. As the losing agents will try to improve their lot there is no static equilibrium. Instead, agents might be expected to adapt their buy or sell strategies based on perceived trends in the history of outcomes [1\u201311]. The Minority Game proposed by Zhang and Challet [2] formalizes this type of market dynamics where agents of limited intellect compete for a scarce resource by adapting to the aggregate input of all others [1, 11]. Each agent has a set of strategies that, depending on the recent past history of minority groups going m time steps back, gives a prediction of the next minority being buy or sell. The agent uses at each time step her highest scoring strategy which has most accurately predicted correct minority groups historically. The state space of the game is given by the strategy scores of each agent together with the recent history of minority groups, and the discrete time evolution in this space represents an intricate dynamical system. What makes the game appealing from a physics perspective is that it can be described using methods for the statistical physics of disordered systems, with the set of randomly assigned strategies corresponding to quenched disorder [4, 7, 12\u201314, 16]. In particular Challet, Marsili, and co-workers showed that the model can be formulated in terms of the gradient descent dynamics of an underly-\ning Hamiltonian [12], plus noise. The asymptotic dynamics corresponds to minimizing the Hamiltonian with respect to the frequency at which agents use each strategy, a problem which in turn can be solved using the replica method [7, 16, 17]. In a complementary development Coolen solved the statistical dynamics of the problem in its full complexity using generating functionals [13\u201315]. The game is controlled by the parameter \u03b1 = P/N, where P = 2m is the number of distinct histories that agents take into account, which tunes the system through a phase transition (for N \u2192\u221e) at a critical value \u03b1c = 0.3374.... In the symmetric (or crowded) phase, \u03b1 < \u03b1c, the game is quasi-periodic with period 2P where a given history gives alternately one or the other of the outcomes for minority group [3, 18]. A somewhat oversimplified characterization of the dynamics is that the information about the last winning minority group for a given history gives a crowding effect [19] where many agents want to repeat the last winning outcome which then counterproductively instead puts them in the majority group. The crowding also gives large fluctuations of the size of the minority group. In the asymmetric (or dilute) phase, \u03b1 > \u03b1c, agents are sufficiently uncorrelated that crowding effects are not important and there is no periodic behavior. Instead, as exemplified in Figure 1 the score dynamics is random but with a net correlation between agents that makes fluctuations in the size of the minority group small. The dilute occupation of the full strategy space gives rise to a non-uniform frequency distribution of histories which can be beneficial for agents with strategies that are tuned to this asymmetry. In this paper we study the dynamics of the Minority Game in the asymmetric phase by formulating a simplified statistical model, focusing on finding probability distributions for the relative strategy scores. In particular, we study the original formulation of the\ngame with sign-payoff for which quantitative results are challenging to derive. By sorting the strategies based on how strongly they are correlated with the average over all strategies in the game, we find that sufficient statistical information can be extracted to formulate a quantitatively accurate model for \u03b1 \u22731. We discuss how the relative score for each agent can be derived from the master equation of a random walk on a chain with asymmetric jump probabilities to nearest neighbor sites, and how these jump probabilities can be calculated from the basic dynamic update equation of the scores. The corresponding probability distributions of scores are either of the form of exponential localization or diffusion with a drift. In the appendices we show that the model is related to but independent from the Hamiltonian formulation and we show how it can also be readily applied to the game with linear payoff where the master equation has long-range hopping.\nAlthough the MG is well understood from the classic works discussed above, it is our hope that the simplified model of the steady state attendance and score distributions presented in this paper provides an alternative and readily accessible perspective on this fascinating model.\n# II. DEFINITION OF THE GAME AND OUTLINE\nIn order to give an overview of our results and for completeness we start by providing the formal definition of the Minority Game and some basic properties [2, 9, 10]. At each discrete time step every agent gives a binary bid ai(t) = \u00b11, all of which are collected into a total attendance\n(1)\n(N odd) and the winning minority group is then identified through \u2212sign(At). A binary string of the m past winning bids, called a history \u00b5, is provided as global information to each agent upon which to base her decision for the following round. There are thus \u00b5 = 1, ..., P with P = 2m different histories. At her disposal each agent has two randomly assigned strategies (a.k.a. strategy tables) that provide a unique bid for each history. The bid of strategy j = 1, 2 of agent i = 1, .., N in response to history \u00b5 is given by a\u00b5 i,j = \u00b11 and the full strategy is the P dimensional random binary vector \u20d7ai,j. There are thus a total of 2P distinct strategies available. The agent uses at each time step the strategy that has made the best predictions for minority group historically. This is decided by a score Ui,j(t) for each strategy which is updated according to Ui,j(t + 1) = Ui,j(t) \u2212a\u00b5 i,jsign(A\u00b5 t ), irrespectively of the strategy actually being used or not. (Here the superscript \u00b5 on At\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/88ec/88ecba23-d9c2-425b-9446-e1a9443dba05.png\" style=\"width: 50%;\"></div>\nFIG. 1: Evolution of strategy scores for the two strategies of four (i = 1, ...4) representative agents in a game with N = 101 agents and a memory of length m = 7 (P = 27). At each time step every agent uses the one of her two strategies which has the highest momentary score, given by how well the strategy has predicted the past minority groups. The corresponding score difference xi(t) (inset) shows the distinction between frozen agents that consistently use a single strategy, and fickle agents that switch between strategies.\njust indicates that the attendance will depend on the history \u00b5(t) giving the bids at time t.) Ties, i.e. Ui,1 = Ui,2, are decided by a coin toss. Since it is only the relative score between an agent\u2019s two strategies that is important in deciding which strategy to use, one may focus on the relative score\n(2)\nThis is updated according to\n(3)\nxi(t + 1) = xi(t) + \u2206i(t) ,\n(3)\n(4)\nand where \u20d7\u03bei = (\u20d7ai,1 \u2212\u20d7ai,2)/2 is an agents \u201cdifference vector\u201d that takes values \u00b11 or 0 for each history \u00b5. To make the dynamics generated by these equations more concrete, Figure 1 shows the scores of the strategies of four particular agents Ui,1/2, i = 1, . . . , 4 for one realization of a game with N = 101, P = 27, together with the corresponding relative scores xi (inset), over a limited time interval. As exemplified by this figure agents come in two flavors, known as \u201dfrozen\u201d and \u201dfickle\u201d [4, 13]. An agent is frozen if one of her strategies performs consistently better than the other, such that on average the score difference is diverging, whereas fickle agents have a relative score that meanders around x = 0 switching their used strategy. The motion of xi for both fickle and frozen agents is a random walk with a bias towards or\naway from x = 0. A basic problem is to characterize and understand this random walk and derive the corresponding probability distribution Pi(x, t); the probability to find agent i at position x at time t [9, 15].\n# A. Outline and results\nAs presented in Section III we can quantify the correlation between an agent\u2019s strategies, specified by \u03be\u00b5 i , and the total attendance A\u00b5 t , which in turn allows for characterizing the mean (time averaged) step size \u2206i = \u27e8xi(t + 1) \u2212xi(t)\u27e9in terms of a distribution over agents P(\u2206i). In agreement with earlier work we find that \u2206i has two contributions; one center (x = 0) seeking bias term which arises from self interaction (the used strategy contributes to the attendance and as such is more likely to be in the majority group [16]) and a fitness term which reflects the relative adaptation of the agent\u2019s two strategies to the time averaged stochastic environment of the game. The distribution of step sizes over the population of agents are shown in Figure 3 where frozen agents are simply those where the fitness overcomes the bias, such that \u2206i > 0 for x > 0 or \u2206i < 0 for x < 0, whereas for fickle agents \u2206i < 0 for x > 0 and vice versa. Knowing the mean step size of an agent allows for a formulation in terms of a one dimensional random walk (Fig. 4) with corresponding jump probabilities, as presented in Section IV. Depending on whether it is more likely to jump towards the center or not (fickle or frozen respectively) the master equation on the chain can be solved in terms of a stationary exponential distribution centered at x = 0 or (in the continuum limit) a normal distribution with a variance and mean that grow linearly in time (diffusion with drift). These are the distributions Pi(x, t) depending on \u2206i. In simulations over many agents it is natural to consider the full distribution P(x, t) = \ufffdN i=1 Pi(x, t)/N = \ufffd P(\u2206i)Pi(x, t)d\u2206i, with NP(x, t) thus the probability of finding an agent at time t with relative score x. In terms of scaled coordinates x/ \u221a N and t/N we find that the distribution only depends on \u03b1. The model distributions show excellent agreement with direct numerical simulations (Fig. 5 and 6) with no fitting parameters. This result for the full distribution of relative scores together with its systematic derivation for the original signpayoff game represent the main results of this paper. In Appendix B we discuss the relation between the model presented in this work and the formulation in terms of a minimization problem of a Hamiltonian generator of the asymptotic dynamics [7, 12]. We find that one way to view the present model is as a reduced ansatz for the ground state where the only parameters are the fraction of positively and negatively frozen agents (solved for self-consistently) instead of the full space of the frequency of use of each strategy. With this ansatz closed expressions can be derived for the steady state distributions irrespective of the form of the Hamiltonian.\nIn Appendix C we show how the model applies to the game with linear payoff \u2206i(t) = \u2212\u03be\u00b5 i A\u00b5 t .\n# In Appendix C we show how the model applies to the game with linear payoff \u2206i(t) = \u2212\u03be\u00b5 i A\u00b5 t .\nIII. STATISTICAL MODEL\n# III. STATISTICAL MODEL\nWe will now turn to describing the statistical model in some detail and derive the results discussed in the previous section. We define for each agent the sum and difference of strategies for each bid \u20d7\u03c9i = (\u20d7ai,1+\u20d7ai,2)/2 and (as discussed above) \u20d7\u03bei = (\u20d7ai,1 \u2212\u20d7ai,2)/2 [4]. Clearly \u03c9\u00b5 i , being the sum of two random numbers \u00b11 is distributed over (\u22121, 0, 1) with probability (1/4, 1/2, 1/4). A nonzero value of \u03c9\u00b5 i means that agent i always has the same bid for history \u00b5 independently of which strategy it has in play. The sum over all agents, \u20d7\u2126= \ufffdN i=1 \u20d7\u03c9i, thus gives a constant history dependent but time independent background contribution to the attendance. (In the sense that every time history \u00b5 occurs in the time series it gives the same contribution.) This background \u2126\u00b5 is, for large N, normally distributed with mean zero and variance\nAn interesting property of the Minority Game is that there is a \u201cZ2 gauge\u201d freedom with respect to an arbitrary choice of which is called strategy 1 and which is 2, thus corresponding to a change of sign of \u20d7\u03bei. Such a sign change will simply result in a change of sign of xi(t) having no consequence on which strategy is actually in play. (It is the strategy in play which is an observable, not whether it is labeled by 1 or 2.) Nevertheless, it turns out that making a consistent definition of the order of strategies is helpful in formulating a simple statistical model. Explicitly we order the two strategies (\u201cfix the gauge\u201d) of all agents i such that\n(5)\nShortly we will describe the distribution over agents of \u03be\u00b5 i , to quantify its anticorrelation with \u2126\u00b5 i . To proceed we write the attendance at a time step t with history \u00b5 as\n(6)\nwhere si(t) = \u00b11 depending on which strategy agent i is playing [4]. Again, the relative strategy score xi of agent i is updated according to Eqn. 4. Given the background contribution to the attendance \u20d7\u2126we expect there to be a surplus of si = 1 in the steady state with our choice of gauge because the strategy 1 is expected to be favored by the score update function. (In other words, strategy 1 is expected to have a higher fitness.) However, this correlation is not trivial as the accumulated score also depends on the dynamically generated contribution the attendance. As discussed previously some fraction \u03c6 of the agents are frozen, in the sense of always\nusing the same strategy, si = constant. We make an additional distinction (made significant by our choice of gauge) and separate the group of frozen agents into those with si(t) = 1 (fraction \u03c61), and those with si(t) = \u22121 (fraction \u03c62), such that \u03c6 = \u03c61 + \u03c62. Clearly, we expect the former to be more plentiful than the latter. We will now derive steady state distributions over agents for the mean step size \u2206i. For this purpose we will write the attendance as\n(7)\nwhere\n(8)\n(9)\n(10)\ncorresponding to the three categories of agents discussed previously. We will make the following simplifying approximations for these three components: the fickle component we will model as completely disordered, such that si(t) = \u00b11 is random, and correspondingly (for large N) St is normally distributed with mean zero and variance\nwith \u03d5 = (1\u2212\u03c61\u2212\u03c62) the fraction of fickle agents. (Thus, neglecting that the fickle agents would also have a net anticorrelation with the background \u20d7\u2126). We will assume the frozen agents to simply be a sum of independent random variables drawn from the distribution of \u20d7\u03be, thus neglecting that the agents that are frozen may come from the extremes of this distribution. To proceed, we need to find the distribution of \u20d7\u03bei, i.e. how it varies over the set of agents. (Henceforth we will usually drop the index i and regard the objects as drawn from a distribution.) Begin by defining \u20d7\u03c8 = Random(\u00b11)\u20d7\u03be, which is thus disordered with respect to the sign of \u20d7\u2126\u00b7 \u20d7\u03c8 [22]. The object \u03c8\u00b5 is independent of \u2126\u00b5 (ignoring 1/N corrections due to \u2126\u00b5 \u0338= 0 limiting the available bids \u00b11), taking values (1, 0, \u22121) with probability (1/4, 1/2, 1/4), which gives mean zero and variance 1/2. Consider the joint object h = 1 P \u20d7\u2126\u00b7 \u20d7\u03c8, for large P this becomes normally distributed with mean zero and variance \u03c32 h = 1 P (N/2)(1/2) = 1/(4\u03b1) [4]. Now, to quantify the correlation between \u20d7\u03be and \u20d7\u2126we define the object\nwhich consequently has mean < \u02dch >= \u2212 \ufffd dhP(h)|h| = \u22121/ \u221a 2\u03c0\u03b1 and < \u02dch2 >= \u03c32 h. We will represent this distribution by assuming that each component \u03be\u00b5 are independent Gaussian random variables with a mean that is\nlinearly dependent on \u2126\u00b5. With this assumption we find the conditional distribution\n(11)\nwhere c(\u03b1) = \ufffd 2 \u03c0\u03b1, and \u03c32 \u03be = 1/2, and where we write the normal distribution over x with mean \u00b5 and variance \u03c32 as Nx(\u00b5, \u03c3) = 1 \u221a 2\u03c0\u03c3e\u2212(x\u2212\u00b5)2/2\u03c32. This quantifies that \u03be\u00b5 is on average anticorrelated with \u2126\u00b5 which is expected to place strategy 1 in the minority group more often than strategy 2. Using Eqn. 11 we can also calculate the distributions of X\u00b5 (Y \u00b5) as the sum of \u03c61N (\u03c62N) correlated objects \u03be\u00b5 i , giving\n(12) (13)\nwith conditional variances \u03c32 X|\u2126= \u03c61N/2 and \u03c32 Y |\u2126= \u03c62N/2.\nGiven the model expressions for the distributions of all the components of the score update equation (Eqn 4) we will find the distribution of mean (time averaged) step sizes. As a first step we integrate out the fast variable St to get a conditional on \u00b5 time averaged step size \u2206\u00b5 = \u27e8\u2206(t)|\u00b5\u27e9. (Over a long time series of the game every history \u00b5 will occur many times, we thus average over all those occurrences of a single history.) This corresponds to\n(14)\nThe second term, which is a self-interaction, follows from the discrete nature of the original problem. It gives a negative bias for the used strategy coming from the fact that if the net attendance from all other agents is zero, the used strategy puts the agent in the majority group. (The factor 1 2 in the delta function is to account for the fact that the attendance, as defined in Eqn 1, changes in steps of two and the factor sign(x)\u03be\u00b5 comes from the fact that only the used strategy enters the attendance.) Integrated this gives\n,(15)\nwhere we have identified the first term as a fitness \u2206fit which quantifies the relative fitness of the agent\u2019s two\nstrategies and the second as a negative bias \u2206bias for the used strategy as discussed previously. To calculate the distribution of mean step sizes we will assume that histories occur with the same frequency such that \u2206= 1 P \ufffd \u00b5 \u2206\u00b5. This is in fact not the case for a single realization of the game in the dilute phase, some histories occur more often than others, as one can see directly from any simulation in this regime. Nevertheless, for large P we will assume that this variation of occurrences of \u00b5 averages out. As discussed extensively in the literature the overall behavior of the game is insensitive to whether the actual history is used (endogenous information) as input to the agents or if a random history is supplied (exogenous information) [9, 10, 15, 20, 21]. This is also confirmed by the present work through the good agreement between the model using exogenous information and simulations in which we use the actual history. Assuming large P and given the assumption of independence of the distributions \u2126, \u03be, X, Y for different \u00b5 we expect the distribution P(\u2206) to approach a Gaussian (by the central limit theorem) with mean\n(16)\nwith \u2206\u00b5 as in eqn 15, and with variance \u03c32 = 1 P (\u22062 \u2212 \u00af\u22062). The integrals are readily done analytically as described in the appendix A, but the expressions are very lengthy. The main features can be expressed in the following form:\n(17)\nwhere \u02dc\u2206bias/fit > 0 are functions that only depend on N and P through \u03b1 = P/N, change slowly as a function of the arguments in the physically relevant regime 0 \u2264\u03c61 + \u03c62 \u22641 (Fig. 7) and which satisfy \u02dc\u2206bias(\u03b1, 0, 0) = 1 \u221a 2\u03c0 and \u02dc\u2206fit(\u03b1, 0, 0) = 1 \u03c0. As seen from Eqn. 17, the mean bias is towards x = 0, the used strategy is penalized, while the mean fitness is positive acting to increase the relative score x, consistent with our choice of gauge as discussed earlier. The only appreciable contribution to the variance comes from the fitness term scaling as 1/P whereas the bias has a variance that scales with 1/(NP) and thus negligible (as is the cross term). The variance can be written\n(18) (19)\nwhere \u02dc\u03c3 > 0 also changes slowly in the relevant regime (Fig. 7) and satisfies \u02dc\u03c3(\u03b1, 0, 0) = 1 \u221a 6. The width of the fitness distribution explains the fact that even though\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/fa4a/fa4a95ff-600e-4b46-b26a-83ed953ed603.png\" style=\"width: 50%;\"></div>\nFIG. 2: The fraction of frozen agents as a function of \u03b1 = P/N from the statistical model (Eqns. 21 and 22) compared to results from direct numerical simulations of the game. The frozen agents are divided into two groups \u03c61 and \u03c62 depending on if they are frozen with relative score x > 0 or x < 0 respectively. The fact that \u03c61 > \u03c62 follows from our convention \u20d7\u03bei \u00b7 \u20d7\u2126\u22640 (eqn 5). Also shown is the total fraction of frozen agents from the replica calculation for linear payoff (Eqns. 3.41-3.44 of [9]). (Each data point is averaged over 20 runs with \u223c1e6 time steps each (1e5 steps for N = 2001).)\n\u00af\u2206fit > 0 consistent with \u03c61 \u0338= 0, there are also some agents with a large negative fitness which implies \u03c62 \u0338= 0. The fact that \u20d7\u03be \u00b7 \u20d7\u2126< 0 thus does not necessarily imply that strategy 1 is more successful than strategy 2 as the correlation with the other frozen agents is also an important factor. For large \u03b1, both the mean and variance of the fitness vanish, as can be understood as a result of there being too few agents compared to the number of possible outcomes to maintain any appreciable correlation between an agents strategies and the aggregate background, \u20d7\u03be\u00b7\u20d7\u2126\u22480. In this limit, since the bias term always penalizes the used strategy there can be no frozen agents. We also see that both the mean and width of the distribution for given \u03b1 scales with 1/ \u221a N, consistent with simulations (Fig. 3).\nFor each agent the score difference xi moves with a mean step per unit time of\n(20)\nwhere \u2206fit is drawn from the distribution N( \u00af\u2206fit, \u03c3fit). If the fitness is high, such that \u2206+ > 0, the agent will\nhave a net positive movement and the agent is frozen, with xi > 0 and growing unbounded. The fraction of positive frozen agents is given by\n (21)\nSimilarly, if the fitness is relatively very poor, such that \u2206\u2212< 0 the agent is frozen (with xi < 0) with magnitude growing unbounded. The fraction of negatively frozen agents is given by\n (22)\nand correspondingly the complete fraction of frozen agents \u03c6 = \u03c61 +\u03c62 and fickle agents \u03d5 = 1\u2212\u03c6 are found. Since \u02dc\u2206fit, \u02dc\u2206bias, and \u02dc\u03c3 are functions of \u03b1, \u03c61, and \u03c62, the two equations allow for solving for \u03c61(\u03b1) and \u03c62(\u03b1) as a function of the only parameter \u03b1. We find that the solutions are readily found by forward iteration, and the results are plotted and compared to direct simulations of the game in Figure 2 [23]. The fit is good, but there is no indication of a phase transition for small \u03b1 in this simplified model. From simulations we can also measure the distribution of mean step sizes to compare to the model, which is shown in Figure 3. There we show an intermediate value of \u03b1, the fit in terms of mean and width is not as good close to \u03b1c and almost perfect for large \u03b1, but everywhere the data seems well represented by a normal distribution. We also use the mean step size distributions from simulations to calculate the fraction of frozen agents, Figure 2. (The naive way to distinguish between frozen and switching agents; to introduce a cut-off xcut at some time t, with any agents with |xt| > xcut considered frozen, makes it difficult to distinguish between frozen and switching agents with \u2206near 0.)\n# IV. DISTRIBUTIONS OVER x\nWe now use the fact that each agent is characterized by an average step size per unit time, specified by the fitness \u2206fit, to describe the movement of the relative score x on the set of integers. Consider that the agent at time step t has score difference x, what is the probability that at time t + 1 the score difference is x\u2032? In each time step, x can only change by \u22121, 0, 1 as given by the basic score update equation 4. We specify the respective probabilities p\u2212, p0, p+ with p\u2212+ p0 + p+ = 1 for x > 0 and q\u2212, q0, q+ for x < 0. The mean probability that x remains unchanged is p0 = q0 = 1 2 as this corresponds to \u03be\u00b5 i = 0, meaning that the agent\u2019s two strategies have the\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3bea/3bea9bcf-d31e-463e-b73c-88a39f365e5a.png\" style=\"width: 50%;\"></div>\n0.1 0.2 0.3 0.4 0.5 raction of frozen agents Fraction of frozen agents Frozen with x > 0 Frozen with x < 0 All frozen Frozen with x > 0 Frozen with x < 0 All frozen N = 101 N = 201 N = 401 N = 801 N = 2001 FIG. 3: Distributions for mean step per unit time \u2206= \u27e8x(t+ 1) \u2212x(t)\u27e9at \u03b1 \u22484 for x > 0 (top) and x < 0 (bottom), comparing direct simulations of the game to the statistical model (Eqn. 20). The fraction of frozen agents with x > 0 (\u03c61) is indicated by \u201dfr,+\u201d and similarly for x < 0 (\u03c62). The distributions of step sizes are different for x > 0 and x < 0 because of the convention \u20d7\u03bei \u00b7 \u20d7\u2126\u22640 as explained in Fig. 2. (Simulations averaged over 1e6 time steps, excluding a 1e4 equilibration time.)\n100 101 \ufffd same bid which on average (over \u00b5) will be the case for half of the histories. It should also be clear that the stepping probabilities cannot depend on the magnitude of x, only the sign, because the difference in score between strategies does not enter the game, only which strategy is currently used. The case x = 0 has to be treated separately; we toss a coin to decide which strategy is used, thus the probability for a +1 increment is (p+ + q+)/2 and for a \u22121 increment is (p\u2212+q\u2212)/2. The movement of x thus corresponds to a one-dimensional random walk on a chain, with asymmetric jump probabilities, as sketched in Figure 4. To relate the probabilities to the mean step size we note that for x > 0, \u2206+ = 1 \u00b7 p+ + 0 \u00b7 p0 \u22121 \u00b7 p\u2212, which together with the conservation of probability and the fact that p0 = 1/2 gives\n(23)\n(23)\n(24)\n  where results for q follow from the same analysis for x < 0. Keeping in mind that for a fickle agent \u2206+ < 0 and\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/31cd/31cd249c-0b0d-4fbb-aa9a-baba352c2f46.png\" style=\"width: 50%;\"></div>\nFIG. 4: The movement of the relative strategy score x of an agent is described by a random walk on a chain with jump probabilities p+, p\u2212, p0 for x > 1 (i.e. strategy 1 in play) and q+, q\u2212, q0 for x < \u22121 (i.e. strategy 2 in play). At the boundary x = \u22121, 0, 1 due to the coin toss choice of strategy the probabilities are altered as in the figure.\n\u2206\u2212> 0 this is of course consistent with p+ < p\u2212and q\u2212< q+. A frozen agent is instead given by p+ > p\u2212or q\u2212> q+. With the known probabilities we can write down a master equation on the chain for the probability distribution Px(t) (implicit \u2206fit dependence)\n1 Px(t + 1) = p0Px(t) + p+Px\u22121(t) + p\u2212Px+1(t), x > 1 Px(t + 1) = q0Px(t) + q+Px\u22121(t) + q\u2212Px+1(t), x < 1 , (25)\nand at the boundary\n(26)\nAssuming that the distribution is stationary, such that Px(t) = Px, and concentrating on x > 0, we find after some manipulations the equation\nwhich has the exponential solution\n(27)\nIn the last step we used equation 23 and the fact that from equation 17 the mean step size is small such that |\u2206+| \u223c1/ \u221a N \u226a1. From this we can identify a decay length x+ = 1/(4|\u2206+|) \u223c \u221a N, which characterizes the range of positive excursions of the score difference of the fickle agent. Clearly, this solution requires p\u2212> p+ (\u2206+ < 0) to be bounded, as is the case for fickle agents. From the same analysis for x < 1 the fickle agents with q\u2212< q+ have the distribution Px \u223ce x ln q+ q\u2212\u2248e4x\u2206\u2212. What remains is to match up the solutions for positive and negative x at the interface. This can be solved exactly, but given that the exponential prefactor is small\n(28)\nFrom this expression we see that the distribution is asymmetric, such that given that on average |\u2206+| < \u2206\u2212 agents are more likely to be found with x > 0. This opens up for a more sophisticated modelling (left for future work) where this aspect is fed back into the initial statistical description of the sum of fickle agents through the dynamical variable St, the total attendance of the fickle agents, acquiring a mean depending on \u00b5. For the frozen agents the master equation is the same, but given p+ > p\u2212(or q\u2212> q+) we expect a drift of the mean of the distribution. Thus focusing on long times we can consider one or the other of Eqs. 25 depending on whether the agent is frozen with x > 0 or x < 0. For x > 0 and assuming that the agent at time t = 0 is at site x = 0 (neglecting the influence any excursions to x < 0) we can write down an exact expression for Px(t) in terms of a multinomial distribution. Alternatively, and simpler, we can take the continuum limit Px(t+1) = P(x, t)+ dP dt and Px\u00b11(t) = P(x, t) \u00b1 dP dx + 1 2 d2P dx2 to find the FokkerPlanck equation\n(29)\nGiven the initial condition P(x, 0) = \u03b4(x) this has the solution P(x, t) = Nx(\u00afx, \u03c3t) with \u00afx = (p+ \u2212p\u2212)t = \u2206+t and \u03c32 t = (p+ + p\u2212)t = 1 2t, thus describing diffusion with a drift.\nGiven that we now have a description of the relative score distribution of a single agent in terms of an asymmetric exponential decay or diffusion, we can also consider the full distribution of relative scores over all agents, by integrating over the distribution of mean step sizes. Defining the scaled variables \u02dcx = x/ \u221a N and \u02dct = t/N we write P(\u02dcx, \u02dct) = Pfi(\u02dcx) + Pfr,+(\u02dcx, \u02dct) + Pfr,\u2212(\u02dcx, \u02dct), corresponding to the stationary distribution of the fickle agents and diffusive distributions of the frozen agents with x > 0 and x < 0 respectively. The first component is\n(30)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8e92/8e92da5c-55ef-4e58-bc28-0f8a1aecd7d0.png\" style=\"width: 50%;\"></div>\nFIG. 5: Full scaled distribution P\u02dcx with \u02dcx = x/ \u221a N over all agents for \u03b1 \u22484 compiled by averaging simulations over scaled time window \u02dct0 = t0/ \u221a N to \u02dct1 = t1/ \u221a N. The model results (\u201dfickle+frozen\u201d) are P\u02dcx = 1 \u02dct1\u2212\u02dct0 \ufffd\u02dct1 \u02dct0 d\u02dctP(\u02dcx, \u02dct), using Equations 30 and 31. Also shown are model results using only fickle agents. The following time windows are used: for N = 501, t0 = 5e5 to t1 = 5e6; for N = 1001, t = 2t0 to 2t1; for N = 2001, t = 4t0 to 4t1, which correspond to the same \u02dct0 and \u02dct1. (Simulations are averaged over 80 runs for N = 501 and 15 runs for N = 1001 and 2001.)\nwhere \u00b1 corresponds to x < 0 and x > 0 respectively, and where b\u03b1 = | \u02dc\u2206bias|. For the frozen agents we have\n(31)\nwhere \u03c32 \u02dct = \u02dct/2. These expressions are compared to direct simulations of the game for intermediate \u03b1 \u22484 in Fig. 5. The simulations are averaged over a specific time window and the diffusive component Eqn. 31 is integrated over the corresponding scaled time window. The agreement is excellent over the complete stationary and diffusive components of the distribution and shows the data collapse in terms of scaled coordinates. In Fig. 6 we also show a comparison for large \u03b1 \u224880 where the simulations have no frozen agents and all fickle agents are localized by a length close to the \u03b1 \u2192\u221evalue x0 = \ufffd \u03c0N/8. The asymmetry of these plots is an artefact of our gauge choice \u20d7\u03bei \u00b7 \u20d7\u2126\u22640 which implies that on average agents will use strategy 1 (x > 0) more frequently than strategy 2 (x < 0). To restore the full symmetry is simply a matter of symmetrizing the distributions around x = 0.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c77e/c77e6c9d-d054-4201-bb92-a43ec4632ef2.png\" style=\"width: 50%;\"></div>\nFIG. 6: Distribution P\u02dcx at large \u03b1 \u224880. There are no frozen agents, and the simulated and model (\u201cfickle\u201d) distributions are stationary. Also shown is the asymptotic \u03b1 \u2192\u221ebehavior where all agents are symmetrically localized with localization length x0 = \ufffd \u03c0N/8, and a simulation at \u03b1 \u2248650 which approaches this asymptotic behavior. (Simulations averaged over \u223c4e8 time steps.)\nFinally, we remark that the formal solution in terms of an exponential distribution of strategy scores for frozen agents was derived in [12] from a Fokker-Planck equation for the linear payoff game. See Appendix B and C for a further discussion of the comparison between the present model and the Hamiltonian formulation.\n# V. SUMMARY\nWe have studied the asymmetric phase of the basic Minority Game, focusing on the statistical distribution of relative strategy scores and the original sign-payoff formulation of the game. We formulate a statistical model for the attendance that relies on a specific gauge choice in which the two strategies of each agent are ordered with respect to the background (\u20d7\u03bei \u00b7 \u20d7\u2126\u22640 for all agents i). Using this model we can derive a distribution of the mean step per time increment for the relative scores, specified in terms of a bias for the used strategy and the relative fitness of the two strategies. The relative strategy score for each agent is conveniently described as a random walk on an integer chain, where the jump probabilities are calculated from the mean step. The probability distribution of observing the agent at some position on the chain at a given time is either given by a static asymmetric exponential localized around x = 0 for fickle agents or to diffusion with a drift for frozen agents. Excellent agreement with direct simulations of the game for the score distribution confirms the basic validity of the modelling. At the same time, as discussed in the appendix, the fluctuations of the attendance are\noverestimated by the model. By contrasting with the Hamiltonian formulation of the dynamics the reason for this discrepancy is readily understood from viewing the model as a crude ansatz for full minimization problem. This also opens up for improving the model by introducing some variational parameters without having to confront the full complexity of the minimization of a non-quadratic Hamiltonian for general payoff functions. We thank Erik Werner for valuable discussions. Simulations were performed on resources at Chalmers Centre for Computational Science and Engineering (C3SE) provided by the Swedish National Infrastructure for Computing (SNIC).\n# Appendix A: Solving for mean and variance of step size.\nAppendix A: Solving for mean and variance of step size.\nThe integrals to calculate the mean and variance for the distribution of average step sizes, Eqn. 16, are Gaussian integrals including the error function. To solve these we first rescale the variables in terms of the variance \u2126/\u03c3\u2126\u2192\u2126, X/\u03c3X|\u2126\u2192X etc. and perform the integral over the distribution of agents \u03be which evaluates to \u27e8\u03be|\u2126\u27e9= \u2212c(\u03b1)\u2126/ \u221a 2N (c(\u03b1) = \ufffd 2 \u03c0\u03b1) and \u27e8\u03be2|\u2126\u27e9= 1 2. We are left with integrals\n(A1)\nand\n(A3)\nTo evaluate these we use the following integral formulas\n(A4)\n(A5)\nand\ufffd\n(A6)\n\ufffd where A is a symmetric (positive definite) matrix, and b and c are real constants. The bias term thus follows from a direct application of the first integral formula to a 3x3 matrix. The fitness term follows from a substitution X\u2032 = X + \u221a\u03c61c(\u03b1)\u2126and Y \u2032 = Y \u2212\u221a\u03c62c(\u03b1)\u2126 to apply the second integral formula over \u2126and subsequently the first integral formula on a 2x2 matrix. The variance can be calculated by the substitution for \u2126, z = \u2126+\u221a\u03c61X+\u221a\u03c62Y , followed by integrating out X and Y to finally apply the third integral formula over z. The actual expressions are quite lengthy[24], but the important features can be represented according to Eqs. 17 and 19 in terms of functions \u02dc\u2206bias(\u03b1, \u03c61, \u03c62), \u02dc\u2206fit(\u03b1, \u03c61, \u03c62), and \u02dc\u03c3(\u03b1, \u03c61, \u03c62). After solving for for the fractions of frozen agents \u03c61(\u03b1) and \u03c62(\u03b1) using Eqs. 21 and 22, we can consider these functions as dependent only on the control parameter \u03b1. The dependence on \u03b1 is plotted in Figure 7, to point out that these functions change little over the whole relevant range \u03b1 > \u03b1c \u22480.3.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bd8c/bd8cec09-2432-43fe-9b04-f80b292d6d18.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIG. 7: The \u03b1 parameter dependence of the three quantities specifying the mean and variance of the distribution of mean step sizes according to Equations 17 and 19.</div>\nFIG. 7: The \u03b1 parameter dependence of the three quantities specifying the mean and variance of the distribution of mean step sizes according to Equations 17 and 19.\n<div style=\"text-align: center;\">Appendix B: Hamiltonian formulation</div>\n# Appendix B: Hamiltonian formulation\nHere we connect the formalism in the present work to the solution using the replica method, following closely the presentation in [12] and [7]. Expressing the attendance for given history in terms of fluctuations around a mean as\n(B1)\nwhere St is a Gaussian random variable with mean zero and variance \u03c32 S (to be determined self-consistently).\nThis is related to expression (7), where we take an explicit statistical form \u27e8A|\u00b5\u27e9= \u2126\u00b5 + X\u00b5 + Y \u00b5, assumed to correspond to background plus frozen agents. Also, in the model in this paper we have the magnitude of \u03c32 S as \u03d5N/2, with \u03d5 the fraction of fickle agents. This is not assumed in the present treatise, but as we will see the outcome is related. There is also the explicit expression, Eqn. 6, for the attendance A\u00b5 t = \u2126\u00b5 + \ufffd i \u03be\u00b5 i si(t), where si(t) = \u00b11 depending on which strategy is momentarily used by the agent. Taking the time average of this and assuming that the frequency of use is not influenced by the rapid switches of history we write \u27e8si(t)\u27e9= mi, where for frozen agents mi = \u00b11 and for fickle |mi| < 1. AS discussed in [12] the fluctuations of si(t) are statistically independent such that \u27e8si(t)sj(t)\u27e9= mimj for i \u0338= j, whereas (si(t))2 = 1 by definition. With this we can write \u27e8A|\u00b5\u27e9= \u2126\u00b5 + \ufffd i \u03be\u00b5 i mi, noting that \u2202\u27e8A|\u00b5\u27e9 \u2202mi = \u03be\u00b5 i . Now, evaluating the variance of the attendance using Eqn. 6 and \u03c32 \u2126= N/2, we find\nThis we can alternatively write (using Eqn. B1) as \u03c32 = 1 P \ufffd \u00b5\u27e8A|\u00b5\u27e92 + \u03c32 S = H + \u03c32 S. Here H, the predictability, also has the alternative form (using Eqn. 6)\nCorrespondingly we find for the rapidly fluctuating field St the variance\n(using \u03c32 \u03be = 1/2). The latter expression has no contribution from frozen agents (as expected), and assuming that the distribution of mi is quite strongly centred at 0 it will be close to, but always lower than, our assumed value of \u03d5N/2. Consider now the fixed history time averaged step size for agent i, \u2206\u00b5 i = \u2212\u03be\u00b5 i \u27e8sign(At)|\u00b5\u27e9, with\nThe aim is to find a Hamiltonian generator H of the long time dynamics such that the time and history averaged update is given by\n(Note that this expression is not equivalent to Eqn. 16). The latter is the mean of a distribution, whereas the present object represents the full distribution of average\nstep sizes over agents corresponding to different i.) A function that does this is H = \ufffd dSP(S)G(\u27e8A|\u00b5\u27e9+ S) where G(x) = x sign(x) such that dG dx = sign(x), which evaluates to\n(B2)\nThinking of the long-time evolution of the score difference for agent xi which has an average step size \u00af\u2206i, we find that if \u00af\u2206i > 0 the agent will be frozen positive, with mi = 1 and similarly if \u00af\u2206i < 0 it will be frozen negative, with mi = \u22121. Only if \u00af\u2206i = 0 the agent will be fickle, with \u22121 < mi < 1. Considering that \u00af\u2206i = \u2212\u2202H \u2202mi we find the three cases: m1 = 1 corresponds to \u2202H \u2202mi < 0, m1 = \u22121 corresponds to \u2202H \u2202mi > 0, and \u22121 < mi < 1 corresponds to \u2202H \u2202mi = 0. The solution to this thus corresponds to finding the minimum of H with respect to {mi}. The minimization of Eqn. B2 however, looks like a formidable problem in the thermodynamic limit, and we are not aware that it has been pursued in the literature. (Note that \u27e8A|\u00b5\u27e9\u223c \u221a N \u223c\u03c3S such that an expansion is not appropriate.) This is in contrast to the case of linear payoff (se Appendix C) where Hlinear = H = 1 P \ufffd \u00b5\u27e8A|\u00b5\u27e92 which is a quadratic form in the variables mi. For the latter case the minimization problem has been solved using the replica method [7, 16, 17]. The equilibrium score distributions that we focus on in the present work have been solved for in [12] but to the best of our knowledge not for the sign-payoff game. Also, it appears that these distributions have not been discussed or studied in any detail, or compared to simulations, in earlier work.\n# Appendix C: Distributions with linear payof\nHere we repeat the analysis of the main paper for the case of linear payoff where Eqn. 4 is replaced by\n(C1)\nWe apply the same distributions, Eqs. 11-13, for the relative bid \u03be\u00b5, the contribution to the attendance of the positively (x > 0) frozen agents X\u00b5, and the negatively (x < 0) frozen agents Y \u00b5 and write A\u00b5 t = \u2126\u00b5 + X\u00b5 + Y \u00b5 + St (Eqn. 7). Here \u2126\u00b5 is the background (mean zero, variance N/2) and St is the contribution from the fickle agents (with assumed mean zero). Integrating over time at fixed history \u00b5, St integrates to zero because of linearity, giving\n(C2)\nwhere we have explicitly inserted the negative bias term for the used strategy. Averaging over histories in the\n(C3)\nand the fitness is normal with mean and variance given by\n(C4)\n(C5)\nwhere as before c = c(\u03b1) = \ufffd 2/\u03c0\u03b1 and \u03c61 and \u03c62 are the respective fractions of frozen agents. We note that the step size is of order 1 for the linear payoff, compared to order 1/ \u221a N for the sign payoff game. Similarly in both cases, for large \u03b1 the fitness drops out, ensuring that there are no frozen agents. For moderate \u03b1 the fraction of frozen agents need to be solved for self-consistently through the equations\nAs for the sign-payoff game the results from solving these equations numerically are in good agreement with simulation data in the dilute phase as shown in Fig. 8. (Note, compared to Fig. 2, that both the data and model results for the fraction of frozen agents are very similar and quite insensitive to whether sign-payoff or linear payoff is used.)\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e0a1/e0a1e1fa-f0ea-4a44-84f0-e094900e018a.png\" style=\"width: 50%;\"></div>\nFIG. 8: The fraction of frozen agents as a function of \u03b1 for linear payoff. Also shown is the total fraction of frozen agents from the replica calculation (Eqns. 3.41-3.44 of [9]) (Each data point is averaged over 20 runs with \u223c1e6 time steps each (1e5 steps for N = 2001).)\nThe fluctuations of attendance \u03c32 = \u27e8A2\u27e9= H +\u03d5N/2 with H = 1 P \ufffd \u00b5\u27e8A|\u00b5\u27e92 = N 2 (1 \u2212c(\u03c61 \u2212\u03c62)))2 are compared to simulations in Fig. 9. These are clearly significantly overestimated by the model. (Similar results are found for the sign-payoff game and model.) Following the exposition in appendix B, the reasons for this discrepancy is quite clear. The model always overestimates the fluctuations St, and since we are assuming that only the frozen agents contribute to \u27e8A|\u00b5\u27e9we also miss the contribution of the fickle agents to reduce H. There seems to be a quite clear path to improve the model along these lines, which is left for future work. Here we opt for the simplicity of solving the present model and the fact that it does give quantitative agreement with distribution of realtive strategy scores.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3f7c/3f7cf715-0c72-42c9-af9a-0281c35f805c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIG. 9: Model and simulation results for \u03c32 and H for the linear payoff game. (Each point is averaged over 10 runs with 107 time steps each).</div>\nAs a next step we can find the score distributions by solving the master equation on an integer chain. In contrast to the t game where scores are only updated by 0 or \u00b11, we now have to consider longer range hopping where scores are updated by integer steps in the range \u2212N to N. Taking into account the individual time averaged step size \u2206\u00b1 = \u2206fit\u22131 2 (for x > 0 and x < 0 respectively) and the fact that \u03be\u00b5(t)At has variance N/2, we expect that the jump propabilities are well represented by a normal distribution (for a jump from x to x\u2032)\n(C6)\nThe master equation takes the form\n(C7)\nTaking the continuum limit over space and ignoring complications due to the boundary x = 0, this can be solved in terms of exponential localization for fickle agents\n(\u2206+ < 0 and \u2206\u2212> 0) and diffusion with a drift for frozen agents (\u2206+ > 0 or \u2206\u2212< 0). For fickle agents the score distributions are given by\n(C8)\nfor x > 0 and x < 0 respectively, which in the large \u03b1 limit reduces to P(x) \u223ce\u22132x/N. For frozen agents the\n[1] W. B. Arthur. Inductive Reasoning and Bounded Rationality: The El Farol Problem. Amer. Econ. Review (Papers and Proceedings), 84, 406 (1994). [2] D. Challet, Y.-C. Zhang. Emergence of Cooperation and Organization in an Evolutionary Game. Physica A, 246, 407 (1997). Y.-C. Zhang, Evolving models of financial markets. Europhys. News 29, 51 (1998) [3] R. Savit, R. Manuca, R. Riolo. Adaptive Competition, Market Efficiency, and Phase Transitions. Phys. Rev. Lett., 82, 2203 (1999). [4] D. Challet, M. Marsili. Phase transition and symmetry breaking in the Minority Game. Phys. Rev. E 60, R6271(R), (1999). [5] M. A. R. de Cara, O. Pla, F. Guinea. Competition, efficiency and collective behavior in the \u201dEl Farol\u201d bar model. Eur. Phys. J. B 10, 187 (1999). [6] A. Cavagna, J. P. Garrahan, I. Giardina, and D. Sherrington. Thermal Model for Adaptive Competition in a Market, Phys. Rev. Lett. 83, 4429 (1999). [7] D. Challet, M. Marsili, and R. Zecchina. Statistical Mechanics of Systems with Heterogeneous Agents: Minority Games, Phys. Rev. Lett., 84 1824 (2000). [8] P. Jefferies, M. L. Hart, P. M. Hui and N. F. Johnson. From market games to real-world markets. Eur. Phys. J. B 20, 493 (2001). [9] D. Challet, M. Marsili, Y-C. Zhang. Minority Games, Oxford University Press, Oxford, UK, 2005. 10] C.H. Yeung, Y.-C. Zhang. Minority Games. Encyclopedia of Complexity and Systems Science, 5588-5604 (2009). 11] A. Chakrabortia, D Challeta, A Chatterjeec, M Marsilie, Yi-Cheng Zhang, B. K. Chakrabartid. Statistical Mechanics of Competitive Resource Allocation using Agentbased Models, Phys. Rep. 552, 1 (2015). 12] M. Marsili and D. Challet. Continuum time limit and stationary states in the minority game, Phys. Rev. E 64, 056138 (2001). 13] J.A.F. Hemiel and A.C.C. Coolen. Generating functional\n12\n(C9)\nfor positively and negatively frozen agents respectively.\nanalysis of the dynamics of the batch minority game with random external information, Phys. Rev. E 63, 056121 (2001). [14] A. C. C. Coolen. Generating functional analysis of minority games with real market histories. J. Phys. A: Math. Gen. 38, 2311 (2005). [15] A.C.C. COOLEN. The Mathematical Theory of Minority Games: Statistical mechanics of interacting agents, Oxford University Press 2005. [16] M. Marsilia, D. Challet, R. Zecchinac, Exact solution of a modified El Farol\u2019s bar problem: Efficiency and the role of market impact. Physica A 280, 522 (2000). [17] M. Mezard, G. Parisi and M. Virasoro Spin Glass Theory and Beyond: An Introduction to the Replica Method and Its Applications, World Scientific Lecture Notes in Physics: Volume 9. World Scientific, Singapore (1987) [18] G. Acosta, I. Caridi, S. Guala, J. Marenco. The quasiperiodicity of the minority game revisited. Physica A, 392, 4450 (2013). [19] M. Hart, P. Jefferies, P. M. Hui and N. F. Johnson. Crowd-anticrowd theory of multi-agent market games. Eur. Phys. J. B 20, 547 (2001) [20] A. Cavagna, Irrelevance of memory in the minority game, Phys. Rev. E, 59, R3783 (1999). [21] D. Challet and M. Marsili. Relevance of memory in minority games. Phys. Rev. E 62, 1862 (2000). [22] Note that what we here refer to as \u03c8 is what is called \u03be in the literature [4]. In this paper we reserve \u03be for the object where strategies are ordered such that \u20d7\u2126\u00b7 \u20d7\u03bei \u22640, corresponding to \u03be\u00b5 i = \u2212\u03c8\u00b5 i sign(\u20d7\u2126\u00b7 \u20d7\u03c8i). [23] The numerical data for Fig. 2 is found by measuring the mean step size and identifying those that for x > 0 have \u2206> 0 or for x < 0 have \u2206< 0 as shown in Fig. 3. [24] The exact expressions for these quantities are derived from the integral formulas as explained, but we are also happy to share them directly. Contact the first author.\n",
    "paper_type": "theory",
    "attri": {
        "background": "This paper addresses the dynamics of the Minority Game in its asymmetric phase, where agents compete to choose the minority option in a market-like scenario. It highlights the importance of understanding the equilibrium distribution of relative strategy scores among agents and the statistical methods that can be employed to analyze these dynamics.",
        "problem": {
            "definition": "The main problem is to characterize the dynamics and score distributions of agents in the asymmetric phase of the Minority Game, specifically focusing on the behavior of agents with varying strategies over time.",
            "key obstacle": "A significant challenge lies in deriving quantitative results for the original sign-payoff formulation of the game, which is complex and difficult to analyze directly."
        },
        "idea": {
            "intuition": "The idea is inspired by the need to simplify the modeling of the Minority Game while retaining essential characteristics of the agents' interactions and strategy adaptations.",
            "opinion": "The authors propose that a statistical model can effectively capture the dynamics of relative strategy scores in the Minority Game, allowing for a clearer understanding of agent behavior.",
            "innovation": "This work introduces a simplified statistical model that avoids complex reformulations seen in previous approaches, providing a more transparent method for analyzing the dynamics of the game."
        },
        "Theory": {
            "perspective": "The paper adopts a statistical mechanics perspective, treating the agents\u2019 strategies and scores as dynamic variables influenced by random interactions.",
            "opinion": "The authors assume that the distribution of strategy scores can be represented through random walks with asymmetric jump probabilities, leading to either exponential localization or diffusion.",
            "proof": "The derivation of the theory is based on the master equation of random walks and the relationship between the agents' score dynamics and their strategies, which has been validated against numerical simulations."
        },
        "experiments": {
            "evaluation setting": "The evaluation involves simulations of the Minority Game with a varying number of agents (N) and distinct histories (P), focusing on the distribution of strategy scores over time.",
            "evaluation method": "The authors compare the theoretical distributions derived from their statistical model with the outcomes of numerical simulations, analyzing the agreement between the two."
        },
        "conclusion": "The study concludes that the proposed statistical model provides an accurate description of the dynamics of relative strategy scores in the Minority Game, showing good agreement with simulation results without requiring fitting parameters.",
        "discussion": {
            "advantage": "The main advantage of this paper is its ability to simplify the analysis of the Minority Game, making it more accessible while still producing reliable results.",
            "limitation": "A limitation noted is that the model tends to overestimate fluctuations in attendance, indicating that it may not fully capture the complexity of agent interactions.",
            "future work": "Future improvements could involve refining the model by introducing variational parameters and exploring the full complexity of the minimization problem related to the dynamics of the game."
        },
        "other info": []
    },
    "mount_outline": [
        {
            "section number": "2. Background and Definitions",
            "key information": "The paper addresses the dynamics of the Minority Game, which can be contextualized within discussions of algorithmic bias and AI systems by exploring the competitive strategies of agents."
        },
        {
            "section number": "3. Algorithmic Bias",
            "key information": "The main problem is to characterize the dynamics and score distributions of agents in the asymmetric phase of the Minority Game, focusing on the behavior of agents with varying strategies over time."
        },
        {
            "section number": "4. Ethical AI",
            "key information": "The authors propose that a statistical model can effectively capture the dynamics of relative strategy scores, which can inform ethical considerations in AI development by highlighting the importance of understanding agent behavior."
        },
        {
            "section number": "5. Model Interpretability",
            "key information": "This work introduces a simplified statistical model that avoids complex reformulations, providing a more transparent method for analyzing the dynamics of the game, which parallels the need for interpretability in AI models."
        },
        {
            "section number": "8. Future Directions",
            "key information": "Future improvements could involve refining the model by introducing variational parameters, suggesting potential areas for future research in enhancing model interpretability and understanding complex agent interactions."
        }
    ],
    "similarity_score": 0.5307969592411446,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-15-0337_algor/papers/Diffusion and localization of relative strategy scores in the Minority Game.json"
}