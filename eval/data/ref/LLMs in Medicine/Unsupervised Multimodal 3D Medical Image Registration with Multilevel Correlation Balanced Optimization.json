{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2409.05040",
    "title": "Unsupervised Multimodal 3D Medical Image Registration with Multilevel Correlation Balanced Optimization",
    "abstract": "Surgical navigation based on multimodal image registration has played a significant role in providing intraoperative guidance to surgeons by showing the relative position of the target area to critical anatomical structures during surgery. However, due to the differences between multimodal images and intraoperative image deformation caused by tissue displacement and removal during the surgery, effective registration of preoperative and intraoperative multimodal images faces significant challenges. To address the multimodal image registration challenges in Learn2Reg 2024, an unsupervised multimodal medical image registration method based on multilevel correlation balanced optimization (MCBO) is designed to solve these problems. First, the features of each modality are extracted based on the modality independent neighborhood descriptor, and the multimodal images is mapped to the feature space. Second, a multilevel pyramidal fusion optimization mechanism is designed to achieve global optimization and local detail complementation of the deformation field through dense correlation analysis and weight-balanced coupled convex optimization for input features at different scales. For preoperative medical images in different modalities, the alignment and stacking of valid information between different modalities is achieved by the maximum fusion between deformation fields. Our method focuses on the ReMIND2Reg task in Learn2Reg 2024, and to verify the generality of the method, we also tested it on the COMULIS3DCLEM task. Based on the results, our method achieved second place in the validation of both two tasks.",
    "bib_name": "wang2024unsupervisedmultimodal3dmedical",
    "md_text": "# Unsupervised Multimodal 3D Medical Image Registration with Multilevel Correlation Balanced Optimization\nJiazheng Wang1,2, Xiang Chen1,2, Yuxi Zhang1,2, Min Liu1,2(\ufffd), Yaonan Wang1,2, and Hang Zhang3\n1 College of Electrical and Information Engineering, Hunan University, Changsha, Hunan, China 2 National Engineering Research Center of Robot Visual Perception and Control Technology, Hunan University, Changsha, Hunan, China {wjiazheng, xiangc, hnuzyx, liu_min, yaonan}@hnu.edu.cn 3 Cornell University, USA {hz459}@cornell.edu\nAbstract. Surgical navigation based on multimodal image registration has played a significant role in providing intraoperative guidance to surgeons by showing the relative position of the target area to critical anatomical structures during surgery. However, due to the differences between multimodal images and intraoperative image deformation caused by tissue displacement and removal during the surgery, effective registration of preoperative and intraoperative multimodal images faces significant challenges. To address the multimodal image registration challenges in Learn2Reg 2024, an unsupervised multimodal medical image registration method based on multilevel correlation balanced optimization (MCBO) is designed to solve these problems. First, the features of each modality are extracted based on the modality independent neighborhood descriptor, and the multimodal images is mapped to the feature space. Second, a multilevel pyramidal fusion optimization mechanism is designed to achieve global optimization and local detail complementation of the deformation field through dense correlation analysis and weight-balanced coupled convex optimization for input features at different scales. For preoperative medical images in different modalities, the alignment and stacking of valid information between different modalities is achieved by the maximum fusion between deformation fields. Our method focuses on the ReMIND2Reg task in Learn2Reg 2024, and to verify the generality of the method, we also tested it on the COMULIS3DCLEM task. Based on the results, our method achieved second place in the validation of both two tasks.\nKeywords: Multimodal Medical Image Registration \u00b7 Convex Optim sation \u00b7 Multilevel Fusion.\nJ. Wang et al.\n# 1 Introduction\nMedical image registration has been an important topic in the field of medical image analysis, and many significant methods [1,2,3,5] have driven the development of medical image registration tasks. Deep learning-based medical image registration methods [4] usually involve long and complex learning processes, and often struggle to achieve accurate estimation for multimodal, large-deformation data and general usability for extensive tasks. The sub-challenge of Learn2Reg 2024, ReMIND2Reg, is a multimodal medical image registration task oriented to preoperative ultrasound and intraoperative MRI, which is characterized as unlabeled, large deformation, and low feature distinctness. Aiming at the above characteristics, inspired by [6,7], an unsupervised multimodal medical image registration method based on multilevel correlation balanced optimization (MCBO) has been proposed, which can quickly achieve the effective registration of multimodal medical images by only a small number of learning and optimization procedures.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e7b9/e7b9ae7a-e3b1-4fc6-88d0-511e04c83202.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 1. The overall flow of the proposed MCBO method.</div>\n# 2 Methodology\nThe proposed MCBO method is based on convexAdam [8] with a series of improvements, which include (1) Introducing a weight balancing term on the coupled convex optimization to achieve smoother deformation optimization. (2) A multilevel pyramidal fusion optimization mechanism is designed to achieve the refinement of the dense deformation field by fusing the optimization results of different scales. (3) For the multimodal preoperative medical images in the task,\nthe alignment and stacking of valid information between different modalities is achieved through the maximum fusion of deformation fields. The overall flow of the proposed MCBO method is shown in Fig. 1. The moving image and the fixed image are inputted and then the modal-independent features of the images are first obtained by Mind-SSC Feature Extractor [7]. The Mind-SSC feature extractor exploits the self-similarity of partial area in the image to extract the unique structural information of the local neighborhood, which results in a highly consistent structural representation across modalities.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/74ac/74ac6c08-35fd-4c6d-8844-562ec92df760.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 2. The fusion of different modalities.</div>\nThe acquired features are subsequently downsampled by average pooling operations with different times n (n = 1, 2, 4, 6) to obtain leveled features Fi1 to Fi4 as inputs for multilevel pyramidal fusion optimization mechanism. For the input features of levels 2 to 4, the feature matrix is directly passed through the dense correlation layer, the weight-balanced coupled convex optimization layer, and the inverse-consistency constraint layer to obtain the initial deformation fields of each level. For the first level where the input features are of the original scale, a pyramid splitting optimization strategy is used to reduce the amount of computation during the optimization procedure and at the same time to enhance the ability to align the low-contrast features. Specifically, the original feature is first divided into eight parts by equally splitting along the H, W, D dimensions of the input feature respectively, and the same three-step process as the other levels is performed for each part of the feature separately, followed by splicing the feature in the original dimensions to get the initial deformation field of the first level. To ensure the smoothness of the deformation field after splicing, an additional adam instance optimization [6] operation is performed on the output of the first level. Finally, the deformation fields at each level are summed up by multilevel weighted fusion using different weights, where the sum of the weights is 1, to obtain the final deformation field.\n# 4 J. Wang et al.\n# J. Wang et al.\nIn particular, the acquired input features are first fed into the dense correlation layer to compute the sum-of-squared-differences (SSD) cost volume and the initial optimal displacements for each voxel. The large search space allows us to make an initial capture of the displacement for each voxel, even though some voxel points may have large deformations. The output of the dense correlation layer is alternately optimized for similarity and smoothness by iterations in the weight-balanced coupled convex optimization layer, and then the iterative optimization results are averaged to achieve global regularization with weight balancing. After that, an inverse consistency constraint layer [9] is introduced to minimize the difference between the forward and backward transformations to avoid incredible deformations. For moving images with multiple modalities, the alignment and stacking of valid information between different modalities is realized by the maximum fusion of deformation fields, and the detailed steps are shown in Fig. 2.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/15fc/15fccf00-5cca-4334-82dd-7d238b529f75.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 3. Visualization results of ReMIND2Reg sub-challenge in Learn2Reg 2024.</div>\n# 3 Experiments and Results\nOur method focuses on the ReMIND2Reg sub-challenge task in Learn2Reg 2024, and to verify the generality of the method, we also tested it on the COMULIS3DCLEM sub-challenge task. The experimental setup of the method is slightly different in the two sub-challenges and the results demonstrate the effectiveness of our method.\nReMIND2Reg task. The goal of the ReMIND2Reg [10] sub-challenge is to register preoperative MRI from multiple modalities (including ceT1 and T2) and intraoperative 3D ultrasound images. For this task, we set the weights of each level in Multilevel Weighted Fusion as 0.10, 0.27, 0.27, 0.36. Meanwhile, for the\nadam instance optimization operation performed in the first level, the number of iterations is set to 15, the smooth convolution kernel is set to 5, and the rest of the parameters are referred to the original settings[8]. The experimental results are shown in Table 1. The visualization of the multimodal image registration for this task is shown in Fig. 3. In the validation phase, our method ranks in the second place.\n<div style=\"text-align: center;\">Table 1. Results of ReMIND2Reg sub-challenge in Learn2Reg 2024.</div>\nTRE(mm)\nInitial\n3.727 \u00b1 0.714\nConvexAdam-Rigid 2.773 \u00b1 1.273\nNiftyReg\n2.751 \u00b1 1.333\nours(next-gen-nn) 2.224 \u00b1 0.639\nTable 2. Results of COMULIS3DCLEM sub-challenge in Learn2Reg 2024.\nTRE(LM)\nInitial\n50.370 \u00b1 20.355\nours(next-gen-nn) 49.609 \u00b1 20.875\nCOMULIS3DCLEM task. Automated registration of multimodal microscope 3D images is a rarely addressed issue in medical image analysis. The COMULIS3DCLEM [11] sub-challenge aims to align electron microscope (EM) 3D images and light microscope (LM) 3D images of the same cellular region. Since there is no multimodal input of moving images involved in this task, the multimodal fusion part of the method is not used. Since the input image is only 32 \u00d7 256 \u00d7 256, the n of the multilevel pyramidal fusion optimization mechanism in this task is selected as 1, 2, 4, and the weight of each level in Multilevel Weighted Fusion is set as 0.33, 0.33, 0.33.The experimental results are shown in Table 2. Although the average results are not significant, for some cases, the error of our proposed method can reach 13.882, which is a very competitive registration result for this task. The visualization of the registration for this task is shown in Fig. 4. In the validation phase, our method ranks in the second place.\n# 4 Conclusion\nThe application of the proposed MCBO method to the Learn2Reg 2024 challenge shows that a multilevel optimization strategy using only a small amount of learning can quickly and accurately achieve the registration between multimodal\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ed52/ed526f4f-a594-4125-bb0d-1d7a21c27cc9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">g. 4. Visualization results of COMULIS3DCLEM sub-challenge in Learn</div>\nmedical images with large deformations. Especially for the registration of preoperative images and intraoperative images, better results can be obtained by the deep fusion of multimodal moving images. Meanwhile, the method proposed in this paper ranks second in both ReMIND2Reg and COMULIS3DCLEM subchallenges, which illustrates the generality of the method for multimodal medical image registration.\nmedical images with large deformations. Especially for the registration of preoperative images and intraoperative images, better results can be obtained by the deep fusion of multimodal moving images. Meanwhile, the method proposed in this paper ranks second in both ReMIND2Reg and COMULIS3DCLEM subchallenges, which illustrates the generality of the method for multimodal medical image registration. Acknowledgments. Thanks all the organizers of the MICCAI 2024 Learn2Reg challenge. This work was supported in part by the National Key Research and Development Program of China (grant number 2022YFE0134700), and in part by the National Natural Science Foundation of China (grant number 62221002), and in part by the Fundamental Research Funds for the Central Universities, China.\nAcknowledgments. Thanks all the organizers of the MICCAI 2024 Learn2Reg challenge. This work was supported in part by the National Key Research and Development Program of China (grant number 2022YFE0134700), and in part by the National Natural Science Foundation of China (grant number 62221002), and in part by the Fundamental Research Funds for the Central Universities, China.\n# References\n1. Balakrishnan, G., Zhao, A., Sabuncu, M. R., et al.: An Unsupervised Learning Model for Deformable Medical Image Registration. In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA pp. 92529260, doi: 10.1109/CVPR.2018.00964. (2018) 2. Zhang, H., Chen, X., Hu, R., et al.:MemWarp: Discontinuity-Preserving Cardiac Registration with Memorized Anatomical Filters. arXiv preprint arXiv:2407.08093. (2024) 3. Zhang, H., Chen, X., Wang, R., et al.:Spatially covariant image registration with text prompts. arXiv preprint arXiv:2311.15607. (2023) 4. Chen, X., Diaz-Pinto, A., Ravikumar, N., Frangi, A.F: Deep learning in medical image registration. Progress in Biomedical Engineering 3(1), 012003 (2021) 5. Chen, X., Xia, Y., Ravikumar, N., Frangi, A.F: A deep discontinuity-preserving image registration network. In: Medical Image Computing and Computer Assisted Intervention\u2013MICCAI 2021: 24th International Conference, Strasbourg, France, September 27\u2013October 1, 2021, Proceedings, Part IV 24, pp. 46-55. (2021) 6. Siebert, H., Hansen, L., Heinrich, M.P: Fast 3D Registration with Accurate Optimisation and Little Learning for Learn2Reg 2021. In:Aubreville, M., Zimmerer, D., Heinrich, M. (eds) Biomedical Image Registration, Domain Generalisation and Out-of-Distribution Analysis. MICCAI 2021. Lecture Notes in Computer Science, vol 13166. Springer, Cham. (2022) https://doi.org/10.1007/978-3-030-97281-3 25\n1. Balakrishnan, G., Zhao, A., Sabuncu, M. R., et al.: An Unsupervised Learning Model for Deformable Medical Image Registration. In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA pp. 92529260, doi: 10.1109/CVPR.2018.00964. (2018) 2. Zhang, H., Chen, X., Hu, R., et al.:MemWarp: Discontinuity-Preserving Cardiac Registration with Memorized Anatomical Filters. arXiv preprint arXiv:2407.08093. (2024) 3. Zhang, H., Chen, X., Wang, R., et al.:Spatially covariant image registration with text prompts. arXiv preprint arXiv:2311.15607. (2023) 4. Chen, X., Diaz-Pinto, A., Ravikumar, N., Frangi, A.F: Deep learning in medical image registration. Progress in Biomedical Engineering 3(1), 012003 (2021) 5. Chen, X., Xia, Y., Ravikumar, N., Frangi, A.F: A deep discontinuity-preserving image registration network. In: Medical Image Computing and Computer Assisted Intervention\u2013MICCAI 2021: 24th International Conference, Strasbourg, France, September 27\u2013October 1, 2021, Proceedings, Part IV 24, pp. 46-55. (2021) 6. Siebert, H., Hansen, L., Heinrich, M.P: Fast 3D Registration with Accurate Optimisation and Little Learning for Learn2Reg 2021. In:Aubreville, M., Zimmerer, D., Heinrich, M. (eds) Biomedical Image Registration, Domain Generalisation and Out-of-Distribution Analysis. MICCAI 2021. Lecture Notes in Computer Science, vol 13166. Springer, Cham. (2022) https://doi.org/10.1007/978-3-030-97281-3 25\n7. Heinrich, M., Jenkinson, M.: Mind: Modality Independent Neighbourhood Descriptor for Multi-Modal Deformable Registration. Medical image analysis 16(7), 1423-35 (2012) 8. ConvexAdam, https://github.com/multimodallearning/convexAdam/tree/main 9. Heinrich, M.P., Papiez, B.W., Schnabel, J.A., Handels, H.: Non-parametric discrete registration with convex optimisation. In: Ourselin, S., Modat, M. (eds.) WBIR 2014. LNCS, vol. 8545, pp. 51\u201361. Springer, Cham (2014). https://doi.org/10.1007/ 978-3-319-08554-8 6 10. Juvekar, P., Dorent, R., K\u00f6gl, F., et al.: The Brain Resection Multimodal Imaging Database (ReMIND). Nature Scientific Data 11, 494 (2024). 11. Daniel K., Matou\u0161 E., Marie-Charlotte D., et al.: CLEM-Reg: An automated point cloud based registration algorithm for correlative light and volume electron microscopy. bioRxiv 2023.05.11.540445. (2023) doi: https://doi.org/10.1101/2023.05.11.540445\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the challenges in multimodal medical image registration, particularly the difficulties arising from differences between modalities and intraoperative image deformations. Previous methods have struggled with these issues, necessitating a new approach to enhance accuracy and efficiency in surgical navigation.",
        "problem": {
            "definition": "The problem focuses on the registration of preoperative and intraoperative multimodal images, which is characterized by large deformations and low feature distinctness, making accurate alignment challenging.",
            "key obstacle": "The main difficulty lies in the significant deformations of images during surgery and the inherent differences in features between multimodal images, which existing methods fail to address effectively."
        },
        "idea": {
            "intuition": "The proposed method is inspired by the need for a quick and efficient registration process that can handle large deformations and multimodal data without extensive learning.",
            "opinion": "The method introduces an unsupervised approach based on multilevel correlation balanced optimization (MCBO), which aims to optimize the registration process with minimal learning steps.",
            "innovation": "The key innovation of this method is its multilevel pyramidal fusion optimization mechanism, which allows for both global optimization and local detail enhancement, differentiating it from traditional registration methods."
        },
        "method": {
            "method name": "Multilevel Correlation Balanced Optimization",
            "method abbreviation": "MCBO",
            "method definition": "MCBO is a method designed for unsupervised multimodal medical image registration that leverages a multilevel optimization strategy to achieve accurate alignment of images.",
            "method description": "The core of MCBO involves extracting modality-independent features and optimizing the deformation fields through a series of coupled convex optimizations across multiple levels.",
            "method steps": [
                "Extract features from each modality using the Mind-SSC feature extractor.",
                "Downsample the features to create leveled inputs for optimization.",
                "Apply dense correlation analysis and weight-balanced coupled convex optimization to obtain initial deformation fields.",
                "Use pyramid splitting optimization for the original scale features to enhance low-contrast feature alignment.",
                "Sum the deformation fields from each level using multilevel weighted fusion to obtain the final deformation field."
            ],
            "principle": "The method's effectiveness is rooted in its ability to perform dense correlation analysis and optimization across multiple scales, allowing for robust handling of large deformations and multimodal feature integration."
        },
        "experiments": {
            "evaluation setting": "The method was evaluated on the ReMIND2Reg and COMULIS3DCLEM sub-challenges of Learn2Reg 2024, using preoperative MRI and intraoperative ultrasound images for the former and electron and light microscope images for the latter.",
            "evaluation method": "Performance was assessed by comparing the proposed method against baseline methods, measuring registration accuracy through Target Registration Error (TRE) metrics."
        },
        "conclusion": "The MCBO method demonstrated its capability to achieve rapid and accurate multimodal medical image registration, ranking second in both evaluated tasks, thereby highlighting its effectiveness and generalizability in addressing the challenges of large deformations in medical imaging.",
        "discussion": {
            "advantage": "The main advantages of the proposed approach include its unsupervised nature, minimal learning requirements, and the ability to handle large deformations effectively, making it suitable for real-time surgical applications.",
            "limitation": "One limitation is that while the method performs well in the tested scenarios, its effectiveness in more complex or varied imaging conditions remains to be fully explored.",
            "future work": "Future research could focus on enhancing the method's robustness across different imaging modalities and conditions, as well as exploring the integration of additional features for improved registration accuracy."
        },
        "other info": {
            "acknowledgments": "This work was supported by the National Key Research and Development Program of China, the National Natural Science Foundation of China, and the Fundamental Research Funds for the Central Universities.",
            "task focus": "The method specifically targets the ReMIND2Reg task in Learn2Reg 2024, with additional testing on COMULIS3DCLEM to validate its generality."
        }
    },
    "mount_outline": [
        {
            "section number": "6",
            "key information": "The proposed method is inspired by the need for a quick and efficient registration process that can handle large deformations and multimodal data without extensive learning."
        },
        {
            "section number": "6.2",
            "key information": "One limitation is that while the method performs well in the tested scenarios, its effectiveness in more complex or varied imaging conditions remains to be fully explored."
        },
        {
            "section number": "7.1",
            "key information": "Future research could focus on enhancing the method's robustness across different imaging modalities and conditions, as well as exploring the integration of additional features for improved registration accuracy."
        },
        {
            "section number": "4.1",
            "key information": "The core of MCBO involves extracting modality-independent features and optimizing the deformation fields through a series of coupled convex optimizations across multiple levels."
        },
        {
            "section number": "5.3",
            "key information": "The MCBO method demonstrated its capability to achieve rapid and accurate multimodal medical image registration, ranking second in both evaluated tasks."
        }
    ],
    "similarity_score": 0.5310092740789735,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-12-0928_,arti/papers/Unsupervised Multimodal 3D Medical Image Registration with Multilevel Correlation Balanced Optimization.json"
}