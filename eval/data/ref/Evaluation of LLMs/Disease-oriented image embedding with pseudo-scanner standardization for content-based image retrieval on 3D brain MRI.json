{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2108.06518",
    "title": "Disease-oriented image embedding with pseudo-scanner standardization for content-based image retrieval on 3D brain MRI",
    "abstract": "To build a robust and practical content-based image retrieval (CBIR) system that is applicable to a clinical brain MRI database, we propose a new framework -- Disease-oriented image embedding with pseudo-scanner standardization (DI-PSS) -- that consists of two core techniques, data harmonization and a dimension reduction algorithm. Our DI-PSS uses skull stripping and CycleGAN-based image transformations that map to a standard brain followed by transformation into a brain image taken with a given reference scanner. Then, our 3D convolutioinal autoencoders (3D-CAE) with deep metric learning acquires a low-dimensional embedding that better reflects the characteristics of the disease. The effectiveness of our proposed framework was tested on the T1-weighted MRIs selected from the Alzheimer's Disease Neuroimaging Initiative and the Parkinson's Progression Markers Initiative. We confirmed that our PSS greatly reduced the variability of low-dimensional embeddings caused by different scanner and datasets. Compared with the baseline condition, our PSS reduced the variability in the distance from Alzheimer's disease (AD) to clinically normal (CN) and Parkinson disease (PD) cases by 15.8-22.6% and 18.0-29.9%, respectively. These properties allow DI-PSS to generate lower dimensional representations that are more amenable to disease classification. In AD and CN classification experiments based on spectral clustering, PSS improved the average accuracy and macro-F1 by 6.2% and 10.7%, respectively. Given the potential of the DI-PSS for harmonizing images scanned by MRI scanners that were not used to scan the training data, we expect that the DI-PSS is suitable for application to a large number of legacy MRIs scanned in heterogeneous environments.",
    "bib_name": "arai2021diseaseorientedimageembeddingpseudoscanner",
    "md_text": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000. Digital Object Identifier 10.1109/ACCESS.2021.DOI\n# Disease-oriented image embedding wit pseudo-scanner standardization for content-based image retrieval on 3D brain MRI 1\n# Disease-oriented image embedding with pseudo-scanner standardization for content-based image retrieval on 3D\nHAYATO ARAI1, YUTO ONGA1, KUMPEI IKUTA1, YUSUKE CHAYAMA1, HITOSHI IYATOMI1 (MEMBER, IEEE), AND KENICHI OISHI 2 for the Alzheimer\u2019s Disease Neuroimaging Initiativ and the Parkinson\u2019s Progression Markers Initiative. 1Department of Applied Informatics, Graduate School of Science and Engineering, Hosei University, Tokyo, 184-8584 Japan (e-mail: iyatomi@hosei.ac.jp) 2Department of Radiology and Radiological Science, Johns Hopkins University School of Medicine, Baltimore, MD 21205 USA (email:koishi2@jhmi.edu) Corresponding author: Hitoshi Iyatomi (e-mail: iyatomi@hosei.ac.jp). Data used in preparation of this article were obtained from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf V]  14 Aug 20\nData used in preparation of this article were obtained from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf V]  14\nABSTRACT To build a robust and practical content-based image retrieval (CBIR) system that is applicable to a clinical brain MRI database, we propose a new framework \u2013 Disease-oriented image embedding with pseudo-scanner standardization (DI-PSS) \u2013 that consists of two core techniques, data harmonization and a dimension reduction algorithm. Our DI-PSS uses skull stripping and CycleGAN-based image transformations that map to a standard brain followed by transformation into a brain image taken with a given reference scanner. Then, our 3D convolutioinal autoencoders (3D-CAE) with deep metric learning acquires a low-dimensional embedding that better reflects the characteristics of the disease. The effectiveness of our proposed framework was tested on the T1-weighted MRIs selected from the Alzheimer\u2019s Disease Neuroimaging Initiative and the Parkinson\u2019s Progression Markers Initiative. We confirmed that our PSS greatly reduced the variability of low-dimensional embeddings caused by different scanner and datasets. Compared with the baseline condition, our PSS reduced the variability in the distance from Alzheimer\u2019s disease (AD) to clinically normal (CN) and Parkinson disease (PD) cases by 15.8\u201322.6% and 18.0\u201329.9%, respectively. These properties allow DI-PSS to generate lower dimensional representations that are more amenable to disease classification. In AD and CN classification experiments based on spectral clustering, PSS improved the average accuracy and macro-F1 by 6.2% and 10.7%, respectively. Given the potential of the DI-PSS for harmonizing images scanned by MRI scanners that were not used to scan the training data, we expect that the DI-PSS is suitable for application to a large number of legacy MRIs scanned in heterogeneous environments. arXiv:2108.06518v1  [cs\nINDEX TERMS ADNI, CBIR, convolutional auto encoders, CycleGAN, Data harmonization, data standardization, metric learning, MRI, PPMI\n# I. INTRODUCTION\nI N the new era of Open Science [1], data sharing has become increasingly crucial for efficient and fair development of science and industry. Especially in the field of medical image science, various datasets have been released and used for the development of new methods and benchmarks. There have been attempts to create publicly open databases\nVOLUME 4, 2016\nconsisting of medical images, demographic data, and clinical information, such as ADNI, AIBL, PPMI, 4RTN, PING, ABCD and UK BioBank. In the near future, clinical images acquired with medical indications will become available for research use.\nBig data, consisting of large amounts of brain magnetic resonance (MR) images and corresponding medical records,\ncould provide new evidence for the diagnosis and treatment of various diseases. Clearly, search technology is essential for the practical and effective use of such big data. Currently, text-based searching is widely used for the retrieval of brain MR images. However, since this approach requires skills and experience during retrieval and data registration, there is a strong demand from the field to realize content-based image retrieval (CBIR) [2]. To build a CBIR system that is feasible for brain MR imaging (MRI) databases, obtaining an appropriate and robust low-dimensional representation of the original MR images that reflects the characteristics of the disease in focus is extremely important. Various methods have been proposed, including those based on classical feature description [3]\u2013 [5], anatomical phenotypes [6], and deep learning techniques [7]\u2013[9]. The latter two techniques [8], [9] acquire similar low-dimensional representations for similar disease data by introducing the idea of distance metric learning [10] [11]. Their low-dimensional representations adequately capture disease characteristics rather than individual variations seen on gyrification patterns in the brain. However, the application of these methods to a heterogeneous database containing MRIs from various scanners and scan protocols is hampered by the scanner or protocol bias, which is not negligible. In brain MRI, such non-biological experimental variations (i.e., magnetic field strength, scanner manufacturer, reconstruction method) resulting from differences in scanner characteristics and protocols can affect the images in various ways and have a significant impact on the subsequent process [9], [12]\u2013[16]. Wachinger et al. [16] analyzed 35,320 MR images from 17 open datasets and performed the \u2019Name That Dataset\u2019 test, that is guessing which dataset it is based on the images alone. They reported a prediction accuracy of 71.5% based only on volume and thickness information from 70% of the training data. This is evidence that there are clear features left among datasets. Removing those variabilities is essential in multi-site and long-term studies and for building a robust CBIR system. There has been an increase in recent research on data harmonization, i.e., eliminating or reducing variation that is not intrinsically related to the brain\u2019s biological features. Perhaps the most straightforward image harmonization approach is to reduce the variations in the intensity profile [17], [18]. In the methods in both [17] and [18], correction of the luminance distribution for each sub-region reduces the variability of the underlying statistics between images, whereas histogram equalization reduces the variability of neuroradiological features. However, these methods are limited to approximating rudimentary statistics that can be calculated from images, and they are based on the assumption that the intensity histogram is similar among images. This assumption is invalid when images that contain pathological findings that affect intensity profile are included. While some improvement in unintended image variability can be expected, the effect on practical tests that utilize data from multiple sites is unknown.\nIn the field of genomics, Johnson et al. [19] proposed an empirical Bayes-based correction method to reduce batch effects, which are non-biological differences originating from each batch of micro-array experiments obtained from multiple tests. This effective statistical bias reduction method is now called ComBat, and it has recently been published as a tool for MRI harmonization [20]. This tool has been applied to several studies [14], [16], [21], [22]. The ComBatbased methods standardize each cortical region based on an additive and use multiplicative linear transform to compensate for variability. Some limitations of these models have been pointed out, such as the following: (i) they might be insufficient for complex multi-site and area-level mapping, (ii) the assumption of certain prior probabilities (Gaussian or inverse gamma) is not always appropriate, and (iii) they are susceptible to outliers [23]. Recently, advancements in machine learning techniques [23]\u2013[26] have provided practical solutions for MR image harmonization. DeepHarmony [24] uses a fully convolutional U-net to perform the harmonization of scanners. The researchers used an MRI dataset of multiple sclerosis patients in a longitudinal clinical setting to evaluate the effect of protocol changes on atrophy measures in a clinical study. As a result, DeepHarmony confirmed a significant improvement in the consistency of volume quantification across scanning protocols. This study was practical in that it aimed to directly standardize MR images using deep learning to achieve longterm, multi-institutional quantitative diagnosis. However, this model requires \u201dtraveling head\u201d (participants are scanned using multiple MRI scanners) to train the model. Zhao et al. [23] attempted to standardize a group of MR images of infants taken at multiple sites into a reference group using CycleGAN [27], which has a U-net structure in the generator. The experiment validated the evaluation of cortical thickness with several indices (i.e., ROI (region-of-interest)-base, distribution of low-dimensional representations). They argued that the retention of the patient\u2019s age group was superior to ComBat in evaluating group difference. Moyer et al. [25] proposed a sophisticated training technique to reconstruct bias-free MR images by acquiring a lowdimensional representation independent of the scanner and condition. Their method is an hourglass-type unsupervised learning model based on variational autoencoders (VAE) with an encoder\u2013decoder configuration. The input x and output x\u2032 are the same MR images, and their low-dimensional representation is z (i.e., x \u2192z \u2192x\u2032). The model is trained with the constraint that z and site- and scanner-specific information s are orthogonal (actually relaxed), such that the s in z is eliminated. They demonstrated the advantages of their method on diffusion MRI, but their technological framework is applicable to other modalities. Dinsdale et al. [26] also proposed a data harmonization method based on the idea of domain adaptation [28]. Their model uses adversarial learning, where the feature extractor consisting of convolutional neural networks (CNN) following the input is branched into a fully connected net for the\noriginal task (e.g., segmentation and classification) and other fully connected nets for domain discriminators (e.g., scanner type or site prediction) to make the domain unknown while improving the accuracy of the original task. They have confirmed its effectiveness in age estimation and segmentation tasks. The methods developed by Moyer et al. and Dinsdale et al. aim to generate a low-dimensional representation with \u201dno site information\u201d, and they are highly practical and generalizable techniques for data harmonization. Nevertheless, for CBIR, a method that is applicable for a large number of legacy images is necessary. Here, it is not realistic to collect images from each site and train the model to harmonize them. Practically, a method that can convert heterogeneous images in terms of variations in scanners and scan parameters into images scanned by a given pseudo-\u201dstandard\u201d environment by applying a learned model is highly desired. In this paper, we propose a novel framework called disease-oriented image embedding with pseudo-scanner standardization (DI-PSS) to obtain a low-dimensional representation of MR images for practical CBIR implementation. The PSS, the key element of the proposal, corrects the bias caused by different scanning environments and converts the images so that it is as if the same equipment had scanned them. Our experiments on ADNI and PPMI datasets consisting of MR images captured by three manufacturers\u2019 MRI systems confirmed that the proposed DI-PSS plays an important role in realizing CBIR. The highlights of this paper\u2019s contribution are as follows: \u2022 To the best of the authors\u2019 knowledge, this is the first study of the acquisition and quantitative evaluation of an effective low-dimensional representation of brain MR images for CBIR, including scanner harmonization. \u2022 Our DI-PSS framework reduces undesirable differences caused by differences in scanning environments (e.g., scanner, protocol, dataset) by converting MR images to images taken on a predefined pseudo-standard scanner, and a deep network using a metric learning acquires a low-dimensional representation that better represents the characteristics of the disease. \u2022 DI-PSS provides appropriately good low-dimensional representations for images from other vendors\u2019 scanners, diseases, and datasets that are not used for learning image harmonization. This is an important feature for the practical and robust CBIR, which applies to a large amount of legacy MRIs scanned at heterogeneous environments.\n# II. CLARIFICATION OF THE ISSUES ADDRESSED IN\n# II. CLARIFICATION OF THE ISSUES ADDRESSED IN THIS PAPER\nWe begin by presenting the issues to be solved in this paper. As mentioned above, to realize CBIR for brain MRI, Onga et al. proposed a new technique called disease-oriented data concentration with metric learning (DDCML), which acquires low-dimensional representations of 3D brain MR\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1ec8/1ec82c87-dfa3-4736-a270-3065e97716b7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 1: Plots of low-dimensional representations of 3D MRI obtained from different datasets. The impact of different scanners (CN\u21d4Control; they are medically equivalent) is greater than the impact of the disease (AD\u21d4CN).</div>\nimages that are focused on disease features rather than the features of the subject\u2019s brain shape [9]. DDCML is composed of 3D convolutional autoencoders (3D-CAE) effectively combined with deep metric learning. Thanks to its metric learning, DDCML could acquire reasonable lowdimensional representations for unlearned diseases according to their severity, demonstrating the feasibility of CBIR for brain MR images. However, we found that such representations are highly sensitive to differences in datasets (i.e., differences in imaging environments, scanners, protocols, etc.), which is a serious challenge for CBIR. Figure 1 shows the low-dimensional distribution obtained by DDCML and visualized by t-SNE [29]. Here, DDCML was trained on Alzheimer\u2019s disease (AD) and healthy cases (clinically normal; CN) in the ADNI2 dataset and evaluated ADNI2 cases not used for training and healthy control (Control \u2013 equivalent to CN) and Parkinson\u2019s disease (PD) cases in the untrained PPMI dataset. From the perspective of CBIR, it is desirable to obtain similar low-dimensional representations for CN and Control. However, it can be confirmed that the obtained low-dimensional representations are more affected by the differences in the environment (dataset) than by the disease. As mentioned above, differences in imaging environments, including scanners, are a major problem in multi-center and time series analysis, and inconsistent lowdimensional representations because of such differences in datasets are a fatal problem in CBIR implementation. The purpose of this paper is reducing these differences and to obtain a low-dimensional representation that better captures the characteristics of the disease and is suitable for appropriate CBIR.\n# B. OUR DATA HARMONIZATION STRATEGY FOR\n# B. OUR DATA HARMONIZATION STRATEGY FOR REALIZING CBIR\nIn studies dealing with multi-site and long-term data, it is undoubtedly important to reduce non-biological bias origi-\nnating from differences among sites and datasets. Since the methods of Moyer et. al. [25] and Dinsdale et al. [26] are theoretical and straightforward learning method that utilizes images of the target site to achieve data harmonization, their robustness to unexpected input (i.e. from another site or dataset) is questionable. Therefore, in principle, the images of all target sites (scanners, protocols) need to be learned in advance. Since CBIR requires more consideration of the use of images taken in the past, the number of environments that need to be addressed can be larger than for general data harmonization. It will be more difficult to implement a harmonization method that learns all the data of multiple environments in advance. Therefore, in contrast to their approaches, we aim to achieve data harmonization by converting images taken in each environment into images that can be regarded as having been taken in one predetermined \u201dstandard\u201d environment (e.g., the scanner currently used primarily at each site). However, in addition to the problems described above, it is practically impossible to build an image converter for each environment. With this background, we have developed a framework that combines CycleGAN, which realizes robust image transformation, with deep metric learning to achieve a certain degree of harmonization even for images in untrained environments. In this paper, we validate the feasibility of our framework, which converts MR images captured in various environments into pseudo standard environment images using only one type of image converter.\n# III. DISEASE-ORIENTED IMAGE EMBEDDING WITH PSEUDO-SCANNER STANDARDIZATION (DI-PSS)\nThe aim of this study is to obtain a low-dimensional embedding of brain MRI that is independent of the MRI scanner and individual characteristics but dependent on the pathological features of the brain, to realize a practical CBIR system for brain MRI. To accomplish this, we propose a DI-PSS framework, which is composed of the three following components: (1) pre-process, (2) PSS, and (3) embedding acquisition.\n# A. THE PRE-PROCESSING COMPONENT (SKULL STRIPPING WITH GEOMETRY AND INTENSITY\nThe pre-processing component performs the necessary preprocessing for future image scanner standardization processing and low-dimensional embedding acquisition processing. Specifically, for all 3D brain MR image data, skull stripping was performed using a multi-atlas label-fusion algorithm implemented in the MRICloud [30]. The skull-stripped images were linearly aligned to the JHU-MNI space using a 12-parameters affine transformation function implemented in the MRICloud, resulting in aligned brain images. This feature makes a significant contribution to the realization of the proposed PSS in the next stage. It is important to note here that since brain volume information is the feature that contributes most to the prediction of the dataset [16], the alignment to a standard brain with this skull stripping\ntechnique should also contribute to the harmonization of the data. In addition, because the intensity and contrast of brain MR images are arbitrarily determined, there is a large inter-image variation. In brain MR image processing using machine learning, the variation in the average intensity confounds the results. Therefore, we standardized the intensity so that the average intensity value of each case was within mean \u00b5 = 18 and margin \u03f5 = 1.0 by performing an iterative gamma correction process, as in previous studies [31] [9].\n1) The concept of PSS The proposed PSS is an image conversion scheme that converts a given raw MR image into a synthesized image that looks like an MR image scanned by a standard scanner and a protocol. Since there are numerous combinations of scanners and scan parameters, building scanner- and parameterspecific converters is not practical. Therefore, in our PSS scheme, we only construct a 1:1 image conversion model (i.e., PSS network) that converts images from a particular scanner Y to a standard scanner X. That is, a particular PSS network is used to convert images captured by other scanners (Z1, Z2, \u00b7 \u00b7 \u00b7 ) as well. This strategy is in anticipation of the generalizability of the PSS network, backed by advanced deep learning techniques. In this paper, we evaluate the robustness of our image transformations provided by PSS on MR images taken by other vendors\u2019 scanners and on images in different datasets. Figure 2 gives an overview of our PSS network that realizes the PSS. The PSS network makes effective use of CycleGAN [27], which has achieved excellent results in 1:1 image transformation. Here, training of CycleGAN generally requires a lot of training data, especially in the case of 3D data, because the degree of freedom of the model parameters is large. However, it is difficult to collect such a large amount of supervised labeled 3D MRI data to keep up with the increase. Since the position of any given slice is almost the same in our setting thanks to MRICloud in the skull stripping process, a 3D image can be treated as a set of 2D images containing position information. With these advantages, our PSS suppressed the problems an overwhelmingly insufficient amount of training data and the high degree of freedom of the transformation network. In sum, arbitrary slices are cut out from the input 3D image and converted to slices corresponding to the same position in the 3D image as the target domain using the PSS network based on common (2D) CycleGAN. Note that the PSS process is performed using the trained generator GX.\n2) Implementation of the PSS network The structure of the PSS network that realizes the proposed PSS is explained according to the CycleGAN syntax, with images captured by a standard scanner as domain X and images captured by a certain different scanner as domain Y . Generator GY transforms (generates) an image y\u2032 = GY (x) with the features of domain Y from an image x of the original\n2) Implementation of the PSS network The structure of the PSS network that realizes the proposed PSS is explained according to the CycleGAN syntax, with images captured by a standard scanner as domain X and images captured by a certain different scanner as domain Y . Generator GY transforms (generates) an image y\u2032 = GY (x) with the features of domain Y from an image x of the original\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/1482/14824525-c207-42c0-9a6c-5c9953304812.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 2: Overview of pseudo-scanner standardization (PSS) network. Our PSS network is based on CycleGAN, and PSS is performed with trained generator GX.</div>\ndomain X. Discriminator DY determines the authenticity of the real image y belonging to domain Y or the generated y\u2032 = GY (x). Similarly, the conversion from domain Y to domain X is performed by generator GY , and discriminator DX judges the authenticity of the image. The goal of this model is to learn maps of two domains X and Y given as training data. Note here again that we use the trained module GX (maps Y to X) as an image converter. The training of the model proceeds by repeating the transformation of the training data sample xi \u2208X and the training data sample yj \u2208Y . The overall objective function of the PSS network, LP SS to be minimized, consists of the three following loss components: adversarial loss (LGAN), cycle consistency loss (Leye), and identity mapping loss (Lidentity). This is expressed as follows:\n(1)\nThe adversarial loss (LGAN) is defined based on the competition between the generator, which tries to produce the desired other domain image, and the discriminator, which sees through the fake generated image; this minimization implies a refinement of both. From the point of view of image transformation, the minimization of this loss means that the probability distribution generated by the generator is closer to the probability distribution of the counterpart domain, which means that a higher quality image can be obtained. This loss is defined in both directions, X \u2192Y and Y \u2192X, and these are expressed in order as follows:\n(2)\nLGAN(GX, DX) =Ex\u223cpdata(x)[(DX(x) \u22121)2] +Ey\u223cpdata(y)[(DX(GX(y))2].\n(3)\nThe cycle consistency loss (Leye) is a constraint to guarantee that mutual transformation is possible by cycling two generators:\n(4)\nFinally, the identity mapping loss (Lidentity) is a constraint to maintain the original image features without performing any transformation when the image of the destination domain is input:\nLidentity(GX, GY ) =Ex\u223cpdata(x)||GX(x) \u2212x||1 +Ey\u223cpdata(y)||GY (y) \u2212y||1\n(5)\nIt has been confirmed that the introduction of this constraint can suppress the learning of features that are not important in either domain, such as unneeded tints. Here, \u03bb1 and \u03bb2 are hyper-parameters and we set \u03bb1 = 10.0 and \u03bb2 = 0.5 as in the original setting.\n3) The Embedding acquisition component In the embedding acquisition component, the lowdimensional embedding of 3D brain MRI images is obtained by our embedding network after the PSS process. Our embedding network is a 3D-CAE model consisting of encoders and decoders with distance metric learning, referring to Onga et al.\u2019s DDCML [9]. Distance metric learning is a learning technique that reduces the Euclidean distance between feature representations of the same label and increases the distance between feature representations of different labels. Thanks to the introduction of metric learning, 3D-CAE has been found to yield embedding that is more focused on disease features. According to Hoffer\u2019s criteria [11], the distance distribution in the low-dimensional embedding space for input x for\nclass i (i \u22081, \u00b7 \u00b7 \u00b7 c; where c is the number of types of disease labels in the dataset) is calculated by\n(6)\n\ufffd Here, xi (i \u22081, \u00b7 \u00b7 \u00b7 , c) is randomly sampled data from each class i, and f denotes the operation of the encoder (i.e., encoder part of the 3D-CAE in our implementation). This probability can be thought of as the probability that the data x belong to each class i. The loss function Ldist is calculated by the cross-entropy between the c-dimensional vector P described above and the c-dimensional one-hot vector I(x) with bits of the class to which x belongs as\n(7)\nHere, H(I(x), P (x; x1, \u00b7 \u00b7 \u00b7 , xc)) takes a small value when the probability that the element firing in I(x) belongs to the class it represents is high, whereas it takes a large value when the probability is low. Thus, Ldist aims at the distribution of the sampled data at locations closer to the same class and farther from the different classes on the low-dimensional feature space. Finally, the objective function LCAE of our low-dimensional embedding acquisition network consisting of 3D-CAE and metric learning is finally expressed by the following equation:\nHere, LRMSE is the pixel-wise root mean square error normalized by image size in CAE image reconstruction. Furthermore, \u03b1 is a hyper-parameter set to 1/3 based on the results of preliminary experiments.\nIn CBIR, cases of the same disease should be able to acquire similar low-dimensional representations, regardless of the individual, scanner, or protocol. We investigated the effectiveness of the proposed DI-PSS by quantitatively evaluating how PSS changes the distribution of embeddings within and between data groups (i.e., combination of scanner type and disease). In addition, we compared the clustering performance of the obtained embeddings against diseases with and without PSS.\n# A. DATASET\nIn this experiment, we used the ADNI2 and PPMI datasets, in which the vendor information of the scanners (Siemens [SI], GE Medical Systems [GE], Philips Medical Systems [PH]) was recorded along with the disease information. Statistics of those datasets used in the experiment are shown in Table 1. We used Alzheimer\u2019s disease (ADNI-AD or AD) and clinically normal cases (ADNI-CN) from ADNI2 dataset with vendor information. From the PPMI dataset, we used two types of labeled images, Parkinson\u2019s disease (PD) and Control. We did not utilize the scanner information for this\n<div style=\"text-align: center;\">TABLE 1: Dataset used in our study</div>\ndataset\nvendor\nlabel\n#used\n#patients\n#total\nADNI\nCN\nSiemens\nCN_SI\n92\n103\n439\nGE\nCN_GE\n93\n101\n494\nPhilips\nCN_PH\n27\n27\n119\nAD\nSiemens\nAD_SI\n80\n84\n254\nGE\nAD_GE\n80\n92\n302\nPhilips\nAD_PH\n20\n24\n73\nPPMI\nn/a\nControl\n75\n75\n114\nPD\n149\n149\n338\nADNI-CN and Control can be considered medically equivalent.\nADNI-CN and Control can be considered medically equivalent. There are no PD-related anatomical features observable on T1-weighted MRI.\ndataset in evaluating the versatility of the proposed method. Note that ADNI-CN and Control can be considered medically equivalent. Furthermore, PD is known to show little or no difference in MRI from healthy cases [32] [33]. The ADNI and PPMI are longitudinal studies that include multiple time points, and the datasets contain multiple scans for each participant. To avoid duplication, one MRI was randomly selected from each participant. The MRICloud (https: //mricloud.org/) was used to skull strip the T1-weighted MRIs and affine transform to the JHU-MNI atlas [34]. A neurologist with more than 20 years of experience in brain MRI research performed the quality control of the MRIs and removed MRIs that the MRICloud did not appropriately pre-process. Due to the neural network model used in the experiments, the skull-stripped and affine-transformed brain MR images were converted to 160\u00d7160\u00d7192 pixels after cropping the background area. Training and evaluation of the PSS network and embedding network were performed using five-fold cross validation. In the evaluation experiments described below\u201e the evaluation data of each fold is not included in the training data for either the PSS network or the embedding network. Note that even skilled and experienced neuroradiologists cannot separate PD from CN or Control by visual inspection of the T1-weighted images. Therefore, we did not expect these two conditions to be separable by unsupervised clustering methods even after applying the DIPSS.\nB. DETAIL OF THE PSS NETWORK AND ITS TRAINING Figures 3a and 3b show the architecture of the generator (GX, GY ) and the discriminator (DX, DY ), respectively of the PSS network. They are basically the same as the original CycleGAN for 2D images. Since PSS is to reduce the bias caused by variations in scanners and scan parameters, the disease-related anatomical variations should be minimized in the training images. Therefore, we used only ADNI-CN cases, in which disease features do not appear in the brain structure, to train the PSS network. In this experiment, we chose the Siemens scanner as the standard scanner because it has largest market share, and we chose the GE scanner as the specific vendor of image conversion source. In other words, our PSS network is designed to convert CN images taken by GE scanners from the ADNI2-dataset (CN_GE) to\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/7e89/7e89e61a-a648-4199-b48a-3b0542a2c609.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) Generator</div>\n<div style=\"text-align: center;\">FIGURE 3: Architecture of (a) Generators (GX, GY ) and (b) Discriminators (DX, DY ) in the PSS network. (a) kernel size (f\u00d7f), stride size (s), padding size (p), \u00d7 # of kernel + instance norm + ReLU* (b) convA : kernel size (f\u00d7f), stride size (s), padding size (p), \u00d7 # of kernel + LeakyReLU convB : kernel size (f\u00d7f), stride size (s), padding size (p), \u00d7 # of kernel + instanceNorm + LeakyReLU convC : kernel size (f\u00d7f), stride size (s), padding size (p), \u00d7 # of kernel FC : fully connected layer (400\u21921)</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/641b/641bfa76-4804-4597-92b4-f09508b1004f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 4: Architecture of embedding network. conv : kernel 3\u00d73, stride size=1, padding size=1, \u00d7 (# of kernel) + ReLU deconv : kernel 3\u00d73, stride size=1, padding size=1, \u00d7 (# of kernel) + ReLU average pooling, up-sampling (bi-linear interpolation): 2\u00d72\u00d72:1.</div>\nsynthetic images similar to those scanned by the Siemens scanners (CN_SI). We evaluated the applicability of the PSS to the diseased brain MRIs (AD and PD), as well as the generalizability to the non-GE scanners (see Section IV.D). In PSS network, we used coronal images for the training. The number of training images of each fold in the PSS network is (93+92)\u00d74/5 (5-fold CV)\u00d7192 (slices).\n# C. DETAIL OF THE EMBEDDING NETWORK AND ITS TRAINING\nFigure 4 shows the architecture of our 3D-CAE-based embedding network. Our embedding network embeds each 3D brain MR image into 150-dimensional vectors. The size of the MRIs handled by the embedding network is halved at each side, as in DDCML [9], to improve the learning efficiency. Note that the compression ratio of our embedding network is (80\u00d780\u00d796):150 = 4,096:1. The embedding network was trained and evaluated using ADNI2 and PPMI datasets with the five-fold cross-validation strategy. As mentioned above, PD and CN cannot even be diagnosed from images by skilled neuroradiologists, so for training 3D-CAE to obtain low-dimensional representations, two classes of metric learning are used so that the representations of AD and (CN + Control) are separated. The lowdimensional representations of brain MR images are acquired by five-fold cross validation of 3D-CAE. In addition to AD, CN, and Control in each test fold, the low-dimensional\n<div style=\"text-align: center;\">(b) Discriminator</div>\nrepresentation of PD, which was not included in the training, is analyzed to quantitatively verify the effectiveness of the proposed DI-PSS evaluation. D. EVALUATION OF THE PSS To evaluate the effectiveness of the proposed DI-PSS framework, we evaluate the three following elements: 1) Changes in MR images 2) Distribution of the embedding. 3) Clustering performance of the embedding. In (1), we assess how the images are changed by our scanner standardization. We quantitatively evaluate the difference between the original (raw) image and the synthetic image with peak signal-to-noise ratio (PSNR), root mean squared error (RMSE), and structured similarity (SSIM). To ensure that the evaluation is not affected by differences in brain size, these evaluations were performed on brain regions only. Although MRICloud, which is used in skull stripping in this experiment, standardizes the brain size to the standard brain size, reducing the differences in brain size between cases, this method was adopted for a more rigorous evaluation. In (2), we quantitatively examine the effect of PSS by analyzing the distribution of the obtained low-dimensional representations. Specifically, for each category (e.g., CN_SI, AD_GE) we investigate the following: (i) variation (i.e., standard deviation) of the embedding and (ii) the mean and standard deviation of the distance from each embedding to the\nrepresentation of PD, which was not included in the training, is analyzed to quantitatively verify the effectiveness of the proposed DI-PSS evaluation.\n# D. EVALUATION OF THE PSS\nIn (1), we assess how the images are changed by our scanner standardization. We quantitatively evaluate the difference between the original (raw) image and the synthetic image with peak signal-to-noise ratio (PSNR), root mean squared error (RMSE), and structured similarity (SSIM). To ensure that the evaluation is not affected by differences in brain size, these evaluations were performed on brain regions only. Although MRICloud, which is used in skull stripping in this experiment, standardizes the brain size to the standard brain size, reducing the differences in brain size between cases, this method was adopted for a more rigorous evaluation. In (2), we quantitatively examine the effect of PSS by analyzing the distribution of the obtained low-dimensional representations. Specifically, for each category (e.g., CN_SI, AD_GE) we investigate the following: (i) variation (i.e., standard deviation) of the embedding and (ii) the mean and standard deviation of the distance from each embedding to the\ncentroid of a different category, where the distance between the centroids of ADNI-CN_Siemens (CN_SI) and ADNIAD_Siemens (AD_SI) are normalized to 1. In addition, we visualize those distributions in 2D space using t-SNE [29] as supplemental results for intuitive understanding. In (3), we evaluate the separability of the resulting embeddings. In this study, we performed spectral clustering [35] to assess its potential quality for CBIR. In the spectral clustering, we used a normalized graph Laplacian based on 10-nearest neighbor graphs with a general Gaussian-type similarity measure. We set the number of clusters to be two (AD vs. CN + Control + PD), which is the number of disease categories to be classified. Here, the consistency of the distance between the embedded data because of the difference in folds is solved by standardizing the distance between CN_SI and AD_SI per fold to be 1, as mentioned above. The clustering performance was evaluated using two methodologies. The first was evaluation with six commonly used criteria (i.e., silhouette score, homogeneity, completeness, V-measure, adjusted Rand-index [ARI], and adjusted mutual information [AMI]) implemented on the scikit-learn machine learning library (https://scikit-learn.org/). The other is a diagnostic capability based on clustering results. Here, as with other clustering evaluations in the literature, we swap the columns so that each fold results in the optimal clustering result and then sum them.\n# V. RESULTS\nA. CHANGES IN MR IMAGES BY PSS Figure 5 shows an example of each MR image converted to an image taken on a pseudo-standard (= Siemens) scanner with PSS and the difference visualized. Table 2 summarizes the statistics of the degree of change in the images in the brain regions. Here, the background region was excluded from the calculation to eliminate the effect of differences in brain size. For the ADNI dataset, the differences obtained by the PSS image transformation were not significant between CN, AD, and scanner vendors, although the Philips scanners showed less variation on average. For the PPMI dataset that was not used for training, the change in the image because of PSS is clearly larger compared with ADNI (approx. \u00d7 1.5 in RMSE). In all categories, the amount of change because of PSS varied from case to case, but the PSS treatment did not cause any visually unnatural changes in the images. Figure 6 shows the cumulative intensity changes of images by PSS in each category. This time, the background areas other than the brain are also included in the evaluation. The number of pixels where the intensity has not changed because of PSS exceeds 80% for all categories, indicating that no undesired intensity changes have occurred for the background (as also seen in Figures. 5 and 6). There is no significant difference in the distribution of intensity change by vendor, and the PPMI dataset has a larger amount of intensity change overall.\n<div style=\"text-align: center;\">TABLE 2: Summary of image changes by PSS</div>\ndataset\nlabel\nPSNR (db)\nRMSE\nSSIM\nADNI\nCN_SI\n31.52 \u00b1 2.85\n7.17 \u00b1 2.57\n0.9743 \u00b1 0.0048\nCN_GE\n31.67 \u00b1 2.45\n6.94 \u00b1 2.13\n0.9748 \u00b1 0.0041\nCN_PH\n32.18 \u00b1 2.65\n6.58 \u00b1 2.02\n0.9747 \u00b1 0.0038\nAD_SI\n31.64 \u00b1 3.04\n7.13 \u00b1 2.77\n0.9746 \u00b1 0.0043\nAD_GE\n31.65 \u00b1 2.52\n6.98 \u00b1 2.32\n0.9750 \u00b1 0.0044\nAD_PH\n32.33 \u00b1 2.13\n6.36 \u00b1 1.63\n0.9751 \u00b1 0.0031\nPPMI\nControl\n30.16 \u00b1 5.47\n9.81 \u00b1 8.32\n0.9596 \u00b1 0.0346\nPD\n29.40 \u00b1 5.94\n11.60 \u00b1 10.89\n0.9539 \u00b1 0.0473\n<div style=\"text-align: center;\">TABLE 3: Variation (SD) of the embedding in category \u2020</div>\n \u2020\ndataset\nlabel\n#data\nbaseline\nwith PSS\n\u2212SD (%)\nADNI\nCN_SI\n92\n0.697\n0.648\n7.12\nCN_GE\n93\n0.784\n0.716\n8.66\nCN_PH\n27\n0.622\n0.619\n0.48\nADNI-CN\n212\n0.753\n0.701\n6.91\nAD_SI\n80\n0.863\n0.783\n9.24\nAD_GE\n80\n0.849\n0.806\n5.09\nAD_PH\n20\n0.771\n0.706\n8.46\nADNI-AD\n180\n0.876\n0.823\n6.09\nPPMI\nControl\n75\n0.607\n0.554\n8.74\nPD\n149\n0.603\n0.515\n14.71\nboth\nCN\n92\n0.759\n0.704\n7.20\nall\n616\n0.755\n0.693\n8.27\n:Distance between CN_SI and AD_SI were normalized to 1.\n\u2020:Distance between CN_SI and AD_SI were normalized to 1.\n# B. DISTRIBUTION OF LOW-DIMENSIONAL EMBEDDED DATA\nTable 3 shows the variation (standard deviation; SD) of the 150-dimensional embedded representation in each category. Again, it should be noted here that CN_SI and AD_SI were normalized to 1. The average reduction in SD for all data by PSS was 8.27%. Tables 4 shows the statistics of distances from each embedding to the centroid of a different category. This shows the distribution of the data, considering the direction of variation, which is more practical for CBIR application. With PSS, the average distance between centroids across categories is almost unchanged, but the variability is greatly reduced for all categories.\n2) Visualization of the distribution of the embedding Figures 7a and 7b show scatter plots of the embedding of test data with and without PSS, respectively in an arbitrary fold by t-SNE. Specifically, this is a scatter plot of the AD, CN, and Control test cases (data excluded from the training in the five-fold cross-validation) along with the untrained PD cases on the model. Here, PD has been randomly reduced to 1/5 for better visualization. Without PSS (baseline; 3D CAE + metric learning), AD and CN are properly separated, but the distribution of Control + PD (i.e., the difference in datasets) is separated from that of CN to a discernible degree (left). It can be confirmed that by performing PSS, the distribution of Control + PD becomes closer to that of CN, and the separation between AD and other categories becomes better (right).\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/afcd/afcd9bf9-db05-4d54-a3ff-017934448309.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 5: Example of image change by PSS (in coronal plane). In each category, from left to right, the original image, the PSS processed image, and the difference between them.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/ef6a/ef6aac5b-954c-4a77-bb37-af8a88b9b80c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(a) overall view</div>\n<div style=\"text-align: center;\">FIGURE 6: Cumulative intensity changes of MR images by PSS.</div>\nC. CLUSTERING PERFORMANCE OF THE EMBEDDING In this section, we compare the separation ability of the obtained low-dimensional embedding of MR images with and without PSS (baseline). Tables 5 summarizes the clustering performance evaluated with six commonly used criteria. These are the silhouette score (silh), homogeneity score (homo), completeness score (comp), V-measure (harmonic mean of homogeneity and completeness; V) , ARI, and AMI implemented on the scikitlearn library. In each category, 1 is the best score and 0 is a score based on random clustering. It can be confirmed that\n<div style=\"text-align: center;\">(b) enlarged view</div>\nPSS improved the clustering ability in all evaluation items. Table 6 is a summary of the clustering performance evaluated with the diagnostic ability. Table 6 (a) is a confusion matrix. Here, the numbers of CN, Control and AD cases are the sum of each fold in the cross-validation. In each fold, we tested all PD cases (not included in the training), and the number was divided by five and rounded to the nearest whole number. Tables 6b and 6c summarize the diagnostic performance calculated from Table 6 (a) without and with PD cases, respectively. It can be confirmed that PSS enhances the separation of AD and other categories (i.e., CN, Control and\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/796b/796b1c74-1c38-4346-a483-58c7e9308df3.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">FIGURE 7: Distribution of embedding visualized with t-SNE [29]: (left) baseline (3D-CAE+metric learning), (right) baseline with PSS.</div>\nTABLE 4: Mean and variability of embedding across categories of data \u2020\n \u2020\nbaseline\nwith PSS\n-SD (%)\nfrom\nto\nmean\nSD\nmean\nSD\nADNI-CN\nAD\n0.879\n0.669\n0.890\n0.541\n19.1\nAD\nADNI-CN\n0.875\n0.729\n16.6\nControl\nAD\n1.354\n0.745\n1.329\n0.537\n28.0\nAD\nControl\n0.907\n0.702\n22.6\nPD\nControl\n0.256\n0.469\n0.297\n0.312\n33.5\nControl\nPD\n0.414\n0.368\n11.2\nADNI-CN\nPD\n0.364\n0.609\n0.362\n0.474\n22.2\nPD\nADNI-CN\n0.373\n0.255\n31.4\nAD\nPD\n1.164\n0.939\n1.091\n0.770\n18.0\nPD\nAD\n0.620\n0.434\n29.9\nCN\nAD\n0.996\n0.753\n0.997\n0.583\n22.6\nAD\nCN\n0.917\n0.773\n15.8\nCN\nPD\n0.249\n0.593\n0.269\n0.466\n21.4\nPD\nCN\n0.349\n0.264\n24.2\n\u2020:Distance between CN_SI and AD_SI were normalized to 1.\n\u2020:Distance between CN_SI and AD_SI were normalized to 1.\nTABLE 5: Clustering performance evaluated with common criteria \u2020\nTABLE 5: Clustering performance evaluated with common criteria \u2020\nTABLE 5: Clustering performance evaluated with common\n \u2020\nsilh\nhomo\ncomp\nV\nARI\nAMI\nbaseline\n0.236\n0.220\n0.301\n0.250\n0.251\n0.241\n+PSS\n0.246\n0.301\n0.351\n0.324\n0.387\n0.317\n\u2020: Score 1 is the best in each category. 0 is the score for random clustering.\n\u2020: Score 1 is the best in each category. 0 is the score for random clustering.\nPD) in the low-dimensional representation. PSS improved the diagnostic performance by about 6.2% (from 73.7 to 79.9%) for micro-accuracy and about 10.7% (from 63.8 to 74.5%) for macro-F1. The specificity for PD was also improved by 6.1% (from 69.7% to 75.8%).\n# VI. DISCUSSION\n# A. CHANGES ON MR IMAGES BY PSS\nA. CHANGES ON MR IMAGES BY PSS Our PSS network transforms healthy cases taken with GE scanners to those taken with Siemens scanners. As can be seen from Figure 6 and Table 2, the amount of change in the images because of PSS was almost the same for both AD and\nCN images in the ADNI dataset, including the Philips case. The amount of conversion of the image for the PPMI dataset was larger than that for the ADNI dataset. This is thought to be due to the process of absorbing the differences in the datasets that exist in the image but are invisible to the eye. However, in all cases, the converted images have a natural appearance without destroying the brain structure. This can be objectively confirmed in SSIM, which evaluates the structural similarity on the image, maintains a high value. As discussed in detail below, PSS can reduce disease-specific variation in the resulting low-dimensional embedding, absorb differences among datasets and scanner vendors, and improve the separability of diseases. Given these factors, we can conclude that this PSS transformation was done properly. B. CONTRIBUTIONS OF DI-PSS FOR CBIR This section discusses the effects of our DI-PSS framework from the perspective of CBIR implementation.\nB. CONTRIBUTIONS OF DI-PSS FOR CBIR This section discusses the effects of our DI-PSS framework from the perspective of CBIR implementation.\nThis section discusses the effects of our DI-PSS framework from the perspective of CBIR implementation.\n1) Distribution of embedding\nBased on the results in Tables 3 and 4, we first discuss the effectiveness of the proposed DI-PSS. From Table 3, PSS reduces the inter-cluster variability for all data categories. In particular, the SD of ADNI-CN and ADNI-AD, which are taken by scanners from three different companies in the same dataset, are reduced by 6.9% and 6.1%, respectively. This indicates that the PSS reduces the difference caused by different scanners. In addition, the SD of ALL_CN, which is a combination of ADNI-CN and Control from a different PPMI dataset, is also reduced by 7.2%, which clearly shows that the proposed PSS can absorb differences in datasets. This benefit can also be seen in Figure 7. The reduction of PD variability by PSS is more pronounced (\u221214.7%) than the others, and it is ultimately the category with the lowest variability. This is mentioned later in this section. From Table 4, PSS also succeeds in reducing the variability from each piece of data to all the different\n<div style=\"text-align: center;\">TABLE 6: Evaluation of clustering ability by diagnostic ability (a) Confusion matrix</div>\nbaseline\nwith PSS\nCN+Control (+PD)\nAD\nCN+Control (+PD)\nAD\nCN+Control\n284\n3\n274\n13\n(+PD)\n(+104)\n(+45)\n(+113)\n(+36)\nAD\n114\n66\n75\n105\n<div style=\"text-align: center;\">(b) Clustering performance (excluded PD cases)</div>\nCN+Control\nAD\naccuracy\nmacro-F1\nprecision\nrecall\nF1\nprecision\nrecall\nF1\nbaseline\n71.36\n98.95\n82.92\n95.65\n36.67\n53.01\n74.9\n68.0\n+PSS\n78.51\n95.47\n86.16\n88.98\n58.33\n70.47\n81.1\n78.3\n<div style=\"text-align: center;\">(c) Clustering performance (included PD cases)</div>\nCN+Control\nAD\naccuracy\nmacro-F1\nSpecificity\nprecision\nrecall\nF1\nprecision\nrecall\nF1\nof PD\nbaseline\n77.29\n88.99\n82.73\n57.89\n36.67\n44.90\n73.7\n63.8\n69.7\n+PSS\n83.77\n88.76\n86.19\n68.18\n58.33\n62.87\n79.9\n74.5\n75.8\ncluster centers (inter-cluster variability). What is noteworthy here is the degree of decrease in the standard deviation, which reached an average of 22.6%. This ability to reduce not only the variability of data in the same category, but also the directional variability up to different data categories is an important feature in CBIR. In this experiment, we only built an image transformer (i.e. PSSnetwork) that converts CN_GE to CN_SI cases, but we could confirm that the harmonization is desirable for categories that are not included in the training in this way. This strongly suggests that the strategy we have adopted \u2013 that is, not having to build image harmonizers for all scanner types \u2013 may have sufficient harmonization effects for many types of scanners. Incidentally, the distances between PD and CN (ADNI-CN vs. PD and ALL-CN vs. PD) are closer than the distances between other categories. This supports the validity of the assumption we made in our experiment that PD and CN are outwardly indistinguishable, and therefore, they can be treated as the same class. In contrast, if we look closely, we can see that the distances of the gravity centers between PD and CN (0.249\u21920.269) and PD and Control (0.256\u21920.297) are slightly increased by PSS, and Table 3 shows that the variation of PD is greatly reduced by PSS. From this, we can say that the PSS is moving the PDs into smaller groups away from CN and Control. This can be taken as an indication that the model trained by DI-PSS tends to consider PD as a different class that is potentially separated from the CN category. Since the size of the dataset for this experiment was limited, we would like to run tests with a larger dataset in the future.\n2) Separability of the embedding for CBIR Thanks to the harmonization of scanners by PSS, the proposed DI-PSS not only reduces the variability of lowdimensional representations of each disease category, which\n2) Separability of the embedding for CBIR Thanks to the harmonization of scanners by PSS, the proposed DI-PSS not only reduces the variability of lowdimensional representations of each disease category, which\ncould not be reduced by deep metric learning learning alone as adopted in DCMML [9], but also reduces the differences among datasets, resulting in a significant performance improvement in the clustering ability of low-point representations. The PD data are different from the ADNI data used for training, and thus, it is an unknown dataset from our model. The improvement of clustering performance by the proposed DI-PSS for PD as well is an important and noteworthy result for the realization of CBIR.\n# C. VALIDITY OF THE MODEL ARCHITECTURE\nThe recently proposed data harmonization methods for brain MR images by Moyer et al [25] and Dinsdale et al. [26] have been reported to be not only logically justified but also very effective. However, as mentioned above, these methods are difficult to apply to CBIR applications because images from all scanners are theoretically needed to train the model. Our DI-PSS is a new proposal to address these problems. Although DI-PSS only learned the transformation from CN_GE to CN_Siemens, the improvement of the properties of the obtained embeddings was confirmed even for combinations that included other companies\u2019 scanners, such as the Philips scanner, and different disease categories (AD) that were not included in the training. The results are evidence of proper data harmonization. We think this is due to the combination of MRICloud, an advanced skull stripping algorithm that performs geometric and volumetric positioning, and CycleGAN\u2019s generic style transformation capabilities and distance metric learning, which make up the PSS network. Experiments with large-scale data from more diverse disease classes are needed, but in this experiment, we could confirm the possibility of obtaining effective scanner standardization by building one model that translates into a standard scanner.\n# LIMITATIONS OF THIS STUDY\nThe number of data and diversity of their conditions used in these experiments are limited. There is also a limit to the\nnumber of diseases we considered. In the future, verification using more data is essential.\n# VII. CONCLUSION\nIn this paper, we proposed a novel and effective MR image embedding method, DI-PSS, which is intended for application to CBIR. DI-PSS achieves data harmonization by transforming MR images to look like those captured with a predefined standard scanner, reducing the bias caused by variations in scanners and scan protocols, and obtaining a low-dimensional representation preserving disease-related anatomical features. The DI-PSS did not require training data that contained MRIs from all scanners and protocols; One set of image converters (i.e., CN_GE to CN_Siemens) was sufficient to train the model. In the future, we will continue the validation with more extensive and diverse data.\n# ACKNOWLEDGMENT\nThis research was supported in part by the Ministry of Education, Science, Sports and Culture of Japan (JSPS KAKENHI), Grant-in-Aid for Scientific Research (C), 21K12656, 2021\u20132023. The MRI data collection and sharing for this project was funded by the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12\u20132-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, Alzheimer\u2019s Association; Alzheimer\u2019s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research & Development, LLC.; Johnson & Johnson Pharmaceutical Research & Development LLC.; Lumosity; Lundbeck; Merck & Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer\u2019s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California. An additional MRI data used in the preparation of this article were obtained from the Parkinson\u2019s Progression Markers Initiative (PPMI) database (www.ppmi-info.org/data). For up-to-date information on the study, visit www.ppmi-info.org. PPMI \u2013 a public-private partnership \u2013 is funded by the Michael J. Fox Foundation for Parkinson\u2019s Research and funding partners, including AbbVie, Allergan, Avid Radiopharmaceuticals, Biogen, Biolegend, Bristol-Myers Squibb, Celgene, Denali, GE Healthcare, Genentech, GlaxoSmithKline, Lilly, Lundbeck, Merck, Meso Scale Discovery, Pfizer, Piramal, Prevail Therapeutics, Roche, Sanofi Genzyme, Servier, Takeda, Teva, UCB, Verily, Voyager Therapeutics, and Golub Capital.\n# REFERENCES\n[1] M. Woelfle, P. Olliaro, and M. H. Todd, \u201cOpen science is a research accelerator,\u201d Nature chemistry, vol. 3, no. 10, pp. 745\u2013748, 2011. [2] A. Kumar, J. Kim, W. Cai, M. Fulham, and D. Feng, \u201cContent-based medical image retrieval: a survey of applications to multidimensional and multimodality data,\u201d Journal of Digital Imaging, vol. 26, no. 6, pp. 1025\u2013 1039, 2013. [3] Z. Tu and X. Bai, \u201cAuto-context and its application to high-level vision tasks and 3D brain image segmentation,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 32, no. 10, pp. 1744\u20131757, 2010. [4] M. Huang, W. Yang, M. Yu, Z. Lu, Q. Feng, and W. Chen, \u201cRetrieval of brain tumors with region-specific bag-of-visual-words representations in contrast-enhanced MRI images,\u201d Computational and Mathematical Methods in Medicine, vol. 2012, p. 280538, 2012. [5] S. Murala and Q. M. J. Wu, \u201cLocal mesh patterns versus local binary patterns: Biomedical image indexing and retrieval,\u201d IEEE Journal of Biomedical and Health Informatics, vol. 18, no. 3, pp. 929\u2013938, 2014. [6] A. V. Faria, K. Oishi, S. Yoshida, A. Hillis, M. I. Miller, and S. Mori, \u201cContent-based image retrieval for brain MRI: An image-searching engine and population-based analysis to utilize past clinical data for future diagnosis,\u201d NeuroImage: Clinical, vol. 7, pp. 367\u2013376, 2015. [7] K. Kruthika, Rajeswari, and H. Maheshappa, \u201cCBIR system using capsule networks and 3D CNN for alzheimer\u2019s disease diagnosis,\u201d Informatics in Medicine Unlocked, vol. 14, pp. 59\u201368, 2019. [8] Z. N. K. Swati, Q. Zhao, M. Kabir, F. Ali, Z. Ali, S. Ahmed, and J. Lu, \u201cContent-based brain tumor retrieval for MR images using transfer learning,\u201d IEEE Access, vol. 7, pp. 17 809\u201317 822, 2019. [9] Y. Onga, S. Fujiyama, H. Arai, Y. Chayama, H. Iyatomi, and K. Oishi, \u201cEfficient feature embedding of 3D brain MRI images for content-based image retrieval with deep metric learning,\u201d pp. 3764\u20133769, 2019. [10] B. Alipanahi, M. Biggs, and A. Ghodsi, \u201cDistance metric learning vs. fisher discriminant analysis,\u201d Proceedings of the 23rd National Conference on Artificial Intelligence, vol. 2, pp. 598\u2013603, 2008. [11] E. Hoffer and N. Ailon, \u201cSemi-supervised deep learning by metric embedding,\u201d arXiv preprint, p. 1611.01449, 2016. [12] K. A. Clark, R. P. Woods, D. A. Rottenberg, A. W. Toga, and J. C. Mazziotta, \u201cImpact of acquisition protocols and processing streams on tissue segmentation of t1 weighted mr images,\u201d NeuroImage, vol. 29, no. 1, pp. 185\u2013202, 2006. [13] X. Han, J. Jovicich, D. Salat, A. van der Kouwe, B. Quinn, S. Czanner, E. Busa, J. Pacheco, M. Albert, R. Killiany, P. Maguire, D. Rosas, N. Makris, A. Dale, B. Dickerson, and B. Fischl, \u201cReliability of MRIderived measurements of human cerebral cortical thickness: the effects of field strength, scanner upgrade and manufacturer,\u201d Neuroimage, vol. 32, no. 1, pp. 180\u2013194, 2006. [14] M. Yu, K. A. Linn, P. A. Cook, M. L. Phillips, M. McInnis, M. Fava, M. H. Trivedi, M. H. Trivedi, R. T. Shinohara, and Y. I. Sheline, \u201cStatistical harmonization corrects site effects in fuctional connectivity measures from multi-site fMRI data,\u201d Human brain mapping, vol. 39, no. 11, pp. 4213\u2013 4227, 2018. [15] K. Oishi, J. Chotiyanonta, D. Wu, M. I. Miller, and S. Mori, \u201cDevelopmental trajectories of the human embryologic brain regions,\u201d Neuroscience Letters, vol. 708, p. 134342, 2019. [16] C. Wachinger, A. Rieckmann, and S. P\u00f6lsterl, \u201cDetect and correct bias in multi-site neuroimaging datasets,\u201d Medical Image Analysis, vol. 67, p. 101879, 2021. [17] Y. Gao, J. Pan, Y. Guo, J. Yu, J. Zhang, D. Geng, and Y. Wang, \u201cOptimised mri intensity standardisation based on multi-dimensional subregional point cloud registration,\u201d Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization, vol. 7, no. 5-6, pp. 594\u2013603, 2019. [18] H. Um, F. Tixier, D. Deasy, Bermudez, J. O, R. J. Young, and H. Veeraraghavan, \u201cImpact of image preprocessing on the scanner dependence of multi-parametric MRI radiomic features and covariate shift in multiinstitutional glioblastoma datasets,\u201d Physics in Medicine and Biology, vol. 64, no. 16, p. 165011, 2019. [19] W. E. Johnson, C. Li, and A. Rabinovic, \u201cAdjusting batch effects in microarray expression data using empirical Bayes methods,\u201d Biostatistics, vol. 8, no. 1, pp. 118\u2013127, 2006. [20] J.-P. Fortin, D. Parker, B. Tunc, T. Watanabe, M. A. Elliott, K. Ruparel, D. R. Roalf, T. D. Satterthwaite, R. C. Gur, R. E. Gur, R. T. Schultz, R. Verma, and R. T. Shinohara, \u201cHarmonization of multi-site diffusion tensor imaging data,\u201d bioRxiv, 2017. [Online]. Available: http://biorxiv.org/content/early/2017/03/15/116541\n[21] J.-P. Fortin, D. Parker, B. Tun\u00e7, T. Watanabe, M. A. Elliott, K. Ruparel, D. R. Roalf, T. D. Satterthwaite, R. C. Gur, R. E. Gur, R. T. Schultz, R. Verma, and R. T. Shinohara, \u201cHarmonization of multi-site diffusion tensor imaging data,\u201d NeuroImage, vol. 161, pp. 149\u2013170, 2017. [22] J.-P. Fortin, N. Cullen, Y. I. Sheline, W. D. Taylor, I. Aselcioglu, P. A. Cook, P. Adams, C. Cooper, M. Fava, P. J. McGrath, M. McInnis, M. L. Phillips, M. H. Trivedi, and M. M. Weissman, \u201cHarmonization of cortical thickness measurements across scanners and sites,\u201d NeuroImage, vol. 167, pp. 104\u2013120, 2017. [23] F. Zhao, Z. Wu, L. Wang, W. Lin, S. Xia, D. Shen, and G. Li, \u201cHarmonization of infant cortical thickness using surface-to-surface cycle-consistent adversarial networks,\u201d Med Image Comput Comput Assist Interv, vol. 11767, pp. 475\u2013483, 2019. [24] C. Zhao, J. C. Reinhold, A. Carass, K. C. Fitzgerald, E. S. Sotirchos, S. Saidha, J. Oh, D. L. Pham, P. A. Calabresi, P. C. M. van Zijl, and J. L. Prince, \u201cDeepharmony: A deep learning approach to contrast harmonization across scanner changes,\u201d Magnetic Resonance Imaging, vol. 64, pp. 160\u2013170, 2019. [25] D. Moyer, G. Ver Steeg, C. M. W. Tax, and T. P. M., \u201cScanner invariant representations for diffusion MRI harmonization,\u201d Magnetic resonance in medicine, vol. 84, no. 4, pp. 2174\u20132189, 2020. [26] N. K. Dinsdale, M. Jenkinson, and A. I. L. Namburete, \u201cDeep learningbased unlearning of dataset bias for MRI harmonisation and confound removal,\u201d NeuroImage, vol. 228, p. 117689, 2021. [27] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, \u201cUnpaired image-to-image translation using cycle-consistent adversarial networks,\u201d pp. 2242\u20132251, 2017. [28] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. Marchand, and V. Lempitsky, \u201cDomain-adversarial training of neural networks,\u201d Journal of Machine Learning Research, vol. 17, pp. 1\u201335, 2016. [29] M. van der Laurens and G. Hinton, \u201cVisualizing data using t-SNE,\u201d Journal of machine learning research, vol. 9, no. 86, pp. 2579\u20132605, 2008. [30] S. Mori, D. Wu, C. Ceritoglu, Y. Li, A. Kolasny, M. A. Vaillant, A. V. Faria, K. Oishi, and M. I. Miller, \u201cMRICloud: Delivering high-throughput mri neuroinformatics as cloud-based software as a service,\u201d Computing in Science Engineering, vol. 18, no. 5, pp. 21\u201335, 2016. [31] H. Arai, Y. Chayama, H. Iyatomi, and K. Oishi, \u201cSignificant dimension reduction of 3D brain MRI using 3D convolutional autoencoders,\u201d pp. 5162\u20135165, 2018. [32] R. B. Postuma, D. Berg, M. Stern, W. Poewe, C. W. Olanow, W. Oertel, J. Obeso, K. Marek, I. Litvan, A. E. Lang, G. Halliday, C. G. Goetz, T. Gasser, B. Dubois, P. Chan, B. R. Bloem, C. H. Adler, and G. Deuschl, \u201cMDS clinical diagnostic criteria for Parkinson\u2019s disease,\u201d Movement Disorders, vol. 30, no. 12, pp. 1591\u2013601, 2015. [33] F. J. Meijera, B. Goraja, B. R. Bloemc, and R. A. Esselinkc, \u201cClinical application of brain mri in the diagnostic work-up of parkinsonism,\u201d Journal of Parkinson\u2019s Disease, vol. 7, pp. 211\u2013217, 2017. [34] K. Oishi, A. Faria, H. Jiang, X. Li, K. Akhter, J. Zhang, J. T. Hsu, M. I. Miller, P. C. M. van Zijl, M. Albert, C. G. Lyketsos, R. Woods, A. W. Toga, G. B. Pike, P. Rosa Neto, A. Evans, J. Mazziotta, and S. Mori, \u201cAtlas-based whole brain white matter analysis using large deformation diffeomorphic metric mapping: application to normal elderly and alzheimer\u2019s disease participants,\u201d Neuroimage, vol. 46, no. 2, pp. 486\u2013499, 2009. [35] A. Y. Ng, M. I. Jordan, and Y. Weiss, \u201cOn spectral clustering: Analysis and an algorithm,\u201d Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic, pp. 849\u2013 856, 2001.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of effectively retrieving brain MRI images for clinical applications, which is hampered by scanner and protocol variations. Previous methods have struggled to harmonize images from different scanners, leading to inconsistencies in image retrieval. The proposed method, Disease-oriented image embedding with pseudo-scanner standardization (DI-PSS), aims to overcome these challenges.",
        "problem": {
            "definition": "The core problem is the inability to achieve reliable content-based image retrieval (CBIR) from brain MRI databases due to significant variations caused by different MRI scanners and protocols.",
            "key obstacle": "The main obstacle is the non-biological variations in MRI data, which affect the quality and consistency of low-dimensional representations necessary for accurate disease classification."
        },
        "idea": {
            "intuition": "The idea behind DI-PSS arose from the need to harmonize MR images acquired from different scanners, focusing on disease characteristics rather than scanner-specific features.",
            "opinion": "DI-PSS proposes a method to convert MR images into a standardized format that simulates images taken by a reference scanner, thereby facilitating more accurate disease classification.",
            "innovation": "The key innovation of DI-PSS lies in its ability to standardize images from various scanners using a single model, which contrasts with previous methods that required extensive datasets from all scanners for training."
        },
        "method": {
            "method name": "Disease-oriented image embedding with pseudo-scanner standardization",
            "method abbreviation": "DI-PSS",
            "method definition": "DI-PSS is a framework that harmonizes brain MRI images by transforming them into a pseudo-standard format, thereby reducing variability and improving disease classification.",
            "method description": "The method employs data harmonization and a deep metric learning approach to create low-dimensional embeddings that reflect disease characteristics.",
            "method steps": [
                "Perform skull stripping on MRI data.",
                "Align the skull-stripped images to a standard brain space.",
                "Apply the pseudo-scanner standardization process using CycleGAN.",
                "Extract low-dimensional embeddings using a 3D convolutional autoencoder with metric learning."
            ],
            "principle": "The effectiveness of DI-PSS stems from its ability to reduce scanner-related variability, allowing for more consistent and reliable low-dimensional representations that enhance disease classification."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted using T1-weighted MRIs from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) and the Parkinson\u2019s Progression Markers Initiative (PPMI) datasets, which included images from multiple scanner manufacturers.",
            "evaluation method": "Performance was assessed through clustering techniques and metrics such as accuracy, macro-F1 score, and distance metrics between embeddings, comparing results with and without the application of PSS."
        },
        "conclusion": "The DI-PSS framework significantly improved the consistency of low-dimensional embeddings, enhancing the accuracy of disease classification in brain MRI images. The method demonstrates potential for broader application in clinical settings, particularly for legacy MRI data.",
        "discussion": {
            "advantage": "DI-PSS effectively reduces variability across different scanners and protocols, leading to improved clustering performance and diagnostic accuracy.",
            "limitation": "The study is limited by the diversity and size of the datasets used, which may affect the generalizability of the findings.",
            "future work": "Future research should focus on validating DI-PSS with larger and more diverse datasets to further assess its robustness and applicability in clinical practice."
        },
        "other info": {
            "acknowledgment": "This research was supported by the Ministry of Education, Science, Sports and Culture of Japan and funded by the Alzheimer\u2019s Disease Neuroimaging Initiative and the Parkinson\u2019s Progression Markers Initiative."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper addresses the issue of effectively retrieving brain MRI images for clinical applications, highlighting the significance of large language models in harmonizing data from different sources."
        },
        {
            "section number": "1.2",
            "key information": "Evaluating large language models is crucial for ensuring their effectiveness and reliability, similar to how the proposed DI-PSS method aims to standardize MRI images for accurate disease classification."
        },
        {
            "section number": "2.1",
            "key information": "Defines the core problem of unreliable content-based image retrieval (CBIR) from brain MRI databases due to variations caused by different MRI scanners and protocols."
        },
        {
            "section number": "2.3",
            "key information": "The necessity of standardized methods for evaluating language models is paralleled in the DI-PSS framework, which harmonizes MRI images to improve classification consistency."
        },
        {
            "section number": "5.1",
            "key information": "Discusses the impact of non-biological variations in MRI data, which affect the quality and consistency of low-dimensional representations necessary for accurate disease classification."
        },
        {
            "section number": "6.1",
            "key information": "The DI-PSS framework demonstrates advancements in evaluation methodologies by reducing scanner-related variability and improving diagnostic accuracy."
        }
    ],
    "similarity_score": 0.5553724013203015,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-0214_large/papers/Disease-oriented image embedding with pseudo-scanner standardization for content-based image retrieval on 3D brain MRI.json"
}