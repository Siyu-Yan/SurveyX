{
    "from": "google",
    "scholar_id": "X-rA_fEK-40J",
    "detail_id": null,
    "title": "Llmrec: Large language models with graph augmentation for recommendation",
    "abstract": " ABSTRACT\nABSTRACT\nThe problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information. However, this approach often introduces side effects such as noise, availability issues, and low data quality, which in turn hinder the accurate modeling of user preferences and adversely impact recommendation performance. In light of the recent advancements in large language models (LLMs), which possess extensive knowledge bases and strong reasoning capabilities, we propose a novel framework called LLMRec that enhances recommender systems by employing three simple yet effective LLM-based graph augmentation strategies. Our approach leverages the rich content available within online platforms (e.g., Netflix, MovieLens) to augment the interaction graph in three ways: (i) reinforcing user-item interaction egde, (ii) enhancing the understanding of item node attributes, and (iii) conducting user node profiling, intuitively from the natural language perspective. By employing these strategies, we address the challenges posed by sparse implicit feedback and low-quality side information in recommenders. Besides, to ensure the quality of the augmentation, we develop a denoised data robustification mechanism that includes techniques of noisy implicit feedback pruning and MAE-based feature enhancement that help refine the augmented data and improve its reliability. Furthermore, we provide theoretical analysis to support the effectiveness of LLMRec and clarify the benefits of our method in facilitating model optimization. Experimental results on benchmark datasets demonstrate the superiority of our LLMbased augmentation approach over state-of-the-art techniques. To\n\u2217Chao Huang is the corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or ",
    "bib_name": "wei2024llmrec",
    "md_text": "# LLMRec: Large Language Models with Graph Augmentation for Recommendation\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/886e/886ec1b1-0b23-424a-8ad1-828866b44e9e.png\" style=\"width: 50%;\"></div>\n# ABSTRACT\nABSTRACT\nThe problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information. However, this approach often introduces side effects such as noise, availability issues, and low data quality, which in turn hinder the accurate modeling of user preferences and adversely impact recommendation performance. In light of the recent advancements in large language models (LLMs), which possess extensive knowledge bases and strong reasoning capabilities, we propose a novel framework called LLMRec that enhances recommender systems by employing three simple yet effective LLM-based graph augmentation strategies. Our approach leverages the rich content available within online platforms (e.g., Netflix, MovieLens) to augment the interaction graph in three ways: (i) reinforcing user-item interaction egde, (ii) enhancing the understanding of item node attributes, and (iii) conducting user node profiling, intuitively from the natural language perspective. By employing these strategies, we address the challenges posed by sparse implicit feedback and low-quality side information in recommenders. Besides, to ensure the quality of the augmentation, we develop a denoised data robustification mechanism that includes techniques of noisy implicit feedback pruning and MAE-based feature enhancement that help refine the augmented data and improve its reliability. Furthermore, we provide theoretical analysis to support the effectiveness of LLMRec and clarify the benefits of our method in facilitating model optimization. Experimental results on benchmark datasets demonstrate the superiority of our LLMbased augmentation approach over state-of-the-art techniques. To\n\u2217Chao Huang is the corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WSDM \u201924, March 4\u20138, 2024, Merida, Mexico \u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0371-3/24/03...$15.00 https://doi.org/10.1145/3616855.3635853\nensure reproducibility, we have made our code and augmented data publicly available at: https://github.com/HKUDS/LLMRec.git.\n# KEYWORDS\nLarge Language Models, Graph Learning, Data Augmentation, Content based Recommendation, Multi-modal Recommendation, Collaborative Filtering, Data Sparsity, Bias in Recommender System\nLarge Language Models, Graph Learning, Data Augmentation, Conten based Recommendation, Multi-modal Recommendation, Collaborative Filtering, Data Sparsity, Bias in Recommender System ACM Reference Format: Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2024. LLMRec: Large Language Models with Graph Augmentation for Recommendation . In Proceedings of the 17th ACM International Conference on Web Search and Data Mining (WSDM \u201924), March 4\u20138, 2024, Merida, Mexico. ACM, Merida, Mexico, 10 pages. https://doi.org/10.1145/3616855.3635853\nACM Reference Format: Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2024. LLMRec: Large Language Models with Graph Augmentation for Recommendation . In Proceedings of the 17th ACM International Conference on Web Search and Data Mining (WSDM \u201924), March 4\u20138, 2024, Merida, Mexico. ACM, Merida, Mexico, 10 pages. https://doi.org/10.1145/3616855.3635853\n# 1 INTRODUCTION\nRecommender systems play a crucial role in mitigating information overload by providing online users with relevant content [27, 44]. To achieve this, an effective recommender needs to have a precise understanding of user preferences, which is not limited to analyzing historical interaction patterns but also extends to incorporating rich side information associated with users and items [61]. In modern recommender systems, such as Netflix, the side information available exhibits heterogeneity, including item attributes [53], user-generated content [7, 28], and multi-modal features [52] encompassing both textual and visual aspects. This diverse content offer distinct ways to characterize user preferences. By leveraging such side information, models can obtain informative representations to personalize recommendations. However, despite significant progress, these methods often face challenges related to data scarcity and issues associated with handling side information.\nRecommender systems play a crucial role in mitigating information overload by providing online users with relevant content [27, 44]. To achieve this, an effective recommender needs to have a precise understanding of user preferences, which is not limited to analyzing historical interaction patterns but also extends to incorporating rich side information associated with users and items [61]. In modern recommender systems, such as Netflix, the side information available exhibits heterogeneity, including item attributes [53], user-generated content [7, 28], and multi-modal features [52] encompassing both textual and visual aspects. This diverse content offer distinct ways to characterize user preferences. By leveraging such side information, models can obtain informative representations to personalize recommendations. However, despite significant progress, these methods often face challenges related to data scarcity and issues associated with handling side information. Sparse Implicit Feedback Signals. Data sparsity and the coldstart problem hinder collaborative preference capturing [48]. While many efforts (e.g., NGCF [41], LightCGN [11]) tried powerful graph neural networks(GNNs) in collaborative filtering(CF), they face limits due to insufficient supervised signals. Some studies [33] used contrastive learning to add self-supervised signals (e.g., SGL [51],\nSparse Implicit Feedback Signals. Data sparsity and the coldstart problem hinder collaborative preference capturing [48]. While many efforts (e.g., NGCF [41], LightCGN [11]) tried powerful graph neural networks(GNNs) in collaborative filtering(CF), they face limits due to insufficient supervised signals. Some studies [33] used contrastive learning to add self-supervised signals (e.g., SGL [51],\nSimGCL [54]). However, considering that real-world online platforms (e.g., Netflix, MovieLens) derive benefits from modal content, recent approaches, unlike general CF, are dedicated to incorporating side information as auxiliary for recommenders. For example, MMGCN [50] and GRCN [49] incorporate item-end content into GNNs to discover high-order content-aware relationships. LATTICE [59] leverages auxiliary content to conduct data augmentation by establishing i-i relationships. Recent efforts (e.g., MMSSL [45], MICRO [58]) address sparsity by introducing self-supervised tasks that maximize the mutual information between multiple contentaugmented views. However, strategies for addressing data sparsity in recommender systems, especially in multi-modal content, can sometimes be limited. This is because the complexity and lack of side information relevance to CF can introduce distortions in the underlying patterns [49]. Therefore, it becomes crucial to ensure the accurate capture of realistic user preferences when incorporating side information in CF, in order to avoid suboptimal results. Data Quality Issues of Side Information. Recommender systems that incorporate side information often encounter significant issues that can negatively impact their performance. i) Data Noise is an important limitation faced by recommender systems utilizing side information is the issue of data noise[39], where attributes or features may lack direct relevance to user preferences. For instance, in a micro video recommender, the inclusion of irrelevant textual titles that fail to capture the key aspects of the video\u2019s content introduces noise, adversely affecting representation learning. The inclusion of such invalid information confuse the model and lead to biased or inaccurate recommendations. ii) Data heterogeneity[4] arises from the integration of different types of side information, each with its own unique characteristics, structures, and representations. Ignoring this heterogeneity leads to skewed distributions [26, 53]. Bridging heterogeneous gap is crucial for successfully incorporating side information uniformly. iii) Data incompleteness [15, 20] occurs when side information lacks certain attributes or features. For instance, privacy concerns[56] may make it difficult to collect sufficient user profiles to learn their interests. Additionally, items may have incomplete textual descriptions or missing key attributes. This incompleteness impairs the model\u2019s ability to fully capture the unique characteristics of users and items, thereby affecting the accuracy of recommendations. Having gained insight into data sparsity and low-quality encountered by modern recommenders with auxiliary content, this work endeavors to overcome these challenges through explicit augment potential user-item interactive edges as well as enhances user/item node side information (e.g., language, genre). Inspired by the impressive natural language understanding ability of large language models (LLMs), we utilize LLMs to augment the interaction graph. Firstly, LLMRec embraces the shift from an ID-based recommendation framework to a modality-based paradigm [17, 55]. It leverages large language models (LLMs) to predict user-item interactions from a natural language perspective. Unlike previous approaches that rely solely on IDs, LLMRec recognizes that valuable item-related details are often overlooked in datasets [18]. Natural language representations provide a more intuitive reflection of user preferences compared to indirect ID embeddings. By incorporating LLMs, LLMRec captures the richness and context of natural\nlanguage, enhancing the accuracy and effectiveness of recommendations. Secondly, to elaborate further, the low-quality and incomplete side information is enhanced by leveraging the extensive knowledge of LLMs, which brings two advantages: i) LLMs are trained on vast real-world knowledge, allowing them to understand user preferences and provide valuable completion information, even for privacy-constrained user profiles. ii) The comprehensive word library of LLMs unifies embeddings in a single vector space, bridging the gap between heterogeneous features and facilitating encoder computations. This integration prevents the dispersion of features across separate vector spaces and provide more accurate results. Enabling LLMs as effective data augmentors for recommenders poses several technical challenges that need to be addressed: \u2022 C1: How to enable LLMs to reason over user-item interaction patterns by explicitly augmenting implicit feedback signals? \u2022 C2: How to ensure the reliability of the LLM-augmented content to avoid introducing noise that could compromise the results? The potential of LLM-based augmentation to enhance recommenders by addressing sparsity and improving incomplete side information is undeniable. However, effectively implementing this approach requires addressing the aforementioned challenges. Hence, we have designed a novel framework LLMRec to tackle these challenges. Solution. Our objective is to address the issue of sparse implicit feedback signals derived from user-item interactions while simultaneously improving the quality of side information. Our proposed LLMRec incorporates three LLM-based strategies for augmenting the interaction graph: i) Reinforcing user-item interaction edges, ii) Enhancing item attribute modeling, and iii) Conducting user profiling. To tackle C1 for \u2019i)\u2019, we devise an LLM-based Bayesian Personalized Ranking (BPR)[34] sampling algorithm. This algorithm uncover items that users may like or dislike based on textual content from from natural language perspective. These items are then used as positive and negative samples in the BPR training process. It is important to note that LLMs are unable to perform all-item ranking, so the selected items are chosen from a candidate item pool provided by the base recommender for each user. During the node attribute generation process (corresponding to \u2019ii)\u2019 and \u2019iii)\u2019), we create additional attributes for each user/item using existing text and interaction history. However, it is important to acknowledge that both the augmented edges and node features can contain noise. To address C2, our denoised data robustification mechanism comes into play by integrating noisy edge pruning and feature MAE [36] to ensure the quality of the augmented data. In summary, our contributions can be outlined as follows: \u2022 The LLMRec is the pioneering work that using LLMs for graph augmentation in recommender by augmenting: user-item interaction edges, ii) item node attributes, iii) user node profiles. \u2022 The proposed LLMRec addresses the scarcity of implicit feedback signals by enabling LLMs to reason explicitly about user-item\n\u2022 The LLMRec is the pioneering work that using LLMs for graph augmentation in recommender by augmenting: user-item interaction edges, ii) item node attributes, iii) user node profiles. \u2022 The proposed LLMRec addresses the scarcity of implicit feedback signals by enabling LLMs to reason explicitly about user-item interaction patterns. Additionally, it resolves the low-quality side information issue through user/item attribute generation and a denoised augmentation robustification mechanism with the noisy feedback pruning and MAE-based feature enhancement. \u2022 Our method has been extensively evaluated on real-world datasets demonstrating its superiority over state-of-the-art baseline methods. The results highlight the effectiveness of our approach in\nimproving recommendation accuracy and addressing sparsity issues. Furthermore, in-depth analysis and ablation studies provide valuable insights into the impact of our LLM-enhanced data augmentation strategies, further solidifying the model efficacy.\n# 2 PRELIMINARY\nRecommendation with Graph Embedding. Collaborative filtering (CF) learns from sparse implicit feedback E+, with the aim of learning collaborative ID-corresponding embeddings E\ud835\udc62, E\ud835\udc56for recommender prediction, given user \ud835\udc62\u2208U and item \ud835\udc56\u2208I. Recent advanced recommenders employ GNNs to model complex high-order[37] u-i relation by taking E+ as edges of sparse interactive graph. Therefore, the CF process can be separated into two stages, bipartite graph embedding, and u-i prediction. Optimizing collaborative graph embeddings E = {E\ud835\udc62, E\ud835\udc56} aims to maximize the posterior estimator with E+, which is formally presented below:\n(1)\nHere, \ud835\udc5d(E|E+) is to encode as much u-i relation from E+ into E\ud835\udc62, E\ud835\udc56 as possible for accurate u-i prediction \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56= e\ud835\udc62\u00b7 e\ud835\udc56. Recommendation with Side Information. However, sparse interactions in E+ pose a challenge for optimizing the embeddings. To handle data sparsity, many efforts introduced side information in form of node features F, by taking recommender encoder \ud835\udc53\u0398 as feature graph. The learning process of the \ud835\udc53\u0398 (including E\ud835\udc62, E\ud835\udc56and feature encoder) with side information F is formulated as maximizing the posterior estimator \ud835\udc5d(\u0398|F, E+):\n\ud835\udc53\u0398 will output the final representation h contain both collaborative signals from E and side information from F, i.e., h = \ud835\udc53\u0398(f, E+).\n\ud835\udc53\u0398 will output the final representation h contain both collaborative signals from E and side information from F, i.e., h = \ud835\udc53(f, E+).\nsignals from E and side information from F, i.e., h = \ud835\udc53\u0398(f, E+).\n# ( E) Recommendation with Data Augmentation. Despite signi cant progress in incorporating side information into recommend\nRecommendation with Data Augmentation. Despite significant progress in incorporating side information into recommender, introducing low-quality side information may even undermine the effectiveness of sparse interactions E+. To address this, our LLMRec focuses on user-item interaction feature graph augmentation, which involves LLM-augmented u-i interactive edges EA, and LLM-generated node features FA. The optimization target with augmented interaction feature graph is as:\n(3)\nThe recommender \ud835\udc53\u0398 input union of original and augmented data, which consist of edges {E+, EA} and node features {F, FA}, and output quality representation h to predicted preference scores \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56 by ranking the likelihood of user \ud835\udc62will interact with item \ud835\udc56.\n# 3 METHODOLOGY\nTo conduct LLM-based augmentation, in this section, we address these questions: Q1: How to enable LLMs to predict u-i interactive edges? Q2: How to enable LLMs to generate valuable content? Q3: How to incorporate augmented contents into original graph contents? Q4: How to make model robust to the augmented data?\n# 3.1 LLMs as Implicit Feedback Augmentor (Q1)\nTo directly confront the scarcity of implicit feedback, we employ LLM as a knowledge-aware sampler to sample pair-wise [34] u-i training data from a natural language perspective. This increases\npotential effective supervision signals and helps gain a better understanding of user preferences by integrating contextual knowledge into the u-i interactions. Specifically, we feed each user\u2019s historical interacted items with side information (e.g., year, genre) and an item candidates pool C\ud835\udc62= {\ud835\udc56\ud835\udc62,1,\ud835\udc56\ud835\udc62,2, ...,\ud835\udc56\ud835\udc62,| C\ud835\udc62|} into LLM. LLM then is expected to select items that user \ud835\udc62might be likely (\ud835\udc56+\ud835\udc62) or unlikely (\ud835\udc56\u2212\ud835\udc62) to interact with from C\ud835\udc62. Here, we introduce C\ud835\udc62 because LLMs can\u2019t rank all items. Selecting items from the limited candidate set recommended by the base recommender (e.g., MMSSL [45], MICRO [58]), is a practical solution. These candidates C\ud835\udc62are hard samples with high prediction score \u02c6\ud835\udc66\ud835\udc62\ud835\udc56to provide potential, valuable positive samples and hard negative samples. It is worth noting that we represent each item using textual format instead of ID-corresponding indexes [18]. This kind of representation offers several advantages: (1) It enables recommender to fully leverage the content in datasets, and (2) It intuitively reflects user preferences. The process of augmenting user-item interactive edges and incorporating it into the training data can be formalized as:\npotential effective supervision signals and helps gain a better understanding of user preferences by integrating contextual knowledge into the u-i interactions. Specifically, we feed each user\u2019s historical interacted items with side information (e.g., year, genre) and an item candidates pool C\ud835\udc62= {\ud835\udc56\ud835\udc62,1,\ud835\udc56\ud835\udc62,2, ...,\ud835\udc56\ud835\udc62,| C\ud835\udc62|} into LLM. LLM then is expected to select items that user \ud835\udc62might be likely (\ud835\udc56+\ud835\udc62) or unlikely (\ud835\udc56\u2212\ud835\udc62) to interact with from C\ud835\udc62. Here, we introduce C\ud835\udc62 because LLMs can\u2019t rank all items. Selecting items from the limited candidate set recommended by the base recommender (e.g., MMSSL [45], MICRO [58]), is a practical solution. These candidates C\ud835\udc62are hard samples with high prediction score \u02c6\ud835\udc66\ud835\udc62\ud835\udc56to provide potential, valuable positive samples and hard negative samples. It is worth noting that we represent each item using textual format instead of ID-corresponding indexes [18]. This kind of representation offers several advantages: (1) It enables recommender to fully leverage the content in datasets, and (2) It intuitively reflects user preferences. The process of augmenting user-item interactive edges and incorporating it into the training data can be formalized as: \ud835\udc56+ \ud835\udc62,\ud835\udc56\u2212 \ud835\udc62= \ud835\udc3f\ud835\udc3f\ud835\udc40(P\ud835\udc48\ud835\udc3c \ud835\udc62); E\ud835\udc35\ud835\udc43\ud835\udc45= E \u222aEA (4) where \ud835\udc56+\ud835\udc62,\ud835\udc56\u2212\ud835\udc62are positive and negative samples for BPR selected by LLMs from candidates C\ud835\udc62for user \ud835\udc62based on input prompt P\ud835\udc48\ud835\udc3c \ud835\udc62. The augmented dataset EA comprises pairwise training triplets (\ud835\udc62,\ud835\udc56+\ud835\udc62,\ud835\udc56\u2212\ud835\udc62), i.e., EA = {(\ud835\udc62,\ud835\udc56+\ud835\udc62,\ud835\udc56\u2212\ud835\udc62)|(\ud835\udc62,\ud835\udc56+\ud835\udc62) \u2208E+ A, (\ud835\udc62,\ud835\udc56\u2212\ud835\udc62) \u2208E\u2212 A}. The textual u-i augmentation prompt P\ud835\udc48\ud835\udc3c \ud835\udc62 encompasses different components: i) task description, ii) historical interactions, iii) candidates, and iv) output format description, as illustrated in Fig. 2 (a). The utilization of LLMs-based sampler in this study to some extent alleviate noise (i.e., false positive) and non-interacted items issue (i.e., false negative) [2, 16] exist in raw implicit feedback. In this context, (i) false positive are unreliable u-i interactions, which encompass items that were not genuinely intended by the user, such as accidental clicks or instances influenced by popularity bias [40]; (ii) false negative represented by non-interacted items, which may not necessarily indicate user dispreference but are conventionally treated as negative samples [3]. By taking LLMs as implicit feedback augmentor, LLMRec enables the acquisition of more meaningful and informative samples by leveraging the remarkable reasoning ability of LLMs with the support of LLMs\u2019 knowledge. The specific analysis is supported by theoretical discussion in Sec. 3.4.1. 3.2 LLM-based Side Information Augmentation 3.2.1 User Profiling & Item Attribute Enhancing (Q2). Leveraging knowledge base and reasoning abilities of LLMs, we propose to summarize user profiles by utilizing users\u2019 historical interactions and item information to overcome limitation of privacy. Additionally, the LLM-based item attributes generation aims to produce space-unified, and informative item attributes. Our LLM-based side information augmentation paradigm consists of two steps: \u2022 i) User/Item Information Refinement. Using prompts derived from the dataset\u2019s interactions and side information, we enable LLM to generate user and item attributes that were not originally part of the dataset. Specific examples are shown in Fig. 2(b)(c). \u2022 ii) LLM-enhanced Semantic Embedding. The augmented user and item information will be encoded as features and used as input for the recommender. Using LLM as an encoder offers efficient\n(4)\n( ) E E \u222aEA where \ud835\udc56+\ud835\udc62,\ud835\udc56\u2212\ud835\udc62are positive and negative samples for BPR selected by LLMs from candidates C\ud835\udc62for user \ud835\udc62based on input prompt P\ud835\udc48\ud835\udc3c \ud835\udc62. The augmented dataset EA comprises pairwise training triplets (\ud835\udc62,\ud835\udc56+\ud835\udc62,\ud835\udc56\u2212\ud835\udc62), i.e., EA = {(\ud835\udc62,\ud835\udc56+\ud835\udc62,\ud835\udc56\u2212\ud835\udc62)|(\ud835\udc62,\ud835\udc56+\ud835\udc62) \u2208E+ A, (\ud835\udc62,\ud835\udc56\u2212\ud835\udc62) \u2208E\u2212 A}. The textual u-i augmentation prompt P\ud835\udc48\ud835\udc3c \ud835\udc62 encompasses different components: i) task description, ii) historical interactions, iii) candidates, and iv) output format description, as illustrated in Fig. 2 (a). The utilization of LLMs-based sampler in this study to some extent alleviate noise (i.e., false positive) and non-interacted items issue (i.e., false negative) [2, 16] exist in raw implicit feedback. In this context, (i) false positive are unreliable u-i interactions, which encompass items that were not genuinely intended by the user, such as accidental clicks or instances influenced by popularity bias [40]; (ii) false negative represented by non-interacted items, which may not necessarily indicate user dispreference but are conventionally treated as negative samples [3]. By taking LLMs as implicit feedback augmentor, LLMRec enables the acquisition of more meaningful and informative samples by leveraging the remarkable reasoning ability of LLMs with the support of LLMs\u2019 knowledge. The specific analysis is supported by theoretical discussion in Sec. 3.4.1.\n# 3.2 LLM-based Side Information Augmentation\n# 3.2.1 User Profiling & Item Attribute Enhancing (Q2). L aging knowledge base and reasoning abilities of LLMs, we pro\naging knowledge base and reasoning abilities of LLMs, we propose to summarize user profiles by utilizing users\u2019 historical interactions and item information to overcome limitation of privacy. Additionally, the LLM-based item attributes generation aims to produce space-unified, and informative item attributes. Our LLM-based side information augmentation paradigm consists of two steps: \u2022 i) User/Item Information Refinement. Using prompts derived from the dataset\u2019s interactions and side information, we enable LLM to generate user and item attributes that were not originally part of the dataset. Specific examples are shown in Fig. 2(b)(c). \u2022 ii) LLM-enhanced Semantic Embedding. The augmented user and item information will be encoded as features and used as input for the recommender. Using LLM as an encoder offers efficient and state-of-the-art language understanding, enabling profiling user interaction preferences and debiasing item attributes.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3978/3978b2ed-4ad2-4023-9866-45729e631e04.png\" style=\"width: 50%;\"></div>\nFigure 1: The LLMRec framework: (1) Three types of data augmentation strategies: i) augmenting enhancing item attributes, and iii) user profiling. (2) Augmented training with and denoised data r\n<div style=\"text-align: center;\">Figure 1: The LLMRec framework: (1) Three types of data augmentation strategies: i) augmenting user-item interactions; ii) enhancing item attributes, and iii) user profiling. (2) Augmented training with and denoised data robustification mechanism.</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d523/d52383c4-ea82-44d3-bd28-74c485170473.png\" style=\"width: 50%;\"></div>\nFigure 2: Constructed prompt P\ud835\udc48\ud835\udc3c \ud835\udc62, P\ud835\udc48\ud835\udc62, P\ud835\udc3c \ud835\udc56for LLMs\u2019 completion including i) task description, ii) historical interactions, iii) candidates, and iv) output format description.\n<div style=\"text-align: center;\">Formally, the LLM-based side information augmentation is as: \ufffd</div>\n(5)\n( ) \u2212\u2192 A() where fA,\ud835\udc62, fA,\ud835\udc56, \u2208R\ud835\udc51\ud835\udc3f\ud835\udc3f\ud835\udc40are LLM-augmented user/item features with LLM\u2019s hidden dimension\ud835\udc51\ud835\udc3f\ud835\udc3f\ud835\udc40. The textual prompts P\ud835\udc48\ud835\udc62and P\ud835\udc3c \ud835\udc56 are used for attribute refinement for user \ud835\udc62and item \ud835\udc56, respectively. A\ud835\udc62and A\ud835\udc56represent generated textual attributes that to be encoded as features FA,\ud835\udc62, FA,\ud835\udc56using the embedding capability of \ud835\udc3f\ud835\udc3f\ud835\udc40(\u00b7).\n# \u2022 Augmented Semantic Projection. Linear layers with dro are employed to not only reduce the dimensionality of \n\ud835\udc53\u0398, we opt to treat FA as additional compositions added to the ID-corresponding embeddings (e\ud835\udc62, e\ud835\udc56). This allows flexibly adjust the influence of LLM-augmented features using scale factors and normalization. Formally, the FA\u2019s incorporation is presented as:\n\u2211\ufe01 \u2208M\u222a \u2225 \u2225 \u2211\ufe01 \u2208M\u222a \u2225 \u2225 The final prediction representations h\ud835\udc62and h\ud835\udc56, are in R1\u00d7\ud835\udc51. User profiles are A\ud835\udc62, debiased item attributes are A\ud835\udc56, and original multimodal side information is M. The specific type of feature is f\ud835\udc58. We adjust feature vectors using the aggregation weight \ud835\udf141 and \ud835\udc3f2 normalization to mitigate distribution gaps [8], ensurring the effectiveness of additional features within the recommender encoder.\n# 3.3 Training with Denoised Robustification (Q4)\nIn this section, we outline how LLMRec integrate augmented data into the optimization. We also introduce two quality constraint mechanisms for augmented edges and node features: i) Noisy useritem interaction pruning, and ii) MAE-based feature enhancement.\n3.3.1\n3.3.1 Augmented Optimization with Noise Pruning. We train our recommender using the union set E \u222aEA, which includes the original training set E and the LLM-augmented set EA. The objective is to optimize the BPR LBPR loss with increased supervisory signals E\u222aEA, aiming to enhance the recommender\u2019s performance by leveraging the incorporated LLM-enhanced user preference: \u2211\ufe01\n  EA \u2286{\ud835\udc3f\ud835\udc3f\ud835\udc40(P\ud835\udc62)|\ud835\udc62\u2208U}, |EA| = \ud835\udf143 \u2217\ud835\udc35 The training triplet (\ud835\udc62,\ud835\udc56+,\ud835\udc56\u2212) is selected from the union training set E \u222aEA. The predicted scores of positive-negative sample pairs are obtained through inner products of final representation h, i.e., \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56+ = h\ud835\udc62\u00b7 h\ud835\udc56+, \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56\u2212= h\ud835\udc62\u00b7 h\ud835\udc56\u2212. The augmented dataset EA is a subset of the overall LLM-generated data {\ud835\udc3f\ud835\udc3f\ud835\udc40(P\ud835\udc62)|\ud835\udc62\u2208U}, obtained by sampling. This is because excessive inclusion of pseudo label may lead to a degradation in result accuracy. The number of samples |EA| is controlled by the batch size \ud835\udc35and a rate \ud835\udf143. Weightdecay regularization |\u0398|2 weighted by\ud835\udf142, mitigates overfitting. \ud835\udf0e(\u00b7) is activation function sigmoid to introduce non-linearity. Noise Pruning. To enhance the effectiveness of augmented data, we prune out unreliable u-i interaction noise. Technically, the largest values before minus are discarded after sorting each iteration. This helps prioritize and emphasize relevant supervisory\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8353/8353e2ec-8800-48e8-a670-5393a7c3f997.png\" style=\"width: 50%;\"></div>\nFigure 3: (a) Implicit feedback encompasses both false positive and false negative samples. (b) The gradient \u2207of the BPR loss for positive \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56+ and negative \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56\u2212scores, despite having a large magnitude, can have an incorrect direction that notably impacts the robustness and effectiveness of training. signals while mitigating the influence of noise. Formally, the objective LBPR in Eq. 6 with noise pruning can be rewritten as follows: (1\u2212\ud835\udf144)\u2217|E\u222aEA | \u2211\ufe01 \ufffd\ufffd\n(7) op-\nThe function \ud835\udc46\ud835\udc5c\ud835\udc5f\ud835\udc61\ud835\udc34\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc51(\u00b7)[0 : \ud835\udc41] sorts values and selects the topN. The retained number \ud835\udc41is calculated by \ud835\udc41= (1 \u2212\ud835\udf144) \u00b7 |E \u222aEA|, where \ud835\udf144 is a rate. This approach allows for controlled pruning of loss samples, emphasizing relevant signals while reducing noise. This can avoid the impact of unreliable gradient backpropagation, thus making optimization more stable and effective.\n# .2 Enhancing Augmented Semantic Featur  mitigate the impact of noisy augmented features, w\nTo mitigate the impact of noisy augmented features, we employ the Masked Autoencoders (MAE) for feature enhancement [9]. Specifically, the masking technique is to reduce the model\u2019s sensitivity to features, and subsequently, the feature encoders are strengthened through reconstruction objectives. Formally, we select a subset of nodes \ufffd V \u2282V and mask their features using a mask token [MASK], denoted as f[\ud835\udc40\ud835\udc34\ud835\udc46\ud835\udc3e] (e.g., a learnable vector or mean pooling). The mask operation can be formulated as follows: \ufffd \ufffd\n\ufffd \ufffd \ufffd The augmented feature after the mask operation is denoted as\ufffdfA. It is substituted as mask token f[\ud835\udc40\ud835\udc34\ud835\udc46\ud835\udc3e] if the node is selected ( \ufffd V \u2282V), otherwise, it corresponds to the original augmented feature fA. To strengthen the feature encoder, we introduce the feature restoration loss L\ud835\udc39\ud835\udc45by comparing the masked attribute matrix\ufffdfA,\ud835\udc56with the original augmented feature matrix fA, with a scaling factor \ud835\udefe. The restoration loss function L\ud835\udc39\ud835\udc45is as follows: \u2211\ufe01 \ufffd\n(9)\n| \ufffd V| \u2211\ufe01 \u2208\ufffd V \u2225\ufffdA \u2225\u00b7 \u2225A \u2225 The final optimization objective is the weighted sum of the noisepruned BPR loss LBPR and the feature restoration (FR) loss L\ud835\udc39\ud835\udc45.\n# 3.4 In-Depth Analysis of our LLMRec\n3.4.1 LLM-based Augmentation Facilitates Optimization. This section highlights challenges addressed by LLM-based augmentation in recommender systems. False negatives (non-interacted interactions) and false positives (noise) as in Fig. 3 (a) can affect data\n<div style=\"text-align: center;\">Table 1: Statistics of the Original and Augmented Datasets</div>\nTable 1: Statistics of the Original and Augmented Datasets\nDataset\nNetflix\nMovieLens\nGraph\nOri.\n# U\n# I\n# E\n# U\n# I\n# E\n13187\n17366\n68933\n12495\n10322\n57960\nAug.\n# E:\n26374\n# E:\n24990\nOri. Sparsity\n99.970%\n99.915%\nAtt.\nOri.\nU: None\nI: year, title\nU: None I: title, year, genre\nAug. U[1536]: age, gender, liked genre, disliked genre,\nliked directors, country, and language\nI[1536]:\ndirector, country, language\nModality\nTextual[768], Visiual [512]\nTextual [768], Visiual [512]\n* Att. represents attribute, Ori. represents original, and Aug. represents augmentation. Number in [] represents the feature dimensionality.\nquality and result accuracy [3, 40]. Non-interacted items do not necessarily imply dislike [3], and interacted one may fail to reflect real user preferences due to accidental clicks or misleading titles, etc. Mixing of unreliable data with true user preference poses a challenge in build accurate recommender. Identifying and utilizing reliable examples is key to optimizing the recommender [2]. In theory, non-interacted and noisy interactions are used for negative \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56\u2212and positive \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56+ scores, respectively. However, their optimization directions oppose the true direction with large magnitudes, i.e., the model optimizes significantly in the wrong directions (as in Fig. 3 (b)), resulting in sensitive suboptimal results. Details. By computing the derivatives of the L\ud835\udc35\ud835\udc43\ud835\udc45( Eq. 10), we obtain positive gradients \u2207\ud835\udc62,\ud835\udc56+ = 1\u2212\ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62+\u2212) and negative gradients \u2207\ud835\udc62,\ud835\udc56\u2212= \ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62+\u2212) \u22121, where \u02c6\ud835\udc66\ud835\udc62+\u2212= \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56+ \u2212\u02c6\ud835\udc66\ud835\udc62,\ud835\udc56\u2212. Fig. 3 (b) illustrates these gradients and unveils some observations. Noisy interactions, although treated as positives, often have small values \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56+ as false positives, resulting in large gradients \u2207\ud835\udc62,\ud835\udc56+. Conversely, unobserved items, treated as negatives, tend to have relatively large values \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56\u2212 as false negatives, leading to small \u02c6\ud835\udc66\ud835\udc62+\u2212and large gradients \u2207\ud835\udc62,\ud835\udc56\u2212.\n\ud835\udc62\ud835\udc5b\ud835\udc5c\ud835\udc4f\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc52\ud835\udc51 \ufffd\ufffd\ufffd\ufffd\n= 1 \ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62+\u2212) \u00b7 \ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62+\u2212) \u00b7 (1 \u2212\ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62+\u2212)) \u00b7 1 = 1 \u2212\ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56+ \u2212\n= 1 \ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62+\u2212) \u00b7 \ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62+\u2212) \u00b7 (1 \u2212\ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62+\u2212)) \u00b7 1 = 1 \u2212\ud835\udf0e( \u02c6\ud835\udc66\ud835\udc62,\ud835\udc56+ \u2212\n\uf8f4\uf8f4\uf8f4\uf8f3 Conclusion. Wrong samples possess incorrect directions but are influential. LLM-based augmentation uses the natural language space to assist the ID vector space to provide a comprehensive reflection of user preferences. With real-world knowledge, LLMRec gets quality samples, reducing the impact of noisy and unobserved implicit feedback, improving accuracy, and speeding up convergence.\n# .2 Time Complexity. We analyze the time complexity. T ojection of augmented semantic features has a time complex\n3.4.2 Time Complexity. We analyze the time complexity. The projection of augmented semantic features has a time complexity of O(|U \u222aI| \u00d7 \ud835\udc51\ud835\udc3f\ud835\udc3f\ud835\udc40\u00d7 \ud835\udc51). The GNN encoder for graph-based collaborative context learning takes O(\ud835\udc3f\u00d7 |E+| \u00d7\ud835\udc51) time. The BPR loss function computation has a time complexity of O(\ud835\udc51\u00d7 |E \u222a EA|), while the feature reconstruction loss has a time complexity of O(\ud835\udc51\u00d7 | \ufffd V|), where | \ufffd V| represents the count of masked nodes.\n# 4 EVALUATION\nTo evaluate the performance of LLMRec, we conduct experiments, aiming to address the following research questions:\naiming to address the following research questions: \u2022 RQ1: How does our LLM-enhanced recommender perform compared to the current state-of-the-art baselines? \u2022 RQ2: What is the impact of key components on the performance? \u2022 RQ3: How sensitive is the model to different parameters? \u2022 RQ3: Are the data augmentation strategies in our LLMRec applicable across different recommendation models? \u2022 RQ5: What is the computational cost associated with our devised LLM-based data augmentation schemes?\n# 4.1 Experimental Settings\n4.1.1 Datasets. We perform experiments on publicly available datasets, i.e., Netflix and MovieLens, which include multi-modal side information. Tab. 1 presents statistical details for both the original and augmented datasets for both user and item domains. MovieLens. We utilize the MovieLens dataset derived from ML-10M1. Side information includes movie title, year, and genre in textual format. Visual content consists of movie posters obtained through web crawling by ourselves. Netflix. We collected its multi-model side information through web crawling. The implicit feedback and basic attribute are sourced from the Netflix Prize Data2 on Kaggle. For both datasets, CLIP-ViT[31] is utilized to encode visual features. LLM-based Data Augmentation. The study employs the OpenAI package, accessed through LLMs\u2019 APIs, for augmentation. The OpenAI Platform documentation provides details3. Augmented implicit feedback is generated using the \"gpt-3.5-turbo-0613\" chat completion model. Item attributes such as directors, country, and language are gathered using the same model. User profiling, based on the \"gpt-3.5-turbo-16k\" model, includes age, gender, preferred genre, disliked genre, preferred directors, country, and language. Embedding is performed using the \"text-embedding-ada-002\" model. The approximate cost of augmentation strategies on two datasets is 15.65 USD, 20.40 USD, and 3.12 USD, respectively.\n# 4.1.2 Implementation Details. The experiments are conduc\non a 24 GB Nvidia RTX 3090 GPU using PyTorch[29] for code implementation. The AdamW optimizer[25] is used for training, with different learning rate ranges of [5\ud835\udc52\u22125, 1\ud835\udc52\u22123] and [2.5\ud835\udc52\u22124, 9.5\ud835\udc52\u22124] for Netflix and MovieLens, respectively. Regarding the parameters of the LLMs, we choose the temperature from larger values {0.0, 0.6, 0.8, 1 } to control the randomness of the generated text. The value of top-p is selected from smaller values {0.0, 0.1, 0.4, 1} to encourage probable choices. The stream is set to false to ensure the completeness of responses. For more details on the parameter analysis, please refer to Section 4.4. To maintain fairness, both our method and the baselines employ a unified embedding size of 64.\n# .1.3 Evaluation Protocols. We evaluate our approach in th op-K item recommendation task using three common metri\ntop-K item recommendation task using three common metrics: Recall (R@k), Normalized Discounted Cumulative Gain (N@k), and Precision (P@k). To avoid potential biases from test sampling, we employ the all-ranking strategy[47, 49]. We report averaged results from five independent runs, setting K to 10, 20, and 50 (reasonable\n1https://files.grouplens.org/datasets/movielens/ml-10m-README.html 2https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data 3https://platform.openai.com/docs/api-reference\nfor all-ranking). Statistical significance analysis is conducted by calculating \ud835\udc5d-values against the best-performing baseline.\n4.1.4 Baseline Description. Four distinct groups of baseline methods for thorough comparison. i) General CF Methods: MFBPR [34], NGCF [41] and LightGCN [11]. ii) Methods with Side Information: VBPR [10], MMGCN [50] and GRCN [49]. iii) Data Augmentation Methods: LATTICE [59]. iv) Self-supervised Methods: CLCRec [48], MMSSL [45] and MICRO [58].\n# 4.2 Performance Comparison (RQ1)\nTab. 2 compares our proposed LLMRec method with baselines. \u2022 Overall Model Superior Performance. Our LLMRec outperforms the baselines by explicitly augmenting u-i interactive edges and enhancing the quality of side information. It is worth mentioning that our model based on LATTICE\u2019s [59] encoder, consisting of a ID-corresponding encoder and a feature encoder. This improvement underscores the effectiveness of our framework. \u2022 Effectiveness of Side Information Incorporation. The integration of side information significantly empowers recommenders. Methods like MMSSL [45] and MICRO [58] stand out for their effective utilization of multiple modalities of side information and GNNs. In contrast, approaches rely on limited content, such as VBPR [10] using only visual features, or CFbased architectures like NGCF [41], without side information, yield significantly diminished results. This highlights the importance of valuable content, as relying solely on ID-corresponding records fails to capture the complete u-i relationships. \u2022 Inaccurate Augmentation yields Limited Benefits. Existing methods, such as LATTICE[59], MICRO[58] that also utilize side information for data augmentation have shown limited improvements compared to our LLMRec. This can be attributed to two main factors: (1) The augmentation of side information with homogeneous relationships (e.g., i-i or u-u) may introduce noise, which can compromise the precise of user preferences. (2) These methods often not direct augmentation of u-i interaction data. \u2022 Advantage over SSL Approaches. Self-supervised models like, MMSSL[45], MICRO[58], have shown promising results in addressing sparsity through SSL signals. However, they do not surpass the performance of LLMRec, possibly because their augmented self-supervision signals may not align well with the target task of modeling u-i interactions. In contrast, we explicitly tackle the scarcity of training data by directly establishing BPR triplets.\n# 4.3 Ablation and Effectiveness Analyses (RQ2)\nWe conduct an ablation study of our proposed LLMRec approach to validate its key components, and present the results in Table 3.\n# 4.3.1 Effectiveness of Data Augmentation Strategies.\n\u2022 (1). w/o-u-i: Disabling the LLM-augmented implicit feedback EA results in a significant decrease. This indicates that LLMRec increases the potential supervision signals by including contextual knowledge, leading to a better grasp of user preferences. \u2022 (2). w/o-u: Removing our augmentor for user profiling result in a decrease in performance, indicating that our LLM-enhanced user side information can effectively summarize useful user preference profile using historical interactions and item-end knowledge.\n<div style=\"text-align: center;\">ble 2: Performance comparison on different datasets in terms of Recall@10/20/50, and NDCG@10/20/50, and Precision@20.</div>\nBaseline\nNetflix\nMovieLens\nR@10\nN@10\nR@20\nN@20\nR@50\nN@50\nP@20\nR@10\nN@10\nR@20\nN@20\nR@50\nN@50\nP@20\nGeneral Collaborative Filtering Methods\nMF-BPR\n0.0282\n0.0140\n0.0542\n0.0205\n0.0932\n0.0281\n0.0027\n0.1890\n0.0815\n0.2564\n0.0985\n0.3442\n0.1161\n0.0128\nNGCF\n0.0347\n0.0161\n0.0699\n0.0235\n0.1092\n0.0336\n0.0032\n0.2084\n0.0886\n0.2926\n0.1100\n0.4262\n0.1362\n0.0146\nLightGCN\n0.0352\n0.0160\n0.0701\n0.0238\n0.1125\n0.0339\n0.0032\n0.1994\n0.0837\n0.2660\n0.1005\n0.3692\n0.1209\n0.0133\nRecommenders with Side Information\nVBPR\n0.0325\n0.0142\n0.0553\n0.0199\n0.1024\n0.0291\n0.0028\n0.2144\n0.0929\n0.2980\n0.1142\n0.4076\n0.1361\n0.0149\nMMGCN\n0.0363\n0.0174\n0.0699\n0.0249\n0.1164\n0.0342\n0.0033\n0.2314\n0.1097\n0.2856\n0.1233\n0.4282\n0.1514\n0.0147\nGRCN\n0.0379\n0.0192\n0.0706\n0.0257\n0.1148\n0.0358\n0.0035\n0.2384\n0.1040\n0.3130\n0.1236\n0.4532\n0.1516\n0.0150\nData Augmentation Methods\nLATTICE\n0.0433\n0.0181\n0.0737\n0.0259\n0.1301\n0.0370\n0.0036\n0.2116\n0.0955\n0.3454\n0.1268\n0.4667\n0.1479\n0.0167\nMICRO\n0.0466\n0.0196\n0.0764\n0.0271\n0.1306\n0.0378\n0.0038\n0.2150\n0.1131\n0.3461\n0.1468\n0.4898\n0.1743\n0.0175\nSelf-supervised Methods\nCLCRec\n0.0428\n0.0217\n0.0607\n0.0262\n0.0981\n0.0335\n0.0030\n0.2266\n0.0971\n0.3164\n0.1198\n0.4488\n0.1459\n0.0158\nMMSSL\n0.0455\n0.0224\n0.0743\n0.0287\n0.1257\n0.0383\n0.0037\n0.2482\n0.1113\n0.3354\n0.1310\n0.4814\n0.1616\n0.0170\nLLMRec\n0.0531\n0.0272\n0.0829\n0.0347\n0.1382\n0.0456\n0.0041\n0.2603\n0.1250\n0.3643\n0.1628\n0.5281\n0.1901\n0.0186\np-value\n2.9\ud835\udc52\u22124\n3.0\ud835\udc52\u22123\n9.4\ud835\udc52\u22125\n1.5\ud835\udc52\u22123\n2.8\ud835\udc52\u22125\n2.2\ud835\udc52\u22123\n3.4\ud835\udc52\u22125\n2.8\ud835\udc52\u22125\n1.6\ud835\udc52\u22122\n3.1\ud835\udc52\u22123\n4.1\ud835\udc52\u22124\n1.9\ud835\udc52\u22123\n1.3\ud835\udc52\u22122\n1.8\ud835\udc52\u22123\nImprov.\n13.95%\n21.43%\n8.51%\n20.91%\n5.82%\n19.06%\n7.89%\n4.88%\n10.52%\n5.26%\n10.90%\n7.82%\n9.06%\n6.29%\n<div style=\"text-align: center;\">Table 3: Ablation study on key components (i.e., data augmentation strategies, denoised data robustification mechanisms)</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f61a/f61a983c-3af6-481b-bee3-208c3e381219.png\" style=\"width: 50%;\"></div>\nMetrics\nR@10 N@10 R@20 N@20 R@50 N@50 P@20\nAug.\nw/o-u-i\n0.0477 0.0239 0.0791 0.0317 0.1376 0.0432 0.0037\nw/o-u\n0.0423 0.0196 0.0656 0.0255 0.1192 0.0360 0.0033\nw/o-u&i 0.0309 0.0127 0.0602 0.0202 0.1051 0.0289 0.0030\nQ. C.\nw/o-prune 0.0504 0.0258 0.0786 0.0328 0.1363 0.0447 0.0039\nw/o-QC\n0.0488 0.0244 0.0786 0.0318 0.1279 0.0416 0.0038\nLLMRec 0.05310.0272 0.08290.0347 0.13820.0456 0.0041\n* \u201cAug\u201d: data augmentation operations; Q. C.: denoised data robustification.\n\u2022 (3). w/o-u&i: when we remove the augmented side information for both users and items (FA,\ud835\udc62, FA,\ud835\udc56,1), lower recommendation accuracy is observed. This finding indicates that the LLM-based augmented side information provides valuable augmented data to the recommender system, assisting in obtaining quality and informative representations.\n# 4.3.2 Impact of the Denoised Data Robustification.\n\u2022 w/o-prune: The removal of noise pruning results in worse performance. This suggests that the process of removing noisy implicit feedback signals helps prevent incorrect gradient descent. \u2022 w/o-QC: The performance suffer when both the limits on implicit feedback and semantic feature quality are simultaneously removed (i.e., w/o-prune + w/o-MAE). This indicates the benefits of our denoised data robustification mechanism by integrating noise pruning and semantic feature enhancement.\n# 4.4 Hyperparameter Analysis (RQ3) 4.4.1 Parameters Affecting Augmented Data Quality.\n Temperature \ud835\udf0fof LLM: The temperature parameter \ud835\udf0faffects text randomness. Higher values (>1.0) increase diversity and creativity, while lower values (<0.1) result in more focus. We use \ud835\udf0ffrom {0, 0.6, 0.8, 1}. As shown in Table 4, increasing \ud835\udf0finitially improves most metrics, followed by a decrease.\nPara.\nTemperature \ud835\udf0f\nTop-p \ud835\udf0c\nMetrics\n\ud835\udf0f=0\n\ud835\udf0f=0.6\n\ud835\udf0f=0.8\n\ud835\udf0f=1\n\ud835\udf0c=0\n\ud835\udf0c=0.1\n\ud835\udf0c=0.4\n\ud835\udf0c=1\nR@10 0.0558\u21910.0531 0.0553\u21910.0531= 0.0537\u21910.0531 0.0520\u21930.0531=\nR@20 0.0808\u21930.0829 0.0813\u21930.0775\u21930.0802\u21930.0829 0.0796\u21930.0770\u2193\nR@50 0.1344\u21930.1382 0.1360\u21930.1312\u21930.1360\u21930.1382 0.1344\u21930.1333\u2193\n<div style=\"text-align: center;\">Table 5: Analysis of key parameter (i.e., # candidate |C| ) for LLM w.r.t implicit feedback augmentation EA.</div>\n EA\nData\nNetflix\nMovieLens\nMetrics\n| C|=3\n| C|=10\n| C|=30\n| C|=3\n| C|=10\n| C|=30\nR@20\n0.0786 \u2193\n0.0829\n0.0808 \u2193\n0.3567 \u2193\n0.3643\n0.3695 \u2191\nN@20\n0.0314 \u2193\n0.0347\n0.0330 \u2193\n0.1603 \u2193\n0.1628\n0.1614 \u2193\nP@20\n0.0039 \u2193\n0.0041\n0.0040 \u2193\n0.0179 \u2193\n0.0186\n0.0182 \u2193\n\u2022 Top-p \ud835\udc5dof LLM: Top-p Sampling[12] selects tokens based on a threshold determined by the top-p parameter \ud835\udc5d. Lower \ud835\udc5dvalues prioritize likely tokens, while higher values encourage diversity. We use \ud835\udc5dfrom {0, 0.1, 0.4, 1} and smaller \ud835\udc5dvalues tend to yield better results, likely due to avoiding unlisted candidate selection. Higher \ud835\udf0cvalues cause wasted tokens due to repeated LLM inference. \u2022 # of Candidate C: We use C to limit item candidates for LLM-based recommendation. {3, 10, 30} are explored due to cost limitations, and Table 5 shows that C = 10 yields the best results. Small values limit selection, and large values increase recommendation difficulty. \u2022 Prune Rate \ud835\udf144: LLMRec uses \ud835\udf144 to control noise in augmented training data to be pruned. We set \ud835\udf144 to {0.0, 0.2, 0.4, 0.6, 0.8} on both datasets. As shown in Fig. 4 (a), \ud835\udf144 = 0 yields the worst result, highlighting the need to constrain noise in implicit feedback.\n# 4.4.2 Sensitivity of Recommenders to the Augmented Data.\n # of Augmented Samples per Batch |EA| : LLMRec uses \ud835\udf143 and batch size \ud835\udc35to control the number of augmented BPR training data samples per batch. \ud835\udf143 is set to {0.0, 0.1, 0.2, 0.3, 0.4} on Netflix and {0.0, 0.2, 0.4, 0.6, 0.8} on MovieLens. Suboptimal results occur\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9a57/9a574b3f-61b7-4399-a173-4c8db2fdf5bd.png\" style=\"width: 50%;\"></div>\nFigure 4: Impact of hyperparameters (i.e., prune rate \ud835\udf144, # augmented BPR training data |EA|, and augmented feature incorporate scale \ud835\udf141).\nTable 6: Model-agnostic experiment to evaluate the effectiveness of LLM-based data augmentation on different recommender in terms of R@20, N@20, and P@20.\n<div style=\"text-align: center;\">Table 6: Model-agnostic experiment to evaluate the effectiveness of LLM-based data augmentation on different recommender in terms of R@20, N@20, and P@20.</div>\nMethod\nLATTICE\nMICRO\nMMSSL\nAug.\nR@20\n0.0821 \u219111.40%\n0.0835 \u21919.29%\n0.0833 \u219111.11%\nN@20\n0.0287 \u219110.81%\n0.0301 \u219111.07%\n0.0313 \u21919.06%\nP@20\n0.0039 \u21918.33%\n0.0041 \u21917.89%\n0.0041 \u219110.81%\nwhen \ud835\udf143 is zero or excessively large. Increasing diversity and randomness can lead to a more robust gradient descent. \u2022 Scale \ud835\udf142 for Incorporating Augmented Features: LLMRec uses \ud835\udf142 to control feature magnitude, with values set to {0.0, 0.8, 1.6, 2.4, 3.2} on Netflix and {0.0, 0.1, 0.2, 0.3, 0.4} on MovieLens. Optimal results depend on the data, with suboptimal outcomes occurring when \ud835\udf142 is too small or too large, as shown in Fig. 4 (c).\n# 4.5 Model-agnostic Property (RQ4)\nWe conducted model-agnostic experiments on Netflix to validate the applicability of our data augmentation. Specifically, we incorporated the augmented implicit feedback EA and features FA,\ud835\udc62, FA,\ud835\udc56into baselines MICRO, MMSSL, and LATTICE. As shown in Tab. 6, our LLM-based data improved the performance of all models, demonstrating their effectiveness and reusability. Some results didn\u2019t surpass our model, maybe due to: i) the lack of a quality constraint mechanism to regulate the stability and quality of the augmented data, and ii) the absence of modeling collaborative signals in the same vector space, as mentioned in Sec. 3.2.2.\n# 4.6 Cost/Improvement Conversion Rate (RQ5)\nTo evaluate the cost-effectiveness of our augmentation strategies, we compute the CIR as presented in Tab. 7. The CIR is compared with the ablation of three data augmentation strategies and the best baseline from Tab. 3 and Tab. 2. The cost of the implicit feedback augmentor refers to the price of GPT-3.5 turbo 4K. The cost of side information augmentation includes completion (using GPT-3.5 turbo 4K or 16K) and embedding (using text-embedding-ada-002). We utilize the HuggingFace API tool for tokenizer and counting. The results in Tab. 7 show that \u2019U\u2019 (LLM-based user profiling) is the most cost-effective strategy, and the overall investment is worthwhile.\nTable 7: Comparison of the cost and improvement rate(CIR) of data augmentation strategies and LLMRec. \u2019Cost\u2019: expenditure of utilizing LLM, \u2019Imp.\u2019: the average improvement rate in R@10/N@10. \u2019CIR\u2019: the ratio of improvement to cost.\nin R@10/N@10. \u2019CIR\u2019: the ratio of improvement to cost.\nR@10\nN@10\nCost(USD)\nImp.(%)\nCIR(%)\nImp.(%)\nCIR(%)\nU\n10.92\n25.53\n233.79\n38.78\n355.13\nI\n1.96\n2.31\n117.86\n1.12\n57.14\nU-I\n8.26\n11.32\n137.05\n13.81\n167.19\nLLMAug\n21.14\n13.95\n65.99\n21.43\n101.37\n# 5 RELATED WORK\nContent-based Recommendation. Existing recommenders have explored the use of auxiliary multi-modal side knowledge[21, 22], with methods like VBPR [10] combine traditional CF with visual features, while MMGCN [50], GRCN [49] leverage GNNs to capture modality-aware higher-order collaborative signals. Recent approaches MMSSL [45] and MICRO [58] align modal signals with collaborative signals through contrastive SSL[19], revealing the informative aspects of modal signals that benefit recommendations. However, the data noise, heterogeneity, and incompleteness can introduce bias. To overcome this, LLMRec explores LLM-based augmentation to improve the quality of the data. Large Language Models (LLMs) for Recommendation. LLMs have gained attention in recommendation systems, with various efforts to use them for modeling user behavior [14, 32, 42]. LLMs have been employed as an inference model in diverse recommendation tasks, including rating prediction, sequential recommendation, and direct recommendation [1, 5, 6, 57]. Some efforts [35, 38] also tried to utilize LLMs to model structure relations. However, most previous methods primarily used LLMs as recommenders, abandoning the base model that has been studied for decades. We combine LLM-based data augmentation with classic CF, achieving both result assurance and enhancement concurrently. Data Augmentation for Recommendation. Extensive research has explored data augmentation in recommendation systems [13, 16]. Various operations, such as permutation, deletion, swap, insertion, and duplication, have been proposed for sequential recommendation [24, 30]. Commonly used techniques include counterfactual reasoning [43, 60] and contrastive learning [23]. Our LLMRec use LLMs as an inference model to augment edge and enhance node features by leveraging consensus knowledge from the large model.\n# 6 CONCLUSION\nThis study focuses on the design of LLM-enhanced models to address the challenges of sparse implicit feedback signals and lowquality side information by profiling user interaction preferences and debiasing item attributes. To ensure the quality of augmented data, a denoised augmentation robustification mechanism is introduced. The effectiveness of LLMRec is supported by theoretical analysis and experimental results, demonstrating its superiority over state-of-the-art recommendation techniques on benchmark datasets. Future directions for investigation include integrating causal inference into side information debiasing and exploring counterfactual factors for context-aware user preference.\n# REFERENCES\n[1] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation. arXiv preprint arXiv:2305.00447 (2023). [2] Chong Chen, Weizhi Ma, Min Zhang, et al. 2023. Revisiting negative sampling vs. non-sampling in implicit recommendation. TOIS 41, 1 (2023), 1\u201325. [3] Chong Chen, Min Zhang, Yongfeng Zhang, et al. 2020. Efficient neural matrix factorization without sampling for recommendation. TOIS 38, 2 (2020), 1\u201328. [4] Mengru Chen, Chao Huang, Lianghao Xia, Wei Wei, et al. 2023. Heterogeneous graph contrastive learning for recommendation. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining. 544\u2013552. [5] Zheng Chen. 2023. PALR: Personalization Aware LLMs for Recommendation. arXiv preprint arXiv:2305.07622 (2023). [6] Sunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao Zhang, and Jun Xu. 2023. Uncovering ChatGPT\u2019s Capabilities in Recommender Systems. arXiv preprint arXiv:2305.02182 (2023). [7] Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019. Graph neural networks for social recommendation. In ACM International World Wide Web Conference. 417\u2013426. [8] Xinyu Fu, Jiani Zhang, et al. 2020. Magnn: Metapath aggregated graph neural network for heterogeneous graph embedding. In ACM International World Wide Web Conference. 2331\u20132341. [9] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. 2022. Masked autoencoders are scalable vision learners. In CVPR. 16000\u201316009. [10] Ruining He and Julian McAuley. 2016. VBPR: visual bayesian personalized ranking from implicit feedback. In AAAI, Vol. 30. [11] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for recommendation. In ACM SIGIR Conference on Research and Development in Information Retrieval. 639\u2013648. [12] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751 (2019). [13] Tinglin Huang, Yuxiao Dong, Ming Ding, Zhen Yang, Wenzheng Feng, Xinyu Wang, and Jie Tang. 2021. MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining. [14] Wang-Cheng Kang, Jianmo Ni, Nikhil Mehta, Maheswaran Sathiamoorthy, Lichan Hong, et al. 2023. Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction. arXiv preprint arXiv:2305.06474 (2023). [15] Hyeyoung Ko, Suyeon Lee, Yoonseo Park, and Anna Choi. 2022. A survey of recommendation systems: recommendation models, techniques, and application fields. Electronics 11, 1 (2022), 141. [16] Dongha Lee, SeongKu Kang, Hyunjun Ju, et al. 2021. Bootstrapping user and item representations for one-class collaborative filtering. In ACM SIGIR Conference on Research and Development in Information Retrieval. 317\u2013326. [17] Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and Julian McAuley. 2023. Text Is All You Need: Learning Language Representations for Sequential Recommendation. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining. [18] Jinming Li, Wentao Zhang, Tian Wang, Guanglei Xiong, et al. 2023. GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation. arXiv preprint arXiv:2304.03879 (2023). [19] Ke Liang, Yue Liu, Sihang Zhou, Wenxuan Tu, Yi Wen, Xihong Yang, Xiangjun Dong, and Xinwang Liu. 2023. Knowledge Graph Contrastive Learning Based on Relation-Symmetrical Structure. IEEE Transactions on Knowledge and Data Engineering (2023), 1\u201312. https://doi.org/10.1109/TKDE.2023.3282989 [20] Ke Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, and Xinwang Liu. 2023. Learn from relational correlations and periodic events for temporal knowledge graph reasoning. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval Conference on Research and Development in Information Retrieval. 1559\u20131568. [21] Ke Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu, and Fuchun Sun. 2022. Reasoning over different types of knowledge graphs: Static, temporal and multi-modal. arXiv preprint arXiv:2212.05767 (2022). [22] Ke Liang, Sihang Zhou, Yue Liu, Lingyuan Meng, Meng Liu, and Xinwang Liu. 2023. Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning. arXiv preprint arXiv:2307.03591 (2023). [23] Zhiwei Liu, Yongjun Chen, Jia Li, Philip S Yu, Julian McAuley, and Caiming Xiong. 2021. Contrastive self-supervised sequential recommendation with robust augmentation. arXiv preprint arXiv:2108.06479 (2021). [24] Zhiwei Liu, Ziwei Fan, et al. 2021. Augmenting sequential recommendation with pseudo-prior items via reversely pre-training transformer. In ACM SIGIR Conference on Research and Development in Information Retrieval. 1608\u20131612. [25] Ilya Loshchilov et al. 2017. Decoupled weight decay regularization. In ICLR. [26] Chang Meng, Chenhao Zhai, Yu Yang, Hengyu Zhang, and Xiu Li. 2023. Parallel Knowledge Enhancement based Framework for Multi-behavior Recommendation.\nIn Proceedings of the 32nd ACM International Conference on Information and Knowledge Management. 1797\u20131806. [27] Chang Meng, Hengyu Zhang, Wei Guo, Huifeng Guo, Haotian Liu, Yingxue Zhang, Hongkun Zheng, Ruiming Tang, Xiu Li, and Rui Zhang. 2023. Hierarchical Projection Enhanced Multi-Behavior Recommendation. In Proceedings of the 29th ACM SIGACM SIGKDD Conference on Knowledge Discovery and Data Mining Conference on Knowledge Discovery and Data Mining. 4649\u20134660. [28] Chang Meng, Ziqi Zhao, Wei Guo, Yingxue Zhang, Haolun Wu, Chen Gao, Dong Li, Xiu Li, and Ruiming Tang. 2023. Coarse-to-fine knowledge-enhanced multi-interest learning framework for multi-behavior recommendation. ACM Transactions on Information Systems 42, 1 (2023), 1\u201327. [29] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, et al. 2019. Pytorch: An imperative style, high-performance deep learning library. Conference on Neural Information Processing Systems 32 (2019). [30] Aleksandr Petrov and Craig Macdonald. 2022. Effective and Efficient Training for Sequential Recommendation using Recency Sampling. In Recsys. 81\u201391. [31] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, et al. 2021. Learning transferable visual models from natural language supervision. In ICML. PMLR, 8748\u20138763. [32] Xubin Ren, Wei Wei, Lianghao Xia, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2023. Representation Learning with Large Language Models for Recommendation. arXiv preprint arXiv:2310.15950 (2023). [33] Xubin Ren, Lianghao Xia, Yuhao Yang, Wei Wei, Tianle Wang, Xuheng Cai, and Chao Huang. 2023. SSLRec: A Self-Supervised Learning Library for Recommendation. arXiv preprint arXiv:2308.05697 (2023). [34] Steffen Rendle, Christoph Freudenthaler, et al. 2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv preprint arXiv:1205.2618 (2012). [35] Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, Suqi Cheng, Dawei Yin, and Chao Huang. 2023. GraphGPT: Graph Instruction Tuning for Large Language Models. arXiv preprint arXiv:2310.13023 (2023). [36] Yijun Tian, Kaiwen Dong, Chunhui Zhang, Chuxu Zhang, and Nitesh V Chawla. 2023. Heterogeneous graph masked autoencoders. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 37. 9997\u201310005. [37] Yijun Tian, Shichao Pei, Xiangliang Zhang, Chuxu Zhang, and Nitesh V Chawla. 2023. Knowledge Distillation on Graphs: A Survey. arXiv preprint arXiv:2302.00219 (2023). [38] Yijun Tian, Huan Song, Zichen Wang, Haozhu Wang, Ziqing Hu, Fang Wang, Nitesh V Chawla, and Panpan Xu. 2023. Graph neural prompting with large language models. arXiv preprint arXiv:2309.15427 (2023). [39] Yijun Tian, Chuxu Zhang, Zhichun Guo, Xiangliang Zhang, and Nitesh Chawla. 2022. Learning mlps on graphs: A unified view of effectiveness, robustness, and efficiency. In The Eleventh International Conference on Learning Representations. [40] Wenjie Wang, Fuli Feng, Xiangnan He, Liqiang Nie, and Tat-Seng Chua. 2021. Denoising implicit feedback for recommendation. In WSDM. 373\u2013381. [41] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. In ACM SIGIR Conference on Research and Development in Information Retrieval. 165\u2013174. [42] Xiaolei Wang, Xinyu Tang, Wayne Xin Zhao, Jingyuan Wang, and Ji-Rong Wen. 2023. Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models. arXiv preprint arXiv:2305.13112 (2023). [43] Zhenlei Wang, Jingsen Zhang, Hongteng Xu, Xu Chen, Yongfeng Zhang, Wayne Xin Zhao, and Ji-Rong Wen. 2021. Counterfactual data-augmented sequential recommendation. In ACM SIGIR Conference on Research and Development in Information Retrieval. 347\u2013356. [44] Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, and Dawei Yin. 2022. Contrastive meta learning with behavior multiplicity for recommendation. In Proceedings of the fifteenth ACM international conference on web search and data mining. 1120\u20131128. [45] Wei Wei, Chao Huang, Lianghao Xia, and Chuxu Zhang. 2023. Multi-Modal Self-Supervised Learning for Recommendation. In ACM International World Wide Web Conference. 790\u2013800. [46] Wei Wei, Lianghao Xia, and Chao Huang. 2023. Multi-Relational Contrastive Learning for Recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems. 338\u2013349. [47] Yinwei Wei, Xiang Wang, et al. 2021. Hierarchical user intent graph network for multimedia recommendation. Transactions on Multimedia (TMM) (2021). [48] Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, et al. 2021. Contrastive learning for cold-start recommendation. In ACM MM. 5382\u20135390. [49] Yinwei Wei, Xiang Wang, Liqiang Nie, Xiangnan He, and Tat-Seng Chua. 2020. Graph-refined convolutional network for multimedia recommendation with implicit feedback. In MM. 3541\u20133549. [50] Yinwei Wei, Xiang Wang, Liqiang Nie, Xiangnan He, Richang Hong, and Tat-Seng Chua. 2019. MMGCN: Multi-modal graph convolution network for personalized recommendation of micro-video. In MM. 1437\u20131445. [51] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, et al. 2021. Selfsupervised graph learning for recommendation. In ACM SIGIR Conference on Research and Development in Information Retrieval. 726\u2013735.\n[52] Zixuan Yi, Xi Wang, Iadh Ounis, and Craig Macdonald. 2022. Multi-modal Graph Contrastive Learning for Micro-video Recommendation. In ACM SIGIR Conference on Research and Development in Information Retrieval. 1807\u20131811. [53] Yuxin Ying, Fuzhen Zhuang, Yongchun Zhu, Deqing Wang, and Hongwei Zheng. 2023. CAMUS: Attribute-Aware Counterfactual Augmentation for Minority Users in Recommendation. In ACM International World Wide Web Conference. 1396\u20131404. [54] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung Nguyen. 2022. Are graph augmentations necessary? Simple graph contrastive learning for recommendation. In ACM SIGIR Conference on Research and Development in Information Retrieval. 1294\u20131303. [55] Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023. Where to go next for recommender systems? id-vs. modality-based recommender models revisited. In ACM SIGIR Conference on Research and Development in Information Retrieval. [56] Honglei Zhang, Fangyuan Luo, Jun Wu, Xiangnan He, and Yidong Li. 2023. LightFR: Lightweight federated recommendation with privacy-preserving matrix\nfactorization. ACM Transactions on Information Systems 41, 4 (2023), 1\u201328. [57] Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Recommendation as instruction following: A large language model empowered recommendation approach. arXiv preprint arXiv:2305.07001 (2023). [58] Jinghao Zhang, Yanqiao Zhu, Qiang Liu, et al. 2022. Latent structure mining with contrastive modality fusion for multimedia recommendation. TKDE (2022). [59] Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Shu Wu, et al. 2021. Mining Latent Structures for Multimedia Recommendation. In MM. 3872\u20133880. [60] Shengyu Zhang, Dong Yao, Zhou Zhao, et al. 2021. Causerec: Counterfactual user sequence synthesis for sequential recommendation. In ACM SIGIR Conference on Research and Development in Information Retrieval. 367\u2013377. [61] Ding Zou, Wei Wei, Xian-Ling Mao, Ziyang Wang, Minghui Qiu, Feida Zhu, and Xin Cao. 2022. Multi-level cross-view contrastive learning for knowledge-aware recommender system. In ACM SIGIR Conference on Research and Development in Information Retrieval. 1358\u20131368.\n",
    "paper_type": "method",
    "attri": {
        "background": "The problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information. However, this approach often introduces side effects such as noise, availability issues, and low data quality, which in turn hinder the accurate modeling of user preferences and adversely impact recommendation performance. In light of the recent advancements in large language models (LLMs), which possess extensive knowledge bases and strong reasoning capabilities, we propose a novel framework called LLMRec that enhances recommender systems by employing three simple yet effective LLM-based graph augmentation strategies.",
        "problem": {
            "definition": "The paper aims to solve the issue of sparse implicit feedback signals in recommendation systems, which limits the ability to capture user preferences accurately.",
            "key obstacle": "The main difficulty is the data sparsity and the quality issues associated with side information, which can introduce noise and hinder effective modeling."
        },
        "idea": {
            "intuition": "The idea is inspired by the natural language understanding capabilities of large language models, which can enhance the interaction graph in recommendation systems.",
            "opinion": "The proposed method, LLMRec, leverages LLMs to augment user-item interactions, enhance item attributes, and profile user preferences for better recommendations.",
            "innovation": "The innovation lies in using LLMs for explicit reasoning over user-item interactions and improving the quality of side information, which distinguishes LLMRec from existing methods."
        },
        "method": {
            "method name": "LLMRec",
            "method abbreviation": "LLMRec",
            "method definition": "LLMRec is a framework that incorporates three LLM-based strategies for augmenting recommendation systems, focusing on user-item interactions and side information.",
            "method description": "The method enhances recommendation accuracy by augmenting user-item interaction edges, improving item attributes, and conducting user profiling.",
            "method steps": [
                "Reinforce user-item interaction edges using LLMs.",
                "Enhance understanding of item node attributes.",
                "Conduct user profiling based on historical interactions."
            ],
            "principle": "The effectiveness of LLMRec is based on the ability of LLMs to reason over user-item interactions and improve the quality of side information."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted on publicly available datasets, specifically Netflix and MovieLens, which include multi-modal side information.",
            "evaluation method": "Performance was assessed using metrics like Recall, Normalized Discounted Cumulative Gain, and Precision, comparing LLMRec against state-of-the-art baseline methods."
        },
        "conclusion": "LLMRec effectively addresses the challenges of sparse implicit feedback and low-quality side information, demonstrating superior performance over existing recommendation techniques in benchmark datasets.",
        "discussion": {
            "advantage": "LLMRec stands out due to its ability to enhance recommendation accuracy by leveraging LLMs for data augmentation and improving side information quality.",
            "limitation": "The method may encounter challenges related to the potential introduction of noise in the augmented data and the reliance on the quality of the underlying LLM.",
            "future work": "Future research could explore integrating causal inference into side information debiasing and investigating counterfactual factors for context-aware user preferences."
        },
        "other info": {
            "info1": "The code and augmented data for LLMRec are publicly available at: https://github.com/HKUDS/LLMRec.git.",
            "info2": {
                "info2.1": "The approximate cost of augmentation strategies on the datasets is 15.65 USD for Netflix and 20.40 USD for MovieLens.",
                "info2.2": "Experiments utilized a 24 GB Nvidia RTX 3090 GPU and implemented using PyTorch."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information."
        },
        {
            "section number": "1.2",
            "key information": "The proposed method, LLMRec, leverages LLMs to augment user-item interactions, enhance item attributes, and profile user preferences for better recommendations."
        },
        {
            "section number": "2.1",
            "key information": "The paper aims to solve the issue of sparse implicit feedback signals in recommendation systems, which limits the ability to capture user preferences accurately."
        },
        {
            "section number": "3.2",
            "key information": "The innovation lies in using LLMs for explicit reasoning over user-item interactions and improving the quality of side information, which distinguishes LLMRec from existing methods."
        },
        {
            "section number": "4.1",
            "key information": "LLMRec is a framework that incorporates three LLM-based strategies for augmenting recommendation systems, focusing on user-item interactions and side information."
        },
        {
            "section number": "4.2",
            "key information": "The effectiveness of LLMRec is based on the ability of LLMs to reason over user-item interactions and improve the quality of side information."
        },
        {
            "section number": "10.1",
            "key information": "The method may encounter challenges related to the potential introduction of noise in the augmented data and the reliance on the quality of the underlying LLM."
        },
        {
            "section number": "10.2",
            "key information": "Future research could explore integrating causal inference into side information debiasing and investigating counterfactual factors for context-aware user preferences."
        }
    ],
    "similarity_score": 0.7862664136918917,
    "image": [
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/886e/886ec1b1-0b23-424a-8ad1-828866b44e9e.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3978/3978b2ed-4ad2-4023-9866-45729e631e04.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/d523/d52383c4-ea82-44d3-bd28-74c485170473.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8353/8353e2ec-8800-48e8-a670-5393a7c3f997.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f61a/f61a983c-3af6-481b-bee3-208c3e381219.png",
        "https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9a57/9a574b3f-61b7-4399-a173-4c8db2fdf5bd.png"
    ],
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-10-1935_recom/papers/Llmrec_ Large language models with graph augmentation for recommendation.json"
}