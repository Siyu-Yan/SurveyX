{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2210.05331",
    "title": "Generalization Analysis on Learning with a Concurrent Verifier",
    "abstract": "Machine learning technologies have been used in a wide range of practical systems. In practical situations, it is natural to expect the input-output pairs of a machine learning model to satisfy some requirements. However, it is difficult to obtain a model that satisfies requirements by just learning from examples. A simple solution is to add a module that checks whether the input-output pairs meet the requirements and then modifies the model\u2019s outputs. Such a module, which we call a concurrent verifier (CV), can give a certification, although how the generalizability of the machine learning model changes using a CV is unclear. This paper gives a generalization analysis of learning with a CV. We analyze how the learnability of a machine learning model changes with a CV and show a condition where we can obtain a guaranteed hypothesis using a verifier only in the inference time. We also show that typical error bounds based on Rademacher complexity will be no larger than that of the original model when using a CV in multi-class classification and structured prediction settings.",
    "bib_name": "nishino2022generalizationanalysislearningconcurrent",
    "md_text": "# Generalization Analysis on Learning with a Concurrent Verifier\nMasaaki Nishino, Kengo Nakamura, Norihito Yasuda NTT Communication Science Laboratories, NTT Corporation {masaaki.nishino.uh, kengo.nakamura.dx, norihito.yasuda.hn}@hco.ntt.co.jp\n# Abstract\nMachine learning technologies have been used in a wide range of practical systems. In practical situations, it is natural to expect the input-output pairs of a machine learning model to satisfy some requirements. However, it is difficult to obtain a model that satisfies requirements by just learning from examples. A simple solution is to add a module that checks whether the input-output pairs meet the requirements and then modifies the model\u2019s outputs. Such a module, which we call a concurrent verifier (CV), can give a certification, although how the generalizability of the machine learning model changes using a CV is unclear. This paper gives a generalization analysis of learning with a CV. We analyze how the learnability of a machine learning model changes with a CV and show a condition where we can obtain a guaranteed hypothesis using a verifier only in the inference time. We also show that typical error bounds based on Rademacher complexity will be no larger than that of the original model when using a CV in multi-class classification and structured prediction settings.\n# 1 Introduction\nAs machine learning technology matures, many systems have been developed that exploit machine learning models. When developing a system that uses a machine learning model, a model with merely small prediction error is not satisfactory due to real-field requirements. For example, an object recognition model that is sensitive to slight noise would cause security issues [4, 28], or a model with unexpected output would increase a system\u2019s cost for dealing with it. Thus, we want the input-output pairs of a machine learning model to satisfy some requirements. However, it is difficult to obtain a model that satisfies the requirements by just learning from examples. Moreover, since the learned models tend to be complex and the input domain tends to be quite large, it is unrealistic to certify that every input-output pair satisfies the requirements. In addition, even if we find an input-output pair that does not satisfy the requirements, modifying a model is difficult since we have to re-estimate it from the training examples. This paper considers a way to obtain a machine learning model whose input-output pairs satisfy the required properties. We address the following assumptions for a situation where a machine learning model is used. First, we can judge whether input-output pair (x, h(x)) satisfies the requirements, where h : X \u2192Y is a machine learning model or a hypothesis. As we show below, important use cases fit this setting. Second, a machine learning model already exists whose prediction error is small enough, although its input-output pairs are not guaranteed to satisfy the requirements. This second assumption is also reasonable since modern machine learning models show sufficient prediction accuracy in various tasks. Under these assumptions, a practical choice for addressing this problem isn\u2019t changing the machine learning model but adding a module that checks the input-output pairs of machine learning model h. We call this module a concurrent verifier (CV). Fig. 1 shows the system configuration of a machine learning model with a CV. The verifier checks whether the input-output\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c9b6/c9b6eadb-9ebf-4091-a2ad-85cd89845ae9.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: Overview of a machine learning model with a concurrent verifier that checks whether input-output pairs of a model satisfy requirements.</div>\npair (x, h(x)) satisfies the required properties. If it satisfies the requirements, it outputs h(x). If not, then it rejects h(x) and modifies or requests the learning model to modify its output. A machine learning model and verifier pair can be seen as another machine learning model whose input-output pairs are guaranteed to satisfy the required conditions. Although a model with a verifier can guarantee that its input-output pairs satisfy requirements, its effect on prediction error is unclear. This paper gives theoretical analyses of the generalization errors of a machine learning model with a CV. We focus on how the learnability of the original model, denoted as hypothesis class H, can change by using the verifier. First, we consider a situation where we use a CV only in the inference phase. This setting corresponds to a case where the required properties are unknown when we are in the training phase. If the hypothesis class is PAC-learnable, we can obtain a guaranteed hypothesis using a verifier only in the inference time. Second, we consider a situation where we know the requirements when learning the model. This situation corresponds to viewing the learnability of hypothesis set Hc, which is obtained by modifying every hypothesis h \u2208H to satisfy the requirements. Hence we compare the generalization error upper bounds of Hc with those of H. On the multi-class classification setting, we show that existing error bounds [15, 18] based on the Rademacher complexity of H are also bounds of modified hypothesis Hc for any input-output requirements. Moreover, we give similar analyses for a structured prediction task, which is a kind of multi-class classification where set of classes Y can be decomposed into substructures. It is worth analyzing the task since many works address the constraints in structured prediction. Some works give error bounds for structured prediction tasks, which are tighter than simply applying the bound for multi-class classification tasks [16, 6, 19]. Similar to the case of multiclass classification, we show that existing Rademacher complexity-based bounds for the structured prediction of H are also the bounds for Hc. Our main contributions are as follows: a) We introduce a concurrent verifier, which is a modelagnostic way to guarantee that machine learning models satisfy the required properties. Although a similar mechanism was used in some existing models, our model gives a generalization analysis that does not depend on a specific model. b) We show that if hypothesis class H is PAC-learnable, then using a verifier at the inference time can give a hypothesis with a guarantee in its generalization error. Interestingly, if H is not PAC-learnable, we might fail to obtain a guaranteed hypothesis even if the requirements are consistent with distribution D. c) We show that if we use a CV in a learning phase of multi-class classification tasks, then the theoretical error bounds of H based on the Rademacher complexity will not increase with any input-output requirements. We also give similar results for structured prediction tasks.\n# 1.1 Use Cases of a Concurrent Verifier\nThe following are some typical use cases for CVs. Error-sensitive applications: A typical situation where we want to use a verifier is that some prediction errors might cause severe effects, which we want to avoid. For example, a recommender system might limit the set of candidate items depending on user attributes. Although such a rule might degrade the prediction accuracy, practically a safer model is preferable. Controlling outputs of structured prediction: Constraints are frequently used in structured prediction tasks for improving the performance or the controllability of the outputs. For example, some works [23, 5] exploited the constraints on sequence labeling tasks for reflecting background knowledge to improve the prediction results. More recently, some works [9, 2] exploited the constraints in language generation tasks, including image captioning and machine translation, and restricted a\nmodel to output a sentence that includes given keywords. Since the constraints used in this previous work can be written as a logical formula, our CV model can represent them as requirements. Robustness against input perturbations: If a machine learning model changes its output because we modified its input from x to x\u2032, which is very close to x, then the model is described as sensitive against a small change [27]. It might be a security risk if a model is sensitive since its behavior is unpredictable. Therefore, some methods evaluate and verify the robustness of neural networks against small perturbations [28, 4]. Existing verification methods check a machine learning model\u2019s robustness around input x by determining whether x\u2032 exists that is close to x and whether model f gives different outputs, i.e., h(x) \u0338= h(x\u2032), for verification samples x1, . . . , xn. Although these verification methods can test a model, they do not directly show how to obtain a robust model. A CV can fix a model to achieve robustness around samples x1, . . . , xn by setting a rule of form: \u201ch(x\u2032) must equal h(xi) if x\u2032 is close to xi.\u201d Although this solution might not guarantee robustness where samples are scarce, adding enough non-labeled verification samples is often a reasonable choice.\n# 2 Related Work\nMachine learning models that can exploit constraints have been investigated in many research fields, including statistical symbolic learning and structured prediction. For example, Markov logic networks [22], Problogs [8], and probabilistic circuit models [11] integrate statistical models with symbolic logic formulations. Since these models can incorporate hard constraints represented by symbolic logic, they can guarantee input-output pairs. However, previous research focused on their practical performance and gave little theoretical analysis of their learnability when hard constraints are used. Moreover, previous works integrated the ability to exploit constraints into specific models. In contrast, our CV is model-agnostic and can be used in combination with a wide range of machine learning models. Recently, the verification of machine learning models has been gathering more attention. Attempts have verfified whether a machine learning model has the desired properties [4, 28, 10, 26]. Exact verification methods use integer programming (MIP) [28], constraint satisfaction (SAT) [20], and a satisfiable module theory (SMT) solver [10] to assess the robustness of a neural network model against input noise. These approaches aim to obtain models that fulfill the required properties. However, verification methods cannot help modify the models if they do not satisfy the requirements. If we want ML models to meet requirements, post-processing is needed as our concurrent verification model. Other methods can give upper bounds on generalization error, including VC-dimension [29] and its extensions [7, 21], Rademacher complexity [3, 12], stability [25], and PAC-Bayes [17, 1]. We use Rademacher complexity in the following analysis since it is among the most popular tools for giving theoretical upper bounds on generalization error. Rademacher complexity also has some extensions, including local Rademacher complexity [15] and factor graph Rademacher complexity [6]. We can provide theoretical guarantees on these extended measures.\n# 3 Preliminaries\nOur notation follows a previous work [24]. We first introduce the notations used in the following sections. Let X denote the domain of the inputs, let Y be the domain of the labels, and let Z be the domain of the examples defined as Z := X \u00d7Y. Let H be a hypothesis class, and let \u2113: H\u00d7Z \u2192R+ be a loss function. Training data S = (z1, . . . , zm) \u2208Zm is a finite sequence of size m drawn i.i.d. from a fixed but unknown probability distribution D on Z. Learning algorithm A maps training data S to hypothesis h. We use notation A(S) to denote the hypothesis that learning algorithm A returns upon receiving S. We represent set {1, . . . , K} as [K]. Given distribution D on Z, we denote by LD(h) the generalization error and by LS(h) the empirical error of h over S, defined by\n(1)\nPAC learnability: We introduce PAC learnability and agnostic PAC learnability as follows. Definition 3.1. (Agnostic PAC learnability) Hypothesis class H is agnostic PAC-learnable if there exists function mH : (0, 1)2 \u2192N and learning algorithm A with the following property: For every \u03f5, \u03b4 \u2208(0, 1) and distribution D over Z, if S consists of m \u2265mH(\u03f5, \u03b4) i.i.d. examples generated by D, then with at least probability 1 \u2212\u03b4, the following holds:\nDistribution D is realizable by hypothesis set H if h\u2217\u2208H exists such that LD(h\u2217) = 0. If D is realizable by agnostic PAC-learnable hypothesis H, then H is PAC-learnable. If H is PAC-learnable, then Eq. (2) becomes LD(A(S)) \u2264\u03f5 since minh\u2032\u2208H LD(h\u2032) = 0.\nD \u2264\u2032\u2208HD Rademacher complexity: In the following sections, we use Rademacher complexity for deriving the generalization bounds. Given loss function \u2113(h, z) and hypothesis class H, we denote G as\nG\u25e6H{ \ufffd\u2192 \u2208H} Definition 3.2. (Empirical Rademacher complexity) Let G be a family of functions mapping from Z to R, and let S = (z1, . . . , zm) \u2208Zm be the training data of size m. Then the empirical Rademacher complexity of G with respect to S is defined:\nwhere \u03c3 = (\u03c31, . . . , \u03c3m) \u2208{\u00b11}m are random variables distributed i.i.d. according to P[\u03c3i = 1] = P[\u03c3i = \u22121] = 1/2. The Rademacher complexity of G is defined as the expected value of the empirical Rademacher complexity:\n# 4 Concurrent Verifier\nNext we give a formal definition of a CV. A CV works with a machine learning model, which is function h : X \u2192Y. If x is given to the model, which outputs h(x), then the verifier checks whether (x, h(x)) satisfies the required property. We assume that the required property can be represented as requirement function c : (X \u00d7 Y) \u2192{0, 1}. If c(x, h(x)) = 1, then the pair satisfies the property; if c(x, h(x)) = 0, then it does not. Requirement function c can be represented by a set of deterministic rules. For example, if X = R and Y = {0, 1}, then the requirements can be in the following form: \u201cif x > 0, then y \u0338= 0.\u201d We assume that for all possible input x \u2208X, there exists y \u2208Y such that c(x, y) = 1 for avoiding the situation where the requirements are unsatisfiable for any output y. This assumption can be easily relaxed if we allow a machine learning model to reject unsatisfiable input x. After checking the input-output pair, a verifier modifies output h(x) depending on the value of c(x, h(x)). If c(x, h(x)) = 1, the verifier outputs h(x) since it satisfies the requirements. If c(x, h(x)) = 0, then the verifier modifies h(x) to some y \u2208Y that satisfies c(x, y) = 1. If we use a verifier with a machine learning model that corresponds to h, then the combination of the model and the verifier can be seen as function hc : X \u2192Y, defined as \ufffd\nwhere yc \u2208Y satisfies c(x, yc) = 1 and is selected deterministically. When Y = [K], an example for selecting minimum i \u2208[K] satisfying c(x, i) = 1 as yc is a reasonable choice. When Y = [K] and h(x) is made by scoring functions h(x, y) : (X \u00d7 Y) \u2192R, it is also reasonable to select y\u2217such that y\u2217= argmaxy\u2208Y,c(x,y)=1 h(x, y). Learning a model corresponds to selecting hypothesis h from hypothesis class H. Therefore, learning a model with a CV corresponds to choosing a hypothesis from the modified hypothesis class: Hc = {hc : h \u2208H}. By definition, every hypothesis in Hc satisfies the requirements, and thus we can guarantee that the model satisfies the condition if we select a hypothesis from Hc. In the following sections, we analyze the learnability of Hc by comparing it with that of H.\n(2)\n(3)\n# 5 Inference Time Verification\nWe first analyze the change of the generalization errors when we use a verifier only in an inference phase. In other words, requirements are unknown in the learning phase,and we estimate hypothesis \u02c6h = A(S) from hypothesis class H by using training data S and algorithm A. In the inference phase, we use a CV to modify \u02c6h to \u02c6hc. We call this setting the inference time verification (ITV). This class of situations contains many exciting settings: 1) pre-trained machine learning models used in a wide range of applications, and 2) models that are hard to replace, which might encounter different requirements from those at the learning time in the long run. In this section, we give analyses on a multi-class classification setting. We set Y = [K], and hypothesis class H is set of mappings h : X \u2192[K]. We also assume that loss function \u2113is 0-1 loss defined as \u21130-1(h, (x, y)) := 1h(x)\u0338=y, where 1 is an indicator function. The following theorem shows a situation where ITV works well: a situation where the generalization error of \u02c6hc does not exceed that of the other hypotheses in Hc with high probability. Theorem 5.1. If Y = [K], and hypothesis class H is PAC-learnable with 0-1 loss \u21130-1, training data S, and algorithm A, then suppose that \u02c6h = A(S) is a hypothesis estimated form S satisfying LD(\u02c6h) \u2264\u03f5 for some parameter \u03f5 \u2208(0, 1). Then for any requirement c, hypothesis \u02c6hc obtained by modifying \u02c6h with a CV satisfies\nWe give a proof in Appendix A. The proof bounds LD(\u02c6hc) using the fact that it is close to LD(fc), where fc is obtained by modifying f : X \u2192Y to satisfy LD(f) = 0. The theorem suggests that if H is PAC-learnable, then inference time verification is sufficient to obtain a hypothesis with small generalization error in Hc. Note that the generalization error might increase with a verifier, and the amount of the increase is always larger than LD(fc). Therefore, LD(fc) represents the discrepancy between data distribution D and requirement c, which is consistent with f if c(x, f(x)) = 1 for all x. If c is consistent with f, then LD(fc) = 0, and we can certify that LD(\u02c6hc) \u2264\u03f5. The above theorem shows that ITV works when H is PAC-learnable. However, this will not hold if D is not realizable with H, i.e, H is not PAC-learnable. Theorem 5.2. If Y = [K], the loss function is 0-1 loss \u21130-1 and hypothesis class H is not realizable with D, and then there exists training data S, algorithm A, requirements c, and \u03f5 \u2208(0, 1) such that \u02c6h = A(S) satisfies LD(\u02c6h) \u2264minh\u2208H LD(h) + \u03b5 but LD(\u02c6hc) > minhc\u2208Hc LD(hc) + \u03f5. We give in Appendix B a proof that shows a counterexample even if c is consistent with ground truth f. The above theorems show that the realizability of H is the key factor that distinguishes among the cases where ITV works well. Moreover, unlike the realizable case, Theorem 5.2 holds even if requirement c is consistent with distribution D. Let fD : X \u2192Y be defined as the Bayes optimal predictor:\nThe Bayes optimal predictor is optimal, in the sense that for every other classifier g : X \u2192Y LD(fD) \u2264LD(g). Theorem 5.2 holds if c is consistent with fD. These results show that existing methods [9, 2] using constraints only in the inference time might fail to select the best hypothesis. Running time analysis: Using a CV increases the time needed for inference. Suppose that a verifie is an oracle that can answer the query about the value of c(x, y). To achieve a previously shown modification procedure (3), we need at most K queries.\n# 6 Learning Time Verification\nIn Section 5, we show that if H is PAC-learnable with 0-1 loss, then modifying a hypothesis at the inference time is sufficient to obtain a hypothesis with the smallest generalization error while\nsatisfying the requirements. If H is not PAC-learnable, then the ITV scheme might fail to obtain a hypothesis with small generalization error. Here we show that the generalization error can be bounded when we use a CV in the learning phase. We call this setting learning time verification (LTV). Since the LTV scheme corresponds to a learning task where the hypothesis class is Hc, we analyze the learnability of Hc using the standard tools for generalization analyses. This paper provides analyses based on Rademacher complexity since its a widely used tools that can give tight bounds for both data-dependent and data-independent cases. Moreover, some previous work gives bounds of structured prediction tasks using Rademacher complexity. In the literature, constraints are actively used in structured prediction tasks, including language generation and sequence labeling. Therefore, analyzing the generalization error is important when using a CV on structured prediction tasks. In the following, we first show the upper bounds of generation error based on the Rademacher complexity of Hc in a multi-class classification task (\u00a76.1, 6.2) and a structured prediction setting (\u00a76.3). Our main finding is that the upper bounds based on the Rademacher complexity of Hc are always less than or equal to those of H. Therefore, adding a CV to a machine learning model will not degrade its learnability.\n# 6.1 Multi-class Classification\nWe first give the Rademacher complexity-based error bounds on a multi-class classification task, i.e., Y = [K]. In this section, we show that a standard upper bound [18] based on the Rademacher complexity of H can be used as an upper bound of Hc for any requirement c. In the next section, we show that a state-of-the-art error bound, based on local Rademacher complexity H, can also be used as an upper bound of Hc. Following previous works, let h : (X \u00d7 Y) \u2192R be a scoring function, and define hypothesis class H as a set of scoring functions. A scoring function defines a mapping from X to Y:\nLet \u03c1h(x, y) be the margin of function of h:\nHypothesis h misclassifies the labeled example (x, y) if \u03c1h(x, y) \u22640. Thus, by using a margin function, the 0-1 loss can be represented as \u21130-1(h, z) = 1\u03c1h(x,y)\u22640. Since 0-1 loss is hard to handle during learning, we use margin loss \u2113\u03c1(h, (x, y)) = \u03a6\u03c1(\u03c1h(x, y)), where \u03a6\u03c1(t) is defined as\n \u2212 Function f : R \u2192R is said to be \u00b5-Lipschitz if |f(t) \u2212f(t\u2032)| \u2264\u00b5|t \u2212t\u2032| for any t, t\u2032 \u2208R. \u03a6\u03c1 is an 1/\u03c1-Lipschitz function. The empirical margin loss of hypothesis h is defined as\nIdentical to the case of ITV, introducing a CV to a machine learning model corresponds to modifying its corresponding hypothesis class H to hypothesis class Hc that is consistent with requirement c. If h is a score function, then we define consistent function hc: \ufffd\nwhere M is a positive constant satisfying M > | max(x,y)\u2208Z h(x, y)|. As described in Section 4, we assume that there exists y \u2208Y that satisfies c(x, y) = 1 for all x \u2208X. Therefore, we can guarantee that \u03c1hc(x, y) < 0 if c(x, y) = 0. The following are the main results of the general multi-class learning problem, which is based on the margin bound shown in Theorem 9.2 of Mohri et al. [18]. Our main finding is that the generalization error of any hypothesis, hc, is bounded by the Rademacher complexity of hypothesis set H, which suggests that if we have a tight bound for hypothesis class H, then we can expect to find a good hypothesis from Hc under any requirements c.\n(4)\n# Theorem 6.1. Let H \u2286RX\u00d7Y be a hypothesis class with Y = [K], and let c be a requirement. Fix \u03c1 > 0. Then for any \u03b4 > 0, with probability at least 1 \u2212\u03b4, the following bound holds for all hc \u2208Hc:\nLD(hc) \u2264LS,\u03c1(hc) + 4K \u03c1 Rm(\u03a01(H)) + \ufffd log 1 \u03b4 2m ,\nwhere \u03a01(H) is defined as\n\u03a01(H) :={x \ufffd\u2192h(x, y) : y \u2208Y, h \u2208H} .\nWe give a proof in Appendix C. We obtain the results by showing that the upper bounds of the Rademacher complexity of Hc are bounded by some upper bounds of the Rademacher complexity of H. All the proofs of the theorems in this section use similar techniques. Parameter \u03c1 sets the margin value. Following a previously shown technique [18], we obtain a generalized bound that holds uniformly for all \u03c1 > 0. The above theorem suggests that using a CV at a learning phase does not worsen the error bound for any requirement c. Intuitively, the theorem seems reasonable since requirements c imposes a restriction on H, and thus the complexity of Hc is not larger than H. However, it is not so trivial since Hc \u2286H is not always true. Running time analysis: We analyze the number of evaluations c(x, y) required for learning with a CV. Let S1 be a sub-sequence of training example S such that c(xi, yi) = 1, and let S0 be a sub-sequence such that c(xi, yi) = 0. If we use a 0-1 loss function, then the empirical loss of hypothesis hc is\nsince every hc misclassifies the examples in S0. Therefore, we need at most K|S1| + |S0| queries for the learning process. This is also true when we use a margin loss function. On the other hand, the problem of estimating the best hypothesis might be more difficult than the original problem depending on requirement c.\n# 6.2 Tighter Bound Based on Local Rademacher Complexity\nThe bound for Hc shown in the previous section is relatively simple, and tighter bounds of H based on the Rademacher complexity have been developed in the literature. In this section, we show that the state-of-the-art error bound for H based on the local Rademacher complexity can be used as a bound for Hc for any requirements c. Definition 6.2. Let G be a family of functions from Z to R, and let S be training data of size m. Then for any r > 0, the empirical local Rademacher complexity of G is defined as\n\ufffd \ufffd Li et al. [15] showed a tighter generalization bound for a multi-class classification problem using the local Rademacher complexity when the hypothesis class is a \u2113p norm hypothesis space with kernel \u03ba, defined as\nwhere h is represented as a vector valued function (h1, . . . , hK) with hj(x) = h(x, j), \u2200j = 1, . . . , K, and \u03ba : X \u00d7 X \u2192R is a Mercer kernel with associated feature map \u03c6, i.e., \u03ba(x, x\u2032) = \u27e8\u03c6(x), \u03c6(x\u2032)\u27e9. w = (w1, . . . , wK), and \u2225w\u2225= \ufffd\ufffdK i=1 \u2225w\u2225p 2 \ufffd1 p is the \u21132,p-norm. For any p \u22651, let q be the dual exponent of p satisfying 1/p + 1/q = 1. Let \u03a6 : R \u2192R be a loss function satisfying the following: 1) 1t\u22640(t) \u2264\u03a6(t) for all t; 2) \u03a6(t) is decreasing and has zero point c\u03a6; 3) \u03a6 is \u03b6-smooth, that is, |\u03a6\u2032(t) \u2212\u03a6\u2032(t\u2032)| \u2264\u03b6|t \u2212t\u2032|. Let Hp,\u03ba,c be the hypothesis class obtained by modifying hypothesis Hp,\u03ba to satisfy requirements c, and Lc :={(x, y) \ufffd\u2192\u03a6(\u03c1hc(x, y)) : hc \u2208Hp,\u03ba,c}. The following theorem gives a bound of the local Rademacher complexity of Lc.\nFigure 2: Example of factor graphs: (a) represents decomposition h(x, y) = hf1(x, y1, y2) + hf2(x, y2, y3) and (b) represents decomposition h(x, y) = hf1(x, y1, y2) + hf2(x, y1, y2, y3).\nTheorem 6.3. Let Hp,\u03ba,c be the set of hypotheses obtained by modifying hypothesis h \u2208Hp,\u03ba with requirement c. For any \u03b4 > 0, with probability at least 1 \u2212\u03b4, the following bound holds:\nwhere \u03d1 = supx\u2208X \u03ba(x, x) < \u221e, d = supt\u2208R \u03a6(t) < \u221e, and Cd,\u03d1 is a constant. \u03be(K) is\nWe give a proof in Appendix D. The bound equals that of Rm(L; r) (Theorem 1 of [15]) for any requirement c and any hypothesis H\u03c1,\u03ba. Therefore, the generalization error bounds based on Theorem 1 of Li et al. [15] holds for any requirement c.\n# 6.3 Analyses of Structured Prediction\nStructured prediction is a kind of multi-class classification task, where label set Y might be a set of sequences, images, graphs, trees, or other objects admitting some possibly overlapping structure. As mentioned in Section 1, previous works try to impose constraints on the output of structured prediction tasks. Thus it is also useful to derive error bounds for structured prediction tasks when we use a CV. In the following, we show that the Rademacher complexity-based generalization error bounds derived in a seminal work of Cortes et al. [6] also hold if we use a CV. Although tighter bounds are given in a more recent work [19, 16], we give bounds based on Cortes et al. [6] due to their simplicity. We give some definitions for the structured prediction task. Following previous work, we assume that Y is decomposable along with substructures: Y = Y1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 Yl. Here Yk is a set of possible labels that can be assigned to the k-th substructure. We denote by L : Y \u00d7 Y \u2192R+ a loss function that measures the dissimilarity of two elements of output space Y. L is definite, that is, L(y, y\u2032) = 0 iff y = y\u2032. A typical definite loss function for a structured prediction task is the Hamming loss defined by L(y, y\u2032) = 1 l \ufffdl k=1 1yk\u0338=y\u2032 k for all y = (y1, . . . , yl) and y\u2032 = (y\u2032 1, . . . , y\u2032 l), with yk, y\u2032 k \u2208Yk. Other typical examples of loss functions can be seen in Cortes et al. [6]. Using loss function L, the generalization and empirical error of h are defined:\nStructured prediction is a kind of multi-class classification task, where label set Y might be a set of sequences, images, graphs, trees, or other objects admitting some possibly overlapping structure. As mentioned in Section 1, previous works try to impose constraints on the output of structured prediction tasks. Thus it is also useful to derive error bounds for structured prediction tasks when we use a CV. In the following, we show that the Rademacher complexity-based generalization error bounds derived in a seminal work of Cortes et al. [6] also hold if we use a CV. Although tighter bounds are given in a more recent work [19, 16], we give bounds based on Cortes et al. [6] due to their simplicity. We give some definitions for the structured prediction task. Following previous work, we assume that\nAs with the multi-class classification task, hypothesis class H can be represented as a set of scoring function h : X \u00d7 Y \u2192R. We use h(x) to represent the predictor defined by h \u2208H: h(x) := argmaxy\u2208Y h(x, y) for all x \u2208X. Following the previous work, we assume that each scoring function can be decomposed as a sum, and such decomposition follows a factor graph. Factor graph G is a tuple G = (V, F, E), where V is a set of variable nodes, F is a set of factor nodes, and E is a set of undirected edges between a variable node and a factor node. Every node in V corresponds to a substructure index, where V = {1, . . . , l}. For any factor node f, we denote by N(f) \u2286V a set of variable nodes connected to f and define Yf as substructure set cross-product Yf = \ufffd k\u2208N (f) Yk. Then h admits the following decomposition as\nFigure 2 shows examples of decompositions based on factor graphs. We conventionally assume that the structure of the factor graphs may change depending on a particular example (xi, yi): G(xi, yi) = Gi = ([li], Fi, Ei). A special case of this setting is when size li of each example is allowed to vary. In such a case, the number of possible labels Y is potentially infinite. Following multi-class classification, our CV maps hypothesis h to hc to satisfy the requirements. The definition of hc follows Eq. (4). This definition does not require hc to have a factored representation. For analyzing the complexity, Cortes et al. [6] introduced empirical factor graph Rademacher complexity RG S (H) of hypothesis class H for S = (x1, . . . , xm) and factor graph G:\n\uf8f0 \uf8fb where \u03f5 = (\u03f5i,f,y)i\u2208[m],f\u2208Fi,y\u2208Yf and every \u03f5i,f,y is i.i.d. a Rademacher random variable. Factor graph Rademacher complexity of H for factor graph G is defined as expectation\nBy using the factor graph Rademacher complexity, Cortes et al. [6] gives bounds for a structured prediction task with the following additive and multiplicative empirical losses:\nwhere \u03a6\u2217(t) = min(B, max(0, t)) for all t, with B = maxy,y\u2032 L(y, y\u2032). As shown in [6], these loss functions cover typical surrogate loss functions used in structured prediction tasks. We show the following bound for structured predictions. Theorem 6.4. Fix \u03c1 > 0. For any \u03b4 > 0 and requirement c, with probability at least 1 \u2212\u03b4 over the draw of sample S of size m from distribution D, the following holds for all hc \u2208Hc:\nWe give a proof in Appendix E. \u03c1 is a parameter that determines the margin. Similar to the case of multi-class classification, we can derive a bound that holds for any \u03c1 > 0 following a previous derivation [6]. The above result indicates that the bound will not change if we use a CV for any requirement c. This is interesting since the above result holds even if we do not have a factored representation of hc(x, y), similar to Eq. (5), although the derived bound depends on the factor graph Rademacher complexity, which depends on the factored representation of h(x, y). We analyzed the overhead of the running time for evaluating loss function Ladd S,\u03c1 (hc) and Lmult S,\u03c1 (hc) for hypothesis hc. Different from the multi-class classification case, both the number of queries and the overhead of the running time for the loss evaluation when we use a CV depend on the model and the type of requirements for structured predictions. This result is consistent with the literature, which reports that for structured prediction tasks, original tractable optimization problems can be intractable if we put additional constraints [23].\nThis paper gives a generalization analysis when there are requirements that the input-output pairs of a machine learning model must satisfy. We introduce a concurrent verifier, a simple module that enables us to guarantee that the input-output pairs of a machine learning model satisfy the requirements. We show a situation where we can obtain a hypothesis with small error when we use a verifier only in the inference phase. Interestingly, if H is not PAC-learnable, we might fail to obtain a guaranteed hypothesis even if the requirements are consistent with distribution D. We also give the generalization bounds based on Rademacher complexity when we use a verifier in a learning phase and find that the obtained bounds are less than or equal to the existing ones, independent of the machine learning model and the type of requirements.\n# Acknowledgements\nThe authors thank the anonymous reviewers for their valuable feedback, corrections, and suggestions. This work was supported by JST PRESTO (Grant Number JPMJPR20C7, Japan) and JSPS KAKENHI (Grant Number JP20H05963, Japan).\n# References\n# A Proof of Theorem 5.1\n# B Proof of Theorem 5.2\nProof. Suppose that H = {h0, h1}, and f \u0338\u2208H exists, satisfying LD(f) = 0. Suppose partition X0, X1 of X exists such that h0(x) \u0338= f(x) iff x \u2208X0 and h1(x) \u0338= f(x) iff x \u2208X1. Suppose that |LD(h0) \u2212LD(h1)| \u2264\u03f5 for some \u03f5 \u2208(0, 1). If we design c such that c(x, y) = 0 iff x \u2208X0 and y = h0(x), otherwise c(x, y) = 1. Then the generalization error of modified hypothesis hc1 becomes LD(hc0) = 0, and LD(hc1) = LD(h1). Thus if LD(h1) > \u03f5, and then difference |LD(hc0) \u2212LD(hc1)| becomes larger than \u03f5.\nNote that the above proof holds for c, which is consistent with f; that is, c(x, f(x)) = 1 for all x \u2208X.\n# C Proof of Theorem 6.1\nWe first introduce Talagrand\u2019s lemma with which we prove the main theorem. Lemma C.1 (Talagrand\u2019s lemma, [13, 18] ). Let \u03a6 be the \u00b5-Lipschitz function from R to R, and let \u03c31, . . . , \u03c3m be Rademacher random variables. Then for any hypothesis set H of real-valued functions, the following inequality holds:\nLemma C.1 (Talagrand\u2019s lemma, [13, 18] ). Let \u03a6 be the \u00b5-Lipschitz function from R to R, and let \u03c31, . . . , \u03c3m be Rademacher random variables. Then for any hypothesis set H of real-valued functions, the following inequality holds:\nWe also use the following lemma.\nLemma C.2 (Lemma 9.1 of Mohri et al. [18]). Let F1, . . . , Fl be l hypothesis sets in RX , l \u22651, and let G = {max{h1, . . . , hl} : hi \u2208Fi, i \u2208[l]}. Then for any training data S of size m, the empirical Rademacher complexity of G can be upper bounded:\nThe following lemma shows the relationship between the Rademacher complexities of H and Hc. Lemma C.3. Let H be a hypothesis set in RX\u00d7Y, and let c : X \u00d7 Y \u2192{0, 1} be the requirements. Then for any training data S = ((x1, y1), . . . , (xm, ym)) of size m, the following inequality holds:\nProof. Let b0(x, y) : X \u00d7 Y \u2192R be the following function:\nLet B0 = {b0}. Then Hc can be represented as Hc = {min{h, b0} : h \u2208H, b0 \u2208B0}. From Lemma C.2,\nwhere we define \u03c1\u03b8,h(x, y):\nwhere \u03b8 > 0 is an arbitrary constant. \u03c1\u03b8,h satisfies E[1\u03c1h(x,y)\u22640] \u2264E[1\u03c1\u03b8,h(x,y)\u22640] since \u03c1\u03b8,h(x, y) \u2264\u03c1h(x, y) holds for all (x, y) \u2208X \u00d7 Y. Following the proof of Theorem 9.2 of Mohri et al. [18] with a probability of at least 1 \u2212\u03b4, for all hc \u2208Hc:\nus, to complete the proof it suffices to show Rm(Hc0) \u22642KRm(\u03a01(H)). We can upper bound :\nThus, to complete the proof it suffices to show Rm(Hc0) \u22642KRm(\u03a01(H)). We can upper bound Rm(Hc0):\n\ufffd \ufffd By applying lemma C.3, the first term is bounded by Rm(H). Then we follow a previous proof of Mohri et al. [18] to see that Rm(H) \u2264KRm(\u03a01(H)). We bound the second term:\n<div style=\"text-align: center;\">We use lemma C.2 to derive the second line and lemma C.3 to derive the fourth line.</div>\n# D Proof of Theorem 6.3\nOur proof is made by changing a part of a previous proof of theorem 1 of Li et al. [15]. We first introduce empirical Gaussian complexity and a lemma. Definition D.1. (Empirical Gaussian complexity) Let G be a family of functions mapping from Z to R, and let S = (z1, . . . , zm) \u2208Zm be training data of size m. Then the empirical Gaussian complexity of G with respect to S is defined:\nWe need the following lemma, which is based on lemma 4 of Lei et al. [14]. Lemma D.2. Let H be a hypothesis class of mappings X \u00d7 Y \u2192R, where Y = [K]. h \u2208H is represented as vector h = (h1, . . . , hK). Let c be a requirement, and let g1, . . . , gmK be N(0, 1) random variables. Then for any training data S = (x1, . . . , xm) of size m, we have: \uf8ee \uf8f9\n\n(6)\nProof. We make a proof by modifying the proof for lemma 4 of Lei et al. [14]. Define two Gaussian processes indexed by Hc and H:\n\ufffd \ufffd Finally, we can prove the lemma using this inequality and lemma A.1 of Lei et al. [14].\nBy using lemma D.2, we can bound the second term:\nAdding these bounds can prove the lemma.\nWe use the above lemma instead of lemma 1 of Li et al. [15] for proving Theorem 1 Li et al. [15], which gives a proof for our theorem.\n# E Proof of Theorem 6.4\nProof. We first prove the bound for Ladd S,\u03c1 (h). Following the proof of Theorem 1 in Cortes et al.[6], we can prove that LD(hc) < Ladd D,\u03c1(hc) and\nwhere Hc1 is defined:\nWe give a bound on the empirical Rademacher complexity of Hc1. Due to the sub-additivity of the supremum, the following holds:\nWe give a bound on the empirical Rademacher complexity of Hc1. Due to the sub-additivity of t supremum, the following holds:\nWe first bound the first term with the Lipschitzness of h \ufffd\u2192maxy\u2032\u0338=y \ufffd L(y\u2032, yi) + hc(xi,y\u2032) \u03c1 \ufffd for any requirement c. For any h, \u02dch \u2208H,\n\ufffd\ufffd \ufffd\ufffd where we use the fact that |hc(x, y) \u2212\u02dchc(x, y)| \u2264|h(x, y) \u2212\u02dch(x, y)| for any h, \u02dch \u2208H and (x, y) \u2208X \u00d7Y since |hc(x, y)\u2212\u02dchc(x, y)| = 0 or equals |h(x, y)\u2212\u02dch(x, y)|, depending on requirement\n\n\ufffd \ufffd\ufffd We can apply Lemma 5 of Cortes et al. [6], which yields: \ufffd\nTherefore, we can also obtain bound\nTaking the expectation over S of the two inequalities shows that Rm(Hc1) \u22642 \u221a 2 \u03c1 RG m(H), which completes the proof of the first statement. For the second statement, we follow a proof of Cortes et al. [6] to obtain: \ufffd\nwhere\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd where we use the fact |hc(x, y)\u2212\u02dchc(x, y)| \u2264|h(x, y)\u2212\u02dch(x, y)| for any h, \u02dch \u2208H and (x, y) \u2208X \u00d7Y. The reminder of the proof is identical as in the previous argument.\n# F Summary of Notations\n<div style=\"text-align: center;\">Table 1 shows the notations used in the paper.</div>\nSymbol\nMeaning\nX\ndomain of inputs\nY\ndomain of labels\nZ\ndomain of examples\nh\na hypothesis\nH\na hypothesis class\nc : X \u00d7 Y \u2192{0, 1}\nrequirement function\nhc\nhypothesis h modified to satisfy requirement c\nHc\nset of modified hypotheses defined as Hc := {hc : h \u2208H}\n\u2113: H \u00d7 Z \u2192R+\nloss function\n\u21130-1\nthe 0-1 loss function\n\u2113\u03c1\na margin loss function\nS = z1, . . . , zm\na sequence of m examples\nD\na distribution over X \u00d7 Y\nLD(h)\ngeneralization error of h\nLS(h)\nempirical error of h over S\nLS,\u03c1(h)\nempirical margin error of h over S\nRS(G)\nthe empirical Rademacher complexity of G with respect to S\nRm(G)\nthe Rademacher complexity of G\nRm(G; r)\nthe empirical local Rademacher complexity of G\nRG\nm(H)\nthe empirical factor graph Rademacher complexity of hypothesis class H\n\u03c1h(x, y)\na margin function\nTable 1: Summary of notations\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the problem of ensuring that input-output pairs of machine learning models satisfy specific requirements, highlighting the inadequacy of existing methods that rely solely on learning from examples. It introduces the concept of a concurrent verifier (CV) as a solution to certify model outputs.",
        "problem": {
            "definition": "The issue at hand is the difficulty in obtaining machine learning models that can guarantee that their input-output pairs meet certain requirements, especially when the models are complex and the input domain is large.",
            "key obstacle": "The main challenge is that existing methods often fail to modify learned models effectively to ensure compliance with these requirements, necessitating a new approach."
        },
        "idea": {
            "intuition": "The idea of incorporating a concurrent verifier is inspired by the need for a mechanism that can check and adjust model outputs to meet required properties without needing to retrain the model.",
            "opinion": "The proposed idea involves adding a CV module that evaluates whether the outputs of a machine learning model satisfy the predefined requirements and modifies them if necessary.",
            "innovation": "The key innovation of this method lies in its ability to guarantee compliance with requirements while maintaining the generalization properties of the original model, which is not achievable with existing approaches."
        },
        "method": {
            "method name": "Concurrent Verifier",
            "method abbreviation": "CV",
            "method definition": "A concurrent verifier is a module that checks if the input-output pairs of a machine learning model satisfy certain requirements and modifies the outputs if they do not.",
            "method description": "The CV operates by evaluating the output of the model against specified requirements and adjusting the output accordingly to ensure compliance.",
            "method steps": "1. Receive input x; 2. Obtain output h(x) from the model; 3. Check if the pair (x, h(x)) satisfies the requirement using the CV; 4. If it does, output h(x); if not, modify the output to a valid response.",
            "principle": "The effectiveness of the CV method is based on the ability to enforce requirements at inference time, ensuring that the outputs are reliable and meet the necessary conditions."
        },
        "experiments": {
            "evaluation setting": "The experiments were conducted in multi-class classification and structured prediction settings, using Rademacher complexity to analyze the generalization errors of models with and without the CV.",
            "evaluation method": "The performance of the method was assessed by comparing the generalization error bounds of the modified hypothesis class Hc with those of the original hypothesis class H."
        },
        "conclusion": "The paper concludes that the introduction of a concurrent verifier allows for the modification of machine learning models to ensure compliance with requirements without significantly increasing the generalization error, thus providing a robust solution to the problem.",
        "discussion": {
            "advantage": "The main advantage of the proposed approach is its ability to maintain the learnability of the model while ensuring that outputs meet specified requirements, which is a significant improvement over existing methods.",
            "limitation": "A limitation of the method is that if the original hypothesis class H is not PAC-learnable, the CV may not be able to guarantee a hypothesis with small generalization error.",
            "future work": "Future research could explore enhancing the CV mechanism to better handle cases where the original models are not PAC-learnable and investigate its applicability in other machine learning tasks."
        },
        "other info": {
            "acknowledgements": "The authors thank the anonymous reviewers for their valuable feedback, and this work was supported by JST PRESTO and JSPS KAKENHI."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "This paper addresses the problem of ensuring that input-output pairs of machine learning models satisfy specific requirements, highlighting the inadequacy of existing methods that rely solely on learning from examples."
        },
        {
            "section number": "2.1",
            "key information": "The issue at hand is the difficulty in obtaining machine learning models that can guarantee that their input-output pairs meet certain requirements, especially when the models are complex and the input domain is large."
        },
        {
            "section number": "3.5",
            "key information": "The proposed idea involves adding a concurrent verifier (CV) module that evaluates whether the outputs of a machine learning model satisfy the predefined requirements and modifies them if necessary."
        },
        {
            "section number": "6.1",
            "key information": "The effectiveness of the CV method is based on the ability to enforce requirements at inference time, ensuring that the outputs are reliable and meet the necessary conditions."
        },
        {
            "section number": "7.1",
            "key information": "A limitation of the method is that if the original hypothesis class H is not PAC-learnable, the CV may not be able to guarantee a hypothesis with small generalization error."
        }
    ],
    "similarity_score": 0.6330940854884464,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Generalization Analysis on Learning with a Concurrent Verifier.json"
}