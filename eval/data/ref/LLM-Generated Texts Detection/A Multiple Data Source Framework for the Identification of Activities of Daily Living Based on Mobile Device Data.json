{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1711.00104",
    "title": "A Multiple Data Source Framework for the Identification of Activities of Daily Living Based on Mobile Device Data",
    "abstract": "Most mobile devices include motion, magnetic, acoustic, and location sensors. They allow the implementation of a framework for the recognition of Activities of Daily Living (ADL) and its environments, composed by the acquisition, processing, fusion, and classification of data. This study compares different implementations of artificial neural networks, concluding that the obtained results were 85.89% and 100% for the recognition of standard ADL. Additionally, for the identification of standing activities with Deep Neural Networks (DNN) respectively, and 86.50% for the identification of the environments with Feedforward Neural Networks. Numerical results illustrate that the proposed framework can achieve robust performance from the data fusion of off-the-shelf mobile devices.",
    "bib_name": "pires2019multipledatasourceframework",
    "md_text": "# A Multiple Data Source Framework for the Identification of  Activities of Daily Living Based on Mobile Devices \nIvan Miguel Pires1, Nuno M. Garcia1, Nuno Pombo1, Francisco Fl\u00f3rez-Revuelta2, Maria  Canavarro Teixeira3,4, Eftim Zdravevski5 and Susanna Spinsante6 \n1Instituto de Telecomunica\u00e7\u00f5es, Universidade da Beira Interior, Covilh\u00e3, Portugal  2Department of Computer Technology, Universidad de Alicante, Spain  3 UTC de Recursos Naturais e Desenvolvimento Sustent\u00e1vel, Polytechnique Institute of Castelo Branco,  Castelo Branco, Portugal   4 CERNAS - Research Centre for Natural Resources, Environment and Society, Polytechnique Institute of  Castelo Branco, Castelo Branco, Portugal   5 Faculty of Computer Science and Engineering, University Ss Cyril and Methodius, Skopje, Macedonia   6 Department of Information Engineering, Marche Polytechnic University, Ancona, Italy \nimpires@it.ubi.pt, ngarcia@di.ubi.pt, ngpombo@di.ubi.pt francisco.florez@ua.es, ccanavarro@ipcb.pt,  eftim.zdravevski@finki.ukim.mk, s.spinsante@univpm.it \n# Abstract \nMost mobile devices include motion, magnetic, acoustic, and location sensors. They allow the implementation of a framework for the recognition of Activities of Daily Living (ADL) and its environments, composed by the acquisition, processing, fusion, and classification of data. This study compares different implementations of artificial neural networks, concluding that the obtained results were 85.89% and 100% for the recognition of standard ADL. Additionally, for the identification of standing activities with Deep Neural Networks (DNN) respectively, and 86.50% for the identification of the environments with Feedforward Neural Networks. Numerical results illustrate that the proposed framework can achieve robust performance from the data fusion of off-the-shelf mobile devices. \nFeedforward Neural Networks. Numerical results illustrate that the proposed framework can achieve robust performance from the data fusion of off-the-shelf mobile devices.    Keywords: Mobile devices; Activities of Daily Living (ADL); sensors; data fusion; feature extraction; pattern recognition. \nKeywords: Mobile devices; Activities of Daily Living (ADL); sensors; data fusion; feature extraction;  pattern recognition.   \n# 1. Introduction\nA multiple data source framework for the identification of ADL [1], proposed in [2-4], can be implemented using data acquired from the several sensors available in mobile devices, e.g., accelerometer, magnetometer, gyroscope, microphone, and Global Positioning System (GPS) receiver. These sensors allow the capture of several parameters to enable the automatic identification of the activities. This identification of activities and environments are taken into account the sensing of the characteristics of the movement these activities produce and the environmental sound characteristics associated with the data acquisition period [5]. This framework can integrate the development of a personal digital life coach [6], currently under research.  Based on previous work [7, 8] related to the use of sensors' data for the recognition of ADL and environments, this study enhances both the support to the GPS receiver, and the ability to recognize the driving activity, and a significant number of standing events in comparison with the previous works, including sleeping and watching TV. Since data acquired from the GPS receiver allows the recognition of the geographic location of the user, the proposed framework is capable of distinguishing between different ADL, e.g., the running, walking, walking on stairs, standing, driving and sleeping, and different environments, e.g. classroom, gym, kitchen, library, street, hall, watching TV, bedroom. The proposed framework includes several modules, such as the data acquisition performed with a mobile application, the data processing, and the data fusion and classification methods. The data processing module consists of data cleaning and feature extraction. The most important achievement of our framework is related to\nthe adoption of all sensors available in the mobile devices for the recognition either of ADL or environments. It may pave the way not only for a ubiquitous personal life coach but also for healthy aging or disease monitoring and support.  The focus of this study consists in the performance assessment of several methods with a different number of sensors. It allows the adaption of the framework to various mobile devices currently available in the market, as the number of sensors and their capabilities may be different by each smartphone.  This paper continues with the literature review, presented in Section 2, focused on the location sensors for the recognition of ADL and environments. Next, Section 3 presents the methodology used in this study. The results, showed in Section 4, were obtained with the fusion of the location sensors for the recognition of standing activities. Section 5 discusses the results obtained in this study. Finally, Section 6 presents the conclusions of this study. \n# 2. Related Work\nTo date, the recognition of ADL using some sensors available in the mobile devices [9-14] and several  classification methods have been widely studied. We can conclude that Artificial Neural Networks (ANN)  is one of the most used implementations with the best accuracy [15, 16].   Currently, there are no studies related to the use of the fusion of the data acquired from all sensors  available on mobile devices, including accelerometer, gyroscope, magnetometer, microphone, and GPS  receiver, for the recognition of ADL and environments [1], but there are some studies using subsets of  these sensors. This literature review has its main focus on the use of the GPS receiver for the recognition  of ADL and environments where the analysis is available in previous studies [7, 8]. It makes use of the  motion and magnetic sensors for the identification of standard ADL, the microphone for the recognition  of environmental sounds, and the recognition of standing activities based on the environment   The authors of [17] implemented several methods, such as Support Vector Machine (SVM), Na\u00efve  Bayes, ANN, i.e., Multilayer Perceptron (MLP), Logistic Regression, k-Nearest Neighbor (k-NN), Decision  Trees, and Rule-Based Classifiers, for the recognition of walking, standing, running, sitting, and going  upstairs and downstairs, using the data acquired from accelerometer, magnetometer, GPS receiver, and  gyroscope. They extracted the mean and standard deviation related to the accelerometer, gyroscope and  magnetometer sensors, and the distance, location, and speed from the GPS receiver, reporting accuracies  between 69% and 89% [17].  The data acquired from the accelerometer, GPS receiver and gyroscope for the recognition of ADL,  such as standing, walking, running, walking on stairs, and laying activities, were presented in [18]. The  authors used several features, including mean, energy, standard deviation, the correlation between axis,  and entropy extracted from the motion sensors, and distance, location, and speed obtained from the GPS  receiver. That study reported accuracies of 99% with MLP, 96% with logistic regression, 94.2% with a J48  decision tree, and 93.3% with SVM.  In [19], with the data acquired from the accelerometer, the gyroscope, barometer, and the GPS  receiver, the authors recognized sitting, standing, washing dishes, walking on stairs, cycling and running  with the SVM method. This method was implemented with several features, including mean, standard  deviation, and mean squared extracted from the accelerometer and gyroscope sensors, pressure derived  from the barometer, and altitude difference in meters and speed from the GPS receiver. Finally, the  authors reported an accuracy of 90%.  The authors of [20] used several types of sensors, such as acoustic, location, motion, and medical  sensors for the recognition of preparing food, sleeping, standing, jogging, eating, working, and traveling  activities. They implemented the Na\u00efve Bayes, C4.5 decision tree, RIPPER, SVM, Random Forest, Bagging,  AdaBoost, and Vote methods [20]. The inputs for these methods were the features extracted from the  several sensors [20]. The sound features corresponded to the Mel-Frequency Cepstral Coefficients  (MFCC), the averages of the spectral centroids, the zero crossing rates, and the Linear Predictive Coding  (LPC) values [20]. The distance between to access points is a feature extracted from the Wi-Fi receiver  used by the authors of [20]. The features extracted from the GPS receiver were the GPS location identifier,  the velocity, and the category of the nearest place [20]. The acceleration features extracted were the  elementary activity and energy expenditure obtained by an algorithm [20]. Finally, the Heart-Rate and  Respiration-Rate features were minimum, maximum, and average [20]. The reported results obtained by  the several methods implemented were 68% for the Na\u00efve Bayes, 66% for the C4.5 decision tree, 72% for  the RIPPER, 72% for the SVM, 71% for the Random Forest, 69% for the Bagging, 66% for the AdaBoost,  and 77% for the Vote [20]. \nIn [21], with the accelerometer, GPS receiver, camera, and timer used for the recognition of several  ADL, including sitting, standing, lying, riding an elevator, walking, dining, going upstairs and downstairs,  moving a kettle, washing dishes, preparing a meal, drying hands, moving plates, washing hands, brushing  teeth and combing hair, the authors implemented a decision tree as a classification method. The features  used were mean and range of Y-axis of the accelerometer, standard deviation of each axis of the  accelerometer, sum of intervals of the accelerometer, Signal Magnitude Area (SMA) of amount of  variations of the accelerometer, difference of ranges of the accelerometer, interval between X- and Z-axis  of the accelerometer, distance, location, and speed, reporting an accuracy between 88.24% and 100%  [21].  The SVM was implemented with several features as input, such as the minimum, maximum, mean,  standard deviation, correlation between axis and median crossing extracted from the accelerometer data,  and the distance, location, and speed obtained from the GPS receiver, to recognize the walking, standing  still and running activities, reporting an accuracy around 97.51% [22].  The accelerometer and the GPS receiver were used to recognize standing, traveling by car, traveling  by train and walking activities with a J48 decision tree, Random Forest, ZeroR, Logistic, decision table,  Radial Basis Function Network (RBFN), ANN, Na\u00efve Bayes, and Bayesian Network [23]. The input features  of the methods were the average speed, average accuracy, average rail line closeness, average  acceleration, average heading change, magnitudes of the frequency domain, and the signal variance [23].  The average reported accuracies were 85.2% with a J48 decision tree, 85.1% with Random Forest, 84.8%  with ZeroR, 84.7% with logistic, 84.6% with decision table, 84.4% with RBFN, 84.4% with MLP, 84.2% with  Na\u00efve Bayes, and 84.1% with Bayesian Network [23].  The authors of [24] implemented several methods, including J48 decision tree, MLP, and Likelihood  Ratio (LR) for the recognition of going downstairs, jogging, sitting, standing, going upstairs, and walking  activities using the accelerometer and GPS receiver. The input features for the methods implemented  were the maximum, minimum, mean, standard deviation and zero-crossing rate for each axis for the  accelerometer, the correlation between the axis of the accelerometer, and the distance, location, and  speed acquired from the GPS receiver [24]. The reported accuracies were 92.4% with a J48 decision tree,  91.7% with MLP, and 84.3% with LR [24].  In [25], the accelerometer and GPS receiver are used for the recognition of standing, driving, walking,  running, going upstairs, going downstairs, riding an elevator, and cycling, using Bayesian networks. The  input features used are mean, variance, spectral energy, and spectral entropy from the accelerometer,  and the location retrieved from the GPS receiver, reporting an accuracy of 95% [25].  Other authors implemented methods for the recognition of ADL using the GPS receiver and other  sensors available in off-the-shelf mobile devices. The authors of [26] tested the use of SVM and HMMbased on the data acquired from the accelerometer, gyroscope and GPS receiver, recognizing, standing,  walking, running and sitting activities with a reported reliable accuracy.   In [27], traveling by car or train, and cycling activities were recognized based on the International Road  Index (IRI) and angle of slope measured by the data acquired from the accelerometer, gyroscope and GPS  receiver with reliable accuracy.  The authors of [28] combined the accelerometer with the GPS receiver for the recognition of lying,  sitting, standing, and fall activities. The used the following features: Signal Magnitude Area (SMA), Signal  Magnitude Vector (SMV) and Tilt Angle (TA) from the accelerometer data, and the distance, location, and  speed retrieved from the GPS receiver.   In [29], the GPS receiver, Wi-Fi Positioning System (WPS), GSM Positioning System (GSMPS), and  accelerometer were used for the recognition of standing, sitting, lying, walking, jogging, cycling, traveling  by bus, train, t taxi or car. These authors applied several features, including the numbers of peaks, the  number of troughs, the sum of peaks and troughs, the difference between the maximum peak and the  maximum trough, the difference between the maximum and the minimum either peak or trough.  The  proposed method revealed its effectiveness in terms of energy efficiency (less 53% of battery energy  spent than others).  The authors of [30] used only the GPS receiver for the recognition of working, attending lectures,  shopping, swimming, training in a gym, playing team sports, visiting friends, eating, going to a pub, to the  cinema, to a concert, to the theatre, to a church, and visiting a doctor, based on the density and timebased methods available in the OpenStreetMap (OSM) platform.. Based on different levels of threshold,  the accuracies reported by the authors were between 72.2% and 95.4% with the density-based method,  and between 66.1% and 69.6% with time-based approach [30]. \nFollowing the analysis of the studies available in the literature, Table 1 shows the ADL recognized with  GPS receiver and other sensors, sorted in descending order of their respective number of research works.  As shown, the standing, walking, sitting, running, going upstairs, going downstairs, and driving/traveling  are the most recognized ADL (highlighted in blue background).  \n<div style=\"text-align: center;\">Table 1 - Distribution of the ADL extracted in the studies analyzed.</div>\nADL: \nNumber of \nStudies: \nstanding \n11 \ndriving/traveling (i.e., car, train, bus, taxi) \n9 \nwalking \n8 \nsitting \n7 \nrunning; going upstairs; going downstairs \n6 \nlying; cycling \n4 \njogging \n3 \nwashing dishes; preparing food; eating; working; riding an elevator \n2 \nsleeping; dining; moving a kettle; drying hands; moving plates; washing hands; brushing \nteeth; combing hair; falling; attending lectures; shopping; swimming; training in a gym; \nplaying team sports; visiting friends; going to a pub; going to the cinema; going to a \nconcert; going to the theatre; visiting a doctor; going to church \n1 \n \n<div style=\"text-align: center;\">Table 2 - Distribution of the features extracted in the studies analyzed. </div>\nFeatures: \nNumber of \nStudies: \nlocation \n9 \nspeed \n8 \ndistance \n6 \naltitude difference in meters; velocity; category of the nearest place; International \nRoad Index (IRI); angle of the slope; Points of Interest (POI) \n1 \n \n<div style=\"text-align: center;\">3 - Distribution of the classification methods used in the studies analyzed</div>\nMethods: \nNumber of Studies: \nAverage of Reported Accuracy: \nMultilayer Perceptron (MLP) \n4 \n93.53% \nLogistic Regression \n3 \n93.23% \nSupport Vector Machine (SVM) \n6 \n90.36% \nBayesian Network \n2 \n89.55% \nk-Nearest Neighbor (k-NN) \n1 \n89.00% \nRule-Based Classifiers \n1 \n89.00% \nDecision trees (i.e., J48, C4.5) \n6 \n88.88% \nZeroR \n1 \n84.80% \nDecision Table \n1 \n84.60% \nRadial Basis Function Network (RBFN) \n1 \n84.40% \nLikelihood Ratio (LR) \n1 \n84.30% \nNa\u00efve Bayes \n3 \n83.73% \nRandom Forest \n2 \n78.05% \nVote \n1 \n77.00% \nRIPPER \n1 \n72.00% \nBagging \n1 \n69.00% \nAdaBoost \n1 \n66.00% \n \nTable 2 shows the features extracted from the data acquired from the GPS receiver in descending  order. As observed, the location, speed, and distance are the most common features. On the one hand, \nTable 2 shows the features extracted from the data acquired from the GPS receiver in descending order. As observed, the location, speed, and distance are the most common features. On the one hand,\nthe GPS receiver provides the geographic information of the place of activity. On the other hand, speed  and distance enable to measure the intensity of the event (shown in text with a blue background).   Finally, Table 3 highlights the most popular methods for the recognition of ADL in descending order of  their reported accuracies, such as MLP, Logistic Regression, and SVM (shown in text with a blue  background). Therefore, the method that indicates that the best average accuracy in recognition of ADL  is with the MLP method, with an average accuracy equals to 93.53%.  \n# 3. Methods \nThe development of a multiple data source framework [2-4] for the recognition of ADL enhances the techniques presented in previous studies [7, 8] with the following modules:  \u2022  Data acquisition performed by a mobile application;  \u2022  Data processing forked in data cleaning and feature extraction methods; and  \u2022  Recognition forked in data fusion and classification methods. \n\u2022  Data processing forked in data cleaning and feature extraction methods; and \u2022  Recognition forked in data fusion and classification methods. \n# 3.1. Data Acquisition \nThe study [8] presented the acquisition of data from the accelerometer, the magnetometer, the gyroscope, the microphone, and the GPS receiver related to several ADL and environments, which is stored in the ALLab MediaWiki [31] and made publicly available for validation of these conclusions and further research.  Considering that the data acquisition occurs for 5 seconds every 5 minutes, and users are active for 16 hours per day, we estimate that the data collection time is around 16 minutes per day. Thus, the proposed method is feasible either in the most sophisticated or low-cost mobile devices.  The ultimate goal of this study is to allow the recognition of standing activities, such as sleeping, driving, and watching TV to map the users' lifestyles. \n# 3.2. Data Processing \nThis study uses the accelerometer, gyroscope, and magnetometer data, applying the low pass filter  [32] for the reduction of the effects of the environmental noise and invalid data. This study also acquires  microphone data, and the data is immediately summarized, therefore not compromising the user's  privacy, because it only receives raw data.   Based in both the literature and our previous studies [7, 8], the most relevant features extracted in  the sensors mentioned above are: the features mentioned in [8] plus the distance traveled, and the  environment recognized.  \n# 3.3. A fusion of the Data Acquired from Sensors Available in Off-the-shelf Mobile Devices\nThe features presented in the previous section for the recognition of standing activities are merged,  creating different datasets as depicted in Figure 1.  Thus, based on these datasets, three different experiments were performed: (1) using just the  accelerometer, (2) using the accelerometer combined with the magnetometer, and (3) using the  accelerometer, magnetometer, and gyroscope. \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/16e3/16e3ac15-6212-42e5-b72f-916d9737654c.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">  Figure 1 \u2013 Datasets created for the analysis of standing activities, using the distance traveled calculated with data acquired from the GPS receiver and the previously recognized environment. </div>\n<div style=\"text-align: center;\">3.4. Classification </div>\nBased on the literature review presented in section 2, this study focuses on the fusion of the features  extracted from the location, motion, mechanical, and acoustic sensors available in the off-the-shelf  mobile devices. As observed in the literature, one of the most popular classification methods for the  recognition ADL and environments is the ANN, which reports the best accuracy to recognize standing  activities.  The implementations used both normalized and non-normalized data with some frameworks and  methods implemented and tested in [8], where we tested these methods with different values of  maximum training iterations, such as 106, 2x106 and 4x106. Figure 2 presents the architecture of the  framework for the recognition of ADL and environments. \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9d1c/9d1cf054-7692-4c13-864c-4a9a33e5f2f0.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2 \u2013 ADL and environments recognized by the proposed framework. </div>\n# 4. Results\nWe benchmark both MLP and FNN with Backpropagation, and the DNN to determine the most  accurate method for the recognition of standing activities. The mentioned datasets were created based  on 6000 records equally distributed for the proposed standing activities, namely: watching TV, sleeping,  and driving.  Based on the analyzed combinations of sensors for the identification of standing activities, the  following combinations of sensors\u2019 data were defined:  \u2022  1) Environment recognized and the accelerometer and GPS receiver data;  \u2022  2) Sensors' data collected in the mix 1 plus the magnetometer data;  \u2022  3) Sensors' data collected in the combination 2 plus the gyroscope data.  For the identification of standing activities based on the features extracted from the combination 1,  our experiments revealed that the results obtained with MLP with Backpropagation are always 100%,  except in the dataset 1 (66.67%) with non-normalized data. Also, the results obtained with the FNN with  Backpropagation are still 100%, except when in both datasets 4 and 5 (96.67%) with non-normalized data.  Finally, the results obtained with the DNN are always 100%, except when is used the dataset 1 (33.37%)  with non-normalized data.  Therefore, for the recognition of standing activities based on the features extracted from the  combination 2, the obtained results on the implementation of the MLP with Backpropagation are always  around 100%, except when is used the dataset 1 (66.72%) with non-normalized data. Similarly, the results  obtained with the FNN with Backpropagation are always 100%, except when is used the dataset 1  (94.03%) with non-normalized data. At last, the results obtained with the DNN are still 100% with  normalized data and 33.42% with non-normalized data.  Finally, for the recognition of standing activities based on the features extracted from the combination  3, the results revealed an accuracy equals to 100% by MLP method, except when is used the dataset 1  (55.35%) with non-normalized data. Congruently, the results obtained with the FNN with Backpropagation  are always 100%, except when is used the dataset 1 (96%) with non-normalized data. Finally, the results  obtained with the DNN are still 100% with normalized data and 33.4% with non-normalized data.  Comparing the maximum accuracies reported by the different implementations, Table 4 presents the  best results reported with the various combinations of sensors and datasets. \n<div style=\"text-align: center;\">Table 4 - Best accuracies obtained in recognition of standing activities. </div>\n \nFramework \nDataset \n(Combination) \nIterations needed for \ntraining \nBest accuracy \nachieved (%) \nNon-normalized data \nNeuroph \n2 (1) \n106 \n99.97 \n2 (3) \n106 \n100.00 \n4 (2) \n106 \n100.00 \nEncog \n1 (1) \n106 \n100.00 \n3 (2) \n106 \n99.97 \n2 (3) \n106 \n99.98 \nDeep learning \n2 (1) \n106 \n100.00 \n2 (2) \n106 \n33.42 \n1 (3) \n106 \n33.40 \nNormalized \ndata \nNeuroph \n2 (1) \n106 \n100.00 \n5 (2) \n106 \n100.00 \n1 (3) \n106 \n100.00 \nEncog \n1 (1, 2 or 3) \n106 \n100.00 \nDeep learning \n1 (1, 2 or 3) \n106 \n100.00 \n \n# 5. Discussion \nThis paper complements the research about the development of a framework for the recognition of  ADL and environments [2-4] using all sensors available in the off-the-shelf mobile devices, providing the  identification of some ADL with movement, i.e., running, standing, going upstairs, going downstairs, and  walking, some user\u2019s environments, i.e., bar, classroom, gym, kitchen, library, street, hall, watching TV,  and bedroom, and some standing activities, i.e., watching TV, driving and sleeping. Table VIII summarizes \nthe literature on the recognition of ADL and environments. Also, Figure 10 presents the results obtained  with the proposed framework for the identification of ADL and environmental sounds using the motion,  magnetic, acoustic, and location sensors. The highlighted values in Table V represents the  ADL/Environments recognized by the proposed framework.  As shown in Table 5, the results obtained with either the accelerometer or accelerometer combined  with magnetometer and gyroscope, revealed the ability of our framework to recognize 5 of 6 ADL  presented in the literature (83%). On the other hand, the proposed framework can identify 4 of 8 events  presented in the literature (50%) with the accelerometer, magnetometer, gyroscope, and microphone.  Finally, 6 of 7 ADL presented in the literature (86%) are recognized by the proposed framework with the  accelerometer, magnetometer, gyroscope, microphone, and GPS receiver.   \n<div style=\"text-align: center;\">able 5 - Most recognized ADL and environments based on the literature review distributed by the sensors used (# epresents the number of studies available in the literature that identifies the ADL/environment).  </div>\nAccelerometer \nAccelerometer \nMagnetometer \nGyroscope \nAccelerometer \nMagnetometer \nGyroscope \nMicrophone \nAccelerometer \nMagnetometer \nGyroscope \nMicrophone \nGPS receiver \nADL \n# \nADL \n# \nADL \nEnvironment \n# \nADL \n# \nWalking \n63 \nWalking \n21 \nEmergency \nvehicles  \n6 \nResting \nStanding \n11 \nResting \nStanding \n48 \nGoing \ndownstairs \n17 \nSleeping \n5 \nDriving \nTravelling  \n9 \nGoing upstairs \n45 \nGoing upstairs \n17 \nWalking \n5 \nWalking \n8 \nGoing \ndownstairs \n44 \nResting \nStanding \n16 \nResting \nStanding \n5 \nSitting \n7 \nRunning \n31 \nRunning \n13 \nStreet traffic \n5 \nRunning \n6 \nSitting \n30 \nSitting \n11 \nOcean \n5 \nGoing upstairs \n6 \n \n \n \n \nDriving \n4 \nGoing \ndownstairs \n6 \n \n \n \n \nRiver \n4 \n \n \n \nAs shown in Table 6, he best accuracies in recognition of standard ADL is 89.51%, in the identification  of environments is 86.50%, and, in the identification of standing activities is 100%. Thus, we recommend  the implementation of DNN method with normalized data and the application of L2 regularization for the  recognition of the standard ADL and standing activities and the implementation of FNN method with nonnormalized data for the identification of environments. Also, the average accuracy of the framework for  all devices with different combinations of sensors is 91.27%.  \n \nStages of the framework \nAccelerometer \nMicrophone \nGPS \nAccelerometer \nMagnetometer \nMicrophone \nGPS \nAccelerometer \nMagnetometer \nGyroscope \nMicrophone \nGPS \nAverage \naccuracy \nRecognition of common ADL \n85.89% \n86.49% \n89.51% \n87.30% \nRecognition of environments \n86.50% \n86.50% \n86.50% \n86.50% \nRecognition of standing \nactivities \n100.00% \n100.00% \n100.00% \n100.00% \nAverage accuracy \n90.80% \n91.00% \n92% \n91.27% \n \nThe hardware of off-the-shelf mobile devices includes several sensors that can handle the recognition  of ADL and environments in a framework. It combines the data acquired from an enlarged set of sensors  available in the mobile devices to develop a framework that adapts their functionalities with the number  of sensors available in the equipment used. This paper finished the definition of the methods for the  different stages of the framework. The framework starts with the data acquisition, data cleaning and  feature extraction methods, and, at the first stage of the recognition of ADL, the framework uses the DNN  for the identification of walking, running, standing, going downstairs, and going upstairs. In the second  stage, the framework recognizes some environments with the FNN with Backpropagation, and these are  a bar, classroom, gym, kitchen, library, street, hall, watching TV, and bedroom. Finally, in the third stage,  the framework uses DNN for the recognition of standing activities, and these are watching TV, sleeping,  and driving.  The recognition of the ADL and environments is based on the features extracted from the different  sensors' data (excluding the microphone and the GPS receiver), such as the five greatest distances  between the maximum peaks, the average, standard deviation, variance and median of the maximum  peaks, and the standard deviation, average, maximum value, minimum value, variance and median of the  raw signal. The features extracted from the microphone data are the 26 MFCC coefficients, the standard  deviation, average, maximum value, minimum value, variance, and median of the raw signal. Also, the  unique feature obtained from the GPS receiver; the distance traveled, also enables to identify the users'  location.  For the development of a framework for the recognition of ADL and environments, we compared three  different implementations of ANN, and these are MLP and FNN with Backpropagation and DNN. Our study  revealed that an average accuracy of 87.50% in recognition of standard ADL, 86.50% in identification of  environments, and 100% in recognition of standing activities. Finally, the average accuracy of the  proposed framework is 91.27%. Thus, the proposed framework proves its reliability in the identification  of the ADL and its environments. \n# Acknowledgments\nThis work was supported by FCT project UID/EEA/50008/2013 (Este trabalho foi suportado pelo projecto FCT UID/EEA/50008/2013).  The authors would also like to acknowledge the contribution of the COST Action IC1303 \u2013 AAPELE \u2013 Architectures, Algorithms, and Protocols for Enhanced Living Environments.  \n# References\n1]  D. Foti and J. S. Koketsu, \"Activities of daily living,\" Pedretti\u2019s Occupational Therapy: Practical  Skills for Physical Dysfunction, vol. 7, pp. 157-232, 2013  2]  I. Pires, N. Garcia, N. Pombo, and F. Fl\u00f3rez-Revuelta, \"From Data Acquisition to Data Fusion: A  Comprehensive Review and a Roadmap for the Identification of Activities of Daily Living Using  Mobile Devices,\" Sensors, vol. 16, p. 184, 2016  3]  I. M. Pires, N. M. Garcia, and F. Fl\u00f3rez-Revuelta, \"Multi-sensor data fusion techniques for the  identification of activities of daily living using mobile devices,\" in Proceedings of the ECMLPKDD  2015 Doctoral Consortium, European Conference on Machine Learning and Principles and  Practice of Knowledge Discovery in Databases, Porto, Portugal, 2015.  4]  I. M. Pires, N. M. Garcia, N. Pombo, and F. Fl\u00f3rez-Revuelta, \"Identification of Activities of Daily  Living Using Sensors Available in off-the-shelf Mobile Devices: Research and Hypothesis,\" in  Ambient Intelligence-Software and Applications\u20137th International Symposium on Ambient  Intelligence (ISAmI 2016), 2016, pp. 121-130.  5]  L. H. A. Salazar, T. Lacerda, J. V. Nunes, and C. Gresse von Wangenheim, \"A Systematic Literature  Review on Usability Heuristics for Mobile Phones,\" International Journal of Mobile Human  Computer Interaction, vol. 5, pp. 50-61, 2013. DOI: 10.4018/jmhci.2013040103  6]  N. M. Garcia, \"A Roadmap to the Design of a Personal Digital Life Coach,\" in ICT Innovations 2015,  ed: Springer, 2016.  7]  I. M. Pires, N. M. Garcia, N. Pombo, F. Fl\u00f3rez-Revuelta, and S. Spinsante, \"Pattern Recognition  Techniques for the Identification of Activities of Daily Living using Mobile Device Accelerometer,\"  ed: arXiv:1711.00096, 2017.  8]  I. M. Pires, N. M. Garcia, N. Pombo, F. Fl\u00f3rez-Revuelta, S. Spinsante, and M. C. Teixeira,  \"Identification of Activities of Daily Living through Data Fusion on Motion and Magnetic Sensors \n  D. Foti and J. S. Koketsu, \"Activities of daily living,\" Pedretti\u2019s Occupational Therapy: Practical  Skills for Physical Dysfunction, vol. 7, pp. 157-232, 2013    I. Pires, N. Garcia, N. Pombo, and F. Fl\u00f3rez-Revuelta, \"From Data Acquisition to Data Fusion: A  Comprehensive Review and a Roadmap for the Identification of Activities of Daily Living Using  Mobile Devices,\" Sensors, vol. 16, p. 184, 2016    I. M. Pires, N. M. Garcia, and F. Fl\u00f3rez-Revuelta, \"Multi-sensor data fusion techniques for the  identification of activities of daily living using mobile devices,\" in Proceedings of the ECMLPKDD  2015 Doctoral Consortium, European Conference on Machine Learning and Principles and  Practice of Knowledge Discovery in Databases, Porto, Portugal, 2015.    I. M. Pires, N. M. Garcia, N. Pombo, and F. Fl\u00f3rez-Revuelta, \"Identification of Activities of Daily  Living Using Sensors Available in off-the-shelf Mobile Devices: Research and Hypothesis,\" in  Ambient Intelligence-Software and Applications\u20137th International Symposium on Ambient  Intelligence (ISAmI 2016), 2016, pp. 121-130.    L. H. A. Salazar, T. Lacerda, J. V. Nunes, and C. Gresse von Wangenheim, \"A Systematic Literature  Review on Usability Heuristics for Mobile Phones,\" International Journal of Mobile Human  Computer Interaction, vol. 5, pp. 50-61, 2013. DOI: 10.4018/jmhci.2013040103    N. M. Garcia, \"A Roadmap to the Design of a Personal Digital Life Coach,\" in ICT Innovations 2015,  ed: Springer, 2016.    I. M. Pires, N. M. Garcia, N. Pombo, F. Fl\u00f3rez-Revuelta, and S. Spinsante, \"Pattern Recognition  Techniques for the Identification of Activities of Daily Living using Mobile Device Accelerometer,\"  ed: arXiv:1711.00096, 2017.    I. M. Pires, N. M. Garcia, N. Pombo, F. Fl\u00f3rez-Revuelta, S. Spinsante, and M. C. Teixeira,  \"Identification of Activities of Daily Living through Data Fusion on Motion and Magnetic Sensors \n[2]\n[3]\n[4]\nembedded on Mobile Devices,\" Pervasive and Mobile Computing, vol. 47, pp. 78-93, 2018. DOI:  10.1016/j.pmcj.2018.05.005  [9]  O. Banos, M. Damas, H. Pomares, and I. Rojas, \"On the use of sensor fusion to reduce the impact  of rotational and additive noise in human activity recognition,\" Sensors (Basel), vol. 12, pp. 803954, 2012. DOI: 10.3390/s120608039  [10]  M. A. A. Akhoundi and E. Valavi, \"Multi-Sensor Fuzzy Data Fusion Using Sensors with Different  Characteristics,\" arXiv preprint arXiv:1010.6096, 2010  [11]  P. Paul and T. George, \"An Effective Approach for Human Activity Recognition on Smartphone,\"  2015 Ieee International Conference on Engineering and Technology (Icetech), pp. 45-47, 2015.  DOI: 10.1109/icetech.2015.7275024  [12]  Y.-W. Hsu, K.-H. Chen, J.-J. Yang, and F.-S. Jaw, \"Smartphone-based fall detection algorithm using  feature extraction,\" in 2016 9th International Congress on Image and Signal Processing,  BioMedical Engineering and Informatics (CISP-BMEI), Datong, China, 2016, pp. 1535-1540.  [13]  S. Dernbach, B. Das, N. C. Krishnan, B. L. Thomas, and D. J. Cook, \"Simple and Complex Activity  Recognition through Smart Phones,\" in 2012 8th International Conference on Intelligent  Environments (IE), Guanajuato, Mexico, 2012, pp. 214-221.  [14]  C. Shen, Y. F. Chen, and G. S. Yang, \"On Motion-Sensor Behavior Analysis for Human-Activity  Recognition via Smartphones,\" in 2016 Ieee International Conference on Identity, Security and  Behavior Analysis (Isba), Sendai, Japan, 2016, pp. 1-6.  [15]  D. Wang, \"Pattern recognition: neural networks in perspective,\" IEEE Expert, vol. 8, pp. 52-60,  1993. DOI: 10.1109/64.223991  [16]  K. Doya and D. Wang, \"Exciting Time for Neural Networks,\" Neural Networks, vol. 61, pp. xv-xvi,  2015. DOI: 10.1016/s0893-6080(14)00260-3  [17]  M. Shoaib, H. Scholten, and P. J. M. Havinga, \"Towards Physical Activity Recognition Using  Smartphone Sensors,\" 2013 Ieee 10th International Conference on and 10th International  Conference on Autonomic and Trusted Computing (Uic/Atc) Ubiquitous Intelligence and  Computing, pp. 80-87, 2013. DOI: 10.1109/Uic-Atc.2013.43  [18]  W. C. Hung, F. Shen, Y. L. Wu, M. K. Hor, and C. Y. Tang, \"Activity Recognition with Sensors on  Mobile Devices,\" Proceedings of 2014 International Conference on Machine Learning and  Cybernetics (Icmlc), Vol 2, pp. 449-454, 2014. DOI: 10.1109/icmlc.2014.7009650  [19]  M. Altini, R. Vullers, C. Van Hoof, M. van Dort, and O. Amft, \"Self-Calibration of Walking Speed  Estimations Using Smartphone Sensors,\" 2014 Ieee International Conference on Pervasive  Computing and Communications Workshops (Percom Workshops), pp. 10-18, 2014. DOI:  10.1109/PerComW.2014.6815158  [20] M. Lu\u0161trek, B. Cvetkovic, V. Mirchevska, \u00d6. Kafal\u0131, A. Romero, and K. Stathis, \"Recognising lifestyle  activities  of  diabetic  patients  with  a  smartphone,\"  2015.  DOI:  10.4108/icst.pervasivehealth.2015.259118   [21]  H. H. Wu, E. D. Lemaire, and N. Baddour, \"Change-of-state determination to recognize mobility  activities using a BlackBerry smartphone,\" Conf Proc IEEE Eng Med Biol Soc, vol. 2011, pp. 52525, 2011. DOI: 10.1109/IEMBS.2011.6091299  [22]  S. Kaghyan and H. Sarukhanyan, \"Accelerometer and GPS Sensor Combination Based System for  Human Activity Recognition,\" 2013 Computer Science and Information Technologies (Csit), pp. 19, 2013. DOI: 10.1109/CSITechnol.2013.6710352  [23]  A. Bloch, R. Erdin, S. Meyer, T. Keller, and A. de Spindler, \"Battery-Efficient Transportation Mode  Detection on Mobile Devices,\" 2015 16th Ieee International Conference on Mobile Data  Management, Vol 1, pp. 185-190, 2015. DOI: 10.1109/Mdm.2015.16  [24]  M. N. S. Zainudin, M. N. Sulaiman, N. Mustapha, and T. Perumal, \"Activity Recognition based on  Accelerometer Sensor using Combinational Classifiers,\" 2015 Ieee Conference on Open Systems  (Icos), pp. 68-73, 2015. DOI: 10.1109/icos.2015.7377280  [25]  X. Zou, M. Gonzales, and S. Saeedi, \"A Context-aware Recommendation System using  smartphone sensors,\" in 2016 IEEE 7th Annual Information Technology, Electronics and Mobile  Communication Conference (IEMCON), 2016, pp. 1-6.  [26]  S. Kaghyan and H. Sarukhanyan, \"Multithreaded Signal Preprocessing Approach for Inertial  Sensors of Smartphone,\" Tenth International Conference on Computer Science and Information  Technologies  Revised  Selected  Papers  Csit-2015,  pp.  85-89,  2015.  DOI:  10.1109/CSITechnol.2015.7358256 \n[10]\n[18] \n[19]\n[21]\n[22]\n[27]  F. Seraj, N. Meratnia, and P. J. M. Havinga, \"RoVi: Continuous transport infrastructure monitoring  framework for preventive maintenance,\" in 2017 IEEE International Conference on Pervasive  Computing and Communications (PerCom), 2017, pp. 217-226.  [28]   H. Yi, L. Ye, and B. Shu-Di, \"Fall detection by built-in tri-accelerometer of smartphone,\" pp. 184187, 2012. DOI: 10.1109/bhi.2012.6211540   [29]  T. O. Oshin and S. Poslad, \"LALS: A Low Power Accelerometer Assisted Location Sensing  technique for smartphones,\" in 2013 IEEE Global Communications Conference (GLOBECOM),  2013, pp. 127-133.  [30]  S. Difrancesco, P. Fraccaro, S. N. v. d. Veer, B. Alshoumr, J. Ainsworth, R. Bellazzi, et al., \"Out-ofHome Activity Recognition from GPS Data in Schizophrenic Patients,\" in 2016 IEEE 29th  International Symposium on Computer-Based Medical Systems (CBMS), 2016, pp. 324-328.  [31]  ALLab. (2017, September 2nd). August 2017- Multi-sensor data fusion in mobile devices for the  identification  of  activities  of  daily  living  -  ALLab  Signals.  Available:  https://allab.di.ubi.pt/mediawiki/index.php/August_2017-_Multisensor_data_fusion_in_mobile_devices_for_the_identification_of_activities_of_daily_living  [32]  V. Graizer, \"Effect of low-pass filtering and re-sampling on spectral and peak ground acceleration  in strong-motion records,\" in Proc. 15th World Conference of Earthquake Engineering, Lisbon,  Portugal, 2012, pp. 24-28. \n[32]\n",
    "paper_type": "benchmark",
    "attri": {
        "background": {
            "problem background": "The recognition of Activities of Daily Living (ADL) has gained importance due to the proliferation of mobile devices equipped with various sensors. Previous studies have focused on subsets of these sensors, but there is a lack of comprehensive frameworks that utilize all available sensors for ADL recognition.",
            "purpose of benchmark": "The benchmark aims to evaluate the performance of different artificial neural network implementations in recognizing ADL and environments using data from mobile device sensors."
        },
        "problem": {
            "definition": "The benchmark addresses the challenge of accurately identifying a range of ADL and their respective environments based on data collected from multiple sensors in mobile devices.",
            "key obstacle": "Existing benchmarks often utilize limited sensor data or focus on specific activities, which restricts their applicability and effectiveness in real-world scenarios."
        },
        "idea": {
            "intuition": "The development of a framework that integrates data from all available sensors in mobile devices was inspired by the need for more accurate and comprehensive recognition of ADL and environments.",
            "opinion": "The authors believe that this benchmark is crucial for advancing research in the field of human activity recognition and could significantly improve personal digital life coaching applications.",
            "innovation": "This benchmark is innovative in its use of a multi-sensor approach, combining data from accelerometers, gyroscopes, magnetometers, microphones, and GPS receivers, unlike previous benchmarks that focused on fewer sensors.",
            "benchmark abbreviation": "ADL-Bench"
        },
        "dataset": {
            "source": "The dataset was created from data collected by mobile devices equipped with multiple sensors, including accelerometers, gyroscopes, magnetometers, microphones, and GPS receivers.",
            "desc": "The dataset consists of 6,000 records, equally distributed across various standing activities such as watching TV, sleeping, and driving.",
            "content": "The dataset includes data types from motion sensors (accelerometer, gyroscope, magnetometer), acoustic sensors (microphone), and location sensors (GPS).",
            "size": "6,000",
            "domain": "Human Activity Recognition",
            "task format": "Activity Recognition"
        },
        "metrics": {
            "metric name": "Accuracy, F1-score",
            "aspect": "The metrics measure the performance of the models in terms of their ability to correctly identify ADL and environments.",
            "principle": "The choice of accuracy and F1-score as metrics is based on their relevance in evaluating classification models, particularly in scenarios with imbalanced classes.",
            "procedure": "Model performance is evaluated through the application of the chosen metrics on the predictions made by the models against the ground truth labels in the dataset."
        },
        "experiments": {
            "model": "The benchmark tested multiple models, including Multilayer Perceptron (MLP), Feedforward Neural Networks (FNN), and Deep Neural Networks (DNN).",
            "procedure": "Models were trained using various combinations of sensor data, with specific parameters adjusted for each model type to optimize performance.",
            "result": "The experiments revealed that MLP consistently achieved an accuracy of 100% for normalized data in recognizing standing activities, while DNN also performed well under similar conditions.",
            "variability": "Variability in results was accounted for by conducting multiple trials and using different subsets of the dataset to ensure robustness."
        },
        "conclusion": "The benchmark demonstrated that the proposed multi-sensor framework significantly improves the recognition of ADL and environments, achieving high accuracies across various configurations.",
        "discussion": {
            "advantage": "The benchmark provides a comprehensive framework that leverages all available sensors in mobile devices, enhancing the accuracy and reliability of ADL recognition.",
            "limitation": "One limitation is the dependency on the quality of sensor data, which can vary across different mobile devices and environments, potentially affecting the benchmark's generalizability.",
            "future work": "Future research could explore the integration of additional sensor types and advanced machine learning techniques to further improve the recognition capabilities of the framework."
        },
        "other info": {
            "acknowledgments": "This work was supported by FCT project UID/EEA/50008/2013.",
            "additional notes": "The dataset is publicly available for further validation and research."
        }
    },
    "mount_outline": [
        {
            "section number": "2.1",
            "key information": "The benchmark addresses the challenge of accurately identifying a range of Activities of Daily Living (ADL) and their respective environments based on data collected from multiple sensors in mobile devices."
        },
        {
            "section number": "2.2",
            "key information": "The recognition of Activities of Daily Living (ADL) has gained importance due to the proliferation of mobile devices equipped with various sensors."
        },
        {
            "section number": "3.1",
            "key information": "This benchmark is innovative in its use of a multi-sensor approach, combining data from accelerometers, gyroscopes, magnetometers, microphones, and GPS receivers."
        },
        {
            "section number": "3.2",
            "key information": "The benchmark tested multiple models, including Multilayer Perceptron (MLP), Feedforward Neural Networks (FNN), and Deep Neural Networks (DNN)."
        },
        {
            "section number": "7.1",
            "key information": "One limitation is the dependency on the quality of sensor data, which can vary across different mobile devices and environments, potentially affecting the benchmark's generalizability."
        },
        {
            "section number": "7.4",
            "key information": "Future research could explore the integration of additional sensor types and advanced machine learning techniques to further improve the recognition capabilities of the framework."
        }
    ],
    "similarity_score": 0.5637317767858159,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-0011_large/papers/A Multiple Data Source Framework for the Identification of Activities of Daily Living Based on Mobile Device Data.json"
}