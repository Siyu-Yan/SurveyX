{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:1909.03032",
    "title": "Reproducibility via Crowdsourced Reverse Engineering: A Neural Network Case Study With DeepMind's Alpha Zero",
    "abstract": "The reproducibility of scientific findings are an important hallmark of quality and integrity in research. The scientific method requires hypotheses to be subjected to the most crucial tests, and for the results to be consistent across independent trials. Therefore, a publication is expected to provide sufficient information for an objective evaluation of its methods and claims. This is particularly true for research supported by public funds, where transparency of findings are a form of return on public investment. Unfortunately, many publications fall short of this mark for various reasons, including unavoidable ones such as intellectual property protection and national security of the entity creating those findings. This is a particularly important and documented problem in medical research, and in machine learning. Fortunately for those seeking to overcome these difficulties, the internet makes it easier to share experiments, and allows for crowd-sourced reverse engineering. A case study of this capability in neural networks research is presented in this paper. The significant success of reverse-engineering the important accomplishments of DeepMind's Alpha Zero exemplifies the leverage that can be achieved by a concerted effort to reproduce results.",
    "bib_name": "tanksley2019reproducibilitycrowdsourcedreverseengineering",
    "md_text": "# Reproducibility via Crowdsourced Reverse Engineering: A Neural Network Case Study With DeepMind\u2019s Alpha Zero  Dustin Tanksley and Donald C. Wunsch II  Applied Computational Intelligence Laboratory  Missouri University of Science and Technology \n# Reproducibility via Crowdsourced Reverse Engineering: A Neural Network Case Study With DeepMind\u2019s Alpha Zero \nReproducibility via Crowdsourced Reverse Engineering: A Neural Network Case Study With DeepMind\u2019s Alpha Zero  Dustin Tanksley and Donald C. Wunsch II  Applied Computational Intelligence Laboratory  Missouri University of Science and Technology \nThe reproducibility of scientific findings are an important hallmark of quality and integrity in research.  The scientific method requires hypotheses to be subjected to the most crucial tests, and for the results  to be consistent across independent trials.  Therefore, a publication is expected to provide sufficient  information for an objective evaluation of its methods and claims. This is particularly true for research  supported by public funds, where transparency of findings are a form of return on public investment.  Unfortunately, many publications fall short of this mark for various reasons, including unavoidable ones such as intellectual property protection and national security of the entity creating those findings.  This  is a particularly important and documented problem in medical research, and in machine learning.  Fortunately for those seeking to overcome these difficulties, the internet makes it easier to share  experiments, and allows for crowd-sourced reverse engineering. A case study of this capability in neural networks research is presented in this paper. The significant success of reverse-engineering the  important accomplishments of DeepMind\u2019s Alpha Zero exemplifies the leverage that can be achieved by a concerted effort to reproduce results.  \n# 1. Introduction \n1.1 Reproducibility \nConcerns about reproducibility have received increased visibility for several reasons, particularly since  the Internet offers the opportunity for more data sharing than was available to previous generations.  Furthermore, several prominent studies have shown that many reports in highly-reputed journals were  not reproducible. (Baker, 2016) surveyed 1,500 scientists and found \u201cMore than 70% of researchers  have tried and failed to reproduce another scientist's experiments, and more than half have failed to  reproduce their own experiments\u201d and that \u201c52% of those surveyed agree that there is a significant  'crisis' of reproducibility\u201d. Therefore, many top journals are demanding improvements in the description of research and sharing of data to enhance reproducibility. (Greene, Garmire, Gilbert, Ritchie, & Hunter, 2017) states that \u201cJournals, although they conduct peer review, do not validate each experimental resul or claim.\u201d, and goes on to say  \n\u201cThe act of rigorous secondary data analysis is critical for maintaining the accuracy and  efficiency of scientific discovery. As scientists, we make predictions, perform experiments and generate data to test those predictions. When we ask rigorous questions, we obtain more  accurate findings that can prevent harm.\u201d \n# (Committee on Reproducibility and Replicability in Science et al., 2019) notes how difficult  reproducibility is, stating  \n\u201cWhen results are produced by complex computational processes using large volumes of data,  the traditional methods section of a scientific paper is insufficient to convey the necessary  information for others to reproduce the results. Additional information related to data, code,  models, and computational analysis is needed.\u201d \nHowever, the desire for reproducibility can conflict with legitimate interests of the researchers who  provide the initial results. The pros and cons of sharing results have been vigorously debated in the  medical literature. But this is even more salient when commercial researchers have proprietary  responsibilities that may preclude sufficient disclosure to allow reproducibility. A prominent example of this in neural networks are the reports of the breakthrough accomplishments of DeepMind\u2019s AlphaGo  series of systems. There is little doubt of the financial value of their neural network-related intellectual  property. As of this writing, in three years since the victory, Google grew by approximately 70% in  market value, a gain of over $350 billion. Of course, not all of that is attributable to the victory, but it is  still clear that the company\u2019s reputation in neural-network based reinforcement learning is a significant part of its perceived value. The victory not only generated positive media coverage and bolstered the  prospects of AI-enabled products, but even greatly influenced national budgets with South Korea alone  increasing AI spending by 860 million (Zastrow, 2016), and China trying to draw equal to the US by 2020 and expanding its AI industry to $150 billion by 2030 (\u201cBeijing Wants A.I. to Be Made in China by 2030\u2014 The New York Times,\u201d 2017; \u201cChina wants to be a $150 billion world leader in AI by 2030,\u201d 2017)  \n# \n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f7f8/f7f83d1b-10e2-4012-831a-6849c85619c7.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">gure 1 China drastically increases AI spending following Alpha Go's Victory (\u201cChina Is Starting To Edge Out The US In AI </div>\n<div style=\"text-align: center;\">Figure 1 China drastically increases AI spending following Alpha Go's Victory (\u201cChina Is Starting To Edge Out The US In AI  Investment\u2014CB Insights Research,\u201d 2019) </div>\nResearch,\u201d 2019) \nAlthough DeepMind was justified in retaining key information, reproducibility of these important results  was initially limited. Only the generalized search and training algorithms were provided, not the full  source code or neural network architecture that was used. Trying to directly reproduce results using  machine learning provides a unique challenge, as it is very costly due to the computing power needed to  validate a single trial, much less actually finding the correct architecture and hyperparameters.  DeepMind clearly spent many millions on computing resources alone to achieve these results. The labor  hours and training time of failed models further increased the cost. Furthermore, previous progress in  Go was among the impressive accomplishments that led to the US $500 million equivalent purchase of  DeepMind by Google in 2014. The extraordinary economic impact of this research discussed above  justifies these expenditures. It therefore is not surprising that details that would enhance reproducibility  were withheld. If source code and final training weights were provided however, the cost to replicate  results would drop by several orders of magnitude.  In lieu of that, reverse-engineering for  reproducibility may be the only viable option. This is difficult, but not nearly as difficult as developing  the contribution in the first place. This example clearly illustrates the overwhelming importance of  reverse-engineering for reproducibility. As a case study, it is highly instructive for future efforts.  \n# 2. Development of Go-playing Systems and Timeline of AlphaGo \nMost Go researchers outside the DeepMind group did not expect a champion-level system in the near  term, for good reason. Go is much harder than any of the games solved by previous AI systems. The  game tree of Go is estimated to be between 10575and 10620, hundreds of orders of magnitude greater  than the game tree for Chess estimated around 10120 (L. Victor Allis, 1994; L.V. Allis, Herik, & Herschberg 1990). Fundamental research has been conducted over a period of decades. (Silver, Sutton, & M\u00fcller,  2007) notes that it speculated that Go \u201crequires an altogether different approach to other games.\u201c  (Krikke, 2007) even foresaw that \u201cmethods which are successful at determining the value of Go  positions might prove useful for image processing, as the analysis of Go positions is a very visual task\u201d .  Alpha Go used these, and many other insights that had built up over time, notably training a neural  network to screen for a smaller subset of moves (Zaman & Wunsch, 1999), training via reinforcement  learning in self-play (Zaman, Prokhorov, & Wunsch, 1997) and Monte-Carlo-based methods (D. Silver,  2009).  \nMost Go researchers outside the DeepMind group did not expect a champion-level system in the near  term, for good reason. Go is much harder than any of the games solved by previous AI systems. The  game tree of Go is estimated to be between 10575and 10620, hundreds of orders of magnitude greater  than the game tree for Chess estimated around 10120 (L. Victor Allis, 1994; L.V. Allis, Herik, & Herschberg 1990). Fundamental research has been conducted over a period of decades. (Silver, Sutton, & M\u00fcller,  2007) notes that it speculated that Go \u201crequires an altogether different approach to other games.\u201c  (Krikke, 2007) even foresaw that \u201cmethods which are successful at determining the value of Go  positions might prove useful for image processing, as the analysis of Go positions is a very visual task\u201d .  Alpha Go used these, and many other insights that had built up over time, notably training a neural  network to screen for a smaller subset of moves (Zaman & Wunsch, 1999), training via reinforcement  learning in self-play (Zaman, Prokhorov, & Wunsch, 1997) and Monte-Carlo-based methods (D. Silver,  2009).   However, none of these systems were scaled up to nearly the level of AlphaGo. The human design effor and computational resources for training the system were unprecedented. DeepMind was given access  to thousands of Google\u2019s proprietary TPUs, new hardware specifically designed for machine learning  calculations, and trained for months.  Even in the context of the extensive resources invested, the  accomplishment was a major milestone in the history of neural networks and AI. Indeed, public and  private investment in the field has dramatically increased since this accomplishment.  The same researchers announced an even more significant result just one year later (Silver,  Schrittwieser, et al., 2017). They developed a new system, named AlphaGo Zero, that learned without  historical game data, but purely by self-play. Furthermore, it performed far better than the original  system, renamed AlphaGo Lee (in honor of Sedol), and required only 40 days of training (albeit on state of-the-art hardware) compared to months for the previous research.   \nThe same researchers announced an even more significant result just one year later (Silver,  Schrittwieser, et al., 2017). They developed a new system, named AlphaGo Zero, that learned without  historical game data, but purely by self-play. Furthermore, it performed far better than the original  system, renamed AlphaGo Lee (in honor of Sedol), and required only 40 days of training (albeit on stateof-the-art hardware) compared to months for the previous research.   \nThe system was then generalized to one that could learn arbitrary turn-based games, called Alpha Zero,  with convincing performance learning from purely win-loss data on several games, notably chess, which  only required 9 hours of training (Silver, Hubert, et al., 2017). It is notable that in 1000 games against the strongest rule based chess engine, Stockfish, Alpha Zero won 155 games, and lost only 6. This result was far beyond what many expected, as computers had already dominated chess for decades. Even Demis  Hassabis, CEO of DeepMind noted in (Sadler & Regan, 2019)\u201cit was far from clear that a program of this  type could possibly hope to compete with the specialist handcrafted chess engines that had decades of  cumulative effort spent on them from some of the best computer scientists and chess grandmasters in  the world.\u201d If these results could be independently reproduced, it would confirm the importance of the  tools described in their research. \n# eline of Reverse-Engineered Reproducibility Studies of Alpha Ze\n3. Timeline of Reverse-Engineered Reproducibility Studies of Alpha Zero\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/e395/e39581dd-6b03-495a-b44b-4c28b9b3ac01.png\" style=\"width: 50%;\"></div>\nGo and Chess.  When DeepMind published their first paper on AlphaGo, interest began to build over the new method,  which quickly became international news with the defeat of Lee Sedol. Despite this, replications efforts  really went nowhere outside of promises for more investments into AI research. This initial version had  used hundreds of thousands of master level games to train itself before being self-training, and direct  access to this volume of data was difficult to get. This was a major roadblock until AlphaGo Zero was  introduced. AlphaGo Zero managed to learn the entire game thru only self-play, meaning no data  repository was needed to train the agent. Quickly group efforts were established to combine computing  resources to replicate the results published, and this only spread more rapidly when DeepMind shared  that the methods had been applied to other games, chess and shoji, with successful results.  The results in chess provided a unique opportunity for reverse-engineered reproducibility, as rule based  game engines had already reached the pinnacle of chess play, where Go systems had no reliable  comparison tool other than top ranked humans who couldn\u2019t compete with Alpha Go anymore. As well,  DeepMind claimed only 9 hours of training time for chess, versus the 40 days they had used for AlphaGo  Zero. Despite the fact that training would still be much slower due to the not having the resources to  dedicate that DeepMind had, it would be much faster than Go. \nAlthough DeepMind did not provide source code or neural network weights, they did provide enough  details, that, with some assumptions, a similar system could be constructed. This was done and released\nin late 2017 (\u201cLCZero,\u201d n.d.) and the interested community was invited to contribute to the code and the  computational effort of training the system, named Leela Chess. Many community members suggested  improvements for the system on a public forum, while the GitHub project was slowly expanded to fix  issues with the architecture being used and upgraded for more efficient computations. Interested  people could download a client, which would run simulations on their computer, and the results would  be sent to a central repository where after several tens of thousands of games, a new network would be  trained. If the new network performed better than the old one, clients would be updated with the new  network and continue running simulations. Around this time Google Colabs introduced free GPU  resources as well, allowing people to use their free computing power from Colabs to help contribute if  they didn\u2019t have a powerful computing system (Bob23, 2018a; \u201cColaboratory \u2013 Google,\u201d n.d.).   Training on diverse systems of much lower capacity took longer, several months. But the system  gradually moved from slow, weak play to grandmaster level, beating its first human GM in April 2018  (\u201cGM Andrew Tang Defends Humanity Against Leela Chess Zero,\u201d 2018).  Soon it began competing  against other top engines in the TCEC (Top Chess Engine Championship), and in February 2019 managed  to win the TCEC cup 2 playing on par with the best rule-based chess agents (Bob23, 2019b). The  architecture, software and weights are in the public domain and this independent confirmation of the  findings confirm the suitability and efficacy of the techniques proffered by DeepMind researchers. In  addition to documenting the important independent confirmation of this achievement, this paper is also  documenting the value of crowdsourced reverse engineering as a resource for independent  reproducibility. Although more difficult, this independent confirmation is even more important than it  would have been with shared code, because it leaves no question of the efficacy of the original \nWhile the results in chess are very interesting, there are also plenty of results in Go as well. The Leela  Zero project was the original inspiration for the Leela Chess Zero project and has steadily become  stronger. Facebook has released an open source version of their Go AI named Elf, which managed to  defeat top human Go players 20-0. One of the leading AI companies in China, Tencent, has also released  an open source version of its Phoenix Go program, which won the 2018 World AI competition. This  pursuit of independent, alternative implementations of important research ideas is a laudable trend that should be encouraged in the field.    \n# 4. Discussion: Implications and Resources\nThe challenge of reproducibility is increased in neural networks research due to the resource demands  of many simulations. The software development effort can also be significant. Open source software and crowdsourcing of computational resources can mitigate these challenges. While in many cases this may  become intractable, the approach should not be overlooked. Both high-performance computing and  software neural network model development have steadily lowered barriers to entry, so that an  approach that may be impractical in one year might subsequently become workable.  The approaches  described in this paper may therefore become more common. Policies could even be developed to  encourage this type of independent verification (or refutation) of important research results.  \nGiven the accelerating scale of investments in neural networks in particular, and research in general, by  diverse stakeholders, many important contributions will not be described in a manner to allow  immediate confirmation or refutation by the scientific community. However, this must not deter  scientists from assessing reproducibility of the most important scientific results, with or without the help of the original researchers. Indeed, confirmation of results by researchers who are not among the  original collaborators lends additional credibility to research results. This paper presented a case study  of precisely such an approach to DeepMind\u2019s Alpha Zero design. This approach has provided a much  broader community of researchers with the opportunity to confirm or refute results.  \n# Acknowledgements \nPartial support for this research was received from the Missouri University of Science and Technology  Intelligent Systems Center, The Missouri University of Science and Technology Chancellor\u2019s  Distinguished Fellowship, the U.S. Department of Education Graduate Assistance in Areas of National  Need program, the Mary K. Finley Missouri Endowment, the National Science Foundation, the Lifelong  Learning Machines program from DARPA/Microsystems Technology Office, and  the  Army  Research  Laboratory (ARL); and it was accomplished under Cooperative Agreement Number W911NF-18-2-0260.  \nThe views and conclusions contained in this document are those of the authors and should not be  interpreted as representing the official policies, either expressed or implied, of the Army Research  Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein. \n# References \nReferences\n# Allis, L. Victor. (1994). Searching for solutions in games and artificial intelligence.\nAllis, L.V., Herik, H. J., & Herschberg, I. S. (1990). Which Games Will Survive? Retrieved from  https://books.google.com/books?id=PlZAGwAACAAJ  Baker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature News, 533(7604), 452.  https://doi.org/10.1038/533452a  Beijing Wants A.I. to Be Made in China by 2030\u2014The New York Times. (2017, July 20). Retrieved Augus 6, 2019, from https://www.nytimes.com/2017/07/20/business/china-artificial-intelligence.htm\nAllis, L.V., Herik, H. J., & Herschberg, I. S. (1990). Which Games Will Survive? Retrieved from  https://books.google.com/books?id=PlZAGwAACAAJ  Baker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature News, 533(7604), 452.  https://doi.org/10.1038/533452a  Beijing Wants A.I. to Be Made in China by 2030\u2014The New York Times. (2017, July 20). Retrieved August 6, 2019, from https://www.nytimes.com/2017/07/20/business/china-artificial-intelligence.htm\nBob23. (2018a, October 2). Contributing to Leela Chess Zero. Creating the Caissa of Chess engines....  Retrieved August 19, 2019, from http://blog.lczero.org/2018/10/contributing-to-leela-chesszero.html  Bob23. (2019b). Leela won the TCEC CUP! Retrieved February 23, 2019, from  http://blog.lczero.org/2019/02/leela-won-tcec-cup.html  China Is Starting To Edge Out The US In AI Investment\u2014CB Insights Research. (2019, February 12).  Retrieved August 6, 2019, from https://www.cbinsights.com/research/china-artificialintelligence-investment-startups-tech/  China wants to be a $150 billion world leader in AI by 2030. (2017, July 21). Retrieved August 6, 2019,  from https://www.cnbc.com/2017/07/21/china-ai-world-leader-by-2030.html  Colaboratory \u2013 Google. (n.d.). Retrieved August 19, 2019, from  https://research.google.com/colaboratory/faq.html  Committee on Reproducibility and Replicability in Science, Committee on National Statistics, Board on Behavioral, Cognitive, and Sensory Sciences, Division of Behavioral and Social Sciences and  Education, Nuclear and Radiation Studies Board, Division on Earth and Life Studies, \u2026 Nationa Academies of Sciences, Engineering, and Medicine. (2019). Reproducibility and Replicability in Science. https://doi.org/10.17226/25303  GM Andrew Tang Defends Humanity Against Leela Chess Zero. (2018, April 23). Retrieved August 19,  2019, from Lichess.org website: https://lichess.org/blog/WtzZAyoAALvE8ZSQ/gm-andrew-tan defends-humanity-against-leela-chess-zero  Greene, C. S., Garmire, L. X., Gilbert, J. A., Ritchie, M. D., & Hunter, L. E. (2017). Celebrating parasites.  Nature Genetics, 49(4), 483\u2013484. https://doi.org/10.1038/ng.3830  Krikke, J. (2007). The Challenge of Go. IEEE Intelligent Systems, 22(01), 7\u20138.  https://doi.org/10.1109/5254.747899 \nBob23. (2018a, October 2). Contributing to Leela Chess Zero. Creating the Caissa of Chess engines....  Retrieved August 19, 2019, from http://blog.lczero.org/2018/10/contributing-to-leela-chesszero.html  Bob23. (2019b). Leela won the TCEC CUP! Retrieved February 23, 2019, from  http://blog.lczero.org/2019/02/leela-won-tcec-cup.html  China Is Starting To Edge Out The US In AI Investment\u2014CB Insights Research. (2019, February 12).  Retrieved August 6, 2019, from https://www.cbinsights.com/research/china-artificialintelligence-investment-startups-tech/  China wants to be a $150 billion world leader in AI by 2030. (2017, July 21). Retrieved August 6, 2019,  from https://www.cnbc.com/2017/07/21/china-ai-world-leader-by-2030.html  Colaboratory \u2013 Google. (n.d.). Retrieved August 19, 2019, from  https://research.google.com/colaboratory/faq.html  Committee on Reproducibility and Replicability in Science, Committee on National Statistics, Board on Behavioral, Cognitive, and Sensory Sciences, Division of Behavioral and Social Sciences and  Education, Nuclear and Radiation Studies Board, Division on Earth and Life Studies, \u2026 National Academies of Sciences, Engineering, and Medicine. (2019). Reproducibility and Replicability in  Science. https://doi.org/10.17226/25303  GM Andrew Tang Defends Humanity Against Leela Chess Zero. (2018, April 23). Retrieved August 19,  2019, from Lichess.org website: https://lichess.org/blog/WtzZAyoAALvE8ZSQ/gm-andrew-tan defends-humanity-against-leela-chess-zero  Greene, C. S., Garmire, L. X., Gilbert, J. A., Ritchie, M. D., & Hunter, L. E. (2017). Celebrating parasites.  Nature Genetics, 49(4), 483\u2013484. https://doi.org/10.1038/ng.3830  Krikke, J. (2007). The Challenge of Go. IEEE Intelligent Systems, 22(01), 7\u20138.  https://doi.org/10.1109/5254.747899 \nLCZero. (n.d.). Retrieved February 23, 2019, from http://lczero.org/  Sadler, M., & Regan, N. (2019). Game Changer: AlphaZero\u2019s Groundbreaking Chess Strategies and the  Promise of AI. Retrieved from https://books.google.com/books?id=KhhivwEACAAJ  Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., \u2026 Hassabis, D. (2017). Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm.  ArXiv:1712.01815 [Cs]. Retrieved from http://arxiv.org/abs/1712.01815  Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., \u2026 Bolton, A. (2017).  Mastering the game of go without human knowledge. Nature, 550(7676), 354.  Silver, D., Sutton, R., & M\u00fcller, M. (2007). Reinforcement Learning of Local Shape in the Game of Go. 6.  Zaman, R., Prokhorov, D., & Wunsch, D. C. (1997). Adaptive critic design in learning to play game of Go.  Proceedings of International Conference on Neural Networks (ICNN\u201997), 1, 1\u20134 vol.1.  https://doi.org/10.1109/ICNN.1997.611623  Zaman, R., & Wunsch, D. C. (1999). TD methods applied to mixture of experts for learning 9/spl times/9 Go evaluation function. IJCNN\u201999. International Joint Conference on Neural Networks.  Proceedings (Cat. No.99CH36339), 6, 3734\u20133739 vol.6.  https://doi.org/10.1109/IJCNN.1999.830746  Zastrow, M. (2016). South Korea trumpets $860-million AI fund after AlphaGo \u201cshock.\u201d Nature News.  https://doi.org/10.1038/nature.2016.19595 \nSadler, M., & Regan, N. (2019). Game Changer: AlphaZero\u2019s Groundbreaking Chess Strategies and the  Promise of AI. Retrieved from https://books.google.com/books?id=KhhivwEACAAJ  Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., \u2026 Hassabis, D. (2017). Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm.  ArXiv:1712.01815 [Cs]. Retrieved from http://arxiv.org/abs/1712.01815  Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., \u2026 Bolton, A. (2017).  Mastering the game of go without human knowledge. Nature, 550(7676), 354.  Silver, D., Sutton, R., & M\u00fcller, M. (2007). Reinforcement Learning of Local Shape in the Game of Go. 6.  Zaman, R., Prokhorov, D., & Wunsch, D. C. (1997). Adaptive critic design in learning to play game of Go.  Proceedings of International Conference on Neural Networks (ICNN\u201997), 1, 1\u20134 vol.1.  https://doi.org/10.1109/ICNN.1997.611623  Zaman, R., & Wunsch, D. C. (1999). TD methods applied to mixture of experts for learning 9/spl times/9 Go evaluation function. IJCNN\u201999. International Joint Conference on Neural Networks.  Proceedings (Cat. No.99CH36339), 6, 3734\u20133739 vol.6.  https://doi.org/10.1109/IJCNN.1999.830746  Zastrow, M. (2016). South Korea trumpets $860-million AI fund after AlphaGo \u201cshock.\u201d Nature News.  https://doi.org/10.1038/nature.2016.19595 \n",
    "paper_type": "survey",
    "attri": {
        "background": {
            "purpose": "The survey aims to address the reproducibility crisis in scientific research, particularly in machine learning, by exploring the potential of crowdsourced reverse engineering as a means to reproduce results, exemplified through a case study of DeepMind's Alpha Zero.",
            "scope": "The survey focuses on the reproducibility of neural network research, specifically the efforts to replicate results from DeepMind's Alpha Zero. It excludes discussions on proprietary information and other unrelated AI systems to maintain focus on the reproducibility aspect."
        },
        "problem": {
            "definition": "The core issue is the challenge of reproducibility in scientific findings, particularly in complex computational processes like those used in neural networks.",
            "key obstacle": "The primary challenges include the high costs of computing resources required for validation, the lack of shared information (like source code and architecture), and the proprietary nature of many successful AI systems."
        },
        "architecture": {
            "perspective": "The survey introduces a framework for understanding how crowdsourced efforts can facilitate reproducibility in neural network research, emphasizing the importance of community collaboration.",
            "fields/stages": "The survey categorizes current methods into stages of reverse-engineering efforts, including initial community engagement, development of independent implementations, and validation through competitive performance against established AI systems."
        },
        "conclusion": {
            "comparisions": "The survey compares various reverse-engineering efforts, highlighting how community-driven projects like Leela Chess Zero successfully replicated aspects of Alpha Zero, demonstrating the effectiveness of crowd-sourced approaches.",
            "results": "The key takeaway is that independent confirmation of results enhances the credibility of research and that crowdsourced reverse engineering can serve as a viable pathway to achieving reproducibility in AI research."
        },
        "discussion": {
            "advantage": "The strengths of existing research lie in the significant advancements made in AI and neural networks, with successful replication efforts showcasing the potential of community collaboration.",
            "limitation": "Current studies often fall short due to the lack of transparency in sharing methodologies and the proprietary nature of successful AI implementations.",
            "gaps": "Unanswered questions remain regarding the extent to which results can be reproduced across different systems and the need for standardized practices in sharing research methodologies.",
            "future work": "Future research should focus on developing policies that encourage transparency and sharing of resources, as well as exploring new trends in AI that facilitate reproducibility through community engagement."
        },
        "other info": {
            "acknowledgements": "Partial support for this research was received from various institutions, including the Missouri University of Science and Technology and the U.S. Department of Education."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The survey aims to address the reproducibility crisis in scientific research, particularly in machine learning, highlighting its importance in building robust AI systems."
        },
        {
            "section number": "1.2",
            "key information": "The survey focuses on the reproducibility of neural network research, specifically the efforts to replicate results from DeepMind's Alpha Zero, which relates to anomaly detection and uncertainty estimation."
        },
        {
            "section number": "2.1",
            "key information": "The core issue is the challenge of reproducibility in scientific findings, particularly in complex computational processes like those used in neural networks."
        },
        {
            "section number": "2.5",
            "key information": "The primary challenges include the high costs of computing resources required for validation, the lack of shared information (like source code and architecture), and the proprietary nature of many successful AI systems."
        },
        {
            "section number": "7.1",
            "key information": "Current studies often fall short due to the lack of transparency in sharing methodologies and the proprietary nature of successful AI implementations."
        },
        {
            "section number": "7.2",
            "key information": "Future research should focus on developing policies that encourage transparency and sharing of resources, as well as exploring new trends in AI that facilitate reproducibility through community engagement."
        }
    ],
    "similarity_score": 0.6368794280572894,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Reproducibility via Crowdsourced Reverse Engineering_ A Neural Network Case Study With DeepMind's Alpha Zero.json"
}