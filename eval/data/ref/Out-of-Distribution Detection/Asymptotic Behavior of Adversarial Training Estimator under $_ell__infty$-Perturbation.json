{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2401.15262",
    "title": "Asymptotic Behavior of Adversarial Training Estimator under $\\ell_\\infty$-Perturbation",
    "abstract": "Adversarial training has been proposed to hedge against adversarial attacks in machine learning and statistical models. This paper focuses on adversarial training under $\\ell_\\infty$-perturbation, which has recently attracted much research attention. The asymptotic behavior of the adversarial training estimator is investigated in the generalized linear model. The results imply that the limiting distribution of the adversarial training estimator under $\\ell_\\infty$-perturbation could put a positive probability mass at $0$ when the true parameter is $0$, providing a theoretical guarantee of the associated sparsity-recovery ability. Alternatively, a two-step procedure is proposed -- adaptive adversarial training, which could further improve the performance of adversarial training under $\\ell_\\infty$-perturbation. Specifically, the proposed procedure could achieve asymptotic unbiasedness and variable-selection consistency. Numerical experiments are conducted to show the sparsity-recovery ability of adversarial training under $\\ell_\\infty$-perturbation and to compare the empirical performance between classic adversarial training and adaptive adversarial training.",
    "bib_name": "xie2024asymptoticbehavioradversarialtraining",
    "md_text": "# Asymptotic Behavior of Adversarial Training Estimator under \u2113\u221e-Perturbation\nYiling Xie School of Industrial and Systems Engineering, Georgia Institute of Technology,\nand Xiaoming Huo School of Industrial and Systems Engineering, Georgia Institute of Technology. January 30, 2024\nAbstract\nAdversarial training has been proposed to hedge against adversarial attacks in machine learning and statistical models. This paper focuses on adversarial training under \u2113\u221e-perturbation, which has recently attracted much research attention. The asymptotic behavior of the adversarial training estimator is investigated in the generalized linear model. The results imply that the limiting distribution of the adversarial training estimator under \u2113\u221e-perturbation could put a positive probability mass at 0 when the true parameter is 0, providing a theoretical guarantee of the associated sparsity-recovery ability. Alternatively, a two-step procedure is proposed\u2014 adaptive adversarial training, which could further improve the performance of adversarial training under \u2113\u221e-perturbation. Specifically, the proposed procedure could achieve asymptotic unbiasedness and variable-selection consistency. Numerical experiments are conducted to show the sparsity-recovery ability of adversarial training under \u2113\u221e-perturbation and to compare the empirical performance between classic adversarial training and adaptive adversarial training.\n# 1 Introduction\nModern machine-learning models are susceptible to adversarial attacks on their inputs. The adversarial training procedure has been proposed to remedy this issue by minimizing the empirical worst-case loss under a given magnitude of perturbation for each observation (El Ghaoui and Lebret, 1997; Xu et al., 2008; Szegedy et al., 2014). In this paper, we consider the adversarial training problem as the optimization problem shown below, min \u03b2 E(X,Y )\u223cPn \ufffd sup \u2225\u2206\u2225\u2264\u03b4 L (f(X + \u2206, \u03b2), Y ) \ufffd , (1) where \u2225\u2206\u2225denotes the norm of the perturbation \u2206, \u03b4 denotes the perturbation magnitude, X \u2208Rd and Y \u2208R denote the feature variable and label variable, Pn is the empirical distribution of (X, Y ), L is the loss function, f is the hypothesis function and the linear function f(x, \u03b2) = \u27e8x, \u03b2\u27e9is usually chosen. If the norm of the perturbation \u2225\u00b7 \u2225is chosen as \u2113p norm, we call the problem (1) adversarial training under \u2113p-perturbation. Compared with other types of norms of the perturbation, adversarial training under \u2113\u221e-perturbation is of particular interest. Firstly, \u2113\u221e-perturbation is widely used and has attracted significant attention (Madry et al., 2018; Schmidt et al., 2018; Yin et al., 2019; Chen et al., 2020; Guo et al., 2020; Xing et al., 2021) in the literature. For example, Yin et al. (2019) studies the generalization ability of the adversarial training under \u2113\u221e-perturbation, and Schmidt et al. (2018); Chen et al. (2020) investigate the generalization gap between standard and adversarial robust models under \u2113\u221e-perturbation. Secondly, some literature (Javanmard and Soltanolkotabi, 2022; Ribeiro and Sch\u00a8on, 2023; Ribeiro et al., 2022, 2023) has pointed out that, for the linear regression where L = (\u27e8x, \u03b2\u27e9\u2212y)2/2, the adversarial training under \u2113\u221e-perturbation could produce sparse solutions. However, the literature in this line does not provide precise statistical analysis to explain the sparsity-recovery phenomenon while our paper aims to\nModern machine-learning models are susceptible to adversarial attacks on their inputs. The adversarial training procedure has been proposed to remedy this issue by minimizing the empirical worst-case loss under a given magnitude of perturbation for each observation (El Ghaoui and Lebret, 1997; Xu et al., 2008; Szegedy et al., 2014). In this paper, we consider the adversarial training problem as the optimization problem shown below,\nwhere \u2225\u2206\u2225denotes the norm of the perturbation \u2206, \u03b4 denotes the perturbation magnitude, X \u2208Rd and Y \u2208R denote the feature variable and label variable, Pn is the empirical distribution of (X, Y ), L is the loss function, f is the hypothesis function and the linear function f(x, \u03b2) = \u27e8x, \u03b2\u27e9is usually chosen. If the norm of the perturbation \u2225\u00b7 \u2225is chosen as \u2113p norm, we call the problem (1) adversarial training under \u2113p-perturbation. Compared with other types of norms of the perturbation, adversarial training under \u2113\u221e-perturbation is of particular interest. Firstly, \u2113\u221e-perturbation is widely used and has attracted significant attention (Madry et al., 2018; Schmidt et al., 2018; Yin et al., 2019; Chen et al., 2020; Guo et al., 2020; Xing et al., 2021) in the literature. For example, Yin et al. (2019) studies the generalization ability of the adversarial training under \u2113\u221e-perturbation, and Schmidt et al. (2018); Chen et al. (2020) investigate the generalization gap between standard and adversarial robust models under \u2113\u221e-perturbation. Secondly, some literature (Javanmard and Soltanolkotabi, 2022; Ribeiro and Sch\u00a8on, 2023; Ribeiro et al., 2022, 2023) has pointed out that, for the linear regression where L = (\u27e8x, \u03b2\u27e9\u2212y)2/2, the adversarial training under \u2113\u221e-perturbation could produce sparse solutions. However, the literature in this line does not provide precise statistical analysis to explain the sparsity-recovery phenomenon while our paper aims to\n(1)\n(1)\ngive a rigorous theoretical explanation for the associated sparsity-recovery ability in the generalized linear model where the linear regression is a special case. In this paper, we study the asymptotic statistical property of the adversarial training estimator under \u2113\u221e-perturbation in the generalized linear model. We derive the associated limiting distribution based on the regularization effect of the adversarial training procedure. The results have two main implications. Firstly, \u2113\u221e-perturbation could recover sparsity while other types of perturbation could not. Secondly, as for the order of \u2113\u221e-perturbation magnitude \u03b4 = \u03b7/n\u03b3, \u03b3 = 1/2 is the optimal choice since the resulting estimator is both asymptotically normal and has a positive probability at 0 in terms of the asymptotic behavior when the true parameter is 0. However, the bias exists in the asymptotic distribution even when \u03b3 = 1/2. In this regard, to further improve the performance, we propose a new two-step procedure\u2014adaptive adversarial training, where we first compute the empirical risk minimization estimator and then use the empirical risk minimization estimator as the weights added to the \u2113\u221e-perturbation. Notably, the estimator obtained from the proposed procedure is unbiased and achieves variable-selection consistency in the asymptotic sense. In addition, our theoretical results are validated by numerical experiments. Specifically, we run the adversarial training procedure in the linear and logistic regression. The associated estimator path performs different patterns when the order of \u2113\u221e-perturbation is chosen as \u03b3 < 1/2, \u03b3 = 1/2, \u03b3 > 1/2, among which the choice \u03b3 = 1/2 has the best performance. We also compare the performance of classic adversarial training with that of adaptive adversarial training. It is observed that the proposed adaptive adversarial training has superior\n# 1.1 Related Work\nIn the adversarial training literature, Javanmard and Soltanolkotabi (2022); Dobriban et al. (2023); Taheri et al. (2023) investigate the statistical behavior of standard accuracy and robust accuracy of adversarial training in the binary linear classification under the highdimension regime. Our work differs on several points: (a) Instead of focusing on the behavior of the accuracy, we focus on the estimator obtained by the adversarial training directly. (b) Instead of the binary linear classification, we study the generalized linear model, which covers broader statistical models, including linear regression and logistic regression. (c) Instead of the high-dimension regime, we mainly deal with the fixed-dimension scenario. Notably, some literature has also figured out that the adversarial training procedure is equivalent to \u221e-Wasserstein distributionally robust optimization (Staib and Jegelka, 2017; Gao et al., 2022). While there is much work studying the finite p-Wasserstein distributionally robust optimization (Blanchet et al., 2022; Gao and Kleywegt, 2022), the statistical properties of \u221e-Wasserstein distributionally robust (adversarial training) estimator are not taken into account. Not surprisingly, our results upon the regularization effect and asymptotic behavior of adversarial training are consistent with the associated results in the finite p-Wasserstein distributionally robust optimization (Gao et al., 2022; Blanchet et al., 2022; Blanchet and Shapiro, 2023). However, we focus more on the statistical insight implied by the corresponding asymptotic distribution and give potential improvements from the statistical perspective. Adversarial training under \u2113\u221e-perturbation is closely related to the well-known statistical procedure LASSO. This connection has already been mentioned in Javanmard and Soltanolkotabi (2022); Ribeiro and Sch\u00a8on (2023); Ribeiro et al. (2022, 2023). The connection between these two procedures could be established using the regularization effect of\nadversarial training where the regularization term depends on the dual norm\u2014\u21131-norm of the parameter. In this regard, it will also be shown that the asymptotic distribution of the adversarial training estimator under \u2113\u221e-perturbation has a similar formulation with that of LASSO estimator (Fu and Knight, 2000). Specifically, the asymptotic distributions of both the LASSO estimator and the adversarial training estimator under \u2113\u221e-perturbation put a positive probability to 0 when the underlying parameter is 0. Further, the proposed adaptive adversarial training and the adaptive LASSO (Zou, 2006) are also closely related to each other. Recall that adaptive adversarial training forces weights in the \u2113\u221e-perturbation while the adaptive LASSO forces weights in the \u21131-norm regularization term. Thanks to the regularization effect of the adversarial training, the aforementioned two approaches of adding weights have a similar influence on the resulting estimator. Specifically, both adaptive LASSO and adaptive adversarial training help achieve unbiasedness and variableselection consistency for the asymptotic behavior of the corresponding estimator.\n# 1.2 Notations\nFor a given norm \u2225\u00b7 \u2225, we denote the associated dual norm by \u2225\u00b7 \u2225\u2217, which is defined by \u2225y\u2225\u2217= max\u2225x\u2225\u22641 x\u22a4y. [x]i denotes the ith component of vector x. [x]I denotes the subvector of x with I as the index set. 1 denotes vector of all ones. sign([x]i) denotes the sign of xi (where we let sign(0) = 0), and accordingly we let sign(x) = (sign([x]1), ..., sign([x]d)). If x = (x1, ..., xd)\u22a4and y = (y1, ..., yd)\u22a4, then we have the following denotations: |x| = (|x1|, ..., |xd|)\u22a4, x\u22121 = (1/x1, ..., 1/xd)\u22a4, x \u2297y = (x1y1, ..., xdyd), \u27e8x, y\u27e9= x \u00b7 y = x1y1 + ...+xdyd. \u201c\u21d2\u201d denotes converge in distribution and \u201c\u2192p\u201d denotes converge in probability. \u201cOp(1)\u201d denotes \u201cbounded in probability\u201d. \u201cop(1)\u201d denotes \u201cconverge to 0 in probability\u201d. I(\u00b7) denotes the indicator function.\n# 1.3 Organization of this Paper\nThe remainder of this paper is organized as follows. In Section 2, we introduce the regularization effect of adversarial training. In Section 3, we investigate the asymptotic behavior of the adversarial training estimator under \u2113\u221e-perturbation. In Section 4, we propose adaptive adversarial training, which could improve the performance of the classical adversarial training under \u2113\u221e-perturbation. Numerical experiments are conducted and analyzed in Section 5. The proofs are relegated to the appendix whenever possible.\n# Regularization Effect of Adversarial Training\nThis section discusses the regularization effect of the adversarial training procedure. The following proposition states the regularization effect of the adversarial training worst-case loss measured by the function h. Proposition 1. If the function h : Rd \u2192R is differentiable, then we have that EZ\u223cP \ufffd sup \u2225\u2206\u2225\u2264\u03b4 h(Z + \u2206) \ufffd = EZ\u223cP [h(Z)] + \u03b4EZ\u223cP [\u2225\u2207h(Z)\u2225\u2217] + o(\u03b4). Remark 2. Compared with the adversarial training problem (1) introduced in Section 1, we consider the general loss function h in Proposition 1, where h is smooth w.r.t. z, and the decision variable Z follows any valid distribution P. One may observe from Proposition 1 that the expectation of the worst-case loss could be reformulated as the sum of the expectation of the loss EZ\u223cP [h(Z)], the expectation of dual norm of the gradient EZ\u223cP [\u2225\u2207h(Z)\u2225\u2217], and a high order residual o(\u03b4). Notably, the term \u03b4EZ\u223cP [\u2225\u2207h(Z)\u2225\u2217] could be considered as the \u201cregularization effect\u201d caused by computing the \u201cworst-case\u201d loss to hedge against adversarial attacks. Also, there is no\nThis section discusses the regularization effect of the adversarial training procedure. The following proposition states the regularization effect of the adversarial trainin worst-case loss measured by the function h.\n\u201csup\u201d inside the expectation in the reformulation, enabling us to investigate the statistical properties of the adversarial training more conveniently.\n# 3 Asymptotic Behavior in Generalized Linear Model\nThis section analyzes the asymptotic behavior of the adversarial training estimator under \u2113\u221e-perturbation in the generalized linear model. Recall that l\u221e-perturbation has attracted a lot of research attention. In this regard, we investigate the statistical behavior of the adversarial training under l\u221e-perturbation. We focus on the generalized linear model. In the generalized linear model, the label variable Y is generated from a particular distribution from the exponential family, including the Bernoulli distribution on Y \u2208{\u22121, 1} in the logistic regression, the Poisson distribution on Y \u2208{0, 1, 2, ...} in the Poisson regression, the normal distribution on Y \u2208R in the linear regression, etc. The expectation of the label variable Y conditional on the feature variable X is determined by the link function. If we denote the nonzero ground-truth parameter by \u03b2\u2217and the link function by G(\u00b7), we have G(E[Y |X = x]) = \u27e8x, \u03b2\u2217\u27e9. The link functions G(\u00b7) are chosen as the logit function in the logistic regression, the log function in the Poisson regression, the identity function in the linear regression, etc. In the generalized linear model, the ground-truth parameter \u03b2\u2217is estimated by the maximum likelihood estimation method, and the associated loss function can be denoted by L(f(x, \u03b2), y) = L(\u27e8x, \u03b2\u27e9, y). The following corollary could be immediately obtained by Proposition 1 and reveals the regularization effect of the adversarial training procedure under \u2113\u221e-perturbation in the generalized linear model. Corollary 3. If the function L(f, y) is continuously differentiable w.r.t. the first argument,\n\u2225\u2225\u2264 (2) holds, where L\u2032(f, Y ) denotes the gradient of L taken w.r.t. the first argument f. Corollary 3 implies that, in the generalized linear model, the adversarial training worstcase loss EPn \ufffd sup\u2225\u2206\u2225\u221e\u2264\u03b4 L(\u27e8X + \u2206, \u03b2\u27e9, Y ) \ufffd can be written as the sum of the empirical loss EPn [L(\u27e8X, \u03b2\u27e9, Y )], the regularization term \u03b4\u2225\u03b2\u22251EPn [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|], and a higher-order residual o(\u03b4). Notably, the regularization term is the product of the perturbation magnitude \u03b4, the parameter \u21131-norm \u2225\u03b2\u22251 and the empirical expectation of the absolute value of the loss gradient EPn [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|]. Informally, computing the loss in the adversarial training procedure under \u2113\u221e-perturbation could be understood as imposing the \u21131-norm regularization to the empirical loss. Taking advantage of Corollary 3, we could obtain the asymptotic behavior of the adversarial training estimator in the generalized linear model. In particular, the associated estimator is defined by the following:\nwhere B is a convex compact subset of Rd, and \u03b4n = \u03b7/n\u03b3 for some \u03b7, \u03b3 > 0. We first clarify several assumptions before introducing our main theorem. Assumption 4. For the loss function L, the ground-truth parameter \u03b2\u2217, and true underlying distribution P\u2217, we assume the following conditions hold: \u2022 The ground-truth parameter \u03b2\u2217is an interior point of B. \u2022 The loss function L(\u27e8x, \u03b2\u27e9, y) is twice continuously differentiable w.r.t. the first argument.\n(2)\n(3)\n\u2022 The loss function L(\u27e8x, \u03b2\u27e9, y) is convex w.r.t. \u03b2. \u2022 The Hessian matrix H = \u22072 \u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )] is nonsingular. \u2022 P\u2217(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ) = 0) = 0 holds. \u2022 The first-order condition \u2207\u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )] = 0 holds. In particular, we claim that conditions in Assumption 4 could be satisfied by the linear regression and the logistic regression in the following proposition. Proposition 5. In linear regression and logistic regression, if there does not exist nonzero vector \u03b1 such that P\u2217(\u03b1\u22a4X = 0) = 1 and the ground-truth parameter \u03b2\u2217is an interior point of B, then Assumption 4 is satisfied. Equipped with Assumption 4, we could derive the following theorem, which depicts the asymptotic behavior of adversarial training estimator under different perturbation magnitude \u03b4n choices. Theorem 6 (Asymptotic behavior). Under Assumption 4, for the adversarial training estimator \u03b2n defined in (3), if the perturbation magnitude is chosen as \u03b4n = \u03b7/n\u03b3 for some \u03b7, \u03b3 > 0, and G \u223cN(0, \u03a3) with covariance matrix \u03a3 = Cov(\u2207\u03b2L(\u27e8X, \u03b2\u2217\u27e9, Y )), we have that nmin{1/2,\u03b3} (\u03b2n \u2212\u03b2\u2217) \u21d2arg min u V (u). \u2022\n\u2022 The Hessian matrix H = \u22072 \u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )] is nonsingular. \u2022 P\u2217(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ) = 0) = 0 holds. \u2022 The first-order condition \u2207\u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )] = 0 holds. In particular, we claim that conditions in Assumption 4 could be satisfied by the linear regression and the logistic regression in the following proposition. Proposition 5. In linear regression and logistic regression, if there does not exist nonzero vector \u03b1 such that P\u2217(\u03b1\u22a4X = 0) = 1 and the ground-truth parameter \u03b2\u2217is an interior point of B, then Assumption 4 is satisfied. Equipped with Assumption 4, we could derive the following theorem, which depicts the asymptotic behavior of adversarial training estimator under different perturbation magnitude \u03b4n choices. Theorem 6 (Asymptotic behavior). Under Assumption 4, for the adversarial training estimator \u03b2n defined in (3), if the perturbation magnitude is chosen as \u03b4n = \u03b7/n\u03b3 for some \u03b7, \u03b3 > 0, and G \u223cN(0, \u03a3) with covariance matrix \u03a3 = Cov(\u2207\u03b2L(\u27e8X, \u03b2\u2217\u27e9, Y )), we have that\nthat\nnmin{1/2,\u03b3} (\u03b2n \u2212\u03b2\u2217) \u21d2arg min u V (u).\n\u2022 If \u03b3 > 1/2, then\n\u2022 If \u03b3 = 1/2, then\nu + 1 2u\u22a4Hu + \u03b7 \ufffd d \ufffd j=1 \ufffd uj sign(\u03b2\u2217 j )I(\u03b2\u2217 j \u0338= 0) + |uj|I(\u03b2\u2217 j = 0) \ufffd \ufffd r;\n(4)\nwhere r = EP\u2217[|L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )|] , K = \u2225\u03b2\u2217\u22251EP\u2217[sign(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ))\u2207\u03b2L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )], and H = \u22072 \u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )]. Remark 7. Theorem 6 analyzes the asymptotic behavior of adversarial training estimator under \u2113\u221e-perturbation. As for \u2113p-perturbation when p \u2208(1, \u221e), the associated asymptotic distribution could be obtained using the technique in Blanchet and Shapiro (2023). One could check that, for \u2113p-perturbation where p \u2208(1, \u221e), the asymptotic distribution of the adversarial training estimator follows some normal distribution when \u03b3 = 1/2 and \u03b3 \u22651/2, and the estimator converges to a nonrandom quantity when \u03b3 < 1/2. The detailed proofs are omitted. Theorem 6 shows that the asymptotic behavior of adversarial training could be classified into three cases according to the order of the perturbation magnitude. Recall the perturbation magnitude is defined by \u03b4n = \u03b7/n\u03b3. If \u03b3 > 1/2, the asymptotic behavior of the adversarial training estimator is the same as that of the empirical risk minimization estimator, which means the influence of hedging against adversarial attacks disappears. If \u03b3 = 1/2, the adversarial training estimator converges to a non-degenerate random variable at the rate of \u221an. The term K, r and \ufffdd j=1(uj sign(\u03b2\u2217 j )I(\u03b2\u2217 j \u0338= 0) + |uj|I(\u03b2\u2217 j = 0)) reflects the influence of hedging against adversarial attacks in the adversarial training. Alternatively, recall that the adversarial training has the reformulation (2), then the additional term K, r and \ufffdd j=1(uj sign(\u03b2\u2217 j )I(\u03b2\u2217 j \u0338= 0) + |uj|I(\u03b2\u2217 j = 0)) could also be understood as the result of the \u21131-norm regularization term \u03b4\u2225\u03b2\u22251EPn [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|]. If \u03b3 < 1/2, the adversarial training estimator converges to a nonrandom quantity and has a slower convergence\nrate than the case of \u03b3 = 1/2. In conclusion, the order choice \u03b3 = 1/2 is preferred since the resulting estimator is root-n consistent and the associated limiting distribution could reflect the influence of the \u2113\u221e-perturbation, which will be discussed in detail in Proposition 9. We take the linear regression as an example in the following corollary. Corollary 8 (Asymptotic behavior in linear regression). In the linear regression where L = (\u27e8x, \u03b2\u27e9\u2212y)2/2, we assume that the distribution of label variable Y conditional on feature variable X is normal, i.e., Y |X = x \u223cN(\u27e8x, \u03b2\u2217\u27e9, \u03c32). If the perturbation magnitude is chosen as \u03b4n = \u03b7/n\u03b3 and G \u223cN(0, \u03c32EP\u2217[XX\u22a4]), we have that nmin{1/2,\u03b3} (\u03b2n \u2212\u03b2\u2217) \u21d2arg min u V (u).\n\u2022 If \u03b3 > 1/2, then\nV (u) = \u2212G\u22a4u + 1 2u\u22a4EP\u2217[XX\u22a4]u.\n\u2022 If \u03b3 = 1/2, then\n# \u2022 If \u03b3 < 1/2, then\n\u2022 If \u03b3 < 1/2, then\nV (u) = 1 2u\u22a4EP\u2217[XX\u22a4]u + \u03b7\u03c3 \ufffd 2 \u03c0 \ufffd d \ufffd j=1 \ufffd uj sign(\u03b2\u2217 j )I(\u03b2\u2217 j \u0338= 0) + |uj|I(\u03b2\u2217 j = 0) \ufffd \ufffd . Recall that some literature pointed out that the adversarial training under \u2113\u221e-perturbation could help recover sparsity (Ribeiro et al., 2022, 2023). The following proposition, which is based on the asymptotic behavior of the associated estimator \u03b2n in Theorem 6, provides a theoretical guarantee for the sparsity-recovery ability of the adversarial training via \u2113\u221e-perturbation under the \u221an-order of perturbation magnitude.\nV (u) = 1 2u\u22a4EP\u2217[XX\u22a4]u + \u03b7\u03c3 \ufffd 2 \u03c0 \ufffd d \ufffd j=1 \ufffd uj sign(\u03b2\u2217 j )I(\u03b2\u2217 j \u0338= 0) + |uj|I(\u03b2\u2217 j = 0) \ufffd \ufffd\nRecall that some literature pointed out that the adversarial training under \u2113\u221e-perturbatio could help recover sparsity (Ribeiro et al., 2022, 2023). The following proposition, which is based on the asymptotic behavior of the associated estimator \u03b2n in Theorem 6, provides a theoretical guarantee for the sparsity-recovery ability of the adversarial training via \u2113\u221e-perturbation under the \u221an-order of perturbation magnitude.\nProposition 9 (Positive probability). Under Assumption 4 and the setting \u03b4n = \u03b7/\u221an, for the adversarial training estimator \u03b2n defined in (3), if we suppose [\u03b2\u2217]1, ..., [\u03b2\u2217]r \u0338= 0 and [\u03b2\u2217]r+1 = ... = [\u03b2\u2217]d = 0, then the asymptotic distribution of (\u03b2n)2 have a positive probability mass at 0, where (\u03b2n)2 = ([\u03b2n]r+1, ..., [\u03b2n]d)\u22a4. In the generalized linear model, for the classic empirical risk minimization estimator (See Blanchet et al. (2022)) and the adversarial training estimator under \u2113p-perturbation, where p \u2208(1, \u221e) (See Remark 7), the associated asymptotic distribution is normal distribution, which is continuous and could not have a positive probability mass at 0 even if the corresponding true parameter equals to 0. However, Proposition 9 indicates that the asymptotic distribution of the adversarial training estimator under \u2113\u221e-perturbation has a positive probability mass at 0 if the underlying parameter equals 0, indicating this procedure has better theoretical performance in obtaining sparse solutions if the sparsity of the parameter is known.\n# 4 Adaptive Adversarial Training\nIn this section, we propose a new two-step approach, called adaptive adversarial training, and analyze its superior asymptotic statistical properties compared with classic adversarial training procedure under \u2113\u221e-perturbation. We focus on the generalized linear model, and our new approach has the following two steps: \u2022 Step 1: Solve the problem\n\u2022 Step 1: Solve the problem\n\ufffd\u03b2n \u2208arg min \u03b2\u2208B EPn [L(\u27e8X, \u03b2\u27e9, Y )] .\n\ufffd and output the estimator \ufffd\u03b2n.\n \ufffd In other words, the proposed adaptive adversarial training procedure under \u2113\u221e-perturbati utputs an estimator defined by\noutputs an estimator defined by\n\ufffd where w is the weight added to the perturbation \u2206and is chosen as |\ufffd\u03b2n|. More specifically, the weight component [w]i is chosen as the absolute value of the associated ith component of the classic empirical risk minimization estimator, i.e., |[\ufffd\u03b2n]i|. That is to say, we shrink the perturbation component if the associated empirical risk minimization estimator component has a large norm, while we inflate the perturbation component if the associated empirical risk minimization estimator component is close to 0. Also, the proposed procedure could be understood as imposing more perturbation along the direction where the underlying parameter is close to 0. It will be shown later that this adjustment in adversarial training under \u2113\u221e-perturbation could help de-bias the adversarial training estimator. To better understand our proposed adaptive adversarial training and prepare for later theoretical analysis, we investigate the regularization effect of the adaptive adversarial training in the following proposition. Proposition 10. Suppose the function h(\u00b7) : Rd \u2192R is continuously differentiable. Then, we have that \ufffd \ufffd\n(5)\nProposition 10 implies that the influence of adding weight in adaptive adversarial training is reflected in the regularization term \u03b4EZ\u223cP [\u2225w\u22121 \u2297\u2207h(Z)\u2225\u2217]. We could obtain immediately the following corollary, which describes the scenario of \u2113\u221e-perturbation in the generalized linear model from Proposition 10. Corollary 11. If the function L(f, y) is continuously differentiable w.r.t. the first argument, then we have that EPn \ufffd sup \u2225w\u2297\u2206\u2225\u221e\u2264\u03b4 L(\u27e8X + \u2206, \u03b2\u27e9, Y ) \ufffd = EPn [L(\u27e8X, \u03b2\u27e9, Y )] + \u03b4\u2225w\u22121 \u2297\u03b2\u22251EPn [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|] + o(\u03b4). (6) Corollary 11 indicates that adding weight to the \u2113\u221e-perturbation is equivalent to adding weight to the \u21131-norm of the parameter \u03b2 in the regularization term. Equipped with Corollary 11, we obtain the desirable properties of the proposed adaptive adversarial training in the following subsection.\nProposition 10 implies that the influence of adding weight in adaptive adversarial training is reflected in the regularization term \u03b4EZ\u223cP [\u2225w\u22121 \u2297\u2207h(Z)\u2225\u2217]. We could obtain immediately the following corollary, which describes the scenario of \u2113\u221e-perturbation in the generalized linear model from Proposition 10. Corollary 11. If the function L(f, y) is continuously differentiable w.r.t. the first argument, then we have that \ufffd \ufffd\n= EPn [L(\u27e8X, \u03b2\u27e9, Y )] + \u03b4\u2225w\u22121 \u2297\u03b2\u22251EPn [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|] + o(\u03b4).\nCorollary 11 indicates that adding weight to the \u2113\u221e-perturbation is equivalent to adding weight to the \u21131-norm of the parameter \u03b2 in the regularization term. Equipped with Corollary 11, we obtain the desirable properties of the proposed adaptive adversarial training in the following subsection.\n# 4.1 Properties of Adaptive Adversarial Training\nThis subsection discusses the properties of adaptive adversarial training and compares it with classic adversarial training. We first clarify some notations. For the ground-truth parameter \u03b2\u2217\u2208Rd, we let A = {j|[\u03b2\u2217]j \u0338= 0} denote the index set of associated non-zero components. Without loss of generality, we also assume that A = {1, ..., r}. In this regard, for any Rd\u00d7d matrix M, we let\nlet\n\uf8ed \uf8f8 where M11 \u2208Rr\u00d7r, M22 \u2208R(d\u2212r)\u00d7(d\u2212r), M12 \u2208Rr\u00d7(d\u2212r), and M21 \u2208R(d\u2212r)\u00d7r. We show the superiority of the adaptive adversarial training in the following theorems\n\uf8ed \uf8f8 where M11 \u2208Rr\u00d7r, M22 \u2208R(d\u2212r)\u00d7(d\u2212r), M12 \u2208Rr\u00d7(d\u2212r), and M21 \u2208R(d\u2212r)\u00d7r.\n\uf8ed \uf8f8 where M11 \u2208Rr\u00d7r, M22 \u2208R(d\u2212r)\u00d7(d\u2212r), M12 \u2208Rr\u00d7(d\u2212r), and M21 \u2208R(d\u2212r)\u00d7r.\nWe show the superiority of the adaptive adversarial training in the following theorems.\n(6)\nTheorem 12 (Unbiasedness of adaptive adversarial training). If we choose the magnitude of perturbation as \u03b4 = \u03b7/n\u03b3 and 1/2 < \u03b3 < 1, the estimator defined in (5) has the following convergence: \u221an \ufffd [\ufffd\u03b2n]A \u2212[\u03b2\u2217]A \ufffd \u21d2H\u22121 11 [G]A, \u221an \ufffd [\ufffd\u03b2n]Ac \u2212[\u03b2\u2217]Ac \ufffd \u21d20,\n\u221an \ufffd [\ufffd\u03b2n]A \u2212[\u03b2\u2217]A \ufffd \u21d2H\u22121 11 [G]A, \u221an \ufffd [\ufffd\u03b2n]Ac \u2212[\u03b2\u2217]Ac \ufffd \u21d20,\n\ufffd \ufffd where [G]A \u223cN(0, \u03a311), \u03a3 = Cov(\u2207\u03b2L(\u27e8X, \u03b2\u2217\u27e9, Y )) and H = \u22072 \u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )]. Recall that the asymptotic results in Theorem 6 imply that the adversarial training estimator with \u221an-order perturbation magnitude is root-n consistent, and the influence of \u2113\u221e-perturbation could be interpreted as the ability to recover the model sparsity. However, Theorem 6 also indicates that the limiting distribution of the classic adversarial training estimator obtained by (4) has a bias, demonstrating that the classic estimator may not be reliable in terms of the parameter estimation. In contrast, the proposed adaptive adversarial training procedure provides an asymptotically unbiased estimator, where we require 1/2 < \u03b3 < 1. In addition to achieving asymptotic unbiasedness, we also emphasize that the adaptive adversarial training procedure could realize asymptotic variable-selection consistency, while the classic estimator could not. Proposition 13 (Variable-selection inconsistency of adversarial training). For the adversarial training estimator \u03b2n defined in (3), if the perturbation magnitude is chosen as \u03b4n = \u03b7/\u221an, we have the following lim sup n P\u2217(An = A) \u2264c < 1, where c is some constant, and An = {j|[\u03b2n]j \u0338= 0}. Recall that we have shown in Proposition 9 that the limiting distribution of the adver-\nRecall that we have shown in Proposition 9 that the limiting distribution of the adversarial training estimator under \u2113\u221e-perturbation could put a positive probability to 0, which\nwe claim as the theoretical evidence for the sparsity-recovery ability. However, Proposition 13 demonstrates that the index set of nonzero components identified by the adversarial training procedure under \u2113\u221e-perturbation is wrong with a positive probability. That is to say, the classic adversarial training procedure has limitations in asymptotic variableselection consistency. In contrast, adaptive adversarial training could achieve asymptotic variable-selection consistency, seeing the following theorem. Theorem 14 (Variable-selection consistency of adaptive adversarial training). For the adaptive adversarial training estimator \ufffd\u03b2n defined in (5), if the perturbation magnitude is chosen as \u03b4n = \u03b7/n\u03b3 and 1/2 < \u03b3 < 1, we have the following lim n P\u2217(A\u2032 n = A) = 1,\nwhere A\u2032 n = {j|[\ufffd\u03b2n]j \u0338= 0}.\n\ufffd In conclusion, the proposed two-step procedure could improve the statistical properties of adversarial training from the following perspectives: Firstly, adaptive adversarial training could de-bias the asymptotic distribution of classic adversarial training estimator; Secondly, adaptive adversarial training could achieve asymptotic variable-selection consistency.\n# 5 Numerical Experiments\nIn this section, we investigate the numerical performance of adversarial training under \u2113\u221e-perturbation and the proposed two-step procedure\u2014adaptive adversarial training. We will first give details of calculating the estimators obtained by the aforementioned two procedures in Section 5.1, and then introduce our experimental settings and results in Section 5.2.\n# 5.1 Tractable Reformulation\nA major challenge of implementing adversarial training is to solve the inner maximization problem inside the empirical expectation (1). To overcome this challenge, Ribeiro et al. (2023) provides the tractable reformulation when the hypothesis function is linear. We restate the result in the following theorem. Theorem 15 (Theorem 4 in Ribeiro et al. (2023)). If L(f, y) is convex and lower-semicontinu w.r.t the first argument, then we have the following: max \u2225\u2206\u2225\u2264\u03b4 L(\u27e8x + \u2206, \u03b2\u27e9, y) = max s\u2208{\u22121,1} L (\u27e8x, \u03b2\u27e9+ \u03b4s\u2225\u03b2\u2225\u2217, y) . Based on Theorem 15, we develop the tractable reformulation for the adaptive adversarial training in the following corollary. Corollary 16. If L(f, y) is convex and lower-semicontinuous w.r.t the first argument, then we have the following: max \u2225w\u2297\u2206\u2225\u2264\u03b4 L(\u27e8x + \u2206, \u03b2\u27e9, y) = max s\u2208{\u22121,1} L \ufffd \u27e8x, \u03b2\u27e9+ \u03b4s\u2225w\u22121 \u2297\u03b2\u2225\u2217, y \ufffd . We mainly focus on linear regression and logistic regression in our experiments. Accordingly, we could immediately obtain the reformulations of the adversarial training and the adaptive adversarial training under \u2113\u221e-perturbation for the linear regression and logistic regression, shown in the following example.\nmax \u2225\u2206\u2225\u2264\u03b4 L(\u27e8x + \u2206, \u03b2\u27e9, y) = max s\u2208{\u22121,1} L (\u27e8x, \u03b2\u27e9+ \u03b4s\u2225\u03b2\u2225\u2217, y) .\nWe mainly focus on linear regression and logistic regression in our experiments. Accordingly, we could immediately obtain the reformulations of the adversarial training and the adaptive adversarial training under \u2113\u221e-perturbation for the linear regression and logistic regression, shown in the following example. Example 17. For the adversarial training worst-case loss in the linear regression and logistic regression, we have the following reformulations: max \u2225\u2206\u2225\u221e\u2264\u03b4(\u27e8x + \u2206, \u03b2\u27e9\u2212y)2 = (|\u27e8x, \u03b2\u27e9\u2212y| + \u03b4\u2225\u03b2\u22251)2 . max \u2225\u2206\u2225\u221e\u2264\u03b4 log (1 + exp(\u2212y\u27e8x + \u2206, \u03b2\u27e9)) = log (1 + exp(\u2212y\u27e8x, \u03b2\u27e9+ \u03b4\u2225\u03b2\u22251)) .\nFor the adaptive adversarial training worst-case loss in the linear regression and logistic regression, we have the following reformulations: max \u2225w\u2297\u2206\u2225\u221e\u2264\u03b4(\u27e8x + \u2206, \u03b2\u27e9\u2212y)2 = \ufffd |\u27e8x, \u03b2\u27e9\u2212y| + \u03b4\u2225w\u22121 \u2297\u03b2\u22251 \ufffd2 . max \u2225w\u2297\u2206\u2225\u221e\u2264\u03b4 log (1 + exp(\u2212y\u27e8x + \u2206, \u03b2\u27e9)) = log \ufffd 1 + exp(\u2212y\u27e8x, \u03b2\u27e9+ \u03b4\u2225w\u22121 \u2297\u03b2\u22251) \ufffd . We implement the adversarial training and the adaptive adversarial training using the reformulations in Example 17. More implementation details are elaborated in the next subsection.\n# 5.2 Experiments\nIn this subsection, we describe how to carry out our numerical experiments and show ou numerical results.\n# 5.2.1 Experimental Setting\nWe consider the linear regression and the logistic regression. For the linear regression, we assume the feature variable X follows the 10-dimensional standard normal distribution, and the label variable Y follows the normal distribution, where we set Y |X = x \u223cN(\u27e8x, \u03b2\u2217\u27e9, 0.01) and \u03b2\u2217= (1, 0.8, \u22120.4, 0, 0, 0, 0, 0, 0, 0). The first three components of the ground-truth parameter \u03b2\u2217are nonzero while others are zero. For the logistic regression, we assume the feature variable X follows the 10-dimensional standard normal distribution, and the label variable Y follows the Bernoulli distribution. More specifically, we have P\u2217(Y = 1|X = x) = 1/(1 + e\u2212\u27e8x,\u03b2\u2217\u27e9) and \u03b2\u2217= (0.3, 0.1, 0, 0, 0, 0, 0, 0, 0, 0), where the first two components are nonzero where others are zero. We run the adversarial training and the adaptive adversarial training for the linear regression and the logistic regression using different sample sizes. The \u2113\u221e-perturbation is\ninvestigated. Recall Theorem 6 discusses different types of asymptotic behavior for the adversarial training estimator under different orders of perturbation magnitude \u03b4 = \u03b7/n\u03b3. Hence, we choose \u03b7 = 1 by default and \u03b3 = 1/3, 1/2, 1 to validate the results in Theorem 6. Also, since we argue that the order of perturbation magnitude in adversarial training should be chosen as 1/2 < \u03b3 < 1 in Theorem 12, we choose \u03b3 = 2/3 in adaptive adversarial training to validate the results in Theorem 12.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/018a/018a4d16-565a-4413-9d19-3156a0cf4445.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 1: Coefficient Estimation in the Linear Regression</div>\nThe experimental results are shown in Figure 1, Figure 2, Table 1, and Table 2. The coefficient paths are presented in Figure 1 and Figure 2, showing the ability of sparsity recovery and variable selection under different settings. The prediction error is recorded\nn = 100\nn = 200\nn = 400\nn = 600\nn = 800\nn = 1000\nAT, \u03b3 = 1/3\n0.5556\n0.5280\n0.4735\n0.3322\n0.2780\n0.2582\nAT, \u03b3 = 1/2\n0.2637\n0.1754\n0.0960\n0.0665\n0.0606\n0.0652\nAT, \u03b3 = 1\n0.1211\n0.0642\n0.0495\n0.0468\n0.0480\n0.0438\nAdaptive AT, \u03b3 = 2/3\n0.1945\n0.1166\n0.0534\n0.0358\n0.0356\n0.0419\nTable 1: Prediction Error \u2225\ufffd\u03b2n \u2212\u03b2\u2217\u22252 in the Linear Regression\nn = 1000\nn = 2000\nn = 4000\nn = 6000\nn = 8000\nn = 10000\nAT, \u03b3 = 1/3\n0.2165\n0.2328\n0.1396\n0.1358\n0.1263\n0.1310\nAT, \u03b3 = 1/2\n0.1051\n0.1102\n0.0517\n0.0251\n0.0190\n0.0411\nAT, \u03b3 = 1\n0.0470\n0.0487\n0.0496\n0.0500\n0.0501\n0.0502\nAdaptive AT, \u03b3 = 2/3\n0.1106\n0.1392\n0.0068\n0.0205\n0.0182\n0.0343\nTable 2: Prediction Error \u2225\ufffd\u03b2n \u2212\u03b2\u2217\u22252 in the Logistic Regression\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/538f/538fe4db-3ac1-4382-9dcf-ba23b2437f49.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: Coefficient Estimation in the Logistic Regressio</div>\nin Table 1 and Table 2, helping us compare the overall estimation accuracy for different procedures and settings. In the tables, we use \u201cAT\u201d to denote \u201cadversarial training\u201d to save space. We analyze the numerical results as follows. In Figure 1 and Figure 2, the coefficient paths have different patterns for different choices of \u03b3. In the adversarial training, when \u03b3 = 1/3 < 1/2, the coefficient paths imply an obvious estimation bias, indicating the estimations in this scenario are not accurate. When \u03b3 = 1 > 1/2, the adversarial training outputs desirable estimations for the nonzero components but can not shrink the estimations for the zero components. When \u03b3 = 1/2, the adversarial training performs the shrinkage for the zero components and also has desirable estimations for the nonzero components. These observations are consistent with the results in Theorem 12. In this\nway, \u03b3 = 1/2 is the optimal choice, especially when we consider the sparsity recovery in adversarial training. In the adaptive adversarial training, we have desirable estimations for both zero and nonzero components. Compared with the optimal scenario (\u03b3 = 1/2) in the classic adversarial training, Figure 1 and Figure 2 demonstrate that the estimation performances for nonzero components are similar while the adaptive adversarial training has superior estimation performances for the zero components. Moreover, Table 1 and Table 2 show that the prediction error in the adaptive adversarial training is the smallest in most cases, which are marked in bold fonts. In conclusion, adaptive adversarial training (1) has a better ability for sparsity recovery and variable selection and (2) outputs more accurate estimations. These observations are consistent with the results in Theorem 12 and Proposition 14.\n# 6 Discussions\nIn this paper, we take advantage of tools from statistics (in particular, LASSO) and optimization (in particular, distributionally robust optimization) to characterize the asymptotic behavior of the popular machine learning model\u2014adversarial training. We give a theoretical explanation for the sparsity-recovery ability of the adversarial training procedure through the lens of the asymptotic behavior of the associated estimator. Further, we propose adaptive adversarial training by using the empirical risk minimization estimator as the weights for the adversarial perturbation. In this way, adaptive adversarial training has the advantages of both adversarial training and empirical risk minimization\u2014providing an asymptotically unbiased estimator that could produce sparse solutions. There are two potential future directions. Notably, there is much literature delivering the non-asymptotic analysis for the LASSO estimator or general \u21131-norm regularized\nestimator (Wainwright, 2009; Lee et al., 2013; Honorio and Jaakkola, 2014). The first direction is how to apply the associated technique to give a more precise description of the adversarial training under \u2113\u221e-perturbation in the non-asymptotic sense. Also, as mentioned earlier, the adversarial training relates to the Wasserstein distributionally robust optimization. The second direction is to find out if a similar story could be developed for the distributionally robust optimization problem.\n# References\nBlanchet, J., Murthy, K., and Si, N. (2022). Confidence regions in Wasserstein distributionally robust estimation. Biometrika, 109(2):295\u2013315. Blanchet, J. and Shapiro, A. (2023). Statistical limit theorems in distributionally robust optimization. arXiv preprint arXiv:2303.14867. Chen, L., Min, Y., Zhang, M., and Karbasi, A. (2020). More data can expand the generalization gap between adversarially robust and standard models. In International Conference on Machine Learning, pages 1670\u20131680. PMLR. Dobriban, E., Hassani, H., Hong, D., and Robey, A. (2023). Provable tradeoffs in adversarially robust classification. IEEE Transactions on Information Theory, 69(12):7793\u20137822. El Ghaoui, L. and Lebret, H. (1997). Robust solutions to least-squares problems with uncertain data. SIAM Journal on Matrix Analysis and Applications, 18(4):1035\u20131064. Fu, W. and Knight, K. (2000). Asymptotics for lasso-type estimators. The Annals of Statistics, 28(5):1356\u20131378.\nBlanchet, J., Murthy, K., and Si, N. (2022). Confidence regions in Wasserstein distributionally robust estimation. Biometrika, 109(2):295\u2013315. Blanchet, J. and Shapiro, A. (2023). Statistical limit theorems in distributionally robust optimization. arXiv preprint arXiv:2303.14867. Chen, L., Min, Y., Zhang, M., and Karbasi, A. (2020). More data can expand the generalization gap between adversarially robust and standard models. In International Conference on Machine Learning, pages 1670\u20131680. PMLR. Dobriban, E., Hassani, H., Hong, D., and Robey, A. (2023). Provable tradeoffs in adversarially robust classification. IEEE Transactions on Information Theory, 69(12):7793\u20137822. El Ghaoui, L. and Lebret, H. (1997). Robust solutions to least-squares problems with uncertain data. SIAM Journal on Matrix Analysis and Applications, 18(4):1035\u20131064. Fu, W. and Knight, K. (2000). Asymptotics for lasso-type estimators. The Annals of Statistics, 28(5):1356\u20131378.\nGao, R., Chen, X., and Kleywegt, A. J. (2022). Wasserstein distributionally robust optimization and variation regularization. Operations Research. Gao, R. and Kleywegt, A. (2022). Distributionally robust stochastic optimization with Wasserstein distance. Mathematics of Operations Research, 48(2):603\u2013655. Geyer, C. J. (1994). On the asymptotics of constrained M-estimation. The Annals of Statistics, 22(4):1993\u20132010. Geyer, C. J. (1996). On the asymptotics of convex stochastic optimization. Unpublished manuscript, 37. Guo, Y., Chen, L., Chen, Y., and Zhang, C. (2020). On connections between regularizations for improving DNN robustness. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(12):4469\u20134476. Honorio, J. and Jaakkola, T. (2014). A unified framework for consistency of regularized loss minimizers. In International Conference on Machine Learning, pages 136\u2013144. PMLR. Javanmard, A. and Soltanolkotabi, M. (2022). Precise statistical analysis of classification accuracies for adversarial training. The Annals of Statistics, 50(4):2127\u20132156. Kato, K. (2009). Asymptotics for argmin processes: Convexity arguments. Journal of Multivariate Analysis, 100(8):1816\u20131829. Lee, J. D., Sun, Y., and Taylor, J. E. (2013). On model selection consistency of M-estimators with geometrically decomposable penalties. arXiv preprint arXiv:1305.7477, 241. Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A. (2018). Towards deep learning models resistant to adversarial attacks. In International Conference on Learning\nRibeiro, A. H. and Sch\u00a8on, T. B. (2023). Overparameterized linear regression under adversarial attacks. IEEE Transactions on Signal Processing, 71:601\u2013614. Ribeiro, A. H., Zachariah, D., Bach, F., and Sch\u00a8on, T. B. (2023). Regularization properties of adversarially-trained linear regression. In Thirty-seventh Conference on Neural Information Processing Systems. Ribeiro, A. H., Zachariah, D., and Sch\u00a8on, T. B. (2022). Surprises in adversarially-trained linear regression. arXiv preprint arXiv:2205.12695. Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A. (2018). Adversarially robust generalization requires more data. In Advances in Neural Information Processing Systems, volume 31. Staib, M. and Jegelka, S. (2017). Distributionally robust deep learning as a generalization of adversarial training. In NIPS workshop on Machine Learning and Computer Security, volume 3, page 4. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., and Fergus, R. (2014). Intriguing properties of neural networks. In 2nd International Conference on Learning Representations. Taheri, H., Pedarsani, R., and Thrampoulidis, C. (2023). Asymptotic behavior of adversarial training in binary linear classification. IEEE Transactions on Neural Networks and Learning Systems, pages 1\u20139. Wainwright, M. J. (2009). Sharp thresholds for high-dimensional and noisy sparsity recovery using l1-constrained quadratic programming (lasso). IEEE Transactions on Information Theory, 55(5):2183\u20132202.\nXie, Y. and Huo, X. (2023). Adjusted Wasserstein distributionally robust estimator in statistical learning. arXiv preprint arXiv:2303.15579. Xing, Y., Song, Q., and Cheng, G. (2021). On the generalization properties of adversarial training. In International Conference on Artificial Intelligence and Statistics, pages 505\u2013 513. PMLR. Xu, H., Caramanis, C., and Mannor, S. (2008). Robust regression and lasso. In Advances in Neural Information Processing Systems, volume 21. Yin, D., Kannan, R., and Bartlett, P. (2019). Rademacher complexity for adversarially robust generalization. In International Conference on Machine Learning, pages 7085\u2013 7094. PMLR. Zou, H. (2006). The adaptive lasso and its oracle properties. Journal of the American Statistical Association, 101(476):1418\u20131429.\n# A Proofs\n# A.1 Proof of Proposition 1\nProof. Notice we have that\nEZ\u223cP \ufffd sup \u2225\u2206\u2225\u2264\u03b4 h(Z + \u2206) \u2212h(Z) \ufffd =EZ\u223cP \ufffd sup \u2225\u2206\u2225\u22641 h(Z + \u03b4\u2206) \u2212h(Z) \ufffd =EZ\u223cP \ufffd sup \u2225\u2206\u2225\u22641 \u03b4\u2207h(Z) \u00b7 \u2206+ o(\u03b4) \ufffd =\u03b4EZ\u223cP \ufffd sup \u2225\u2206\u2225\u22641 \u2207h(Z) \u00b7 \u2206 \ufffd + o(\u03b4) =\u03b4EZ\u223cP [\u2225\u2207h(Z)\u2225\u2217] + o(\u03b4).\n# A.2 Proof of Proposition 5\nProof. It follows from Lemma 18 - Lemma 23 in Xie and Huo (2023) that it suffices to show\nProof. It follows from Lemma 18 - Lemma 23 in Xie and Huo (2023) that it suffices to show\nP\u2217(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ) = 0) = 0.\nIn the linear regression, we have that\nL\u2032(\u27e8x, \u03b2\u2217\u27e9, y) = \u27e8x, \u03b2\u2217\u27e9\u2212y,\nindicating that P\u2217(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ) = 0) = 0. In the logistic regression, we have that\nindicating that P\u2217(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ) = 0) = 0.\n# A.3 Proof of Theorem 6\nthat\nProof. We let\n\ufffd \ufffd where \u03bb(Q)max is the largest eigenvalue of Q. Since sign(b) is the extreme point of the l\u221eunit ball and we require y = sign(b) + \u2206 lso belongs to the l\u221eunit ball, we have\nSince sign(b) is the extreme point of the l\u221eunit ball and we require y = sign(b) + \u2206 also belongs to the l\u221eunit ball, we have\n|cos\u27e8\u2206, b\u27e9| \u2265 1 \u221a d , \u2225\u2206\u22252 \u22642 \u221a d.\nwhen \u03b5 < \u03b5\u2032, we have that\n\u03b5\u2206\u22a4Q\u2206+ 2\u03b5 sign(b)\u22a4Q\u2206+ \u2206\u22a4b < 0.\nIn this way, when \u03b5 < \u03b5\u2032, we have that\nsup \u2225sign(b)+\u2206\u2225\u221e\u22641 \u03b5\u2206\u22a4Q\u2206+ 2\u03b5Q sign(b)\u2206+ \u2206\u22a4b = 0,\nwhich is obtained when \u2206= 0.\nThe proof is done.\nBased on Lemma 18, we could obtain the more precise regularization effect result.\nLemma 19. If the function L(\u27e8x, \u03b2\u27e9, y) is twice continuously differentiable w.r.t. the firs argument, then we have that\n=EPn [L(\u27e8X, \u03b2\u27e9, Y )] + \u03b4\u2225\u03b2\u22251EPn [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|] + \u03b42EPn[P(X, \u03b2, Y )] + o(\u03b42),\n(7)\n# Proof. Since the function L(\u27e8x, \u03b2\u27e9, y) is twice continuously differentiable w.r.t. the first argument, we have that\nargument, we have that\n= sup \u2225\u2206\u2225\u221e\u22641 \u03b4\u2206\u00b7 \u2207xL(\u27e8x, \u03b2\u27e9, y) + \u03b42\u2206\u22a4\u22072 xL(\u27e8x, \u03b2\u27e9, y)\u2206+ o(\u03b42) =\u03b4 \ufffd sup \u2225\u2206\u2225\u221e\u22641 (\u2206\u00b7 \u03b2)L\u2032(\u27e8x, \u03b2\u27e9, y) + \u03b4(\u2206\u00b7 \u03b2)2L\u2032\u2032(\u27e8x, \u03b2\u27e9, y) \ufffd + o(\u03b42).\nIf L\u2032(\u27e8x, \u03b2\u27e9, y) = 0, then we have that\nThe following lemma is also needed to prove Theorem 6.\n\u03a8n(\u03b2) = EPn \ufffd sup \u2225\u2206\u2225\u221e\u2264\u03b4n L(\u27e8X + \u2206, \u03b2\u27e9, Y ) \ufffd , and L(\u27e8x, \u03b2\u27e9, y) is convex w.r.t \u03b2, then \u03a8n(\u03b2) is convex w.r.t. \u03b2. Proof. If we choose any \u03b21, \u03b22 \u2208B and a1 \u2208(0, 1), we have that a1\u03a8n(\u03b21) + (1 \u2212a1)\u03a8n(\u03b22) =EPn \ufffd a1 sup \u2225\u2206\u2225\u221e\u2264\u03b4n L(\u27e8X + \u2206, \u03b21\u27e9, Y ) + (1 \u2212a1) sup \u2225\u2206\u2225\u221e\u2264\u03b4n L(\u27e8X + \u2206, \u03b22\u27e9, Y ) \ufffd =EPn \ufffd sup \u2225\u2206\u2225\u221e\u2264\u03b4n a1L(\u27e8X + \u2206, \u03b21\u27e9, Y ) + sup \u2225\u2206\u2225\u221e\u2264\u03b4n (1 \u2212a1)L(\u27e8X + \u2206, \u03b22\u27e9, Y ) \ufffd \u2265EPn \ufffd sup \u2225\u2206\u2225\u221e\u2264\u03b4n a1L(\u27e8X + \u2206, \u03b21\u27e9, Y ) + (1 \u2212a1)L(\u27e8X + \u2206, \u03b22\u27e9, Y ) \ufffd (a) \u2265EPn \ufffd sup \u2225\u2206\u2225\u221e\u2264\u03b4n L(\u27e8X + \u2206, a1\u03b21 + (1 \u2212a1)\u03b22\u27e9, Y ), \ufffd = \u03a8n(a1\u03b21 + (1 \u2212a1)\u03b22), where (a) comes from the convexity of L(\u27e8x, \u03b2\u27e9, y). Then, \u03a8n(\u03b2) is convex due to th definition of convexity. We begin to prove Theorem 6. Proof. Case 1: \u03b3 = 1/2 We obtain from Lemma 19 that EPn \ufffd sup \u2225\u2206\u2225\u221e\u2264\u03b4 L(\u27e8X + \u2206, \u03b2\u27e9, Y ) \ufffd =E [L(\u27e8X, \u03b2\u27e9, Y )] + \u03b4\u2225\u03b2\u2225E [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|] + \u03b42E[P(X, \u03b2, Y )] + o(\u03b42),\n=EPn [L(\u27e8X, \u03b2\u27e9, Y )] + \u03b4\u2225\u03b2\u22251EPn [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|] + \u03b42EPn[P(X, \u03b2, Y )] + o(\u03b42),\nVn(u)\nFor the first term in Eq. (8), due to the asymptotic theory of empirical risk minimization,  have that\nwe have that\nwhere G \u223cN(0, \u03a3) with covariance matrix \u03a3 = Cov (\u2207\u03b2L(\u27e8X, \u03b2\u2217\u27e9, Y )) and H = \u22072 \u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )]. We refer to Theorem 3, Proposition 6, and the associated proofs in Blanchet et al. (2022) for more detailed descriptions. For the second term in Eq. (8), we have the following decomposition\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd For the first term in Eq. (10), we have that\nand\n(8)\n(9)\n(10)\n(11)\nFor the second term in Eq. (10), it follows from Taylor\u2019s expansion that, if L\u2032(\u27e8x, \u03b2\u2217\u27e9, y) \u0338= 0,\nif L\u2032(\u27e8x, \u03b2\u2217\u27e9, y) \u0338= 0,\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd = sign(L\u2032(\u27e8x, \u03b2\u2217\u27e9, y))\u2207\u03b2L\u2032(\u27e8x, \u03b2\u2217\u27e9, y)\u22a4u + o(1),\nand if L\u2032(\u27e8x, \u03b2\u2217\u27e9, y) = 0,\n\ufffd\ufffd In this way, we have that\n\ufffd \ufffd\ufffd \ufffd\ufffd +I(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ) \u0338= 0) sign(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ))\u2207\u03b2L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )\u22a4u \ufffd + o(1), dicates that\nwhich indicates that\nwhere (a) comes from our assumption P\u2217(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )) = 0) = 0. Combining (10)-(14), we could obtain that, for the second term in (8), the followin\n(12)\n(13)\n(14)\n\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd \u2192p \ufffd d \ufffd j=1 \ufffd uj sign(\u03b2\u2217 j )I(\u03b2\u2217 j \u0338= 0) + |uj|I(\u03b2\u2217 j = 0) \ufffd \ufffd EP\u2217[|L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )|]\nFor the third term in Eq. (10), it follows from Lemma 19 that\nIf we denote the term \u2225\u03b2\u2217\u22251EP\u2217[sign(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ))\u2207\u03b2L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )] by K and th term EP\u2217[|L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )|] by r, it follows from (9), (15) and (16) that\nV (u) = (\u2212G + \u03b7K)\u22a4u + 1 2u\u22a4Hu + \u03b7 \ufffd d \ufffd j=1 \ufffd uj sign(\u03b2\u2217 j )I(\u03b2\u2217 j \u0338= 0) + |uj|I(\u03b2\u2217 j = 0) \ufffd \ufffd r. Notably, Lemma 20 implies \u03a8n(\u03b2) is convex, demonstrating Vn(u) is convex. Since H is positive definite, V (u) has a unique minimizer. It follows from Geyer (1996); Fu and Knight (2000); Kato (2009) that \u221a\n\ufffd \ufffd \ufffd Notably, Lemma 20 implies \u03a8n(\u03b2) is convex, demonstrating Vn(u) is convex. Since H is positive definite, V (u) has a unique minimizer. It follows from Geyer (1996); Fu and Knight (2000); Kato (2009) that\nCase 2: \u03b3 > 1/2\n(15)\n(16)\nVn(u)\nSimilar to the proof of Case 1, it follows from (9) that\n\u221an (\u03b2n \u2212\u03b2\u2217) \u21d2arg min u V (u),\nwhere\nV (u) = \u2212G\u22a4u + 1 2u\u22a4Hu.\nCase 3: \u03b3 < 1/2\nIn this case, we have that\nVn(u)\n(17)\nThe second term and the third term in Eq. (17) have the same limits as in Case 1, so\nThe second term and the third term in Eq. (17) have the same limits as in Case 1, so\nThe second term and the third term in Eq. (17) have the same limits as in Case 1,  we could conclude that\nThe second term and the third term in Eq. (17) have the same limits as in Case 1, so\nwhere\nV (u) = \u03b7K\u22a4u + 1 2u\u22a4Hu + \u03b7 \ufffd d \ufffd j=1 \ufffd uj sign(\u03b2\u2217 j )I(\u03b2\u2217 j \u0338= 0) + |uj|I(\u03b2\u2217 j = 0) \ufffd \ufffd r.\n# A.4 Proof of Corollary 8\nProof. We have that\n\u03a3 = Cov(\u2207\u03b2L(\u27e8X, \u03b2\u2217\u27e9, Y )) = Cov (X(\u27e8X, \u03b2\u2217\u27e9\u2212Y )) = \u03c32EP\u2217[XX\u22a4], H = \u22072 \u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )] = EP\u2217[XX\u22a4], r = EP\u2217[|L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )|] = EP\u2217[|\u27e8X, \u03b2\u2217\u27e9\u2212Y |] = \u03c3 \ufffd 2 \u03c0, K = \u2225\u03b2\u2217\u22251EP\u2217[sign(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y ))\u2207\u03b2L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )] = \u2225\u03b2\u2217\u22251EP\u2217[sign(\u27e8X, \u03b2\u2217\u27e9\u2212Y )X] = 0. The results are obtained by plugging the expressions above into equations Theore\n= 0) + |uj|I(\u03b2\u2217 j = 0) \ufffd \ufffd r.\n# A.5 Proof of Proposition 9\nProof. Since [\u03b2\u2217]1, ..., [\u03b2\u2217]r are nonzero components and [\u03b2\u2217]r+1, ..., [\u03b2\u2217]d are zero compo-\nProof. Since [\u03b2\u2217]1, ..., [\u03b2\u2217]r are nonzero components and [\u03b2\u2217]r+1, ..., [\u03b2\u2217]d are zero components, we have that\nnents, we have that\nNext, we rewrite\n\uf8ed \uf8f8 \uf8ed \uf8f8 \uf8ed \uf8f8 \uf8ed \uf8f8 where G1, K1, u1 \u2208Rr, G2, K2, u2 \u2208Rd\u2212r, H11 \u2208Rr\u00d7r, H22 \u2208R(d\u2212r)\u00d7(d\u2212r), H12 \u2208Rr\u00d7(d\u2212r), and H21 \u2208R(d\u2212r)\u00d7r. Notably, the probability of the asymptotic distribution (\u03b2n)2 lies at 0 equals to the probability of V (u) being minimized at u2 = 0. It suffices to show that V (u) is minimized at u2 = 0 with a positive probability. If V (u) is minimized at u2 = 0, it follow from KKT optimality condition that\n<div style=\"text-align: center;\">\u2202V (u) = 0.</div>\nThat is to say,\n\u2212\u03b7r1 \u2264\u2212G2 + \u03b7K2 + H21u1 \u2264\u03b7r1.\nIn this sense, we have that\nu1 = H\u22121 11 (G1 \u2212\u03b7K1 \u2212\u03b7rs(\u03b2\u2217)) ,\n\u2212\u03b7r1 \u2264H21H\u22121 11 (G1 \u2212\u03b7K1 \u2212\u03b7rs(\u03b2\u2217)) \u2212G2 + \u03b7K2 \u2264\u03b7r1. In conclusion, the probability of V (u) being minimized at u2 = 0 is equal to the probability of the inequality \u2212\u03b7r1 \u2264H21H\u22121 11 (G1 \u2212\u03b7K1 \u2212\u03b7rs(\u03b2\u2217)) \u2212G2 + \u03b7K2 \u2264\u03b7r1 holds. Since G1 and G2 are normal random variables, V (u) is minimized at u2 = 0 with a positive probability.\n\u2212\u03b7r1 \u2264H21H\u22121 11 (G1 \u2212\u03b7K1 \u2212\u03b7rs(\u03b2\u2217)) \u2212G2 + \u03b7K2 \u2264\u03b7r\nholds. Since G1 and G2 are normal random variables, V (u) is minimized at u2 = 0 with a positive probability.\n# A.6 Proof of Proposition 10\nProof. Notice we have that\n# A.7 Proof of Theorem 12\nA precise regularization effect for adaptive adversarial training could be obtained imme ately from Lemma 19, and we state the result in the following lemma. Lemma 21. If the function L(\u27e8x, \u03b2\u27e9, y) is twice continuously differentiable w.r.t. the f argument, then we have that EPn \ufffd sup \u2225w\u2297\u2206\u2225\u221e\u2264\u03b4 L(\u27e8X + \u2206, \u03b2\u27e9, Y ) \ufffd =EPn [L(\u27e8X, \u03b2\u27e9, Y )] + \u03b4\u2225w\u22121 \u2297\u03b2\u22251EPn [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|] + \u03b42EPn[P(X, \u03b2, Y )] + o(\u03b42), where P(x, \u03b2, y) = I(L\u2032(\u27e8x, \u03b2\u27e9, y) \u0338= 0)L\u2032\u2032(\u27e8x, \u03b2\u27e9, y) sign \ufffd (w\u22121 \u2297\u03b2)L\u2032(\u27e8x, \u03b2\u27e9, y) \ufffd\u22a4(w\u22121 \u2297\u03b2)(w\u22121 \u2297\u03b2)\u22a4sign \ufffd (w\u22121 \u2297\u03b2)L\u2032(\u27e8x, \u03b2\u27e9, y) \ufffd + I(L\u2032(\u27e8x, \u03b2\u27e9, y) = 0)\u2225w\u22121 \u2297\u03b2\u22252 1L\u2032\u2032(\u27e8x, \u03b2\u27e9, y), and L\u2032\u2032(f, y) denotes the second order gradient of L(f, y) w.r.t. the first argument. Now we begin to prove Theorem 12.\nA precise regularization effect for adaptive adversarial training could be obtained immedi ately from Lemma 19, and we state the result in the following lemma. Lemma 21. If the function L(\u27e8x, \u03b2\u27e9, y) is twice continuously differentiable w.r.t. the firs argument, then we have that EPn \ufffd sup \u2225w\u2297\u2206\u2225\u221e\u2264\u03b4 L(\u27e8X + \u2206, \u03b2\u27e9, Y ) \ufffd =EPn [L(\u27e8X, \u03b2\u27e9, Y )] + \u03b4\u2225w\u22121 \u2297\u03b2\u22251EPn [|L\u2032(\u27e8X, \u03b2\u27e9, Y )|] + \u03b42EPn[P(X, \u03b2, Y )] + o(\u03b42), where P(x, \u03b2, y) = I(L\u2032(\u27e8x, \u03b2\u27e9, y) \u0338= 0)L\u2032\u2032(\u27e8x, \u03b2\u27e9, y) sign \ufffd (w\u22121 \u2297\u03b2)L\u2032(\u27e8x, \u03b2\u27e9, y) \ufffd\u22a4(w\u22121 \u2297\u03b2)(w\u22121 \u2297\u03b2)\u22a4sign \ufffd (w\u22121 \u2297\u03b2)L\u2032(\u27e8x, \u03b2\u27e9, y) \ufffd + I(L\u2032(\u27e8x, \u03b2\u27e9, y) = 0)\u2225w\u22121 \u2297\u03b2\u22252 1L\u2032\u2032(\u27e8x, \u03b2\u27e9, y), and L\u2032\u2032(f, y) denotes the second order gradient of L(f, y) w.r.t. the first argument. Now we begin to prove Theorem 12.\nNow we begin to prove Theorem 12.\nProof. Let\n\u03a6n(\u03b2) = EPn \ufffd sup \u2225|\ufffd\u03b2n|\u2297\u2206\u2225\u221e\u2264\u03b4n L(\u27e8X + \u2206, \u03b2\u27e9, Y ) \ufffd .\nWe have that\n(18)\nFor the first term in Eq. (18), due to the asymptotic theory of empirical risk minimization, we have that\nwhere G \u223cN(0, \u03a3) with covariance matrix \u03a3 = Cov (\u2207\u03b2L(\u27e8X, \u03b2\u2217\u27e9, Y )) and H = \u22072 \u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )]. For the second term in Eq. (18), we have the following decomposition\nFor the first term in Eq. (20), we have that\n\ufffd For [\u03b2\u2217]j \u0338= 0, since we have that\n|[\ufffd\u03b2n]j|\u22121 \u2192p |[\u03b2\u2217]j|\u22121,\nand\n40\n(19)\n(20)\n(21)\n\ufffd For [\u03b2\u2217]j = 0, we have that\nand\n\ufffd which comes from the asymptotic normality of \ufffd\u03b2n.\nIn this case,\n\uf8f4 \uf8f4 \uf8f4 \uf8f3 For the third term in Eq. (18), it follows from Lemma 21 that\nCombining (19)-(23), we could obtain that\nwhere\nV (u) = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f3 \u2212[G]\u22a4 A[u]A + 1 2[u]\u22a4 AH11[u]A, if [u]j = 0, \u2200j \u0338\u2208A; \u221e, otherwise.\n(22)\n(23)\nOne could show \u03a8n(\u03b2) is convex following steps in Lemma 20. The detailed proofs are omitted. In this way, we further have that Vn(u) is convex. Also, notice that the unique minimizer of V (u) is (H\u22121 11 [G]A, 0)\u22a4. It follows from the epi-convergence results in Geyer (1994); Fu and Knight (2000); Zou (2006) that \u221an \ufffd [\ufffd\u03b2n]A \u2212[\u03b2\u2217]A \ufffd \u21d2H\u22121 11 [G]A, \u221an \ufffd [\ufffd\u03b2n]Ac \u2212[\u03b2\u2217]Ac \ufffd \u21d20, where G \u223cN(0, \u03a3) with covariance matrix \u03a3 = Cov(\u2207\u03b2L(\u27e8X, \u03b2\u2217\u27e9, Y )) and H = \u22072 \u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )].\nOne could show \u03a8n(\u03b2) is convex following steps in Lemma 20. The detailed proofs are omitted. In this way, we further have that Vn(u) is convex. Also, notice that the unique minimizer of V (u) is (H\u22121 11 [G]A, 0)\u22a4. It follows from the epi-convergence results in Geyer (1994); Fu and Knight (2000); Zou (2006) that\n\ufffd \ufffd where G \u223cN(0, \u03a3) with covariance matrix \u03a3 = Cov(\u2207\u03b2L(\u27e8X, \u03b2\u2217\u27e9, Y )) and H = \u22072 \u03b2EP\u2217[L(\u27e8X, \u03b2\u2217\u27e9, Y )].\n# A.8 Proof of Proposition 13\nProof. An = A implies [\u03b2n]j = 0, \u2200j \u0338\u2208A, indicating\nP\u2217(An = A) \u2264P\u2217(\u221an[\u03b2n]j = 0, \u2200j \u0338\u2208A).\nthat\nand\n\u2212\u03b7r1 \u2264\u2212[G]Ac + \u03b7[K]Ac + H21[u\u2217]A \u2264\u03b7r1.\nc = P\u2217 \ufffd \u2212\u03b7r1 \u2264\u2212[G]Ac + \u03b7[K]Ac + H21H\u22121 11 ([G]A \u2212\u03b7[K]C \u2212\u03b7r sign([\u03b2\u2217]A)) \u2264\u03b7r1 \ufffd < 1. (24)\n# A.9 Proof of Theorem 14\nProof. We consider the following function\n\ufffd  \ufffd \ufffd = EPn [L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )[X]j] + (\ufffd\u03b2n \u2212\u03b2\u2217)\u22a4EPn [L\u2032\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )[X]jX] + op(\u2225\ufffd\u03b2n \u2212\u03b2\u2217\u22252).\n\u221anEPn [L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )[X]j] \u21d2N (0, Cov(L\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )[X]j)) .\nDue to the proof of Theorem 12, we know that \u221an(\ufffd\u03b2n \u2212\u03b2\u2217) converges to some distribution, and EPn [L\u2032\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )[X]jX] \u2192p EP\u2217[L\u2032\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )[X]jX] .\nand\n(25)\n(26)\nIn this way, we have that (\ufffd\u03b2n \u2212\u03b2\u2217)\u22a4EPn [L\u2032\u2032(\u27e8X, \u03b2\u2217\u27e9, Y )[X]jX] converges to some distribution. Then, notice that op(\u221an\u2225\ufffd\u03b2n \u2212\u03b2\u2217\u22252) = Op(1). In conclusion, the first term in Eq. (26) is bounded in probability. The second term in Eq. (26) is also bounded in probability since 1/2 < \u03b3. For the third term in Eq. (26), we have that \u03b3 < 1 and \u221an[\ufffd\u03b2n]j = Op(1). In this way, we know that\nThus,\nP\u2217(j \u2208A\u2032 n) \u2264P\u2217(the equation (26) holds) \u2212\u21920.\n# A.10 Proof of Corollary 16\nProof. Similar to the proof of Theorem 4 in Ribeiro et al. (2023), we define the Fenchel conjugate of L as\nL\u2217(u, y) \u25b3= sup z {uz \u2212L(z, y)}.\nL\u2217(u, y) \u25b3= sup z {uz \u2212L(z, y)}.\n) = max \u2225w\u2297\u2206\u2225\u2264\u03b4 sup u {u\u27e8x, \u03b2\u27e9+ u\u27e8\u2206, \u03b2\u27e9\u2212L\u2217(u, y)} = sup u \ufffd u\u27e8x, \u03b2\u27e9+ max \u2225w\u2297\u2206\u2225\u2264\u03b4 u\u27e8\u2206, \u03b2\u27e9\u2212L\u2217(u, y) \ufffd = sup u \ufffd u\u27e8x, \u03b2\u27e9+ max \u2225\u2206\u2225\u2264\u03b4 u\u27e8\u2206, w\u22121 \u2297\u03b2\u27e9\u2212L\u2217(u, y) \ufffd = sup u \ufffd u\u27e8x, \u03b2\u27e9+ max s={1,\u22121} \ufffd su\u03b4\u2225w\u22121 \u2297\u03b2\u2225\u2217 \ufffd \u2212L\u2217(u, y) \ufffd = sup u max s={1,\u22121} \ufffd u\u27e8x, \u03b2\u27e9+ su\u03b4\u2225w\u22121 \u2297\u03b2\u2225\u2217\u2212L\u2217(u, y) \ufffd = max s={1,\u22121} sup u \ufffd u \ufffd \u27e8x, \u03b2\u27e9+ s\u03b4\u2225w\u22121 \u2297\u03b2\u2225\u2217 \ufffd \u2212L\u2217(u, y) \ufffd = max s\u2208{\u22121,1} L \ufffd \u27e8x, \u03b2\u27e9+ \u03b4s\u2225w\u22121 \u2297\u03b2\u2225\u2217, y \ufffd .\n",
    "paper_type": "theory",
    "attri": {
        "background": "Adversarial training has been proposed to hedge against adversarial attacks in machine learning and statistical models. This paper focuses on adversarial training under \u2113\u221e-perturbation, which has attracted significant research attention and is important for ensuring the robustness of machine learning models.",
        "problem": {
            "definition": "The paper addresses the optimization problem of minimizing the empirical worst-case loss under a given magnitude of perturbation for each observation in a generalized linear model.",
            "key obstacle": "The main challenge is to provide a precise statistical analysis that explains the sparsity-recovery phenomenon associated with adversarial training under \u2113\u221e-perturbation."
        },
        "idea": {
            "intuition": "The idea was inspired by the need for robust statistical models that can withstand adversarial attacks while maintaining performance.",
            "opinion": "The authors propose that adversarial training under \u2113\u221e-perturbation can recover sparsity and achieve better estimation properties.",
            "innovation": "The primary improvement over previous methods is the introduction of a two-step procedure called adaptive adversarial training, which enhances the performance of adversarial training by achieving asymptotic unbiasedness and variable-selection consistency."
        },
        "Theory": {
            "perspective": "The theoretical framework is based on the asymptotic behavior of the adversarial training estimator under \u2113\u221e-perturbation in the generalized linear model.",
            "opinion": "The authors assume that the regularization effect of adversarial training can lead to better statistical properties, particularly in terms of sparsity recovery.",
            "proof": "The paper derives the limiting distribution of the adversarial training estimator, showing that it can put a positive probability mass at 0 when the true parameter is 0, thus providing a theoretical guarantee for sparsity recovery."
        },
        "experiments": {
            "evaluation setting": "Numerical experiments were conducted using linear and logistic regression models, comparing the performance of classic adversarial training and adaptive adversarial training under various settings of perturbation magnitude.",
            "evaluation method": "The evaluation involved calculating the prediction error and analyzing the coefficient paths to assess the sparsity-recovery ability and variable selection."
        },
        "conclusion": "The experiments confirm that adaptive adversarial training outperforms classic adversarial training in terms of sparsity recovery and variable selection, providing a more accurate estimator.",
        "discussion": {
            "advantage": "The main advantages of this paper include the introduction of adaptive adversarial training, which improves the statistical properties of adversarial training by achieving asymptotic unbiasedness and variable-selection consistency.",
            "limitation": "The limitations include potential biases in the classic adversarial training estimator, which may not reliably identify nonzero components.",
            "future work": "Future work could focus on applying non-asymptotic analysis techniques to provide a more precise description of adversarial training under \u2113\u221e-perturbation and exploring connections with distributionally robust optimization."
        },
        "other info": []
    },
    "mount_outline": [
        {
            "section number": "5.2",
            "key information": "The main challenge is to provide a precise statistical analysis that explains the sparsity-recovery phenomenon associated with adversarial training under \u2113\u221e-perturbation."
        },
        {
            "section number": "5.3",
            "key information": "The primary improvement over previous methods is the introduction of a two-step procedure called adaptive adversarial training, which enhances the performance of adversarial training by achieving asymptotic unbiasedness and variable-selection consistency."
        },
        {
            "section number": "6.1",
            "key information": "The authors assume that the regularization effect of adversarial training can lead to better statistical properties, particularly in terms of sparsity recovery."
        },
        {
            "section number": "7.1",
            "key information": "The limitations include potential biases in the classic adversarial training estimator, which may not reliably identify nonzero components."
        },
        {
            "section number": "7.2",
            "key information": "Future work could focus on applying non-asymptotic analysis techniques to provide a more precise description of adversarial training under \u2113\u221e-perturbation and exploring connections with distributionally robust optimization."
        }
    ],
    "similarity_score": 0.659057341564372,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2332_Out-o/papers/Asymptotic Behavior of Adversarial Training Estimator under $_ell__infty$-Perturbation.json"
}