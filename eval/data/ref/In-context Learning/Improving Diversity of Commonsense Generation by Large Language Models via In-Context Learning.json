{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2404.16807",
    "title": "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning",
    "abstract": "Generative Commonsense Reasoning (GCR) requires a model to reason about a situation using commonsense knowledge, while generating coherent sentences. Although the quality of the generated sentences is crucial, the diversity of the generation is equally important because it reflects the model\u2019s ability to use a range of commonsense knowledge facts. Large Language Models (LLMs) have shown proficiency in enhancing the generation quality across various tasks through in-context learning (ICL) using given examples without the need for any fine-tuning. However, the diversity aspect in LLM outputs has not been systematically studied before. To address this, we propose a simple method that diversifies the LLM generations, while preserving their quality. Experimental results on three benchmark GCR datasets show that our method achieves an ideal balance between the quality and diversity. Moreover, the sentences generated by our proposed method can be used as training data to improve diversity in existing commonsense generators.1",
    "bib_name": "zhang2024improvingdiversitycommonsensegeneration",
    "md_text": "# Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning\nTianhui Zhang\u2020\n# Tianhui Zhang\u2020\n# Abstract\nGenerative Commonsense Reasoning (GCR) requires a model to reason about a situation using commonsense knowledge, while generating coherent sentences. Although the quality of the generated sentences is crucial, the diversity of the generation is equally important because it reflects the model\u2019s ability to use a range of commonsense knowledge facts. Large Language Models (LLMs) have shown proficiency in enhancing the generation quality across various tasks through in-context learning (ICL) using given examples without the need for any fine-tuning. However, the diversity aspect in LLM outputs has not been systematically studied before. To address this, we propose a simple method that diversifies the LLM generations, while preserving their quality. Experimental results on three benchmark GCR datasets show that our method achieves an ideal balance between the quality and diversity. Moreover, the sentences generated by our proposed method can be used as training data to improve diversity in existing commonsense generators.1\n# 1 Introduction\nCommonsense reasoning is the ability to make logical deductions about concepts encountered in daily life, and is considered as a critical property of intelligent agents (Davis and Marcus, 2015). Concepts are mental representations of classes and are expressed using words in a language (Liu et al., 2023). Given the inputs, the GCR task requires a model to generate a coherent sentence that is grammatical and adheres to commonsense, evaluated by its similarity to a set of human-written reference sentences covering the same set of concepts (Lin et al., 2020). Often there exists multiple relationships between a given set of concepts, leading to alternative reasoning paths that take diverse view points. For ex-\n1The code is available at https://github.com/ AvataGarde/In Context Diversification\nDanushka Bollegala\u2020,\u2662\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3ccb/3ccbb33b-a9cc-43cf-b623-aadcc88071aa.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/eb08/eb0805a5-4dd9-4ff7-ad1b-01ef43de9ad0.png\" style=\"width: 50%;\"></div>\nFigure 1: An example of diverse generated sentence sets in CommonGen (Lin et al., 2020) dataset. The generation shown at the bottom (in green ) is considered by human annotators to be more diverse than those at the top (in red ).\nample, given the four concepts dog, frisbee, throw and catch, different sentences can be generated as shown in Figure 1. Although all sentences shown in Figure 1 are grammatical, the bottom set expresses diverse view points (e.g. from the dog\u2019s as well as the man\u2019s) compared to the set at the top. Apart from the generation quality, diversity is also an important factor in text generation because the low-diversity texts tend to be dull, repetitive or biased towards a particular view point (Tevet and Berant, 2021). Diversity is an important consideration in many Natural Language Generation (NLG) applications, such as story generation (Li et al., 2018), paraphrase generation (Gupta et al., 2018), and GCR (Yu et al., 2022; Liu et al., 2023). In GCR tasks, diversity requires model\u2019s ability to generate explanations for everyday scenarios from various perspectives and to reflect diverse relationships between input concepts. Moreover, GCR datasets often contain input texts with limited information. Diversifying GCR requires a deep understanding of relationships and commonsense knowledge around the input concepts. Existing methods promote diversity through special decoding strategies, such as nucleus sampling (Holtzman et al., 2019), or encoding interventions such as random noise injection (Gupta et al., 2018) or Mixture\nof Experts (MoE) approaches (Shen et al., 2019). Temperature sampling is one of the common methods to increase the LLM generation diversity. However, it could affect the quality of the generation and lead to nonsensical sequences (Peeperkorn et al., 2024). We propose In-Context Diversification (ICD), a computationally-efficient and accurate method to improve the diversity in GCR, where the sentences are generated from a pre-trained LLM, and strikes a fine-balance between the output diversity and quality. ICD uses an ICL approach to increase the diversity of the sentences generated by an LLM, while maintaining the quality of the generation. ICD is a two-step process where it first lets an LLM to generate sentences that are grammatical, commonsense bearing and cover the tasks\u2019 requirements. If the diversity is low, ICD provides feedback to the LLM, instructing it to generate more diverse sentences considering the already generated sentences. Next, ICD uses a diversity-based sampling method to make a trade-off between quality and diversity with a user-specific diversity metric. Given that ICD is using LLMs to generate diverse sentences via ICL and without updating the parameters of the LLMs, an interesting and open question is whether an LLM can accurately judge the diversity of a given set of sentences. To answer this question, we conduct an experiment where we instruct GPT3.5-turbo to judge the diversity of the set of input sentences according to a fivescale grading system, and convert the predicted grades into binary judgements (i.e. diverse vs. nondiverse). We compare the LLM-assigned grades against those by a group of human annotators, and find a moderate-level (Cohen\u2019s Kappa of 0.409) agreement between human vs. LLM judgements, demonstrating that LLMs can indeed be instructed to obtain diversity judgements for GCR tasks. We evaluate ICD on three GCR tasks/datasets: CommonGen (Lin et al., 2020), ComVE (Wang et al., 2020), and DimonGen (Liu et al., 2023). We find that our proposed ICD balances diversity and quality appropriately, improving their harmonic mean by at least 6% over that of a default baseline. Moreover, the sentences generated by ICD can be used as training data to improve diversity in a Seq2Seq model (Sutskever et al., 2014; Lewis et al., 2020), producing results that are comparable to the models that are trained on knowledge graphs\n# 2 Related Work\nDiverse Text Generation. A variety of methods have been proposed to enhance the diversity of NLG. Sampling-based decoding is an effective method to increase the generation diversity. Holtzman et al. (2019) proposed nucleus sampling to generate diverse content at the generation stage. Truncated sampling (Fan et al., 2018) prunes and then samples the tokens based on the probability distribution. Furthermore, Shen et al. (2019) proposed an MoE approach to diversify translation outputs. Moreover, incorporating external corpora in the MoE further promotes diversity, such as by using a knowledge graph (Yu et al., 2022; Hwang et al., 2023) or by a collection of retrieved sentences (Liu et al., 2023). Although LLMs have reported superior performance in numerous NLPtasks (Touvron et al., 2023; OpenAI, 2023b,a), to the best of our knowledge, diversifying their generations in commonsense reasoning with ICL has not been explored in prior work on GCR.\nIn-Context Learning. Recent studies demonstrate that LLMs can exhibit robust few-shot performance on a variety of downstream tasks through ICL (Brown et al., 2020). ICL is a technique for instructing an LLM using one or more examples for a particular text generation task. The generated text is conditioned on both the input as well as the instruction prompt. Wang et al. (2023) show that in ICL, label words in the demonstration examples function as anchors, which aggregate semantic information to their word representations in the shallow (closer to the input) layers, while providing that information to the final predictions performed by the deeper (closer to the output) layers. In contrast to fine-tuning-based methods, ICL is computationally lightweight because it does not update the parameters of the LLM. Therefore, ICL is an attractive method when integrating task-specific knowledge to an LLM by simply changing the prompt and the few-shot examples (Dong et al., 2022).\n# 3 In-context Diversification\nWe consider the problem of generating a set of diverse sentences that express commonsense reasoning, either by covering a set of given concepts (in CommonGen and DimonGen) or by providing an explanation for a given counterfactual statement\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/255b/255b85b4-41e8-4be3-91a0-c617f32bfaf8.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: An example of default and diversified prompts is shown for an instance selected from the CommonGen dataset. Here, the default prompt shown in Figure 2a is taken from Li et al. (2023). Few-shot examples are included in each prompt where [SRC] denotes the set of input concepts and [TGT] the corresponding sentences in CommonGen. For a given set of [INPUT] concepts, the LLM is then required to generate sentences at the slot [OUTPUT]. As shown in Figure 2b, ICD uses the diversified prompt, which operates in two steps. Step 1 generates a set of [N] sentences, [PRV]. We check for the diversity among the sentences in [PRV], and if it is low, we use the prompt in Step 2 to generate the final set of sentences.</div>\n(in ComVE). Formally, given a sequence (a set of concepts or a statement) X = {x1, . . . , xm}, the goal of GCR is to generate a set of grammatically correct and commonsense bearing sentences Y = {y1, . . . , yn}, where yi is the i-th output generated by the model with probability p(yi|X). Moreover, we require that the generated sentences {y1, . . . , yn} to be lexically as well as semantically diverse.\n# 3.1 Sentence Generation\nTo explain our proposed ICD, let us consider GCR on CommonGen, where the models should generate a set of commmonsense bearing sentences Y, such that each sentence contains all of the input concepts X as shown in Figure 2a. Given an LLM, we can design a prompt that contains a task-specific instruction and one or more examples containing the input concepts (denoted by [SRC] in Figure 2) and the corresponding human-written sentences containing all given input concepts (denoted by [TGT]) to instruct the LLM to generate output sentences Y (denoted by [OUTPUT]) for a given set of input concepts X (denoted by [INPUT]). We refer to a prompt of this nature as a default prompt, and the corresponding set of generated sentences by Sdef. Note that the default prompt does not guaran-\ntee that the generated set of sentences will be diverse and the LLM may return sentences that are redundant. To address this issue, we propose a diversified prompt as shown in Figure 2b. Specifically, the diversified prompt operates in two steps. In Step 1, we require that the LLM generate N sentences that are different, in addition to being coherent and commonsense bearing. Next, we use a suitable diversity metric to evaluate the level of diversity among the generated set of sentences. If the diversity of the generated sentences is low, in Step 2, the sentences would be sent back to the LLM and instruct it to generate sentences that are different to those. As the criterion for triggering Step 2, we check whether the exact same sentence has been generated multiple times by the LLM during Step 1. The final set of generated sentences is denoted by Sdiv.\n# 3.2 Diversity-based Sampling\nBecause of the limited availability of humanwritten reference sentences for evaluating GCR models, there exists a trade-off between quality vs. diversity for GCR tasks.2 Simply maximising for diversity often leads to generations that do not cover the input concepts in a natural way. For ex-\n2This trade-off is further empirically verified in \u00a7 5.1.\nInput: Generated sets of sentences Sdef and Sdiv, respec-\ntively from default and diversified prompts, the number of\ndesired output sentences N, the temporarily stored value \u03b1\nand a diversity metric f.\nOutput: Output set of sentences S\u2217\nS\u2217\u2190\u2205\n\u03b1 \u21900\nfor S \u2208(Sdef \u222aSdiv) do\nif (|S| == N) \u2227(f(S) \u2265\u03b1) then\n\u03b1 \u2190f(S)\nS\u2217\u2190S\nend if\nend for\nreturn S\u2217\nInput: Generated sets of sentences Sdef and Sdiv, respectively from default and diversified prompts, the number of desired output sentences N, the temporarily stored value \u03b1 and a diversity metric f. Output: Output set of sentences S\u2217 S\u2217\u2190\u2205 \u03b1 \u21900 for S \u2208(Sdef \u222aSdiv) do if (|S| == N) \u2227(f(S) \u2265\u03b1) then \u03b1 \u2190f(S) S\u2217\u2190S end if end for return S\u2217\nample, a randomly selected set of sentences would be highly diverse, yet unlikely to capture the input concept sets. On the other hand, if we force an LLM to generate sentences that contain all of the input concepts, it might find difficult to generate semantically diverse sentences and resort to trivial lexical or syntactic diversity tricks such as morphological inflections or word-order permutations. To address this issue, we propose a diversitybased sampling method shown in Algorithm 1. Consider that the default prompt provides a set Sdef of sentences that have not been optimised for diversity (likely to have a higher quality), while on the other hand the diversified prompt provides a set Sdiv of sentences that are further refined for diversity (likely to have a higher diversity). We wish to find a set of sentences that simultaneously satisfies the following criteria: (a) must contain exactly N sentences, as specified by the user, and (b) must have a high diversity score, measured using a userspecified diversity metric f(\u2208R\u22650). We formalise this as a subset search problem, where we compute the union Sdef \u222aSdiv and search for the subset S\u2217 that jointly satisfies those criteria following the procedure detailed in Algorithm 1. Although the total number of subsets of size N is \ufffd|Sdef\u222aSdiv| N \ufffd , it is sufficiently small for the values of N(\u22646) in our GCR tasks, which makes this subset search fast in practice.\n# 4 Experimental Settings 4.1 Tasks and Datasets\n# 4.1 Tasks and Datasets\nWe evaluate ICD on three GCR tasks as follows. Constrained Commonsense Reasoning: In CommonGen (Lin et al., 2020) benchmark, a model is required to generate a sentence covering a given set of concepts such that background commonsense knowledge associated with the input concepts is\nreflected. This dataset contains 35K distinct concept sets (train = 32651, dev = 993, and test = 1497) with corresponding human written sentences (train = 67389, dev = 4018, and test = 6042). Each instance contains on average 3-5 input concepts. Commonsense Explanation Reasoning: ComVE (Wang et al., 2020) is part of the SemEval 2020 commonsense validation task, where for a given counterfactual statement, a model is required to generate an explanation providing a reason describing why the statement is nonsensical. This dataset contains 10K (train = 8532, dev = 476, and test = 992) examples, where each example contains three reference outputs. Diversified GCR: DimonGen (Liu et al., 2023) involves generating diverse sentences that describe the relationships between two given concepts. It is a challenging task because it requires generating reasonable scenarios for a given pair of concepts without any context. This dataset contains 17109 instances (train = 15263, dev = 665, test = 1181), where each instance has 3-5 references.\n# 4.2 Evaluation Metrics\nWe measure both the quality and diversity of the sentences generated by models using the metrics described next.\n# 4.2.1 Quality Metrics\nWe compare a generated sentence by a model against a set of human-written references to evaluate the quality of the generation using several metrics: BLEU (Papineni et al., 2002) measures n-gram precision against human reference texts, SPICE (Anderson et al., 2016) measures the semantic propositional overlap between two sentences, and BERTScore (Zhang et al., 2020) uses contextualised word embeddings to measure the semantic similarity between tokens in two sentences. In alignment with prior works (Yu et al., 2022; Liu et al., 2023; Hwang et al., 2023), when multiple candidate sentences are generated for a test case, we select the highest-scoring candidate for evaluating quality.\n# 4.2.2 Diversity Metrics\nPairwise Diversity: We use self-BLEU (Zhu et al., 2018) to measure n-gram overlap among sentences within each generated set. The metric computes the average sentence-level similarity between all pairwise combinations of the generations in the generation set. Note that unlike BLEU, self-BLEU\ndoes not require human generated references for measuring diversity. We use self-BLEU3/4 (corresponding to n = 3 and 4) in our experiment. Lower self-BLEU scores indicate higher lexical diversity. Corpus Diversity: To measure the variety within our generated text corpus, we employ Distinctk (Li et al., 2016), which calculates the ratio of unique k-grams to the total number of k-grams. This metric is particularly useful for adjusting the bias of LLMs toward generating longer sequences, ensuring that diversity is not artificially inflated by the sentence length. Additionally, we use Entropyk to evaluate the distributional uniformity of kgram occurrences, considering word frequencies for a more nuanced view of diversity. Higher Distinct-k and Entropy-k scores indicate higher diversity. Semantic Diversity: All previously described diversity metrics are limited to evaluating lexical diversity. To measure diversity at a semantic level, we propose self-cosSim, which is the average pairwise cosine similarity between generated sentences, computed using sentence embeddings obtained from SimCSE (Gao et al., 2021). Likewise, we define the self-BERTScore as a diversity metric that averages the BERTScores for all generated sentence pairs. Lower self-cosSim and self-BERTScore values indicate higher semantic diversity.\n# 4.2.3 Combined Metrics\nWe would prefer GCR models that have both high quality and high diversity. To incoporate both aspects into a single metric, we compute the Harmonic Mean between (a) the self-BLEU-4 as the diversity metric, and (b) BERTScore as the quality metric. As discussed in \u00a7 3.2, there exists a tradeoff between quality and diversity in GCR. Therefore, the harmonic mean is suitable when averaging quality and diversity scores.3 Alihosseini et al. (2019) proposed Fr\u00b4echet BERT Distance (FBD) as a joint metric for simultaneously measuring both the quality and diversity of NLG. FBD is inspired by the Fr\u00b4echet Inception Distance (FID), proposed by Heusel et al. (2017), for measuring the quality of image generation. Specifically, FBD computes the pooler output4 of a sentence as\n3We use self-BLEU-4 for diversity and BERTScore for quality in Harmonic Mean due to their reliability shown in preliminary evaluations. Other metric pairs are in \u00a7 5.3. 4The last layer\u2019s hidden-state of the first token of the sequence is further processed by a Linear layer and a Tanh\nits embedding (Devlin et al., 2019) and represents a set of sentences using the mean vector and the covariance matrix computed from their sentence embeddings. Next, Wasserstein-2 distance is computed between the set of reference sentences and the set of generated sentences, which captures both the distance between the means as well as variance in the distributions. Lower FBD scores indicate high combined performance.\nWe use GPT3.5-turbo and Vicuna-13b-v1.55 as LLMs with temperature set to 1.0 in our experiments. By using two LLMs with significantly differing number of parameters and by including, Vicuna, an open source LLM, we plan to improve the reliability and reproducibility of our results. Max response length is set to 25 tokens. The inference times for CommonGen, ComVE and DimonGen datasets are respectively 5-6, 2-3 and 1-2 hours. The costs of running ICD with GPT3.5-turbo are ca. $6, $4 and $4 respectively for CommonGen, ComVE and DimonGen datasets. On the other hand, the costs of fine-tuning on GPT3.5-turbo are much higher at $58.8 for CommonGen, $24.7 for ComVE and $32.0 for DimonGen. Moreover, fine-tuning with LoRA (Hu et al., 2022) with rank of 8 and alpha of 16 on Vicuna takes ca. 34 hours. We use BART-large6 for MoE-based models. We use the GPT3.5-turbo to generate sentences for the CommonGen train/dev/test sets using the default, diversified and for ICD. For model training, we use the Adam optimiser (Kingma and Ba, 2015) with a batch size of 64, a learning rate of 3e-5 and a beam size of 5. All of the MoE-based models are trained for 20 epochs and required to generate k = 3 sentences. All experiments, except with GPT3.5-turbo, are conducted on a single RTX A6000 GPU.\n# 5 Results and Discussion\n# 5 Results and Discussion 5.1 Commonsense Generatio\nWe compare the commonsense generations made by ICD against those using the default and diversified prompts. For this purpose, we use GPT3.5-turbo as the LLM and use the same 10 few-shot examples in all prompts for ICL. Further templates of the default and diversified prompts\nactivation function. 5https://huggingface.co/lmsys/vicuna-13b-v1.5 6https://huggingface.co/facebook/bart-large\nSemantic Diversity \u21d3\nCorpus Diversity \u21d1\nPairwise Diversity \u21d3\nQuality \u21d1\nCombined\nself-cosSim\nself-BERTScore\nEntropy-4\nDistinct-4\nself-BLEU-3\nself-BLEU-4\nBLEU-3\nBLEU-4\nSPICE\nBERTScore\nHarmonic \u21d1\nFBD \u21d3\nCommonGen\nHuman\n67.3\n60.6\n10.9\n91.0\n25.4\n17.6\n-\n-\n-\n-\n-\n-\nFine-tune\n64.7\n55.9\n11.4\n91.1\n26.9\n17.9\n41.2\n32.1\n30.3\n64.2\n72.1\n51.9\ndefault\n93.3\n88.7\n10.2\n53.7\n77.2\n72.4\n50.8\n40.9\n30.1\n70.4\n39.6\n60.2\ndiversified\n85.2\n69.8\n11.0\n83.7\n44.4\n34.9\n44.3\n34.6\n28.5\n65.0\n65.4\n53.9\nICD\n83.5\n66.2\n11.0\n88.5\n31.0\n21.0\n47.4\n37.7\n29.1\n67.4\n72.7\n51.8\nComVE\nHuman\n62.7\n47.0\n9.6\n96.1\n12.4\n8.1\n-\n-\n-\n-\n-\n-\nFine-tune\n59.8\n42.6\n9.8\n95.2\n13.4\n10.3\n27.4\n19.4\n33.1\n53.7\n67.2\n47.6\ndefault\n83.9\n73.5\n9.6\n74.3\n50.8\n45.2\n27.5\n19.7\n36.2\n55.1\n54.9\n50.9\ndiversified\n76.0\n56.5\n9.7\n88.0\n23.3\n16.6\n30.6\n22.0\n35.8\n56.5\n67.4\n47.9\nICD\n72.5\n51.1\n9.8\n90.1\n13.7\n8.7\n29.0\n20.8\n36.1\n55.5\n69.0\n48.7\nDimonGen\nHuman\n56.8\n47.0\n10.1\n85.6\n14.7\n8.7\n-\n-\n-\n-\n-\n-\nFine-tune\n43.4\n33\n10.4\n98.7\n6.8\n3.4\n17.7\n10.7\n15.5\n42\n58.5\n51.6\ndefault\n75.7\n71.3\n10\n83.2\n43.4\n37.3\n15.9\n9.5\n16.4\n44.5\n52.1\n68.2\ndiversified\n57.1\n46.9\n10.5\n95.9\n11.2\n6.5\n11.4\n6.4\n15.2\n39.9\n55.9\n69.0\nICD\n56.7\n45.7\n10.4\n96.3\n6.5\n3.5\n13.2\n7.6\n15.4\n41.7\n58.2\n68.0\nTable 1: Diversity and quality scores on CommonGen, ComVE and DimonGen with GPT3.5-turbo LLM. Best results on each task for each metric are shown in italics, while the best performing ICL results are shown in bold.\nused for each task are given in Appendix D. To assess the impact of ICL, we compare against finetune method, wherein GPT3.5-turbo is fine-tuned on the entire training set in each dataset. Specifically, we use multiple human-written sentences, available in the training data for the three datasets to separately fine-tune the models for each task. It is noteworthy that the fine-tune method uses a substantially larger dataset for training (e.g., 67,389 sentences from CommonGen) compared to the 10 examples used by the ICL-based approaches. We use self-BLEU-3 as the diversity metric f in Algorithm 1 for ICD in this evaluation. The outcomes, presented in Table 1, highlight the diversity and quality metrics of these methods across the CommonGen, ConVE, and DimonGen datasets. Additionally, a human baseline is introduced to evaluate the diversity of sentences written by humans, where we pair-wise compare the human-written sentences for each input in the instances in the benchmark datasets using diversity metrics. Note that however, the human baseline must not be considered as an upper-bound for diversity because there are only a smaller number of human-written sentences per instance in the benchmark datasets. From Table 1, we see that fine-tune generates sentences that have high semantic and corpus diversity, and outperforms the human baseline. However, recall that fine-tune requires a much larger training set and is computationally costly compared to all ICL-based methods. Moreover, we see that ICD can strike a good balance between quality and diversity in the sentences generated. Among\nthe ICL-based methods, ICD achieves the best diversity scores on all diversity metrics in all three datasets. It also exhibits higher diversity compared against the human-written references. Moreover, ICD outperforms default and diversified according to the Combined metrics. ICD also achieves a Harmonic Mean comparable to that of the fine-tune baseline. Although default reports the best quality scores, it has low diversity, and is consistently outperformed by diversified and ICD on diversity metrics. On the other hand, diversified generally scores lower on the quality metrics. Compared to default and diversified, ICD enhances generation diversity while maintaining a satisfactory level of quality. ICD is also more stable to the sampling method such as temperature than fine-tune, as shown in Appendix B. Note that fine-tune is not an ICL setting (the focus of this paper) and is included only as a baseline to demonstrate the level of performance that can be achieved by finetuning on a much larger dataset. Despite this, ICD outperforms fine-tune on the Pairwise Diversity in all three datasets, and Combined metrics in the CommonGen dataset. As an open source alternative LLM to GPT3.5-turbo, we repeat this evaluation with Vicuna-13b (Zheng et al., 2023) in Table 2. The same 10 few-shot examples as used with GPT3.5-turbo are used in this experiment for the ICL-based methods. Full table on three datasets are shown in Appendix C. Table 2 reconfirms ICD\u2019s ability to balance both quality and diversity according to the Combined metrics (i.e. Harmonic Mean\nMethod\nSCS \u21d3\nSBS \u21d3\nE-4\u21d1\nD-4\u21d1\nSB-3\u21d3\nBLEU-3\u21d1\nSPICE\u21d1\nHM \u21d1\nFBD \u21d3\nFine-tune\n59.6\n49.9\n11.4\n93.3\n22.8\n35.8\n27.6\n69.9\n52.4\nDefault\n82.2\n73.8\n10.9\n74.9\n52.9\n44.6\n29.1\n60.2\n56.2\nDiversified\n59.1\n53.3\n11.3\n91.3\n23.6\n32.6\n24.3\n68.6\n53.2\nICD\n59.3\n49.8\n11.3\n93.7\n11.3\n34.2\n25.5\n73.4\n51.0\nTable 2: GCR on CommonGen using Vicuna-13b. ICD uses self-BLEU-3. Here, SCS: self-CosSim, SBS: se BERTScore, E-4: Entropy-4, D-4: Distinct-4, SB-3: self-BLEU3, HM: Harmonic Mean. Best results for ea metric are shown in italics, while the best performing ICL results are shown in bold.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a24c/a24cc9fa-4a60-4179-bcf1-d9ae0054ee4d.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 3: Human vs. GPT3.5 diversity ratings for randomly sampled sets of sentences generated by ICD. Cohen\u2019s \u03ba = 0.409 indicates a moderate level of agreement.</div>\nFigure 3: Human vs. GPT3.5 diversity ratings for randomly sampled sets of sentences generated by ICD. Cohen\u2019s \u03ba = 0.409 indicates a moderate level of agreement.\nand FBD) on this dataset. Interestingly, we see that methods that use Vicuna-13b to be more diverse compared to those that use GPT3.5-turbo, while the latter showing better generation quality. In Table 3, we use different diversity metrics as f in Algorithm 1 to study the effect on text generation of ICD. We see that self-BLUE-3 and self-CosSim perform similarly across the quality metrics. SelfBERTScore shows a slightly lower quality (BLEU3 and SPICE). According to the combined metrics, any of those diversity metrics can be used with ICD to obtain comparable performance.\n# 5.2 Downstream Evaluation\nThe experiments presented in \u00a7 5.1 show the ability of our proposed ICD to generate diverse and commonsense bearing sentences. Therefore, an important question with practical implications is whether we can use the sentences generated by ICD as additional training data to improve both diversity and quality of previously proposed models on the GCR task, which could be seen as a downstream (extrinsic) evaluation. For this purpose we select the MoE (Shen et al.,\n2019), which diversifies the generation by selecting outputs from a mixture of experts. Each expert is assigned a randomly generated sequence of tokens, which is used as a prefix for all inputs sent to that expert. For each input, an expert is selected according to the value of a latent variable, which is trained using the hard-EM algorithm. We follow Liu et al. (2023) and train three experts that retrieve sentences from the collection of sentences generated by ICD for concept sets in the CommonGen train split (210846 sentences in total). We use BART-large (Lewis et al., 2020) as the base model, which has shown to produce high quality commonsense generations (Zhang et al., 2023) as the generator for all experts (see Appendix A for further details). We denote this method by ICD+MoE. As baselines for comparisons, we repeat the above process using the sentences generated by default and diversified, which we denote respectively as default+MoE and diversified+MoE in Table 4. Moreover, we compare the performance against two previously proposed MoE models: MoE (Shen et al., 2019) and MoKGE (Yu et al., 2022). MoE relies solely on the base model, whereas MoKGE requires each expert to use different sets of concepts from the ConceptNet (Speer et al., 2017) knowledge graph (KG). Because Yu et al. (2022) do not evaluate their MoKGE method on CommonGen, we ran their original implementation7 on CommonGen and report results in Table 4. All previously proposed GCR methods are exclusively trained using human-created data (e.g. sentences written by human and/or manually compiled KGs such as ConceptNet), whereas the methods described thus far in this section are trained on sentences generated by an LLM (GPT3.5-turbo). Therefore, to evaluate the feasibility of using LLMgenerated sentences for training GCR models, we include the following previously proposed GCR models that are trained using a combination of cor-\n7https://github.com/DM2-ND/MoKGE\nMethod\nSCS \u21d3\nSBS \u21d3\nE-4\u21d1\nD-4\u21d1\nSB-3\u21d3\nBLEU-3\u21d1\nSPICE\u21d1\nHM \u21d1\nFBD \u21d3\nself-BLEU-3\n83.5\n66.2\n11.0\n88.5\n31.0\n47.4\n29.1\n72.7\n51.8\nself-CosSim\n81.0\n70.1\n10.9\n82.5\n44.5\n47.6\n29.3\n65.7\n51.8\nself-BERTScore\n83.1\n62.8\n11.0\n87.0\n36.3\n46.5\n28.9\n69.6\n51.8\nTable 3: Comparing the effect of using different diversity metrics, f, in Algorithm 1 for ICD. We use GPT3.5-turb as the LLM and the best results on CommonGen dataset are in bold. Here, SCS: self-CosSim, SBS: self-BERTScor E-4: Entropy-4, D-4: Distinct-4, SB-3: self-BLEU3, HM: Harmonic Mean.\nSemantic Diversity \u21d3\nCorpus Diversity \u21d1\nPairwise Diversity \u21d3\nQuality \u21d1\nCombined\nself-cosSim\nself-BERTScore\nEntropy-4\nDistinct-4\nself-BLEU-3\nself-BLEU-4\nBLEU-3\nBLEU-4\nSPICE\nBERTScore\nHarmonic Mean \u21d1\nFBD \u21d3\nKG-BART\n-\n-\n-\n-\n-\n-\n42.1\n30.9\n32.7\n-\n-\n-\nEKI-BART\n-\n-\n-\n-\n-\n-\n46.0\n36.1\n33.4\n-\n-\n-\nKFCNet-w/o FC\n-\n-\n-\n-\n-\n-\n50.2\n42.0\n35.9\n-\n-\n-\nKFCNet\n-\n-\n-\n-\n-\n-\n57.3\n51.5\n39.1\n-\n-\n-\nMoE\n89.3\n81.9\n9.7\n61.6\n63.1\n56.6\n49.0\n38.5\n33.5\n70.6\n53.8\n61.7\nMoKGE\n88.7\n80.6\n9.9\n65.2\n60.4\n53.6\n48.8\n38.4\n33.1\n70.3\n55.9\n60.8\ndefault+MoE\n91.2\n84.6\n9.7\n60.3\n66.5\n60.0\n51.2\n40.6\n34.8\n72.9\n51.6\n62.3\ndiversified+MoE\n86.7\n80.4\n9.8\n63.3\n59.2\n53.5\n50.7\n40.6\n34.0\n71.3\n56.3\n55.0\nICD+MoE\n91.1\n82.6\n9.8\n64.8\n59.0\n51.1\n52.4\n42.2\n34.5\n73.5\n58.7\n62.3\nTable 4: Downstream evaluation of the LLM-generated sentences. Top block methods use human-generated resources for training, while the ones in the bottom block are trained on LLM-generated sentences. MoE approaches are shown in the middle block and bottom block. BART-large is used as the generator for MoE-based methods. Best results for each metric are shown in bold, while the best performing MoE for quality is shown in underline.\npora and KGs: KG-BART (Liu et al., 2021),EKIBART (Fan et al., 2020) and KFCNet (Li et al., 2021). For KFCNet, we present its two results \u2013 KFCNet w/o FC (without Filtering and Contrastive modules), which relies only on sentences including the input concepts, without further processing, and KFCNet, which additionally ranks candidates and adds contrastive modules for the encoder and the decoder (Li et al., 2021). However, note that those methods do not consider diversification, and do not report performance using diversity metrics. Therefore, we report only their published results for generation quality in Table 4. From Table 4 we see that diversified+MoE always outperforms the original MoE in all diversity metrics, which shows that sentences generated from LLMs can be used to diversify MoEbased GCR. ICD+MoE closely matches the performance of diversified+MoE on diversity metrics, while outperforming both diversified+MoE and default+MoE on quality metrics. In particular, the quality metrics reported by ICD+MoE (underlined in Table 4) are competitive against those obtained by the models that are trained on human-compiled resources (in the top block), except against KFCNet. This finding hints at potential improvement gains for GCR by using hybrid training resources that combine both human-compiled and LLM-generated data, which we highlight as an interesting future research direction.\nDataset & Metrics\nFine-tune\nDefault\nDiversified\nICD\nCommonGen\nself-BLEU4 + BERTScore\n72.1\n39.6\n65.4\n72.7\nself-cosSim + SPICE\n32.6\n11.0\n19.5\n21.1\nself-BERTScore + BLEU3\n42.6\n18.5\n35.9\n39.5\nComVE\nself-BLEU4 + BERTScore\n67.2\n54.9\n67.4\n69.0\nself-cosSim + SPICE\n36.3\n22.3\n28.7\n31.2\nself-BERTScore + BLEU3\n37.1\n27.0\n35.9\n36.4\nDimongen\nself-BLEU4 + BERTScore\n58.5\n52.1\n55.9\n58.2\nself-cosSim + SPICE\n24.3\n19.6\n22.4\n22.7\nself-BERTScore + BLEU3\n28.0\n20.5\n18.8\n21.2\nTable 5: Different combined metrics that are calculated as the harmonic means between quality and diversity metric pairs. The metric with \u2018self\u2019 in each line is a diversity metric and the other is a quality metric. Best results on each task for each metric are shown in italics, while the best performing ICL results are shown in bold.\n# 5.3 Candidate metrics for calculating Harmonic Means\nIn the previous experiments, we computed the harmonic mean between self-BLEU-4 and BERTScore to obtain a combined metric that considers both quality and diversity of commonsense generation. Specifically, self-BLEU (Zhu et al., 2018) evaluates the n-gram overlap between pairs of sentences in the generated set, providing a measure of lexical diversity. On the other hand, BERTScore (Zhang et al., 2020) assesses the semantic similarity between the generated sentences and the human-\nHuman: \u2022 A pizza parlor wouldn't have workout equipment, and sells fattening food. \u2022 A pizza parlor is not a good place to exercise. \u2022 Pizza parlors do not have exercise equipment. Default: \u2022 Pizza parlors are not typically associated with exercise or physical activity \u2022 Pizza parlors are not typically associated with exercise or physical activity \u2022 Pizza parlors are not places for exercise, they are places to eat pizza.\nICD: \u2022 People usually go to a gym, park or fitness center to exercise, not a pizza parlor. \u2022 Pizza parlors are not typically associated with exercise. \u2022 Exercise is not typically done at a pizza parlor.\nFigure 4: Sentences generated by default prompt and ICD against those by humans on CommonGen and ComVE test instances. ICD generates more diverse and high quality sentences than default.\nwritten sentences in each dataset, capturing the quality aspects from a semantic perspective. Note that other combinations of quality and diversity metrics can also be used for computing different harmonic means as shown in Table 5. From Table 5, we see that according to each combined metric, ICD achieves the best performance among all ICL-based approaches. Moreover, ICD also has comparable performance against the fine-tune method.\n# 5.4 Diversity-Awareness of LLMs\nGiven that we use LLMs to produce diverse generations via ICL, it remains an open question whether an LLM would agree with humans on the diversity of a given set of sentences. To answer this question, we use randomly selected 210 sentences (35 sets, each containing 6 sentences) generated by ICD (using self-BLEU-3 as the diversity metric) for the input concept sets in the CommonGen dataset. We use GPT3.5-turbo to rate the diversity of a set of sentences according to five levels from 1 (highly similar) to 5 (highly diverse).8 We provide the same instructions as the annotation guidelines for eight human annotators, who are graduate students in Natural Language Processing (NLP). To reduce subjective variability in human judgements, we average and then normalise the ratings following the Likert scale. In Figure 3, we plot the GPT-assigned ratings against those provided by humans. We further split the ratings into high vs. low diversity ratings depending on whether the rating is greater or lesser than 3. The majority of the data points are dis-\n8Detailed prompt templates are shown in Appendix D.\ntributed along the diagonal quadrants and a Cohen\u2019s Kappa of 0.409 indicating a moderate level of agreement between GPT and human ratings for diversity. The generated sentences using the default prompt, ICD and the human references in CommonGen and ComVE datasets for a single test instance are shown in Figure 4. From Figure 4 we see that the sentences generated using the default prompt often results in significant token overlap, thereby lowering the diversity. On the other hand, although Table 1 shows that ICD has lower scores in quality metrics, we find that ICD generates sentences of sufficient quality. These sentences are both lexically and semantically diverse, covering the diverse viewpoints found in the human references. We provided additional ICD generated sentences in Table 8, showing that ICD achieves better diversity than the default prompt while maintaining adequate quality, and is fluent and commonsense bearing.\n# 6 Conclusion\nWe proposed, ICD, an ICL-based method for achieving the optimal balance between diversity and quality in text generation via LLMs. Our experiments, conducted on three GCR tasks, demonstrate that ICD significantly improves the diversity without substantially compromising the quality. Furthermore, we found that by training on the sentences generated by ICD, we can improve diversity in previously proposed GCR methods.\nThis study primarily focuses on the generation of English sentences using pre-trained LLMs, a limitation shaped by the datasets we employed. Specifically, we used the ComVE (Wang et al., 2020), CommonGen (Lin et al., 2020) and DimonGen (Liu et al., 2023) datasets, which are well-regarded for evaluating diversified commonsense reasoning in English. Therefore, our evaluation of the generation quality was limited to English, which is a morphologically limited language. Future research could expand this scope to include multilingual pretrained models, thereby encompassing a broader linguistic spectrum. Three GCR datasets contain multiple human-written sentences (3-5 for each sample), which could be considered as golden references for quality evaluation. The focus of our paper is on diversity and in \u00a7 5.4, we compare the human and LLM produced ratings for commonsense generation diversity. Therefore, we only conducted additional human evaluation for the diversity of the sentences generated. Our approach is primarily geared towards optimizing the trade-off between diversity and quality in text generation. Consequently, we maintained consistent default instructions across all experiments, adopting the standard commonsense generation prompts used in Li et al. (2023) as our default instructions. We note that decoding strategies can influence the diversity of generated outputs. In our work, we fix the decoding strategy (top-p, temperature) to maintain consistency across our experiments. We also evaluate our proposed method under various temperature sampling settings, as shown in Appendix B. Studying the effect of other decoding strategies on the system could be considered as a future direction. We conducted our experiments using both a closed model (i.e. GPT3.5-turbo-0613) as well as an open-source one (i.e. Vicuna-13b-v1.5) to promote the reproducibility of our results, which are reported using multiple publicly available benchmarks. However, there exist many other LLMs with varying numbers of parameters and trained on different corpora. Therefore, we consider that it is important to evaluate our proposed method on a broad range of LLMs to verify the generalisability of our proposed method. However, conducting such a broad analysis can be computationally intensive and costly. For example, although GPT-4 is\nknown to have superior text generation capabilities, it incurs substantially higher costs (being 30 times more expensive than GPT3.5-turbo at the current pricing). Nevertheless, ICD is adaptable and could be extended to other LLMs.\n# 8 Ethical Considerations\nThe experiments conducted in this paper are based on the publicly available datasets, CommonGen, ComVE, and DimonGen. To the best of our knowledge, no ethical issues have been reported for those datasets. Therefore, we do not foresee any datarelated ethical issues arising from our work. However, LLMs are known to generate responses that may reflect societal biases and potentially harmful content. We have not verified whether the GPT3.5-turbo and Vicuna-13b LLMs that we use in our experiments have similar problems. Therefore, it is important to test on existing benchmarks for social biases and harmful generations before the proposed method is deployed to diversify existing GCR methods used by human users. To elicit human judgements of diversity for the sentences generated by ICD, we use annotators who are familiar with working with LLMs. It is possible that their subjective (and possibly biased) viewpoints might have influenced the ratings provided. Therefore, it will be important to conduct the evaluation involving a group of annotators with different backgrounds to validate the findings reported in this analysis.\n# Acknowledgements\nDanushka Bollegala holds concurrent appointments as a Professor at University of Liverpool and as an Amazon Scholar. This paper describes work performed at the University of Liverpool and is not associated with Amazon.\n# References\nDanial Alihosseini, Ehsan Montahaei, and Mahdieh Soleymani Baghshah. 2019. Jointly measuring diversity and quality in text generation models. In Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation. Association for Computational Linguistics, Minneapolis, Minnesota, pages 90\u201398.\nECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V 14. Springer, pages 382\u2013398. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33:1877\u20131901. Yi Chen, Rui Wang, Haiyun Jiang, Shuming Shi, and Ruifeng Xu. 2023. Exploring the use of large language models for reference-free text quality evaluation: A preliminary empirical study. arXiv preprint arXiv:2304.00723 . Ernest Davis and Gary Marcus. 2015. Commonsense reasoning and commonsense knowledge in artificial intelligence. Communications of the ACM 58(9):92\u2013 103. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, pages 4171\u20134186. Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey for in-context learning. arXiv preprint arXiv:2301.00234 . Angela Fan, Mike Lewis, and Yann Dauphin. 2018. Hierarchical neural story generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics. Zhihao Fan, Yeyun Gong, Zhongyu Wei, Siyuan Wang, Yameng Huang, Jian Jiao, Xuan-Jing Huang, Nan Duan, and Ruofei Zhang. 2020. An enhanced knowledge injection model for commonsense generation. In Proceedings of the 28th International Conference on Computational Linguistics. pages 2014\u20132025. Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021. Simcse: Simple contrastive learning of sentence embeddings. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. pages 6894\u20136910. Ankush Gupta, Arvind Agarwal, Prawaan Singh, and Piyush Rai. 2018. A deep generative framework for paraphrase generation. In Proceedings of the aaai conference on artificial intelligence. volume 32 (1). Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. 2017. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In I. Guyon, U. Von Luxburg,\nand R. Garnett, editors, Advances in Neural Information Processing Systems. Curran Associates, Inc., volume 30. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751 . Edward J Hu, yelong shen, Phillip Wallis, Zeyuan AllenZhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations. EunJeong Hwang, Veronika Thost, Vered Shwartz, and Tengfei Ma. 2023. Knowledge graph compression enhances diverse commonsense generation. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Singapore, pages 558\u2013 572. https://aclanthology.org/2023.emnlp-main.37. Diederik P. Kingma and Jimmy Lei Ba. 2015. Adam: A method for stochastic optimization. In Proc. of ICLR. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pages 7871\u20137880. Bei Li, Rui Wang, Junliang Guo, Kaitao Song, Xu Tan, Hany Hassan, Arul Menezes, Tong Xiao, Jiang Bian, and JingBo Zhu. 2023. Deliberate then generate: Enhanced prompting framework for text generation. Haonan Li, Yeyun Gong, Jian Jiao, Ruofei Zhang, Timothy Baldwin, and Nan Duan. 2021. Kfcnet: Knowledge filtering and contrastive learning for generative commonsense reasoning. In Findings of the Association for Computational Linguistics: EMNLP 2021. pages 2918\u20132928. Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and William B Dolan. 2016. A diversity-promoting objective function for neural conversation models. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pages 110\u2013119. Zhongyang Li, Xiao Ding, and Ting Liu. 2018. Generating reasonable and diversified story ending using sequence to sequence model with adversarial training. In Proceedings of the 27th International Conference on Computational Linguistics. pages 1033\u20131043. Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, and Xiang Ren. 2020. CommonGen: A constrained text\nOpenAI. 2023b. Introducing chatgpt. https://openai. com/blog/chatgpt. Accessed: 2023-11-23.\nCunxiang Wang, Shuailong Liang, Yili Jin, Yilong Wang, Xiaodan Zhu, and Yue Zhang. 2020. Semeval2020 task 4: Commonsense validation and explanation. In Proceedings of the Fourteenth Workshop on Semantic Evaluation. pages 307\u2013321.\nCunxiang Wang, Shuailong Liang, Yili Jin, Yilong Wang, Xiaodan Zhu, and Yue Zhang. 2020. Semeval2020 task 4: Commonsense validation and explanation. In Proceedings of the Fourteenth Workshop on Semantic Evaluation. pages 307\u2013321.\nLean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, and Xu Sun. 2023. Label words are anchors: An information flow perspective for understanding in-context learning. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Singapore, pages 9840\u2013 9855.\nWenhao Yu, Chenguang Zhu, Lianhui Qin, Zhihan Zhang, Tong Zhao, and Meng Jiang. 2022. Diversifying content generation for commonsense reasoning with mixture of knowledge graph experts. In Proceedings of the 2nd Workshop on Deep Learning on Graphs for Natural Language Processing (DLG4NLP 2022). pages 1\u201311.\nTianhui Zhang, Danushka Bollegala, and Bei Peng. 2023. Learning to predict concept ordering for common sense generation. In Jong C. Park, Yuki Arase, Baotian Hu, Wei Lu, Derry Wijaya, Ayu Purwarianti, and Adila Alfa Krisnadhi, editors, Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics, Nusa Dua, Bali, pages 10\u201319.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert.\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\nYaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and Yong Yu. 2018. Texygen: A benchmarking platform for text generation models. In The 41st international ACM SIGIR conference on research & development in information retrieval. pages 1097\u20131100.\n# Supplementary Appendix A Mixture of Experts\n# Supplementary Appendix\nGiven an input x, its corresponding LLM-generated sentences are divided into three random subsets. For each subset Gi = {gi 1, ..., gi k}, alongside the input x, we concatenate their token sequences with a separate latent variable zi, resulting in the final\ninput xf i . The zi is a randomly initialised sequence of tokens.\n(1)\nWe train the model using the hard ExpectationMaximization (EM) approach, where during the E-step, for each xf i and its corresponding target ytarget i , we identify the input that yields the highest probability as the best training example, with \u03b8 representing the generator model parameters: The model is trained using hard-EM by assigning full responsibility to the expert with the largest joint probability. In the E-step, for each input xfin i and target ytgt i , choose the best input with the highest probability, to construct the training examples, where \u03b8 is the model\u2019s parameters.\n(2)\nSubsequently, in the M-step, we use these selected training examples to fine-tune the generator models. During inference, we input all diversified, contextaware inputs into the generator model to yield a range of diverse outputs.\n# B Impact of sampling temperature on the diversity and quality\nIn this section, we investigate the impact of temperature on various methods on the CommonGen dataset. Although GPT-3.5 also provides the nucleus sampling beyond sampling temperature, we specifically focus on the general performance of ICD under different temperature settings and set nucleus sampling hyper-parameter to 1. Our experiments are conducted on the GPT-3.5-turbo-0613. Table 6 demonstrates that ICD consistently outperforms both default and diversified on the Combined metrics across all temperature settings, which aligns with our findings in \u00a7 5.1. Moreover, ICD exhibits less sensitivity to temperature variations compared to the other baselines and performs better on Combined metrics with the increase of temperature, which can be considered as an additional advantage of our proposed method. Furthermore, we observe that the fine-tune method is also significantly influenced by temperature sampling on the GCR task. At T = 1.5, the default baseline, which applies ICL on the same base model GPT-3.5-turbo, outperforms the fine-tune method. The fine-tuned model generates responses that are of very low quality, consisting mostly of nonsensical word combinations.\nFor example, given the input \u201csidewalk leash dog walk\u201d, the fine-tune method would generate the random sequence: A owners with 2 kangaroos trying to walk their yappy circus bear disguised as a gers?\u201d\u2019texturesumm while ICD generates sentence than covers the task requirement: A dog walks on a sidewalk, attached to a leash. Therefore, we conclude that increasing temperature of the decoder is not a suitable strategy for improving diversity in GCR.\n# C Full results on Vicuna-13b model\nTable 7 shows the full result on the open source Vicuna-13b model across three datasets. It reconfirms ICD\u2019s ability to balance both quality and diversity according to the combined metrics. Furthermore, we find that methods using the Vicuna model show lower quality than those using GPT-3.5-turbo while generating more diverse sentences.\n# D LLM Prompt Templates\nFigure 5 shows the templates that are used for the two GCR tasks: CommonGen and ConVE. The default prompt is adapted from Li et al. (2023) and are task-specific. On the other hand, the diversified prompt modifies the default prompt by appending a task-independent instruction that first checks whether the diversity of the sentences generated in Step 1 is low, and if presents the generated sentences to the LLM and re-prompts it to generate more diverse set of sentences. We use GPT3.5-turbo to predict the diversity of a given set of sentences using the prompt shown in Figure 6. This prompt uses five diversity categories (i.e. very similar, somewhat similar, neutral, somewhat diverse, and highly diverse) with increasing diversity with their definitions. Next, the set of sentences to be evaluated for their diversity is presented. Finally, the expected output format of the predictions is described at the end of the prompt. As recommended by Chen et al. (2023), we do not require the LLM to provide reasons for its predictions because it sometimes forces the model to focus on the reason generation than the prediction. After the LLM\u2019s evaluation, the predictions are mapped to values from 1 to 5 where 1 being highly similar to 5 being highly diverse. For each sentences set, we take the average of LLM predictions over three independent runs.\nSemantic Diversity \u21d3\nCorpus Diversity \u21d1\nPairwise Diversity \u21d3\nQuality \u21d1\nCombined\nself-cosSim\nself-BERTScore\nEntropy-4\nDistinct-4\nself-BLEU-3\nself-BLEU-4\nBLEU-3\nBLEU-4\nSPICE\nBERTScore\nHarmonic \u21d1\nFBD \u21d3\nT = 0\nFine-tune\n100.0\n100.0\n9.15\n14.1\n100.0\n100.0\n45.6\n34.9\n34.4\n71.3\n0.0\n69.7\nDefault\n100.0\n100.0\n9.12\n15\n100.0\n100.0\n40.8\n30.4\n28.5\n67.6\n0.0\n69.7\nDiversified\n86.7\n74\n10.8\n77.8\n52.2\n43.4\n46.2\n36.4\n28.6\n66.6\n61.2\n54.9\nICD\n86\n72.2\n10.9\n80\n46.5\n37.6\n48.1\n38.3\n29.1\n67.7\n65\n53.5\nT = 0.5\nFine-tune\n83.6\n81.6\n10.6\n65.4\n63.8\n55.7\n56.3\n46.8\n36.1\n73.8\n55.4\n58.3\nDefault\n96.1\n94.9\n9.75\n36.9\n88.9\n86.8\n47.6\n37.3\n29.5\n69.6\n22.4\n63.7\nDiversified\n86.4\n73\n10.9\n79.8\n49.9\n40.8\n46\n36.5\n28.6\n66.5\n62.6\n55.4\nICD\n85.1\n70\n10.9\n84.2\n39.4\n29.5\n48.6\n39.1\n29.2\n68.1\n69.3\n53.4\nT = 1\nFine-tune\n64.7\n55.9\n11.4\n91.1\n26.9\n17.9\n41.2\n32.1\n30.3\n64.2\n72.1\n51.9\ndefault\n93.3\n88.7\n10.2\n53.7\n77.2\n72.4\n50.8\n40.9\n30.1\n70.4\n39.6\n60.2\ndiversified\n85.2\n69.8\n11.0\n83.7\n44.4\n34.9\n44.3\n34.6\n28.5\n65.0\n65.4\n53.9\nICD\n83.5\n66.2\n11.0\n88.5\n31.0\n21.0\n47.4\n37.7\n29.1\n67.4\n72.7\n51.8\nT = 1.5\nFine-tune\n25.7\n0.0\n11.9\n100.0\n2.5\n1.8\n8.1\n4.3\n11\n16\n27.5\n67.8\nDefault\n90.4\n81.5\n10.5\n68.4\n63.5\n56.1\n51.4\n41.9\n29.9\n70.1\n54\n56.5\nDiversified\n67.7\n59.3\n11.2\n89.5\n30.6\n22.3\n39.3\n29.7\n26.9\n61.9\n68.9\n54\nICD\n78.3\n59.8\n11.2\n92.8\n20.9\n12.4\n44.1\n34.7\n27.9\n65.4\n74.9\n51.6\nTable 6: Diversity and quality scores on four temperature settings (T = 0/0.5/1/1.5) on the CommonGen dataset. The results show that our proposed method ICD performs well across different temperatures. Best results for each metric at each temperature setting are shown in italics, while the best performing ICL results are shown in bold.\nSemantic Diversity \u21d3\nCorpus Diversity \u21d1\nPairwise Diversity \u21d3\nQuality \u21d1\nCombined\nself-cosSim\nself-BERTScore\nEntropy-4\nDistinct-4\nself-BLEU-3\nself-BLEU-4\nBLEU-3\nBLEU-4\nSPICE\nBERTScore\nHarmonic \u21d1\nFBD \u21d3\nCommonGen\nFine-tune\n59.6\n49.9\n11.4\n93.3\n22.8\n14.5\n35.8\n26.8\n27.6\n59.1\n69.9\n52.4\ndefault\n82.2\n73.8\n10.9\n74.9\n52.9\n45.4\n44.6\n34.9\n29.1\n67.1\n60.2\n56.2\ndiversified\n59.1\n53.3\n11.3\n91.3\n23.6\n16.4\n32.6\n23.7\n24.3\n58.2\n68.6\n53.2\nICD\n59.3\n49.8\n11.3\n93.7\n11.3\n5.8\n34.2\n24.9\n25.5\n60.1\n73.4\n51.0\nComVE\nFine-tune\n60.4\n45.8\n9.6\n93.8\n17.1\n14.1\n27.9\n19\n31.1\n52.3\n65.0\n47.3\ndefault\n75.7\n57.1\n9.8\n78.0\n36.7\n31.1\n23.8\n16.9\n33\n49.2\n57.4\n60.8\ndiversified\n64.7\n42.3\n10.0\n89.3\n13.4\n8.8\n23.2\n16.0\n32.6\n49.8\n64.4\n56.9\nICD\n61.5\n37.3\n10.0\n90.1\n5.8\n3.0\n22.7\n15.7\n32.5\n48.8\n65.1\n58.2\nDimonGen\nFine-tune\n41\n29.5\n10.4\n99\n5\n2.2\n15.4\n8.9\n14.6\n39.4\n56.2\n52.8\ndefault\n64.0\n48.6\n10.3\n95.0\n17.9\n13.1\n13.6\n7.9\n14.4\n41.3\n56\n61.1\ndiversified\n55.2\n45.4\n10.3\n97\n11.9\n7.3\n12.1\n6.7\n13.4\n39.8\n55.7\n62\nICD\n53.1\n37.0\n10.4\n98\n2.4\n0.9\n12.7\n7.3\n13.6\n39\n56.6\n61.1\nTable 7: Performance on CommonGen, ComVE and DimonGen with Vicuna-13b. Best results on each task f each metric are shown in italics, while the best performing ICL results are shown in bold.\n# E Human Evaluation\nAs human-annotators, we recruited eight graduate students from the department of computer science who specialise in NLP and are fluent speakers in English. We provided the human annotators with the same set of instructions as we provided to the LLMs. Apart from the instruction in Figure 6, we also instruct the human annotators to focus on the diversity, and not so much on their commonsense quality, which we evaluate separately using semiautomatic metrics by comparing against humanwritten reference sentences in the evaluation benchmarks. Moreover, we informed the annotators that their evaluations would be used in a comparative analysis with the scores generated by an LLM.\n# F Additional Generation Examples\nWe show additional sentences generated by our proposed methods for the CommonGen, ComVE and DimonGen datasets in Table 8.\nCommonGen\nKeyword\ndog throw frisbee catch\nSentences\nThe dog eagerly waits for the frisbee to be thrown and then leaps to catch it in mid-air.\nThe owner tosses the frisbee and the dog quickly reacts, catching it effortlessly.\nThe dog excitedly chases after the thrown frisbee and skillfully catches it in its mouth.\nAfter the frisbee is thrown, the dog jumps up high and grabs it, showcasing its impressive catching skills.\nThe dog enthusiastically catches the frisbee, bringing it back to the owner for another throw.\nA dog catches a frisbee that was thrown.\nKeyword\nroast stick marshmallow fire\nSentences\nA marshmallow is being roasted on a stick over a fire.\nPeople roast marshmallows on a stick over a fire.\nDuring a campfire, people often stick marshmallows on a stick and roast them over the fire.\nThe act of roasting marshmallows involves sticking them on a stick and holding them over a fire.\nPeople gather around a fire, roasting marshmallows on sticks.\nSticking a marshmallow on a stick and roasting it over a fire is a common activity.\nComVE\nStatement\nShe parachuted into the grocery store from a plane.\nExplanation\nParachuting is not a common method of entering a grocery store.\nGrocery stores do not have landing areas for parachutes.\nParachuting into a grocery store from a plane is highly unlikely and not a normal activity.\nStatement\nYou can drive after drinking.\nExplanation\nDrinking alcohol impairs your ability to drive, so it is not recommended.\nIt is illegal and unsafe to drive after drinking.\nDriving after drinking is dangerous and against the law.\nDimonGen\nKeyword\ncloud mountain\nSentences\nAs we climbed the mountain, the clouds grew thicker, obscuring our view.\nThe mountain stood tall and majestic, with clouds swirling around its peaks.\nThe mountain peak pierced through the clouds, reaching towards the sky.\nKeyword\nrace victory\nSentences\nThe underdog pulled off an unexpected victory in the race, leaving the favorite trailing behind.\nWith a burst of speed and determination, the runner sprinted towards the finish line, securing a triumphant victory.\nAfter a fierce race, the champion celebrated their victory with a crowd cheering and fireworks lighting up the sky.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/191f/191f4d57-c497-4610-a3b7-20d845fc2d6f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) Diversified instructions</div>\nFigure 5: The templates used by the default and the diversified prompt instructions for the CommonGen/DimonGen (shown on the left, (a)) and ComVE (shown on the right, (b)) tasks. Few-shot examples are included in each prompt where [SRC] denotes the set of input concepts and [TGT] the corresponding sentences in CommonGen. For a given set of [INPUT] concepts, the LLM is then required to generate sentences at the slot [OUTPUT].\n# Evaluate the sentence set\u2019s diversity\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/6037/6037ca37-7eb9-42b7-bb23-341f0f06ff05.png\" style=\"width: 50%;\"></div>\nFigure 6: The instructions provided to GPT3.5-turbo for predicting the diversity of a given set of sentences. Diversity is predicted according to five categories: very similar, somewhat similar, neutral, somewhat diverse, and highly diverse. Definitions of the categories are included within the instructions. Next, the set of sentences to be evaluated for their diversity is presented. Finally, the expected output format of the predictions is described at the end of the prompt. As recommended by Chen et al. (2023), we do not require the LLM to provide reasons for its predictions because it sometimes forces the model to focus on the reason generation than the prediction.\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of enhancing the diversity of Generative Commonsense Reasoning (GCR) outputs from Large Language Models (LLMs) while maintaining high quality, as existing methods have not systematically studied the diversity aspect in LLM outputs.",
        "problem": {
            "definition": "The problem is the lack of diversity in commonsense generation outputs from LLMs, which leads to dull, repetitive, or biased responses despite the quality being acceptable.",
            "key obstacle": "The main challenge is that existing methods to increase diversity often compromise the quality of the generated sentences or result in nonsensical outputs."
        },
        "idea": {
            "intuition": "The idea is inspired by the observation that while LLMs can generate high-quality sentences, their outputs often lack the necessary diversity to reflect a range of commonsense knowledge.",
            "opinion": "The proposed method, In-Context Diversification (ICD), aims to enhance the diversity of generated sentences by providing feedback to LLMs based on the diversity of previously generated sentences.",
            "innovation": "ICD innovates by using a two-step process to first generate sentences and then refine them based on diversity metrics, unlike existing methods that solely focus on quality or use simplistic diversity-enhancing techniques."
        },
        "method": {
            "method name": "In-Context Diversification",
            "method abbreviation": "ICD",
            "method definition": "ICD is a method that improves the diversity of sentence generation by leveraging in-context learning to guide LLMs in producing more varied outputs while maintaining coherence and commonsense.",
            "method description": "ICD operates in two steps: generating a set of sentences and then refining them based on their diversity.",
            "method steps": [
                "Step 1: Generate a set of sentences using a default prompt.",
                "Step 2: If diversity is low, provide feedback to the LLM to generate more diverse sentences considering the previously generated ones."
            ],
            "principle": "ICD is effective because it maintains a balance between quality and diversity through user-specific diversity metrics, allowing for nuanced control over the generation process."
        },
        "experiments": {
            "evaluation setting": "ICD was evaluated on three GCR tasks: CommonGen, ComVE, and DimonGen, using datasets that contain human-written reference sentences for comparison.",
            "evaluation method": "Performance was measured using various quality and diversity metrics, including BLEU, SPICE, BERTScore, self-BLEU, Distinct, and FBD, to assess the quality and diversity of the sentences generated."
        },
        "conclusion": "The experiments demonstrated that ICD significantly improves the diversity of commonsense generation outputs without substantially compromising quality, and the generated sentences can enhance the training of existing GCR models.",
        "discussion": {
            "advantage": "The key advantages of ICD include its ability to produce diverse and high-quality sentences, outperforming existing methods in both aspects.",
            "limitation": "A limitation of the study is that it primarily focuses on English language generation, which may not generalize to other languages or linguistic structures.",
            "future work": "Future research could explore expanding ICD to multilingual models and investigate the effects of different decoding strategies on diversity."
        },
        "other info": {
            "ethics": "The paper uses publicly available datasets for its experiments and does not foresee ethical issues, although it acknowledges the potential for LLMs to reflect societal biases.",
            "acknowledgements": "Danushka Bollegala holds concurrent appointments as a Professor at the University of Liverpool and as an Amazon Scholar."
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper addresses the issue of enhancing the diversity of Generative Commonsense Reasoning (GCR) outputs from Large Language Models (LLMs) while maintaining high quality."
        },
        {
            "section number": "1.2",
            "key information": "The lack of diversity in commonsense generation outputs from LLMs leads to dull, repetitive, or biased responses despite the quality being acceptable."
        },
        {
            "section number": "3.1",
            "key information": "The proposed method, In-Context Diversification (ICD), aims to enhance the diversity of generated sentences by providing feedback to LLMs based on the diversity of previously generated sentences."
        },
        {
            "section number": "3.3",
            "key information": "ICD operates in two steps: generating a set of sentences using a default prompt and refining them based on their diversity."
        },
        {
            "section number": "4.1",
            "key information": "ICD maintains a balance between quality and diversity through user-specific diversity metrics, allowing for nuanced control over the generation process."
        },
        {
            "section number": "6.1",
            "key information": "A limitation of the study is that it primarily focuses on English language generation, which may not generalize to other languages or linguistic structures."
        }
    ],
    "similarity_score": 0.6908994412085079,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2330_in-co/papers/Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning.json"
}