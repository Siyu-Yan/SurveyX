{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2310.00385",
    "title": "Dynamic Demonstrations Controller for In-Context Learning",
    "abstract": "In-context learning (ICL) is a new paradigm for natural language processing (NLP), where a large language model (LLM) observes a small number of demonstrations and a test instance as its input, and directly makes predictions without updating model parameters. Previous studies have revealed that ICL is sensitive to the selection and the ordering of demonstrations. However, there are few studies regarding the impact of the demonstration number on the ICL performance within a limited input length of LLM, because it is commonly believed that the number of demonstrations is positively correlated with model performance. In this paper, we found this conclusion does not always hold true. Through pilot experiments, we discover that increasing the number of demonstrations does not necessarily lead to improved performance. Building upon this insight, we propose a Dynamic Demonstrations Controller (D$^2$Controller), which can improve the ICL performance by adjusting the number of demonstrations dynamically. The experimental results show that D$^2$Controller yields a 4.6% relative improvement on ten different sizes of LLMs across ten datasets. Moreover, we also extend our method to previous ICL models and achieve competitive results.",
    "bib_name": "zhao2024dynamicdemonstrationscontrollerincontext",
    "md_text": "# D YNAMIC D EMONSTRATIONS C ONTROLLER FOR I N C ONTEXT L EARNING\n\nFei Zhao, Taotian Pang, Zhen Wu, Zheng Ma, Shujian Huang, Xinyu Dai National Key Laboratory for Novel Software Technology, Nanjing University {zhaof,pangtt,maz} @smail.nju.edu.cn {wuz,huangsj,daixinyu} @nju.edu.cn\n\nFei Zhao, Taotian Pang, Zhen Wu, Zheng Ma, Shujian Huang, Xinyu Dai National Key Laboratory for Novel Software Technology, Nanjing University {zhaof,pangtt,maz} @smail.nju.edu.cn {wuz,huangsj,daixinyu} @nju.edu.cn\n\n# A BSTRACT\n\nA BSTRACT\n\nIn-Context Learning (ICL) is a new paradigm for natural language processing (NLP), where a large language model (LLM) observes a small number of demonstrations and a test instance as its input, and directly makes predictions without updating model parameters. Previous studies have revealed that ICL is sensitive to the selection and the ordering of demonstrations. However, there are few studies regarding the impact of the demonstration number on the ICL performance within a limited input length of LLM, because it is commonly believed that the number of demonstrations is positively correlated with model performance. In this paper, we found this conclusion does not always hold true. Through pilot experiments, we discover that increasing the number of demonstrations does not necessarily lead to improved performance. Building upon this insight, we propose a D ynamic D emonstrations Controller (D 2 Controller), which can improve the ICL performance by adjusting the number of demonstrations dynamically. The experimental results show that D 2 Controller yields a 5.4% relative improvement on eight different sizes of LLMs across ten datasets. Moreover, we also extend our method to previous ICL models and achieve competitive results 1.\n\n# I NTRODUCTION\n\nIn-Context Learning (ICL) is a new paradigm for performing various NLP tasks using large language models (LLMs) (Brown et al., 2020). In ICL, by conditioning on a small number of demonstrations, LLMs can generate predictions for a given test input without updating model parameters. Restricted by the maximum input length of LLMs, it is common to sample a small set of examples from the training dataset randomly to formulate demonstrations. Figure 1 shows an example of sentiment analysis using ICL.\nTo improve the performance of ICL, existing work primarily focuses on designing Demonstration Selection methods (Liu et al., 2022a; Rubin et al., 2022; Zhang et al., 2022b; Kim et al., 2022; Gonen et al., 2022; Sorensen et al., 2022; Wang et al., 2023; Li et al., 2023; Li & Qiu, 2023) or finding an appropriate Demonstration Ordering (Lu et al., 2022; Wu et al., 2022), since a lot of studies have revealed that ICL is sensitive to the selection as well as the ordering of demonstrations (Liu et al., 2022a; Rubin et al., 2022; Zhang et al., 2022b; Lu et al., 2022; Wu et al., 2022; Li et al., 2023; Li & Qiu, 2023; Dong et al., 2022).\nHowever, to the best of our knowledge, there are few studies available regarding the impact of the Demonstration Number  on the ICL performance. This scarcity may be attributed to the prevailing belief that the relation between the number of demonstrations and model performance follows a power law \u2013 as the number of demonstrations increases, model performance continues to improve (Xie et al., 2022; Xu et al., 2023). Nevertheless, through pilot experiments, we find this conclusion does not always hold true. Specifically, within the constraints of input length in LLMs, we systematically evaluate model performance across a spectrum ranging from the minimum to the maximum number of demonstrations. This comprehensive assessment involves five different datasets and encompasses five sizes of LLMs (Brown et al., 2020; Zhang et al., 2022a; Dey et al., 2023). Our findings reveal that:\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/170d/170d2f8c-d904-4368-a7c3-498b00d8d55c.png\" style=\"width: 50%;\"></div>\n\u2022 As more demonstrations are incorporated into the model input, the changes of the performance across different datasets on the same model tend to be inconsistent, with some datasets showing improvements while others experiencing declines. Similarly, the performance of different models on the same dataset also rises or falls. This suggests that increasing the number of demonstrations does not necessarily improve performance.\n\u2022 During the transition from minimum to maximum number of demonstrations, the number of demonstrations needed for the same model to attain the optimal performance varies across different datasets. Likewise, different models exhibit variations in the number of demonstrations required to reach the optimal performance on the same dataset. This suggests that the optimal number of demonstrations may differ depending on the specific dataset and model combination.\n\nBased on the above observation, we can infer that it is necessary to dynamically select an appropriate demonstration number for different datasets and models. Doing so not only boosts ICL performance but also can help in saving time and space during the inference of LLMs. To achieve this goal, we propose a D ynamic D emonstrations Controller (D 2 Controller), the core idea of which involves comparing the prediction accuracy of different demonstration numbers on a small set of specially selected evaluation examples. The key challenge of this idea is determining which evaluation examples should be chosen to provide a correct assessment for different demonstration numbers. To tackle this challenge, we design a metric named I ntraI nterC lass Score (IICScore) to guide the D 2 Controller to select suitable evaluation examples from the training dataset. Finally, we apply D 2 Controller to eight different sizes of LLMs and achieve a 5.4% relative improvement over ten datasets. Besides, we also extend our method to previous ICL models and achieve competitive results.\nOur contributions are summarized as follows: (1) We comprehensively analyze the effects of the number of demonstrations on ICL performance under a limited input length of LLM, and find that the number of demonstrations may not necessarily be positively correlated with model performance; (2) We propose a method named D 2 Controller, which not only boosts ICL performance but also saves time and space during inference of the LLMs; (3) We apply our method to eight different sizes of LLMs and realize an average of 5.4% relative improvement across ten datasets. Moreover, we also extend our method to previous ICL models and yield competitive results.\n\n# 2 B ACKGROUND\n\nIn this section, we review the definition of In-Context Learning and the k-shot setting.\n\nNotation We use \u03b8 to denote an LLM. The training dataset is denoted as D. A training example (x i, y i) consists of a sentence x i and a label y i. The sentence of a training example is also referred to as an instance. We use I D = {x i} |D| i =1 to represent all instances of training examples in D. The label space is denoted as Y. In this paper, we focus on ICL for text classification tasks. Each training example belongs to a certain class. The set of classes is represented as C and a class c \u2208C  has a oneto-one correspondence with a label y c \u2208Y, i.e., |Y| = |C|. For example, the label \u201cnot entailment\u201d corresponds to the class in which premise sentences do not entail hypothesis sentences.\n\nGiven an LLM \u03b8, a group of n in-context examples {x i, y i} n i =1 sampled from training dataset D (In general, n \u226a|D|), and a test instance x test, ICL first formulates in-context examples in the\n\n# ormat of the input-label pairs which are named the demonstrations (See Appendix A for details) via templates, and then concatenates them together along with a test input to construct a prompt P:\n\nwhere \u2126(\u00b7, \u00b7) denotes template-based transformation and \u2295 means concatenation operation. Notice that there is a verbalization process \u03c0 (\u00b7) inside \u2126(\u00b7, \u00b7), which maps the label y i to a token v i in the LLM vocabulary. The y i and v i can be different. For example, the label \u201cnot entailment\u201d can be mapped to the token \u201cfalse\u201d. We denote the mapping token space as V and we have |Y| = |V| (See Appendix A for details). Finally, The prompt P is fed into the LLM \u03b8 to predict the label of the test instance x test:\n\nwhere \u03c0 (\u00b7) \u2212 1 denotes the inverse mapping from the token v i to the label y i.\n\nwhere \u03c0 (\u00b7) \u2212 1 denotes the inverse mapping from the token v i to the label y\n\n2.2 k SHOT S ETTING\n\nFor text classification tasks, each prompt P is formulated in the class balance way, i.e., the demonstrations of each class are contained in a prompt P and the numbers of them are the same 2. Among them, the number of demonstrations of each class is also called the shot number, denoted as k. Based on this, the k-shot setting means a prompt P contains k demonstrations for each class. In other words, the total demonstration number n of each prompt P is equal to k |C|. In this paper, we vary the number of demonstrations n by changing the k-shot setting.\nDue to the input length limitation of LLMs, there exists a maximum k, denoted as k max, for every dataset. All feasible choices of k for a dataset form a set K = {1, 2, \u00b7 \u00b7 \u00b7, k max} (Appendix B provides the calculation method for k max and the value of k max for each dataset).\n\n# 3 P ILOT E XPERIMENTS\n\nIn this section, we conduct pilot studies to answer the following research question: Does mod performance consistently improve when more demonstrations are added to prompts?\n\nExperimental Setup We conduct pilot experiments across five text classification datasets on five different sizes of LLMs, including two Cerebras-GPT models (Dey et al., 2023) (with 2.7B and 6.7B parameters), two OPT models (Zhang et al., 2022a) (with 13B and 30B parameters) and a GPT-3 model (Brown et al., 2020) (with 175B parameters). We adopt Accuracy as the evaluation metric for model performance (Lu et al., 2022; Zhang et al., 2022b). Following (Lu et al., 2022; Xu et al., 2023), we randomly sample 256 examples from the validation set for each dataset to evaluate the accuracy and report the average performance and standard deviation based on 5 different seeds.\nFor each dataset, we iteratively test the model performance from 1-shot setting to k max-shot setting on five sizes of LLMs. Figure 2 and Figure 3 show the performance curves of five datasets on Cerebras-GPT 6.7B model and GPT-3 175B model, respectively. Figure 4 shows performance curves of the SST5 dataset on five different sizes of LLMs. More results are provided in Appendix C. Based on these results, we find that:\nIncreasing the number of demonstrations does not necessarily improve the model performance. In Figure 2, we can see that when more demonstrations are added to prompts, i.e., the shot number is increased, the model performance goes up or down on five different datasets. From a local point of view, when changing from an 8-shot setting to a 16-shot setting on the MPQA dataset, the model performance increases from 71. 5 to 83. 1, while the accuracy drops to 79. 8 with a 32-shot setting. Likewise, on the CB dataset, the accuracy declines when shifting from a 2-shot setting to a 4-shot setting. Furthermore, when providing more demonstrations on the SST-5 dataset, the model\u2019s performance consistently decreases. From the perspective of a general trend, the accuracy improves on the MPQA dataset while declines on the CB and SST-5 datasets. Similar observations can be found in the results of the GPT-3 175B model, shown in Figure 3. Besides, the performance of\n\nExperimental Setup We conduct pilot experiments across five text classification datasets on five different sizes of LLMs, including two Cerebras-GPT models (Dey et al., 2023) (with 2.7B and 6.7B parameters), two OPT models (Zhang et al., 2022a) (with 13B and 30B parameters) and a GPT-3 model (Brown et al., 2020) (with 175B parameters). We adopt Accuracy as the evaluation metric for model performance (Lu et al., 2022; Zhang et al., 2022b). Following (Lu et al., 2022; Xu et al., 2023), we randomly sample 256 examples from the validation set for each dataset to evaluate the accuracy and report the average performance and standard deviation based on 5 different seeds.\nFor each dataset, we iteratively test the model performance from 1-shot setting to k max-shot setting on five sizes of LLMs. Figure 2 and Figure 3 show the performance curves of five datasets on Cerebras-GPT 6.7B model and GPT-3 175B model, respectively. Figure 4 shows performance curves of the SST5 dataset on five different sizes of LLMs. More results are provided in Appendix C. Based on these results, we find that:\n\non Cerebras-GPT 6.7B model and GPT-3 175B model, respectively. Figure 4 shows performance curves of the SST5 dataset on five different sizes of LLMs. More results are provided in Appendix C. Based on these results, we find that:\nIncreasing the number of demonstrations does not necessarily improve the model performance. In Figure 2, we can see that when more demonstrations are added to prompts, i.e., the shot number is increased, the model performance goes up or down on five different datasets. From a local point of view, when changing from an 8-shot setting to a 16-shot setting on the MPQA dataset, the model performance increases from 71. 5 to 83. 1, while the accuracy drops to 79. 8 with a 32-shot setting. Likewise, on the CB dataset, the accuracy declines when shifting from a 2-shot setting to a 4-shot setting. Furthermore, when providing more demonstrations on the SST-5 dataset, the model\u2019s performance consistently decreases. From the perspective of a general trend, the accuracy improves on the MPQA dataset while declines on the CB and SST-5 datasets. Similar observations can be found in the results of the GPT-3 175B model, shown in Figure 3. Besides, the performance of\n\nIncreasing the number of demonstrations does not necessarily improve the model performance. In Figure 2, we can see that when more demonstrations are added to prompts, i.e., the shot number is increased, the model performance goes up or down on five different datasets. From a local point of view, when changing from an 8-shot setting to a 16-shot setting on the MPQA dataset, the model performance increases from 71. 5 to 83. 1, while the accuracy drops to 79. 8 with a 32-shot setting. Likewise, on the CB dataset, the accuracy declines when shifting from a 2-shot setting to a 4-shot setting. Furthermore, when providing more demonstrations on the SST-5 dataset, the model\u2019s performance consistently decreases. From the perspective of a general trend, the accuracy improves on the MPQA dataset while declines on the CB and SST-5 datasets. Similar observations can be found in the results of the GPT-3 175B model, shown in Figure 3. Besides, the performance of\n\n2 For example, in a 2-class sentiment analysis task, a prompt P contains demonstrations from both th positive sentiment class and the negative sentiment class.\n\n(1)\n\n(2)\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/349f/349f2134-9396-4586-a2df-15102bde0171.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a08b/a08b1d2a-2d96-4c0a-9a6b-c851c0565f62.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: Effect of the demonstrations number on CerebrasGPT-6.7B across five datasets.\n</div>\n<div style=\"text-align: center;\">Figure 3: Effect of the number of demonstrations on GPT-3 175B across five datasets.\n</div>\ndifferent models on the same dataset also rises or falls. As shown in Figure 4, when changing from a 1-shot setting to a 8-shot setting, the accuracy of the SST5 dataset on the OPT-13B model continues to decrease, while that on the GPT-3-175B model keeps rising. These observations indicate that the inclusion of more demonstrations does not guarantee improved performance.\n\nThe optimal k-shot setting differs depending on specific datasets and models. Here we define the k-shot setting under which a dataset acquires the highest accuracy as the optimal k-shot setting. From Figure 3, we can tell that the optimal k-shot setting for each dataset is different: 2-shot setting for CR and CB datasets, 8-shot setting for RTE and SST5 dataset and 32-shot setting for MPAQ dataset. Jointly observing Figure 2 and Figure 3, we find that the optimal k-shot settings for the same dataset on different models can be different. The curves in Figure 4 further support this finding.\nFrom the above analysis, we can infer that to achieve better performance in ICL, it is not appropriate to simply use the k max-shot setting for each dataset or the same k-shot setting for all datasets. The latter is a strategy widely adopted in previous work (Lu et al., 2022; Xu et al., 2023). Instead, we should dynamically decide k-shot settings for ICL depending on specific datasets and models.\n\n# 4 M ETHODOLOGY\n\nBased on the observations of the pilot study, we propose a D ynamic D emonstrations Controller (D 2 Controller), which dynamically finds a suitable k from the feasible shot numbers set K for each dataset. An intuitive way to decide an appropriate k for a specific dataset is to compare the average prediction accuracy of different k-shot settings on a set of evaluation examples and make a choice. The key challenge of such idea lies in that on which evaluation examples we can obtain the proper evaluation for each k-shot setting.\nTo tackle the above challenge, we propose a metric named I ntraI nterC lass Score (IICScore) to guide us to choose the representative evaluation examples for each group of in-context examples from the training dataset. The whole process to evaluate each k-shot setting is divided into three steps: (1) In-context examples sampling. (2) IICScore-guided evaluation examples selection. (3) Accuracy-based evaluation. The workflow of D 2 Controller is illustrated in Figure 5.\n\n# 4.1 I N CONTEXT E XAMPLES S AMPLING\n\nFor each k-shot setting, we sample N s groups of in-context examples to evaluate, where N s is th number of in-context example groups. Each group of in-context examples is denoted as:\n\nE {| \u00b7 \u00b7 \u00b7|C|} \u00b7 \u00b7 \u00b7\nwhere k denotes the k-shot setting. All in-context examples are removed from training set D and the remaining ones formulate the candidate set for evaluation examples, denoted as D \u2032.\n\nIn traditional machine learning, there are two dimensions to assess the ability of a model: the fit ability and the generalization ability, which corresponds to how well a model can capture patterns\n\n<div style=\"text-align: center;\">Figure 4: The accuracy of five different sizes of LLMs on the SST5 dataset.\n</div>\n(3)\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/9d05/9d05e6c4-2af2-40fb-946b-fd6abbf3463f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 5: The whole process of the D 2 Controller on a 2-class classification task.\n</div>\nin training data and deal with unseen data, respectively. Inspired by such a point of view, to comprehensively evaluate a group of in-context examples, we select similar examples (which are analogous to training-data patterns) and dissimilar examples (which are analogous to unseen data) to each class of them from the training dataset as evaluation examples. To measure similarities, we transform each sentence x to a vector representation x, which essentially is a language modeling distribution, by querying LLMs with x and obtaining the output.\nWhen searching similar examples for classc in-context examples, we expect them to be not only close to the in-context examples of class c, but also far from those of other classes. To this end, we propose IICScore, which considers both intra-class distance and inter-class distance, to guide our selection procedure. IICScore is defined as:\n\nwhere e c j = (x c j, y c) \u2208D \u2032 is a candidate example of class c, x c j denotes the vector representation of instance x c j, I E k i denotes the set of all instances in E k i, \u00af x c I E k i is the average representation of classc\ninstances in I E k i, D \u2032 c \u2032  means the set of classc \u2032 candidate examples, and KL (\u00b7, \u00b7)  is the KL diver\ngence. The |D \u2032 c \u2032 |\n|D \u2032 | is a scale factor that balances the contribution of intra-class distance and inter-class distance. Given that the x c j is a distribution, we choose KL divergence to measure distances. The higher the IICScore is, the more similar that candidate example e c j is to classc in-context examples. For each group E k i, the example with the highest IICScore in each class is selected as follows:\n\nIn total, |C| similar examples are selected for each E i.\nThere is no need to identify dissimilar examples, however, as they have already been obtained when selecting similar examples: For any two different groups of in-context examples E k i and E k j, their similar examples are different. Then the similar example \u02dc e c E k j is naturally a dissimilar example for\nE k i. Gathering all N s |C| similar examples to form the set of evaluation examples T k, there are |C| similar examples and (N s \u2212 1) |C| less similar examples for each group of in-context examples.\n\nIn the last stage, each group of in-context examples is transformed into demonstrations and each instance of evaluation examples in T k is transformed into a test input. Then we iteratively concatenate demonstrations with every test input to create prompts (As shown in Equation 1). After that, the prompts are fed into LLMs to get predictions. The average prediction accuracy of N s group of\n\n(5)\n\ndemonstrations is treated as the performance of k-shot setting:\n\nwhere \u02c6 y j, E k i means the predicted label of j-th example in T k using demonstrations transformed from E k i and I is the indicator function. After testing the performance of all feasible k-shot settings, we choose the one with the best performance as follows:\n\nThe algorithm details of the D 2 Controller are presented in Appendix D. It is worth mentioning that our approach is model-agnostic, allowing it to be combined with LLMs of different sizes and applied to previous ICL methods.\n\n# 5 E XPERIMENTS\n\n# 5.1 S ETUP\n\nDatasets We conduct experiments on ten text classification datasets ranging from sentiment classification to textual entailment, including SST-2 (Socher et al., 2013), SST-5 (Socher et al., 2013), DBPedia (Zhang et al., 2015), MR (Pang & Lee, 2005), CR (Hu & Liu, 2004),\u2018 MPQA (Wiebe et al., 2005), Subj (Pang & Lee, 2004), AGNews (Zhang et al., 2015), RTE (Dagan et al., 2005), and CB (De Marneffe et al., 2019). More details of the datasets are provided in Appendix B.\nLLMs To verify the effectiveness of D 2 Controller, we apply our method to a wide range of LLMs, including three GPT-2 models (Radford et al., 2019) (with 0.3B, 0.8B, and 1.5B parameters), two Cerebras-GPT models (Dey et al., 2023) (with 2.7B and 6.7B parameters), two OPT models (Zhang et al., 2022a) (with 13B and 30B parameters) and GPT-3 175B model (Brown et al., 2020).\nEvaluation Metric Following (Lu et al., 2022; Xu et al., 2023), to control the GPT-3 inference costs 3, we randomly sample 256 examples from the validation set for each dataset to evaluate the accuracy and report the average performance and standard deviation over 5 different seeds.\nImplementation Details For D 2 Controller, K is set as {1, 2, 4, 8, \u00b7 \u00b7 \u00b7, k max} (See Appendix B for details of k max of each dataset on different sizes of LLMs). We sample N s = 5 groups of in-context examples for k-shot setting evaluation on Cerebras-GPT-2.7B model, and set N s as 25 on other sizes of LLMs, the reason of which is presented in the Section 5.4.2. We implement our method with the PyTorch framework and run experiments on 8 NVIDIA A100 GPUs.\n\n# 5.2 B ASE M ODEL AND O RACLE\n\nWe consider the default k-shot setting in previous work (Lu et al., 2022; Xu et al., 2023) as our base model, which is: the 4-shot settting for most of the datasets except the 1-shot setting for the DBpedia dataset and the 2-shot setting for the AGNews dataset. In addition, we also provide an Oracle to show the upper bound of performance, that is, for each dataset, we iterate all feasible k-shot settings on 256 examples (mentioned in Evaluation Metric) and record the highest achievable performance.\n\n# 5.3 M AIN R ESULTS\n\nThe main experiment results are shown in Table 1, from which we have following findings:\n\nD 2 Controller is effective for selecting suitable k-shot setting for each dataset and is compatible with different LLMs. In comparison to the base model, D 2 Controller achieves 5.4% relative improvements on average across ten datasets, which validates the rationality of dynamically selecting\n3 It requires the usage of a monetary paid-for API.\n\n3 It requires the usage of a monetary paid-for API.\n\n(7)\n\n<div style=\"text-align: center;\">Table 1: Main results of our methods on eight sizes of LLMs across ten datasets. We report the average performance and standard deviation over 5 different seeds for each dataset. The last column represents the average result across the ten datasets. AVG is short for Average.\n</div>\nSST-2\nSST-5\nDBPedia\nMR\nCR\nMPQA\nSubj\nAGNews\nRTE\nCB\nAVG\nGPT-2\n0.3B\nDefault\n58.113.1\n24.17.4\n60.67.2\n54.210.6\n50.60.4\n59.615.8\n53.45.3\n48.78.5\n51.31.7\n48.66.4\n50.9\nD2Controller\n74.19.3\n31.68.6\n60.67.2\n53.87.0\n67.711.4\n57.19.7\n53.84.2\n48.78.5\n48.72.9\n48.66.4\n54.5\nOracle\n74.19.3\n31.68.6\n60.67.2\n56.09.9\n67.711.4\n64.516.0\n58.612.8\n49.418.4\n51.31.7\n50.09.2\n56.4\nGPT-2\n0.8B\nDefault\n71.812.1\n37.86.8\n63.46.0\n71.115.6\n80.511.4\n65.811.3\n59.912.2\n65.617.2\n53.13.4\n37.114.5\n60.6\nD2Controller\n65.915.2\n37.55.1\n63.46.0\n71.115.6\n80.511.4\n70.55.2\n69.412.4\n65.617.2\n53.13.4\n47.53.2\n62.4\nOracle\n71.812.1\n39.65.1\n63.46.0\n71.115.6\n80.511.4\n74.58.8\n69.412.4\n65.617.2\n53.84.4\n49.33.7\n63.9\nGPT-2\n1.5B\nDefault\n70.36.6\n35.48.4\n82.02.0\n52.03.8\n52.03.2\n66.78.2\n57.310.5\n78.26.7\n53.11.7\n52.96.3\n60.0\nD2Controller\n81.35.4\n35.48.4\n82.02.0\n72.213.9\n66.216.7\n83.91.5\n64.111.3\n78.26.7\n53.12.9\n52.96.3\n67.0\nOracle\n81.35.4\n40.65.4\n82.02.0\n72.213.9\n66.216.7\n83.91.5\n64.111.3\n81.37.5\n53.12.9\n57.99.8\n68.2\nCerebras-GPT\n2.7B\nDefault\n65.513.8\n28.44.3\n81.81.4\n65.111.2\n85.84.2\n64.211.6\n69.314.4\n69.53.2\n48.11.1\n52.59.5\n63.0\nD2Controller\n77.37.7\n34.34.8\n81.81.4\n76.07.7\n87.41.5\n81.62.1\n74.27.6\n77.34.1\n48.01.1\n54.62.7\n69.3\nOracle\n80.79.1\n34.34.8\n81.81.4\n76.07.7\n87.41.5\n82.93.0\n74.27.6\n77.34.1\n49.62.3\n55.75.0\n70.0\nCerebras-GPT\n6.7B\nDefault\n83.48.5\n38.31.8\n87.02.4\n88.01.1\n89.03.1\n75.210.3\n72.014.5\n79.22.4\n52.32.3\n52.58.0\n71.7\nD2Controller\n82.011.3\n39.53.7\n87.02.4\n86.81.9\n90.50.9\n83.83.3\n79.212.5\n80.21.5\n52.82.5\n57.97.2\n74.0\nOracle\n88.62.7\n43.61.6\n87.02.4\n88.01.1\n90.62.8\n83.83.3\n79.212.5\n80.21.5\n53.41.7\n57.93.0\n75.2\nOPT\n13B\nDefault\n81.26.7\n43.34.6\n92.32.1\n87.82.7\n91.43.3\n75.06.7\n79.112.7\n81.92.9\n54.44.2\n58.98.1\n74.5\nD2Controller\n90.25.8\n43.34.6\n92.32.1\n87.82.7\n91.32.1\n72.09.4\n91.62.0\n82.61.5\n55.83.1\n58.98.1\n76.6\nOracle\n90.93.7\n48.02.8\n92.32.1\n91.80.6\n93.31.2\n78.67.3\n91.62.0\n82.61.5\n55.83.1\n73.212.4\n79.8\nOPT\n30B\nDefault\n92.31.3\n40.91.8\n91.73.7\n91.82.1\n87.33.3\n78.86.2\n76.14.9\n78.73.6\n63.03.1\n60.08.2\n76.1\nD2Controller\n92.31.3\n42.02.8\n91.73.7\n93.41.1\n87.32.7\n85.73.8\n83.48.6\n76.74.5\n61.62.8\n60.08.2\n77.4\nOracle\n92.81.6\n45.23.1\n91.73.7\n93.41.1\n87.73.9\n85.73.8\n83.48.6\n78.73.6\n63.03.1\n60.08.2\n78.1\nGPT-3\n175B\nDefault\n94.01.4\n47.70.6\n90.22.8\n94.10.6\n91.40.0\n84.40.6\n71.12.2\n86.91.4\n60.45.3\n70.513.9\n79.1\nD2Controller\n94.01.4\n48.40.6\n90.22.8\n95.50.8\n93.02.3\n84.40.6\n87.34.7\n86.91.4\n66.63.0\n73.22.5\n82.0\nOracle\n94.10.0\n48.40.6\n90.22.8\n95.50.3\n93.62.8\n86.52.5\n87.34.7\n86.91.4\n69.71.4\n73.22.5\n82.6\nthe number of demonstrations 4. It is worth mentioning that, in contrast to other LLMs, D 2 Controller at most obtains 7.0% and 6.3% improvements in accuracy for GPT-2-1.5B and Cerebras-GPT-2.7B on ten datasets. These results reveal that our method has good compatibility. Some LLMs exhibit a minor decline in performance on the MPQA, SST-2, and MR datasets. One possible reason is that these datasets have relatively shorter average demonstration lengths (shown in Table 6), and they contain fewer crucial features related to classification. Therefore, selecting an appropriate demonstration number for these datasets may be more challenging.\nD 2 Controller achieves near-optimal results at a lower cost. In most LLMs, our approach achieves performance levels close to that of the Oracle, aligning with our original research intent. While the Oracle represents the upper bound of performance, it is unfeasible in practice to iterate through all k-shot settings on large-scale examples to attain such performance, mainly due to the extensive resource and time demands. In contrast, our method achieves good performance with a small number of evaluation examples and effectively controls inference costs. Our approach underscores the practical feasibility of striking a balance between performance and resource consumption, which is a crucial aspect for a wide range of real-world applications.\n\nthe number of demonstrations 4. It is worth mentioning that, in contrast to other LLMs, D 2 Controller at most obtains 7.0% and 6.3% improvements in accuracy for GPT-2-1.5B and Cerebras-GPT-2.7B on ten datasets. These results reveal that our method has good compatibility. Some LLMs exhibit a minor decline in performance on the MPQA, SST-2, and MR datasets. One possible reason is that these datasets have relatively shorter average demonstration lengths (shown in Table 6), and they contain fewer crucial features related to classification. Therefore, selecting an appropriate demonstration number for these datasets may be more challenging.\n\nD 2 Controller achieves near-optimal results at a lower cost. In most LLMs, our approach achieves performance levels close to that of the Oracle, aligning with our original research intent. While the Oracle represents the upper bound of performance, it is unfeasible in practice to iterate through all k-shot settings on large-scale examples to attain such performance, mainly due to the extensive resource and time demands. In contrast, our method achieves good performance with a small number of evaluation examples and effectively controls inference costs. Our approach underscores the practical feasibility of striking a balance between performance and resource consumption, which is a crucial aspect for a wide range of real-world applications.\n\n# 5.4 A NALYSIS AND D ISCUSSION\n\nIn this section, we conduct a series of analysis experiments related to D 2 Controller. It should noted that the results we report are the average performance of ten datasets.\n\nHere we extend our method to some representative ICL methods, i.e., applying the number of demonstrations decided by D 2 Controller to other ICL methods. These methods include a  Demonstration Selection method KATE (Liu et al., 2022b), a Demonstration Order method GlobalE (Lu et al., 2022), and two Calibration-based method Contextual Calibration (Zhao et al., 2021) and the k NN Prompting (Xu et al., 2023). The results are shown in Table 2.\nAs we can see, incorporating D 2 Controller into other ICL methods can obtain competitive performance. To be specific, compared to KATE using the default k-shot settings (As mentioned in Section 5.2), KATE + D 2 Controller at most obtains 3.1% improvements in terms of accuracy. Similarly,\n4 The values of k chosen by the D 2 Controller and Oracle are provided in Appendix E.\n\n<div style=\"text-align: center;\">Table 2: The result of extending D 2 Controller to other ICL models.\n</div>\nGPT-2 0.3B\nGPT-2 0.8B\nGPT-2 1.5B\nCerebras-GPT 2.7B\nCerebras-GPT 6.7B\nKATE\n66.7\n69.4\n67.7\n71.6\n77.6\n+ D2Controller\n68.8\n70.5\n69.4\n74.7\n77.9\nGlobalE\n59.5\n67.7\n69.8\n-\n-\n+ D2Controller\n61.5\n68.7\n71.6\n-\n-\nContextual Calibration\n59.5\n64.2\n63.9\n67.2\n72.5\n+ D2Controller\n60.8\n66.6\n65.4\n68.7\n73.5\nkNN Prompting\n74.8\n76.0\n77.3\n77.8\n79.0\n+ D2Controllern\n75.8\n77.1\n78.2\n78.1\n79.7\nGlobalE + D 2 Controller improves the accuracy by up to 2.0% compared to GlobalE. For Contextual Calibration and k NN Prompting, when combined with D 2 Controller, the accuracy is improved by up to 2.4% and 1.1% respectively. The improvements of these extending methods further confirm the necessity to dynamically decide k-shot settings instead of using the default setting as well as indicate that the D 2 Controller has excellent generalization capabilities. Moreover, the improvements in KATE + D 2 Controller and GlobalE + D 2 Controller prove that the number of demonstrations is a critical factor in ICL performance along with the selection and ordering of demonstrations.\n\nTo investigate the effect of the number of in-context example groups N s on D 2 Controller, we vary the value of N s in the range of [5, 30] with a step size of 5. Figure 6 shows the average performance of D 2 Controller with different N s on ten datasets. Actually, the majority of LLMs can achieve good results at N s = 5, and their performance remains stable as the number of in-context example groups increases. For the other LLMs, their performance has an initial upward trend and then flattens out. These observations indicate that D 2 Controller can select near-optimal k-shot settings depending on a small number of in-context example groups. Finally, according to the trend of the curve, we set N s  to 5 in the CerebrasGPT-2.7B model and set N s as 25 in other sizes of LLMs.\n5.4.3 T E IICS\n\n5.4.3 T HE E FFECTIVENESS OF IICS CORE\n\nIn D 2 Controller, we use IICScore to select evaluation examples. Here, we also explore other ways to select evaluation examples. As shown in Table 3, Random denotes randomly selecting the same number of examples as that of IICScore. D 2 Controller-ED and D 2 Controller-Cos  indicate replacing KL divergence in Equation 4 with Euclidean distance and negative cosine similarity, respectively. It is clear that D 2 Controller outperforms Random in every LLM, which suggests that the evaluation examples selected by D 2 Controller are more representative than those of Random to properly reflect the performance of each k-shot setting. Comparing D 2 Controller with the two variants, we can find that both of the variants perform worse than D 2 Controller on most of the LLMs (except for GPT-2-0.3B), which verifies the superiority of using KL divergence as the distance metric.\n\n5.4.4 D YNAMIC k v.s. M AXIMUM k\n\nWe also compare dynamically selecting the k-shot setting (i.e., D 2 Controller) with using the maximum number of demonstrations (i.e., k max-shot setting). As shown in Table 4, we observe that our method achieves more competitive results, which agree with our motivation mentioned in Section 3. Specifically, in contrast to the k max-shot setting, our approach achieves a 3.0% relative improvement across five different sizes of LLMs on ten datasets, indicating that adopting the k max-shot setting for each dataset is not appropriate. It is crucial to mention that the performance of D 2 Controller is improved by up to 3.7% and 3.3% on the GPT-2-0.8B model and the Cerebras-GPT-2.7B model\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/4eca/4ecaad71-1717-4126-bfff-d0e96386e695.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 6: The impact of the number of in-context example groups N s on D 2 Controller.\n</div>\nFigure 6: The impact of the number of in-context example groups N s on D 2 Controller.\n\n<div style=\"text-align: center;\">Table 3: The results of using three other ways to select evaluation examples.\n</div>\nGPT-2 0.3B\nGPT-2 0.8B\nGPT-2 1.5B\nCerebras-GPT 2.7B\nCerebras-GPT 6.7B\nRandom\n54.1\n59.2\n63.5\n68.0\n72.9\nD2Controller-ED\n54.4\n59.2\n64.0\n67.1\n72.6\nD2Controller-Cos\n54.9\n59.3\n62.2\n68.3\n72.4\nD2Controller\n54.5\n62.4\n66.9\n69.3\n74.0\n<div style=\"text-align: center;\">Table 4: The results of D 2 Controller and using the maximum number of demonstrations (i.e., k max shot setting) for each dataset.\n</div>\nGPT-2 0.3B\nGPT-2 0.8B\nGPT-2 1.5B\nCerebras-GPT 2.7B\nCerebras-GPT 6.7B\nkmax-shot setting\n54.1\n58.7\n66.0\n65.4\n73.0\nD2Controller\n54.5\n62.4\n67.0\n68.7\n74.0\ncompared to other LLMs. These results further highlight the superiority of dynamic demonstr tion selection. In addition, our approach achieves better performance with fewer demonstration compared to utilizing the maximum number of demonstrations. This underscores that D 2 Controll economizes both time and space during the inference of LLMs from another perspective.\n\n# 6 R ELATED W ORK\n\nWith the increase in both model size and training corpus size (Devlin et al., 2019; Radford et al., 2019; Brown et al., 2020; Chowdhery et al., 2022), large language models (LLMs) show a capacity for In-Context Learning (ICL). Given that ICL is sensitive to the selection and the order of the demonstrations (Liu et al., 2022a; Rubin et al., 2022; Zhang et al., 2022b; Lu et al., 2022; Wang et al., 2023; Wu et al., 2022; Li et al., 2023; Li & Qiu, 2023; Li et al., 2023), their works can be roughly divided into two categories:\n(1) Demonstration Selection. Liu et al. (2022a) propose to retrieve in-context examples that are semantically similar to a test example to formulate its corresponding prompt. Rubin et al. (2022) first label training examples as positive or negative, and then train an efficient dense retriever using this data, which is used to retrieve training examples as prompts at test time. Zhang et al. (2022b) formulate the problem as a sequential decision problem, and propose a reinforcement learning algorithm for identifying generalizable policies to select demonstrations. Li & Qiu (2023) propose to find supporting examples for ICL. Specifically, they design a two-stage method to filter and search demonstrations from training data.\n(2) Demonstration Ordering. Lu et al. (2022) study order sensitivity for ICL and propose a simple, generation-based probing method to identify performant prompts. Wu et al. (2022) propose the self-adaption mechanism to help each input find a demonstration organization (i.e., selection and permutation) that can derive the correct output, thus maximizing performance.\nHowever, there are few studies related to the impact of the number of demonstrations within a limited input length on ICL performance. The closest work to ours is Xu et al. (2023), which proposes a method that utilizes an unlimited number of training examples for model calibration, while our research focuses on how to select an appropriate number of demonstrations for each dataset when the input length is restricted. Therefore, the two methods have different starting points.\n\n# 7 C ONCLUSION\n\nIn this paper, we conduct an in-depth analysis of the impact of the number of demonstrations on ICL performance within a limited input length of LLM. Surprisingly, we discover that the number of demonstrations does not always exhibit a positive correlation with model performance. Based on these analyses, we propose a method named D 2 Controller, which can improve the ICL performance by dynamically adjusting the number of demonstrations. The experimental results show our method achieves an average of 5.4% relative improvement across ten datasets on eight different sizes of LLMs. Further analysis verifies the effectiveness of our method.\n\n# R EFERENCES\n\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In Hugo Larochelle, Marc\u2019Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.),  Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020. URL https: //proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways. CoRR, abs/2204.02311, 2022. doi: 10.48550/arXiv.2204.02311. URL https://doi.org/10.48550/arXiv.2204.02311.\nIdo Dagan, Oren Glickman, and Bernardo Magnini. The PASCAL recognising textual entailment challenge. In Joaquin Qui\u02dcnonero Candela, Ido Dagan, Bernardo Magnini, and Florence d\u2019Alch\u00b4e-Buc (eds.), Machine Learning Challenges, Evaluating Predictive Uncertainty, Visual Object Classification and Recognizing Textual Entailment, First PASCAL Machine Learning Challenges Workshop, MLCW 2005, Southampton, UK, April 11-13, 2005, Revised Selected Papers, volume 3944 of Lecture Notes in Computer Science, pp. 177\u2013190. Springer, 2005. doi: 10.1007/11736790 \\ 9. URL https://doi.org/10.1007/11736790 9.\nMarie-Catherine De Marneffe, Mandy Simons, and Judith Tonhauser. The commitmentbank: Investigating projection in naturally occurring discourse. In proceedings of Sinn und Bedeutung, volume 23, pp. 107\u2013124, 2019.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. In Jill Burstein, Christy Doran, and Thamar Solorio (eds.), Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pp. 4171\u2013 4186. Association for Computational Linguistics, 2019. doi: 10.18653/v1/n19-1423. URL https://doi.org/10.18653/v1/n19-1423.\nNolan Dey, Gurpreet Gosal, Zhiming Chen, Hemant Khachane, William Marshall, Ribhu Pathria, Marvin Tom, and Joel Hestness. Cerebras-gpt: Open compute-optimal language models trained on the cerebras wafer-scale cluster. CoRR, abs/2304.03208, 2023. doi: 10.48550/arXiv.2304. 03208. URL https://doi.org/10.48550/arXiv.2304.03208.\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. A survey for in-context learning. arXiv preprint arXiv:2301.00234, 2022.\nHila Gonen, Srini Iyer, Terra Blevins, Noah A. Smith, and Luke Zettlemoyer. Demystifying prompts in language models via perplexity estimation. CoRR, abs/2212.04037, 2022. doi: 10.48550/arXiv. 2212.04037. URL https://doi.org/10.48550/arXiv.2212.04037.\nMinqing Hu and Bing Liu. Mining and summarizing customer reviews. In Won Kim, Ron Kohavi, Johannes Gehrke, and William DuMouchel (eds.), Proceedings of the Tenth ACM SIGKDD\n\nInternational Conference on Knowledge Discovery and Data Mining, Seattle, Washington, USA, August 22-25, 2004, pp. 168\u2013177. ACM, 2004. doi: 10.1145/1014052.1014073. URL https: //doi.org/10.1145/1014052.1014073.\nHyuhng Joon Kim, Hyunsoo Cho, Junyeob Kim, Taeuk Kim, Kang Min Yoo, and Sang-goo Lee. Self-generated in-context learning: Leveraging auto-regressive language models as a demonstration generator. CoRR, abs/2206.08082, 2022. doi: 10.48550/arXiv.2206.08082. URL https://doi.org/10.48550/arXiv.2206.08082.\nXiaonan Li and Xipeng Qiu. Finding supporting examples for in-context learning. CoRR, abs/2302.13539, 2023. doi: 10.48550/arXiv.2302.13539. URL https://doi.org/10.48550/arXiv. 2302.13539.\nXiaonan Li, Kai Lv, Hang Yan, Tianyang Lin, Wei Zhu, Yuan Ni, Guotong Xie, Xiaoling Wang, and Xipeng Qiu. Unified demonstration retriever for in-context learning. CoRR, abs/2305.04320, 2023. doi: 10.48550/arXiv.2305.04320. URL https://doi.org/10.48550/arXiv.2305.04320.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. What makes good in-context examples for gpt-3? In Eneko Agirre, Marianna Apidianaki, and Ivan Vulic (eds.),  Proceedings of Deep Learning Inside Out: The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, DeeLIO@ACL 2022, Dublin, Ireland and Online, May 27, 2022, pp. 100\u2013114. Association for Computational Linguistics, 2022a. doi: 10.18653/v1/2022.deelio-1.10. URL https://doi.org/10.18653/v1/2022.deelio-1.10.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. What makes good in-context examples for GPT-3? In  Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, pp. 100\u2013114, Dublin, Ireland and Online, May 2022b. Association for Computational Linguistics. doi: 10.18653/v1/2022.deelio-1.10. URL https://aclanthology.org/2022.deelio-1.10.\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (eds.), Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pp. 8086\u20138098. Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022.acl-long.556. URL https://doi.org/10.18653/v1/2022.acl-long.556.\nBo Pang and Lillian Lee. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Donia Scott, Walter Daelemans, and Marilyn A. Walker (eds.), Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, 21-26 July, 2004, Barcelona, Spain, pp. 271\u2013278. ACL, 2004. doi: 10.3115/1218955.1218990. URL https://aclanthology.org/P04-1035/.\nBo Pang and Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Kevin Knight, Hwee Tou Ng, and Kemal Oflazer (eds.), ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 25-30 June 2005, University of Michigan, USA, pp. 115\u2013124. The Association for Computer Linguistics, 2005. doi: 10.3115/1219840.1219855. URL https://aclanthology.org/ P05-1015/.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\nOhad Rubin, Jonathan Herzig, and Jonathan Berant. Learning to retrieve prompts for in-context learning. In Marine Carpuat, Marie-Catherine de Marneffe, and Iv\u00b4an Vladimir Meza Ru\u00b4\u0131z (eds.), Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15, 2022, pp. 2655\u20132671. Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022.naacl-main.191. URL https://doi.org/10.18653/v1/2022.naacl-main.191.\nRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment\n\ntreebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pp. 1631\u20131642. ACL, 2013. URL https://aclanthology.org/D13-1170/.\nTaylor Sorensen, Joshua Robinson, Christopher Michael Rytting, Alexander Glenn Shaw, Kyle Jeffrey Rogers, Alexia Pauline Delorey, Mahmoud Khalil, Nancy Fulda, and David Wingate. An information-theoretic approach to prompt engineering without ground truth labels. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (eds.), Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pp. 819\u2013862. Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022.acl-long.60. URL https://doi.org/10.18653/v1/2022.acl-long.60.\nXinyi Wang, Wanrong Zhu, and William Yang Wang. Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning. CoRR, abs/2301.11916, 2023. doi: 10.48550/arXiv.2301.11916. URL https://doi.org/10.48550/arXiv. 2301.11916.\nJanyce Wiebe, Theresa Wilson, and Claire Cardie. Annotating expressions of opinions and emotions in language. Lang. Resour. Evaluation, 39(2-3):165\u2013210, 2005. doi: 10.1007/ s10579-005-7880-9. URL https://doi.org/10.1007/s10579-005-7880-9.\nZhiyong Wu, Yaoxiang Wang, Jiacheng Ye, and Lingpeng Kong. Self-adaptive in-context learning. arXiv preprint arXiv:2212.10375, 2022.\nSang Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. An explanation of in-context learning as implicit bayesian inference. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=RdJVFCHjUMI.\nBenfeng Xu, Quan Wang, Zhendong Mao, Yajuan Lyu, Qiaoqiao She, and Yongdong Zhang. knn prompting: Beyond-context learning with calibration-free nearest neighbor inference. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview. net/forum?id=fe2S7736sNS.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068, 2022a.\nXiang Zhang, Junbo Jake Zhao, and Yann LeCun. Character-level convolutional networks for text classification. In Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pp. 649\u2013657, 2015. URL https://proceedings.neurips.cc/paper/2015/hash/ 250cf8b51c773f3f8dc8b4be867a9a02-Abstract.html.\nYiming Zhang, Shi Feng, and Chenhao Tan. Active example selection for in-context learning. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (eds.),  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pp. 9134\u20139148. Association for Computational Linguistics, 2022b. URL https://aclanthology.org/2022.emnlp-main.622.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving few-shot performance of language models. In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pp. 12697\u201312706. PMLR, 2021. URL http://proceedings.mlr.press/v139/zhao21c.html.\n\nAs depicted in Table 5, we provide detailed information on the Demonstration, mapping token spa and label space for different tasks.\n\n<div style=\"text-align: center;\">Table 5: Demonstration, mapping token space, and label space for different tasks.\n</div>\nDataset\nDemonstration\nMapping Token Space V\nLabel Space Y\nSST-2\nReview: the greatest musicians.\nSentiment: Positive\npositive/negative\npositive/negative\nSST-5\nReview: it \u2019s a very valuable film ...\nSentiment: great\nterrible/bad/okay\n/good/great\nvery positive/positive\n/neutral/negative\n/very negative\nDBPedia\ninput: Monte Vermenone is a mountain\nof Marche Italy.\ntype: nature\ncompany/school/artist/\nathlete/politics/book/\nbuilding/nature/village/\nanimal/plant/album/\nfilm/transportation\ncompany/school/artist/\nathlete/politics/book/\nbuilding/nature/village/\nanimal/plant/album/\nfilm/transportation\nMR\nReview: a dreary movie .\nSentiment: negative\npositive/negative\npositive/negative\nCR\nReview: i am bored with the silver look .\nSentiment: negative\npositive/negative\npositive/negative\nMPQA\nReview: is also the most risky\nSentiment: negative\npositive/negative\npositive/negative\nSubj\nInput: presents a most persuasive\nvision of hell on earth .\nType: subjective\nsubjective/objective\nsubjective/objective\nAGNews\ninput: Historic Turkey-EU deal welcomed. The\nEuropean Union\u2019s decision to hold entry talks with\nTurkey receives a widespread welcome.\ntype: world\nworld/sports/business\n/technology\nworld/sports/business\n/technology\nRTE\npremise: Oil prices fall back as Yukos oil threat lifted\nhypothesis: Oil prices rise.\nprediction: not entailment\ntrue/false\nentailment/not entailment\nCB\npremise: \u201cClever\u201d. Klug means \u201cclever\u201d. Would\nyou say that Abie was clever?\nhypothesis: Abie was clever\nprediction: neutral\ntrue/false/neither\nentailment/contradiction/\nneutral\n# B D ETAIL FOR D ATASETS AND M AX S HOTS\n\nAs shown in Table 6, we present detailed information for ten datasets. Besides, as we mentioned in section 2.1, for each dataset, the input prompt P consists of different numbers of demonstrations and a test instance. The maximum shot number, i.e., k max is calculated as follows:\n\n\u2264 \u00b7 \u00b7 \u00b7 where Upper bound is the Upper-bound of shots that can be accommodated by GPT-2, Cerebras-GPT, OPT or GPT-3, Max input  indicates the maximum input length of different sizes of LLMs, i.e., GPT2 (1024 tokens), Cerebras-GPT-2.7B (2048 tokens), Cerebras-GPT-6.7B (2048 tokens), OPT-13B (2048 tokens), OPT-30B (2048 tokens), GPT-3 175B (2048 tokens), Max test denotes the max length of test input, Avg template means the average length of each demonstration, and Numbers classes indicates the numbers of classes for each task, i.e., |C|. To narrow down the search scope, we set the value range of Max Shots to {1, 2, 4, 8, 16, 32, 64, \u00b7 \u00b7 \u00b7 }. Thus, for each dataset, the max shots we choose should be below the upper bound and closest to it. For example, the Upper-bound (1024 tokens) of the SST-2 dataset is 25, so the max shot we need to select is 16; the Upper-bound (1024 tokens) of the MPQA dataset is 48, so the max shot we need to select is 32. It should be noted that while the Upper-bound (1024 tokens) of the CB dataset is 2, for a fair comparison with other\n\n(9)\n\n<div style=\"text-align: center;\">Table 6: Statistics of evaluation datasets, the average length of each demonstration, and the max length of test input are calculated based on sentence-piece length.\n</div>\nDataset\nNumber of\nClasses\nAvg. Length\nof Demonstration\nMax Length of\nTest Input\nUpper-bound\n(1024 tokens)\nMax Shots\n(1024 tokens)\nUpper-bound\n(2048 tokens)\nMax Shots\n(2048 tokens)\nSST-2 (Socher et al., 2013)\n2\n19.1\n55\n25\n16\n52\n32\nSST-5 (Socher et al., 2013)\n5\n29.7\n60\n6\n4\n13\n8\nDBPedia (Zhang et al., 2015)\n14\n71.6\n161\n1\n1\n1\n1\nMR (Pang & Lee, 2005)\n2\n32.7\n66\n14\n8\n30\n16\nCR (Hu & Liu, 2004)\n2\n29.0\n99\n15\n8\n33\n32\nMPQA (Wiebe et al., 2005)\n2\n10.4\n19\n48\n32\n97\n64\nSubj (Pang & Lee, 2004)\n2\n34.9\n91\n13\n8\n28\n16\nAGNews (Zhang et al., 2015)\n4\n59.5\n167\n3\n2\n7\n4\nRTE (Dagan et al., 2005)\n2\n79.7\n256\n4\n4\n11\n8\nCB (De Marneffe et al., 2019)\n3\n90.8\n278\n2\n4\n6\n4\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f8e2/f8e2c5c9-5abe-4ce2-b460-cdf25f80e2f8.png\" style=\"width: 50%;\"></div>\nFigure 7: Effect of the number of demonstrations on OPT-13B across five datasets.\n\nmethods, we set the max shot to 4. This decision was made because previous methods used 4-shots for the CB dataset (Lu et al., 2022).\n\n# C A DDITIONAL R ESULTS\n\nHere, we present more results to support our arguments. Among them, Figure 7 shows the performance curves of five datasets on the OPT-13B model. Figure 8 shows performance curves of CB dataset on five different sizes of LLMs.\n\nIncreasing the number of demonstrations does not necessarily improve the model performance. In Figure 7, when changing from 1-shot setting to k max-shot setting, we can observe that the accuracy of the OPT-13B model improves on the RTE and MPQA datasets while declines on the SST5 and CB datasets. Besides, as shown in Figure 8, when changing from 1-shot setting to 4-shot setting, the accuracy of the CB dataset initially declines and then increases on the OPT-13B model, while it first rises and then goes down on the GPT-3-175B model. These observations suggests that the inclusion of more demonstrations does not guarantee improved performance.\n\nThe optimal k-shot setting differs depending on specific datasets and models. From Figure 8, we can find that the optimal k-shot settings for the same dataset on different models can be different: 1-shot setting for the OPT-13B model, 2-shot setting for the Cerebras-GPT 2.7B, Cerebras-GPT 6.7B and GPT-3 175B models, 4-shot setting for the OPT-30B model. Likewise, from Figure 7, we can tell that the optimal k-shot settings for the same model on different datasets also can be different: 1-shot setting for the SST5 and CB datasets, 8-shot setting for the RTE dataset, 16-shot setting for the CR dataset, 32-shot setting for the MPQA dataset. These observations suggests that the optimal number of demonstrations may differ depending on the specific dataset and model.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/c500/c50028ec-5029-4582-9bdf-601011b81baa.png\" style=\"width: 50%;\"></div>\nFigure 8: The accuracy of five different sizes of LLMs on the CB dataset.\n\n<div style=\"text-align: center;\">Figure 8: The accuracy of five different sizes of LLMs on the CB dataset.\n</div>\n# D A LGORITHM DETAILS\n\n<div style=\"text-align: center;\">The details of Dynamic Demonstrations Controller are presented in Algorithm 1.\n</div>\nAlgorithm 1: Dynamic Demonstrations Controller.\nInput: The training set: D; The number of in-context example groups: Ns; The feasible k set: K; The set\nof Classes: C;The LLM: \u03b8.\nOutput: The selected k: \u02c6k.\n1 for k in K do\n2\nSampling Ns groups of in-context examples and remove them from D. The rest is D\u2032.\n// Initializing the set of evaluation examples.\n3\nT k \u2190\u2205\n4\nfor i in 1, 2, \u00b7 \u00b7 \u00b7 , Ns do\n5\nfor c in C do\n// Computing the IICScore for each candidate example in D\u2032.\n6\n\u02dcec\nEk\ni \u2190arg max\nec\nj\u2208D\u2032\nIICScore(ec\nj, Ek\ni )\n7\nT k \u2190T k \u222a\u02dcec\nEk\ni\n8\nend\n9\nend\n10\nAcc \u21900\n11\nfor i in 1, 2, \u00b7 \u00b7 \u00b7 , Ns do\n12\nAcc \u2190Acc +\n1\n|T k|\n\ufffd|T k|\nj=1 I(\u02c6yj,Ek\ni = yj)\n13\nend\n14\nAcck \u2190\n1\nNs Acc\n15 end\n16 \u02c6k \u2190arg max\nk\u2208K\nAcck\n17 return \u02c6k\n# E T HE V ALUE OF k\n\n<div style=\"text-align: center;\">In Table 7, we show the values of k chosen by the D 2 Controller and Oracle.\n</div>\nSST-2\nSST-5\nDBPedia\nMR\nCR\nMPQA\nSubj\nAGNews\nRTE\nCB\nGPT-2\n0.3B\nDefault\n4\n4\n1\n4\n4\n4\n4\n2\n4\n4\nD2Controller\n16\n1\n1\n8\n1\n32\n2\n2\n2\n4\nOracle\n16\n1\n1\n1\n1\n16\n8\n1\n4\n2\nGPT-2\n0.8B\nDefault\n4\n4\n1\n4\n4\n4\n4\n2\n4\n4\nD2Controller\n16\n2\n1\n4\n4\n32\n8\n2\n4\n2\nOracle\n4\n1\n1\n4\n4\n16\n8\n2\n2\n1\nGPT-2\n1.5B\nDefault\n4\n4\n1\n4\n4\n4\n4\n2\n4\n4\nD2Controller\n16\n4\n1\n8\n8\n16\n8\n2\n2\n4\nOracle\n16\n1\n1\n8\n8\n16\n8\n1\n2\n2\nCerebras-GPT\n2.7B\nDefault\n4\n4\n1\n4\n4\n4\n4\n2\n4\n4\nD2Controller\n32\n8\n1\n16\n1\n32\n16\n1\n4\n1\nOracle\n8\n8\n1\n16\n1\n64\n16\n1\n2\n2\nCerebras-GPT\n6.7B\nDefault\n4\n4\n1\n4\n4\n4\n4\n2\n4\n4\nD2Controller\n32\n2\n1\n8\n32\n64\n16\n4\n8\n1\nOracle\n1\n1\n1\n4\n16\n64\n16\n4\n2\n2\nOPT\n13B\nDefault\n4\n4\n1\n4\n4\n4\n4\n2\n4\n4\nD2Controller\n16\n4\n1\n4\n1\n1\n16\n4\n8\n4\nOracle\n1\n1\n1\n1\n16\n32\n16\n4\n8\n1\nOPT\n30B\nDefault\n4\n4\n1\n4\n4\n4\n4\n2\n4\n4\nD2Controller\n4\n8\n1\n16\n2\n64\n16\n4\n8\n4\nOracle\n2\n1\n1\n16\n16\n64\n16\n2\n4\n4\nGPT-3\n175B\nDefault\n4\n4\n1\n4\n4\n4\n4\n2\n4\n4\nD2Controller\n4\n8\n1\n16\n1\n4\n16\n2\n2\n2\nOracle\n2\n8\n1\n8\n2\n32\n16\n2\n8\n2\n# F L IMITATIONS\n\nThe current research suffers from two limitations: (1) Due to budget constraints and insufficient GPU memory, we are unable to conduct experiments on larger-scale language models; (2) Our method does not guarantee the selection of the optimal value of k for each dataset. This requires future research to explore and refine techniques in order to continuously approach the optimal value of k.\n\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of In-Context Learning (ICL) in natural language processing, specifically focusing on the impact of the number of demonstrations on model performance. Previous methods have primarily concentrated on demonstration selection and ordering, but there is a lack of research on how the number of demonstrations affects ICL performance, particularly within the constraints of input length in large language models (LLMs).",
        "problem": {
            "definition": "The problem is the prevailing assumption that increasing the number of demonstrations in ICL leads to improved model performance, which this paper challenges.",
            "key obstacle": "The main difficulty is that the relationship between the number of demonstrations and model performance is not straightforward, with varying impacts observed across different datasets and models."
        },
        "idea": {
            "intuition": "The idea was inspired by pilot experiments revealing that adding more demonstrations does not consistently enhance performance, suggesting the need for a more nuanced approach.",
            "opinion": "The proposed idea, the Dynamic Demonstrations Controller (D2 Controller), aims to dynamically adjust the number of demonstrations based on specific dataset and model requirements to optimize ICL performance.",
            "innovation": "The primary innovation of the D2 Controller is its ability to adaptively select the optimal number of demonstrations, which contrasts with existing static methods that do not account for variability in performance based on the number of demonstrations."
        },
        "method": {
            "method name": "Dynamic Demonstrations Controller",
            "method abbreviation": "D2 Controller",
            "method definition": "The D2 Controller is a method that dynamically selects the appropriate number of demonstrations for ICL based on evaluation examples to maximize model performance.",
            "method description": "The method involves comparing prediction accuracy across different demonstration numbers and selecting the optimal configuration for each dataset.",
            "method steps": [
                "Sample in-context examples for different k-shot settings.",
                "Select evaluation examples using the IICScore metric.",
                "Evaluate and compare the accuracy of different k-shot settings to determine the best one."
            ],
            "principle": "The effectiveness of the D2 Controller is rooted in its ability to tailor the number of demonstrations to the specific characteristics of the dataset and model, thus enhancing performance while conserving resources."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted on ten text classification datasets using eight sizes of LLMs, including various models such as GPT-2, Cerebras-GPT, and GPT-3. Accuracy was used as the evaluation metric.",
            "evaluation method": "The evaluation involved sampling a set number of examples from each dataset and testing model performance across different k-shot settings, measuring accuracy and standard deviation over multiple seeds."
        },
        "conclusion": "The D2 Controller improves ICL performance by an average of 5.4% across ten datasets and various LLM sizes, demonstrating its effectiveness in dynamically adjusting the number of demonstrations.",
        "discussion": {
            "advantage": "The D2 Controller provides significant performance improvements by optimizing the number of demonstrations, which is a critical factor in ICL.",
            "limitation": "The method does not guarantee the absolute optimality of the selected k for each dataset, and further research is needed to refine these techniques.",
            "future work": "Future research should focus on enhancing the D2 Controller to better approximate the optimal number of demonstrations and explore its application on larger-scale language models."
        },
        "other info": {
            "info1": "The D2 Controller is model-agnostic and can be integrated with various LLM architectures.",
            "info2": {
                "info2.1": "The method achieved competitive results when extended to previous ICL models.",
                "info2.2": "The IICScore metric was crucial for selecting representative evaluation examples."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The paper addresses In-Context Learning (ICL) in natural language processing, focusing on the impact of the number of demonstrations on model performance."
        },
        {
            "section number": "1.2",
            "key information": "The prevailing assumption that increasing the number of demonstrations in ICL leads to improved model performance is challenged in this paper."
        },
        {
            "section number": "3.3",
            "key information": "The Dynamic Demonstrations Controller (D2 Controller) is proposed to dynamically adjust the number of demonstrations based on specific dataset and model requirements."
        },
        {
            "section number": "3.4",
            "key information": "The D2 Controller tailors the number of demonstrations to the specific characteristics of the dataset and model, thus enhancing performance while conserving resources."
        },
        {
            "section number": "4.1",
            "key information": "The D2 Controller provides significant performance improvements by optimizing the number of demonstrations, which is a critical factor in ICL."
        },
        {
            "section number": "6.1",
            "key information": "The method does not guarantee the absolute optimality of the selected k for each dataset, indicating limitations in the proposed approach."
        },
        {
            "section number": "6.4",
            "key information": "Future research should focus on enhancing the D2 Controller to better approximate the optimal number of demonstrations and explore its application on larger-scale language models."
        }
    ],
    "similarity_score": 0.7342242522827495,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2330_in-co/papers/Dynamic Demonstrations Controller for In-Context Learning.json"
}