{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2002.03225",
    "title": "Convolutional Framework for Accelerated Magnetic Resonance Imaging",
    "abstract": "Magnetic Resonance Imaging (MRI) is a noninvasive imaging technique that provides exquisite soft-tissue contrast without using ionizing radiation. The clinical application of MRI may be limited by long data acquisition times; therefore, MR image reconstruction from highly undersampled k-space data has been an active area of research. Many works exploit rank deficiency in a Hankel data matrix to recover unobserved kspace samples; the resulting problem is non-convex, so the choice of numerical algorithm can significantly affect performance, computation, and memory. We present a simple, scalable approach called Convolutional Framework (CF). We demonstrate the feasibility and versatility of CF using measured data from 2D, 3D, and dynamic applications. Index Terms\u2014 parallel imaging, low rank, calibration-",
    "bib_name": "zhao2020convolutionalframeworkacceleratedmagnetic",
    "md_text": "# CONVOLUTIONAL FRAMEWORK FOR ACCELERATED MAGNETIC RESONANCE IMAGING\nShen Zhao*, Lee C. Potter*, Kiryung Lee*, Rizwan Ahmad**\n*Department of Electrical and Computer Engineering, **Department of Biomedical Engineering, The Ohio State University\n# ABSTRACT\nMagnetic Resonance Imaging (MRI) is a noninvasive imaging technique that provides exquisite soft-tissue contrast without using ionizing radiation. The clinical application of MRI may be limited by long data acquisition times; therefore, MR image reconstruction from highly undersampled k-space data has been an active area of research. Many works exploit rank deficiency in a Hankel data matrix to recover unobserved kspace samples; the resulting problem is non-convex, so the choice of numerical algorithm can significantly affect performance, computation, and memory. We present a simple, scalable approach called Convolutional Framework (CF). We demonstrate the feasibility and versatility of CF using measured data from 2D, 3D, and dynamic applications. Index Terms\u2014 parallel imaging, low rank, calibration-\narXiv:2002.03225v1\n# Index Terms\u2014 parallel imaging, low rank, calibrationless, multi-level block Hankel.\n# 1. INTRODUCTION\nMRI reconstruction from undersampled data implicitly relies on priors to provide regularizing assumptions. Priors in MRI reconstruction may be considered in two classes: coil properties and image structure. The spatial smoothness of coil sensitivity maps may be modeled as filters with finite k-space support, leading to a shift-invariant prediction property for multicoil k-space data. GRAPPA [1] uses a fully-sampled autocalibration signal (ACS) region to solve for a linear prediction kernel and applies the kernel to recover missing k-space samples. SPIRiT [2] is a generalization of GRAPPA that enforces the linear predictability across the entire k-space. PRUNO [3] generalizes SPIRiT further by using multiple kernels satisfying the linear prediction property. The shift invariant linear prediction property may be expressed as a nullspace of a convolution operator, which is a multi-level Hankel-structured matrix. And, the finite k-space support of coil sensitivities translates to low-rank for the structured Hankel data matrix. Calibration-free methods, such as SAKE [4], employ lowrank structured matrix completion to recover missing k-space samples. To improve computational efficiency, alternatives to\nthe Cadzow\u2019s algorithm (used in SAKE) have been proposed for single-coil [5] and multi-coil [6] MRI. Sparsity in the image domain also leads to existence of approximate annihilating filters in the k-space and yields the shift-invariant linear prediction property [7]. Any linear filtering that sparsifies the image also yields annihilating filters in the resulting weighted k-space. In this vein, ALOHA uses a low-rank matrix completion method to recover missing samples in the weighted k-space [8]. We present a viewpoint and computational approach, called Convolutional Framework (CF), that unifies many reconstruction techniques and provides an algorithmic approach for structured matrix completion. Memory efficiency permits high-dimensional imaging cases not demonstrated previously. Numerical evaluations are presented for three imaging applications: 2D, 2D cine, and 3D. Discussion and summary conclude the manuscript.\n# 2. METHODS\nWe first define notation for organizing k-space data into structured arrays. A tensor denotes a multidimensional array. Let \u2217, \u229b, and \ufffddenote linear convolution, circular convolution, and valid convolution, respectively. Valid convolution maps to output points that do not depend on any boundary conditions (i.e., no padding of the input). For example, for n-point vector a and m-point vector b, m \u2265n, the lengths of a \u2217b and a \ufffdb are m + n \u22121 and m \u2212n + 1, respectively. Let s(A) be the row vector that lists the sizes of tensor A. Let Hs(A){B} denote multi-level block Hankelization of the tensor B such that right multiplication of the matrix Hs(A){B} with vectorized A (vec{A}) is the vectorization of the valid convolution result between B and A, i.e.,\n(1)\nFinally, \u25e6denotes Hadamard multiplication between tensors of the same size, and (\u00b7)H denotes conjugate transpose. For generality, we denote the k-space by D with five dimensions: frequency encoding, first phase encoding, second phase encoding, coil, and time; dimensions are ordered and indexed by kx, ky, kz, l, t. We choose the kernel size s = [fx, fy, fz, Nc, ft], where NC is the number of coils.\nBased on the shift-invariant linear predictability assumption, CF leverages linear prediction in all dimensions, i.e., annihilating filters exist for jointly processing all dimensions. An iterative algorithm to apply the property has two simple steps: (i) Estimate all annihilating filters from the current estimate of k-space; and (ii) Enforce annihilation for the whole k-space and update the unobserved k-space. The CF processing is summarized in Algorithm 1.\nAlgorithm 1 Pipeline of CF\nInput:\nDo: Observed k-space with zero filling\nM: Sampling mask\ns: Kernel size\nr: Rank\ntol: Tolerance\nOutput:\n\u02c6D(n): Recovered k-space\nInitialization: n = 0, \u03b4 = \u221e, \u02c6D(n) = Do\n1: while \u03b4 > tol do\n2:\nn = n + 1\n3:\n[\u039b2, V ] = EIG(H H\ns (\u02c6D(n))Hs(\u02c6D(n)))\n4:\nV = [V\u2225| V\u22a5] based on r\n5:\nSplit, reshape and flip V\u22a5into kernels F1, F2, \u00b7 \u00b7 \u00b7\n6:\n\u02c6D(n)\nu\n= argminX\n\ufffd\ni \u2225(Do + X) \ufffdFi\u22252\nF s.t. X \u25e6M = 0\n7:\n\u02c6D(n) = Do + \u02c6D(n)\nu\n8:\n\u03b4 = \u2225\u02c6D(n) \u2212\u02c6D(n\u22121)\u2225F /\u2225\u02c6D(n\u22121)\u2225F\n9: end while\nThe eigendecomposition in Step 3 extracts a null space (V\u22a5) of the product of two Hankel operators; this avoids a singular value decomposition of the explicit \u2013 and very large \u2013 convolutional matrix H H s . The operator product in Step 3 may be calculated with limited memory and computation using convolution with small kernels, in lieu of explicit matrices. Step 6 is a large scale least squares problem; to limit memory requirements, we avoid direct computation and instead rely on the implicit convolution operator in a gradient descent (GD) method with exact linear search (ELS). The memory requirement for GD + ELS is approximately only the original data size, in contrast to explicit construction of Hankel matrices. Step 6 minimizes null space energy while simultaneously preserving Hankel structure and data consistency. In contrast, SAKE enforces the Hankel structure, rank deficiency, and data consistency as three separate projections. Also, spatial, coil, and time dimensions are jointly incorporated in CF. If there is an ACS region, we may directly estimate the null space V\u22a5from DACS, then enforce it to hold for the whole k-space. This variant, which for 2D static MRI shares the assumptions with PRUNO, avoids the iterative step to estimate V\u22a5. Also, the type of convolution (linear, circular, or valid) may differ across k-space dimensions; for example, we may adopt circular convolution for the time dimension and valid\n# 3. EXPERIMENTS AND RESULTS\nWe implement CF and compare to several existing techniques for 2D, 3D, and 2D cine (\u201c2D+t\u201d) imaging. For a fair comparison, we set the kernel size to be 5kx \u00d7 5ky \u00d7 NC for CF, SAKE, and ALOHA. Since P-LORAKS [6] uses a diskshaped kernel, we choose a radius 3 for P-LORAKS (\u201cC\u201d version) which leads to a similar but slightly larger kernel including 29 > 5 \u00d7 5 = 25 k-space points per coil. The reconstruction SNR generally increases with the kernel size but so does the computation burden. The stopping tolerance, relative change in the whole k-space, is 10\u22123 for all methods. A maximum of 200 iterations is used, except for SAKE, in which case we also continue beyond 200 iterations until the SNR of SAKE matches that of CF. This reconstruction is referred to as SAKE*. We fine-tuned rank selection for all methods with respect to the first dataset, then applied that choice of rank to all other datasets. For other parameters, e.g., regularization parameter \u03bb for P-LORAKS, we employ published default values. For the recruitment and consent of human subjects used in this study, the ethical approval was given by an Internal Review Board (2005H0124) at The Ohio State University. For 2D, we retrospectively downsampled three 3T brain datasets using three different acceleration rates, R = 4, 6, and 8 and four different sampling patterns: (i) 2D random; (ii) 2D random + 7kx \u00d7 7ky ACS region; (iii) 2D random + 17kx \u00d7 17ky ACS region; (iv) 1D random + 5 ACS readout lines. The data were compressed to eight virtual coils. Quantitative results and representative frames are in Table 1 and Figure 1, respectively. Not surprisingly, the performances of CF and SAKE* are similar because they essentially solve the same 2D problem, but CF converges in fewer iterations and has a significantly smaller memory footprint. For 3D, we truncated a 3T knee dataset (downloaded from mridata.org) to 160kx \u00d7 80ky \u00d7 64kz, then retrospectively downsampled in ky and kz using 2D random sampling, with 15ky \u00d7 15kz ACS and fully sampled kx. The data were compressed to four virtual coils for faster processing. A representative slice is shown in Figure 2. Since 3D CF reconstruction utilizes similarity and redundancy in three dimensions, with smaller degrees of freedom, it is able to outperform 2D CF reconstruction, which was separately applied to individual 2D slices. Due to prohibitive memory requirements, it was not feasible to extend SAKE\u2019s implementation to 3D. For 2D+t, we retrospectively downsampled three 3T cardiac cine datasets at four different acceleration rates, R = 4, 6, 8, and 10 using a variable density sampling pattern [9]. The data were compressed to four virtual coils for faster processing. We fine-tuned parameters for all methods with respect to the first dataset, then applied these parameters to other two datasets. We averaged the reconstruction SNR for\nthe other two different datasets. Quantitative results and representative frames are in Table 2 and Figure 3. We compare to SENSE-based techniques, as SAKE and LORAKS do not provide extension to these cases. The CF is consistently better than L+S [10] and TV [11] by 1.1 to 2.3 dB in terms of k-space SNR. With square-root sum of squared coils (SSoS), the margin is even larger.\nR=4\nR=6\nR=8\nCF\n22.4 dB\n19.4 dB\n15.8 dB\n147.3s\n306.6 s\n382.7s\nSAKE\n20.5 dB\n16.3 dB\n13.7 dB\n301.2s\n320.7 s\n293.7s\nSAKE\u2217\n22.4 dB\n19.4 dB\n15.8 dB\n593.5s\n772.2 s\n722.8s\nP-LORAKS\n22.3 dB\n18.2 dB\n14.4 dB\n123.6s\n158.6 s\n156.2s\nTable 1. 2D k-space reconstruction SNR (dB) and time (s) comparison. Median time and average k-space SNR are computed across two datasets and four different sampling patterns. SAKE\u2217denotes continuing SAKE past 200 iterations until reaching CF SNR.\nR=4\nR=6\nR=8\nR=10\nCF\n29.5\n28.2\n27.3\n26.3\nL+S\n27.1\n26.4\n25.5\n25.1\nTV\n27.2\n26.1\n25.1\n24.1\nTable 2. 2D+t k-space reconstruction SNR (dB) averaged over two datasets. CF offers more than one dB advantage across all acceleration rates.\n# 4. DISCUSSION AND CONCLUSION\nMany parallel imaging approaches interpolate missing kspace points by solving a rank-deficient matrix completion. Choice of solution method can affect performance and memory requirements for this non-convex problem. CF provides an effective, memory-efficient solution and can subsume modeling choices found in existing GRAPPAinspired methods. The memory requirement for CF processing (EIG + GD + ELS) is approximately the storage of the fully sampled k-space tensor D. For example, for a 3D static double-precision complex k-space tensor with size 256kx \u00d7 256ky \u00d7 256kz \u00d7 8coils and a kernal size 10kx \u00d7 10ky \u00d7 10kz \u00d7 8coils, a SAKE computation requires 2 TB of memory, while CF only needs 2 GB. Computation speed of CF can be further enhanced by using the following properties and processing steps. Automatic filter size adaptation: Many annihilating relationships can be efficiently and approximately captured by a small kernel.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/bee5/bee50384-c321-4638-a288-08d8ab4964c8.png\" style=\"width: 50%;\"></div>\nFig. 1. A representative 2D reconstruction from dataset 2 with sampling pattern without the ACS region and acceleration rate 4. Left: SSoS images. Right: 10\u00d7 absolute error. (a) fully sampled; (b) CF (23.0 dB SNR); (c) P-LORAKS (20.8 dB); (d) SAKE (14.9 dB).\nThus, the CF computation can be sped up by adaptively progressing from small kernels to larger ones as iterations evolve. Automatic center to full k-space reconstruction: Because the annihilation relationship holds for the entire k-space, we can apply CF for a small region of k-space and extract the null space, then enforce the estimated null space for the whole kspace. Highly parallizable: All convolutions inside each iter-\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3848/3848cd6d-13d5-41b7-873b-26029436df09.png\" style=\"width: 50%;\"></div>\nFig. 2. A representative slice from the 3D knee dataset. SSoS image (top row); 10\u00d7 absolute error (bottom row). Columns are: fully sampled image; 3D reconstruction via CF (23.2 dB) and slice-by-slice reconstruction via CF (22.8 dB). Compared to CF 3D, the error map of CF 2D has more structure.\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/8aea/8aeac61c-13a7-4cea-9f12-3fbbbb1b2166.png\" style=\"width: 50%;\"></div>\nFig. 3. A representative frame from 2D+t reconstruction. SSoS images (left) and 20\u00d7 absolute error (right). (a) fully sampled; (b) CF (29.0 dB); (c) TV (27.1 dB); (d) L+S (26.8 dB). Compared to CF, the error maps of TV and L+S have more structure.\native step are independent and thus highly parallizable. Thus, we can fully utilize multi-cluster, multi-core CPU, or GPU architectures to accelerate the processing. JohnsonLinden-\nstrauss Lemma (JLL): The dimensionality of the null space and thus the size of the least squares problem can be further reduced by applying JLL in each iteration. In summary, simple conceptual framework, broad applicability, unifying nature, memory efficient computation, and a potential to further improve the computation speed make CF an attractive framework for MRI reconstruction.\n# 5. REFERENCES\n",
    "paper_type": "method",
    "attri": {
        "background": "This paper addresses the issue of long data acquisition times in Magnetic Resonance Imaging (MRI) and the limitations of existing reconstruction methods that rely on rank deficiency in Hankel data matrices, necessitating a new approach for improved performance.",
        "problem": {
            "definition": "The problem involves reconstructing MR images from highly undersampled k-space data, which is a non-convex problem that significantly affects performance and computational efficiency.",
            "key obstacle": "The main challenge is the non-convex nature of the problem, which complicates the choice of numerical algorithms and affects the performance and memory usage of existing methods."
        },
        "idea": {
            "intuition": "The idea is inspired by the shift-invariant linear prediction property of multicoil k-space data, leading to the development of a unified computational approach.",
            "opinion": "The proposed Convolutional Framework (CF) leverages annihilating filters for jointly processing k-space data, aiming to improve the efficiency and effectiveness of MRI reconstruction.",
            "innovation": "CF differentiates itself from existing methods by integrating multiple modeling choices and ensuring memory efficiency, allowing for high-dimensional imaging applications."
        },
        "method": {
            "method name": "Convolutional Framework",
            "method abbreviation": "CF",
            "method definition": "CF is defined as a method that utilizes linear prediction across multiple dimensions of k-space data for MRI reconstruction.",
            "method description": "CF processes k-space data through an iterative algorithm that estimates annihilating filters and enforces their application to recover unobserved k-space samples.",
            "method steps": [
                "Input the observed k-space with zero filling.",
                "Estimate annihilating filters from the current k-space estimate.",
                "Enforce annihilation for the entire k-space and update the unobserved k-space.",
                "Iterate until convergence is achieved."
            ],
            "principle": "The method is effective due to its reliance on the shift-invariant linear prediction property, which allows for efficient recovery of missing k-space samples through structured matrix completion."
        },
        "experiments": {
            "evaluation setting": "Experiments were conducted on 2D, 3D, and 2D cine MRI datasets, comparing CF against several existing techniques while ensuring consistent kernel sizes and stopping tolerances.",
            "evaluation method": "Performance was assessed through reconstruction SNR measurements and computational time comparisons across different methods and datasets."
        },
        "conclusion": "The CF method demonstrated superior performance in terms of reconstruction quality and memory efficiency compared to existing methods, making it a promising approach for MRI applications.",
        "discussion": {
            "advantage": "CF's key advantages include its memory efficiency, ability to unify various modeling approaches, and faster convergence in fewer iterations compared to existing methods.",
            "limitation": "The limitations of CF include potential challenges in specific high-dimensional scenarios where the assumptions of linear predictability may not hold.",
            "future work": "Future research may focus on enhancing CF's computational speed and exploring its applicability to more complex MRI scenarios."
        },
        "other info": {
            "ethical approval": "The ethical approval for the study was granted by an Internal Review Board (2005H0124) at The Ohio State University.",
            "kernel size": "The kernel size used for CF was set to 5kx \u00d7 5ky \u00d7 NC, with variations for comparison methods.",
            "datasets": {
                "2D": "Three 3T brain datasets with different acceleration rates.",
                "3D": "A 3T knee dataset.",
                "2D+t": "Three 3T cardiac cine datasets."
            }
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The foundational idea behind semi-supervised algorithms includes leveraging both labeled and unlabeled data to improve learning outcomes, which is analogous to the Convolutional Framework's approach of utilizing multiple dimensions of k-space data for MRI reconstruction."
        },
        {
            "section number": "1.2",
            "key information": "The motivation behind the development of the Convolutional Framework (CF) is to address long data acquisition times in Magnetic Resonance Imaging (MRI) and the limitations of existing reconstruction methods."
        },
        {
            "section number": "1.3",
            "key information": "The main objectives of the paper include improving performance and computational efficiency in reconstructing MR images from highly undersampled k-space data."
        },
        {
            "section number": "3.5",
            "key information": "The Convolutional Framework (CF) is a novel approach that integrates multiple modeling choices and ensures memory efficiency, differentiating it from existing methods in semi-supervised learning."
        },
        {
            "section number": "4.1",
            "key information": "Data labeling in the context of MRI reconstruction involves accurately estimating annihilating filters from observed k-space data to recover unobserved samples."
        },
        {
            "section number": "7.1",
            "key information": "The challenges faced in the Convolutional Framework include the non-convex nature of the reconstruction problem, which complicates the choice of numerical algorithms and affects performance."
        },
        {
            "section number": "7.3",
            "key information": "Future research may focus on enhancing the computational speed of the Convolutional Framework and exploring its applicability to more complex MRI scenarios, which relates to effectively integrating unlabeled data in learning processes."
        }
    ],
    "similarity_score": 0.573326599113412,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-2055_semi-/papers/Convolutional Framework for Accelerated Magnetic Resonance Imaging.json"
}