{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2406.00793",
    "title": "Is In-Context Learning in Large Language Models Bayesian? A Martingale Perspective",
    "abstract": "In-context learning (ICL) has emerged as a particularly remarkable characteristic of Large Language Models (LLM): given a pretrained LLM and an observed dataset, LLMs can make predictions for new data points from the same distribution without fine-tuning. Numerous works have postulated ICL as approximately Bayesian inference, rendering this a natural hypothesis. In this work, we analyse this hypothesis from a new angle through the martingale property, a fundamental requirement of a Bayesian learning system for exchangeable data. We show that the martingale property is a necessary condition for unambiguous predictions in such scenarios, and enables a principled, decomposed notion of uncertainty vital in trustworthy, safety-critical systems. We derive actionable checks with corresponding theory and test statistics which must hold if the martingale property is satisfied. We also examine if uncertainty in LLMs decreases as expected in Bayesian learning when more data is observed. In three experiments, we provide evidence for violations of the martingale property, and deviations from a Bayesian scaling behaviour of uncertainty, falsifying the hypothesis that ICL is Bayesian.",
    "bib_name": "falck2024incontextlearninglargelanguage",
    "md_text": "# Is In-Context Learning in Large Language Models Bayesian? A Martingale Perspective\n\nFabian Falck * 1 Ziyu Wang * 1 Chris Holmes\n\n# Abstract\n\nIn-context learning (ICL) has emerged as a particularly remarkable characteristic of Large Language Models (LLM): given a pretrained LLM and an observed dataset, LLMs can make predictions for new data points from the same distribution without fine-tuning. Numerous works have postulated ICL as approximately Bayesian inference, rendering this a natural hypothesis. In this work, we analyse this hypothesis from a new angle through the martingale property, a fundamental requirement of a Bayesian learning system for exchangeable data. We show that the martingale property is a necessary condition for unambiguous predictions in such scenarios, and enables a principled, decomposed notion of uncertainty vital in trustworthy, safety-critical systems. We derive actionable checks with corresponding theory and test statistics which must hold if the martingale property is satisfied. We also examine if uncertainty in LLMs decreases as expected in Bayesian learning when more data is observed. In three experiments, we provide evidence for violations of the martingale property, and deviations from a Bayesian scaling behaviour of uncertainty, falsifying the hypothesis that ICL is Bayesian.\n\n\n# 1. Introduction\n\nLarge Language Models (LLMs) are autoregressive generative models trained on vast amounts of data, exhibiting extraordinary performance across a wide array of tasks (Zhao et al., 2023). A particularly remarkable characteristic of LLMs is so-called in-context learning (ICL)\n\n* Equal contribution 1 Department of Statistics, University of Oxford, Oxford, UK. Correspondence to: Fabian Falck <fabian.falck@stats.ox.ac.uk>, Ziyu Wang <ziyu.wang@stats.ox.ac.uk>, Chris Holmes <cholmes@stats.ox.ac.uk>.\n\nProceedings of the 41 st International Conference on Machine Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the author(s).\n\nProceedings of the 41 st International Conference on Machine Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the author(s).\n\n(Brown et al., 2020; Dong et al., 2022): Given a pretrained language model p M and an observed dataset D:= {(x 1, y 1), . . . , (x n, y n)} = z 1: n  of samples, LLMs capture the distribution of the underlying random variables X and Y  in this in-context dataset. This allows them produce a new sample (x n +1, y n +1) using the  predictive distribution p M (X n +1, Y n +1 | Z 1: n = z 1: n), or if x n +1  is observed infer the predictive distribution p M (Y n +1 | X n +1 = x n +1, Z 1: n = z 1: n), without retraining or fine-tuning p M.\nFew-shot learning via ICL (Brown et al., 2020) has produced numerous breakthroughs in LLM research (Dong et al., 2022), such as in supervised learning (Min et al., 2021) or chain-of-thought prompting (Wei et al., 2022). In spite of the remarkable empirical success of ICL, we lack a unified understanding of the algorithm and the properties of conditioning LLMs on in-context data. In this work, we are interested in characterising the type of learning that occurs in ICL. Specifically, we aim to answer the question: is in-context learning for LLMs on exchangeable data (approximately) Bayesian?\nIn contrast to prior work, our analysis focuses on one fundamental property of Bayesian learning systems for exchangeable data: the martingale property. In a nutshell, the martingale property describes the invariance of a model\u2019s predictive distribution with respect to missing data from a population. We will formally define and extensively explain the martingale property in \u00a7 2, but begin by intuitively describing two important and desirable consequences of it with an example, highlighting its relevance. These consequences are: (i) the martingale property is a necessary condition for rendering predictions unambiguous in an exchangeable data setting, and (ii) it establishes a principled notion of the model\u2019s uncertainty.\nConsider a drug company exploring the efficacy of a new medication for headaches. The company runs a two-arm Randomised Control Trial (RCT) with 100 patients, 50 in each arm, comparing the new treatment with the current standard of care (in this case ibuprofen), and records the outcome Y \u2208{0, 1} whether patients are symptom-free four hours after treatment. It is important to note that in this setting, the distribution of outcomes is independent of the order in which the patients are observed, a property known as  ex\n\nIn contrast to prior work, our analysis focuses on one fundamental property of Bayesian learning systems for exchangeable data: the martingale property. In a nutshell, the martingale property describes the invariance of a model\u2019s predictive distribution with respect to missing data from a population. We will formally define and extensively explain the martingale property in \u00a7 2, but begin by intuitively describing two important and desirable consequences of it with an example, highlighting its relevance. These consequences are: (i) the martingale property is a necessary condition for rendering predictions unambiguous in an exchangeable data setting, and (ii) it establishes a principled notion of the model\u2019s uncertainty.\n\nConsider a drug company exploring the efficacy of a new medication for headaches. The company runs a two-arm Randomised Control Trial (RCT) with 100 patients, 50 in each arm, comparing the new treatment with the current standard of care (in this case ibuprofen), and records the outcome Y \u2208{0, 1} whether patients are symptom-free four hours after treatment. It is important to note that in this setting, the distribution of outcomes is independent of the order in which the patients are observed, a property known as  ex\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5335/5335051f-0d4a-458c-95a0-a3617fc10ef1.png\" style=\"width: 50%;\"></div>\nchangeability (see \u00a7 2 for a formal definition). Half-way into the trial, the company conducts an interim analysis. Define the interim observations D = {(x 1, y 1), . . . , (x 50, y 50)} where y k indicates outcome, and x k the treatment arm and other patient covariates. Given these observations, the company wants to decide whether to stop the trial early. The company uses an LLM, which was trained on potentially useful background information from the internet (e.g. on clinical trials, or the efficacy of ibuprofen), to generate the missing patients via ICL conditioning on x 1: n + k \u2212 1 for the (n + k)-th patient, and determines if the RCT is successful combining the observed and synthetic data. It repeats this imputation procedure J times, and decides to keep going with the trial if the fraction of symptom-free patients in the treatment over the control arm is above a certain threshold on average over these J hypothetical trials. Should we trust the LLM\u2019s prediction using ICL under this procedure?\nIn preview of our experimental results in \u00a7 4, the answer is \u2018No\u2019. Our experiments present evidence that state-of-the-art LLMs violate the martingale property in certain settings (see Fig. 1). The martingale property is a necessary condition for exchangeability, and in turn a fundamental property of Bayesian learning. If the martingale property is violated by an LLM performing ICL it implies that the model\u2019s predictions are not exchangeable, and hence that ICL with this LLM is not following any reasonable notion of probabilistic conditioning. This renders the LLM\u2019s predictive distribution incoherent: the model can make different predictions depending on the order in which the patients are imputed. This is problematic because by the design of an RCT, we know that there is no outcome dependence on the order of observations. It is incoherent and ambiguous to receive a different marginal predictions if we for example impute patient # 51 or patient # 100 first. Note that independent and identically distributed (i.i.d.) is a stricter condition implying exchangeability, and hence our work also applies to any i.i.d. data setting. This should caution the practitioner of the use of LLMs in exchangeable applications and data settings.\nBut there is a second reason why the martingale property is\n\ncrucial: it enables a principled interpretation of the  uncertainty of LLMs, allowing us to decompose inference into epistemic and aleatoric uncertainty (see \u00a7 2 for a detailed introduction). Revisiting the RCT example above, if we acquire data from the 50  remaining patients, a costly decision, can this substantially decrease (epistemic) uncertainty? What is the effect of acquiring additional features for each patient, e.g. a genetic predisposition, on the (aleatoric) uncertainty? \u2013 Without satisfying the martingale property, we have no understanding of the effect on reducing uncertainty in applications where additional data acquisition is feasible, for instance active learning or reinforcement learning. We cannot study the question \u2018why is the point prediction of my LLM imprecise\u2019 in a principled way, and the uncertainty of an LLM\u2019s predictive distribution remains opaque. This finding has important implications for safety-critical, highstakes applications of LLMs where trustworthy systems with a principled uncertainty estimate are vital.\nThis work states the hypothesis that ICL in LLMs given exchangeable data is Bayesian. Numerous works have argued that ICL approximates some form of Bayesian inference (Xie et al., 2021; Hahn & Goyal, 2023; Aky \u00a8 urek et al., 2022; Zhang et al., 2023b; Jiang, 2023) which we will carefully review in App. D, rendering this hypothesis natural. Our work introduces a novel perspective which contradicts their conclusion: we show that the martingale property, a fundamental property of Bayesian learning systems, is violated for state-of-the-art LLMs such as Llama2, Mistral, GPT-3.5 and GPT-4. We on purpose focus our analysis on three synthetic experiments where the ground-truth data generating process is simple and known, and which provide a useful test bed without the convolution of unknown latent effects as is typical in natural language. Our goal is to provide a scientific and precise framework which measures and quantifies the degree to which ICL of an LLM is Bayesian.\nMore specifically, our contributions are: (a) We motivate the martingale property as a fundamental property of Bayesian learning, crucial for unambiguous predictions of an LLM in exchangeable settings, and a principled interpretation of un\n\ncertainty in LLMs (\u00a7 2). (b) We derive actionable diagnostics with corresponding theory and test statistics of the martingale property for ICL. We also characterise the efficiency of ICL compared to standard Bayesian inference (\u00a7 3). (c) We provide novel evidence for violations of the martingale property through LLMs in certain settings, and a deviation of the sample efficiency of ICL relative to Bayesian systems, falsifying our hypothesis that ICL in LLMs is Bayesian and cautioning against the use of LLMs in exchangeable and safety-critical applications (\u00a7 4).\n\n# 2. What Characterises a Bayesian Learning System? A Martingale Perspective\n\nIn this section we rigorously formalise properties of an ICL system that follows Bayesian principles. Theoretical details and technical proofs are presented in App. A.\n\n# 2.1. The Martingale Property\n\nWe begin by defining the martingale property.\nDefinition 1. The predictive distributions for {Z i} satisfy the martingale property if for all integers n, k > 0 and realisations {z, z 1: n} we have\n\np M (Z n +1 = z | Z 1: n = z 1: n)= p M (Z n + k = z | Z 1: n = z 1: n). (1\n\n(1)\n\nEq. (1) states that {Z i} \u223c p M are conditionally identically distributed (Berti et al., 2004). As we will explain in \u00a7 2.3, this renders distributions {p M (Z n +1 = \u00b7| Z 1: n)} to form a martingale, hence the name \u2018martingale property\u2019.\nIt follows from Eq. (1) that predictive distributions of the form p M (Y n + k | X n + k, Z 1: n) satisfy a similar identity:\n\n(2)\n\nfor all integers n, k > 0, realisations {z 1: n, y}, and (almost every) realisation x measured by p M (X n +1 | Z 1: n = z 1: n). In Eq. (2)  the martingale property renders a model\u2019s predictions invariant to imputations of missing samples from the population (on average). Note that Eqs. (1) and (2) are equivalent in the unconditional case (x i = \u2205), which we consider in the majority of our experiments in \u00a7 4.\n\n# 2.2. The Martingale Property is Necessary for Unambiguous Predictions under Exchangeable Data\n\n# 2.2. The Martingale Property is Necessary for Unambiguous Predictions under Exchangeable\n\nTo understand the intuition behind the seemingly technical notion of the martingale property, consider two scenarios for ICL, illustrated in Fig. 2. In both scenarios,\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a7f7/a7f7223c-4506-44bf-9834-225552aae1e1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 2: The martingale property, a fundamental requirement of a Bayesian learning system, requires invariance with respect to missing samples from a population.\n</div>\nthe LLM is given the observed data (D, x n +1). In scenario 1, the LLM directly infers the predictive distribution p M (Y n +1 | Z 1: n = z 1: n, X n +1 = x n +1). In scenario 2, before making a prediction, the LLM generates (imputes) m \u2212 1 missing samples \u02c6 z n +2: n + m  from the population autoregressively. Given the observed data and the imputed samples as a prompt, we then sample from the LLM\u2019s predictive distribution p M (Y n +1 | Z 1: n = z 1: n, X n +1 = x n +1, Z n +2: n + m = \u02c6 z n +2: n + m). We repeat this imputation procedure J times and average the obtained predictive distributions to receive a Monte Carlo estimate of the righthand side of Eq. (2). Scenario 2 is of practical interest when estimating aggregated statistics of a population as illustrated in our RCT example in \u00a7 1. \u2013 The martingale property then states that the predictive distribution from scenario 1, p M (Y n +1 | Z n = z n, X n +1 = x n +1), and the predictive distribution from scenario 2, p M (Y n +1 | Z n = z n, x n +1, Z n +2: n + m = \u02c6 z n +2: n + m), when averaged over all possible imputations of \u02c6 z n +2: n + m are equivalent.\nWhy is the martingale property natural for any probabilistic system, and LLMs in particular? It is important to observe that all information about the distribution of X and Y  presented to the model (in addition to its prior belief (Zellner,\n1988)) lies in the observed data (D, x n +1). Imputing the samples \u02c6 z n +2: n + m should hence not change the predictive distribution for y n +1  when averaged over all possible imputations. This is precisely the core idea of the martingale property. If the predictive distribution for y n +1 changes on average, the model is \u2018creating new knowledge\u2019 when there is none: it is \u2018hallucinating\u2019. In preview of our experimental results in \u00a7 4, we observe this violation of the martingale property in state-of-the-art LLM families. We call this phenomenon introspective hallucinations: by querying itself, the model changes its predictions (on average), which as we\n\nshall see in \u00a7 2.4 violates how Bayesian systems learn.\n\nThere is another way in which predictions are rendered unambiguous: under exchangeability for which the martingale property is a necessary condition (see App. A) the model is invariant to the order of the observed and missing data. This requirement is vital if we know that the order of the underlying distributions is irrelevant, for instance because\u2014as in the RCT example in \u00a7 1\u2014we have designed the experiment such that we can exclude a dependency on the order. Formally, this concept is known as exchangeability. A sequence of random variables {Z i} \u223c p M is exchangeable if for all \u2113 \u2208 N and \u2113-permutations \u03c3,\n\n(3)\n\nExchangeability guarantees the invariance of predictions to the ordering of the observations Z 1: n, but also with respect to the order of future imputations Z n +1,... | Z 1: n. In the standard ICL setup, it is natural to assume that the sequence of example tuples in the ICL dataset, which is part of the prompt, is i.i.d. and thus exchangeable, and many influential works make this assumption (often without stating it explicitly) (Xie et al., 2021; Wang et al., 2023; Jiang, 2023). To understand the importance of this assumption further, consider the RCT example in \u00a7 1, where {Z 1:100} are (by experimental design) exchangeable. A model p M should hence satisfy\n\ntial works make this assumption (often without stating it explicitly) (Xie et al., 2021; Wang et al., 2023; Jiang, 2023). To understand the importance of this assumption further, consider the RCT example in \u00a7 1, where {Z 1:100} are (by experimental design) exchangeable. A model p M should hence satisfy\np M (Y n + k | X n + k = x, Z 1: n, X n +1: n + k \u2212 1 = \u02c6 x n +1: n + k \u2212 1) =\np M (Y n + k | X n + k = x, Z 1: n, X n +1: n + k \u2212 1 = \u02c6 x \u03c3 (n +1: n + k \u2212 1)),\nmeaning that the prediction for Y n + k | D, X n + k  is independent of the order of the imputed inputs \u02c6 x n +1: n + k \u2212 1. If a model p M  violates the above equality, there may be ambiguities in the prediction of the next sample (Y n + k, X n + k) as it may depend on and vary with the ordering. Such ambiguities would substantially undermine the credibility of predictions, as well as the downstream decision-making based on such procedures. The martingale property is connected to the above notions of invariance as a necessary condition for exchangeability. Furthermore, it can even ensure exchangeability of imputed samples as the observed sample size n becomes large, because Eq. (1)  implies asymptotic exchangeability of Z n +1,... | Z 1: n (Berti et al., 2004, Thm. 2.5).\n\nmeaning that the prediction for Y n + k | D, X n + k  is independent of the order of the imputed inputs \u02c6 x n +1: n + k \u2212 1. If a model p M  violates the above equality, there may be ambiguities in the prediction of the next sample (Y n + k, X n + k) as it may depend on and vary with the ordering. Such ambiguities would substantially undermine the credibility of predictions, as well as the downstream decision-making based on such procedures. The martingale property is connected to the above notions of invariance as a necessary condition for exchangeability. Furthermore, it can even ensure exchangeability of imputed samples as the observed sample size n becomes large, because Eq. (1)  implies asymptotic exchangeability of Z n +1,... | Z 1: n (Berti et al., 2004, Thm. 2.5).\n\n# 2.3. The Martingale Property Enables a Principled Notion of Uncertainty\n\nThe second desirable and important consequence of the martingale property is that it establishes a principled notion of uncertainty in the model\u2019s predicitive distribution. More specifically, it allows us to decompose this uncertainty, enabling us to study and interpret the uncertainty of a model.\nTo simplify the exposition, suppose the variables Z i are discrete and have A <\u221e realisations (both standard in\n\nLLMs) 1, so that any distribution p \u03b8 (Z = \u00b7) can be identified by a vector \u03b8 \u2208 R A. Let \u03b8 n denote the random vector that indexes p M (Z n +1 | Z 1: n). Then, the martingale property is equivalent to stating that {\u03b8 n} form a martingale w.r.t. the filtration defined by {Z n}. Under boundedness conditions always satisfied in the above case, Doob\u2019s theorem (Doob,\n1949) states that \u03b8 n converges almost surely to a random vector \u03b8 \u221e, and we have \u03b8 n = E \u03b8 \u221e | Z 1: n \u03b8 \u221e, or equivalently,\n\nNote the similarity of Eq. (4) with Bayesian inference: th Bayesian posterior predictive distribution has the form\n\nThe random vector \u03b8 \u221e plays the same role as the parameter \u03b8  in a Bayesian model, as both determine a predictive distribution (p \u03b8 \u221e (Z) or p (Z | \u03b8)). They are thus interchangeable for prediction purposes. Moreover, if p M is defined through Bayesian inference over \u03b8, p \u03b8 \u221e will define the same distribution over Z as p (\u00b7| \u03b8) (see App. B.1). Therefore we refer to the distribution \u03b8 \u221e | Z 1: n as the martingale posterior.\n\n1. epistemic uncertainty, which is about the latent \u03b8 \u221e and can be reduced if more data is available; and\n2. aleatoric uncertainty, which is irreducible given a fixed set of features even if infinite samples are observed and all aspects of the data generating process, namely the latent \u03b8 \u221e, are known.\n\nThe close connection between Eqs. (4) and (5) shows that this decomposition of uncertainty is established by the same foundations as in Bayesian inference. This is particularly relevant for LLMs which lack clearly stated, interpretable and verifiable assumptions (such as a prespecified statistical model), rendering their predictive distribution a \u2018black-box\u2019.\nImportantly, we can construct the martingale posterior solely using path samples from p M: we can sample from p (\u03b8 n + k | Z 1: n) simply by sampling Z n +1: n + k \u2212 1 | Z 1: n as lim k \u2192\u221e \u03b8 n + k = \u03b8 \u221e. Alternatively, we can also estimate parametric models on the path samples as proposed in Fong et al. (2021) (see App. B.1  for further details). This construction is an appealing tool for interpreting black-box models such as LLMs.\n\nThe interpretable decomposition of uncertainty further provides actionable guidance on how the combined uncertainty can be reduced: We can collect more samples to reduce epistemic uncertainty in scenarios where this is possible such as\n\nactive learning, reinforcement learning or healthcare; particularly in regions of the input space where the uncertainty is high. In \u00a7 3.3 we propose diagnostics to check if epistemic uncertainty decreases w.r.t. training sample size. On the contrary, if the aleatoric uncertainty is high and ought to be reduced, we cannot do so without \u2018changing the problem\u2019, for instance by collecting more features for each data point. This principled notion of uncertainty in a model is crucial in safety-critical, high-stakes scenarios for building trustworthy systems.\n\nExample 1. Suppose Z i \u2208 {0, 1}. Then \u03b8 \u221e = (\u03b8 \u221e, 0, \u03b8 \u221e, 1) \u2208 R 2, and p \u03b8 \u221e = Bern(\u03b8 \u221e, 1). Thus, in both Eq. (4) and Eq. (5)  the epistemic uncertainty is represented by a distribution over the Bernoulli parameter, revealing their inherent connection. The epistemic uncertainty is especially important in scenarios where we use a black-box model p M to impute the missing samples {Z n + i} from a population \u2014as in the RCT example in \u00a7 1\u2014 and want to quantify a model\u2019s lack of knowledge about the population. Note this distribution is not identifiable if we only have samples from a single-step predictive distribution p M (Z n +1 | Z 1: n), but becomes identifiable given sample paths.\n\n# 2.4. On the Link between the Martingale Property and Bayesian Learning Systems\n\nSo far, we asserted that the martingale property is fundamental to a Bayesian ICL system. In this subsection, we want to further formalise this. We have already discussed the close connection between the martingale property, exchangeability (\u00a7 2.2), and uncertainty (\u00a7 2.3). We will now show that for ICL on i.i.d. data, exchangeability, for which the martingale property is a necessary condition, and Bayesian inference are closely connected, equivalent conditions.\n\nICL typically assumes i.i.d. observations Z 1: n, which is our primary focus in this work (see \u00a7 2.2). Therefore, a correctly specified Bayesian model should produce marginal predictive distributions of the form\n\n(6)\n\n(7)\n\nHere, \u03b8 denotes the parameter of a Bayesian model, \u03c0  denotes the prior measure and p M (Z = \u00b7 | \u03b8) denotes the likelihood. From the factorisation over the data dimension n in (7), we can see that it is invariant with respect to permutations of z 1: n, and thus the left-hand side of the equation in (6) is invariant, too. It then follows that {Z i} \u223c p M satisfies\n\nEq. (3), and thus {Z i} are exchangeable. The converse is also true by de Finetti\u2019s representation theorem (De Finetti,\n1929): Under mild regularity conditions any p M  that defines exchangeable {Z i} must have a representation in the form of Eq. (7). It then follows that the predictive distribution p M (Z n +1 | Z 1: n) has the form of a Bayesian posterior predictive distribution,\n\nand can thus be viewed as implicit Bayesian inference for the latent variable \u03b8 (Husz \u00b4 ar, 2022). In conclusion, ICL on i.i.d. data corresponds to a Bayesian model that assumes (conditionally) i.i.d. observations if and only if it defines an exchangeable sample sequence. Since the martingale property is a necessary condition for exchangeability, an ICL system not satisfying the martingale property cannot be Bayesian.\n\n# 3. Probing Bayesian Learning Systems through Martingales\n\nIn this section we introduce practical diagnostics to probe if LLMs match the behaviour of Bayesian learning systems.\n\n# 3.1. Are All Deviations from Bayes Bad? \u2013 Expected and Acceptable Deviations from Bayesian Reasoning\n\nNumerous properties are implied if a learning system satisfies the martingale property, a distributional characteristic, and it is both infeasible and unnecessary as often practically irrelevant to check all of them in order to provide evidence for or against our hypothesis. For example, the martingale property implies that all conditional moments should be equivalent, i.e. E (Z l n \u2032 +1 | Z 1: n) = E (Z l n \u2032 + k | Z 1: n)  for all integers n, n \u2032, k, l > 0 and n \u2032> n, yet higher-order moments are not vital in most applications and hence are acceptable deviations, if existent. Therefore, we will restrict our attention to two key implications of the martingale property which\u2014if present\u2014have important practical consequences.\nPretrained LLMs are general-purpose models and can at best approximate Bayesian learning via ICL. The martingale property is an invariance that is not hard-coded in their transformer-based architecture, and can only be approximately (rather than exactly) satisfied. Let us assume that an LLM internally maintains a \u2018hierarchy of states\u2019 (Wang et al., 2023), say a hierarchical Bayesian model, capturing different tasks (e.g. Bayesian ICL from i.i.d. data, or acting in a dialogue system), and at each sampling step first updates its belief about this state. Say there is a probability p that the LLM deviates from Bayesian ICL or simply fails to approximate. Even if p  is small, the probability of a deviation 1 \u2212 (1 \u2212 p) m becomes substantial when accumulated over a long sampling path of length m. In early experiments, we\n\nobserved frequent poor approximations for long sampling paths (see Fig. 11 in the Appendix). This would trivially falsify the martingale property and our hypothesis.\nIn our experiments in \u00a7 4, we hence restrict the sampling paths to a short, finite length where we check the martingale property. We also design our checks to be robust against such behaviour, for example by removing outliers before computing a test statistic. Furthermore, we are particularly interested in stark and unequivocal evidence of the model violating the martingale property beyond an expected error of any approximating model. We will analyse and quantify violations of the martingale property with diagnostics, which we introduce in \u00a7 3.2, in order to check our hypothesis experimentally. In App. B.3 we derive the order of \u2018acceptable violations\u2019 for the test statistics we will introduce.\n\n# 3.2. Diagnostics for the Martingale Property\n\nAs we showed in \u00a7 2.4, the martingale property is fundamental to a Bayesian learning system. In this work, we probe the martingale property in LLMs via two properties implied by it. If these implied properties are strongly violated, so is the martingale property. More specifically, we will derive implications involving conditional expectations of the form E (f (Z n +1: n + m) | Z 1: n), which can be estimated by generating sample paths {z (j) n +1: n + m \u223c p M (Z n +1: n + m | Z 1: n = z 1: n)} J j =1 autoregressively with an LLM, and use these samples to form Monte Carlo estimates of the conditional expectations. We begin with an equivalent characterisation of the (conditional) martingale property. Proposition 1. A sequence {Z n +1: n + m} \u223c p M (\u00b7| Z 1: n) satisfies the martingale property if and only if the following holds: for all n \u2032, k \u2208 N and integrable functions g, h:\n\n(8)\n\nWe now state two implications of Proposition 1, our two diagnostics of the martingale property, which we will check experimentally in \u00a7 4. Corollary 1. Let {Z i: i \u2208 N} be a sequence of random variables satisfying the martingale property. Then for all integers n, n \u2032, k > 0 and n \u2032> n it holds that:\n\n(ii)\n\nProperties (i) and (ii) are derived from Proposition 1 by making different choices of the functions (g, h). Property (i) follows by setting h (Z n +1: n \u2032) \u2261 1 and examines the marginal predictive distributions p M (Z n + k | Z 1: n). We instantiate (i) using (at most) two choices of g: In preview of \u00a7 4, we will perform our checks on unconditional experiments where Z i\u2014or equivalently Y i  because of the unconditional setting\u2014are Bernoulli or Gaussian distributed\n\nrandom variables. In the Bernoulli experiment it suffices to choose the identity function g (z) = z, as the mean E (Z n + k | Z 1: n)  provides full information about the distribution p M (Z n + k | Z 1: n). In the Gaussian experiment, we will observe that choosing g (z) = z and g (z) = z 2 is in most cases sufficient to reveal substantial violations from the martingale property.\nProperty (ii) is equivalent to requiring Eq. (8) to hold for all linear functions (g, h), which follows by linearity of the functions and the conditional expectation. We will again see in our experiments that this choice is usually sufficient to reveal deviations from the martingale property. Let us further consider our choices for h and g with an example.\nExample 2. Suppose p M is a Bayesian learning system over a latent parameter \u03b8 (see Eq. (7)), and the respective likelihood p (Z | \u03b8) satisfies E Z \u223c p (Z | \u03b8) Z = \u03b8. Then by Corollary 1, for all (k, n \u2032) we have\n\n\u2022 E (Z n + k | Z 1: n) = E (\u03b8 | Z 1: n), and \u2022 E (Z n \u2032 + k +1 Z \u22a4 n \u2032 +1 | Z 1: n) = E (\u03b8\u03b8 \u22a4 | Z 1: n) (see e.g. Ghosal & Van der Vaart, 2017, p. 454).\n\nIn this setting, condition (i) (with g (z) = z) and (ii) thus guarantee that the conditional mean and covariance equal the posterior mean and covariance, respectively, independent of the indices (n \u2032, k). These two important aspects of the posterior are hence consistently expressed by the model. The example is especially relevant as it covers Bernoulli (p (Z | \u03b8) = Bern(\u03b8)) and Gaussian data, which will be our main focus in the experiments.\n\nIn App. C we present aggregated statistics T 1,g and T 2,k to compute and empirically measure properties (i) and (ii) from sample paths generated by an LLM. In our experiments, we check if these statistics lie within bootstrapped confidence intervals obtained by a reference Bayesian predictive model, which is readily available in synthetic settings, through the same sampling procedure. We will refer to these comparisons as \u2018checks\u2019 of the martingale property. If T 1,g and T 2,k lie outside the confidence interval, properties (i) and (ii) and hence the martingale property are violated.\n\n# 3.3. Diagnostics for Epistemic Uncertainty\n\nAs discussed in \u00a7 2.3, the martingale property allows us to identify epistemic uncertainty, which should decrease with more observed samples. Here, we derive a third diagnostic for Bayesian ICL systems which probes this. We begin by presenting a theoretical fact which provides important intuition on the role of epistemic uncertainty.\n\nFact 1. Let \u03c0 (\u03b8) and p M (Z | \u03b8) be the prior and likelihood of a Bayesian model, \u00af \u03b8 n:= E \u03b8 \u223c \u03c0 (\u03b8 | z 1: n) \u03b8 the posterior\n\nmean given data z 1: n, and \u2225\u00b7 \u2225 be any vector norm. Then,\n\n(9)\n\nThe left-hand side in Eq. (9)  is the trace of the posterior covariance (variance) and thus measures epistemic uncertainty. The right-hand side is the estimation error for the true parameter. Thus, Fact 1 states that epistemic uncertainty provides a quantification for the average-case estimation error. Note that Eq. (9) only applies to data from the prior predictive distribution, and thus not necessarily to the real observations. Nonetheless, a significant deviation of a model from the known scaling behaviour of the estimation error will indicate non-conformance with any reasonable Bayesian models. This is precisely our starting point to derive another diagnostic for Bayesian ICL systems.\nAs discussed in \u00a7 2.3, we use sample paths generated by an LLM to approximate a martingale posterior and estimate its epistemic uncertainty. Here, we characterise epistemic uncertainty through the trace of the posterior covariance of the martingale posterior, the \u2018spread\u2019 of the distribution. Because the sample paths we use are finite (see \u00a7 3.1) we cannot study the exact martingale posterior directly, which can only be recovered with infinite samples. Instead, we study the sampling distribution of the maximum likelihood estimate (MLE) on the first m samples: \u02c6 \u03b8 m:= arg max \u03b8 \u2208 \u0398 \ufffd m i =1 log p \u03b8 (Z n + i), where p \u03b8 is the known parametric likelihood. We measure the spread of this distribution using its inter-quartile range\n\n(10)\n\nwhere \u02c6 \u03b8 (j) m denotes the MLE using the j-th sample path {z (j) n + i} m i =1, and Q 0. 25 and Q 0. 75 are the 0. 25- and 0. 75 quantiles. In our experiments in \u00a7 4 we consider scenarios where the true data distribution is defined by regular parametric models. In such cases the optimal (squared) estimation error for the true parameter scales O (d/n) where n is the ICL dataset size and d is the dimension of the parameter, which is also the minimax lower bound (Van der Vaart, 2000, Ch. 8). When choosing m = \u0398(n), a reference Bayesian model will also have the O (d/n)  scaling behaviour following classical posterior contraction results in statistics; see App. B.2. Therefore, we can compare the asymptotic scaling of T 3 between an LLM and a reference Bayesian parametric model through the same sampling-based procedure. If the scaling behaviour of T 3 from our LLM deviates from that of the reference Bayesian model, we can conclude that the LLM either exhibits a marked loss of estimation efficiency, or does not maintain a correct notion of epistemic uncertainty at all. Both characteristics contradict a Bayesian ICL system and are undesirable.\n\n# 4. Experimental Analysis on LLMs\n\nIn this section, we experimentally probe whether ICL in state-of-the-art LLMs is Bayesian using the diagnostics discussed in \u00a7 3 and corresponding test statistics T 1,g, T 2,k, T 3. We provide our code base on https://github.com/ meta-inf/bayes_icl.\n\n# 4.1. Experiment Setup\n\nWe consider three types of synthetic datasets z 1: n:\n\n\u2022 Bernoulli: Z i \u223c Bern(\u03b8), where \u03b8 \u2208{0. 3, 0. 5, 0. 7}; \u2022 Gaussian: Z i \u223cN (\u03b8, 1), where \u03b8 \u2208{\u2212 1, 0, 1};\n\n\u223cN \u2208{\u2212} \u2022 A synthetic natural language experiment representing a prototypical clinical diagnostic task, where Z i = (X i, Y i) indicate the presence or absence of a symptom and disease as a text string for the i-th patient, respectively. Further, X i \u223c Bern(0. 5), Y i | X i \u223c Bern(0. 3 + 0. 4 X i).\n\nOn purpose, we reduce our experimental setup to these minimum viable test beds where the ground-truth latent parameters are known, stripping away the convoluted latent complexity of in-the-wild NLP data. We use the following LLMs: llama-2-7B with 7B parameters (Touvron et al., 2023), mistral-7B (Jiang et al., 2023), gpt-3 (Brown et al., 2020) with 2.7B and 170B parameters, gpt-3.5, and gpt-4 (OpenAI, 2023) 2.\n\nIn all experiments we compute test statistics on LLM samples, and compare their behaviour with the same statistics evaluated on samples from a reference Bayesian model. More specifically, in \u00a7 4.2 we compare the statistics obtained from LLMs with the bootstrap confidence intervals (CIs) derived from the reference Bayesian model. A deviation will thus indicate that the LLM is unlikely to be a good approximation of the reference Bayesian model. More importantly, when n becomes moderately large, the Bernsten von-Mises theorem (Van der Vaart, 2000) applies: the deviations then imply that the LLM is highly likely deviating from all reasonable Bayesian models, namely those satisfying the regularity conditions of the theorem. This is because the theorem guarantees that the test statistics derived from all such models have asymptotically 3 equivalent distributions.\nWe refer to App. C.1 for additional experimental details, such as the prompt format, tokenization, and computational requirements, as well as additional experimental results.\n\n2 We only use gpt-4 in a subset of experiments (Fig. 3, Fig. 5\nin the text) due to API and resource limitations (App. C.1). 3 We note that the asymptotic equivalence results are relevant in our setting. As a concrete example, in the setting of Fig. 3 (a), the CIs obtained by using Beta(1, 11) and Beta(1, 1) as the reference model are practically indistinguishable; the difference is on the order of 10 \u2212 4.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/750f/750f25e2-2f6f-4b25-a8be-b756db0db52f.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Checking the martingale property on Bernoulli experiments. Each data point represents a test statistic (y-axis) or an LLM, as derived in \u00a7 3.2. Subplot and x-axis correspond to choices of Bernoulli probabilities and LLMs. cates the 95% confidence interval from a reference Bayesian model.\n</div>\n# 4.2. Checking the Martingale Property\n\nWe first check if state-of-the-art LLMs satisfy the martingale property. As we discussed in \u00a7 2, this is a necessary condition for an exchangeable Bayesian ICL system.\n\nBernoulli experiment. Fig. 3 reports the results of the Bernoulli experiments with n = 50 observed samples, LLM sample paths of length m \u2208{n/ 2, 2 n}, and datasets with ground-truth mean \u03b8 \u2208{. 3, . 5, . 7}. As discussed in \u00a7 3.2 and \u00a7 4.1 above, we compute the test statistics T 1,g and T 2,k on J sample paths generated by an LLM, and compare them with bootstrap CIs (of high confidence, see scale of y-axis) obtained from a reference Bayesian model. Here we define the reference model using a Bernoulli likelihood and a non-informative Beta(1, 1) prior.\nFor short sample paths of length m = n/ 2 (subplots (a) and (b)), most LLMs lead to test statistics that are generally within the respective CIs, with the main exception being gpt-4 (\u03b8 \u2208{0. 3, 0. 5}), indicating a mostly adherence to the martingale property. However, for longer sample paths with m = 2 n  (subplots (c) and (d)), more frequent deviations from the CIs are observed. For brevity, full results for other choices of n and LLMs are deferred to App. C.2. The findings are generally consistent across all choices of n. We also observe gpt-3.5 to perform better than gpt-4 but worse than gpt-3-170b. As we discuss in App. C.2 the latter observation may be explained by the fact that gpt-3.5 and gpt-4 have undergone instruction tuning (Ouyang et al., 2022). In summary, in the Bernoulli experiments the LLMs generally adhere to the martingale property in short sampling horizons, but in longer horizons demonstrate a significant deviation from the martingale property and hence the Bayesian principle.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/a7c6/a7c6abaa-593c-4052-82ff-64170d970f1d.png\" style=\"width: 50%;\"></div>\nGaussian experiment. In Fig. 4 we present results on the Gaussian experiment with \u03b8 = \u2212 1, n = 100, m =\n\nn/ 2, again performing both checks of the martingale property and using a reference Bayesian model with the noninformative prior N (0, 100). As we can see, all models except gpt-3.5  demonstrate clear deviation from the martingale property. Additional results for gpt-3.5 in App. C present our diagnostics with other choices of (n, m, \u03b8), demonstrating a deviation from the predictive distribution of the reference Bayesian posterior. In conclusion, the presented evidence on the Gaussian experiment falsifies our hypothesis of Bayesian behaviour with the tested LLMs.\n\n<div style=\"text-align: center;\">Figure 4: Checking the martingale property on Gaussian experiments. We present runs with \u03b8 = \u2212 1, n = 100, m = 50 from different LLMs (x-axis) with test functions g (z) = z and g (z) = z 2. See Fig. 3 for further details.\n</div>\nFigure 4: Checking the martingale property on Gaussian experiments. We present runs with \u03b8 = \u2212 1, n = 100, m = 50 from different LLMs (x-axis) with test functions g (z) = z and g (z) = z 2. See Fig. 3 for further details.\n\nSynthetic natural language experiment. In Fig. 5 we present our results for the natural language experiment with n = 80, m = 40, g (z) = z using the GPT models. Here, we compute the test statistics on samples separated by the Bernoulli-distributed value of X i (see App. C.1 for details). As we can see, both gpt-3.5 and gpt-4 demonstrate deviation from a reference Bayesian posterior. This provides further evidence of violations of the martingale property in settings where natural language (instead of numbers) is used.\n\n# 4.3. Checking Epistemic Uncertainty of LLMs\n\nIn this subsection we analyse the scaling behaviour of an LLM\u2019s uncertainty. In Fig. 6 we measure T 3  (y-axis on a logscale) and compare the approximate martingale posterior of\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/dfb4/dfb4a069-d9e6-4005-ba16-7528fb212193.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(b) GPT-3.5\n</div>\n<div style=\"text-align: center;\">(c) GPT-4\n</div>\nFigure 5: Checking the martingale property on the natural language experiment. We present both checks with test statistics computed separately for each value of X i (x-axis). See Fig. 3 for further details.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/2cc1/2cc1bd91-bdc7-432a-8a79-4f4058d6984a.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Figure 6: Scaling of epistemic uncertainty on the Bernoulli experiment: the test statistic T 3 (\u00a7 3.3) computed on LLMs, compared with Bayesian and fractional Bayesian models.\n</div>\nFigure 6: Scaling of epistemic uncertainty on the Bernoulli experiment: the test statistic T 3 (\u00a7 3.3) computed on LLMs, compared with Bayesian and fractional Bayesian models.\n\nan LLM with a reference Bayesian model when increasing the number of observed samples n (x-axis). We consider a Bernoulli experiment with \u03b8 = 0. 5  as it is the only experimental setting where, with a short sampling horizon of m = n/ 2, all LLMs approximately adhere to the martingale property. In addition to the standard reference Bayesian model, we also consider two \u03b1-fractional Bayesian posteriors (Bhattacharya et al., 2019), which are generalisations of the Bayesian posterior that exhibit a O (d/\u03b1n) scaling for its epistemic uncertainty. They allow us to check the weaker hypothesis whether an LLM\u2019s epistemic uncertainty scales at least up to the correct order of magnitude.\nWe observe that the asymptotic rate of llama-2-7b and gpt-3.5 is slower than that of a Bayesian model, which suggests inefficiency as discussed in \u00a7 3.3. Furthermore, gpt-3.5 demonstrates over-confidence in the small-sample regime. The scaling of gpt-3-170b and mistral-7b are closer to the Bayesian model, even though not exactly matching the latter. This finding is interesting as on the Bernoulli experiments, gpt-3-170b and mistral-7b also demonstrate the best adherence to the martingale property.\n\n# 5. Conclusion\n\nIn this work we stated the martingale property as a fundamental requirement of a Bayesian learning system for exchangeable data, and discussed its desirable consequences if satisfied by an LLM. Based on this property we derived three different diagnostics that allowed us to check whether LLMs adhere to the Bayesian principle on synthetic incontext learning tasks. We presented stark evidence that state-of-the-art LLMs violate the martingale property, and hence falsified the hypthesis that ICL in LLMs is Bayesian.\nOur investigation is particularly relevant to a recent line of work that investigates LLM-based ICL for tabular data modelling: for prediction on noisy tabular datasets (Manikandan et al., 2023; Yan et al., 2024), the martingale property would enable us to diagnose the predictive uncertainty; and for synthetic data generation (Borisov et al., 2022; H \u00a8 am \u00a8 al \u00a8 ainen et al., 2023; Veselovsky et al., 2023), it is vital to ensuring valid inference based on imputations of missing data (\u00a7 2.2). It is thus of practical interest to develop models that better adhere to the martingale property.\nThe primary limitation of our work is the (intentional) restriction to small-scale, synthetic datasets, which are different from common NLP applications. We note that while our diagnostics are designed for synthetic problems, they reflect a broader principle: Bayesian epistemic uncertainty can be extracted from black-box models by examining the correlation structure in sequential predictions. This is clearly shown by the variance estimator in Example 2, and by the fact that MLE on sampled paths approximates the Bayesian posterior (\u00a7 3.3). Future work could investigate generalisations of this approach.\nMore broadly, the RCT example in \u00a7 1 can arguably be viewed as the simplest type of decision task involving multistep reasoning, as the right decision (here based on an average treatment effect) is only naturally determined after imputing all missing samples. Thus, it would be interesting to investigate analogies to the hallucination behaviour we have identified for ICL in more complex reasoning tasks such as those involving chain-of-thought prompting (Wei et al., 2022). Lastly, it may be worth to consider fine-tuning objectives to achieve an idealised Bayesian behaviour with a model after pretraining, but before deployment.\n\n# Impact Statement\n\nThis paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here. We refer to App. E for further discussion.\n\n# Acknowledgments\n\nFabian Falck acknowledges the receipt of studentship awards from the Health Data Research UK-The Alan Turing Institute Wellcome PhD Programme (Grant Ref: 218529/Z/19/Z). Ziyu Wang acknowledges support from Novo Nordisk. Chris Holmes acknowledges support from the Medical Research Council Programme Leaders award MC UP A390 1107, The Alan Turing Institute, Health Data Research, U.K., and the U.K. Engineering and Physical Sciences Research Council through the Bayes4Health programme grant.\n\nFabian Falck acknowledges the receipt of studentship awards from the Health Data Research UK-The Alan Turing Institute Wellcome PhD Programme (Grant Ref: 218529/Z/19/Z). Ziyu Wang acknowledges support from Novo Nordisk. Chris Holmes acknowledges support from the Medical Research Council Programme Leaders award MC UP A390 1107, The Alan Turing Institute, Health Data Research, U.K., and the U.K. Engineering and Physical Sciences Research Council through the Bayes4Health programme grant.\nThis research is supported by research compute from the Baskerville Tier 2 HPC service. Baskerville is funded by the EPSRC and UKRI through the World Class Labs scheme (EP/T022221/1) and the Digital Research Infrastructure programme (EP/W032244/1) and is operated by Advanced Research Computing at the University of Birmingham. We further acknowledge the receipt of OpenAI API credits through the OpenAI Researcher Access Program.\n\n# References\n\nAky \u00a8 urek, E., Schuurmans, D., Andreas, J., Ma, T., and Zhou, D. What learning algorithm is in-context learning? investigations with linear models. arXiv preprint arXiv:2211.15661, 2022.\nBai, Y., Chen, F., Wang, H., Xiong, C., and Mei, S. Transformers as statisticians: Provable in-context learning with in-context algorithm selection. arXiv preprint arXiv:2306.04637, 2023.\nBerti, P., Pratelli, L., and Rigo, P. Limit theorems for a class of identically distributed random variables. The Annals of Probability, 32(3), July 2004. ISSN 0091-1798. doi: 10.1214/009117904000000676.\nBhattacharya, A., Pati, D., and Yang, Y. Bayesian fractional posteriors. Annals of Statistics, 47(1):39\u201366, 2019.\nBiewald, L. Experiment tracking with weights and biases, 2020. URL https://www.wandb.com/. Software available from wandb.com.\nBorisov, V., Se\u00dfler, K., Leemann, T., Pawelczyk, M., and Kasneci, G. Language models are realistic tabular data generators. arXiv preprint arXiv:2210.06280, 2022.\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems, 33: 1877\u20131901, 2020.\nDe Finetti, B. Funzione caratteristica di un fenomeno aleatorio. In Atti del Congresso Internazionale dei Matematici:\n\nAky \u00a8 urek, E., Schuurmans, D., Andreas, J., Ma, T., and Zhou, D. What learning algorithm is in-context learning? investigations with linear models. arXiv preprint arXiv:2211.15661, 2022.\nBai, Y., Chen, F., Wang, H., Xiong, C., and Mei, S. Transformers as statisticians: Provable in-context learning with in-context algorithm selection. arXiv preprint arXiv:2306.04637, 2023.\nBerti, P., Pratelli, L., and Rigo, P. Limit theorems for a class of identically distributed random variables. The Annals of Probability, 32(3), July 2004. ISSN 0091-1798. doi: 10.1214/009117904000000676.\nBhattacharya, A., Pati, D., and Yang, Y. Bayesian fractional posteriors. Annals of Statistics, 47(1):39\u201366, 2019.\nBiewald, L. Experiment tracking with weights and biases, 2020. URL https://www.wandb.com/. Software available from wandb.com.\nBorisov, V., Se\u00dfler, K., Leemann, T., Pawelczyk, M., and Kasneci, G. Language models are realistic tabular data generators. arXiv preprint arXiv:2210.06280, 2022.\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems, 33: 1877\u20131901, 2020.\nDe Finetti, B. Funzione caratteristica di un fenomeno aleatorio. In Atti del Congresso Internazionale dei Matematici:\n\nBologna del 3 al 10 de settembre di 1928, pp. 179\u2013190, 1929.\nDong, Q., Li, L., Dai, D., Zheng, C., Wu, Z., Chang, B., Sun, X., Xu, J., and Sui, Z. A survey for in-context learning. arXiv preprint arXiv:2301.00234, 2022.\nDoob, J. L. Application of the theory of martingales. Le calcul des probabilites et ses applications, pp. 23\u201327, 1949.\nFong, E., Holmes, C., and Walker, S. G. Martingale posterior distributions. arXiv preprint arXiv:2103.15671, 2021.\nGhosal, S. and Van der Vaart, A.  Fundamentals of nonparametric Bayesian inference, volume 44. Cambridge University Press, 2017.\nGriffiths, T. L. and Tenenbaum, J. B. Optimal predictions in everyday cognition. Psychological science, 17(9):767\u2013 773, 2006.\nGruver, N., Finzi, M., Qiu, S., and Wilson, A. G. Large language models are zero-shot time series forecasters. arXiv preprint arXiv:2310.07820, 2023.\nHahn, M. and Goyal, N. A theory of emergent in-context learning as implicit structure induction. arXiv preprint arXiv:2303.07971, 2023.\nH \u00a8 am \u00a8 al \u00a8 ainen, P., Tavast, M., and Kunnari, A. Evaluating large language models in generating synthetic hci research data: a case study. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pp. 1\u201319, 2023.\nHarris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., et al. Array programming with NumPy. Nature, 585(7825):357\u2013362, 2020.\nHunter, J. D. Matplotlib: A 2D graphics environment.  Computing in Science & Engineering, 9(3):90\u201395, 2007. doi: 10.1109/MCSE.2007.55.\nHusz \u00b4 ar, F. Implicit bayesian inference in large language models. https://www.inference.vc/implicit-bayesianinference-in-sequence-models/, 2022.\nJiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., Casas, D. d. l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023.\nJiang, H. A latent space theory for emergent abilities in large language models. arXiv preprint arXiv:2304.09960, 2023.\n\nJin, M., Wang, S., Ma, L., Chu, Z., Zhang, J. Y., Shi, X., Chen, P.-Y., Liang, Y., Li, Y.-F., Pan, S., et al. Time-llm: Time series forecasting by reprogramming large language models. arXiv preprint arXiv:2310.01728, 2023.\nKalai, A. T. and Vempala, S. S. Calibrated language models must hallucinate. arXiv preprint arXiv:2311.14648, 2023.\nKallenberg, O. Foundations of modern probability, volume 2. Springer, 1997.\nLi, Z., Zhu, H., Lu, Z., and Yin, M. Synthetic data generation with large language models for text classification: Potential and limitations. arXiv preprint arXiv:2310.07849, 2023.\nLu, Y., Bartolo, M., Moore, A., Riedel, S., and Stenetorp, P. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. arXiv preprint arXiv:2104.08786, 2021.\nManikandan, H., Jiang, Y., and Kolter, J. Z. Language models are weak learners, June 2023. URL http:// arxiv.org/abs/2306.14101. arXiv:2306.14101 [cs].\nMei, Y., Song, S., Fang, C., Yang, H., Fang, J., and Long, J. Capturing semantics for imputation with pre-trained language models. In  2021 IEEE 37th International Conference on Data Engineering (ICDE), pp. 61\u201372. IEEE, 2021.\nMin, S., Lewis, M., Zettlemoyer, L., and Hajishirzi, H. Metaicl: Learning to learn in context. arXiv preprint arXiv:2110.15943, 2021.\n\n# OpenAI. Gpt-4 technical report, 2023.\n\nOuyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al. Training language models to follow instructions with human feedback. Advances in neural information processing systems, 35:27730\u201327744, 2022.\nPanwar, M., Ahuja, K., and Goyal, N. In-context learning through the bayesian prism. In  The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum? id=HX5ujdsSon.\nPaszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., and Chintala, S. PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems, pp. 8024\u20138035, 2019.\n\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825\u20132830, 2011.\nRavent \u00b4 os, A., Paul, M., Chen, F., and Ganguli, S. Pretraining task diversity and the emergence of non-bayesian in-context learning for regression. arXiv preprint arXiv:2306.15063, 2023.\nShumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot, N., and Anderson, R. Model dementia: Generated data makes models forget. arXiv e-prints, pp. arXiv\u20132305, 2023.\nSingh, A. K., Chan, S. C., Moskovitz, T., Grant, E., Saxe, A. M., and Hill, F. The transient nature of emergent in-context learning in transformers. arXiv preprint arXiv:2311.08360, 2023.\nTang, R., Han, X., Jiang, X., and Hu, X. Does synthetic data generation of llms help clinical text mining? arXiv preprint arXiv:2303.04360, 2023.\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et al. Llama 2: Open foundation and finetuned chat models. arXiv preprint arXiv:2307.09288, 2023.\ntqdm contributors. Imageio. https://github.com/tqdm/tqdm, 2022.\nVan der Vaart, A. W. Asymptotic statistics, volume 3. Cambridge university press, 2000.\nVan Rossum, G. The Python Library Reference, release 3.8.2. Python Software Foundation, 2020.\nVeselovsky, V., Ribeiro, M. H., Arora, A., Josifoski, M., Anderson, A., and West, R. Generating faithful synthetic data with large language models: A case study in computational social science. arXiv preprint arXiv:2305.15041, 2023.\nWang, X., Zhu, W., Saxon, M., Steyvers, M., and Wang, W. Y. Large language models are latent variable models: Explaining and finding good demonstrations for incontext learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35: 24824\u201324837, 2022.\n\nVan Rossum, G. The Python Library Reference, release 3.8.2. Python Software Foundation, 2020.\n\nWes McKinney. Data Structures for Statistical Computing in Python. In St \u00b4 efan van der Walt and Jarrod Millman (eds.), Proceedings of the 9th Python in Science Conference, pp. 56 \u2013 61, 2010. doi: 10.25080/Majora-92bf1922-00a.\nWolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Scao, T. L., Gugger, S., Drame, M., Lhoest, Q., and Rush, A. M. Transformers: State-ofthe-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 38\u2013 45, Online, October 2020. Association for Computational Linguistics.\nXiao, Y., Liang, P. P., Bhatt, U., Neiswanger, W., Salakhutdinov, R., and Morency, L.-P. Uncertainty quantification with pre-trained language models: A large-scale empirical analysis. arXiv preprint arXiv:2210.04714, 2022.\nXie, S. M., Raghunathan, A., Liang, P., and Ma, T. An explanation of in-context learning as implicit bayesian inference. arXiv preprint arXiv:2111.02080, 2021.\nYan, J., Zheng, B., Xu, H., Zhu, Y., Chen, D., Sun, J., Wu, J., and Chen, J. Making pre-trained language models great on tabular prediction. In International Conference on Learning Representations, 2024.\nYe, N., Yang, H., Siah, A., and Namkoong, H. Pretraining and in-context learning IS bayesian inference a la de finetti. In  ICLR 2024 Workshop on Mathematical and Empirical Understanding of Foundation Models, 2024. URL https://openreview.net/forum? id=ttupfosvgx.\nZellner, A. Optimal information processing and bayes\u2019s theorem. The American Statistician, 42(4):278\u2013280, 1988.\nZhang, L., McCoy, R. T., Sumers, T. R., Zhu, J.-Q., and Griffiths, T. L. Deep de finetti: Recovering topic distributions from large language models. arXiv preprint arXiv:2312.14226, 2023a.\nZhang, Y., Zhang, F., Yang, Z., and Wang, Z. What and how does in-context learning learn? bayesian model averaging, parameterization, and generalization. arXiv preprint arXiv:2305.19420, 2023b.\nZhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, Z., et al. A survey of large language models. arXiv preprint arXiv:2303.18223, 2023.\nZhao, Z., Wallace, E., Feng, S., Klein, D., and Singh, S. Calibrate before use: Improving few-shot performance of language models. In International Conference on Machine Learning, pp. 12697\u201312706. PMLR, 2021.\n\nAppendix for Is In-Context Learning in Large Language Models Bayesian? A Martingale Perspective\n\n# A. Proofs of Theoretical Statements in the Main Text\n\nFact 2. Any exchangeable random sequence {Z i} must be conditionally identically distributed.\n\nProof. See, e.g., Berti et al. (2004, p. 2030).\n\n\nProposition 1. A sequence {Z n +1: n + m} \u223c p M (\u00b7| Z 1: n) satisfies the martingale property if and only if the following holds: for all n \u2032, k \u2208 N and integrable functions g, h:\n\n(8)\n\nProof.  It suffices to show the equivalence between the following three statements:\n\nThe equivalence between (i) and (ii) is trivial. We have (ii) \u21d2 (iii) because E ((g (Z n \u2032 + k) \u2212 g (Z n \u2032 +1)) h (Z n +1: n \u2032) | Z 1: n) = E (E (g (Z n \u2032 + k) \u2212 g (Z n \u2032 +1) | Z 1: n \u2032) h (Z n +1: n \u2032) |\nZ 1: n) (ii) = 0. To show (iii) \u21d2 (ii), for any \u03c3 (Z n +1: n \u2032) measurable set A let h:= 1 A be the respective indicator\nfunction, so that E ((g (Z n \u2032 + k) \u2212 g (Z n \u2032 +1)) 1 A | Z 1: n) (iii) = 0 = E (0 \u00b7 1 A | Z 1: n). Since this holds for all A, it follows by the definition of conditional expectation (Kallenberg,\n1997) that E (g (Z n \u2032 + k) \u2212 g (Z n \u2032 +1) | Z 1: n \u2032) = 0 a.s..\nCorollary 1. Let {Z i: i \u2208 N} be a sequence of random variables satisfying the martingale property. Then for all integers n, n \u2032, k > 0 and n \u2032> n it holds that:\n(i) E (g (Z n +1) | Z 1: n) = E (g (Z n + k) | Z 1: n)  for all integrable functions g, and\n(ii) E ((Z n \u2032 + k +1 \u2212 Z n \u2032 +1) Z \u22a4 n \u2032 | Z 1: n) = 0.\n\nProof. (i) follows by setting h (z n +1: n \u2032) \u2261 1 in (8). (ii) follows by setting g (z) = z, h (z n +1: n \u2032) = z n \u2032.\nFact 1. Let \u03c0 (\u03b8) and p M (Z | \u03b8) be the prior and likelihood of a Bayesian model, \u00af \u03b8 n:= E \u03b8 \u223c \u03c0 (\u03b8 | z 1: n) \u03b8 the posterior mean given data z 1: n, and \u2225\u00b7 \u2225 be any vector norm. Then,\n\n(ii)\n\nProof. This holds because \u03b8 and \u03b8 0  are conditionally independent and identically distributed given z 1: n, and \u00af \u03b8 n equals the conditional expectation of both random variables.\n\n# B. Further Discussion of Theory and Methodology\n\nB.1. Additional Background on Martingale Posterio\n\nIn \u00a7 2.3  we discussed the construction of martingale posteriors in the finite-support case. Here, we can construct the martingale posterior by sampling Z n +1: n + m | Z 1: n, which will determine a sample \u03b8 n + m | Z 1: n  as the parameter that indexes the predictive distribution p (Z n + m +1 = \u00b7| Z 1: n + m) = p \u03b8 n + m (\u00b7); and since \u03b8 n + m \u2192 \u03b8 \u221e as m \u2192\u221e, we can truncate the process at a large m \u226b n to obtain a good approximation for \u03b8 \u221e.\n\n1. Sample Z n +1: n + m \u223c p M (\u00b7| Z 1: n).\n2. Compute \u02c6 \u03b8 m:= arg max \u03b8 \u2208 \u0398 \ufffd m j =1 log p (Z n + j | \u03b8).\n3. Return \u02c6 \u03b8 m as an approximate sample from the martin gale posterior, defined as the conditional distribution of the pointwise limit lim m \u2192\u221e \u02c6 \u03b8 m given Z 1: n.\n\n\ufffd\n3. Return \u02c6 \u03b8 m  as an approximate sample from the martingale posterior, defined as the conditional distribution of the pointwise limit lim m \u2192\u221e \u02c6 \u03b8 m given Z 1: n.\n\nWe repeat this procedure to obtain multiple samples \u02c6 \u03b8 m from the martingale posterior in order to approximate its distribution (see Fig. 1 [Centre]). In the above, p (Z i | \u03b8) is the likelihood in the Bayesian parametric model. If {p M (Z n + j | Z 1: n + j \u2212 1)} \u221e j =1 corresponds to a certain posterior predictive defined by the same likelihood, and the model is such that maximum likelihood estimation is consistent, it follows from de Finetti\u2019s theorem (applied to Z n +1: | Z 1: n) and consistency that as m \u2192\u221e, \u02c6 \u03b8 m  will converge to a random variable \u02c6 \u03b8 \u221e (w.r.t. the norm and notion of convergence in consistency), and the distribution \u02c6 \u03b8 \u221e | Z 1: n must equal the Bayesian posterior. Applying the same procedure to a more general p M that satisfies Eq. (1) leads to the methodology in Fong et al. (2021).\nWe adopted this \u2018model-based\u2019 approach in \u00a7 3.3 and for computing the approximate martingale posterior in Fig. 1\n\n[centre]. Compared with the former approach, it is easier to implement on ICL tasks where each sample Z i is represented with multiple tokens and a correctly specified likelihood for the true observations is available; the latter is always true in our synthetic experiments. More importantly, when m is finite (and not \u226b n), only with this approach can we compare the sampling distribution of \u02c6 \u03b8 m | Z 1: n  across different p M, as we explain in the following. This is important in our experiments where we find the LLMs (at best) follow the martingale property within a horizon of m = \u0398(n).\n\n# B.2. Approximate Martingale Posteriors with Finite Paths\n\n# B.2. Approximate Martingale Posteriors with Finite\n\nWe have claimed that with a finite m, the spread of the approximate martingale posterior \u02c6 \u03b8 m defined as the MLE on m samples (see \u00a7 3.3, or above) is comparable between different choices of p M. We now substantiate on this claim.\n\nLet us first restrict to exchangeable (i.e., Bayesian) choices of p M. Consider de Finetti\u2019s representation for the posterior predictive measure: Z n +1,... | Z 1: n can be represented through\n\n\u03b8 \u221e \u223c \u03c0 (\u00b7| Z 1: n), Z n +1,... iid \u223c p (\u00b7| \u03b8 \u221e)\n\nwhere the measure \u03c0 (\u00b7| Z 1: n) equals the Bayesian posterior, which as discussed in \u00a7 B.1 equals the exact martingale posterior. Combining the above representation and the fact that \u02c6 \u03b8 m is a function of Z n +1: n + m leads to \u02c6 \u03b8 m \u22a5 Z 1: n | \u03b8 \u221e, and\n\nCov(\u02c6 \u03b8 m | Z 1: n)\n= E (Cov(\u02c6 \u03b8 m | \u03b8 \u221e) | Z 1: n) + Cov(E (\u02c6 \u03b8 m | \u03b8 \u221e) | Z 1: n)\n\u2248 E (Cov(\u02c6 \u03b8 m | \u03b8 \u221e) | Z 1: n) + Cov(\u03b8 \u221e | Z 1: n),\n\nwhere we dropped the term E (\u02c6 \u03b8 m | \u03b8 \u221e) \u2212 \u03b8 \u221e which is the bias of MLE and thus a higher-order term for regular models. Therefore, the (co)variance overhead Cov(\u02c6 \u03b8 m | Z 1: n) \u2212 Cov(\u03b8 \u221e | Z 1: n)  is, up to the first order, the average-case error of MLE on m i.i.d. samples when the true parameter is sampled from the posterior \u03c0 (\u00b7| Z 1: n). For regular models this is always \u0398(d/m), where the coefficient hidden in the \u0398 notation is also comparable across different p M as long as the Fisher information matrix evaluated at \u03b8 \u223c \u03c0 (\u00b7| Z 1: n) has a comparable value (e.g., across all choices of p M that satisfy consistency). As the martingale posterior covariance Cov(\u03b8 \u221e | Z 1: n) has the same \u0398(d/n)  scaling across all regular Bayesian models to which the Bernstein von-Mises theorem applies, with a choice of m = \u0398(n), any deviation in the scaling of Cov(\u02c6 \u03b8 m)\u2014from that of any regular Bayesian model\u2014must be attributable to a different scaling of the exact MP covariance, and thus a deviation from all regular Bayesian models.\n\nLastly, we note that while we focus on ICL models that are approximately Bayesian, the above discussion may also apply to general models that only satisfy the martingale property, since for those models Z n +1,... | Z 1: n  remains asymptotically exchangeable (Berti et al., 2004). Moreover, the above discussion applies to inter-quantile range (IQR) as well, because for asymptotically normal posteriors the IQR is proportional to the posterior standard deviation; and even for non-normal posteriors, the IQR should still have the same order as the posterior contraction rate by definition.\n\n# B.3. Acceptable Approximation Errors of Properties (i) and (ii) in Corollary 1\n\nEven when we restrict to a finite horizon m, there can still be expected deviations from Eq. (1), and thus those in Corollary 1, simply because Eq. (1) represents invariance conditions that are not \u201chard-wired\u201d in the LLM\u2019s architecture. Yet, small violations of these equalities should not have practical consequences. We now derive the order of what is an acceptable violation in the setting of Example 2.\nAs discussed in this example, the equalities in Corollary 1 guarantee the expressions for posterior mean and covariance for the parameter \u03b8 to have consistently defined values, regardless of the choices of (n \u2032, k). The posterior mean has the order of \u0398(1)  and requires the violation of Corollary 1 (i) to be o (1). The posterior covariance is generally \u2126(1 /n) and can be expressed through Example 2 as\n\nCov(\u03b8 | Z 1: n) = E (Z n +1 Z n + k | Z 1: n) \u2212 E (Z n + k | Z 1: n) 2.\n\nTherefore, it can have an approximately consistent value if the equalities in Corollary 1 hold approximately  up to an error of o (1 /n). Posterior mean and covariance are key quantities in the interpretation of predictive uncertainty, which in turn is a major benefit of the martingale property. Thus, we consider the above deviation to be acceptable as it already guarantees the approximately consistent interpretation of predictive uncertainty through the martingale property.\n\n# C. Additional Experimental Details and Results\n\nC.1. Additional Experimental Details\n\nTest statistics of properties implied by the martingale property. We summarise and empirically measure properties (i) and (ii) in Corollary 1 using the aggregated statistics\n\n(11)\n\n(12)\n\nThe statistics T 1,g and T 2,k are defined using samples {z (j) n + i} from J paths generated by an LLM via ICL and correspond to Monte-Carlo estimates of the expectations in properties (i) and (ii). To be robust against the possible outlier paths (\u00a7 3.1), we remove sample paths with anomalous mean absolute values using the standard 1.5 \u00d7 IQR rule.\nWe compare the observed value of the statistics above evaluated on LLMs with bootstrap confidence intervals computed using a reference Bayesian model (\u00a7 4.1). For the latter, we draw K = 300 sets of completions {{z (j,k) bs,n + i: 1 \u2264 i \u2264 m, 1 \u2264 j \u2264 J}: 1 \u2264 k \u2264 K}  from the predictive distribution of the reference Bayesian model, which provides K samples for the test statistics, and compute two-sided confidence intervals using the respective quantiles.\n\nExperimental setup. For the first two experiments we vary n \u2208{20, 50, 100}, m \u2208{n/ 2, 2 n} and sample J = 200 paths from the LLMs. For the natural language experiments we fix n = 100, m = 50, J = 80. As nonexchangeable models may demonstrate different behaviour on different permutations of the same dataset, for the experiments in \u00a7 4.2 we permute the observations when generating each sample path, so that we can produce a single test statistic that summarises each experiment configuration. For the experiments in \u00a7 4.3, however, we use a fixed ordering for the observations for all path samples within each run, and report the median inter-quartile range across 9 runs for each configuration. This change is made to avoid (possibly small) deviations from exchangeability from inflating the estimated spread of the posterior.\nFor a proper test of the martingale property, it is vital that the model cannot distinguish between the ICL training data Z 1: n and its own generations {Z n + i}. This is trivially true if the LLM takes free-form text as inputs without additional annotation, as with llama-2-7b, mistral-7b, and gpt-3.5 accessed through the Completion API from OpenAI. However, the gpt-4  model is only accessible through a different API (ChatCompletion) which includes annotation for user input and model generation in the prompt. To ensure a proper implementation of the checks, we hence call the API m times in generating each path sample. In each iteration we sample a single data point, and then append it to the user input part of the prompt. This is far less cost-efficient than our use of gpt-3.5. Therefore, we only include gpt-4 for the Bernoulli experiment with n \u2264 50, and the natural language experiment.\nWe discuss prompt design and format in detail below. Here we emphasise that across all tasks, the prompt always includes sufficient information about the true likelihood.\nPrompt design and format. We use the following\n\nPrompt design and format. We use the following prompt format <instruction> <observed data>\n\n<sampled data>. <instruction>  describes the distribution (i.e. true likelihood) of the observed data and importantly states that the observed samples were drawn i.i.d., i.e. from exchangeable random variables. <observed data> and <sampled data> lists the observed z 1: n, and sampled data \u02c6 z n + k (if there exists any), respectively. Samples are represented depending on the experiment: as int values as 1-digit characters (e.g. \u20181\u2019), float values with 1-digit of precision (e.g. \u20182.2\u2019) or words for synthetic natural language. As a sanity check, we also consider replacing integers with random words (e.g. \u2018tiger\u2019 for \u20181\u2019, \u2018hedgehog\u2019 for \u20180\u2019), but did not notice important differences in the LLMs\u2019 behaviour. Each sample is delineated by a separator (e.g. \u2018;\u2019).\nWe present exemplary prompts for each dataset below:\n\n# We present exemplary prompts for each dataset below:\n\n\u2022 A Bernoulli experiment with n = 5 and m = 2:  \u201cProvided are independent, identically distributed tosses of a coin, which flips 1 with probability p where p is unknown: 1;0,0,1,0,0;1\u201d.\n\n\u2022 A Gaussian experiment with n = 2 and m = 3:  \u201cProvided are independent, identically distributed draws from a Gaussian, with fixed but unknown mean and unit variance: 1.1,0.8,1.3,1.0,0.9\u201d.\n\nThe the natural language experiment: \u201cYou will make predictions for a novel disease. The observed dataset contains records for multiple subjects which are assumed to be independent and identically distributed. For each subject there are two binary variables, indicating fever and disease diagnosis, respectively. Output your prediction for the disease diagnosis of the next subject. \\ n Id: 0 \\ n Fever: Y \\ n Diagnosis: N ...\u201d\n\nOther work represents both int and float numbers as a space-separated string of digits with fixed precision, where each number is separated by a semi-colon. This guarantees a per-digit tokenisation that was observed to be beneficial in the context of time series forecasting and further minimises the required number of tokens per number as the decimal point is redundant (Gruver et al., 2023). We did not opt for this representation and corresponding tokenisation for two reasons: First, initial experiments with GPT-2 showed deteriorating sampling performance, where the model often hallucinated unrelated content. Second, and related to the first point, this representation is somewhat \u2018out-ofdistribution\u2019 and probably unseen in the training distribution, which could limit and constrain any conclusions made in our experiments. Note that because of the tokenisation, in \u00a7 4, the Gaussian experiment is more difficult than the Bernoulli experiment (or any dataset with single-token samples) as the LLM is required to learn the correlation structure between consecutive tokens representing a real-valued number.\n\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5109/5109b628-4296-4678-8b92-6d346d8c2bda.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(g) T 1,g for g (z) = z, n = 100, m = 200\n</div>\n<div style=\"text-align: center;\">ure 7: Checking the martingale property: results for the Bernoulli experiments for all choices of (n, m) in the settin. 3. Note that we drop gpt-4 for n = 100 due to API limitations (as discussed in App. C.1).\n</div>\nFigure 7: Checking the martingale property: results for the Bernoulli experime Fig. 3. Note that we drop gpt-4 for n = 100 due to API limitations (as discu\n\n<div style=\"text-align: center;\">(b) T 2,k for k \u2208{2, 3, 4, 5}, n = 20, m = 10\n</div>\n<div style=\"text-align: center;\">(d) T 2,k for k \u2208{2, 3, 4, 5}, n = 100, m = 50\n</div>\n<div style=\"text-align: center;\">(f) T 2,k for k \u2208{2, 3, 4, 5}, n = 20, m = 40\n</div>\n<div style=\"text-align: center;\">(h) T 2,k for k \u2208{2, 3, 4, 5}, n = 100, m = 200\n</div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/5606/5606ae48-3ed3-4547-b399-8a41c946d5e1.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/b66d/b66d2d2d-df82-4b8c-982e-8dca014a8785.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">(k) T 1,g for g (z) = z, n = 100, m = 200\n</div>\n<div style=\"text-align: center;\">(b) T 2,k for k \u2208{2, 3, 4, 5}, n = 20, m = 10\n</div>\n<div style=\"text-align: center;\">(d) T 2,k for k \u2208{2, 3, 4, 5}, n = 20, m = 10\n</div>\n<div style=\"text-align: center;\">(h) T 2,k for k \u2208{2, 3, 4, 5}, n = 20, m = 40\n</div>\n<div style=\"text-align: center;\">(j) T 2,k for k \u2208{2, 3, 4, 5}, n = 50, m = 100\n</div>\n<div style=\"text-align: center;\">(l) T 2,k for k \u2208{2, 3, 4, 5}, n = 100, m = 200\n</div>\nAdditional details for the natural language experiment. For the natural language experiment, we modify the scheme as follows: we split the ICL dataset and the imputations into two sequences ({Y i 0",
    "paper_type": "theory",
    "attri": {
        "background": "In-context learning (ICL) is a notable feature of Large Language Models (LLMs), allowing them to make predictions from observed datasets without fine-tuning. This paper explores the hypothesis that ICL can be understood as Bayesian inference, specifically through the martingale property, which is essential for making reliable predictions in Bayesian learning systems.",
        "problem": {
            "definition": "The central question is whether in-context learning in LLMs on exchangeable data can be approximated as Bayesian learning.",
            "key obstacle": "The main challenge is to validate the martingale property as a necessary condition for Bayesian inference, which is violated in certain LLMs."
        },
        "idea": {
            "intuition": "The idea stems from the observation that the martingale property is crucial for ensuring unambiguous predictions in exchangeable data settings.",
            "opinion": "The authors propose that ICL in LLMs should adhere to Bayesian principles to ensure coherent predictions.",
            "innovation": "The paper introduces a novel perspective by analyzing the martingale property in the context of ICL, contrasting with previous assumptions that ICL approximates Bayesian inference."
        },
        "Theory": {
            "perspective": "The theory presented revolves around the martingale property, which asserts that predictive distributions remain invariant to missing data.",
            "opinion": "The authors argue that if LLMs do not satisfy the martingale property, their predictions cannot be considered Bayesian.",
            "proof": "The paper derives conditions under which the martingale property holds, demonstrating its necessity for coherent predictions in exchangeable settings."
        },
        "experiments": {
            "evaluation setting": "The experiments utilize synthetic datasets, including Bernoulli and Gaussian distributions, and a natural language task, comparing the performance of various LLMs against a reference Bayesian model.",
            "evaluation method": "The authors employ statistical tests to check for adherence to the martingale property, analyzing the predictive distributions generated by the LLMs."
        },
        "conclusion": "The experiments provide evidence that state-of-the-art LLMs violate the martingale property, thus falsifying the hypothesis that ICL in LLMs is Bayesian.",
        "discussion": {
            "advantage": "This work highlights the importance of the martingale property in understanding the limitations of LLMs in safety-critical applications.",
            "limitation": "The primary limitation is the focus on synthetic datasets, which may not fully represent the complexities of real-world applications.",
            "future work": "Future research could explore how to develop LLMs that better adhere to the martingale property and investigate its implications in more complex reasoning tasks."
        },
        "other info": [
            {
                "info1": "The paper acknowledges funding from various research grants and institutions supporting the authors."
            },
            {
                "info2": {
                    "info2.1": "The authors provide their code base for the experiments on GitHub.",
                    "info2.2": "The findings have implications for the use of LLMs in clinical and decision-making applications."
                }
            }
        ]
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "In-context learning (ICL) is a notable feature of Large Language Models (LLMs), allowing them to make predictions from observed datasets without fine-tuning."
        },
        {
            "section number": "1.3",
            "key information": "The authors propose that ICL in LLMs should adhere to Bayesian principles to ensure coherent predictions."
        },
        {
            "section number": "3.2",
            "key information": "The theory presented revolves around the martingale property, which asserts that predictive distributions remain invariant to missing data."
        },
        {
            "section number": "3.3",
            "key information": "The paper derives conditions under which the martingale property holds, demonstrating its necessity for coherent predictions in exchangeable settings."
        },
        {
            "section number": "6",
            "key information": "The experiments provide evidence that state-of-the-art LLMs violate the martingale property, thus falsifying the hypothesis that ICL in LLMs is Bayesian."
        },
        {
            "section number": "6.1",
            "key information": "This work highlights the importance of the martingale property in understanding the limitations of LLMs in safety-critical applications."
        }
    ],
    "similarity_score": 0.7116675472292098,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-07-2330_in-co/papers/Is In-Context Learning in Large Language Models Bayesian_ A Martingale Perspective.json"
}