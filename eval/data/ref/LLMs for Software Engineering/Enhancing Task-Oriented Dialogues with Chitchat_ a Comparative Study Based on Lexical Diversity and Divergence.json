{
    "from": "arxiv",
    "scholar_id": null,
    "detail_id": "arXiv:2311.14067",
    "title": "Enhancing Task-Oriented Dialogues with Chitchat: a Comparative Study Based on Lexical Diversity and Divergence",
    "abstract": "As a recent development, task-oriented dialogues (TODs) have been enriched with chitchat in an effort to make dialogues more diverse and engaging. This enhancement is particularly valuable as TODs are often confined to narrow domains, making the mitigation of repetitive and predictable responses a significant challenge. This paper presents a comparative analysis of three chitchat enhancements, aiming to identify the most effective approach in terms of diversity. Additionally, we quantify the divergence between the added chitchat, the original task-oriented language, and chitchat typically found in chitchat datasets, highlighting the top 20 divergent keywords for each comparison. Our findings drive a discussion on future enhancements for augmenting TODs, emphasizing the importance of grounding dialogues beyond the task to achieve more diverse and natural exchanges. Index Terms\u2014 task-oriented dialogue, chitchat, response diversity, entropy, Jensen-Shannon\u2019s divergence",
    "bib_name": "stricker2024enhancingtaskorienteddialogueschitchat",
    "md_text": "# ENHANCING TASK-ORIENTED DIALOGUES WITH CHITCHAT: A COMPARATIVE STUDY BASED ON LEXICAL DIVERSITY AND DIVERGENCE\nArmand Stricker, Patrick Paroubek\nUniversit\u00b4e Paris-Saclay, CNRS, Laboratoire Interdisciplinaire des Sciences du Num\u00b4erique, 91400, Orsay, France\n# ABSTRACT\nAs a recent development, task-oriented dialogues (TODs) have been enriched with chitchat in an effort to make dialogues more diverse and engaging. This enhancement is particularly valuable as TODs are often confined to narrow domains, making the mitigation of repetitive and predictable responses a significant challenge. This paper presents a comparative analysis of three chitchat enhancements, aiming to identify the most effective approach in terms of diversity. Additionally, we quantify the divergence between the added chitchat, the original task-oriented language, and chitchat typically found in chitchat datasets, highlighting the top 20 divergent keywords for each comparison. Our findings drive a discussion on future enhancements for augmenting TODs, emphasizing the importance of grounding dialogues beyond the task to achieve more diverse and natural exchanges. Index Terms\u2014 task-oriented dialogue, chitchat, response diversity, entropy, Jensen-Shannon\u2019s divergence\n# 1. INTRODUCTION\nDeveloping dialogue systems that produce diverse responses is a significant and challenging task, particularly when it comes to task-oriented dialogues (TODs). Indeed, due to the specificity of task domains, such dialogues can easily become repetitive: there are only so many ways one can ask a user for their flight destination, for example. This is why language richness is commonly assessed when comparing dialogue datasets [1, 2] and evaluating response outputs [3, 4, 5], using measures such as the number of unique n-grams, Shannon\u2019s text entropy [6], and next-word conditional entropy [7]. To introduce as much natural diversity as possible, humangenerated responses are often collected. For instance, the MultiWOZ benchmark [8] adopts a human-human Wizardof-Oz style data collection method, while the SGD dataset [9] makes use of human annotators to rephrase dialogues generated based on schemas. To further diversify TODs, a recent approach has been to enhance them with chitchat [10, 11, 12]. As an illustrative example, mentioning a few interesting details about the user\u2019s\n979-8-3503-0689-7/23/$31.00 \u00a92023 European Union\nflight destination is likely to yield significant variation, due to the numerous possible destinations, and therefore make responses more engaging. We note that we consider lexical diversity and engagingness to be positively correlated. Intuitively, a higher level of lexical diversity leads to less predictable, more interesting responses, which in turn helps users be more engaged. Related research [13] has found that children who converse with high lexical diversity are perceived as more appealing, mature and talkative by adults. Furthermore, the addition of lexical diversity has been proposed as a means to improve system responses in chitchat conversations [14], where the primary objective is precisely to maintain user engagement [15]. Several approaches currently exist to enhance TODs with chitchat (Section 2.1), which include incorporating snippets of knowledge-based chitchat, adding complete chitchat exchanges, and including snippets generated by a chatbot trained on a chitchat dataset. It is not immediately clear however which approach is the most effective or which lexical qualities each type of chitchat contributes to TODs, as no cross-comparison has previously been preformed. This paper aims to bridge this gap by comparing three unique types of chitchat enhancements. To conduct this study, we utilize Shannon\u2019s text entropy and conditional entropy (Section 2.2) to measure the increased uncertainty (and therefore diversity) found in augmented responses. Additionally, we quantify the divergence between the task language, the added chitchat and typical chitchat, using Jensen-Shannon\u2019s divergence. This allows for a qualitative analysis of the top 20 most divergent tokens for each corpus comparison, shedding light on the most notable lexical contributions of each chitchat type. Finally, based on our findings, we engage in a discussion regarding the next steps to consider when enhancing TODs.\n# 2. EXPERIMENTAL SETUP\n# 2.1. Datasets\nFigure 1 showcases an illustrative example of each of the three enhancements assessed in our cross-comparison. We\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/91cd/91cd7ad3-66cf-467c-b062-4a653ce1cd3b.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">Fig. 1. Dialogue examples from each dataset.</div>\nalso consider responses from Blended Skill Talk (BST) [16], a comprehensive chitchat dataset, as a frame of reference for chitchat responses. Accentor [10] expands on the SGD dataset [9] and comprises 22,825 dialogues. The authors\u2019 approach is to automatically generate chitchat candidates additions using a chatbot trained on BST. These can then be appended or prepended to the original responses. To introduce more diversity, the authors automatically filter out frequently occurring candidates and rely on crowd workers to label the remaining candidates as good (ie. social or useful) or bad (ie. inappropriate or misleading). We refer readers to the paper for further details. Because the chitchat snippets are only candidates, we construct a corpus of augmented system responses by randomly selecting a good candidate when several are available and appending (resp. prepending) it to the original task utterance. If no candidates or only bad candidates are available, the task utterance remains unchanged. To assess the impact of random candidate selection, we repeat the process using 5 different seeds. We observe minimal impact (1e-4 standard deviation on each metric) and therefore only present the results for one seed. KETOD [12] also extends the SGD dataset. The chosen approach consists in incorporating chitchat explicitly grounded in Wikipedia into system responses. The methodology involves extracting all entities from each dialogue and employing a retrieval model to fetch the top two Wikipedia articles for each entity. To enrich the system responses, human annotators then select which turns to enhance and incorporate retrieved knowledge snippets, rephrasing the original response as needed. In cases where annotators find no suitable way to naturally enrich any turns, dialogues are skipped. This process results in a dataset consisting of 5,324 augmented dialogues.\nFusedChat [11] is developed using the well-known MultiWOZ corpus [8] as its foundation. The chosen approach aims to enhance dialogue diversity by incorporating chitchat exchanges to introduce or continue pre-existing TODs. This integration results in a reciprocal grounding between TOD and chitchat. The additional chitchat exchanges are created by human annotators: each annotator assumes the roles of both the system and the user, ensuring a natural flow in the conversation. In some cases, the original task utterances are rephrased to establish a better connection with the chitchat context. The resulting dataset comprises a total of 10,438 enriched dialogues. For our analysis, BST [16] serves as a comprehensive reference chitchat corpus, as it is designed to exemplify multiple qualities within each chitchat conversation. These qualities include being engaging, knowledgeable, and empathetic. Each conversation is initiated with predefined personas for both participants. Additionally, a pair of utterances is randomly selected from three different chitchat datasets as conversation starters: PersonaChat [17] focuses on maintaining consistent personas throughout the conversations, Wizard of Wikipedia [18] draws on expert knowledge sourced from Wikipedia, and EmpatheticDialogues [19] showcases conversations between a Speaker who discusses an emotional situation and a Listener who is tasked with responding in an empathetic manner.\n# 2.2. Metrics\nShannon\u2019s text entropy [6] quantifies the average uncertainty of selecting an n-gram from a corpus and has been used to measure lexical diversity in text [20] and in dialogues [2, 4]. Compared with simply counting unique n-grams, it also considers their frequencies and distribution, thereby offering a more precise measure of diversity. When view-\ning a corpus of responses as a probability distribution over n-grams, a higher entropy is indicative of more uniform distribution, implying greater uncertainties and therefore a higher lexical diversity. A lower Shannon text entropy suggests a more skewed distribution, meaning the corpus contains more frequently repeated n-grams, resulting in less diversity and more predictable responses. Conditional next-word entropy [7] gives an additional measure of diversity, quantifying the uncertainty of the next token in a sequence given the previous tokens. Typically, if the conditional next-word entropy is high, it implies multiple viable possibilities for the next token, and therefore more varied and diverse responses. On the other hand, a low conditional next-word entropy suggests a more constrained set of potential next tokens and therefore less diversity. Jensen-Shannon\u2019s Divergence (JSD) [21] is a symmetric version of the Kullback-Leibler divergence [22] that evaluates the overlap between two distributions. Based on unigrams, it is commonly used for corpus comparisons [23, 24], as it produces divergence scores at the corpus and token levels. The k tokens with the highest divergence scores can be extracted, along with the corpus within which they are most prevalent, allowing us to identify the key divergent words. Notably, while JSD has been utilized to analyze classroom conversations between teachers and students to assess uptake [25], its application to comparing collections of dialogue responses remains unexplored. Experiments are carried out using the lexical-diversity package 1.\n# 3. RESULTS\n# 3.1. Entropy\nOur findings reveal that the introduction of chitchat in KETOD and FusedChat significantly enhances diversity in these datasets, particularly as the n-gram lengths increase (Figure 2). However, despite these improvements, these diversity scores remain considerably lower than those of our reference chitchat responses: the augmented dialogues still exhibit more repetition compared with full-fledged chitchat conversations. This can be attributed to the fact that a limited number of tasks remain the focal point of these dialogues, preventing them from achieving the same level of diversity as the one observed during actual chitchat. Surprisingly, entropy scores for Accentor (task and augmented responses) show a remarkable similarity. Augmented responses even show slightly lower entropy in the case of unigram diversity. This unexpected observation signifies that responses containing chitchat exhibit a similar level of diversity (or repetition, depending on perspective) as responses without chitchat. This suggests that the chitchat snippets themselves do not possess significant variation, which could be\n1https://pypi.org/project/lexical-diversity\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/f45c/f45c4712-9d0f-4196-b980-08d1f77857a0.png\" style=\"width: 50%;\"></div>\nFig. 2. The bar chart presents the entropy for original and augmented responses for our three datasets, and BST. Considering that entropy is a logarithmic measure, the plot below the bar chart shows the uncertainty ratio between the original and augmented responses. For example, when considering trigrams, augmented responses in FusedChat contain approx. 1.89x more uncertainty than their purely task-oriented counterparts.\nattributed to the fact they are generated automatically. Indeed, chitchat systems such as the one used for candidate creation in Accentor tend to output less diverse responses compared with human-created snippets [14]. Furthermore, this result puts into perspective human evaluations conducted on this dataset, which indicate that augmented dialogues are perceived as more engaging. Given the positive correlation we established, we posit that the increase in engagingness is caused by the added chitchat\u2019s semantic qualities, rather than its diversity, which we explore in Section 3.4, To more intuitively grasp the differences in entropy, we plot the uncertainty ratios between the task and augmented responses. For trigrams, the augmented responses in FusedChat exhibit approximately 1.89x more uncertainty than the original task responses, while for Accentor, the augmented responses only show around 1.02x more uncertainty. Accentor\u2019s ratio remains relatively unchanged as we increase the n-gram size, while it tends to increase for FusedChat and KETOD. These findings suggest that among the approaches examined, the approach chosen in Accentor contributes little to\nno extra diversity in system responses, despite these responses being deemed more engaging by human evaluators.\n# 3.2. Conditional Entropy\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/06f7/06f7315b-9d9d-405b-b37f-2ba022866192.png\" style=\"width: 50%;\"></div>\nFig. 3. The bar chart presents the conditional entropy for original and enhanced responses, and BST. The plot below the bar chart should be read as in Figure 2.\nOur findings for conditional entropy (Figure 3) align with our previous results. With a context of a single token, guessing the next token is hardest for augmented responses in FusedChat. The increase in uncertainty is also highest (1.44x). Conversely, Accentor shows the lowest ratio (1.03x), suggesting no change in difficulty for next token prediction. Furthermore, as the context length is increased, a noticeable trend emerges where collections of responses with higher entropy demonstrate lower conditional entropy. This pattern is exemplified by the drastic drops observed in the bars representing BST as the context size increases. This phenomenon can be explained by the fact that as we consider longer ngrams, these typically become more numerous and diverse. In that case, knowing the preceding n-1 tokens provides substantial information, thereby increasing the predictability of the next token. When the context length is set to 2, the uncertainty ratio for KETOD drops below the threshold of 1, indicating more certainty in predicting the next token when the responses are\naugmented. Considering our previous observation, this suggests the presence of a larger variety of n-grams. In the case of Accentor, the uncertainty ratios only minimally decrease. Even with a context length of 3, Accentor demonstrates the highest ratio (0.99x), showing that the predictability of the next token remains unaffected and that the added chitchat does not introduce many unique 4-grams. This finding implies that the approach employed by Accentor does not yield a noticeable change in diversity, which aligns with our earlier results.\n# 3.3. Corpus-level JSD\nAccentor\nFusedChat\nKetod\nChitchat vs. Task\n0.217\n0.323\n0.393\nChitchat vs. BST\n0.317\n0.155\n0.389\nTable 1. Divergence scores for each respective dataset between the added chitchat and the original task language, as well as between the added chitchat and typical chitchat found in BST.\nThe chitchat in Accentor exhibits the highest similarity to its respective task language, surpassing the other two datasets. In contrast, the chitchat in KETOD demonstrates the highest dissimilarity. When considering typical chitchat, the chitchat in FusedChat showcases the highest similarity, while the chitchat in KETOD is the most dissimilar, once again. These findings are intriguing as they indicate that chitchat grounded in an external source of knowledge differs the most from the language commonly observed in both task and chitchat dialogues. While BST also incorporates chitchat grounded in Wikipedia, it likely encompasses different topics. Consequently, KETOD provides the most novel information among the examined datasets. Moreover, the low divergence observed between the chitchat in FusedChat and the language in BST implies that creating a comparable dataset could involve merging snippets from BST with pre-existing TODS. In this scenario, human annotations would only be required to maintain coherence, eliminating the need for extensive human creative input to generate the complete chitchat exchanges, as is the case in FusedChat.\n# 3.4. Token-level JSD\nWe identify the top 20 keywords that exhibit the highest levels of divergence in several settings and for each dataset (Figure 4). With this analysis, we aim to provide valuable insights into the notable semantic differences that characterize each type of chitchat. In the case of Accentor, the most divergent tokens found in tables a) and c) primarily relate to service-oriented aspects. These tokens include elements from expressions like you\u2019re\n<div style=\"text-align: center;\"><img src=\"https://public-pdf-extract-kit.oss-cn-shanghai.aliyuncs.com/3e3c/3e3c5ce4-616e-4dc5-ae26-4504202aa7c3.png\" style=\"width: 50%;\"></div>\n<div style=\"text-align: center;\">ig. 4. Token-level divergences per dataset. The 20 most divergent tokens are shown in each case and are ranked according to heir JSD scores. Bar directions are in accordance with each back-to-back chart title.</div>\nwelcome and thank you, as well as task-specific keywords such as airlines and ticket. Notably, some of the most divergent tokens convey a positive sentiment, as evidenced by terms like great, good, and enjoy. This semantic quality is what could explain the higher ratings in engagingness given by human evaluators, given the little to no increase in lexical richness. In the case of FusedChat, we also observe the presence of positive sentiment in the chitchat responses (chart a), as indicated by words like fun, sounds, and good. Additionally, we notice that the chitchat displays a higher level of responsiveness to user input, utilizing interjections such as oh and pronouns such as thats (i.e., that is) and it to refer to previously mentioned information. Upon analyzing chart c), we observe a greater emphasis on the user (you, your) compared with BST. Moreover, the chitchat appears to be firmly grounded in the MultiWOZ tasks, made evident by references to entities like hotel, restaurant, and museum. In the case of KETOD, the chitchat primarily focuses on impersonal and factual aspects. In both tables a) and c), we observe the presence of prepositions (such as of and in), adjectives (like largest and American), the names of entities (such as California and San Francisco), and the determiner the. These findings indicate that the added chitchat is strongly grounded in task-oriented entities and lacks consideration of the user, contrary to the other approaches. This demonstrates potential synergy among the different types of chitchat. Lastly, the analysis of charts b) for each dataset reveals notable patterns in the most divergent tokens within BST. These tokens reflect a stronger inclination towards subjectivity, as evidenced by the presence of words like I and my. They also convey a sense of expressiveness with terms such as love and really, while introducing nuance and argumentativeness through the use of conjunctions like so and but. These findings shed light on aspects that are lacking in the chitchat used for enhancing task-oriented dialogues, suggesting areas to consider when developing future enhanced task datasets.\n# 4. DISCUSSION\nAmong the approaches considered, FusedChat emerges as the most effective in achieving diversity: enabling systems to handle both task-oriented and chitchat exchanges proves beneficial for fostering diverse interactions. In contrast, no significant variation in diversity is apparent for Accentor. The higher perceived engagement may in fact be due to the positive sentiment conveyed by the chitchat snippets, rather than response richness. While KETOD may not exhibit the highest level of diversity, its chitchat stands out as the most distinct from both task-oriented and typical chitchat language. Pushing TODs beyond the constraints of a purely task-oriented database and offering additional grounding therefore offers a valuable enhancement. We propose to expand on this idea. Indeed, an encouraging approach for enhancing TODs\ninvolves adopting a more situated dialogue framework that incorporates external knowledge about the world [26] and the user. Although the datasets in our comparison integrate chitchat language, they do not fully incorporate the methods used to collect chitchat data, apart from KETOD to a certain extent. User emotions, a backstory for the interaction, personas that reflect user preferences, and external knowledge could be leveraged to initiate and shape entire TOD conversations, resulting in more diverse and personalized TODs. We note that this will potentially make modeling TODs with current state-of-the-art approaches [27, 28, 29] more challenging, thereby also driving advancements in TOD system architectures. This proposed framework is additionally based on the fact that task-oriented and chitchat dialogues are not so distinct when it comes to human communication. In reality, most language is not purely chitchat or task-oriented but a mix of both [30]. Although the datasets studied move towards a more natural form of communication, a next step would be to further intertwine both modes and modify both user and system utterances accordingly, rather than only focusing on the system utterances, as is the case in Accentor and KETOD. As a step in this direction, we plan to ground TOD exchanges in plausible situations. One approach for creating such situations could involve summarizing chitchat from sources like FusedChat: the added chitchat in this dataset is highly task-related and often contains elements of backstory that naturally explain the user\u2019s motive for engaging with the system. However, instead of keeping chitchat and task-oriented exchanges separate, we aim to inject this information directly into the task-oriented user and system turns. By doing so, we hope to achieve a more diverse and natural dataset of TODs.\n# 5. CONCLUSION\nBased on our analysis, we find that FusedChat enhances dialogue diversity the most significantly, while Accentor enhances it the least. Additionally, our examination of the various types of added chitchat reveals some notable qualities in the language added to the datasets, such as positive sentiment, as well as the absence of others, such as nuance and argumentativeness, expressivity, and user consideration in one case. These findings suggest potential synergies between chitchats to look into as future work. Furthermore, we advocate for the development of more situated TODs, grounded in elements commonly found in chitchat datasets: user emotion, user persona, general knowledge, and user backstory. By further intertwining task and chitchat dialogues, we aim to create naturally diverse TOD datasets that are in line with natural human communication.\n[1] Bill Byrne, Karthik Krishnamoorthi, Chinnadhurai Sankar, Arvind Neelakantan, Ben Goodrich, Daniel Duckworth, Semih Yavuz, Amit Dubey, Kyu-Young Kim, and Andy Cedilnik, \u201cTaskmaster-1: Toward a realistic and diverse dialog dataset,\u201d in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLPIJCNLP), Hong Kong, China, Nov. 2019, pp. 4516\u2013 4525, Association for Computational Linguistics. [2] Ond\u02c7rej Du\u02c7sek, Jekaterina Novikova, and Verena Rieser, \u201cEvaluating the state-of-the-art of end-to-end natural language generation: The e2e nlg challenge,\u201d Computer Speech & Language, vol. 59, pp. 123\u2013156, 2020. [3] Tom\u00b4a\u02c7s Nekvinda and Ond\u02c7rej Du\u02c7sek, \u201cShades of BLEU, flavours of success: The case of MultiWOZ,\u201d in Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), Online, Aug. 2021, pp. 34\u201346, Association for Computational Linguistics. [4] Shereen Oraby, Lena Reed, Shubhangi Tandon, Sharath T.S., Stephanie Lukin, and Marilyn Walker, \u201cControlling Personality-Based Stylistic Variation with Neural Natural Language Generators,\u201d in Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue, Melbourne, Australia, July 2018, pp. 180\u2013190, Association for Computational Linguistics. [5] Glorianna Jagfeld, Sabrina Jenne, and Ngoc Thang Vu, \u201cSequence-to-Sequence Models for Data-to-Text Natural Language Generation: Word- vs. Character-based Processing and Output Diversity,\u201d in Proceedings of the 11th International Conference on Natural Language Generation, Tilburg University, The Netherlands, Nov. 2018, pp. 221\u2013232, Association for Computational Linguistics. [6] Claude Elwood Shannon, \u201cA mathematical theory of communication,\u201d The Bell system technical journal, vol. 27, no. 3, pp. 379\u2013423, 1948. [7] Christopher Manning and Hinrich Schutze, Foundations of statistical natural language processing, MIT press, 1999. [8] Pawe\u0142 Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, I\u02dcnigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Ga\u02c7si\u00b4c, \u201cMultiWOZ - a large-scale multidomain Wizard-of-Oz dataset for task-oriented dialogue modelling,\u201d in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,\n] Bill Byrne, Karthik Krishnamoorthi, Chinnadhurai Sankar, Arvind Neelakantan, Ben Goodrich, Daniel Duckworth, Semih Yavuz, Amit Dubey, Kyu-Young Kim, and Andy Cedilnik, \u201cTaskmaster-1: Toward a realistic and diverse dialog dataset,\u201d in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLPIJCNLP), Hong Kong, China, Nov. 2019, pp. 4516\u2013 4525, Association for Computational Linguistics.\n8] Pawe\u0142 Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, I\u02dcnigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Ga\u02c7si\u00b4c, \u201cMultiWOZ - a large-scale multidomain Wizard-of-Oz dataset for task-oriented dialogue modelling,\u201d in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,\n[9] Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan, \u201cTowards scalable multi-domain conversational agents: The schemaguided dialogue dataset,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, 2020, vol. 34, pp. 8689\u20138696. [10] Kai Sun, Seungwhan Moon, Paul Crook, Stephen Roller, Becka Silvert, Bing Liu, Zhiguang Wang, Honglei Liu, Eunjoon Cho, and Claire Cardie, \u201cAdding chit-chat to enhance task-oriented dialogues,\u201d in Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online, June 2021, pp. 1570\u20131583, Association for Computational Linguistics. [11] Tom Young, Frank Xing, Vlad Pandelea, Jinjie Ni, and Erik Cambria, \u201cFusing task-oriented and open-domain dialogues in conversational agents,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, 2022, vol. 36, pp. 11622\u201311629. [12] Zhiyu Chen, Bing Liu, Seungwhan Moon, Chinnadhurai Sankar, Paul Crook, and William Yang Wang, \u201cKETOD: Knowledge-enriched task-oriented dialogue,\u201d in Findings of the Association for Computational Linguistics: NAACL 2022, Seattle, United States, July 2022, pp. 2581\u20132593, Association for Computational Linguistics. [13] E. Burroughs, \u201cLexical diversity in listeners\u2019 judgments of children,\u201d Percept Mot Skills, vol. 73, no. 1, pp. 19\u2013 22, Aug 1991. [14] Hui Su, Xiaoyu Shen, Sanqiang Zhao, Zhou Xiao, Pengwei Hu, Randy Zhong, Cheng Niu, and Jie Zhou, \u201cDiversifying dialogue generation with non-conversational text,\u201d in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online, July 2020, pp. 7087\u20137097, Association for Computational Linguistics. [15] Stephen Roller, Y-Lan Boureau, Jason Weston, Antoine Bordes, Emily Dinan, Angela Fan, David Gunning, Da Ju, Margaret Li, Spencer Poff, et al., \u201cOpendomain conversational agents: Current progress, open problems, and future directions,\u201d arXiv preprint arXiv:2006.12442, 2020. [16] Eric Michael Smith, Mary Williamson, Kurt Shuster, Jason Weston, and Y-Lan Boureau, \u201cCan you put it all together: Evaluating conversational agents\u2019 ability to blend skills,\u201d in Proceedings of the 58th Annual Meeting\n[9] Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan, \u201cTowards scalable multi-domain conversational agents: The schemaguided dialogue dataset,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, 2020, vol. 34, pp. 8689\u20138696.\nof the Association for Computational Linguistics, Online, July 2020, pp. 2021\u20132030, Association for Computational Linguistics. [17] Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston, \u201cPersonalizing dialogue agents: I have a dog, do you have pets too?,\u201d in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Melbourne, Australia, July 2018, pp. 2204\u20132213, Association for Computational Linguistics. [18] Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston, \u201cWizard of wikipedia: Knowledge-powered conversational agents,\u201d in International Conference on Learning Representations, 2019. [19] Hannah Rashkin, Eric Michael Smith, Margaret Li, and Y-Lan Boureau, \u201cTowards empathetic open-domain conversation models: A new benchmark and dataset,\u201d in Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Florence, Italy, July 2019, pp. 5370\u20135381, Association for Computational Linguistics. [20] Yaqian Shi and Lei Lei, \u201cLexical richness and text length: an entropy-based perspective,\u201d Journal of Quantitative Linguistics, vol. 29, no. 1, pp. 62\u201379, 2022. [21] Jianhua Lin, \u201cDivergence measures based on the shannon entropy,\u201d IEEE Transactions on Information theory, vol. 37, no. 1, pp. 145\u2013151, 1991. [22] Solomon Kullback and Richard A Leibler, \u201cOn information and sufficiency,\u201d The annals of mathematical statistics, vol. 22, no. 1, pp. 79\u201386, 1951. [23] Jinghui Lu, Maeve Henchion, and Brian Mac Namee, \u201cDiverging divergences: Examining variants of Jensen Shannon divergence for corpus comparison tasks,\u201d in Proceedings of the Twelfth Language Resources and Evaluation Conference, Marseille, France, May 2020, pp. 6740\u20136744, European Language Resources Association. [24] Eitan Adam Pechenick, Christopher M Danforth, and Peter Sheridan Dodds, \u201cCharacterizing the google books corpus: Strong limits to inferences of sociocultural and linguistic evolution,\u201d PloS one, vol. 10, no. 10, pp. e0137041, 2015. [25] Dorottya Demszky, Jing Liu, Zid Mancenido, Julie Cohen, Heather Hill, Dan Jurafsky, and Tatsunori Hashimoto, \u201cMeasuring conversational uptake: A case study on student-teacher interactions,\u201d in Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint\nConference on Natural Language Processing (Volume 1: Long Papers), Online, Aug. 2021, pp. 1638\u20131653, Association for Computational Linguistics.\nAssociation for Computational Linguistics. [26] Mojtaba Komeili, Kurt Shuster, and Jason Weston, \u201cInternet-augmented dialogue generation,\u201d in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Dublin, Ireland, May 2022, pp. 8460\u20138478, Association for Computational Linguistics. [27] Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher, \u201cA simple language model for task-oriented dialogue,\u201d in Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, Eds. 2020, vol. 33, pp. 20179\u201320191, Curran Associates, Inc. [28] Baolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayandeh, Lars Liden, and Jianfeng Gao, \u201cSoloist: Building task bots at scale with transfer learning and machine teaching,\u201d Transactions of the Association for Computational Linguistics, vol. 9, pp. 807\u2013824, 2021. [29] Zhaojiang Lin, Andrea Madotto, Genta Indra Winata, and Pascale Fung, \u201cMinTL: Minimalist transfer learning for task-oriented dialogue systems,\u201d in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online, Nov. 2020, pp. 3391\u20133405, Association for Computational Linguistics. [30] Gillian Brown and George Yule, Teaching the spoken language, vol. 2, Cambridge university press, 1983.\n",
    "paper_type": "survey",
    "attri": {
        "background": {
            "purpose": "This survey aims to explore the enhancement of task-oriented dialogues (TODs) with chitchat to increase response diversity and engagement, addressing the challenges of repetitive and predictable responses in narrow domain dialogues.",
            "scope": "The survey focuses on three types of chitchat enhancements in TODs, specifically incorporating knowledge-based chitchat, complete chitchat exchanges, and snippets generated by chatbots. It excludes other dialogue enhancement methods not related to chitchat."
        },
        "problem": {
            "definition": "The core issue being explored is the lack of diversity in responses generated by task-oriented dialogues, which can lead to user disengagement due to repetitive interactions.",
            "key obstacle": "The primary challenge lies in effectively integrating chitchat into TODs without sacrificing the clarity and purpose of the task-oriented interactions, while also ensuring that the chitchat contributes to increased diversity."
        },
        "architecture": {
            "perspective": "The survey introduces a comparative framework for assessing the effectiveness of different chitchat enhancements in terms of lexical diversity and engagement.",
            "fields/stages": "The survey organizes the research into three stages based on the type of chitchat enhancement: knowledge-based snippets, complete exchanges, and chatbot-generated snippets, evaluating each for their impact on dialogue diversity."
        },
        "conclusion": {
            "comparisions": "FusedChat was found to enhance dialogue diversity the most significantly, while Accentor showed minimal improvements. Each enhancement type contributed differently to the perceived engagement of dialogues.",
            "results": "The key takeaway is that while certain chitchat enhancements improve engagement, they do not necessarily lead to increased lexical diversity, indicating a need for more integrated approaches in future work."
        },
        "discussion": {
            "advantage": "The existing research demonstrates the potential of chitchat to make task-oriented dialogues more engaging, particularly through the FusedChat approach, which successfully integrates both task and chitchat exchanges.",
            "limitation": "Current studies often fail to achieve significant diversity in responses, particularly with approaches like Accentor, which do not enhance the richness of the dialogue.",
            "gaps": "There remains a lack of understanding regarding how to effectively blend task-oriented and chitchat dialogues to maximize both engagement and diversity.",
            "future work": "Future research should focus on developing situated dialogue frameworks that incorporate external knowledge and user context to create more natural and diverse TODs."
        },
        "other info": {
            "dataset references": [
                "MultiWOZ",
                "Blended Skill Talk (BST)",
                "KETOD",
                "FusedChat",
                "Accentor"
            ],
            "metrics used": [
                "Shannon\u2019s text entropy",
                "Conditional next-word entropy",
                "Jensen-Shannon\u2019s Divergence"
            ]
        }
    },
    "mount_outline": [
        {
            "section number": "1.1",
            "key information": "The survey explores the enhancement of task-oriented dialogues (TODs) with chitchat to increase response diversity and engagement, highlighting the interdisciplinary nature of dialogue systems."
        },
        {
            "section number": "1.2",
            "key information": "The significance of integrating chitchat into TODs addresses the challenges of repetitive and predictable responses, thereby improving user engagement."
        },
        {
            "section number": "1.3",
            "key information": "The main objectives of the survey include exploring three types of chitchat enhancements in TODs: knowledge-based chitchat, complete chitchat exchanges, and snippets generated by chatbots."
        },
        {
            "section number": "1.4",
            "key information": "There is a need to review recent advancements in chitchat enhancements for TODs to address the lack of diversity in responses and user disengagement."
        },
        {
            "section number": "2.1",
            "key information": "The core issue being explored is the lack of diversity in responses generated by task-oriented dialogues, which can lead to user disengagement due to repetitive interactions."
        },
        {
            "section number": "2.2",
            "key information": "The survey organizes the research into three stages based on the type of chitchat enhancement: knowledge-based snippets, complete exchanges, and chatbot-generated snippets."
        },
        {
            "section number": "3.1",
            "key information": "The FusedChat approach is highlighted as a successful integration of both task-oriented and chitchat exchanges, enhancing the engagement of dialogues."
        },
        {
            "section number": "3.3",
            "key information": "The primary challenge lies in effectively integrating chitchat into TODs without sacrificing the clarity and purpose of the task-oriented interactions."
        },
        {
            "section number": "6.3",
            "key information": "Future research should focus on developing situated dialogue frameworks that incorporate external knowledge and user context to create more natural and diverse task-oriented dialogues."
        }
    ],
    "similarity_score": 0.6045232106356644,
    "image": null,
    "path": "/home/dany/codes/autosurvey/outputs/2025-01-11-1832_natur/papers/Enhancing Task-Oriented Dialogues with Chitchat_ a Comparative Study Based on Lexical Diversity and Divergence.json"
}